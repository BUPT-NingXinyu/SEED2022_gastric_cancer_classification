{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4522989d-157f-4cd4-a278-5018f6fe7f40",
   "metadata": {},
   "source": [
    "# 图像预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6326e917-16c9-429d-b9d5-feda346483dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 5 classes: ['./raw\\\\T0', './raw\\\\T1', './raw\\\\T2', './raw\\\\T3', './raw\\\\Tis']\n",
      "T0\n",
      "len(files): 5996\n",
      "boundary: 299\n",
      "T1\n",
      "len(files): 2700\n",
      "boundary: 135\n",
      "T2\n",
      "len(files): 2900\n",
      "boundary: 145\n",
      "T3\n",
      "len(files): 2700\n",
      "boundary: 135\n",
      "Tis\n",
      "len(files): 3250\n",
      "boundary: 162\n",
      "Totally 16665 files for training\n",
      "Totally 881 files for val\n"
     ]
    }
   ],
   "source": [
    "!python densenet_baseline/split_dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6c1d92-476b-4a0c-8772-97b620a1b173",
   "metadata": {},
   "source": [
    "# 统计训练集均值和标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "485701c9-8745-4920-913d-61eb74920736",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 16665 files for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████████████████████████████████████▎   | 15858/16665 [04:26<00:03, 250.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 16665 files for training\n",
      "[0.79241839 0.62130083 0.79159392]\n",
      "[0.15686465 0.2131858  0.12528739]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/16665 [00:00<?, ?it/s]\n",
      "  0%|          | 18/16665 [00:00<01:34, 176.44it/s]\n",
      "  0%|          | 39/16665 [00:00<01:25, 195.25it/s]\n",
      "  0%|          | 60/16665 [00:00<01:23, 199.25it/s]\n",
      "  0%|          | 83/16665 [00:00<01:19, 208.80it/s]\n",
      "  1%|          | 105/16665 [00:00<01:17, 212.78it/s]\n",
      "  1%|          | 128/16665 [00:00<01:16, 216.39it/s]\n",
      "  1%|          | 151/16665 [00:00<01:15, 218.66it/s]\n",
      "  1%|          | 174/16665 [00:00<01:14, 220.15it/s]\n",
      "  1%|          | 197/16665 [00:00<01:15, 218.66it/s]\n",
      "  1%|▏         | 220/16665 [00:01<01:14, 220.09it/s]\n",
      "  1%|▏         | 243/16665 [00:01<01:13, 222.38it/s]\n",
      "  2%|▏         | 266/16665 [00:01<01:13, 223.52it/s]\n",
      "  2%|▏         | 289/16665 [00:01<01:13, 224.12it/s]\n",
      "  2%|▏         | 313/16665 [00:01<01:12, 226.81it/s]\n",
      "  2%|▏         | 336/16665 [00:01<01:11, 227.09it/s]\n",
      "  2%|▏         | 361/16665 [00:01<01:10, 232.49it/s]\n",
      "  2%|▏         | 385/16665 [00:01<01:09, 233.33it/s]\n",
      "  2%|▏         | 411/16665 [00:01<01:08, 237.95it/s]\n",
      "  3%|▎         | 438/16665 [00:01<01:06, 244.51it/s]\n",
      "  3%|▎         | 465/16665 [00:02<01:04, 252.00it/s]\n",
      "  3%|▎         | 491/16665 [00:02<01:03, 254.36it/s]\n",
      "  3%|▎         | 517/16665 [00:02<01:03, 255.46it/s]\n",
      "  3%|▎         | 543/16665 [00:02<01:03, 253.07it/s]\n",
      "  3%|▎         | 569/16665 [00:02<01:04, 251.40it/s]\n",
      "  4%|▎         | 596/16665 [00:02<01:02, 255.36it/s]\n",
      "  4%|▎         | 622/16665 [00:02<01:02, 255.97it/s]\n",
      "  4%|▍         | 648/16665 [00:02<01:05, 246.26it/s]\n",
      "  4%|▍         | 673/16665 [00:02<01:06, 241.27it/s]\n",
      "  4%|▍         | 698/16665 [00:02<01:07, 235.02it/s]\n",
      "  4%|▍         | 723/16665 [00:03<01:07, 237.91it/s]\n",
      "  4%|▍         | 747/16665 [00:03<01:07, 234.65it/s]\n",
      "  5%|▍         | 771/16665 [00:03<01:08, 231.53it/s]\n",
      "  5%|▍         | 795/16665 [00:03<01:07, 233.96it/s]\n",
      "  5%|▍         | 821/16665 [00:03<01:06, 238.75it/s]\n",
      "  5%|▌         | 845/16665 [00:14<35:08,  7.50it/s] \n",
      "  5%|▌         | 858/16665 [00:14<29:02,  9.07it/s]\n",
      "  5%|▌         | 879/16665 [00:14<20:54, 12.59it/s]\n",
      "  5%|▌         | 898/16665 [00:14<15:29, 16.97it/s]\n",
      "  6%|▌         | 921/16665 [00:14<10:48, 24.26it/s]\n",
      "  6%|▌         | 944/16665 [00:14<07:44, 33.87it/s]\n",
      "  6%|▌         | 966/16665 [00:14<05:45, 45.48it/s]\n",
      "  6%|▌         | 989/16665 [00:14<04:19, 60.41it/s]\n",
      "  6%|▌         | 1011/16665 [00:15<03:23, 77.01it/s]\n",
      "  6%|▌         | 1033/16665 [00:15<02:44, 94.86it/s]\n",
      "  6%|▋         | 1055/16665 [00:15<02:18, 113.08it/s]\n",
      "  6%|▋         | 1077/16665 [00:15<01:57, 132.34it/s]\n",
      "  7%|▋         | 1100/16665 [00:15<01:43, 150.78it/s]\n",
      "  7%|▋         | 1122/16665 [00:15<01:34, 164.47it/s]\n",
      "  7%|▋         | 1145/16665 [00:15<01:26, 178.53it/s]\n",
      "  7%|▋         | 1169/16665 [00:15<01:20, 192.19it/s]\n",
      "  7%|▋         | 1192/16665 [00:15<01:17, 199.24it/s]\n",
      "  7%|▋         | 1214/16665 [00:16<01:16, 203.21it/s]\n",
      "  7%|▋         | 1237/16665 [00:16<01:14, 208.34it/s]\n",
      "  8%|▊         | 1259/16665 [00:16<01:13, 210.58it/s]\n",
      "  8%|▊         | 1281/16665 [00:16<01:13, 209.65it/s]\n",
      "  8%|▊         | 1304/16665 [00:16<01:12, 213.06it/s]\n",
      "  8%|▊         | 1328/16665 [00:16<01:10, 217.69it/s]\n",
      "  8%|▊         | 1351/16665 [00:16<01:09, 220.61it/s]\n",
      "  8%|▊         | 1375/16665 [00:16<01:07, 225.60it/s]\n",
      "  8%|▊         | 1399/16665 [00:16<01:06, 227.99it/s]\n",
      "  9%|▊         | 1422/16665 [00:16<01:06, 227.91it/s]\n",
      "  9%|▊         | 1445/16665 [00:17<01:08, 223.26it/s]\n",
      "  9%|▉         | 1468/16665 [00:17<01:08, 220.34it/s]\n",
      "  9%|▉         | 1491/16665 [00:17<01:10, 216.25it/s]\n",
      "  9%|▉         | 1513/16665 [00:17<01:10, 216.08it/s]\n",
      "  9%|▉         | 1535/16665 [00:17<01:10, 215.35it/s]\n",
      "  9%|▉         | 1558/16665 [00:17<01:08, 218.97it/s]\n",
      "  9%|▉         | 1582/16665 [00:17<01:07, 224.46it/s]\n",
      " 10%|▉         | 1606/16665 [00:17<01:06, 227.70it/s]\n",
      " 10%|▉         | 1629/16665 [00:17<01:07, 222.10it/s]\n",
      " 10%|▉         | 1653/16665 [00:18<01:06, 224.69it/s]\n",
      " 10%|█         | 1676/16665 [00:29<37:34,  6.65it/s] \n",
      " 10%|█         | 1692/16665 [00:29<29:21,  8.50it/s]\n",
      " 10%|█         | 1715/16665 [00:29<20:21, 12.24it/s]\n",
      " 10%|█         | 1738/16665 [00:29<14:19, 17.37it/s]\n",
      " 11%|█         | 1760/16665 [00:29<10:22, 23.95it/s]\n",
      " 11%|█         | 1784/16665 [00:29<07:23, 33.53it/s]\n",
      " 11%|█         | 1808/16665 [00:30<05:24, 45.77it/s]\n",
      " 11%|█         | 1831/16665 [00:30<04:06, 60.09it/s]\n",
      " 11%|█         | 1854/16665 [00:30<03:17, 74.92it/s]\n",
      " 11%|█▏        | 1875/16665 [00:30<02:55, 84.33it/s]\n",
      " 11%|█▏        | 1894/16665 [00:30<02:53, 85.37it/s]\n",
      " 12%|█▏        | 1917/16665 [00:30<02:18, 106.18it/s]\n",
      " 12%|█▏        | 1940/16665 [00:30<01:56, 126.92it/s]\n",
      " 12%|█▏        | 1963/16665 [00:31<01:40, 146.91it/s]\n",
      " 12%|█▏        | 1987/16665 [00:31<01:28, 165.49it/s]\n",
      " 12%|█▏        | 2010/16665 [00:31<01:21, 179.61it/s]\n",
      " 12%|█▏        | 2032/16665 [00:31<01:19, 184.88it/s]\n",
      " 12%|█▏        | 2056/16665 [00:31<01:13, 197.62it/s]\n",
      " 12%|█▏        | 2080/16665 [00:31<01:10, 207.34it/s]\n",
      " 13%|█▎        | 2104/16665 [00:31<01:07, 215.15it/s]\n",
      " 13%|█▎        | 2128/16665 [00:31<01:05, 220.91it/s]\n",
      " 13%|█▎        | 2151/16665 [00:31<01:05, 223.03it/s]\n",
      " 13%|█▎        | 2175/16665 [00:31<01:04, 225.98it/s]\n",
      " 13%|█▎        | 2201/16665 [00:32<01:02, 233.14it/s]\n",
      " 13%|█▎        | 2226/16665 [00:32<01:01, 236.69it/s]\n",
      " 14%|█▎        | 2252/16665 [00:32<00:59, 240.91it/s]\n",
      " 14%|█▎        | 2277/16665 [00:32<01:00, 238.00it/s]\n",
      " 14%|█▍        | 2301/16665 [00:32<01:00, 237.21it/s]\n",
      " 14%|█▍        | 2326/16665 [00:32<00:59, 240.94it/s]\n",
      " 14%|█▍        | 2352/16665 [00:32<00:58, 244.39it/s]\n",
      " 14%|█▍        | 2377/16665 [00:32<00:58, 245.32it/s]\n",
      " 14%|█▍        | 2403/16665 [00:32<00:57, 246.96it/s]\n",
      " 15%|█▍        | 2428/16665 [00:32<00:57, 246.41it/s]\n",
      " 15%|█▍        | 2454/16665 [00:33<00:57, 247.50it/s]\n",
      " 15%|█▍        | 2479/16665 [00:33<00:57, 247.59it/s]\n",
      " 15%|█▌        | 2504/16665 [00:33<00:59, 238.44it/s]\n",
      " 15%|█▌        | 2528/16665 [00:44<32:51,  7.17it/s] \n",
      " 15%|█▌        | 2552/16665 [00:44<23:30, 10.01it/s]\n",
      " 15%|█▌        | 2576/16665 [00:44<16:50, 13.94it/s]\n",
      " 16%|█▌        | 2600/16665 [00:44<12:07, 19.33it/s]\n",
      " 16%|█▌        | 2624/16665 [00:45<08:48, 26.56it/s]\n",
      " 16%|█▌        | 2648/16665 [00:45<06:28, 36.09it/s]\n",
      " 16%|█▌        | 2672/16665 [00:45<04:50, 48.20it/s]\n",
      " 16%|█▌        | 2696/16665 [00:45<03:48, 61.17it/s]\n",
      " 16%|█▋        | 2718/16665 [00:45<03:20, 69.53it/s]\n",
      " 16%|█▋        | 2737/16665 [00:45<02:53, 80.22it/s]\n",
      " 17%|█▋        | 2759/16665 [00:45<02:21, 98.50it/s]\n",
      " 17%|█▋        | 2784/16665 [00:45<01:53, 122.68it/s]\n",
      " 17%|█▋        | 2809/16665 [00:46<01:34, 146.41it/s]\n",
      " 17%|█▋        | 2834/16665 [00:46<01:22, 167.49it/s]\n",
      " 17%|█▋        | 2860/16665 [00:46<01:13, 187.22it/s]\n",
      " 17%|█▋        | 2884/16665 [00:46<01:09, 199.71it/s]\n",
      " 17%|█▋        | 2910/16665 [00:46<01:04, 214.24it/s]\n",
      " 18%|█▊        | 2936/16665 [00:46<01:01, 224.76it/s]\n",
      " 18%|█▊        | 2962/16665 [00:46<00:58, 232.57it/s]\n",
      " 18%|█▊        | 2988/16665 [00:46<00:57, 237.61it/s]\n",
      " 18%|█▊        | 3014/16665 [00:46<00:56, 242.11it/s]\n",
      " 18%|█▊        | 3040/16665 [00:46<00:55, 246.54it/s]\n",
      " 18%|█▊        | 3066/16665 [00:47<00:54, 249.72it/s]\n",
      " 19%|█▊        | 3092/16665 [00:47<00:54, 250.53it/s]\n",
      " 19%|█▊        | 3118/16665 [00:47<00:54, 249.85it/s]\n",
      " 19%|█▉        | 3144/16665 [00:47<00:55, 244.25it/s]\n",
      " 19%|█▉        | 3170/16665 [00:47<00:54, 245.95it/s]\n",
      " 19%|█▉        | 3196/16665 [00:47<00:54, 247.86it/s]\n",
      " 19%|█▉        | 3222/16665 [00:47<00:54, 248.50it/s]\n",
      " 19%|█▉        | 3248/16665 [00:47<00:53, 249.66it/s]\n",
      " 20%|█▉        | 3274/16665 [00:47<00:53, 249.23it/s]\n",
      " 20%|█▉        | 3301/16665 [00:47<00:52, 252.34it/s]\n",
      " 20%|█▉        | 3328/16665 [00:48<00:52, 254.52it/s]\n",
      " 20%|██        | 3354/16665 [00:59<28:33,  7.77it/s] \n",
      " 20%|██        | 3378/16665 [00:59<20:45, 10.67it/s]\n",
      " 20%|██        | 3403/16665 [00:59<15:21, 14.40it/s]\n",
      " 21%|██        | 3424/16665 [00:59<11:41, 18.87it/s]\n",
      " 21%|██        | 3443/16665 [00:59<09:06, 24.21it/s]\n",
      " 21%|██        | 3465/16665 [00:59<06:42, 32.81it/s]\n",
      " 21%|██        | 3492/16665 [00:59<04:41, 46.73it/s]\n",
      " 21%|██        | 3518/16665 [01:00<03:27, 63.29it/s]\n",
      " 21%|██▏       | 3544/16665 [01:00<02:38, 82.82it/s]\n",
      " 21%|██▏       | 3569/16665 [01:00<02:06, 103.38it/s]\n",
      " 22%|██▏       | 3596/16665 [01:00<01:42, 128.05it/s]\n",
      " 22%|██▏       | 3622/16665 [01:00<01:26, 150.84it/s]\n",
      " 22%|██▏       | 3649/16665 [01:00<01:14, 173.74it/s]\n",
      " 22%|██▏       | 3675/16665 [01:00<01:07, 191.38it/s]\n",
      " 22%|██▏       | 3701/16665 [01:00<01:02, 207.32it/s]\n",
      " 22%|██▏       | 3727/16665 [01:00<00:59, 218.74it/s]\n",
      " 23%|██▎       | 3753/16665 [01:01<00:56, 229.27it/s]\n",
      " 23%|██▎       | 3779/16665 [01:01<00:54, 236.40it/s]\n",
      " 23%|██▎       | 3805/16665 [01:01<00:53, 242.54it/s]\n",
      " 23%|██▎       | 3831/16665 [01:01<00:53, 240.65it/s]\n",
      " 23%|██▎       | 3857/16665 [01:01<00:52, 245.45it/s]\n",
      " 23%|██▎       | 3884/16665 [01:01<00:51, 248.94it/s]\n",
      " 23%|██▎       | 3910/16665 [01:01<00:50, 251.40it/s]\n",
      " 24%|██▎       | 3936/16665 [01:01<00:50, 251.71it/s]\n",
      " 24%|██▍       | 3963/16665 [01:01<00:49, 254.28it/s]\n",
      " 24%|██▍       | 3989/16665 [01:01<00:49, 254.47it/s]\n",
      " 24%|██▍       | 4017/16665 [01:02<00:48, 260.43it/s]\n",
      " 24%|██▍       | 4044/16665 [01:02<00:48, 260.94it/s]\n",
      " 24%|██▍       | 4071/16665 [01:02<00:48, 262.28it/s]\n",
      " 25%|██▍       | 4098/16665 [01:02<00:49, 255.52it/s]\n",
      " 25%|██▍       | 4124/16665 [01:02<00:49, 251.72it/s]\n",
      " 25%|██▍       | 4150/16665 [01:02<00:49, 251.93it/s]\n",
      " 25%|██▌       | 4176/16665 [01:13<26:52,  7.74it/s] \n",
      " 25%|██▌       | 4202/16665 [01:13<19:05, 10.88it/s]\n",
      " 25%|██▌       | 4228/16665 [01:13<13:36, 15.23it/s]\n",
      " 26%|██▌       | 4255/16665 [01:13<09:39, 21.42it/s]\n",
      " 26%|██▌       | 4282/16665 [01:14<06:56, 29.73it/s]\n",
      " 26%|██▌       | 4308/16665 [01:14<05:07, 40.14it/s]\n",
      " 26%|██▌       | 4334/16665 [01:14<03:51, 53.22it/s]\n",
      " 26%|██▌       | 4359/16665 [01:14<03:04, 66.64it/s]\n",
      " 26%|██▋       | 4382/16665 [01:14<02:37, 77.84it/s]\n",
      " 26%|██▋       | 4402/16665 [01:14<02:14, 91.14it/s]\n",
      " 27%|██▋       | 4422/16665 [01:14<01:54, 106.49it/s]\n",
      " 27%|██▋       | 4446/16665 [01:14<01:34, 128.69it/s]\n",
      " 27%|██▋       | 4473/16665 [01:15<01:18, 155.79it/s]\n",
      " 27%|██▋       | 4500/16665 [01:15<01:07, 179.36it/s]\n",
      " 27%|██▋       | 4526/16665 [01:15<01:01, 197.98it/s]\n",
      " 27%|██▋       | 4551/16665 [01:15<00:57, 210.52it/s]\n",
      " 27%|██▋       | 4578/16665 [01:15<00:53, 223.84it/s]\n",
      " 28%|██▊       | 4606/16665 [01:15<00:50, 237.15it/s]\n",
      " 28%|██▊       | 4632/16665 [01:15<00:49, 242.15it/s]\n",
      " 28%|██▊       | 4658/16665 [01:15<00:48, 247.20it/s]\n",
      " 28%|██▊       | 4685/16665 [01:15<00:47, 250.87it/s]\n",
      " 28%|██▊       | 4712/16665 [01:15<00:47, 253.72it/s]\n",
      " 28%|██▊       | 4739/16665 [01:16<00:46, 256.21it/s]\n",
      " 29%|██▊       | 4766/16665 [01:16<00:46, 257.97it/s]\n",
      " 29%|██▉       | 4793/16665 [01:16<00:45, 260.91it/s]\n",
      " 29%|██▉       | 4820/16665 [01:16<00:47, 248.95it/s]\n",
      " 29%|██▉       | 4846/16665 [01:16<00:46, 252.09it/s]\n",
      " 29%|██▉       | 4873/16665 [01:16<00:46, 254.32it/s]\n",
      " 29%|██▉       | 4901/16665 [01:16<00:45, 259.50it/s]\n",
      " 30%|██▉       | 4928/16665 [01:16<00:44, 261.04it/s]\n",
      " 30%|██▉       | 4955/16665 [01:16<00:44, 262.33it/s]\n",
      " 30%|██▉       | 4983/16665 [01:16<00:43, 266.73it/s]\n",
      " 30%|███       | 5010/16665 [01:27<24:06,  8.06it/s] \n",
      " 30%|███       | 5036/16665 [01:28<17:17, 11.21it/s]\n",
      " 30%|███       | 5063/16665 [01:28<12:17, 15.74it/s]\n",
      " 31%|███       | 5090/16665 [01:28<08:48, 21.88it/s]\n",
      " 31%|███       | 5116/16665 [01:28<06:32, 29.43it/s]\n",
      " 31%|███       | 5140/16665 [01:28<05:02, 38.12it/s]\n",
      " 31%|███       | 5162/16665 [01:28<03:56, 48.66it/s]\n",
      " 31%|███       | 5189/16665 [01:28<02:54, 65.69it/s]\n",
      " 31%|███▏      | 5216/16665 [01:28<02:13, 85.86it/s]\n",
      " 31%|███▏      | 5242/16665 [01:29<01:46, 107.41it/s]\n",
      " 32%|███▏      | 5269/16665 [01:29<01:26, 131.14it/s]\n",
      " 32%|███▏      | 5296/16665 [01:29<01:13, 154.92it/s]\n",
      " 32%|███▏      | 5322/16665 [01:29<01:05, 173.90it/s]\n",
      " 32%|███▏      | 5349/16665 [01:29<00:58, 194.68it/s]\n",
      " 32%|███▏      | 5375/16665 [01:29<00:53, 210.31it/s]\n",
      " 32%|███▏      | 5401/16665 [01:29<00:50, 222.40it/s]\n",
      " 33%|███▎      | 5427/16665 [01:29<00:48, 231.79it/s]\n",
      " 33%|███▎      | 5453/16665 [01:29<00:47, 237.84it/s]\n",
      " 33%|███▎      | 5481/16665 [01:29<00:45, 246.90it/s]\n",
      " 33%|███▎      | 5508/16665 [01:30<00:44, 251.32it/s]\n",
      " 33%|███▎      | 5535/16665 [01:30<00:43, 253.25it/s]\n",
      " 33%|███▎      | 5562/16665 [01:30<00:43, 256.60it/s]\n",
      " 34%|███▎      | 5589/16665 [01:30<00:44, 248.93it/s]\n",
      " 34%|███▎      | 5616/16665 [01:30<00:43, 254.18it/s]\n",
      " 34%|███▍      | 5643/16665 [01:30<00:42, 257.26it/s]\n",
      " 34%|███▍      | 5669/16665 [01:30<00:43, 255.08it/s]\n",
      " 34%|███▍      | 5695/16665 [01:30<00:42, 255.77it/s]\n",
      " 34%|███▍      | 5721/16665 [01:30<00:43, 252.82it/s]\n",
      " 34%|███▍      | 5747/16665 [01:30<00:43, 249.81it/s]\n",
      " 35%|███▍      | 5773/16665 [01:31<00:43, 247.74it/s]\n",
      " 35%|███▍      | 5798/16665 [01:31<00:44, 245.75it/s]\n",
      " 35%|███▍      | 5823/16665 [01:31<00:44, 242.05it/s]\n",
      " 35%|███▌      | 5848/16665 [01:42<23:59,  7.51it/s] \n",
      " 35%|███▌      | 5861/16665 [01:42<19:55,  9.04it/s]\n",
      " 35%|███▌      | 5882/16665 [01:42<14:24, 12.47it/s]\n",
      " 35%|███▌      | 5901/16665 [01:42<10:45, 16.68it/s]\n",
      " 36%|███▌      | 5919/16665 [01:42<08:09, 21.94it/s]\n",
      " 36%|███▌      | 5942/16665 [01:42<05:42, 31.26it/s]\n",
      " 36%|███▌      | 5966/16665 [01:43<04:04, 43.85it/s]\n",
      " 36%|███▌      | 5992/16665 [01:43<02:55, 60.82it/s]\n",
      " 36%|███▌      | 6017/16665 [01:43<02:13, 79.96it/s]\n",
      " 36%|███▌      | 6041/16665 [01:43<01:46, 99.97it/s]\n",
      " 36%|███▋      | 6068/16665 [01:43<01:24, 125.20it/s]\n",
      " 37%|███▋      | 6094/16665 [01:43<01:11, 148.18it/s]\n",
      " 37%|███▋      | 6119/16665 [01:43<01:02, 168.74it/s]\n",
      " 37%|███▋      | 6144/16665 [01:43<00:56, 186.93it/s]\n",
      " 37%|███▋      | 6170/16665 [01:43<00:51, 202.82it/s]\n",
      " 37%|███▋      | 6195/16665 [01:43<00:49, 213.24it/s]\n",
      " 37%|███▋      | 6220/16665 [01:44<00:47, 221.25it/s]\n",
      " 37%|███▋      | 6245/16665 [01:44<00:45, 227.42it/s]\n",
      " 38%|███▊      | 6270/16665 [01:44<00:45, 226.76it/s]\n",
      " 38%|███▊      | 6294/16665 [01:44<00:45, 228.54it/s]\n",
      " 38%|███▊      | 6318/16665 [01:44<00:44, 231.13it/s]\n",
      " 38%|███▊      | 6343/16665 [01:44<00:43, 235.21it/s]\n",
      " 38%|███▊      | 6369/16665 [01:44<00:42, 239.62it/s]\n",
      " 38%|███▊      | 6394/16665 [01:44<00:42, 241.93it/s]\n",
      " 39%|███▊      | 6420/16665 [01:44<00:41, 244.63it/s]\n",
      " 39%|███▊      | 6446/16665 [01:44<00:41, 248.40it/s]\n",
      " 39%|███▉      | 6473/16665 [01:45<00:40, 254.01it/s]\n",
      " 39%|███▉      | 6500/16665 [01:45<00:39, 258.19it/s]\n",
      " 39%|███▉      | 6526/16665 [01:45<00:39, 256.45it/s]\n",
      " 39%|███▉      | 6552/16665 [01:45<00:40, 250.11it/s]\n",
      " 39%|███▉      | 6578/16665 [01:45<00:40, 247.23it/s]\n",
      " 40%|███▉      | 6603/16665 [01:45<00:41, 244.50it/s]\n",
      " 40%|███▉      | 6628/16665 [01:45<00:41, 243.28it/s]\n",
      " 40%|███▉      | 6653/16665 [01:45<00:41, 241.23it/s]\n",
      " 40%|████      | 6678/16665 [01:45<00:41, 240.97it/s]\n",
      " 40%|████      | 6703/16665 [01:56<22:19,  7.44it/s] \n",
      " 40%|████      | 6730/16665 [01:57<15:27, 10.72it/s]\n",
      " 41%|████      | 6755/16665 [01:57<11:04, 14.91it/s]\n",
      " 41%|████      | 6780/16665 [01:57<07:59, 20.64it/s]\n",
      " 41%|████      | 6805/16665 [01:57<05:57, 27.61it/s]\n",
      " 41%|████      | 6827/16665 [01:57<04:39, 35.14it/s]\n",
      " 41%|████      | 6851/16665 [01:57<03:28, 47.05it/s]\n",
      " 41%|████▏     | 6875/16665 [01:57<02:38, 61.72it/s]\n",
      " 41%|████▏     | 6899/16665 [01:57<02:03, 79.17it/s]\n",
      " 42%|████▏     | 6926/16665 [01:58<01:35, 102.22it/s]\n",
      " 42%|████▏     | 6950/16665 [01:58<01:19, 122.11it/s]\n",
      " 42%|████▏     | 6975/16665 [01:58<01:07, 144.24it/s]\n",
      " 42%|████▏     | 6999/16665 [01:58<01:00, 160.79it/s]\n",
      " 42%|████▏     | 7023/16665 [01:58<00:54, 177.77it/s]\n",
      " 42%|████▏     | 7047/16665 [01:58<00:50, 189.43it/s]\n",
      " 42%|████▏     | 7071/16665 [01:58<00:48, 197.16it/s]\n",
      " 43%|████▎     | 7094/16665 [01:58<00:46, 204.61it/s]\n",
      " 43%|████▎     | 7117/16665 [01:58<00:45, 208.76it/s]\n",
      " 43%|████▎     | 7140/16665 [01:58<00:44, 213.44it/s]\n",
      " 43%|████▎     | 7164/16665 [01:59<00:43, 217.84it/s]\n",
      " 43%|████▎     | 7187/16665 [01:59<00:43, 220.22it/s]\n",
      " 43%|████▎     | 7210/16665 [01:59<00:43, 215.59it/s]\n",
      " 43%|████▎     | 7233/16665 [01:59<00:43, 218.45it/s]\n",
      " 44%|████▎     | 7256/16665 [01:59<00:42, 220.50it/s]\n",
      " 44%|████▎     | 7279/16665 [01:59<00:42, 223.25it/s]\n",
      " 44%|████▍     | 7302/16665 [01:59<00:41, 224.57it/s]\n",
      " 44%|████▍     | 7326/16665 [01:59<00:41, 227.11it/s]\n",
      " 44%|████▍     | 7350/16665 [01:59<00:40, 229.74it/s]\n",
      " 44%|████▍     | 7376/16665 [02:00<00:39, 235.20it/s]\n",
      " 44%|████▍     | 7401/16665 [02:00<00:38, 239.54it/s]\n",
      " 45%|████▍     | 7427/16665 [02:00<00:37, 245.05it/s]\n",
      " 45%|████▍     | 7452/16665 [02:00<00:38, 240.81it/s]\n",
      " 45%|████▍     | 7477/16665 [02:00<00:38, 241.38it/s]\n",
      " 45%|████▌     | 7502/16665 [02:00<00:37, 243.19it/s]\n",
      " 45%|████▌     | 7527/16665 [02:11<20:46,  7.33it/s] \n",
      " 45%|████▌     | 7553/16665 [02:11<14:30, 10.47it/s]\n",
      " 45%|████▌     | 7578/16665 [02:11<10:20, 14.64it/s]\n",
      " 46%|████▌     | 7603/16665 [02:11<07:25, 20.35it/s]\n",
      " 46%|████▌     | 7629/16665 [02:12<05:18, 28.38it/s]\n",
      " 46%|████▌     | 7655/16665 [02:12<03:51, 38.91it/s]\n",
      " 46%|████▌     | 7681/16665 [02:12<02:51, 52.35it/s]\n",
      " 46%|████▌     | 7707/16665 [02:12<02:11, 68.19it/s]\n",
      " 46%|████▋     | 7732/16665 [02:12<01:43, 86.43it/s]\n",
      " 47%|████▋     | 7757/16665 [02:12<01:23, 107.01it/s]\n",
      " 47%|████▋     | 7783/16665 [02:12<01:08, 130.21it/s]\n",
      " 47%|████▋     | 7809/16665 [02:12<00:57, 153.19it/s]\n",
      " 47%|████▋     | 7835/16665 [02:12<00:51, 172.60it/s]\n",
      " 47%|████▋     | 7861/16665 [02:12<00:46, 190.39it/s]\n",
      " 47%|████▋     | 7887/16665 [02:13<00:42, 206.10it/s]\n",
      " 47%|████▋     | 7913/16665 [02:13<00:39, 219.39it/s]\n",
      " 48%|████▊     | 7939/16665 [02:13<00:39, 223.65it/s]\n",
      " 48%|████▊     | 7964/16665 [02:13<00:37, 229.52it/s]\n",
      " 48%|████▊     | 7989/16665 [02:13<00:37, 233.90it/s]\n",
      " 48%|████▊     | 8014/16665 [02:13<00:36, 238.44it/s]\n",
      " 48%|████▊     | 8040/16665 [02:13<00:35, 243.24it/s]\n",
      " 48%|████▊     | 8066/16665 [02:13<00:34, 245.96it/s]\n",
      " 49%|████▊     | 8092/16665 [02:13<00:34, 248.08it/s]\n",
      " 49%|████▊     | 8118/16665 [02:14<00:34, 250.10it/s]\n",
      " 49%|████▉     | 8145/16665 [02:14<00:33, 253.70it/s]\n",
      " 49%|████▉     | 8171/16665 [02:14<00:33, 252.70it/s]\n",
      " 49%|████▉     | 8197/16665 [02:14<00:34, 246.88it/s]\n",
      " 49%|████▉     | 8223/16665 [02:14<00:33, 250.66it/s]\n",
      " 50%|████▉     | 8250/16665 [02:14<00:32, 255.57it/s]\n",
      " 50%|████▉     | 8276/16665 [02:14<00:32, 256.12it/s]\n",
      " 50%|████▉     | 8302/16665 [02:14<00:32, 253.52it/s]\n",
      " 50%|████▉     | 8328/16665 [02:14<00:33, 251.01it/s]\n",
      " 50%|█████     | 8354/16665 [02:25<17:56,  7.72it/s] \n",
      " 50%|█████     | 8379/16665 [02:25<12:50, 10.75it/s]\n",
      " 50%|█████     | 8404/16665 [02:26<09:12, 14.94it/s]\n",
      " 51%|█████     | 8429/16665 [02:26<06:38, 20.69it/s]\n",
      " 51%|█████     | 8454/16665 [02:26<04:49, 28.34it/s]\n",
      " 51%|█████     | 8479/16665 [02:26<03:36, 37.82it/s]\n",
      " 51%|█████     | 8502/16665 [02:26<02:46, 48.96it/s]\n",
      " 51%|█████     | 8529/16665 [02:26<02:02, 66.33it/s]\n",
      " 51%|█████▏    | 8555/16665 [02:26<01:34, 85.83it/s]\n",
      " 51%|█████▏    | 8581/16665 [02:26<01:15, 107.30it/s]\n",
      " 52%|█████▏    | 8607/16665 [02:26<01:02, 129.74it/s]\n",
      " 52%|█████▏    | 8633/16665 [02:27<00:52, 152.60it/s]\n",
      " 52%|█████▏    | 8659/16665 [02:27<00:45, 174.08it/s]\n",
      " 52%|█████▏    | 8685/16665 [02:27<00:42, 189.91it/s]\n",
      " 52%|█████▏    | 8710/16665 [02:27<00:39, 199.50it/s]\n",
      " 52%|█████▏    | 8736/16665 [02:27<00:37, 213.56it/s]\n",
      " 53%|█████▎    | 8761/16665 [02:27<00:35, 221.95it/s]\n",
      " 53%|█████▎    | 8786/16665 [02:27<00:34, 228.95it/s]\n",
      " 53%|█████▎    | 8811/16665 [02:27<00:33, 234.17it/s]\n",
      " 53%|█████▎    | 8836/16665 [02:27<00:32, 237.57it/s]\n",
      " 53%|█████▎    | 8862/16665 [02:27<00:32, 243.32it/s]\n",
      " 53%|█████▎    | 8889/16665 [02:28<00:31, 250.36it/s]\n",
      " 53%|█████▎    | 8915/16665 [02:28<00:30, 251.92it/s]\n",
      " 54%|█████▎    | 8941/16665 [02:28<00:31, 243.56it/s]\n",
      " 54%|█████▍    | 8966/16665 [02:28<00:31, 244.00it/s]\n",
      " 54%|█████▍    | 8992/16665 [02:28<00:30, 248.63it/s]\n",
      " 54%|█████▍    | 9018/16665 [02:28<00:30, 250.49it/s]\n",
      " 54%|█████▍    | 9046/16665 [02:28<00:29, 256.89it/s]\n",
      " 54%|█████▍    | 9074/16665 [02:28<00:28, 262.91it/s]\n",
      " 55%|█████▍    | 9102/16665 [02:28<00:28, 266.60it/s]\n",
      " 55%|█████▍    | 9129/16665 [02:29<00:28, 265.25it/s]\n",
      " 55%|█████▍    | 9156/16665 [02:29<00:28, 259.01it/s]\n",
      " 55%|█████▌    | 9182/16665 [02:29<00:29, 252.18it/s]\n",
      " 55%|█████▌    | 9182/16665 [02:40<00:29, 252.18it/s]\n",
      " 55%|█████▌    | 9185/16665 [02:40<21:14,  5.87it/s] \n",
      " 55%|█████▌    | 9210/16665 [02:40<13:52,  8.95it/s]\n",
      " 55%|█████▌    | 9236/16665 [02:40<09:20, 13.26it/s]\n",
      " 56%|█████▌    | 9259/16665 [02:40<06:46, 18.23it/s]\n",
      " 56%|█████▌    | 9281/16665 [02:40<04:56, 24.90it/s]\n",
      " 56%|█████▌    | 9306/16665 [02:40<03:29, 35.05it/s]\n",
      " 56%|█████▌    | 9331/16665 [02:40<02:32, 48.03it/s]\n",
      " 56%|█████▌    | 9357/16665 [02:40<01:52, 64.75it/s]\n",
      " 56%|█████▋    | 9383/16665 [02:41<01:26, 84.39it/s]\n",
      " 56%|█████▋    | 9408/16665 [02:41<01:09, 105.01it/s]\n",
      " 57%|█████▋    | 9433/16665 [02:41<00:57, 126.40it/s]\n",
      " 57%|█████▋    | 9459/16665 [02:41<00:48, 149.69it/s]\n",
      " 57%|█████▋    | 9484/16665 [02:41<00:42, 168.29it/s]\n",
      " 57%|█████▋    | 9510/16665 [02:41<00:38, 187.45it/s]\n",
      " 57%|█████▋    | 9536/16665 [02:41<00:35, 202.92it/s]\n",
      " 57%|█████▋    | 9561/16665 [02:41<00:33, 213.23it/s]\n",
      " 58%|█████▊    | 9586/16665 [02:41<00:31, 221.94it/s]\n",
      " 58%|█████▊    | 9611/16665 [02:42<00:30, 228.98it/s]\n",
      " 58%|█████▊    | 9636/16665 [02:42<00:30, 234.21it/s]\n",
      " 58%|█████▊    | 9661/16665 [02:42<00:29, 237.55it/s]\n",
      " 58%|█████▊    | 9687/16665 [02:42<00:28, 241.24it/s]\n",
      " 58%|█████▊    | 9713/16665 [02:42<00:28, 245.25it/s]\n",
      " 58%|█████▊    | 9738/16665 [02:42<00:28, 245.21it/s]\n",
      " 59%|█████▊    | 9764/16665 [02:42<00:27, 249.54it/s]\n",
      " 59%|█████▊    | 9790/16665 [02:42<00:27, 248.95it/s]\n",
      " 59%|█████▉    | 9816/16665 [02:42<00:27, 245.23it/s]\n",
      " 59%|█████▉    | 9841/16665 [02:42<00:27, 244.49it/s]\n",
      " 59%|█████▉    | 9867/16665 [02:43<00:27, 247.56it/s]\n",
      " 59%|█████▉    | 9892/16665 [02:43<00:27, 246.31it/s]\n",
      " 60%|█████▉    | 9918/16665 [02:43<00:27, 248.86it/s]\n",
      " 60%|█████▉    | 9943/16665 [02:43<00:27, 246.30it/s]\n",
      " 60%|█████▉    | 9968/16665 [02:43<00:27, 245.23it/s]\n",
      " 60%|█████▉    | 9993/16665 [02:43<00:27, 243.06it/s]\n",
      " 60%|██████    | 10018/16665 [02:43<00:27, 244.38it/s]\n",
      " 60%|██████    | 10043/16665 [02:54<14:52,  7.42it/s] \n",
      " 60%|██████    | 10059/16665 [02:54<11:48,  9.32it/s]\n",
      " 60%|██████    | 10081/16665 [02:54<08:26, 13.00it/s]\n",
      " 61%|██████    | 10107/16665 [02:55<05:44, 19.03it/s]\n",
      " 61%|██████    | 10133/16665 [02:55<04:00, 27.14it/s]\n",
      " 61%|██████    | 10159/16665 [02:55<02:52, 37.78it/s]\n",
      " 61%|██████    | 10184/16665 [02:55<02:07, 50.64it/s]\n",
      " 61%|██████▏   | 10210/16665 [02:55<01:35, 67.44it/s]\n",
      " 61%|██████▏   | 10237/16665 [02:55<01:13, 88.03it/s]\n",
      " 62%|██████▏   | 10263/16665 [02:55<00:58, 109.76it/s]\n",
      " 62%|██████▏   | 10289/16665 [02:55<00:48, 132.11it/s]\n",
      " 62%|██████▏   | 10315/16665 [02:55<00:41, 154.34it/s]\n",
      " 62%|██████▏   | 10341/16665 [02:55<00:36, 175.12it/s]\n",
      " 62%|██████▏   | 10368/16665 [02:56<00:32, 195.54it/s]\n",
      " 62%|██████▏   | 10395/16665 [02:56<00:29, 211.62it/s]\n",
      " 63%|██████▎   | 10422/16665 [02:56<00:27, 225.36it/s]\n",
      " 63%|██████▎   | 10448/16665 [02:56<00:27, 227.91it/s]\n",
      " 63%|██████▎   | 10474/16665 [02:56<00:26, 230.35it/s]\n",
      " 63%|██████▎   | 10500/16665 [02:56<00:25, 237.79it/s]\n",
      " 63%|██████▎   | 10526/16665 [02:56<00:25, 243.33it/s]\n",
      " 63%|██████▎   | 10552/16665 [02:56<00:24, 245.98it/s]\n",
      " 63%|██████▎   | 10578/16665 [02:56<00:24, 243.57it/s]\n",
      " 64%|██████▎   | 10605/16665 [02:56<00:24, 249.70it/s]\n",
      " 64%|██████▍   | 10631/16665 [02:57<00:24, 246.97it/s]\n",
      " 64%|██████▍   | 10656/16665 [02:57<00:24, 247.13it/s]\n",
      " 64%|██████▍   | 10681/16665 [02:57<00:24, 243.72it/s]\n",
      " 64%|██████▍   | 10707/16665 [02:57<00:24, 245.59it/s]\n",
      " 64%|██████▍   | 10732/16665 [02:57<00:24, 244.04it/s]\n",
      " 65%|██████▍   | 10758/16665 [02:57<00:23, 246.53it/s]\n",
      " 65%|██████▍   | 10784/16665 [02:57<00:23, 249.00it/s]\n",
      " 65%|██████▍   | 10809/16665 [02:57<00:23, 247.12it/s]\n",
      " 65%|██████▌   | 10836/16665 [02:57<00:23, 251.62it/s]\n",
      " 65%|██████▌   | 10862/16665 [03:08<12:30,  7.73it/s] \n",
      " 65%|██████▌   | 10888/16665 [03:08<08:49, 10.90it/s]\n",
      " 65%|██████▌   | 10915/16665 [03:09<06:11, 15.47it/s]\n",
      " 66%|██████▌   | 10941/16665 [03:09<04:27, 21.44it/s]\n",
      " 66%|██████▌   | 10967/16665 [03:09<03:16, 29.01it/s]\n",
      " 66%|██████▌   | 10990/16665 [03:09<02:29, 37.86it/s]\n",
      " 66%|██████▌   | 11014/16665 [03:09<01:52, 50.08it/s]\n",
      " 66%|██████▌   | 11038/16665 [03:09<01:26, 65.03it/s]\n",
      " 66%|██████▋   | 11063/16665 [03:09<01:06, 83.70it/s]\n",
      " 67%|██████▋   | 11087/16665 [03:09<00:54, 103.02it/s]\n",
      " 67%|██████▋   | 11112/16665 [03:09<00:44, 124.90it/s]\n",
      " 67%|██████▋   | 11137/16665 [03:10<00:37, 146.69it/s]\n",
      " 67%|██████▋   | 11161/16665 [03:10<00:33, 164.67it/s]\n",
      " 67%|██████▋   | 11185/16665 [03:10<00:31, 176.77it/s]\n",
      " 67%|██████▋   | 11209/16665 [03:10<00:28, 189.51it/s]\n",
      " 67%|██████▋   | 11232/16665 [03:10<00:27, 198.18it/s]\n",
      " 68%|██████▊   | 11256/16665 [03:10<00:26, 207.52it/s]\n",
      " 68%|██████▊   | 11280/16665 [03:10<00:25, 214.58it/s]\n",
      " 68%|██████▊   | 11304/16665 [03:10<00:24, 218.00it/s]\n",
      " 68%|██████▊   | 11328/16665 [03:10<00:24, 221.33it/s]\n",
      " 68%|██████▊   | 11351/16665 [03:11<00:23, 222.52it/s]\n",
      " 68%|██████▊   | 11375/16665 [03:11<00:23, 224.96it/s]\n",
      " 68%|██████▊   | 11398/16665 [03:11<00:23, 224.64it/s]\n",
      " 69%|██████▊   | 11421/16665 [03:11<00:23, 221.69it/s]\n",
      " 69%|██████▊   | 11445/16665 [03:11<00:22, 226.98it/s]\n",
      " 69%|██████▉   | 11469/16665 [03:11<00:22, 228.78it/s]\n",
      " 69%|██████▉   | 11493/16665 [03:11<00:22, 232.06it/s]\n",
      " 69%|██████▉   | 11518/16665 [03:11<00:21, 235.96it/s]\n",
      " 69%|██████▉   | 11542/16665 [03:11<00:21, 233.27it/s]\n",
      " 69%|██████▉   | 11566/16665 [03:11<00:21, 233.17it/s]\n",
      " 70%|██████▉   | 11590/16665 [03:12<00:21, 232.47it/s]\n",
      " 70%|██████▉   | 11614/16665 [03:12<00:21, 230.82it/s]\n",
      " 70%|██████▉   | 11639/16665 [03:12<00:21, 232.35it/s]\n",
      " 70%|██████▉   | 11663/16665 [03:12<00:22, 227.31it/s]\n",
      " 70%|███████   | 11687/16665 [03:12<00:21, 228.98it/s]\n",
      " 70%|███████   | 11710/16665 [03:23<12:02,  6.86it/s] \n",
      " 70%|███████   | 11732/16665 [03:23<08:41,  9.45it/s]\n",
      " 71%|███████   | 11755/16665 [03:24<06:11, 13.23it/s]\n",
      " 71%|███████   | 11779/16665 [03:24<04:22, 18.63it/s]\n",
      " 71%|███████   | 11803/16665 [03:24<03:07, 25.89it/s]\n",
      " 71%|███████   | 11826/16665 [03:24<02:19, 34.65it/s]\n",
      " 71%|███████   | 11848/16665 [03:24<01:48, 44.51it/s]\n",
      " 71%|███████   | 11868/16665 [03:24<01:26, 55.61it/s]\n",
      " 71%|███████▏  | 11892/16665 [03:24<01:05, 73.34it/s]\n",
      " 71%|███████▏  | 11915/16665 [03:24<00:51, 92.31it/s]\n",
      " 72%|███████▏  | 11938/16665 [03:24<00:41, 112.58it/s]\n",
      " 72%|███████▏  | 11961/16665 [03:25<00:35, 132.83it/s]\n",
      " 72%|███████▏  | 11985/16665 [03:25<00:30, 153.56it/s]\n",
      " 72%|███████▏  | 12009/16665 [03:25<00:27, 172.38it/s]\n",
      " 72%|███████▏  | 12032/16665 [03:25<00:28, 164.16it/s]\n",
      " 72%|███████▏  | 12053/16665 [03:25<00:27, 170.06it/s]\n",
      " 72%|███████▏  | 12077/16665 [03:25<00:24, 185.29it/s]\n",
      " 73%|███████▎  | 12100/16665 [03:25<00:23, 196.75it/s]\n",
      " 73%|███████▎  | 12124/16665 [03:25<00:22, 206.14it/s]\n",
      " 73%|███████▎  | 12147/16665 [03:25<00:21, 212.29it/s]\n",
      " 73%|███████▎  | 12171/16665 [03:26<00:20, 218.25it/s]\n",
      " 73%|███████▎  | 12195/16665 [03:26<00:20, 222.55it/s]\n",
      " 73%|███████▎  | 12219/16665 [03:26<00:19, 225.16it/s]\n",
      " 73%|███████▎  | 12242/16665 [03:26<00:19, 222.07it/s]\n",
      " 74%|███████▎  | 12266/16665 [03:26<00:19, 227.24it/s]\n",
      " 74%|███████▎  | 12289/16665 [03:26<00:19, 227.38it/s]\n",
      " 74%|███████▍  | 12313/16665 [03:26<00:18, 229.73it/s]\n",
      " 74%|███████▍  | 12337/16665 [03:26<00:18, 231.39it/s]\n",
      " 74%|███████▍  | 12361/16665 [03:26<00:18, 231.20it/s]\n",
      " 74%|███████▍  | 12385/16665 [03:26<00:18, 230.61it/s]\n",
      " 74%|███████▍  | 12409/16665 [03:27<00:18, 232.68it/s]\n",
      " 75%|███████▍  | 12433/16665 [03:27<00:18, 230.76it/s]\n",
      " 75%|███████▍  | 12457/16665 [03:27<00:18, 232.99it/s]\n",
      " 75%|███████▍  | 12481/16665 [03:27<00:18, 225.75it/s]\n",
      " 75%|███████▌  | 12505/16665 [03:27<00:18, 227.88it/s]\n",
      " 75%|███████▌  | 12528/16665 [03:38<09:58,  6.91it/s] \n",
      " 75%|███████▌  | 12551/16665 [03:38<07:05,  9.66it/s]\n",
      " 75%|███████▌  | 12576/16665 [03:38<04:55, 13.82it/s]\n",
      " 76%|███████▌  | 12600/16665 [03:38<03:30, 19.27it/s]\n",
      " 76%|███████▌  | 12624/16665 [03:39<02:31, 26.59it/s]\n",
      " 76%|███████▌  | 12649/16665 [03:39<01:49, 36.71it/s]\n",
      " 76%|███████▌  | 12673/16665 [03:39<01:21, 48.97it/s]\n",
      " 76%|███████▌  | 12697/16665 [03:39<01:06, 59.51it/s]\n",
      " 76%|███████▋  | 12721/16665 [03:39<00:51, 76.62it/s]\n",
      " 76%|███████▋  | 12745/16665 [03:39<00:40, 95.87it/s]\n",
      " 77%|███████▋  | 12769/16665 [03:39<00:33, 116.55it/s]\n",
      " 77%|███████▋  | 12793/16665 [03:39<00:28, 137.59it/s]\n",
      " 77%|███████▋  | 12818/16665 [03:39<00:24, 158.49it/s]\n",
      " 77%|███████▋  | 12842/16665 [03:40<00:21, 176.29it/s]\n",
      " 77%|███████▋  | 12866/16665 [03:40<00:19, 190.65it/s]\n",
      " 77%|███████▋  | 12890/16665 [03:40<00:18, 201.09it/s]\n",
      " 77%|███████▋  | 12914/16665 [03:40<00:20, 184.98it/s]\n",
      " 78%|███████▊  | 12936/16665 [03:40<00:20, 179.43it/s]\n",
      " 78%|███████▊  | 12957/16665 [03:40<00:19, 186.57it/s]\n",
      " 78%|███████▊  | 12980/16665 [03:40<00:18, 196.85it/s]\n",
      " 78%|███████▊  | 13003/16665 [03:40<00:17, 204.88it/s]\n",
      " 78%|███████▊  | 13027/16665 [03:40<00:17, 212.27it/s]\n",
      " 78%|███████▊  | 13051/16665 [03:41<00:16, 218.85it/s]\n",
      " 78%|███████▊  | 13074/16665 [03:41<00:16, 221.53it/s]\n",
      " 79%|███████▊  | 13098/16665 [03:41<00:15, 223.64it/s]\n",
      " 79%|███████▊  | 13121/16665 [03:41<00:15, 221.63it/s]\n",
      " 79%|███████▉  | 13144/16665 [03:41<00:15, 223.41it/s]\n",
      " 79%|███████▉  | 13167/16665 [03:41<00:15, 224.02it/s]\n",
      " 79%|███████▉  | 13191/16665 [03:41<00:15, 228.03it/s]\n",
      " 79%|███████▉  | 13215/16665 [03:41<00:15, 228.86it/s]\n",
      " 79%|███████▉  | 13239/16665 [03:41<00:14, 229.73it/s]\n",
      " 80%|███████▉  | 13263/16665 [03:41<00:14, 231.39it/s]\n",
      " 80%|███████▉  | 13287/16665 [03:42<00:14, 231.87it/s]\n",
      " 80%|███████▉  | 13311/16665 [03:42<00:14, 233.77it/s]\n",
      " 80%|████████  | 13335/16665 [03:42<00:14, 231.51it/s]\n",
      " 80%|████████  | 13359/16665 [03:42<00:14, 227.98it/s]\n",
      " 80%|████████  | 13382/16665 [03:53<07:59,  6.84it/s] \n",
      " 80%|████████  | 13406/16665 [03:53<05:36,  9.69it/s]\n",
      " 81%|████████  | 13430/16665 [03:53<03:57, 13.63it/s]\n",
      " 81%|████████  | 13454/16665 [03:54<02:48, 19.02it/s]\n",
      " 81%|████████  | 13477/16665 [03:54<02:02, 25.96it/s]\n",
      " 81%|████████  | 13501/16665 [03:54<01:29, 35.54it/s]\n",
      " 81%|████████  | 13524/16665 [03:54<01:07, 46.40it/s]\n",
      " 81%|████████▏ | 13546/16665 [03:54<00:55, 56.01it/s]\n",
      " 81%|████████▏ | 13565/16665 [03:54<00:47, 65.85it/s]\n",
      " 82%|████████▏ | 13584/16665 [03:54<00:38, 79.96it/s]\n",
      " 82%|████████▏ | 13609/16665 [03:54<00:29, 103.30it/s]\n",
      " 82%|████████▏ | 13633/16665 [03:54<00:24, 125.83it/s]\n",
      " 82%|████████▏ | 13659/16665 [03:55<00:19, 150.68it/s]\n",
      " 82%|████████▏ | 13685/16665 [03:55<00:17, 173.88it/s]\n",
      " 82%|████████▏ | 13709/16665 [03:55<00:15, 187.59it/s]\n",
      " 82%|████████▏ | 13734/16665 [03:55<00:14, 201.61it/s]\n",
      " 83%|████████▎ | 13760/16665 [03:55<00:13, 214.60it/s]\n",
      " 83%|████████▎ | 13785/16665 [03:55<00:12, 223.53it/s]\n",
      " 83%|████████▎ | 13810/16665 [03:55<00:12, 227.71it/s]\n",
      " 83%|████████▎ | 13835/16665 [03:55<00:12, 226.96it/s]\n",
      " 83%|████████▎ | 13859/16665 [03:55<00:12, 227.61it/s]\n",
      " 83%|████████▎ | 13884/16665 [03:56<00:12, 231.33it/s]\n",
      " 83%|████████▎ | 13909/16665 [03:56<00:11, 235.99it/s]\n",
      " 84%|████████▎ | 13933/16665 [03:56<00:11, 235.28it/s]\n",
      " 84%|████████▍ | 13957/16665 [03:56<00:11, 229.96it/s]\n",
      " 84%|████████▍ | 13981/16665 [03:56<00:11, 224.46it/s]\n",
      " 84%|████████▍ | 14007/16665 [03:56<00:11, 231.91it/s]\n",
      " 84%|████████▍ | 14031/16665 [03:56<00:11, 233.56it/s]\n",
      " 84%|████████▍ | 14056/16665 [03:56<00:11, 236.95it/s]\n",
      " 85%|████████▍ | 14082/16665 [03:56<00:10, 241.01it/s]\n",
      " 85%|████████▍ | 14108/16665 [03:56<00:10, 244.41it/s]\n",
      " 85%|████████▍ | 14134/16665 [03:57<00:10, 248.97it/s]\n",
      " 85%|████████▍ | 14160/16665 [03:57<00:10, 249.49it/s]\n",
      " 85%|████████▌ | 14185/16665 [03:57<00:10, 240.46it/s]\n",
      " 85%|████████▌ | 14210/16665 [04:08<05:37,  7.28it/s] \n",
      " 85%|████████▌ | 14225/16665 [04:08<04:30,  9.01it/s]\n",
      " 85%|████████▌ | 14247/16665 [04:08<03:13, 12.50it/s]\n",
      " 86%|████████▌ | 14272/16665 [04:08<02:12, 18.10it/s]\n",
      " 86%|████████▌ | 14298/16665 [04:09<01:31, 25.95it/s]\n",
      " 86%|████████▌ | 14322/16665 [04:09<01:06, 35.45it/s]\n",
      " 86%|████████▌ | 14346/16665 [04:09<00:48, 47.57it/s]\n",
      " 86%|████████▌ | 14372/16665 [04:09<00:35, 64.09it/s]\n",
      " 86%|████████▋ | 14398/16665 [04:09<00:27, 83.62it/s]\n",
      " 87%|████████▋ | 14424/16665 [04:09<00:21, 105.47it/s]\n",
      " 87%|████████▋ | 14451/16665 [04:09<00:17, 129.82it/s]\n",
      " 87%|████████▋ | 14477/16665 [04:09<00:14, 152.90it/s]\n",
      " 87%|████████▋ | 14503/16665 [04:09<00:12, 171.18it/s]\n",
      " 87%|████████▋ | 14528/16665 [04:10<00:11, 185.30it/s]\n",
      " 87%|████████▋ | 14553/16665 [04:10<00:10, 198.26it/s]\n",
      " 87%|████████▋ | 14578/16665 [04:10<00:09, 208.76it/s]\n",
      " 88%|████████▊ | 14603/16665 [04:10<00:09, 212.32it/s]\n",
      " 88%|████████▊ | 14629/16665 [04:10<00:09, 222.60it/s]\n",
      " 88%|████████▊ | 14654/16665 [04:10<00:08, 228.21it/s]\n",
      " 88%|████████▊ | 14680/16665 [04:10<00:08, 235.75it/s]\n",
      " 88%|████████▊ | 14705/16665 [04:10<00:08, 237.77it/s]\n",
      " 88%|████████▊ | 14731/16665 [04:10<00:08, 241.56it/s]\n",
      " 89%|████████▊ | 14756/16665 [04:10<00:07, 241.90it/s]\n",
      " 89%|████████▊ | 14781/16665 [04:11<00:07, 240.76it/s]\n",
      " 89%|████████▉ | 14806/16665 [04:11<00:07, 240.85it/s]\n",
      " 89%|████████▉ | 14831/16665 [04:11<00:07, 232.69it/s]\n",
      " 89%|████████▉ | 14855/16665 [04:11<00:07, 231.48it/s]\n",
      " 89%|████████▉ | 14881/16665 [04:11<00:07, 237.59it/s]\n",
      " 89%|████████▉ | 14905/16665 [04:11<00:07, 238.28it/s]\n",
      " 90%|████████▉ | 14931/16665 [04:11<00:07, 243.91it/s]\n",
      " 90%|████████▉ | 14957/16665 [04:11<00:06, 245.75it/s]\n",
      " 90%|████████▉ | 14982/16665 [04:11<00:06, 241.65it/s]\n",
      " 90%|█████████ | 15007/16665 [04:12<00:06, 242.67it/s]\n",
      " 90%|█████████ | 15032/16665 [04:23<03:45,  7.23it/s] \n",
      " 90%|█████████ | 15046/16665 [04:23<03:02,  8.85it/s]\n",
      " 90%|█████████ | 15068/16665 [04:23<02:08, 12.40it/s]\n",
      " 91%|█████████ | 15088/16665 [04:23<01:33, 16.80it/s]\n",
      " 91%|█████████ | 15108/16665 [04:23<01:08, 22.69it/s]\n",
      " 91%|█████████ | 15129/16665 [04:23<00:49, 31.01it/s]\n",
      " 91%|█████████ | 15152/16665 [04:24<00:35, 42.83it/s]\n",
      " 91%|█████████ | 15175/16665 [04:24<00:25, 57.43it/s]\n",
      " 91%|█████████ | 15198/16665 [04:24<00:19, 74.68it/s]\n",
      " 91%|█████████▏| 15222/16665 [04:24<00:15, 95.07it/s]\n",
      " 91%|█████████▏| 15247/16665 [04:24<00:11, 118.20it/s]\n",
      " 92%|█████████▏| 15272/16665 [04:24<00:09, 141.35it/s]\n",
      " 92%|█████████▏| 15297/16665 [04:24<00:08, 162.00it/s]\n",
      " 92%|█████████▏| 15323/16665 [04:24<00:07, 183.40it/s]\n",
      " 92%|█████████▏| 15348/16665 [04:24<00:06, 197.19it/s]\n",
      " 92%|█████████▏| 15373/16665 [04:24<00:06, 205.38it/s]\n",
      " 92%|█████████▏| 15397/16665 [04:25<00:06, 208.43it/s]\n",
      " 93%|█████████▎| 15421/16665 [04:25<00:05, 212.42it/s]\n",
      " 93%|█████████▎| 15444/16665 [04:25<00:05, 214.28it/s]\n",
      " 93%|█████████▎| 15467/16665 [04:25<00:05, 215.06it/s]\n",
      " 93%|█████████▎| 15490/16665 [04:25<00:05, 218.63it/s]\n",
      " 93%|█████████▎| 15513/16665 [04:25<00:05, 219.99it/s]\n",
      " 93%|█████████▎| 15536/16665 [04:25<00:05, 220.96it/s]\n",
      " 93%|█████████▎| 15559/16665 [04:25<00:04, 223.58it/s]\n",
      " 94%|█████████▎| 15582/16665 [04:25<00:04, 224.30it/s]\n",
      " 94%|█████████▎| 15605/16665 [04:25<00:04, 225.31it/s]\n",
      " 94%|█████████▍| 15629/16665 [04:26<00:04, 226.97it/s]\n",
      " 94%|█████████▍| 15652/16665 [04:26<00:04, 224.09it/s]\n",
      " 94%|█████████▍| 15675/16665 [04:26<00:04, 218.79it/s]\n",
      " 94%|█████████▍| 15697/16665 [04:26<00:04, 218.50it/s]\n",
      " 94%|█████████▍| 15721/16665 [04:26<00:04, 222.17it/s]\n",
      " 94%|█████████▍| 15744/16665 [04:26<00:04, 222.51it/s]\n",
      " 95%|█████████▍| 15768/16665 [04:26<00:03, 224.99it/s]\n",
      " 95%|█████████▍| 15791/16665 [04:26<00:03, 225.79it/s]\n",
      " 95%|█████████▍| 15815/16665 [04:26<00:03, 227.48it/s]\n",
      " 95%|█████████▌| 15839/16665 [04:27<00:03, 229.14it/s]\n",
      " 95%|█████████▌| 15863/16665 [04:27<00:03, 230.97it/s]\n",
      " 95%|█████████▌| 15887/16665 [04:38<01:54,  6.78it/s] \n",
      " 95%|█████████▌| 15901/16665 [04:38<01:31,  8.38it/s]\n",
      " 96%|█████████▌| 15922/16665 [04:38<01:03, 11.70it/s]\n",
      " 96%|█████████▌| 15944/16665 [04:38<00:43, 16.57it/s]\n",
      " 96%|█████████▌| 15966/16665 [04:39<00:30, 23.13it/s]\n",
      " 96%|█████████▌| 15988/16665 [04:39<00:21, 31.80it/s]\n",
      " 96%|█████████▌| 16011/16665 [04:39<00:15, 43.45it/s]\n",
      " 96%|█████████▌| 16034/16665 [04:39<00:10, 57.81it/s]\n",
      " 96%|█████████▋| 16059/16665 [04:39<00:07, 76.77it/s]\n",
      " 97%|█████████▋| 16083/16665 [04:39<00:06, 96.98it/s]\n",
      " 97%|█████████▋| 16108/16665 [04:39<00:04, 119.71it/s]\n",
      " 97%|█████████▋| 16132/16665 [04:39<00:03, 140.74it/s]\n",
      " 97%|█████████▋| 16157/16665 [04:39<00:03, 161.53it/s]\n",
      " 97%|█████████▋| 16182/16665 [04:39<00:02, 179.99it/s]\n",
      " 97%|█████████▋| 16208/16665 [04:40<00:02, 198.69it/s]\n",
      " 97%|█████████▋| 16234/16665 [04:40<00:02, 213.35it/s]\n",
      " 98%|█████████▊| 16259/16665 [04:40<00:01, 219.02it/s]\n",
      " 98%|█████████▊| 16284/16665 [04:40<00:01, 227.43it/s]\n",
      " 98%|█████████▊| 16309/16665 [04:40<00:01, 231.16it/s]\n",
      " 98%|█████████▊| 16334/16665 [04:40<00:01, 235.82it/s]\n",
      " 98%|█████████▊| 16359/16665 [04:40<00:01, 239.21it/s]\n",
      " 98%|█████████▊| 16384/16665 [04:40<00:01, 240.94it/s]\n",
      " 98%|█████████▊| 16410/16665 [04:40<00:01, 243.25it/s]\n",
      " 99%|█████████▊| 16436/16665 [04:41<00:00, 245.99it/s]\n",
      " 99%|█████████▉| 16462/16665 [04:41<00:00, 249.35it/s]\n",
      " 99%|█████████▉| 16488/16665 [04:41<00:00, 248.30it/s]\n",
      " 99%|█████████▉| 16513/16665 [04:41<00:00, 241.05it/s]\n",
      " 99%|█████████▉| 16538/16665 [04:41<00:00, 243.62it/s]\n",
      " 99%|█████████▉| 16564/16665 [04:41<00:00, 246.96it/s]\n",
      "100%|█████████▉| 16589/16665 [04:41<00:00, 245.69it/s]\n",
      "100%|█████████▉| 16615/16665 [04:41<00:00, 247.70it/s]\n",
      "100%|█████████▉| 16640/16665 [04:41<00:00, 242.17it/s]\n",
      "100%|██████████| 16665/16665 [04:41<00:00, 240.94it/s]\n",
      "100%|██████████| 16665/16665 [04:41<00:00, 59.10it/s] \n",
      "100%|████████████████████████████████████████████████████████████████████████████| 16665/16665 [04:41<00:00, 59.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79241839 0.62130083 0.79159392]\n",
      "[0.15686465 0.2131858  0.12528739]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%run densenet_baseline/statistic_mean_std.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c979c-6c56-4cd4-8cb7-b14f23e7893b",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f100b6d-755b-438f-9106-65d3609223b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bat_resnext26ts', 'cspresnext50', 'cspresnext50_iabn', 'dla60_res2next', 'eca_botnext26ts_256', 'eca_halonext26ts', 'eca_lambda_resnext26ts', 'eca_swinnext26ts_256', 'ecaresnext26t_32x4d', 'ecaresnext50t_32x4d', 'gcresnext26ts', 'gluon_resnext50_32x4d', 'gluon_resnext101_32x4d', 'gluon_resnext101_64x4d', 'gluon_seresnext50_32x4d', 'gluon_seresnext101_32x4d', 'gluon_seresnext101_64x4d', 'ig_resnext101_32x8d', 'ig_resnext101_32x16d', 'ig_resnext101_32x32d', 'ig_resnext101_32x48d', 'legacy_seresnext26_32x4d', 'legacy_seresnext50_32x4d', 'legacy_seresnext101_32x4d', 'res2next50', 'resnext50_32x4d', 'resnext50d_32x4d', 'resnext101_32x4d', 'resnext101_32x8d', 'resnext101_64x4d', 'seresnext26d_32x4d', 'seresnext26t_32x4d', 'seresnext26tn_32x4d', 'seresnext50_32x4d', 'seresnext101_32x4d', 'seresnext101_32x8d', 'skresnext50_32x4d', 'ssl_resnext50_32x4d', 'ssl_resnext101_32x4d', 'ssl_resnext101_32x8d', 'ssl_resnext101_32x16d', 'swsl_resnext50_32x4d', 'swsl_resnext101_32x4d', 'swsl_resnext101_32x8d', 'swsl_resnext101_32x16d', 'tv_resnext50_32x4d']\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "model_resnet = timm.list_models('*next*')\n",
    "print(model_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a24d7f3c-98bc-454f-8bee-e7b8d8e5bc1d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mode...\n",
      "train transform\n",
      "finding classes from ./train:\t['T0', 'T1', 'T2', 'T3', 'Tis']\n",
      "mapping classes from ./train to indexes:\t{'T0': 0, 'T1': 1, 'T2': 2, 'T3': 3, 'Tis': 4}\n",
      "eval transform\n",
      "finding classes from ./val:\t['T0', 'T1', 'T2', 'T3', 'Tis']\n",
      "mapping classes from ./val to indexes:\t{'T0': 0, 'T1': 1, 'T2': 2, 'T3': 3, 'Tis': 4}\n",
      "number of params (M): 12.49\n",
      "Epoch 0\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:28 loss: 1.7699 (1.7699) acc1: 0.0000 (0.0000) acc5: 100.0000 (100.0000) time: 0.5030 data: 0.0980 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 1.8231 (1.8316) acc1: 0.0000 (0.5682) acc5: 100.0000 (100.0000) time: 0.2895 data: 0.0978 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 1.8312 (1.8424) acc1: 0.0000 (0.8929) acc5: 100.0000 (100.0000) time: 0.2671 data: 0.0965 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 1.8524 (1.8242) acc1: 0.0000 (2.2177) acc5: 100.0000 (100.0000) time: 0.2688 data: 0.0971 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 1.6184 (1.7463) acc1: 6.2500 (11.5854) acc5: 100.0000 (100.0000) time: 0.2704 data: 0.0999 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 1.5138 (1.6959) acc1: 18.7500 (16.0539) acc5: 100.0000 (100.0000) time: 0.2684 data: 0.1014 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 1.5138 (1.6908) acc1: 12.5000 (14.9830) acc5: 100.0000 (100.0000) time: 0.2571 data: 0.0967 max mem: 15137\n",
      "Test: Total time: 0:00:15 (0.2686 s / it)\n",
      "* Acc@1 14.983 Acc@5 100.000 loss 1.691\n",
      "Accuracy of the network on the 881 test image: 15.0%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 1, Step: 0, Loss: 1.6973960399627686, Lr:0.0001\n",
      "Epoch 1, Step: 1, Loss: 1.544543981552124, Lr:0.0001\n",
      "Epoch 1, Step: 2, Loss: 1.582716941833496, Lr:0.0001\n",
      "Epoch 1, Step: 3, Loss: 1.5380935668945312, Lr:0.0001\n",
      "Epoch 1, Step: 4, Loss: 1.4352707862854004, Lr:0.0001\n",
      "Epoch 1, Step: 5, Loss: 1.4829435348510742, Lr:0.0001\n",
      "Epoch 1, Step: 6, Loss: 1.3067117929458618, Lr:0.0001\n",
      "Epoch 1, Step: 7, Loss: 1.3530657291412354, Lr:0.0001\n",
      "Epoch 1, Step: 8, Loss: 1.2288912534713745, Lr:0.0001\n",
      "Epoch 1, Step: 9, Loss: 1.5571750402450562, Lr:0.0001\n",
      "Epoch 1, Step: 10, Loss: 1.3655685186386108, Lr:0.0001\n",
      "Epoch 1, Step: 11, Loss: 1.496111512184143, Lr:0.0001\n",
      "Epoch 1, Step: 12, Loss: 1.3369768857955933, Lr:0.0001\n",
      "Epoch 1, Step: 13, Loss: 1.0849192142486572, Lr:0.0001\n",
      "Epoch 1, Step: 14, Loss: 1.4389375448226929, Lr:0.0001\n",
      "Epoch 1, Step: 15, Loss: 1.069746732711792, Lr:0.0001\n",
      "Epoch 1, Step: 16, Loss: 1.1319801807403564, Lr:0.0001\n",
      "Epoch 1, Step: 17, Loss: 0.8783531785011292, Lr:0.0001\n",
      "Epoch 1, Step: 18, Loss: 1.108572006225586, Lr:0.0001\n",
      "Epoch 1, Step: 19, Loss: 1.060986876487732, Lr:0.0001\n",
      "Epoch 1, Step: 20, Loss: 0.9336009621620178, Lr:0.0001\n",
      "Epoch 1, Step: 21, Loss: 0.9035230875015259, Lr:0.0001\n",
      "Epoch 1, Step: 22, Loss: 1.0142186880111694, Lr:0.0001\n",
      "Epoch 1, Step: 23, Loss: 1.2773947715759277, Lr:0.0001\n",
      "Epoch 1, Step: 24, Loss: 0.9303524494171143, Lr:0.0001\n",
      "Epoch 1, Step: 25, Loss: 1.4573158025741577, Lr:0.0001\n",
      "Epoch 1, Step: 26, Loss: 1.1138803958892822, Lr:0.0001\n",
      "Epoch 1, Step: 27, Loss: 1.0183919668197632, Lr:0.0001\n",
      "Epoch 1, Step: 28, Loss: 0.828114926815033, Lr:0.0001\n",
      "Epoch 1, Step: 29, Loss: 0.8778843879699707, Lr:0.0001\n",
      "Epoch 1, Step: 30, Loss: 1.078149676322937, Lr:0.0001\n",
      "Epoch 1, Step: 31, Loss: 0.9085819721221924, Lr:0.0001\n",
      "Epoch 1, Step: 32, Loss: 0.7541934847831726, Lr:0.0001\n",
      "Epoch 1, Step: 33, Loss: 1.0368868112564087, Lr:0.0001\n",
      "Epoch 1, Step: 34, Loss: 0.967619776725769, Lr:0.0001\n",
      "Epoch 1, Step: 35, Loss: 0.969378650188446, Lr:0.0001\n",
      "Epoch 1, Step: 36, Loss: 0.747833788394928, Lr:0.0001\n",
      "Epoch 1, Step: 37, Loss: 0.9407617449760437, Lr:0.0001\n",
      "Epoch 1, Step: 38, Loss: 0.7220109105110168, Lr:0.0001\n",
      "Epoch 1, Step: 39, Loss: 1.0087448358535767, Lr:0.0001\n",
      "Epoch 1, Step: 40, Loss: 0.8234980702400208, Lr:0.0001\n",
      "Epoch 1, Step: 41, Loss: 0.9087669253349304, Lr:0.0001\n",
      "Epoch 1, Step: 42, Loss: 1.2802501916885376, Lr:0.0001\n",
      "Epoch 1, Step: 43, Loss: 0.8215301632881165, Lr:0.0001\n",
      "Epoch 1, Step: 44, Loss: 0.8042308688163757, Lr:0.0001\n",
      "Epoch 1, Step: 45, Loss: 0.794231116771698, Lr:0.0001\n",
      "Epoch 1, Step: 46, Loss: 0.8823502063751221, Lr:0.0001\n",
      "Epoch 1, Step: 47, Loss: 0.9113330245018005, Lr:0.0001\n",
      "Epoch 1, Step: 48, Loss: 0.6845049262046814, Lr:0.0001\n",
      "Epoch 1, Step: 49, Loss: 0.7941651940345764, Lr:0.0001\n",
      "Epoch 1, Step: 50, Loss: 1.083296775817871, Lr:0.0001\n",
      "Epoch 1, Step: 51, Loss: 0.7530471086502075, Lr:0.0001\n",
      "Epoch 1, Step: 52, Loss: 1.498706579208374, Lr:0.0001\n",
      "Epoch 1, Step: 53, Loss: 0.5964454412460327, Lr:0.0001\n",
      "Epoch 1, Step: 54, Loss: 1.212285041809082, Lr:0.0001\n",
      "Epoch 1, Step: 55, Loss: 0.8388792276382446, Lr:0.0001\n",
      "Epoch 1, Step: 56, Loss: 0.8041278123855591, Lr:0.0001\n",
      "Epoch 1, Step: 57, Loss: 1.0512195825576782, Lr:0.0001\n",
      "Epoch 1, Step: 58, Loss: 0.5825299620628357, Lr:0.0001\n",
      "Epoch 1, Step: 59, Loss: 0.5103759765625, Lr:0.0001\n",
      "Epoch 1, Step: 60, Loss: 0.8933444619178772, Lr:0.0001\n",
      "Epoch 1, Step: 61, Loss: 1.5177996158599854, Lr:0.0001\n",
      "Epoch 1, Step: 62, Loss: 0.6890427470207214, Lr:0.0001\n",
      "Epoch 1, Step: 63, Loss: 1.3040692806243896, Lr:0.0001\n",
      "Epoch 1, Step: 64, Loss: 1.0213580131530762, Lr:0.0001\n",
      "Epoch 1, Step: 65, Loss: 1.17179536819458, Lr:0.0001\n",
      "Epoch 1, Step: 66, Loss: 0.9841827750205994, Lr:0.0001\n",
      "Epoch 1, Step: 67, Loss: 0.710205078125, Lr:0.0001\n",
      "Epoch 1, Step: 68, Loss: 0.7194782495498657, Lr:0.0001\n",
      "Epoch 1, Step: 69, Loss: 0.8340956568717957, Lr:0.0001\n",
      "Epoch 1, Step: 70, Loss: 0.7086541056632996, Lr:0.0001\n",
      "Epoch 1, Step: 71, Loss: 0.6710280776023865, Lr:0.0001\n",
      "Epoch 1, Step: 72, Loss: 0.6138982176780701, Lr:0.0001\n",
      "Epoch 1, Step: 73, Loss: 0.9355280995368958, Lr:0.0001\n",
      "Epoch 1, Step: 74, Loss: 1.158984661102295, Lr:0.0001\n",
      "Epoch 1, Step: 75, Loss: 0.7262443900108337, Lr:0.0001\n",
      "Epoch 1, Step: 76, Loss: 0.6781335473060608, Lr:0.0001\n",
      "Epoch 1, Step: 77, Loss: 0.5879462957382202, Lr:0.0001\n",
      "Epoch 1, Step: 78, Loss: 0.7004786133766174, Lr:0.0001\n",
      "Epoch 1, Step: 79, Loss: 0.8454513549804688, Lr:0.0001\n",
      "Epoch 1, Step: 80, Loss: 0.8028707504272461, Lr:0.0001\n",
      "Epoch 1, Step: 81, Loss: 0.7291163802146912, Lr:0.0001\n",
      "Epoch 1, Step: 82, Loss: 0.7818902134895325, Lr:0.0001\n",
      "Epoch 1, Step: 83, Loss: 0.8043265342712402, Lr:0.0001\n",
      "Epoch 1, Step: 84, Loss: 1.1402480602264404, Lr:0.0001\n",
      "Epoch 1, Step: 85, Loss: 1.4755189418792725, Lr:0.0001\n",
      "Epoch 1, Step: 86, Loss: 0.7651737928390503, Lr:0.0001\n",
      "Epoch 1, Step: 87, Loss: 0.9135196805000305, Lr:0.0001\n",
      "Epoch 1, Step: 88, Loss: 0.5649079084396362, Lr:0.0001\n",
      "Epoch 1, Step: 89, Loss: 1.0799214839935303, Lr:0.0001\n",
      "Epoch 1, Step: 90, Loss: 0.4368453025817871, Lr:0.0001\n",
      "Epoch 1, Step: 91, Loss: 0.9267116785049438, Lr:0.0001\n",
      "Epoch 1, Step: 92, Loss: 0.7781553268432617, Lr:0.0001\n",
      "Epoch 1, Step: 93, Loss: 1.017022728919983, Lr:0.0001\n",
      "Epoch 1, Step: 94, Loss: 1.1824212074279785, Lr:0.0001\n",
      "Epoch 1, Step: 95, Loss: 0.8446303009986877, Lr:0.0001\n",
      "Epoch 1, Step: 96, Loss: 0.6491325497627258, Lr:0.0001\n",
      "Epoch 1, Step: 97, Loss: 0.9974867701530457, Lr:0.0001\n",
      "Epoch 1, Step: 98, Loss: 0.6970595717430115, Lr:0.0001\n",
      "Epoch 1, Step: 99, Loss: 0.610873818397522, Lr:0.0001\n",
      "Epoch 1, Step: 100, Loss: 0.8738764524459839, Lr:0.0001\n",
      "Epoch 1, Step: 101, Loss: 0.6745910048484802, Lr:0.0001\n",
      "Epoch 1, Step: 102, Loss: 0.95191490650177, Lr:0.0001\n",
      "Epoch 1, Step: 103, Loss: 0.6874308586120605, Lr:0.0001\n",
      "Epoch 1, Step: 104, Loss: 0.5998125672340393, Lr:0.0001\n",
      "Epoch 1, Step: 105, Loss: 0.7593015432357788, Lr:0.0001\n",
      "Epoch 1, Step: 106, Loss: 1.153991937637329, Lr:0.0001\n",
      "Epoch 1, Step: 107, Loss: 0.8551086187362671, Lr:0.0001\n",
      "Epoch 1, Step: 108, Loss: 1.069488525390625, Lr:0.0001\n",
      "Epoch 1, Step: 109, Loss: 0.7293617129325867, Lr:0.0001\n",
      "Epoch 1, Step: 110, Loss: 0.7645618915557861, Lr:0.0001\n",
      "Epoch 1, Step: 111, Loss: 1.1935713291168213, Lr:0.0001\n",
      "Epoch 1, Step: 112, Loss: 0.6944856643676758, Lr:0.0001\n",
      "Epoch 1, Step: 113, Loss: 0.6387999653816223, Lr:0.0001\n",
      "Epoch 1, Step: 114, Loss: 1.0654677152633667, Lr:0.0001\n",
      "Epoch 1, Step: 115, Loss: 0.8478732705116272, Lr:0.0001\n",
      "Epoch 1, Step: 116, Loss: 0.5821612477302551, Lr:0.0001\n",
      "Epoch 1, Step: 117, Loss: 0.6848269701004028, Lr:0.0001\n",
      "Epoch 1, Step: 118, Loss: 0.5933542847633362, Lr:0.0001\n",
      "Epoch 1, Step: 119, Loss: 0.99146968126297, Lr:0.0001\n",
      "Epoch 1, Step: 120, Loss: 1.378467321395874, Lr:0.0001\n",
      "Epoch 1, Step: 121, Loss: 0.7433828115463257, Lr:0.0001\n",
      "Epoch 1, Step: 122, Loss: 0.8386849164962769, Lr:0.0001\n",
      "Epoch 1, Step: 123, Loss: 0.5507156848907471, Lr:0.0001\n",
      "Epoch 1, Step: 124, Loss: 0.6612483859062195, Lr:0.0001\n",
      "Epoch 1, Step: 125, Loss: 0.5989246964454651, Lr:0.0001\n",
      "Epoch 1, Step: 126, Loss: 0.4979884922504425, Lr:0.0001\n",
      "Epoch 1, Step: 127, Loss: 0.839759886264801, Lr:0.0001\n",
      "Epoch 1, Step: 128, Loss: 0.6193350553512573, Lr:0.0001\n",
      "Epoch 1, Step: 129, Loss: 0.4976601004600525, Lr:0.0001\n",
      "Epoch 1, Step: 130, Loss: 0.45481523871421814, Lr:0.0001\n",
      "Epoch 1, Step: 131, Loss: 0.9472653865814209, Lr:0.0001\n",
      "Epoch 1, Step: 132, Loss: 0.5164496898651123, Lr:0.0001\n",
      "Epoch 1, Step: 133, Loss: 0.611989438533783, Lr:0.0001\n",
      "Epoch 1, Step: 134, Loss: 0.49943724274635315, Lr:0.0001\n",
      "Epoch 1, Step: 135, Loss: 0.5496605634689331, Lr:0.0001\n",
      "Epoch 1, Step: 136, Loss: 0.9141651391983032, Lr:0.0001\n",
      "Epoch 1, Step: 137, Loss: 0.8206714391708374, Lr:0.0001\n",
      "Epoch 1, Step: 138, Loss: 0.8405635952949524, Lr:0.0001\n",
      "Epoch 1, Step: 139, Loss: 0.5531077980995178, Lr:0.0001\n",
      "Epoch 1, Step: 140, Loss: 0.6975234150886536, Lr:0.0001\n",
      "Epoch 1, Step: 141, Loss: 0.7429094314575195, Lr:0.0001\n",
      "Epoch 1, Step: 142, Loss: 1.0926374197006226, Lr:0.0001\n",
      "Epoch 1, Step: 143, Loss: 0.6958277821540833, Lr:0.0001\n",
      "Epoch 1, Step: 144, Loss: 0.5995410680770874, Lr:0.0001\n",
      "Epoch 1, Step: 145, Loss: 0.5899417996406555, Lr:0.0001\n",
      "Epoch 1, Step: 146, Loss: 0.5038034915924072, Lr:0.0001\n",
      "Epoch 1, Step: 147, Loss: 0.3358037769794464, Lr:0.0001\n",
      "Epoch 1, Step: 148, Loss: 0.8651750683784485, Lr:0.0001\n",
      "Epoch 1, Step: 149, Loss: 0.6157971620559692, Lr:0.0001\n",
      "Epoch 1, Step: 150, Loss: 1.0532946586608887, Lr:0.0001\n",
      "Epoch 1, Step: 151, Loss: 0.4825001657009125, Lr:0.0001\n",
      "Epoch 1, Step: 152, Loss: 1.013995885848999, Lr:0.0001\n",
      "Epoch 1, Step: 153, Loss: 0.6288926005363464, Lr:0.0001\n",
      "Epoch 1, Step: 154, Loss: 0.7451801300048828, Lr:0.0001\n",
      "Epoch 1, Step: 155, Loss: 1.2770159244537354, Lr:0.0001\n",
      "Epoch 1, Step: 156, Loss: 1.156269907951355, Lr:0.0001\n",
      "Epoch 1, Step: 157, Loss: 0.7580957412719727, Lr:0.0001\n",
      "Epoch 1, Step: 158, Loss: 0.5428147315979004, Lr:0.0001\n",
      "Epoch 1, Step: 159, Loss: 0.8071688413619995, Lr:0.0001\n",
      "Epoch 1, Step: 160, Loss: 0.4380013644695282, Lr:0.0001\n",
      "Epoch 1, Step: 161, Loss: 0.7721096873283386, Lr:0.0001\n",
      "Epoch 1, Step: 162, Loss: 0.504082977771759, Lr:0.0001\n",
      "Epoch 1, Step: 163, Loss: 0.9142147302627563, Lr:0.0001\n",
      "Epoch 1, Step: 164, Loss: 0.7655238509178162, Lr:0.0001\n",
      "Epoch 1, Step: 165, Loss: 0.633942186832428, Lr:0.0001\n",
      "Epoch 1, Step: 166, Loss: 0.8195083141326904, Lr:0.0001\n",
      "Epoch 1, Step: 167, Loss: 0.5111666321754456, Lr:0.0001\n",
      "Epoch 1, Step: 168, Loss: 0.41026949882507324, Lr:0.0001\n",
      "Epoch 1, Step: 169, Loss: 0.5905875563621521, Lr:0.0001\n",
      "Epoch 1, Step: 170, Loss: 0.8430712819099426, Lr:0.0001\n",
      "Epoch 1, Step: 171, Loss: 0.6136767268180847, Lr:0.0001\n",
      "Epoch 1, Step: 172, Loss: 0.5234375596046448, Lr:0.0001\n",
      "Epoch 1, Step: 173, Loss: 0.5822821259498596, Lr:0.0001\n",
      "Epoch 1, Step: 174, Loss: 0.9371781349182129, Lr:0.0001\n",
      "Epoch 1, Step: 175, Loss: 0.9836046695709229, Lr:0.0001\n",
      "Epoch 1, Step: 176, Loss: 0.8837101459503174, Lr:0.0001\n",
      "Epoch 1, Step: 177, Loss: 0.5651606321334839, Lr:0.0001\n",
      "Epoch 1, Step: 178, Loss: 0.7400607466697693, Lr:0.0001\n",
      "Epoch 1, Step: 179, Loss: 0.6185749769210815, Lr:0.0001\n",
      "Epoch 1, Step: 180, Loss: 0.421416699886322, Lr:0.0001\n",
      "Epoch 1, Step: 181, Loss: 0.37920233607292175, Lr:0.0001\n",
      "Epoch 1, Step: 182, Loss: 0.6333761215209961, Lr:0.0001\n",
      "Epoch 1, Step: 183, Loss: 1.0118907690048218, Lr:0.0001\n",
      "Epoch 1, Step: 184, Loss: 0.40660279989242554, Lr:0.0001\n",
      "Epoch 1, Step: 185, Loss: 0.7866549491882324, Lr:0.0001\n",
      "Epoch 1, Step: 186, Loss: 0.678132176399231, Lr:0.0001\n",
      "Epoch 1, Step: 187, Loss: 0.9371457099914551, Lr:0.0001\n",
      "Epoch 1, Step: 188, Loss: 0.6054404973983765, Lr:0.0001\n",
      "Epoch 1, Step: 189, Loss: 0.8311896324157715, Lr:0.0001\n",
      "Epoch 1, Step: 190, Loss: 0.7385948896408081, Lr:0.0001\n",
      "Epoch 1, Step: 191, Loss: 0.6966720819473267, Lr:0.0001\n",
      "Epoch 1, Step: 192, Loss: 0.42739245295524597, Lr:0.0001\n",
      "Epoch 1, Step: 193, Loss: 0.8712085485458374, Lr:0.0001\n",
      "Epoch 1, Step: 194, Loss: 0.525830864906311, Lr:0.0001\n",
      "Epoch 1, Step: 195, Loss: 0.4582211375236511, Lr:0.0001\n",
      "Epoch 1, Step: 196, Loss: 0.5191473960876465, Lr:0.0001\n",
      "Epoch 1, Step: 197, Loss: 0.6573602557182312, Lr:0.0001\n",
      "Epoch 1, Step: 198, Loss: 0.8051459789276123, Lr:0.0001\n",
      "Epoch 1, Step: 199, Loss: 0.652700662612915, Lr:0.0001\n",
      "Epoch 1, Step: 200, Loss: 0.7489346861839294, Lr:0.0001\n",
      "Epoch 1, Step: 201, Loss: 0.41489794850349426, Lr:0.0001\n",
      "Epoch 1, Step: 202, Loss: 0.8346949815750122, Lr:0.0001\n",
      "Epoch 1, Step: 203, Loss: 0.5862066149711609, Lr:0.0001\n",
      "Epoch 1, Step: 204, Loss: 0.917669951915741, Lr:0.0001\n",
      "Epoch 1, Step: 205, Loss: 0.40993383526802063, Lr:0.0001\n",
      "Epoch 1, Step: 206, Loss: 0.6960501074790955, Lr:0.0001\n",
      "Epoch 1, Step: 207, Loss: 0.6222684383392334, Lr:0.0001\n",
      "Epoch 1, Step: 208, Loss: 0.31711453199386597, Lr:0.0001\n",
      "Epoch 1, Step: 209, Loss: 0.5574518442153931, Lr:0.0001\n",
      "Epoch 1, Step: 210, Loss: 0.39292457699775696, Lr:0.0001\n",
      "Epoch 1, Step: 211, Loss: 0.42652714252471924, Lr:0.0001\n",
      "Epoch 1, Step: 212, Loss: 0.5657768249511719, Lr:0.0001\n",
      "Epoch 1, Step: 213, Loss: 0.9267846941947937, Lr:0.0001\n",
      "Epoch 1, Step: 214, Loss: 1.0982284545898438, Lr:0.0001\n",
      "Epoch 1, Step: 215, Loss: 0.4839558005332947, Lr:0.0001\n",
      "Epoch 1, Step: 216, Loss: 0.5332809686660767, Lr:0.0001\n",
      "Epoch 1, Step: 217, Loss: 0.5660519003868103, Lr:0.0001\n",
      "Epoch 1, Step: 218, Loss: 0.839363694190979, Lr:0.0001\n",
      "Epoch 1, Step: 219, Loss: 0.8328776359558105, Lr:0.0001\n",
      "Epoch 1, Step: 220, Loss: 0.8031411170959473, Lr:0.0001\n",
      "Epoch 1, Step: 221, Loss: 0.7418408393859863, Lr:0.0001\n",
      "Epoch 1, Step: 222, Loss: 0.5916328430175781, Lr:0.0001\n",
      "Epoch 1, Step: 223, Loss: 0.5825925469398499, Lr:0.0001\n",
      "Epoch 1, Step: 224, Loss: 0.7545722723007202, Lr:0.0001\n",
      "Epoch 1, Step: 225, Loss: 1.0861990451812744, Lr:0.0001\n",
      "Epoch 1, Step: 226, Loss: 0.5060503482818604, Lr:0.0001\n",
      "Epoch 1, Step: 227, Loss: 0.5045726299285889, Lr:0.0001\n",
      "Epoch 1, Step: 228, Loss: 0.6141118407249451, Lr:0.0001\n",
      "Epoch 1, Step: 229, Loss: 1.2221214771270752, Lr:0.0001\n",
      "Epoch 1, Step: 230, Loss: 0.7944369316101074, Lr:0.0001\n",
      "Epoch 1, Step: 231, Loss: 0.6627379655838013, Lr:0.0001\n",
      "Epoch 1, Step: 232, Loss: 0.7087460160255432, Lr:0.0001\n",
      "Epoch 1, Step: 233, Loss: 0.574383556842804, Lr:0.0001\n",
      "Epoch 1, Step: 234, Loss: 0.734642505645752, Lr:0.0001\n",
      "Epoch 1, Step: 235, Loss: 0.5834387540817261, Lr:0.0001\n",
      "Epoch 1, Step: 236, Loss: 0.8488279581069946, Lr:0.0001\n",
      "Epoch 1, Step: 237, Loss: 0.48869776725769043, Lr:0.0001\n",
      "Epoch 1, Step: 238, Loss: 0.44604548811912537, Lr:0.0001\n",
      "Epoch 1, Step: 239, Loss: 0.643214225769043, Lr:0.0001\n",
      "Epoch 1, Step: 240, Loss: 0.46194520592689514, Lr:0.0001\n",
      "Epoch 1, Step: 241, Loss: 0.7253134250640869, Lr:0.0001\n",
      "Epoch 1, Step: 242, Loss: 0.9516551494598389, Lr:0.0001\n",
      "Epoch 1, Step: 243, Loss: 0.9574074149131775, Lr:0.0001\n",
      "Epoch 1, Step: 244, Loss: 0.5197321176528931, Lr:0.0001\n",
      "Epoch 1, Step: 245, Loss: 0.9788724184036255, Lr:0.0001\n",
      "Epoch 1, Step: 246, Loss: 0.6672855019569397, Lr:0.0001\n",
      "Epoch 1, Step: 247, Loss: 0.47961992025375366, Lr:0.0001\n",
      "Epoch 1, Step: 248, Loss: 0.3881394565105438, Lr:0.0001\n",
      "Epoch 1, Step: 249, Loss: 0.40258702635765076, Lr:0.0001\n",
      "Epoch 1, Step: 250, Loss: 0.6884444355964661, Lr:0.0001\n",
      "Epoch 1, Step: 251, Loss: 0.5867692232131958, Lr:0.0001\n",
      "Epoch 1, Step: 252, Loss: 0.7612543702125549, Lr:0.0001\n",
      "Epoch 1, Step: 253, Loss: 0.4143398106098175, Lr:0.0001\n",
      "Epoch 1, Step: 254, Loss: 1.0409601926803589, Lr:0.0001\n",
      "Epoch 1, Step: 255, Loss: 0.7782576084136963, Lr:0.0001\n",
      "Epoch 1, Step: 256, Loss: 0.5216665863990784, Lr:0.0001\n",
      "Epoch 1, Step: 257, Loss: 0.6172104477882385, Lr:0.0001\n",
      "Epoch 1, Step: 258, Loss: 0.7066450119018555, Lr:0.0001\n",
      "Epoch 1, Step: 259, Loss: 0.6286821365356445, Lr:0.0001\n",
      "Epoch 1, Step: 260, Loss: 1.0589772462844849, Lr:0.0001\n",
      "Epoch 1, Step: 261, Loss: 0.8757016658782959, Lr:0.0001\n",
      "Epoch 1, Step: 262, Loss: 0.353227436542511, Lr:0.0001\n",
      "Epoch 1, Step: 263, Loss: 0.5420964956283569, Lr:0.0001\n",
      "Epoch 1, Step: 264, Loss: 0.2554311156272888, Lr:0.0001\n",
      "Epoch 1, Step: 265, Loss: 1.1509078741073608, Lr:0.0001\n",
      "Epoch 1, Step: 266, Loss: 0.6039442420005798, Lr:0.0001\n",
      "Epoch 1, Step: 267, Loss: 0.627512514591217, Lr:0.0001\n",
      "Epoch 1, Step: 268, Loss: 0.4935641288757324, Lr:0.0001\n",
      "Epoch 1, Step: 269, Loss: 0.5680506229400635, Lr:0.0001\n",
      "Epoch 1, Step: 270, Loss: 0.903817892074585, Lr:0.0001\n",
      "Epoch 1, Step: 271, Loss: 0.46952491998672485, Lr:0.0001\n",
      "Epoch 1, Step: 272, Loss: 0.5418471097946167, Lr:0.0001\n",
      "Epoch 1, Step: 273, Loss: 0.5043761730194092, Lr:0.0001\n",
      "Epoch 1, Step: 274, Loss: 0.7332675457000732, Lr:0.0001\n",
      "Epoch 1, Step: 275, Loss: 0.666350245475769, Lr:0.0001\n",
      "Epoch 1, Step: 276, Loss: 0.19528484344482422, Lr:0.0001\n",
      "Epoch 1, Step: 277, Loss: 0.6527695059776306, Lr:0.0001\n",
      "Epoch 1, Step: 278, Loss: 0.376799613237381, Lr:0.0001\n",
      "Epoch 1, Step: 279, Loss: 0.5404545664787292, Lr:0.0001\n",
      "Epoch 1, Step: 280, Loss: 0.9164186716079712, Lr:0.0001\n",
      "Epoch 1, Step: 281, Loss: 0.5563458204269409, Lr:0.0001\n",
      "Epoch 1, Step: 282, Loss: 0.5011181831359863, Lr:0.0001\n",
      "Epoch 1, Step: 283, Loss: 0.3694373667240143, Lr:0.0001\n",
      "Epoch 1, Step: 284, Loss: 0.5585324764251709, Lr:0.0001\n",
      "Epoch 1, Step: 285, Loss: 0.5159774422645569, Lr:0.0001\n",
      "Epoch 1, Step: 286, Loss: 0.7582561373710632, Lr:0.0001\n",
      "Epoch 1, Step: 287, Loss: 0.6674708127975464, Lr:0.0001\n",
      "Epoch 1, Step: 288, Loss: 0.42139849066734314, Lr:0.0001\n",
      "Epoch 1, Step: 289, Loss: 0.3817369043827057, Lr:0.0001\n",
      "Epoch 1, Step: 290, Loss: 0.6666050553321838, Lr:0.0001\n",
      "Epoch 1, Step: 291, Loss: 0.9759261012077332, Lr:0.0001\n",
      "Epoch 1, Step: 292, Loss: 0.5426661968231201, Lr:0.0001\n",
      "Epoch 1, Step: 293, Loss: 0.47081008553504944, Lr:0.0001\n",
      "Epoch 1, Step: 294, Loss: 0.305257648229599, Lr:0.0001\n",
      "Epoch 1, Step: 295, Loss: 0.7172544598579407, Lr:0.0001\n",
      "Epoch 1, Step: 296, Loss: 1.1267493963241577, Lr:0.0001\n",
      "Epoch 1, Step: 297, Loss: 0.3530672490596771, Lr:0.0001\n",
      "Epoch 1, Step: 298, Loss: 0.23272714018821716, Lr:0.0001\n",
      "Epoch 1, Step: 299, Loss: 0.3543356657028198, Lr:0.0001\n",
      "Epoch 1, Step: 300, Loss: 0.7530137896537781, Lr:0.0001\n",
      "Epoch 1, Step: 301, Loss: 0.2735810875892639, Lr:0.0001\n",
      "Epoch 1, Step: 302, Loss: 0.42200279235839844, Lr:0.0001\n",
      "Epoch 1, Step: 303, Loss: 0.5631191730499268, Lr:0.0001\n",
      "Epoch 1, Step: 304, Loss: 0.71612149477005, Lr:0.0001\n",
      "Epoch 1, Step: 305, Loss: 0.27963170409202576, Lr:0.0001\n",
      "Epoch 1, Step: 306, Loss: 0.814581036567688, Lr:0.0001\n",
      "Epoch 1, Step: 307, Loss: 0.7842550277709961, Lr:0.0001\n",
      "Epoch 1, Step: 308, Loss: 0.3690032362937927, Lr:0.0001\n",
      "Epoch 1, Step: 309, Loss: 0.4639558792114258, Lr:0.0001\n",
      "Epoch 1, Step: 310, Loss: 0.644943118095398, Lr:0.0001\n",
      "Epoch 1, Step: 311, Loss: 0.5563427209854126, Lr:0.0001\n",
      "Epoch 1, Step: 312, Loss: 0.5412152409553528, Lr:0.0001\n",
      "Epoch 1, Step: 313, Loss: 0.6810097694396973, Lr:0.0001\n",
      "Epoch 1, Step: 314, Loss: 0.7337606549263, Lr:0.0001\n",
      "Epoch 1, Step: 315, Loss: 0.44966575503349304, Lr:0.0001\n",
      "Epoch 1, Step: 316, Loss: 0.785166323184967, Lr:0.0001\n",
      "Epoch 1, Step: 317, Loss: 0.6189285516738892, Lr:0.0001\n",
      "Epoch 1, Step: 318, Loss: 0.45502597093582153, Lr:0.0001\n",
      "Epoch 1, Step: 319, Loss: 0.6317952871322632, Lr:0.0001\n",
      "Epoch 1, Step: 320, Loss: 0.8124457597732544, Lr:0.0001\n",
      "Epoch 1, Step: 321, Loss: 0.5224896669387817, Lr:0.0001\n",
      "Epoch 1, Step: 322, Loss: 0.6266814470291138, Lr:0.0001\n",
      "Epoch 1, Step: 323, Loss: 0.4767377972602844, Lr:0.0001\n",
      "Epoch 1, Step: 324, Loss: 0.5813236832618713, Lr:0.0001\n",
      "Epoch 1, Step: 325, Loss: 0.49905845522880554, Lr:0.0001\n",
      "Epoch 1, Step: 326, Loss: 0.40161648392677307, Lr:0.0001\n",
      "Epoch 1, Step: 327, Loss: 0.991411566734314, Lr:0.0001\n",
      "Epoch 1, Step: 328, Loss: 0.5039291381835938, Lr:0.0001\n",
      "Epoch 1, Step: 329, Loss: 0.5062587261199951, Lr:0.0001\n",
      "Epoch 1, Step: 330, Loss: 0.3831058144569397, Lr:0.0001\n",
      "Epoch 1, Step: 331, Loss: 0.6680628657341003, Lr:0.0001\n",
      "Epoch 1, Step: 332, Loss: 0.4269905686378479, Lr:0.0001\n",
      "Epoch 1, Step: 333, Loss: 0.5249968767166138, Lr:0.0001\n",
      "Epoch 1, Step: 334, Loss: 0.5113343596458435, Lr:0.0001\n",
      "Epoch 1, Step: 335, Loss: 0.4254036545753479, Lr:0.0001\n",
      "Epoch 1, Step: 336, Loss: 0.5937917828559875, Lr:0.0001\n",
      "Epoch 1, Step: 337, Loss: 0.36111968755722046, Lr:0.0001\n",
      "Epoch 1, Step: 338, Loss: 0.66302889585495, Lr:0.0001\n",
      "Epoch 1, Step: 339, Loss: 0.4833964407444, Lr:0.0001\n",
      "Epoch 1, Step: 340, Loss: 0.6159067153930664, Lr:0.0001\n",
      "Epoch 1, Step: 341, Loss: 0.5537133812904358, Lr:0.0001\n",
      "Epoch 1, Step: 342, Loss: 0.46409809589385986, Lr:0.0001\n",
      "Epoch 1, Step: 343, Loss: 0.33421558141708374, Lr:0.0001\n",
      "Epoch 1, Step: 344, Loss: 0.5898476243019104, Lr:0.0001\n",
      "Epoch 1, Step: 345, Loss: 0.5925909876823425, Lr:0.0001\n",
      "Epoch 1, Step: 346, Loss: 0.4731687307357788, Lr:0.0001\n",
      "Epoch 1, Step: 347, Loss: 0.4969714283943176, Lr:0.0001\n",
      "Epoch 1, Step: 348, Loss: 0.47707870602607727, Lr:0.0001\n",
      "Epoch 1, Step: 349, Loss: 0.41786321997642517, Lr:0.0001\n",
      "Epoch 1, Step: 350, Loss: 0.925632119178772, Lr:0.0001\n",
      "Epoch 1, Step: 351, Loss: 0.26282167434692383, Lr:0.0001\n",
      "Epoch 1, Step: 352, Loss: 0.6853354573249817, Lr:0.0001\n",
      "Epoch 1, Step: 353, Loss: 0.5950010418891907, Lr:0.0001\n",
      "Epoch 1, Step: 354, Loss: 0.4916645884513855, Lr:0.0001\n",
      "Epoch 1, Step: 355, Loss: 0.34325435757637024, Lr:0.0001\n",
      "Epoch 1, Step: 356, Loss: 0.6393415331840515, Lr:0.0001\n",
      "Epoch 1, Step: 357, Loss: 0.42579126358032227, Lr:0.0001\n",
      "Epoch 1, Step: 358, Loss: 0.6594387888908386, Lr:0.0001\n",
      "Epoch 1, Step: 359, Loss: 0.30570241808891296, Lr:0.0001\n",
      "Epoch 1, Step: 360, Loss: 0.25128087401390076, Lr:0.0001\n",
      "Epoch 1, Step: 361, Loss: 0.4888058304786682, Lr:0.0001\n",
      "Epoch 1, Step: 362, Loss: 0.7840689420700073, Lr:0.0001\n",
      "Epoch 1, Step: 363, Loss: 0.7573602199554443, Lr:0.0001\n",
      "Epoch 1, Step: 364, Loss: 0.5860018730163574, Lr:0.0001\n",
      "Epoch 1, Step: 365, Loss: 1.0901113748550415, Lr:0.0001\n",
      "Epoch 1, Step: 366, Loss: 0.7864384651184082, Lr:0.0001\n",
      "Epoch 1, Step: 367, Loss: 0.50166916847229, Lr:0.0001\n",
      "Epoch 1, Step: 368, Loss: 0.5480462908744812, Lr:0.0001\n",
      "Epoch 1, Step: 369, Loss: 0.40358036756515503, Lr:0.0001\n",
      "Epoch 1, Step: 370, Loss: 0.6349508166313171, Lr:0.0001\n",
      "Epoch 1, Step: 371, Loss: 0.3026207685470581, Lr:0.0001\n",
      "Epoch 1, Step: 372, Loss: 0.7691290378570557, Lr:0.0001\n",
      "Epoch 1, Step: 373, Loss: 1.2010536193847656, Lr:0.0001\n",
      "Epoch 1, Step: 374, Loss: 0.24330681562423706, Lr:0.0001\n",
      "Epoch 1, Step: 375, Loss: 0.7997726798057556, Lr:0.0001\n",
      "Epoch 1, Step: 376, Loss: 0.4633249044418335, Lr:0.0001\n",
      "Epoch 1, Step: 377, Loss: 0.40654563903808594, Lr:0.0001\n",
      "Epoch 1, Step: 378, Loss: 0.37543898820877075, Lr:0.0001\n",
      "Epoch 1, Step: 379, Loss: 0.25384393334388733, Lr:0.0001\n",
      "Epoch 1, Step: 380, Loss: 0.4163781702518463, Lr:0.0001\n",
      "Epoch 1, Step: 381, Loss: 0.7882575392723083, Lr:0.0001\n",
      "Epoch 1, Step: 382, Loss: 0.40684792399406433, Lr:0.0001\n",
      "Epoch 1, Step: 383, Loss: 0.5393677949905396, Lr:0.0001\n",
      "Epoch 1, Step: 384, Loss: 0.6073120832443237, Lr:0.0001\n",
      "Epoch 1, Step: 385, Loss: 0.6014184355735779, Lr:0.0001\n",
      "Epoch 1, Step: 386, Loss: 0.6452212929725647, Lr:0.0001\n",
      "Epoch 1, Step: 387, Loss: 0.6852447986602783, Lr:0.0001\n",
      "Epoch 1, Step: 388, Loss: 0.6730276346206665, Lr:0.0001\n",
      "Epoch 1, Step: 389, Loss: 0.7129769325256348, Lr:0.0001\n",
      "Epoch 1, Step: 390, Loss: 0.6508744955062866, Lr:0.0001\n",
      "Epoch 1, Step: 391, Loss: 0.5470210313796997, Lr:0.0001\n",
      "Epoch 1, Step: 392, Loss: 0.5681620240211487, Lr:0.0001\n",
      "Epoch 1, Step: 393, Loss: 0.5874237418174744, Lr:0.0001\n",
      "Epoch 1, Step: 394, Loss: 0.886850893497467, Lr:0.0001\n",
      "Epoch 1, Step: 395, Loss: 0.3335654139518738, Lr:0.0001\n",
      "Epoch 1, Step: 396, Loss: 0.43594247102737427, Lr:0.0001\n",
      "Epoch 1, Step: 397, Loss: 0.42000314593315125, Lr:0.0001\n",
      "Epoch 1, Step: 398, Loss: 0.6896532773971558, Lr:0.0001\n",
      "Epoch 1, Step: 399, Loss: 0.6089547276496887, Lr:0.0001\n",
      "Epoch 1, Step: 400, Loss: 0.6442461013793945, Lr:0.0001\n",
      "Epoch 1, Step: 401, Loss: 0.5250877141952515, Lr:0.0001\n",
      "Epoch 1, Step: 402, Loss: 0.4180351495742798, Lr:0.0001\n",
      "Epoch 1, Step: 403, Loss: 0.44142627716064453, Lr:0.0001\n",
      "Epoch 1, Step: 404, Loss: 0.459183931350708, Lr:0.0001\n",
      "Epoch 1, Step: 405, Loss: 0.6175038814544678, Lr:0.0001\n",
      "Epoch 1, Step: 406, Loss: 0.7475391030311584, Lr:0.0001\n",
      "Epoch 1, Step: 407, Loss: 0.5986736416816711, Lr:0.0001\n",
      "Epoch 1, Step: 408, Loss: 0.27174827456474304, Lr:0.0001\n",
      "Epoch 1, Step: 409, Loss: 0.4887504577636719, Lr:0.0001\n",
      "Epoch 1, Step: 410, Loss: 0.7337668538093567, Lr:0.0001\n",
      "Epoch 1, Step: 411, Loss: 0.3355519771575928, Lr:0.0001\n",
      "Epoch 1, Step: 412, Loss: 0.32473069429397583, Lr:0.0001\n",
      "Epoch 1, Step: 413, Loss: 0.5728014707565308, Lr:0.0001\n",
      "Epoch 1, Step: 414, Loss: 0.48893067240715027, Lr:0.0001\n",
      "Epoch 1, Step: 415, Loss: 0.8976515531539917, Lr:0.0001\n",
      "Epoch 1, Step: 416, Loss: 0.4743536114692688, Lr:0.0001\n",
      "Epoch 1, Step: 417, Loss: 0.32331839203834534, Lr:0.0001\n",
      "Epoch 1, Step: 418, Loss: 0.5119966864585876, Lr:0.0001\n",
      "Epoch 1, Step: 419, Loss: 0.29812392592430115, Lr:0.0001\n",
      "Epoch 1, Step: 420, Loss: 0.47020936012268066, Lr:0.0001\n",
      "Epoch 1, Step: 421, Loss: 0.3809683918952942, Lr:0.0001\n",
      "Epoch 1, Step: 422, Loss: 0.6425933241844177, Lr:0.0001\n",
      "Epoch 1, Step: 423, Loss: 0.3478989005088806, Lr:0.0001\n",
      "Epoch 1, Step: 424, Loss: 0.9365861415863037, Lr:0.0001\n",
      "Epoch 1, Step: 425, Loss: 0.4260391592979431, Lr:0.0001\n",
      "Epoch 1, Step: 426, Loss: 0.7291373610496521, Lr:0.0001\n",
      "Epoch 1, Step: 427, Loss: 0.5366982817649841, Lr:0.0001\n",
      "Epoch 1, Step: 428, Loss: 0.47836658358573914, Lr:0.0001\n",
      "Epoch 1, Step: 429, Loss: 0.365077942609787, Lr:0.0001\n",
      "Epoch 1, Step: 430, Loss: 0.310441792011261, Lr:0.0001\n",
      "Epoch 1, Step: 431, Loss: 0.3123265504837036, Lr:0.0001\n",
      "Epoch 1, Step: 432, Loss: 0.710487961769104, Lr:0.0001\n",
      "Epoch 1, Step: 433, Loss: 0.5692867636680603, Lr:0.0001\n",
      "Epoch 1, Step: 434, Loss: 0.3264010548591614, Lr:0.0001\n",
      "Epoch 1, Step: 435, Loss: 0.5395049452781677, Lr:0.0001\n",
      "Epoch 1, Step: 436, Loss: 0.7403034567832947, Lr:0.0001\n",
      "Epoch 1, Step: 437, Loss: 0.5044781565666199, Lr:0.0001\n",
      "Epoch 1, Step: 438, Loss: 0.8508656620979309, Lr:0.0001\n",
      "Epoch 1, Step: 439, Loss: 0.7055418491363525, Lr:0.0001\n",
      "Epoch 1, Step: 440, Loss: 0.452963262796402, Lr:0.0001\n",
      "Epoch 1, Step: 441, Loss: 0.3197287619113922, Lr:0.0001\n",
      "Epoch 1, Step: 442, Loss: 0.2179107367992401, Lr:0.0001\n",
      "Epoch 1, Step: 443, Loss: 1.263655424118042, Lr:0.0001\n",
      "Epoch 1, Step: 444, Loss: 0.4641508162021637, Lr:0.0001\n",
      "Epoch 1, Step: 445, Loss: 0.49611249566078186, Lr:0.0001\n",
      "Epoch 1, Step: 446, Loss: 0.538211464881897, Lr:0.0001\n",
      "Epoch 1, Step: 447, Loss: 0.48402151465415955, Lr:0.0001\n",
      "Epoch 1, Step: 448, Loss: 0.38190963864326477, Lr:0.0001\n",
      "Epoch 1, Step: 449, Loss: 0.6408555507659912, Lr:0.0001\n",
      "Epoch 1, Step: 450, Loss: 0.2969650626182556, Lr:0.0001\n",
      "Epoch 1, Step: 451, Loss: 0.6268201470375061, Lr:0.0001\n",
      "Epoch 1, Step: 452, Loss: 0.7570967078208923, Lr:0.0001\n",
      "Epoch 1, Step: 453, Loss: 0.44716668128967285, Lr:0.0001\n",
      "Epoch 1, Step: 454, Loss: 0.5350525379180908, Lr:0.0001\n",
      "Epoch 1, Step: 455, Loss: 0.5364400148391724, Lr:0.0001\n",
      "Epoch 1, Step: 456, Loss: 0.5863462090492249, Lr:0.0001\n",
      "Epoch 1, Step: 457, Loss: 0.2330663502216339, Lr:0.0001\n",
      "Epoch 1, Step: 458, Loss: 0.4331268072128296, Lr:0.0001\n",
      "Epoch 1, Step: 459, Loss: 0.697743833065033, Lr:0.0001\n",
      "Epoch 1, Step: 460, Loss: 0.5413243770599365, Lr:0.0001\n",
      "Epoch 1, Step: 461, Loss: 0.6618868708610535, Lr:0.0001\n",
      "Epoch 1, Step: 462, Loss: 0.5881494283676147, Lr:0.0001\n",
      "Epoch 1, Step: 463, Loss: 0.6244227886199951, Lr:0.0001\n",
      "Epoch 1, Step: 464, Loss: 0.3351404070854187, Lr:0.0001\n",
      "Epoch 1, Step: 465, Loss: 0.34254053235054016, Lr:0.0001\n",
      "Epoch 1, Step: 466, Loss: 0.645733118057251, Lr:0.0001\n",
      "Epoch 1, Step: 467, Loss: 0.4810832738876343, Lr:0.0001\n",
      "Epoch 1, Step: 468, Loss: 0.4401412606239319, Lr:0.0001\n",
      "Epoch 1, Step: 469, Loss: 0.8574612736701965, Lr:0.0001\n",
      "Epoch 1, Step: 470, Loss: 0.5310109257698059, Lr:0.0001\n",
      "Epoch 1, Step: 471, Loss: 0.6144542098045349, Lr:0.0001\n",
      "Epoch 1, Step: 472, Loss: 0.528405487537384, Lr:0.0001\n",
      "Epoch 1, Step: 473, Loss: 0.9039641618728638, Lr:0.0001\n",
      "Epoch 1, Step: 474, Loss: 0.5318774580955505, Lr:0.0001\n",
      "Epoch 1, Step: 475, Loss: 0.34417757391929626, Lr:0.0001\n",
      "Epoch 1, Step: 476, Loss: 0.49600908160209656, Lr:0.0001\n",
      "Epoch 1, Step: 477, Loss: 0.40098482370376587, Lr:0.0001\n",
      "Epoch 1, Step: 478, Loss: 0.2969757914543152, Lr:0.0001\n",
      "Epoch 1, Step: 479, Loss: 0.43809202313423157, Lr:0.0001\n",
      "Epoch 1, Step: 480, Loss: 0.8771908283233643, Lr:0.0001\n",
      "Epoch 1, Step: 481, Loss: 0.5715330243110657, Lr:0.0001\n",
      "Epoch 1, Step: 482, Loss: 0.3737492859363556, Lr:0.0001\n",
      "Epoch 1, Step: 483, Loss: 0.4404362440109253, Lr:0.0001\n",
      "Epoch 1, Step: 484, Loss: 0.24824529886245728, Lr:0.0001\n",
      "Epoch 1, Step: 485, Loss: 0.6142462491989136, Lr:0.0001\n",
      "Epoch 1, Step: 486, Loss: 0.2632253170013428, Lr:0.0001\n",
      "Epoch 1, Step: 487, Loss: 0.38373565673828125, Lr:0.0001\n",
      "Epoch 1, Step: 488, Loss: 0.4923798441886902, Lr:0.0001\n",
      "Epoch 1, Step: 489, Loss: 0.6538726687431335, Lr:0.0001\n",
      "Epoch 1, Step: 490, Loss: 0.311755895614624, Lr:0.0001\n",
      "Epoch 1, Step: 491, Loss: 0.6276114583015442, Lr:0.0001\n",
      "Epoch 1, Step: 492, Loss: 0.4872514605522156, Lr:0.0001\n",
      "Epoch 1, Step: 493, Loss: 0.3118184804916382, Lr:0.0001\n",
      "Epoch 1, Step: 494, Loss: 0.3632268011569977, Lr:0.0001\n",
      "Epoch 1, Step: 495, Loss: 0.31397315859794617, Lr:0.0001\n",
      "Epoch 1, Step: 496, Loss: 0.6836073994636536, Lr:0.0001\n",
      "Epoch 1, Step: 497, Loss: 0.34151965379714966, Lr:0.0001\n",
      "Epoch 1, Step: 498, Loss: 0.42178645730018616, Lr:0.0001\n",
      "Epoch 1, Step: 499, Loss: 0.6115838885307312, Lr:0.0001\n",
      "Epoch 1, Step: 500, Loss: 0.3547571301460266, Lr:0.0001\n",
      "Epoch 1, Step: 501, Loss: 0.37213134765625, Lr:0.0001\n",
      "Epoch 1, Step: 502, Loss: 0.5857433080673218, Lr:0.0001\n",
      "Epoch 1, Step: 503, Loss: 0.3238813281059265, Lr:0.0001\n",
      "Epoch 1, Step: 504, Loss: 0.532298743724823, Lr:0.0001\n",
      "Epoch 1, Step: 505, Loss: 0.4158872365951538, Lr:0.0001\n",
      "Epoch 1, Step: 506, Loss: 0.4909082353115082, Lr:0.0001\n",
      "Epoch 1, Step: 507, Loss: 0.6025874018669128, Lr:0.0001\n",
      "Epoch 1, Step: 508, Loss: 0.3890346884727478, Lr:0.0001\n",
      "Epoch 1, Step: 509, Loss: 0.4632019102573395, Lr:0.0001\n",
      "Epoch 1, Step: 510, Loss: 0.4540811777114868, Lr:0.0001\n",
      "Epoch 1, Step: 511, Loss: 0.6591853499412537, Lr:0.0001\n",
      "Epoch 1, Step: 512, Loss: 0.7644994258880615, Lr:0.0001\n",
      "Epoch 1, Step: 513, Loss: 0.46917524933815, Lr:0.0001\n",
      "Epoch 1, Step: 514, Loss: 0.6658589243888855, Lr:0.0001\n",
      "Epoch 1, Step: 515, Loss: 0.3351597487926483, Lr:0.0001\n",
      "Epoch 1, Step: 516, Loss: 0.4883649945259094, Lr:0.0001\n",
      "Epoch 1, Step: 517, Loss: 0.5421530604362488, Lr:0.0001\n",
      "Epoch 1, Step: 518, Loss: 0.13520032167434692, Lr:0.0001\n",
      "Epoch 1, Step: 519, Loss: 0.3536359667778015, Lr:0.0001\n",
      "Epoch 1, Step: 520, Loss: 0.3056444227695465, Lr:0.0001\n",
      "Epoch 1, Step: 521, Loss: 0.6362413763999939, Lr:0.0001\n",
      "Epoch 1, Step: 522, Loss: 0.23345455527305603, Lr:0.0001\n",
      "Epoch 1, Step: 523, Loss: 0.4373784065246582, Lr:0.0001\n",
      "Epoch 1, Step: 524, Loss: 0.49866095185279846, Lr:0.0001\n",
      "Epoch 1, Step: 525, Loss: 0.5972073078155518, Lr:0.0001\n",
      "Epoch 1, Step: 526, Loss: 0.4458676874637604, Lr:0.0001\n",
      "Epoch 1, Step: 527, Loss: 0.20291201770305634, Lr:0.0001\n",
      "Epoch 1, Step: 528, Loss: 0.15295229852199554, Lr:0.0001\n",
      "Epoch 1, Step: 529, Loss: 0.30725574493408203, Lr:0.0001\n",
      "Epoch 1, Step: 530, Loss: 0.45000386238098145, Lr:0.0001\n",
      "Epoch 1, Step: 531, Loss: 0.5428758263587952, Lr:0.0001\n",
      "Epoch 1, Step: 532, Loss: 0.21664658188819885, Lr:0.0001\n",
      "Epoch 1, Step: 533, Loss: 0.6127221584320068, Lr:0.0001\n",
      "Epoch 1, Step: 534, Loss: 0.6275765895843506, Lr:0.0001\n",
      "Epoch 1, Step: 535, Loss: 0.5388460755348206, Lr:0.0001\n",
      "Epoch 1, Step: 536, Loss: 0.47636738419532776, Lr:0.0001\n",
      "Epoch 1, Step: 537, Loss: 0.45493483543395996, Lr:0.0001\n",
      "Epoch 1, Step: 538, Loss: 0.3854644298553467, Lr:0.0001\n",
      "Epoch 1, Step: 539, Loss: 0.4349825382232666, Lr:0.0001\n",
      "Epoch 1, Step: 540, Loss: 0.3721766471862793, Lr:0.0001\n",
      "Epoch 1, Step: 541, Loss: 0.3307420611381531, Lr:0.0001\n",
      "Epoch 1, Step: 542, Loss: 0.38978829979896545, Lr:0.0001\n",
      "Epoch 1, Step: 543, Loss: 0.6198768615722656, Lr:0.0001\n",
      "Epoch 1, Step: 544, Loss: 0.8147529363632202, Lr:0.0001\n",
      "Epoch 1, Step: 545, Loss: 0.6362083554267883, Lr:0.0001\n",
      "Epoch 1, Step: 546, Loss: 0.5025638937950134, Lr:0.0001\n",
      "Epoch 1, Step: 547, Loss: 0.315544068813324, Lr:0.0001\n",
      "Epoch 1, Step: 548, Loss: 0.225833922624588, Lr:0.0001\n",
      "Epoch 1, Step: 549, Loss: 0.32914209365844727, Lr:0.0001\n",
      "Epoch 1, Step: 550, Loss: 0.2854906916618347, Lr:0.0001\n",
      "Epoch 1, Step: 551, Loss: 0.40167590975761414, Lr:0.0001\n",
      "Epoch 1, Step: 552, Loss: 0.23082786798477173, Lr:0.0001\n",
      "Epoch 1, Step: 553, Loss: 0.5748956799507141, Lr:0.0001\n",
      "Epoch 1, Step: 554, Loss: 0.37016740441322327, Lr:0.0001\n",
      "Epoch 1, Step: 555, Loss: 0.14478640258312225, Lr:0.0001\n",
      "Epoch 1, Step: 556, Loss: 0.5343614816665649, Lr:0.0001\n",
      "Epoch 1, Step: 557, Loss: 0.3679734170436859, Lr:0.0001\n",
      "Epoch 1, Step: 558, Loss: 0.35768407583236694, Lr:0.0001\n",
      "Epoch 1, Step: 559, Loss: 0.5394248962402344, Lr:0.0001\n",
      "Epoch 1, Step: 560, Loss: 0.4897836446762085, Lr:0.0001\n",
      "Epoch 1, Step: 561, Loss: 0.21611492335796356, Lr:0.0001\n",
      "Epoch 1, Step: 562, Loss: 0.5638056397438049, Lr:0.0001\n",
      "Epoch 1, Step: 563, Loss: 0.22287563979625702, Lr:0.0001\n",
      "Epoch 1, Step: 564, Loss: 0.6599752902984619, Lr:0.0001\n",
      "Epoch 1, Step: 565, Loss: 0.6619823575019836, Lr:0.0001\n",
      "Epoch 1, Step: 566, Loss: 0.8472771048545837, Lr:0.0001\n",
      "Epoch 1, Step: 567, Loss: 0.7212149500846863, Lr:0.0001\n",
      "Epoch 1, Step: 568, Loss: 0.5318704843521118, Lr:0.0001\n",
      "Epoch 1, Step: 569, Loss: 0.4204613268375397, Lr:0.0001\n",
      "Epoch 1, Step: 570, Loss: 0.6150158047676086, Lr:0.0001\n",
      "Epoch 1, Step: 571, Loss: 0.576982855796814, Lr:0.0001\n",
      "Epoch 1, Step: 572, Loss: 0.5909889340400696, Lr:0.0001\n",
      "Epoch 1, Step: 573, Loss: 0.3010527789592743, Lr:0.0001\n",
      "Epoch 1, Step: 574, Loss: 0.4805985987186432, Lr:0.0001\n",
      "Epoch 1, Step: 575, Loss: 0.5081875324249268, Lr:0.0001\n",
      "Epoch 1, Step: 576, Loss: 0.37748783826828003, Lr:0.0001\n",
      "Epoch 1, Step: 577, Loss: 0.2926582396030426, Lr:0.0001\n",
      "Epoch 1, Step: 578, Loss: 0.3235066533088684, Lr:0.0001\n",
      "Epoch 1, Step: 579, Loss: 0.4841415286064148, Lr:0.0001\n",
      "Epoch 1, Step: 580, Loss: 0.46769580245018005, Lr:0.0001\n",
      "Epoch 1, Step: 581, Loss: 0.5537219643592834, Lr:0.0001\n",
      "Epoch 1, Step: 582, Loss: 0.4207633137702942, Lr:0.0001\n",
      "Epoch 1, Step: 583, Loss: 0.4261051118373871, Lr:0.0001\n",
      "Epoch 1, Step: 584, Loss: 0.4308401644229889, Lr:0.0001\n",
      "Epoch 1, Step: 585, Loss: 0.3215484321117401, Lr:0.0001\n",
      "Epoch 1, Step: 586, Loss: 0.5641512870788574, Lr:0.0001\n",
      "Epoch 1, Step: 587, Loss: 0.9095039963722229, Lr:0.0001\n",
      "Epoch 1, Step: 588, Loss: 0.48407164216041565, Lr:0.0001\n",
      "Epoch 1, Step: 589, Loss: 0.3454647660255432, Lr:0.0001\n",
      "Epoch 1, Step: 590, Loss: 0.44901618361473083, Lr:0.0001\n",
      "Epoch 1, Step: 591, Loss: 0.43110817670822144, Lr:0.0001\n",
      "Epoch 1, Step: 592, Loss: 0.1943940818309784, Lr:0.0001\n",
      "Epoch 1, Step: 593, Loss: 0.21250873804092407, Lr:0.0001\n",
      "Epoch 1, Step: 594, Loss: 0.7885487079620361, Lr:0.0001\n",
      "Epoch 1, Step: 595, Loss: 0.6589873433113098, Lr:0.0001\n",
      "Epoch 1, Step: 596, Loss: 0.46120312809944153, Lr:0.0001\n",
      "Epoch 1, Step: 597, Loss: 0.2871699333190918, Lr:0.0001\n",
      "Epoch 1, Step: 598, Loss: 1.0511239767074585, Lr:0.0001\n",
      "Epoch 1, Step: 599, Loss: 0.502859890460968, Lr:0.0001\n",
      "Epoch 1, Step: 600, Loss: 0.17558510601520538, Lr:0.0001\n",
      "Epoch 1, Step: 601, Loss: 0.37503156065940857, Lr:0.0001\n",
      "Epoch 1, Step: 602, Loss: 0.3982563614845276, Lr:0.0001\n",
      "Epoch 1, Step: 603, Loss: 0.7293199896812439, Lr:0.0001\n",
      "Epoch 1, Step: 604, Loss: 0.5020396709442139, Lr:0.0001\n",
      "Epoch 1, Step: 605, Loss: 0.5308952331542969, Lr:0.0001\n",
      "Epoch 1, Step: 606, Loss: 0.8076698184013367, Lr:0.0001\n",
      "Epoch 1, Step: 607, Loss: 0.32798904180526733, Lr:0.0001\n",
      "Epoch 1, Step: 608, Loss: 0.5045892596244812, Lr:0.0001\n",
      "Epoch 1, Step: 609, Loss: 0.5375714302062988, Lr:0.0001\n",
      "Epoch 1, Step: 610, Loss: 0.36857080459594727, Lr:0.0001\n",
      "Epoch 1, Step: 611, Loss: 0.2643630802631378, Lr:0.0001\n",
      "Epoch 1, Step: 612, Loss: 0.39031141996383667, Lr:0.0001\n",
      "Epoch 1, Step: 613, Loss: 0.6796860098838806, Lr:0.0001\n",
      "Epoch 1, Step: 614, Loss: 0.4036543369293213, Lr:0.0001\n",
      "Epoch 1, Step: 615, Loss: 0.5505098700523376, Lr:0.0001\n",
      "Epoch 1, Step: 616, Loss: 0.4935030937194824, Lr:0.0001\n",
      "Epoch 1, Step: 617, Loss: 0.5280452370643616, Lr:0.0001\n",
      "Epoch 1, Step: 618, Loss: 0.39508628845214844, Lr:0.0001\n",
      "Epoch 1, Step: 619, Loss: 0.4975617527961731, Lr:0.0001\n",
      "Epoch 1, Step: 620, Loss: 0.25099170207977295, Lr:0.0001\n",
      "Epoch 1, Step: 621, Loss: 0.8050634860992432, Lr:0.0001\n",
      "Epoch 1, Step: 622, Loss: 0.7629199028015137, Lr:0.0001\n",
      "Epoch 1, Step: 623, Loss: 0.646050751209259, Lr:0.0001\n",
      "Epoch 1, Step: 624, Loss: 0.5156553387641907, Lr:0.0001\n",
      "Epoch 1, Step: 625, Loss: 0.3347325325012207, Lr:0.0001\n",
      "Epoch 1, Step: 626, Loss: 0.45140454173088074, Lr:0.0001\n",
      "Epoch 1, Step: 627, Loss: 1.5986758470535278, Lr:0.0001\n",
      "Epoch 1, Step: 628, Loss: 0.4851393699645996, Lr:0.0001\n",
      "Epoch 1, Step: 629, Loss: 0.6113844513893127, Lr:0.0001\n",
      "Epoch 1, Step: 630, Loss: 0.1843591183423996, Lr:0.0001\n",
      "Epoch 1, Step: 631, Loss: 0.2936284840106964, Lr:0.0001\n",
      "Epoch 1, Step: 632, Loss: 0.6392735838890076, Lr:0.0001\n",
      "Epoch 1, Step: 633, Loss: 0.7222132682800293, Lr:0.0001\n",
      "Epoch 1, Step: 634, Loss: 0.576836109161377, Lr:0.0001\n",
      "Epoch 1, Step: 635, Loss: 0.5984349846839905, Lr:0.0001\n",
      "Epoch 1, Step: 636, Loss: 0.30385178327560425, Lr:0.0001\n",
      "Epoch 1, Step: 637, Loss: 0.6420361995697021, Lr:0.0001\n",
      "Epoch 1, Step: 638, Loss: 0.5383042693138123, Lr:0.0001\n",
      "Epoch 1, Step: 639, Loss: 0.34348636865615845, Lr:0.0001\n",
      "Epoch 1, Step: 640, Loss: 1.1603820323944092, Lr:0.0001\n",
      "Epoch 1, Step: 641, Loss: 0.3796595633029938, Lr:0.0001\n",
      "Epoch 1, Step: 642, Loss: 0.5329254269599915, Lr:0.0001\n",
      "Epoch 1, Step: 643, Loss: 0.4083169996738434, Lr:0.0001\n",
      "Epoch 1, Step: 644, Loss: 0.7191667556762695, Lr:0.0001\n",
      "Epoch 1, Step: 645, Loss: 0.5074636340141296, Lr:0.0001\n",
      "Epoch 1, Step: 646, Loss: 0.32512930035591125, Lr:0.0001\n",
      "Epoch 1, Step: 647, Loss: 0.5103755593299866, Lr:0.0001\n",
      "Epoch 1, Step: 648, Loss: 0.37886109948158264, Lr:0.0001\n",
      "Epoch 1, Step: 649, Loss: 0.5878826975822449, Lr:0.0001\n",
      "Epoch 1, Step: 650, Loss: 0.37763649225234985, Lr:0.0001\n",
      "Epoch 1, Step: 651, Loss: 0.6918956637382507, Lr:0.0001\n",
      "Epoch 1, Step: 652, Loss: 0.27788010239601135, Lr:0.0001\n",
      "Epoch 1, Step: 653, Loss: 0.4037609398365021, Lr:0.0001\n",
      "Epoch 1, Step: 654, Loss: 1.1106488704681396, Lr:0.0001\n",
      "Epoch 1, Step: 655, Loss: 0.2617568373680115, Lr:0.0001\n",
      "Epoch 1, Step: 656, Loss: 0.4527089297771454, Lr:0.0001\n",
      "Epoch 1, Step: 657, Loss: 0.8481462001800537, Lr:0.0001\n",
      "Epoch 1, Step: 658, Loss: 0.5855025053024292, Lr:0.0001\n",
      "Epoch 1, Step: 659, Loss: 0.6417813301086426, Lr:0.0001\n",
      "Epoch 1, Step: 660, Loss: 0.4913167655467987, Lr:0.0001\n",
      "Epoch 1, Step: 661, Loss: 0.4695676565170288, Lr:0.0001\n",
      "Epoch 1, Step: 662, Loss: 0.36673110723495483, Lr:0.0001\n",
      "Epoch 1, Step: 663, Loss: 0.3339269757270813, Lr:0.0001\n",
      "Epoch 1, Step: 664, Loss: 0.3706444799900055, Lr:0.0001\n",
      "Epoch 1, Step: 665, Loss: 0.5199787616729736, Lr:0.0001\n",
      "Epoch 1, Step: 666, Loss: 0.4821889400482178, Lr:0.0001\n",
      "Epoch 1, Step: 667, Loss: 0.7996460795402527, Lr:0.0001\n",
      "Epoch 1, Step: 668, Loss: 0.32508474588394165, Lr:0.0001\n",
      "Epoch 1, Step: 669, Loss: 0.5289278626441956, Lr:0.0001\n",
      "Epoch 1, Step: 670, Loss: 0.33343711495399475, Lr:0.0001\n",
      "Epoch 1, Step: 671, Loss: 0.2139439433813095, Lr:0.0001\n",
      "Epoch 1, Step: 672, Loss: 0.5616856813430786, Lr:0.0001\n",
      "Epoch 1, Step: 673, Loss: 0.22908224165439606, Lr:0.0001\n",
      "Epoch 1, Step: 674, Loss: 0.29984357953071594, Lr:0.0001\n",
      "Epoch 1, Step: 675, Loss: 0.24637390673160553, Lr:0.0001\n",
      "Epoch 1, Step: 676, Loss: 0.6962090134620667, Lr:0.0001\n",
      "Epoch 1, Step: 677, Loss: 0.5988104343414307, Lr:0.0001\n",
      "Epoch 1, Step: 678, Loss: 0.41818350553512573, Lr:0.0001\n",
      "Epoch 1, Step: 679, Loss: 0.3090870678424835, Lr:0.0001\n",
      "Epoch 1, Step: 680, Loss: 0.30711814761161804, Lr:0.0001\n",
      "Epoch 1, Step: 681, Loss: 0.3541548252105713, Lr:0.0001\n",
      "Epoch 1, Step: 682, Loss: 0.24744921922683716, Lr:0.0001\n",
      "Epoch 1, Step: 683, Loss: 0.5929896235466003, Lr:0.0001\n",
      "Epoch 1, Step: 684, Loss: 0.6693223118782043, Lr:0.0001\n",
      "Epoch 1, Step: 685, Loss: 0.3996007740497589, Lr:0.0001\n",
      "Epoch 1, Step: 686, Loss: 0.5410516262054443, Lr:0.0001\n",
      "Epoch 1, Step: 687, Loss: 0.9047262668609619, Lr:0.0001\n",
      "Epoch 1, Step: 688, Loss: 0.4678686559200287, Lr:0.0001\n",
      "Epoch 1, Step: 689, Loss: 0.4737347364425659, Lr:0.0001\n",
      "Epoch 1, Step: 690, Loss: 0.3018776774406433, Lr:0.0001\n",
      "Epoch 1, Step: 691, Loss: 0.2829550504684448, Lr:0.0001\n",
      "Epoch 1, Step: 692, Loss: 0.4082449972629547, Lr:0.0001\n",
      "Epoch 1, Step: 693, Loss: 0.46489718556404114, Lr:0.0001\n",
      "Epoch 1, Step: 694, Loss: 0.5664212107658386, Lr:0.0001\n",
      "Epoch 1, Step: 695, Loss: 1.1026264429092407, Lr:0.0001\n",
      "Epoch 1, Step: 696, Loss: 0.47793877124786377, Lr:0.0001\n",
      "Epoch 1, Step: 697, Loss: 0.2876270115375519, Lr:0.0001\n",
      "Epoch 1, Step: 698, Loss: 0.6236048936843872, Lr:0.0001\n",
      "Epoch 1, Step: 699, Loss: 0.26370003819465637, Lr:0.0001\n",
      "Epoch 1, Step: 700, Loss: 0.7967633008956909, Lr:0.0001\n",
      "Epoch 1, Step: 701, Loss: 0.48265787959098816, Lr:0.0001\n",
      "Epoch 1, Step: 702, Loss: 0.5549032688140869, Lr:0.0001\n",
      "Epoch 1, Step: 703, Loss: 0.978370189666748, Lr:0.0001\n",
      "Epoch 1, Step: 704, Loss: 0.365313857793808, Lr:0.0001\n",
      "Epoch 1, Step: 705, Loss: 0.35413190722465515, Lr:0.0001\n",
      "Epoch 1, Step: 706, Loss: 0.3696417808532715, Lr:0.0001\n",
      "Epoch 1, Step: 707, Loss: 0.3544316291809082, Lr:0.0001\n",
      "Epoch 1, Step: 708, Loss: 0.4348565638065338, Lr:0.0001\n",
      "Epoch 1, Step: 709, Loss: 0.4422578513622284, Lr:0.0001\n",
      "Epoch 1, Step: 710, Loss: 0.6024989485740662, Lr:0.0001\n",
      "Epoch 1, Step: 711, Loss: 0.7011962532997131, Lr:0.0001\n",
      "Epoch 1, Step: 712, Loss: 0.8485015630722046, Lr:0.0001\n",
      "Epoch 1, Step: 713, Loss: 0.5455385446548462, Lr:0.0001\n",
      "Epoch 1, Step: 714, Loss: 0.3883773684501648, Lr:0.0001\n",
      "Epoch 1, Step: 715, Loss: 0.2787815034389496, Lr:0.0001\n",
      "Epoch 1, Step: 716, Loss: 0.2560636103153229, Lr:0.0001\n",
      "Epoch 1, Step: 717, Loss: 0.5602461099624634, Lr:0.0001\n",
      "Epoch 1, Step: 718, Loss: 0.49793165922164917, Lr:0.0001\n",
      "Epoch 1, Step: 719, Loss: 0.6059657335281372, Lr:0.0001\n",
      "Epoch 1, Step: 720, Loss: 0.4143555164337158, Lr:0.0001\n",
      "Epoch 1, Step: 721, Loss: 0.2569672763347626, Lr:0.0001\n",
      "Epoch 1, Step: 722, Loss: 0.6372901201248169, Lr:0.0001\n",
      "Epoch 1, Step: 723, Loss: 0.27227354049682617, Lr:0.0001\n",
      "Epoch 1, Step: 724, Loss: 0.6430104970932007, Lr:0.0001\n",
      "Epoch 1, Step: 725, Loss: 0.7176352143287659, Lr:0.0001\n",
      "Epoch 1, Step: 726, Loss: 0.2540270984172821, Lr:0.0001\n",
      "Epoch 1, Step: 727, Loss: 0.704323410987854, Lr:0.0001\n",
      "Epoch 1, Step: 728, Loss: 0.5915929675102234, Lr:0.0001\n",
      "Epoch 1, Step: 729, Loss: 0.3038671612739563, Lr:0.0001\n",
      "Epoch 1, Step: 730, Loss: 0.737671971321106, Lr:0.0001\n",
      "Epoch 1, Step: 731, Loss: 0.27258026599884033, Lr:0.0001\n",
      "Epoch 1, Step: 732, Loss: 0.7904781699180603, Lr:0.0001\n",
      "Epoch 1, Step: 733, Loss: 0.3189260959625244, Lr:0.0001\n",
      "Epoch 1, Step: 734, Loss: 0.4095443785190582, Lr:0.0001\n",
      "Epoch 1, Step: 735, Loss: 0.36123618483543396, Lr:0.0001\n",
      "Epoch 1, Step: 736, Loss: 0.2830694615840912, Lr:0.0001\n",
      "Epoch 1, Step: 737, Loss: 0.40304845571517944, Lr:0.0001\n",
      "Epoch 1, Step: 738, Loss: 0.4463099539279938, Lr:0.0001\n",
      "Epoch 1, Step: 739, Loss: 0.600193202495575, Lr:0.0001\n",
      "Epoch 1, Step: 740, Loss: 0.8243449926376343, Lr:0.0001\n",
      "Epoch 1, Step: 741, Loss: 0.35382917523384094, Lr:0.0001\n",
      "Epoch 1, Step: 742, Loss: 0.538225531578064, Lr:0.0001\n",
      "Epoch 1, Step: 743, Loss: 0.20729464292526245, Lr:0.0001\n",
      "Epoch 1, Step: 744, Loss: 0.6981350183486938, Lr:0.0001\n",
      "Epoch 1, Step: 745, Loss: 0.38075369596481323, Lr:0.0001\n",
      "Epoch 1, Step: 746, Loss: 0.3844224810600281, Lr:0.0001\n",
      "Epoch 1, Step: 747, Loss: 0.4459935426712036, Lr:0.0001\n",
      "Epoch 1, Step: 748, Loss: 0.5059465169906616, Lr:0.0001\n",
      "Epoch 1, Step: 749, Loss: 0.7185842394828796, Lr:0.0001\n",
      "Epoch 1, Step: 750, Loss: 0.7212411761283875, Lr:0.0001\n",
      "Epoch 1, Step: 751, Loss: 0.42356017231941223, Lr:0.0001\n",
      "Epoch 1, Step: 752, Loss: 0.22367733716964722, Lr:0.0001\n",
      "Epoch 1, Step: 753, Loss: 0.5797299742698669, Lr:0.0001\n",
      "Epoch 1, Step: 754, Loss: 0.6635793447494507, Lr:0.0001\n",
      "Epoch 1, Step: 755, Loss: 0.6127517819404602, Lr:0.0001\n",
      "Epoch 1, Step: 756, Loss: 0.5644518136978149, Lr:0.0001\n",
      "Epoch 1, Step: 757, Loss: 0.21696142852306366, Lr:0.0001\n",
      "Epoch 1, Step: 758, Loss: 0.40189021825790405, Lr:0.0001\n",
      "Epoch 1, Step: 759, Loss: 0.3650842607021332, Lr:0.0001\n",
      "Epoch 1, Step: 760, Loss: 0.24034857749938965, Lr:0.0001\n",
      "Epoch 1, Step: 761, Loss: 0.5675733685493469, Lr:0.0001\n",
      "Epoch 1, Step: 762, Loss: 0.3876809775829315, Lr:0.0001\n",
      "Epoch 1, Step: 763, Loss: 0.28006213903427124, Lr:0.0001\n",
      "Epoch 1, Step: 764, Loss: 0.4167865514755249, Lr:0.0001\n",
      "Epoch 1, Step: 765, Loss: 0.3034709095954895, Lr:0.0001\n",
      "Epoch 1, Step: 766, Loss: 0.20948871970176697, Lr:0.0001\n",
      "Epoch 1, Step: 767, Loss: 0.2758527994155884, Lr:0.0001\n",
      "Epoch 1, Step: 768, Loss: 0.5340487360954285, Lr:0.0001\n",
      "Epoch 1, Step: 769, Loss: 0.2090500444173813, Lr:0.0001\n",
      "Epoch 1, Step: 770, Loss: 0.47896599769592285, Lr:0.0001\n",
      "Epoch 1, Step: 771, Loss: 0.20469491183757782, Lr:0.0001\n",
      "Epoch 1, Step: 772, Loss: 0.31316062808036804, Lr:0.0001\n",
      "Epoch 1, Step: 773, Loss: 0.4045983552932739, Lr:0.0001\n",
      "Epoch 1, Step: 774, Loss: 0.708126425743103, Lr:0.0001\n",
      "Epoch 1, Step: 775, Loss: 0.4542889893054962, Lr:0.0001\n",
      "Epoch 1, Step: 776, Loss: 0.28439319133758545, Lr:0.0001\n",
      "Epoch 1, Step: 777, Loss: 0.5476751327514648, Lr:0.0001\n",
      "Epoch 1, Step: 778, Loss: 0.1731371283531189, Lr:0.0001\n",
      "Epoch 1, Step: 779, Loss: 0.2629103660583496, Lr:0.0001\n",
      "Epoch 1, Step: 780, Loss: 0.3659697473049164, Lr:0.0001\n",
      "Epoch 1, Step: 781, Loss: 0.4616885483264923, Lr:0.0001\n",
      "Epoch 1, Step: 782, Loss: 0.4584166705608368, Lr:0.0001\n",
      "Epoch 1, Step: 783, Loss: 0.8095851540565491, Lr:0.0001\n",
      "Epoch 1, Step: 784, Loss: 0.30400243401527405, Lr:0.0001\n",
      "Epoch 1, Step: 785, Loss: 0.4923073947429657, Lr:0.0001\n",
      "Epoch 1, Step: 786, Loss: 0.42097994685173035, Lr:0.0001\n",
      "Epoch 1, Step: 787, Loss: 0.6963354349136353, Lr:0.0001\n",
      "Epoch 1, Step: 788, Loss: 0.34450724720954895, Lr:0.0001\n",
      "Epoch 1, Step: 789, Loss: 0.28038591146469116, Lr:0.0001\n",
      "Epoch 1, Step: 790, Loss: 0.4618656635284424, Lr:0.0001\n",
      "Epoch 1, Step: 791, Loss: 0.7184199690818787, Lr:0.0001\n",
      "Epoch 1, Step: 792, Loss: 0.6538177728652954, Lr:0.0001\n",
      "Epoch 1, Step: 793, Loss: 0.2998138666152954, Lr:0.0001\n",
      "Epoch 1, Step: 794, Loss: 0.42962443828582764, Lr:0.0001\n",
      "Epoch 1, Step: 795, Loss: 0.4192066788673401, Lr:0.0001\n",
      "Epoch 1, Step: 796, Loss: 0.41472169756889343, Lr:0.0001\n",
      "Epoch 1, Step: 797, Loss: 0.6840766072273254, Lr:0.0001\n",
      "Epoch 1, Step: 798, Loss: 0.7099231481552124, Lr:0.0001\n",
      "Epoch 1, Step: 799, Loss: 0.40449249744415283, Lr:0.0001\n",
      "Epoch 1, Step: 800, Loss: 0.42712464928627014, Lr:0.0001\n",
      "Epoch 1, Step: 801, Loss: 0.6427869200706482, Lr:0.0001\n",
      "Epoch 1, Step: 802, Loss: 0.360050767660141, Lr:0.0001\n",
      "Epoch 1, Step: 803, Loss: 0.39643484354019165, Lr:0.0001\n",
      "Epoch 1, Step: 804, Loss: 0.24390365183353424, Lr:0.0001\n",
      "Epoch 1, Step: 805, Loss: 0.24205641448497772, Lr:0.0001\n",
      "Epoch 1, Step: 806, Loss: 0.30146199464797974, Lr:0.0001\n",
      "Epoch 1, Step: 807, Loss: 0.7901219129562378, Lr:0.0001\n",
      "Epoch 1, Step: 808, Loss: 0.4446766972541809, Lr:0.0001\n",
      "Epoch 1, Step: 809, Loss: 0.5950605273246765, Lr:0.0001\n",
      "Epoch 1, Step: 810, Loss: 0.49837955832481384, Lr:0.0001\n",
      "Epoch 1, Step: 811, Loss: 0.28868189454078674, Lr:0.0001\n",
      "Epoch 1, Step: 812, Loss: 0.2875138819217682, Lr:0.0001\n",
      "Epoch 1, Step: 813, Loss: 0.34297093749046326, Lr:0.0001\n",
      "Epoch 1, Step: 814, Loss: 0.3964630365371704, Lr:0.0001\n",
      "Epoch 1, Step: 815, Loss: 0.3859340250492096, Lr:0.0001\n",
      "Epoch 1, Step: 816, Loss: 0.18935345113277435, Lr:0.0001\n",
      "Epoch 1, Step: 817, Loss: 0.49690118432044983, Lr:0.0001\n",
      "Epoch 1, Step: 818, Loss: 0.3723360300064087, Lr:0.0001\n",
      "Epoch 1, Step: 819, Loss: 0.13604648411273956, Lr:0.0001\n",
      "Epoch 1, Step: 820, Loss: 0.4094744920730591, Lr:0.0001\n",
      "Epoch 1, Step: 821, Loss: 0.20480583608150482, Lr:0.0001\n",
      "Epoch 1, Step: 822, Loss: 0.3189631700515747, Lr:0.0001\n",
      "Epoch 1, Step: 823, Loss: 0.5800678133964539, Lr:0.0001\n",
      "Epoch 1, Step: 824, Loss: 0.2978822886943817, Lr:0.0001\n",
      "Epoch 1, Step: 825, Loss: 0.6126663684844971, Lr:0.0001\n",
      "Epoch 1, Step: 826, Loss: 0.7664599418640137, Lr:0.0001\n",
      "Epoch 1, Step: 827, Loss: 0.2757319211959839, Lr:0.0001\n",
      "Epoch 1, Step: 828, Loss: 0.22851206362247467, Lr:0.0001\n",
      "Epoch 1, Step: 829, Loss: 0.26301079988479614, Lr:0.0001\n",
      "Epoch 1, Step: 830, Loss: 0.6143527030944824, Lr:0.0001\n",
      "Epoch 1, Step: 831, Loss: 0.30365896224975586, Lr:0.0001\n",
      "Epoch 1, Step: 832, Loss: 0.5822659730911255, Lr:0.0001\n",
      "Epoch 1, Step: 833, Loss: 0.6860711574554443, Lr:0.0001\n",
      "Epoch 1, Step: 834, Loss: 0.3187320828437805, Lr:0.0001\n",
      "Epoch 1, Step: 835, Loss: 0.32415127754211426, Lr:0.0001\n",
      "Epoch 1, Step: 836, Loss: 0.8009408712387085, Lr:0.0001\n",
      "Epoch 1, Step: 837, Loss: 0.3025949001312256, Lr:0.0001\n",
      "Epoch 1, Step: 838, Loss: 0.646158754825592, Lr:0.0001\n",
      "Epoch 1, Step: 839, Loss: 0.2531042993068695, Lr:0.0001\n",
      "Epoch 1, Step: 840, Loss: 0.5694356560707092, Lr:0.0001\n",
      "Epoch 1, Step: 841, Loss: 0.3661037087440491, Lr:0.0001\n",
      "Epoch 1, Step: 842, Loss: 0.45773494243621826, Lr:0.0001\n",
      "Epoch 1, Step: 843, Loss: 0.3040502667427063, Lr:0.0001\n",
      "Epoch 1, Step: 844, Loss: 0.40618646144866943, Lr:0.0001\n",
      "Epoch 1, Step: 845, Loss: 0.2941180169582367, Lr:0.0001\n",
      "Epoch 1, Step: 846, Loss: 0.46970728039741516, Lr:0.0001\n",
      "Epoch 1, Step: 847, Loss: 0.3435323238372803, Lr:0.0001\n",
      "Epoch 1, Step: 848, Loss: 0.48552387952804565, Lr:0.0001\n",
      "Epoch 1, Step: 849, Loss: 0.26550090312957764, Lr:0.0001\n",
      "Epoch 1, Step: 850, Loss: 0.5105665326118469, Lr:0.0001\n",
      "Epoch 1, Step: 851, Loss: 0.4798709750175476, Lr:0.0001\n",
      "Epoch 1, Step: 852, Loss: 0.757064163684845, Lr:0.0001\n",
      "Epoch 1, Step: 853, Loss: 0.31804782152175903, Lr:0.0001\n",
      "Epoch 1, Step: 854, Loss: 0.5422929525375366, Lr:0.0001\n",
      "Epoch 1, Step: 855, Loss: 0.4399621784687042, Lr:0.0001\n",
      "Epoch 1, Step: 856, Loss: 0.45409947633743286, Lr:0.0001\n",
      "Epoch 1, Step: 857, Loss: 0.3436387777328491, Lr:0.0001\n",
      "Epoch 1, Step: 858, Loss: 0.4610621929168701, Lr:0.0001\n",
      "Epoch 1, Step: 859, Loss: 0.1288623958826065, Lr:0.0001\n",
      "Epoch 1, Step: 860, Loss: 0.2665996253490448, Lr:0.0001\n",
      "Epoch 1, Step: 861, Loss: 0.40606096386909485, Lr:0.0001\n",
      "Epoch 1, Step: 862, Loss: 0.3631296157836914, Lr:0.0001\n",
      "Epoch 1, Step: 863, Loss: 0.8398606777191162, Lr:0.0001\n",
      "Epoch 1, Step: 864, Loss: 0.5530878305435181, Lr:0.0001\n",
      "Epoch 1, Step: 865, Loss: 0.5655528903007507, Lr:0.0001\n",
      "Epoch 1, Step: 866, Loss: 0.2818143367767334, Lr:0.0001\n",
      "Epoch 1, Step: 867, Loss: 0.22714044153690338, Lr:0.0001\n",
      "Epoch 1, Step: 868, Loss: 0.4259481430053711, Lr:0.0001\n",
      "Epoch 1, Step: 869, Loss: 0.3290562927722931, Lr:0.0001\n",
      "Epoch 1, Step: 870, Loss: 0.43251463770866394, Lr:0.0001\n",
      "Epoch 1, Step: 871, Loss: 0.36465731263160706, Lr:0.0001\n",
      "Epoch 1, Step: 872, Loss: 0.24650795757770538, Lr:0.0001\n",
      "Epoch 1, Step: 873, Loss: 0.09727606922388077, Lr:0.0001\n",
      "Epoch 1, Step: 874, Loss: 0.3559917211532593, Lr:0.0001\n",
      "Epoch 1, Step: 875, Loss: 0.4615871012210846, Lr:0.0001\n",
      "Epoch 1, Step: 876, Loss: 0.38879865407943726, Lr:0.0001\n",
      "Epoch 1, Step: 877, Loss: 0.7088876962661743, Lr:0.0001\n",
      "Epoch 1, Step: 878, Loss: 0.5156220197677612, Lr:0.0001\n",
      "Epoch 1, Step: 879, Loss: 0.18596254289150238, Lr:0.0001\n",
      "Epoch 1, Step: 880, Loss: 0.2145157903432846, Lr:0.0001\n",
      "Epoch 1, Step: 881, Loss: 0.3740213215351105, Lr:0.0001\n",
      "Epoch 1, Step: 882, Loss: 0.2755478322505951, Lr:0.0001\n",
      "Epoch 1, Step: 883, Loss: 0.19560979306697845, Lr:0.0001\n",
      "Epoch 1, Step: 884, Loss: 0.6467295289039612, Lr:0.0001\n",
      "Epoch 1, Step: 885, Loss: 0.19838586449623108, Lr:0.0001\n",
      "Epoch 1, Step: 886, Loss: 0.4321110248565674, Lr:0.0001\n",
      "Epoch 1, Step: 887, Loss: 0.7585083842277527, Lr:0.0001\n",
      "Epoch 1, Step: 888, Loss: 0.6955618262290955, Lr:0.0001\n",
      "Epoch 1, Step: 889, Loss: 0.21478116512298584, Lr:0.0001\n",
      "Epoch 1, Step: 890, Loss: 0.7673311233520508, Lr:0.0001\n",
      "Epoch 1, Step: 891, Loss: 0.22527359426021576, Lr:0.0001\n",
      "Epoch 1, Step: 892, Loss: 0.10385040193796158, Lr:0.0001\n",
      "Epoch 1, Step: 893, Loss: 0.46261975169181824, Lr:0.0001\n",
      "Epoch 1, Step: 894, Loss: 0.49240028858184814, Lr:0.0001\n",
      "Epoch 1, Step: 895, Loss: 0.46458718180656433, Lr:0.0001\n",
      "Epoch 1, Step: 896, Loss: 0.9155820608139038, Lr:0.0001\n",
      "Epoch 1, Step: 897, Loss: 0.7728357315063477, Lr:0.0001\n",
      "Epoch 1, Step: 898, Loss: 0.2804385721683502, Lr:0.0001\n",
      "Epoch 1, Step: 899, Loss: 0.3258039653301239, Lr:0.0001\n",
      "Epoch 1, Step: 900, Loss: 0.42149558663368225, Lr:0.0001\n",
      "Epoch 1, Step: 901, Loss: 0.4046645164489746, Lr:0.0001\n",
      "Epoch 1, Step: 902, Loss: 0.5542223453521729, Lr:0.0001\n",
      "Epoch 1, Step: 903, Loss: 0.2550432085990906, Lr:0.0001\n",
      "Epoch 1, Step: 904, Loss: 0.32189467549324036, Lr:0.0001\n",
      "Epoch 1, Step: 905, Loss: 0.496240496635437, Lr:0.0001\n",
      "Epoch 1, Step: 906, Loss: 0.1899145245552063, Lr:0.0001\n",
      "Epoch 1, Step: 907, Loss: 0.4322674572467804, Lr:0.0001\n",
      "Epoch 1, Step: 908, Loss: 0.40423381328582764, Lr:0.0001\n",
      "Epoch 1, Step: 909, Loss: 0.4202745258808136, Lr:0.0001\n",
      "Epoch 1, Step: 910, Loss: 0.3353952169418335, Lr:0.0001\n",
      "Epoch 1, Step: 911, Loss: 0.5748093128204346, Lr:0.0001\n",
      "Epoch 1, Step: 912, Loss: 0.5146518349647522, Lr:0.0001\n",
      "Epoch 1, Step: 913, Loss: 0.27785223722457886, Lr:0.0001\n",
      "Epoch 1, Step: 914, Loss: 0.6262662410736084, Lr:0.0001\n",
      "Epoch 1, Step: 915, Loss: 0.2507244050502777, Lr:0.0001\n",
      "Epoch 1, Step: 916, Loss: 0.11687164753675461, Lr:0.0001\n",
      "Epoch 1, Step: 917, Loss: 0.6453349590301514, Lr:0.0001\n",
      "Epoch 1, Step: 918, Loss: 0.21207265555858612, Lr:0.0001\n",
      "Epoch 1, Step: 919, Loss: 0.7853819131851196, Lr:0.0001\n",
      "Epoch 1, Step: 920, Loss: 0.16610069572925568, Lr:0.0001\n",
      "Epoch 1, Step: 921, Loss: 0.21855969727039337, Lr:0.0001\n",
      "Epoch 1, Step: 922, Loss: 0.3337964117527008, Lr:0.0001\n",
      "Epoch 1, Step: 923, Loss: 0.7701606750488281, Lr:0.0001\n",
      "Epoch 1, Step: 924, Loss: 0.39808180928230286, Lr:0.0001\n",
      "Epoch 1, Step: 925, Loss: 0.4761536121368408, Lr:0.0001\n",
      "Epoch 1, Step: 926, Loss: 0.7617477774620056, Lr:0.0001\n",
      "Epoch 1, Step: 927, Loss: 0.292061984539032, Lr:0.0001\n",
      "Epoch 1, Step: 928, Loss: 0.8399187326431274, Lr:0.0001\n",
      "Epoch 1, Step: 929, Loss: 0.3731693625450134, Lr:0.0001\n",
      "Epoch 1, Step: 930, Loss: 0.43510133028030396, Lr:0.0001\n",
      "Epoch 1, Step: 931, Loss: 0.12881070375442505, Lr:0.0001\n",
      "Epoch 1, Step: 932, Loss: 0.49196362495422363, Lr:0.0001\n",
      "Epoch 1, Step: 933, Loss: 0.5505495667457581, Lr:0.0001\n",
      "Epoch 1, Step: 934, Loss: 0.6332006454467773, Lr:0.0001\n",
      "Epoch 1, Step: 935, Loss: 0.5495009422302246, Lr:0.0001\n",
      "Epoch 1, Step: 936, Loss: 0.7245808839797974, Lr:0.0001\n",
      "Epoch 1, Step: 937, Loss: 0.5643056035041809, Lr:0.0001\n",
      "Epoch 1, Step: 938, Loss: 0.3764949440956116, Lr:0.0001\n",
      "Epoch 1, Step: 939, Loss: 0.41075676679611206, Lr:0.0001\n",
      "Epoch 1, Step: 940, Loss: 0.3736914098262787, Lr:0.0001\n",
      "Epoch 1, Step: 941, Loss: 0.16114088892936707, Lr:0.0001\n",
      "Epoch 1, Step: 942, Loss: 0.6465004682540894, Lr:0.0001\n",
      "Epoch 1, Step: 943, Loss: 0.4000929594039917, Lr:0.0001\n",
      "Epoch 1, Step: 944, Loss: 0.8956027626991272, Lr:0.0001\n",
      "Epoch 1, Step: 945, Loss: 0.3442158102989197, Lr:0.0001\n",
      "Epoch 1, Step: 946, Loss: 0.44070640206336975, Lr:0.0001\n",
      "Epoch 1, Step: 947, Loss: 0.2567373514175415, Lr:0.0001\n",
      "Epoch 1, Step: 948, Loss: 0.4607011675834656, Lr:0.0001\n",
      "Epoch 1, Step: 949, Loss: 0.4528237581253052, Lr:0.0001\n",
      "Epoch 1, Step: 950, Loss: 0.2659778296947479, Lr:0.0001\n",
      "Epoch 1, Step: 951, Loss: 0.7332442998886108, Lr:0.0001\n",
      "Epoch 1, Step: 952, Loss: 0.4508976936340332, Lr:0.0001\n",
      "Epoch 1, Step: 953, Loss: 0.4972166121006012, Lr:0.0001\n",
      "Epoch 1, Step: 954, Loss: 0.3764443099498749, Lr:0.0001\n",
      "Epoch 1, Step: 955, Loss: 0.22447118163108826, Lr:0.0001\n",
      "Epoch 1, Step: 956, Loss: 0.3872644305229187, Lr:0.0001\n",
      "Epoch 1, Step: 957, Loss: 0.3797689974308014, Lr:0.0001\n",
      "Epoch 1, Step: 958, Loss: 0.3563504219055176, Lr:0.0001\n",
      "Epoch 1, Step: 959, Loss: 0.4766155779361725, Lr:0.0001\n",
      "Epoch 1, Step: 960, Loss: 0.3594954311847687, Lr:0.0001\n",
      "Epoch 1, Step: 961, Loss: 0.3534145653247833, Lr:0.0001\n",
      "Epoch 1, Step: 962, Loss: 0.44199004769325256, Lr:0.0001\n",
      "Epoch 1, Step: 963, Loss: 0.3659569323062897, Lr:0.0001\n",
      "Epoch 1, Step: 964, Loss: 0.3702496290206909, Lr:0.0001\n",
      "Epoch 1, Step: 965, Loss: 0.4400351345539093, Lr:0.0001\n",
      "Epoch 1, Step: 966, Loss: 0.41041648387908936, Lr:0.0001\n",
      "Epoch 1, Step: 967, Loss: 0.33464446663856506, Lr:0.0001\n",
      "Epoch 1, Step: 968, Loss: 0.26154595613479614, Lr:0.0001\n",
      "Epoch 1, Step: 969, Loss: 0.3941473364830017, Lr:0.0001\n",
      "Epoch 1, Step: 970, Loss: 0.29484987258911133, Lr:0.0001\n",
      "Epoch 1, Step: 971, Loss: 0.2416379153728485, Lr:0.0001\n",
      "Epoch 1, Step: 972, Loss: 0.2684863209724426, Lr:0.0001\n",
      "Epoch 1, Step: 973, Loss: 0.6228816509246826, Lr:0.0001\n",
      "Epoch 1, Step: 974, Loss: 0.28913718461990356, Lr:0.0001\n",
      "Epoch 1, Step: 975, Loss: 0.1889297515153885, Lr:0.0001\n",
      "Epoch 1, Step: 976, Loss: 0.17528504133224487, Lr:0.0001\n",
      "Epoch 1, Step: 977, Loss: 0.3514280319213867, Lr:0.0001\n",
      "Epoch 1, Step: 978, Loss: 0.34955137968063354, Lr:0.0001\n",
      "Epoch 1, Step: 979, Loss: 1.1280890703201294, Lr:0.0001\n",
      "Epoch 1, Step: 980, Loss: 0.15457549691200256, Lr:0.0001\n",
      "Epoch 1, Step: 981, Loss: 0.3185997009277344, Lr:0.0001\n",
      "Epoch 1, Step: 982, Loss: 0.3566698133945465, Lr:0.0001\n",
      "Epoch 1, Step: 983, Loss: 0.1716708242893219, Lr:0.0001\n",
      "Epoch 1, Step: 984, Loss: 0.5710071921348572, Lr:0.0001\n",
      "Epoch 1, Step: 985, Loss: 0.4545751214027405, Lr:0.0001\n",
      "Epoch 1, Step: 986, Loss: 0.27579614520072937, Lr:0.0001\n",
      "Epoch 1, Step: 987, Loss: 0.5348584055900574, Lr:0.0001\n",
      "Epoch 1, Step: 988, Loss: 0.2774693965911865, Lr:0.0001\n",
      "Epoch 1, Step: 989, Loss: 0.3915358781814575, Lr:0.0001\n",
      "Epoch 1, Step: 990, Loss: 0.38212326169013977, Lr:0.0001\n",
      "Epoch 1, Step: 991, Loss: 0.27694153785705566, Lr:0.0001\n",
      "Epoch 1, Step: 992, Loss: 0.3722895383834839, Lr:0.0001\n",
      "Epoch 1, Step: 993, Loss: 0.5486738085746765, Lr:0.0001\n",
      "Epoch 1, Step: 994, Loss: 0.328003853559494, Lr:0.0001\n",
      "Epoch 1, Step: 995, Loss: 0.3768269121646881, Lr:0.0001\n",
      "Epoch 1, Step: 996, Loss: 0.829170823097229, Lr:0.0001\n",
      "Epoch 1, Step: 997, Loss: 0.276199609041214, Lr:0.0001\n",
      "Epoch 1, Step: 998, Loss: 0.23819628357887268, Lr:0.0001\n",
      "Epoch 1, Step: 999, Loss: 0.16879452764987946, Lr:0.0001\n",
      "Epoch 1, Step: 1000, Loss: 0.530516505241394, Lr:0.0001\n",
      "Epoch 1, Step: 1001, Loss: 0.509431004524231, Lr:0.0001\n",
      "Epoch 1, Step: 1002, Loss: 0.25899773836135864, Lr:0.0001\n",
      "Epoch 1, Step: 1003, Loss: 0.26307976245880127, Lr:0.0001\n",
      "Epoch 1, Step: 1004, Loss: 0.2905706763267517, Lr:0.0001\n",
      "Epoch 1, Step: 1005, Loss: 0.3976305425167084, Lr:0.0001\n",
      "Epoch 1, Step: 1006, Loss: 0.3277069926261902, Lr:0.0001\n",
      "Epoch 1, Step: 1007, Loss: 0.7143973708152771, Lr:0.0001\n",
      "Epoch 1, Step: 1008, Loss: 0.9494436979293823, Lr:0.0001\n",
      "Epoch 1, Step: 1009, Loss: 0.47280624508857727, Lr:0.0001\n",
      "Epoch 1, Step: 1010, Loss: 0.278819739818573, Lr:0.0001\n",
      "Epoch 1, Step: 1011, Loss: 0.6833486557006836, Lr:0.0001\n",
      "Epoch 1, Step: 1012, Loss: 0.5605561137199402, Lr:0.0001\n",
      "Epoch 1, Step: 1013, Loss: 0.3046152889728546, Lr:0.0001\n",
      "Epoch 1, Step: 1014, Loss: 0.35632792115211487, Lr:0.0001\n",
      "Epoch 1, Step: 1015, Loss: 0.3891569674015045, Lr:0.0001\n",
      "Epoch 1, Step: 1016, Loss: 0.4578905403614044, Lr:0.0001\n",
      "Epoch 1, Step: 1017, Loss: 0.307991087436676, Lr:0.0001\n",
      "Epoch 1, Step: 1018, Loss: 0.32174113392829895, Lr:0.0001\n",
      "Epoch 1, Step: 1019, Loss: 0.6310752630233765, Lr:0.0001\n",
      "Epoch 1, Step: 1020, Loss: 0.25193336606025696, Lr:0.0001\n",
      "Epoch 1, Step: 1021, Loss: 0.5087795257568359, Lr:0.0001\n",
      "Epoch 1, Step: 1022, Loss: 0.7807528972625732, Lr:0.0001\n",
      "Epoch 1, Step: 1023, Loss: 0.48301517963409424, Lr:0.0001\n",
      "Epoch 1, Step: 1024, Loss: 0.4541807174682617, Lr:0.0001\n",
      "Epoch 1, Step: 1025, Loss: 0.42293041944503784, Lr:0.0001\n",
      "Epoch 1, Step: 1026, Loss: 0.1576065868139267, Lr:0.0001\n",
      "Epoch 1, Step: 1027, Loss: 0.4523177444934845, Lr:0.0001\n",
      "Epoch 1, Step: 1028, Loss: 0.4098774790763855, Lr:0.0001\n",
      "Epoch 1, Step: 1029, Loss: 0.48580682277679443, Lr:0.0001\n",
      "Epoch 1, Step: 1030, Loss: 0.44602376222610474, Lr:0.0001\n",
      "Epoch 1, Step: 1031, Loss: 0.2858200669288635, Lr:0.0001\n",
      "Epoch 1, Step: 1032, Loss: 0.38000133633613586, Lr:0.0001\n",
      "Epoch 1, Step: 1033, Loss: 0.48464706540107727, Lr:0.0001\n",
      "Epoch 1, Step: 1034, Loss: 0.2660794258117676, Lr:0.0001\n",
      "Epoch 1, Step: 1035, Loss: 0.5338543057441711, Lr:0.0001\n",
      "Epoch 1, Step: 1036, Loss: 0.581961452960968, Lr:0.0001\n",
      "Epoch 1, Step: 1037, Loss: 0.3074776530265808, Lr:0.0001\n",
      "Epoch 1, Step: 1038, Loss: 0.41485756635665894, Lr:0.0001\n",
      "Epoch 1, Step: 1039, Loss: 0.4582921862602234, Lr:0.0001\n",
      "Epoch 1, Step: 1040, Loss: 0.27170658111572266, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 1\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:20 loss: 0.5074 (0.5074) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.3676 data: 0.1136 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:16 loss: 0.1737 (0.2276) acc1: 93.7500 (90.3409) acc5: 100.0000 (100.0000) time: 0.3531 data: 0.1173 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:12 loss: 0.0764 (0.1822) acc1: 100.0000 (92.8571) acc5: 100.0000 (100.0000) time: 0.3454 data: 0.1172 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:09 loss: 0.0764 (0.3999) acc1: 93.7500 (86.0887) acc5: 100.0000 (100.0000) time: 0.3429 data: 0.1176 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:05 loss: 0.5595 (0.5212) acc1: 62.5000 (80.1829) acc5: 100.0000 (100.0000) time: 0.3448 data: 0.1187 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:02 loss: 0.6783 (0.5361) acc1: 62.5000 (79.6569) acc5: 100.0000 (100.0000) time: 0.3414 data: 0.1198 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.4603 (0.5701) acc1: 68.7500 (78.7741) acc5: 100.0000 (100.0000) time: 0.3272 data: 0.1146 max mem: 15137\n",
      "Test: Total time: 0:00:19 (0.3399 s / it)\n",
      "* Acc@1 78.774 Acc@5 100.000 loss 0.570\n",
      "Accuracy of the network on the 881 test image: 78.8%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 2, Step: 0, Loss: 0.19082586467266083, Lr:0.0001\n",
      "Epoch 2, Step: 1, Loss: 0.5366371870040894, Lr:0.0001\n",
      "Epoch 2, Step: 2, Loss: 0.3919571042060852, Lr:0.0001\n",
      "Epoch 2, Step: 3, Loss: 0.338002473115921, Lr:0.0001\n",
      "Epoch 2, Step: 4, Loss: 0.23432785272598267, Lr:0.0001\n",
      "Epoch 2, Step: 5, Loss: 0.2594738304615021, Lr:0.0001\n",
      "Epoch 2, Step: 6, Loss: 0.4260779619216919, Lr:0.0001\n",
      "Epoch 2, Step: 7, Loss: 0.27296605706214905, Lr:0.0001\n",
      "Epoch 2, Step: 8, Loss: 0.2513039708137512, Lr:0.0001\n",
      "Epoch 2, Step: 9, Loss: 0.3054805099964142, Lr:0.0001\n",
      "Epoch 2, Step: 10, Loss: 0.5975412726402283, Lr:0.0001\n",
      "Epoch 2, Step: 11, Loss: 0.6027116179466248, Lr:0.0001\n",
      "Epoch 2, Step: 12, Loss: 0.5595787763595581, Lr:0.0001\n",
      "Epoch 2, Step: 13, Loss: 0.39168781042099, Lr:0.0001\n",
      "Epoch 2, Step: 14, Loss: 0.3006812036037445, Lr:0.0001\n",
      "Epoch 2, Step: 15, Loss: 0.6789953112602234, Lr:0.0001\n",
      "Epoch 2, Step: 16, Loss: 0.35544079542160034, Lr:0.0001\n",
      "Epoch 2, Step: 17, Loss: 0.42425504326820374, Lr:0.0001\n",
      "Epoch 2, Step: 18, Loss: 0.4367469549179077, Lr:0.0001\n",
      "Epoch 2, Step: 19, Loss: 0.4185469448566437, Lr:0.0001\n",
      "Epoch 2, Step: 20, Loss: 0.41035768389701843, Lr:0.0001\n",
      "Epoch 2, Step: 21, Loss: 0.29586201906204224, Lr:0.0001\n",
      "Epoch 2, Step: 22, Loss: 0.20407304167747498, Lr:0.0001\n",
      "Epoch 2, Step: 23, Loss: 0.9776033759117126, Lr:0.0001\n",
      "Epoch 2, Step: 24, Loss: 0.2865469753742218, Lr:0.0001\n",
      "Epoch 2, Step: 25, Loss: 0.20665337145328522, Lr:0.0001\n",
      "Epoch 2, Step: 26, Loss: 0.35150742530822754, Lr:0.0001\n",
      "Epoch 2, Step: 27, Loss: 0.4730033576488495, Lr:0.0001\n",
      "Epoch 2, Step: 28, Loss: 0.21779119968414307, Lr:0.0001\n",
      "Epoch 2, Step: 29, Loss: 0.31482967734336853, Lr:0.0001\n",
      "Epoch 2, Step: 30, Loss: 0.3719003200531006, Lr:0.0001\n",
      "Epoch 2, Step: 31, Loss: 0.6291183233261108, Lr:0.0001\n",
      "Epoch 2, Step: 32, Loss: 0.36726847290992737, Lr:0.0001\n",
      "Epoch 2, Step: 33, Loss: 0.32671043276786804, Lr:0.0001\n",
      "Epoch 2, Step: 34, Loss: 0.13314205408096313, Lr:0.0001\n",
      "Epoch 2, Step: 35, Loss: 0.2135225236415863, Lr:0.0001\n",
      "Epoch 2, Step: 36, Loss: 0.2915935218334198, Lr:0.0001\n",
      "Epoch 2, Step: 37, Loss: 0.13027821481227875, Lr:0.0001\n",
      "Epoch 2, Step: 38, Loss: 0.5593634843826294, Lr:0.0001\n",
      "Epoch 2, Step: 39, Loss: 0.4019390046596527, Lr:0.0001\n",
      "Epoch 2, Step: 40, Loss: 0.2978765070438385, Lr:0.0001\n",
      "Epoch 2, Step: 41, Loss: 0.3393852114677429, Lr:0.0001\n",
      "Epoch 2, Step: 42, Loss: 0.652806282043457, Lr:0.0001\n",
      "Epoch 2, Step: 43, Loss: 0.5932593941688538, Lr:0.0001\n",
      "Epoch 2, Step: 44, Loss: 0.2148699313402176, Lr:0.0001\n",
      "Epoch 2, Step: 45, Loss: 0.5071560144424438, Lr:0.0001\n",
      "Epoch 2, Step: 46, Loss: 0.2271706610918045, Lr:0.0001\n",
      "Epoch 2, Step: 47, Loss: 0.36574825644493103, Lr:0.0001\n",
      "Epoch 2, Step: 48, Loss: 0.6096150875091553, Lr:0.0001\n",
      "Epoch 2, Step: 49, Loss: 0.25567546486854553, Lr:0.0001\n",
      "Epoch 2, Step: 50, Loss: 0.24408869445323944, Lr:0.0001\n",
      "Epoch 2, Step: 51, Loss: 0.7337714433670044, Lr:0.0001\n",
      "Epoch 2, Step: 52, Loss: 0.6526177525520325, Lr:0.0001\n",
      "Epoch 2, Step: 53, Loss: 0.20975477993488312, Lr:0.0001\n",
      "Epoch 2, Step: 54, Loss: 0.49497658014297485, Lr:0.0001\n",
      "Epoch 2, Step: 55, Loss: 1.0750235319137573, Lr:0.0001\n",
      "Epoch 2, Step: 56, Loss: 0.27987635135650635, Lr:0.0001\n",
      "Epoch 2, Step: 57, Loss: 0.29219046235084534, Lr:0.0001\n",
      "Epoch 2, Step: 58, Loss: 0.4093046188354492, Lr:0.0001\n",
      "Epoch 2, Step: 59, Loss: 0.4021894633769989, Lr:0.0001\n",
      "Epoch 2, Step: 60, Loss: 0.5075297355651855, Lr:0.0001\n",
      "Epoch 2, Step: 61, Loss: 0.6014408469200134, Lr:0.0001\n",
      "Epoch 2, Step: 62, Loss: 0.14369630813598633, Lr:0.0001\n",
      "Epoch 2, Step: 63, Loss: 0.638988733291626, Lr:0.0001\n",
      "Epoch 2, Step: 64, Loss: 0.5271462798118591, Lr:0.0001\n",
      "Epoch 2, Step: 65, Loss: 0.5050438046455383, Lr:0.0001\n",
      "Epoch 2, Step: 66, Loss: 0.5551289319992065, Lr:0.0001\n",
      "Epoch 2, Step: 67, Loss: 0.6157298684120178, Lr:0.0001\n",
      "Epoch 2, Step: 68, Loss: 0.5873772501945496, Lr:0.0001\n",
      "Epoch 2, Step: 69, Loss: 0.5646937489509583, Lr:0.0001\n",
      "Epoch 2, Step: 70, Loss: 0.30737122893333435, Lr:0.0001\n",
      "Epoch 2, Step: 71, Loss: 0.2720050811767578, Lr:0.0001\n",
      "Epoch 2, Step: 72, Loss: 0.35163915157318115, Lr:0.0001\n",
      "Epoch 2, Step: 73, Loss: 0.5891215205192566, Lr:0.0001\n",
      "Epoch 2, Step: 74, Loss: 0.4452941417694092, Lr:0.0001\n",
      "Epoch 2, Step: 75, Loss: 0.23933078348636627, Lr:0.0001\n",
      "Epoch 2, Step: 76, Loss: 0.7434502243995667, Lr:0.0001\n",
      "Epoch 2, Step: 77, Loss: 0.6850334405899048, Lr:0.0001\n",
      "Epoch 2, Step: 78, Loss: 0.16518408060073853, Lr:0.0001\n",
      "Epoch 2, Step: 79, Loss: 0.39622268080711365, Lr:0.0001\n",
      "Epoch 2, Step: 80, Loss: 0.2636134922504425, Lr:0.0001\n",
      "Epoch 2, Step: 81, Loss: 0.44871190190315247, Lr:0.0001\n",
      "Epoch 2, Step: 82, Loss: 0.861171543598175, Lr:0.0001\n",
      "Epoch 2, Step: 83, Loss: 0.30856794118881226, Lr:0.0001\n",
      "Epoch 2, Step: 84, Loss: 0.44908902049064636, Lr:0.0001\n",
      "Epoch 2, Step: 85, Loss: 0.5273393392562866, Lr:0.0001\n",
      "Epoch 2, Step: 86, Loss: 0.5491303205490112, Lr:0.0001\n",
      "Epoch 2, Step: 87, Loss: 0.41596370935440063, Lr:0.0001\n",
      "Epoch 2, Step: 88, Loss: 0.3324253559112549, Lr:0.0001\n",
      "Epoch 2, Step: 89, Loss: 0.3876076638698578, Lr:0.0001\n",
      "Epoch 2, Step: 90, Loss: 0.3517952263355255, Lr:0.0001\n",
      "Epoch 2, Step: 91, Loss: 0.5434985160827637, Lr:0.0001\n",
      "Epoch 2, Step: 92, Loss: 0.29374536871910095, Lr:0.0001\n",
      "Epoch 2, Step: 93, Loss: 0.19996139407157898, Lr:0.0001\n",
      "Epoch 2, Step: 94, Loss: 0.3949359953403473, Lr:0.0001\n",
      "Epoch 2, Step: 95, Loss: 0.2586787939071655, Lr:0.0001\n",
      "Epoch 2, Step: 96, Loss: 0.27054738998413086, Lr:0.0001\n",
      "Epoch 2, Step: 97, Loss: 0.20179510116577148, Lr:0.0001\n",
      "Epoch 2, Step: 98, Loss: 0.18714945018291473, Lr:0.0001\n",
      "Epoch 2, Step: 99, Loss: 0.23558679223060608, Lr:0.0001\n",
      "Epoch 2, Step: 100, Loss: 0.4396168887615204, Lr:0.0001\n",
      "Epoch 2, Step: 101, Loss: 0.614189088344574, Lr:0.0001\n",
      "Epoch 2, Step: 102, Loss: 0.20192112028598785, Lr:0.0001\n",
      "Epoch 2, Step: 103, Loss: 0.5314383506774902, Lr:0.0001\n",
      "Epoch 2, Step: 104, Loss: 0.5196868181228638, Lr:0.0001\n",
      "Epoch 2, Step: 105, Loss: 0.3249477744102478, Lr:0.0001\n",
      "Epoch 2, Step: 106, Loss: 0.5445777773857117, Lr:0.0001\n",
      "Epoch 2, Step: 107, Loss: 0.46294280886650085, Lr:0.0001\n",
      "Epoch 2, Step: 108, Loss: 0.3202500641345978, Lr:0.0001\n",
      "Epoch 2, Step: 109, Loss: 0.3610382378101349, Lr:0.0001\n",
      "Epoch 2, Step: 110, Loss: 0.3395243287086487, Lr:0.0001\n",
      "Epoch 2, Step: 111, Loss: 0.3095029890537262, Lr:0.0001\n",
      "Epoch 2, Step: 112, Loss: 0.26784747838974, Lr:0.0001\n",
      "Epoch 2, Step: 113, Loss: 0.5919216871261597, Lr:0.0001\n",
      "Epoch 2, Step: 114, Loss: 0.3133034408092499, Lr:0.0001\n",
      "Epoch 2, Step: 115, Loss: 0.45509836077690125, Lr:0.0001\n",
      "Epoch 2, Step: 116, Loss: 0.21091482043266296, Lr:0.0001\n",
      "Epoch 2, Step: 117, Loss: 0.3779629170894623, Lr:0.0001\n",
      "Epoch 2, Step: 118, Loss: 0.3609919250011444, Lr:0.0001\n",
      "Epoch 2, Step: 119, Loss: 0.38163644075393677, Lr:0.0001\n",
      "Epoch 2, Step: 120, Loss: 0.23023538291454315, Lr:0.0001\n",
      "Epoch 2, Step: 121, Loss: 0.42973196506500244, Lr:0.0001\n",
      "Epoch 2, Step: 122, Loss: 0.6124960780143738, Lr:0.0001\n",
      "Epoch 2, Step: 123, Loss: 0.375276654958725, Lr:0.0001\n",
      "Epoch 2, Step: 124, Loss: 0.20768047869205475, Lr:0.0001\n",
      "Epoch 2, Step: 125, Loss: 0.45842093229293823, Lr:0.0001\n",
      "Epoch 2, Step: 126, Loss: 0.6242028474807739, Lr:0.0001\n",
      "Epoch 2, Step: 127, Loss: 0.3868978023529053, Lr:0.0001\n",
      "Epoch 2, Step: 128, Loss: 0.4606381058692932, Lr:0.0001\n",
      "Epoch 2, Step: 129, Loss: 0.22168505191802979, Lr:0.0001\n",
      "Epoch 2, Step: 130, Loss: 0.8573690056800842, Lr:0.0001\n",
      "Epoch 2, Step: 131, Loss: 0.45626044273376465, Lr:0.0001\n",
      "Epoch 2, Step: 132, Loss: 0.2952668368816376, Lr:0.0001\n",
      "Epoch 2, Step: 133, Loss: 0.3338664472103119, Lr:0.0001\n",
      "Epoch 2, Step: 134, Loss: 0.73537677526474, Lr:0.0001\n",
      "Epoch 2, Step: 135, Loss: 0.3950589895248413, Lr:0.0001\n",
      "Epoch 2, Step: 136, Loss: 0.3461833596229553, Lr:0.0001\n",
      "Epoch 2, Step: 137, Loss: 0.150999516248703, Lr:0.0001\n",
      "Epoch 2, Step: 138, Loss: 0.36482056975364685, Lr:0.0001\n",
      "Epoch 2, Step: 139, Loss: 0.3929629623889923, Lr:0.0001\n",
      "Epoch 2, Step: 140, Loss: 0.31085336208343506, Lr:0.0001\n",
      "Epoch 2, Step: 141, Loss: 0.20159049332141876, Lr:0.0001\n",
      "Epoch 2, Step: 142, Loss: 0.31783902645111084, Lr:0.0001\n",
      "Epoch 2, Step: 143, Loss: 0.29687637090682983, Lr:0.0001\n",
      "Epoch 2, Step: 144, Loss: 0.2255849987268448, Lr:0.0001\n",
      "Epoch 2, Step: 145, Loss: 0.32394230365753174, Lr:0.0001\n",
      "Epoch 2, Step: 146, Loss: 0.23021574318408966, Lr:0.0001\n",
      "Epoch 2, Step: 147, Loss: 0.11645536869764328, Lr:0.0001\n",
      "Epoch 2, Step: 148, Loss: 0.19930528104305267, Lr:0.0001\n",
      "Epoch 2, Step: 149, Loss: 0.3792709708213806, Lr:0.0001\n",
      "Epoch 2, Step: 150, Loss: 0.9095038771629333, Lr:0.0001\n",
      "Epoch 2, Step: 151, Loss: 0.32088416814804077, Lr:0.0001\n",
      "Epoch 2, Step: 152, Loss: 0.15723861753940582, Lr:0.0001\n",
      "Epoch 2, Step: 153, Loss: 0.11015281081199646, Lr:0.0001\n",
      "Epoch 2, Step: 154, Loss: 0.27940842509269714, Lr:0.0001\n",
      "Epoch 2, Step: 155, Loss: 0.4905553460121155, Lr:0.0001\n",
      "Epoch 2, Step: 156, Loss: 0.3111816644668579, Lr:0.0001\n",
      "Epoch 2, Step: 157, Loss: 0.4430622458457947, Lr:0.0001\n",
      "Epoch 2, Step: 158, Loss: 0.18161149322986603, Lr:0.0001\n",
      "Epoch 2, Step: 159, Loss: 0.5253351926803589, Lr:0.0001\n",
      "Epoch 2, Step: 160, Loss: 0.3710026741027832, Lr:0.0001\n",
      "Epoch 2, Step: 161, Loss: 0.30961236357688904, Lr:0.0001\n",
      "Epoch 2, Step: 162, Loss: 0.5118177533149719, Lr:0.0001\n",
      "Epoch 2, Step: 163, Loss: 0.23800458014011383, Lr:0.0001\n",
      "Epoch 2, Step: 164, Loss: 0.621892511844635, Lr:0.0001\n",
      "Epoch 2, Step: 165, Loss: 0.8090922236442566, Lr:0.0001\n",
      "Epoch 2, Step: 166, Loss: 0.2800315320491791, Lr:0.0001\n",
      "Epoch 2, Step: 167, Loss: 0.6636740565299988, Lr:0.0001\n",
      "Epoch 2, Step: 168, Loss: 0.22874462604522705, Lr:0.0001\n",
      "Epoch 2, Step: 169, Loss: 0.31093648076057434, Lr:0.0001\n",
      "Epoch 2, Step: 170, Loss: 0.4160851836204529, Lr:0.0001\n",
      "Epoch 2, Step: 171, Loss: 0.373779833316803, Lr:0.0001\n",
      "Epoch 2, Step: 172, Loss: 0.40187397599220276, Lr:0.0001\n",
      "Epoch 2, Step: 173, Loss: 0.7585166692733765, Lr:0.0001\n",
      "Epoch 2, Step: 174, Loss: 0.454999178647995, Lr:0.0001\n",
      "Epoch 2, Step: 175, Loss: 0.3365251421928406, Lr:0.0001\n",
      "Epoch 2, Step: 176, Loss: 0.3808155357837677, Lr:0.0001\n",
      "Epoch 2, Step: 177, Loss: 0.5939990282058716, Lr:0.0001\n",
      "Epoch 2, Step: 178, Loss: 0.42078691720962524, Lr:0.0001\n",
      "Epoch 2, Step: 179, Loss: 0.2637521028518677, Lr:0.0001\n",
      "Epoch 2, Step: 180, Loss: 0.3658289909362793, Lr:0.0001\n",
      "Epoch 2, Step: 181, Loss: 0.11688993871212006, Lr:0.0001\n",
      "Epoch 2, Step: 182, Loss: 0.2860581874847412, Lr:0.0001\n",
      "Epoch 2, Step: 183, Loss: 0.42334964871406555, Lr:0.0001\n",
      "Epoch 2, Step: 184, Loss: 0.3344806134700775, Lr:0.0001\n",
      "Epoch 2, Step: 185, Loss: 0.20310015976428986, Lr:0.0001\n",
      "Epoch 2, Step: 186, Loss: 0.35863950848579407, Lr:0.0001\n",
      "Epoch 2, Step: 187, Loss: 0.3375813066959381, Lr:0.0001\n",
      "Epoch 2, Step: 188, Loss: 0.4156895875930786, Lr:0.0001\n",
      "Epoch 2, Step: 189, Loss: 0.18337135016918182, Lr:0.0001\n",
      "Epoch 2, Step: 190, Loss: 0.17506851255893707, Lr:0.0001\n",
      "Epoch 2, Step: 191, Loss: 0.21644188463687897, Lr:0.0001\n",
      "Epoch 2, Step: 192, Loss: 0.29819443821907043, Lr:0.0001\n",
      "Epoch 2, Step: 193, Loss: 0.5825368762016296, Lr:0.0001\n",
      "Epoch 2, Step: 194, Loss: 0.5911991596221924, Lr:0.0001\n",
      "Epoch 2, Step: 195, Loss: 0.1743910014629364, Lr:0.0001\n",
      "Epoch 2, Step: 196, Loss: 0.6058992147445679, Lr:0.0001\n",
      "Epoch 2, Step: 197, Loss: 0.2950458526611328, Lr:0.0001\n",
      "Epoch 2, Step: 198, Loss: 0.26689350605010986, Lr:0.0001\n",
      "Epoch 2, Step: 199, Loss: 0.2962051033973694, Lr:0.0001\n",
      "Epoch 2, Step: 200, Loss: 0.6546079516410828, Lr:0.0001\n",
      "Epoch 2, Step: 201, Loss: 0.1343972235918045, Lr:0.0001\n",
      "Epoch 2, Step: 202, Loss: 0.1902638077735901, Lr:0.0001\n",
      "Epoch 2, Step: 203, Loss: 0.20615187287330627, Lr:0.0001\n",
      "Epoch 2, Step: 204, Loss: 0.3499010503292084, Lr:0.0001\n",
      "Epoch 2, Step: 205, Loss: 0.24337218701839447, Lr:0.0001\n",
      "Epoch 2, Step: 206, Loss: 0.7094941139221191, Lr:0.0001\n",
      "Epoch 2, Step: 207, Loss: 0.4429895877838135, Lr:0.0001\n",
      "Epoch 2, Step: 208, Loss: 0.504973828792572, Lr:0.0001\n",
      "Epoch 2, Step: 209, Loss: 0.5269600749015808, Lr:0.0001\n",
      "Epoch 2, Step: 210, Loss: 0.35650163888931274, Lr:0.0001\n",
      "Epoch 2, Step: 211, Loss: 0.45393210649490356, Lr:0.0001\n",
      "Epoch 2, Step: 212, Loss: 0.5443723797798157, Lr:0.0001\n",
      "Epoch 2, Step: 213, Loss: 0.21526069939136505, Lr:0.0001\n",
      "Epoch 2, Step: 214, Loss: 0.5409285426139832, Lr:0.0001\n",
      "Epoch 2, Step: 215, Loss: 0.47253483533859253, Lr:0.0001\n",
      "Epoch 2, Step: 216, Loss: 0.20191842317581177, Lr:0.0001\n",
      "Epoch 2, Step: 217, Loss: 0.17833009362220764, Lr:0.0001\n",
      "Epoch 2, Step: 218, Loss: 0.44562438130378723, Lr:0.0001\n",
      "Epoch 2, Step: 219, Loss: 0.41487404704093933, Lr:0.0001\n",
      "Epoch 2, Step: 220, Loss: 0.27690544724464417, Lr:0.0001\n",
      "Epoch 2, Step: 221, Loss: 0.41227391362190247, Lr:0.0001\n",
      "Epoch 2, Step: 222, Loss: 0.3200843930244446, Lr:0.0001\n",
      "Epoch 2, Step: 223, Loss: 0.20351319015026093, Lr:0.0001\n",
      "Epoch 2, Step: 224, Loss: 0.4077431559562683, Lr:0.0001\n",
      "Epoch 2, Step: 225, Loss: 0.4833615720272064, Lr:0.0001\n",
      "Epoch 2, Step: 226, Loss: 0.3714454770088196, Lr:0.0001\n",
      "Epoch 2, Step: 227, Loss: 0.45293816924095154, Lr:0.0001\n",
      "Epoch 2, Step: 228, Loss: 0.447559118270874, Lr:0.0001\n",
      "Epoch 2, Step: 229, Loss: 0.3418300151824951, Lr:0.0001\n",
      "Epoch 2, Step: 230, Loss: 0.3989121615886688, Lr:0.0001\n",
      "Epoch 2, Step: 231, Loss: 0.7735230922698975, Lr:0.0001\n",
      "Epoch 2, Step: 232, Loss: 0.31352704763412476, Lr:0.0001\n",
      "Epoch 2, Step: 233, Loss: 0.45927637815475464, Lr:0.0001\n",
      "Epoch 2, Step: 234, Loss: 0.39242473244667053, Lr:0.0001\n",
      "Epoch 2, Step: 235, Loss: 0.30292701721191406, Lr:0.0001\n",
      "Epoch 2, Step: 236, Loss: 0.3658248484134674, Lr:0.0001\n",
      "Epoch 2, Step: 237, Loss: 0.19417747855186462, Lr:0.0001\n",
      "Epoch 2, Step: 238, Loss: 0.42863890528678894, Lr:0.0001\n",
      "Epoch 2, Step: 239, Loss: 0.28967416286468506, Lr:0.0001\n",
      "Epoch 2, Step: 240, Loss: 0.40647196769714355, Lr:0.0001\n",
      "Epoch 2, Step: 241, Loss: 0.3120925724506378, Lr:0.0001\n",
      "Epoch 2, Step: 242, Loss: 0.4205763638019562, Lr:0.0001\n",
      "Epoch 2, Step: 243, Loss: 0.22237397730350494, Lr:0.0001\n",
      "Epoch 2, Step: 244, Loss: 0.20377255976200104, Lr:0.0001\n",
      "Epoch 2, Step: 245, Loss: 0.4280298948287964, Lr:0.0001\n",
      "Epoch 2, Step: 246, Loss: 0.2888840436935425, Lr:0.0001\n",
      "Epoch 2, Step: 247, Loss: 0.323127806186676, Lr:0.0001\n",
      "Epoch 2, Step: 248, Loss: 0.2244790941476822, Lr:0.0001\n",
      "Epoch 2, Step: 249, Loss: 0.3320038318634033, Lr:0.0001\n",
      "Epoch 2, Step: 250, Loss: 0.4827192723751068, Lr:0.0001\n",
      "Epoch 2, Step: 251, Loss: 0.40474361181259155, Lr:0.0001\n",
      "Epoch 2, Step: 252, Loss: 0.18958446383476257, Lr:0.0001\n",
      "Epoch 2, Step: 253, Loss: 0.35265660285949707, Lr:0.0001\n",
      "Epoch 2, Step: 254, Loss: 0.16688236594200134, Lr:0.0001\n",
      "Epoch 2, Step: 255, Loss: 0.6288455128669739, Lr:0.0001\n",
      "Epoch 2, Step: 256, Loss: 0.22070090472698212, Lr:0.0001\n",
      "Epoch 2, Step: 257, Loss: 0.33013516664505005, Lr:0.0001\n",
      "Epoch 2, Step: 258, Loss: 0.435272216796875, Lr:0.0001\n",
      "Epoch 2, Step: 259, Loss: 0.21287204325199127, Lr:0.0001\n",
      "Epoch 2, Step: 260, Loss: 0.42197710275650024, Lr:0.0001\n",
      "Epoch 2, Step: 261, Loss: 0.22848261892795563, Lr:0.0001\n",
      "Epoch 2, Step: 262, Loss: 0.343066930770874, Lr:0.0001\n",
      "Epoch 2, Step: 263, Loss: 0.28013354539871216, Lr:0.0001\n",
      "Epoch 2, Step: 264, Loss: 0.491973340511322, Lr:0.0001\n",
      "Epoch 2, Step: 265, Loss: 0.5156555771827698, Lr:0.0001\n",
      "Epoch 2, Step: 266, Loss: 0.29649803042411804, Lr:0.0001\n",
      "Epoch 2, Step: 267, Loss: 0.41780760884284973, Lr:0.0001\n",
      "Epoch 2, Step: 268, Loss: 0.4661436975002289, Lr:0.0001\n",
      "Epoch 2, Step: 269, Loss: 0.2619110941886902, Lr:0.0001\n",
      "Epoch 2, Step: 270, Loss: 0.38335201144218445, Lr:0.0001\n",
      "Epoch 2, Step: 271, Loss: 0.25033292174339294, Lr:0.0001\n",
      "Epoch 2, Step: 272, Loss: 0.21473655104637146, Lr:0.0001\n",
      "Epoch 2, Step: 273, Loss: 0.2338400036096573, Lr:0.0001\n",
      "Epoch 2, Step: 274, Loss: 0.35299116373062134, Lr:0.0001\n",
      "Epoch 2, Step: 275, Loss: 0.24901029467582703, Lr:0.0001\n",
      "Epoch 2, Step: 276, Loss: 0.18409845232963562, Lr:0.0001\n",
      "Epoch 2, Step: 277, Loss: 0.29999691247940063, Lr:0.0001\n",
      "Epoch 2, Step: 278, Loss: 0.29199281334877014, Lr:0.0001\n",
      "Epoch 2, Step: 279, Loss: 0.16264109313488007, Lr:0.0001\n",
      "Epoch 2, Step: 280, Loss: 0.49260804057121277, Lr:0.0001\n",
      "Epoch 2, Step: 281, Loss: 0.2829973101615906, Lr:0.0001\n",
      "Epoch 2, Step: 282, Loss: 0.5040397047996521, Lr:0.0001\n",
      "Epoch 2, Step: 283, Loss: 0.40228721499443054, Lr:0.0001\n",
      "Epoch 2, Step: 284, Loss: 0.20181505382061005, Lr:0.0001\n",
      "Epoch 2, Step: 285, Loss: 0.09643319994211197, Lr:0.0001\n",
      "Epoch 2, Step: 286, Loss: 0.2741132974624634, Lr:0.0001\n",
      "Epoch 2, Step: 287, Loss: 0.4283375144004822, Lr:0.0001\n",
      "Epoch 2, Step: 288, Loss: 0.18974103033542633, Lr:0.0001\n",
      "Epoch 2, Step: 289, Loss: 0.1320386528968811, Lr:0.0001\n",
      "Epoch 2, Step: 290, Loss: 0.37043941020965576, Lr:0.0001\n",
      "Epoch 2, Step: 291, Loss: 0.5168306827545166, Lr:0.0001\n",
      "Epoch 2, Step: 292, Loss: 0.2342451810836792, Lr:0.0001\n",
      "Epoch 2, Step: 293, Loss: 0.4006393551826477, Lr:0.0001\n",
      "Epoch 2, Step: 294, Loss: 1.0984594821929932, Lr:0.0001\n",
      "Epoch 2, Step: 295, Loss: 0.11109437793493271, Lr:0.0001\n",
      "Epoch 2, Step: 296, Loss: 0.2993806302547455, Lr:0.0001\n",
      "Epoch 2, Step: 297, Loss: 0.4848644435405731, Lr:0.0001\n",
      "Epoch 2, Step: 298, Loss: 0.3592994511127472, Lr:0.0001\n",
      "Epoch 2, Step: 299, Loss: 0.3145502209663391, Lr:0.0001\n",
      "Epoch 2, Step: 300, Loss: 0.7306994199752808, Lr:0.0001\n",
      "Epoch 2, Step: 301, Loss: 0.39746710658073425, Lr:0.0001\n",
      "Epoch 2, Step: 302, Loss: 0.3249904215335846, Lr:0.0001\n",
      "Epoch 2, Step: 303, Loss: 0.36887893080711365, Lr:0.0001\n",
      "Epoch 2, Step: 304, Loss: 0.35982954502105713, Lr:0.0001\n",
      "Epoch 2, Step: 305, Loss: 0.5617929697036743, Lr:0.0001\n",
      "Epoch 2, Step: 306, Loss: 0.28107303380966187, Lr:0.0001\n",
      "Epoch 2, Step: 307, Loss: 0.22719042003154755, Lr:0.0001\n",
      "Epoch 2, Step: 308, Loss: 0.18307393789291382, Lr:0.0001\n",
      "Epoch 2, Step: 309, Loss: 0.4991462528705597, Lr:0.0001\n",
      "Epoch 2, Step: 310, Loss: 0.5574461221694946, Lr:0.0001\n",
      "Epoch 2, Step: 311, Loss: 0.3420066237449646, Lr:0.0001\n",
      "Epoch 2, Step: 312, Loss: 0.3872995972633362, Lr:0.0001\n",
      "Epoch 2, Step: 313, Loss: 0.1649223119020462, Lr:0.0001\n",
      "Epoch 2, Step: 314, Loss: 0.2771252691745758, Lr:0.0001\n",
      "Epoch 2, Step: 315, Loss: 0.34637993574142456, Lr:0.0001\n",
      "Epoch 2, Step: 316, Loss: 0.5892487168312073, Lr:0.0001\n",
      "Epoch 2, Step: 317, Loss: 0.9021303653717041, Lr:0.0001\n",
      "Epoch 2, Step: 318, Loss: 0.3346255123615265, Lr:0.0001\n",
      "Epoch 2, Step: 319, Loss: 0.25656047463417053, Lr:0.0001\n",
      "Epoch 2, Step: 320, Loss: 0.3889991343021393, Lr:0.0001\n",
      "Epoch 2, Step: 321, Loss: 0.32622817158699036, Lr:0.0001\n",
      "Epoch 2, Step: 322, Loss: 0.5111361145973206, Lr:0.0001\n",
      "Epoch 2, Step: 323, Loss: 0.21769319474697113, Lr:0.0001\n",
      "Epoch 2, Step: 324, Loss: 0.14770936965942383, Lr:0.0001\n",
      "Epoch 2, Step: 325, Loss: 0.3142754137516022, Lr:0.0001\n",
      "Epoch 2, Step: 326, Loss: 0.2722835838794708, Lr:0.0001\n",
      "Epoch 2, Step: 327, Loss: 0.4604177176952362, Lr:0.0001\n",
      "Epoch 2, Step: 328, Loss: 0.2287668138742447, Lr:0.0001\n",
      "Epoch 2, Step: 329, Loss: 0.7405866980552673, Lr:0.0001\n",
      "Epoch 2, Step: 330, Loss: 0.38298696279525757, Lr:0.0001\n",
      "Epoch 2, Step: 331, Loss: 0.48512938618659973, Lr:0.0001\n",
      "Epoch 2, Step: 332, Loss: 0.3657017946243286, Lr:0.0001\n",
      "Epoch 2, Step: 333, Loss: 0.40623757243156433, Lr:0.0001\n",
      "Epoch 2, Step: 334, Loss: 0.32310256361961365, Lr:0.0001\n",
      "Epoch 2, Step: 335, Loss: 0.255075603723526, Lr:0.0001\n",
      "Epoch 2, Step: 336, Loss: 0.506455659866333, Lr:0.0001\n",
      "Epoch 2, Step: 337, Loss: 0.3738965690135956, Lr:0.0001\n",
      "Epoch 2, Step: 338, Loss: 0.337253212928772, Lr:0.0001\n",
      "Epoch 2, Step: 339, Loss: 0.41596102714538574, Lr:0.0001\n",
      "Epoch 2, Step: 340, Loss: 0.15201541781425476, Lr:0.0001\n",
      "Epoch 2, Step: 341, Loss: 0.22960343956947327, Lr:0.0001\n",
      "Epoch 2, Step: 342, Loss: 0.2262200564146042, Lr:0.0001\n",
      "Epoch 2, Step: 343, Loss: 0.3492337763309479, Lr:0.0001\n",
      "Epoch 2, Step: 344, Loss: 0.5389690399169922, Lr:0.0001\n",
      "Epoch 2, Step: 345, Loss: 0.418023943901062, Lr:0.0001\n",
      "Epoch 2, Step: 346, Loss: 0.9685181975364685, Lr:0.0001\n",
      "Epoch 2, Step: 347, Loss: 0.2693464457988739, Lr:0.0001\n",
      "Epoch 2, Step: 348, Loss: 0.19613398611545563, Lr:0.0001\n",
      "Epoch 2, Step: 349, Loss: 0.554937481880188, Lr:0.0001\n",
      "Epoch 2, Step: 350, Loss: 0.34913623332977295, Lr:0.0001\n",
      "Epoch 2, Step: 351, Loss: 0.12150339037179947, Lr:0.0001\n",
      "Epoch 2, Step: 352, Loss: 0.29626384377479553, Lr:0.0001\n",
      "Epoch 2, Step: 353, Loss: 0.393089234828949, Lr:0.0001\n",
      "Epoch 2, Step: 354, Loss: 0.24957723915576935, Lr:0.0001\n",
      "Epoch 2, Step: 355, Loss: 0.3176040053367615, Lr:0.0001\n",
      "Epoch 2, Step: 356, Loss: 0.45298779010772705, Lr:0.0001\n",
      "Epoch 2, Step: 357, Loss: 0.2858237624168396, Lr:0.0001\n",
      "Epoch 2, Step: 358, Loss: 0.42327386140823364, Lr:0.0001\n",
      "Epoch 2, Step: 359, Loss: 0.44930821657180786, Lr:0.0001\n",
      "Epoch 2, Step: 360, Loss: 0.7025517821311951, Lr:0.0001\n",
      "Epoch 2, Step: 361, Loss: 0.2142149955034256, Lr:0.0001\n",
      "Epoch 2, Step: 362, Loss: 0.6710635423660278, Lr:0.0001\n",
      "Epoch 2, Step: 363, Loss: 0.3175099194049835, Lr:0.0001\n",
      "Epoch 2, Step: 364, Loss: 0.3482315242290497, Lr:0.0001\n",
      "Epoch 2, Step: 365, Loss: 0.47942525148391724, Lr:0.0001\n",
      "Epoch 2, Step: 366, Loss: 0.25054317712783813, Lr:0.0001\n",
      "Epoch 2, Step: 367, Loss: 0.40888214111328125, Lr:0.0001\n",
      "Epoch 2, Step: 368, Loss: 0.29848966002464294, Lr:0.0001\n",
      "Epoch 2, Step: 369, Loss: 0.29564976692199707, Lr:0.0001\n",
      "Epoch 2, Step: 370, Loss: 0.1527690440416336, Lr:0.0001\n",
      "Epoch 2, Step: 371, Loss: 0.48310714960098267, Lr:0.0001\n",
      "Epoch 2, Step: 372, Loss: 0.4739348888397217, Lr:0.0001\n",
      "Epoch 2, Step: 373, Loss: 0.13410043716430664, Lr:0.0001\n",
      "Epoch 2, Step: 374, Loss: 0.36250045895576477, Lr:0.0001\n",
      "Epoch 2, Step: 375, Loss: 0.19893717765808105, Lr:0.0001\n",
      "Epoch 2, Step: 376, Loss: 0.19412529468536377, Lr:0.0001\n",
      "Epoch 2, Step: 377, Loss: 0.3304675817489624, Lr:0.0001\n",
      "Epoch 2, Step: 378, Loss: 0.18136365711688995, Lr:0.0001\n",
      "Epoch 2, Step: 379, Loss: 0.35756915807724, Lr:0.0001\n",
      "Epoch 2, Step: 380, Loss: 0.338369220495224, Lr:0.0001\n",
      "Epoch 2, Step: 381, Loss: 0.5388631224632263, Lr:0.0001\n",
      "Epoch 2, Step: 382, Loss: 0.23663832247257233, Lr:0.0001\n",
      "Epoch 2, Step: 383, Loss: 0.25890234112739563, Lr:0.0001\n",
      "Epoch 2, Step: 384, Loss: 0.26860785484313965, Lr:0.0001\n",
      "Epoch 2, Step: 385, Loss: 0.48367345333099365, Lr:0.0001\n",
      "Epoch 2, Step: 386, Loss: 0.12323949486017227, Lr:0.0001\n",
      "Epoch 2, Step: 387, Loss: 0.3209809958934784, Lr:0.0001\n",
      "Epoch 2, Step: 388, Loss: 0.7562872767448425, Lr:0.0001\n",
      "Epoch 2, Step: 389, Loss: 0.28436702489852905, Lr:0.0001\n",
      "Epoch 2, Step: 390, Loss: 0.4970567226409912, Lr:0.0001\n",
      "Epoch 2, Step: 391, Loss: 0.4922886788845062, Lr:0.0001\n",
      "Epoch 2, Step: 392, Loss: 0.13719606399536133, Lr:0.0001\n",
      "Epoch 2, Step: 393, Loss: 0.45594286918640137, Lr:0.0001\n",
      "Epoch 2, Step: 394, Loss: 0.2164979875087738, Lr:0.0001\n",
      "Epoch 2, Step: 395, Loss: 0.4649074375629425, Lr:0.0001\n",
      "Epoch 2, Step: 396, Loss: 0.13003243505954742, Lr:0.0001\n",
      "Epoch 2, Step: 397, Loss: 0.45738691091537476, Lr:0.0001\n",
      "Epoch 2, Step: 398, Loss: 0.43208837509155273, Lr:0.0001\n",
      "Epoch 2, Step: 399, Loss: 0.5684012770652771, Lr:0.0001\n",
      "Epoch 2, Step: 400, Loss: 0.24953415989875793, Lr:0.0001\n",
      "Epoch 2, Step: 401, Loss: 0.5891255736351013, Lr:0.0001\n",
      "Epoch 2, Step: 402, Loss: 0.2789972424507141, Lr:0.0001\n",
      "Epoch 2, Step: 403, Loss: 0.5496801137924194, Lr:0.0001\n",
      "Epoch 2, Step: 404, Loss: 0.13679152727127075, Lr:0.0001\n",
      "Epoch 2, Step: 405, Loss: 0.28773781657218933, Lr:0.0001\n",
      "Epoch 2, Step: 406, Loss: 0.5851014852523804, Lr:0.0001\n",
      "Epoch 2, Step: 407, Loss: 0.1315842717885971, Lr:0.0001\n",
      "Epoch 2, Step: 408, Loss: 0.2655046284198761, Lr:0.0001\n",
      "Epoch 2, Step: 409, Loss: 0.17151539027690887, Lr:0.0001\n",
      "Epoch 2, Step: 410, Loss: 0.31965452432632446, Lr:0.0001\n",
      "Epoch 2, Step: 411, Loss: 0.37754079699516296, Lr:0.0001\n",
      "Epoch 2, Step: 412, Loss: 0.3781706988811493, Lr:0.0001\n",
      "Epoch 2, Step: 413, Loss: 0.28040939569473267, Lr:0.0001\n",
      "Epoch 2, Step: 414, Loss: 0.1954217404127121, Lr:0.0001\n",
      "Epoch 2, Step: 415, Loss: 0.748592734336853, Lr:0.0001\n",
      "Epoch 2, Step: 416, Loss: 0.3655804991722107, Lr:0.0001\n",
      "Epoch 2, Step: 417, Loss: 0.4372309744358063, Lr:0.0001\n",
      "Epoch 2, Step: 418, Loss: 0.4900517761707306, Lr:0.0001\n",
      "Epoch 2, Step: 419, Loss: 0.48569387197494507, Lr:0.0001\n",
      "Epoch 2, Step: 420, Loss: 0.28953817486763, Lr:0.0001\n",
      "Epoch 2, Step: 421, Loss: 0.3916310966014862, Lr:0.0001\n",
      "Epoch 2, Step: 422, Loss: 0.3914851248264313, Lr:0.0001\n",
      "Epoch 2, Step: 423, Loss: 0.16178587079048157, Lr:0.0001\n",
      "Epoch 2, Step: 424, Loss: 0.410435289144516, Lr:0.0001\n",
      "Epoch 2, Step: 425, Loss: 0.33806079626083374, Lr:0.0001\n",
      "Epoch 2, Step: 426, Loss: 0.3480653464794159, Lr:0.0001\n",
      "Epoch 2, Step: 427, Loss: 0.31973302364349365, Lr:0.0001\n",
      "Epoch 2, Step: 428, Loss: 0.2916679382324219, Lr:0.0001\n",
      "Epoch 2, Step: 429, Loss: 0.39432939887046814, Lr:0.0001\n",
      "Epoch 2, Step: 430, Loss: 0.19617491960525513, Lr:0.0001\n",
      "Epoch 2, Step: 431, Loss: 0.2883690595626831, Lr:0.0001\n",
      "Epoch 2, Step: 432, Loss: 0.31956011056900024, Lr:0.0001\n",
      "Epoch 2, Step: 433, Loss: 0.22403746843338013, Lr:0.0001\n",
      "Epoch 2, Step: 434, Loss: 0.4048856496810913, Lr:0.0001\n",
      "Epoch 2, Step: 435, Loss: 0.29921436309814453, Lr:0.0001\n",
      "Epoch 2, Step: 436, Loss: 0.11577847599983215, Lr:0.0001\n",
      "Epoch 2, Step: 437, Loss: 0.2217121720314026, Lr:0.0001\n",
      "Epoch 2, Step: 438, Loss: 0.224981427192688, Lr:0.0001\n",
      "Epoch 2, Step: 439, Loss: 0.1318691372871399, Lr:0.0001\n",
      "Epoch 2, Step: 440, Loss: 0.4645484983921051, Lr:0.0001\n",
      "Epoch 2, Step: 441, Loss: 0.41886937618255615, Lr:0.0001\n",
      "Epoch 2, Step: 442, Loss: 0.3453780710697174, Lr:0.0001\n",
      "Epoch 2, Step: 443, Loss: 0.9677208662033081, Lr:0.0001\n",
      "Epoch 2, Step: 444, Loss: 0.4554709792137146, Lr:0.0001\n",
      "Epoch 2, Step: 445, Loss: 0.2893792688846588, Lr:0.0001\n",
      "Epoch 2, Step: 446, Loss: 0.2297823280096054, Lr:0.0001\n",
      "Epoch 2, Step: 447, Loss: 0.16465866565704346, Lr:0.0001\n",
      "Epoch 2, Step: 448, Loss: 0.2244574874639511, Lr:0.0001\n",
      "Epoch 2, Step: 449, Loss: 0.2881297767162323, Lr:0.0001\n",
      "Epoch 2, Step: 450, Loss: 0.3466321527957916, Lr:0.0001\n",
      "Epoch 2, Step: 451, Loss: 0.30128124356269836, Lr:0.0001\n",
      "Epoch 2, Step: 452, Loss: 0.568531334400177, Lr:0.0001\n",
      "Epoch 2, Step: 453, Loss: 0.24028362333774567, Lr:0.0001\n",
      "Epoch 2, Step: 454, Loss: 0.604550302028656, Lr:0.0001\n",
      "Epoch 2, Step: 455, Loss: 0.2808413505554199, Lr:0.0001\n",
      "Epoch 2, Step: 456, Loss: 0.7481206655502319, Lr:0.0001\n",
      "Epoch 2, Step: 457, Loss: 0.4026038646697998, Lr:0.0001\n",
      "Epoch 2, Step: 458, Loss: 0.379845529794693, Lr:0.0001\n",
      "Epoch 2, Step: 459, Loss: 0.4238757789134979, Lr:0.0001\n",
      "Epoch 2, Step: 460, Loss: 0.24493388831615448, Lr:0.0001\n",
      "Epoch 2, Step: 461, Loss: 0.21089138090610504, Lr:0.0001\n",
      "Epoch 2, Step: 462, Loss: 0.25327068567276, Lr:0.0001\n",
      "Epoch 2, Step: 463, Loss: 0.37416836619377136, Lr:0.0001\n",
      "Epoch 2, Step: 464, Loss: 0.3126194179058075, Lr:0.0001\n",
      "Epoch 2, Step: 465, Loss: 0.4887005686759949, Lr:0.0001\n",
      "Epoch 2, Step: 466, Loss: 0.36079391837120056, Lr:0.0001\n",
      "Epoch 2, Step: 467, Loss: 0.511187732219696, Lr:0.0001\n",
      "Epoch 2, Step: 468, Loss: 0.156995490193367, Lr:0.0001\n",
      "Epoch 2, Step: 469, Loss: 0.19536305963993073, Lr:0.0001\n",
      "Epoch 2, Step: 470, Loss: 0.1645333468914032, Lr:0.0001\n",
      "Epoch 2, Step: 471, Loss: 0.0466286800801754, Lr:0.0001\n",
      "Epoch 2, Step: 472, Loss: 0.07029814273118973, Lr:0.0001\n",
      "Epoch 2, Step: 473, Loss: 0.2084006667137146, Lr:0.0001\n",
      "Epoch 2, Step: 474, Loss: 0.5474530458450317, Lr:0.0001\n",
      "Epoch 2, Step: 475, Loss: 0.7421104311943054, Lr:0.0001\n",
      "Epoch 2, Step: 476, Loss: 0.22528915107250214, Lr:0.0001\n",
      "Epoch 2, Step: 477, Loss: 0.8163574934005737, Lr:0.0001\n",
      "Epoch 2, Step: 478, Loss: 0.5733909606933594, Lr:0.0001\n",
      "Epoch 2, Step: 479, Loss: 0.33270058035850525, Lr:0.0001\n",
      "Epoch 2, Step: 480, Loss: 0.2686649262905121, Lr:0.0001\n",
      "Epoch 2, Step: 481, Loss: 0.6304643154144287, Lr:0.0001\n",
      "Epoch 2, Step: 482, Loss: 0.29873335361480713, Lr:0.0001\n",
      "Epoch 2, Step: 483, Loss: 0.23392832279205322, Lr:0.0001\n",
      "Epoch 2, Step: 484, Loss: 0.37446266412734985, Lr:0.0001\n",
      "Epoch 2, Step: 485, Loss: 0.2128315269947052, Lr:0.0001\n",
      "Epoch 2, Step: 486, Loss: 0.2903366982936859, Lr:0.0001\n",
      "Epoch 2, Step: 487, Loss: 0.4747803211212158, Lr:0.0001\n",
      "Epoch 2, Step: 488, Loss: 0.3453716039657593, Lr:0.0001\n",
      "Epoch 2, Step: 489, Loss: 0.5200752019882202, Lr:0.0001\n",
      "Epoch 2, Step: 490, Loss: 0.19544407725334167, Lr:0.0001\n",
      "Epoch 2, Step: 491, Loss: 0.49872469902038574, Lr:0.0001\n",
      "Epoch 2, Step: 492, Loss: 0.5173436999320984, Lr:0.0001\n",
      "Epoch 2, Step: 493, Loss: 0.43848666548728943, Lr:0.0001\n",
      "Epoch 2, Step: 494, Loss: 0.22943821549415588, Lr:0.0001\n",
      "Epoch 2, Step: 495, Loss: 0.10137169063091278, Lr:0.0001\n",
      "Epoch 2, Step: 496, Loss: 0.3089568018913269, Lr:0.0001\n",
      "Epoch 2, Step: 497, Loss: 0.48124581575393677, Lr:0.0001\n",
      "Epoch 2, Step: 498, Loss: 0.3566261827945709, Lr:0.0001\n",
      "Epoch 2, Step: 499, Loss: 0.49563068151474, Lr:0.0001\n",
      "Epoch 2, Step: 500, Loss: 0.7408005595207214, Lr:0.0001\n",
      "Epoch 2, Step: 501, Loss: 0.28989431262016296, Lr:0.0001\n",
      "Epoch 2, Step: 502, Loss: 0.21400600671768188, Lr:0.0001\n",
      "Epoch 2, Step: 503, Loss: 0.2149377316236496, Lr:0.0001\n",
      "Epoch 2, Step: 504, Loss: 0.35540708899497986, Lr:0.0001\n",
      "Epoch 2, Step: 505, Loss: 0.20357529819011688, Lr:0.0001\n",
      "Epoch 2, Step: 506, Loss: 0.3923172056674957, Lr:0.0001\n",
      "Epoch 2, Step: 507, Loss: 0.3969647288322449, Lr:0.0001\n",
      "Epoch 2, Step: 508, Loss: 0.4405827820301056, Lr:0.0001\n",
      "Epoch 2, Step: 509, Loss: 0.2874237298965454, Lr:0.0001\n",
      "Epoch 2, Step: 510, Loss: 0.4420086741447449, Lr:0.0001\n",
      "Epoch 2, Step: 511, Loss: 0.3119891285896301, Lr:0.0001\n",
      "Epoch 2, Step: 512, Loss: 1.6672379970550537, Lr:0.0001\n",
      "Epoch 2, Step: 513, Loss: 0.258390337228775, Lr:0.0001\n",
      "Epoch 2, Step: 514, Loss: 0.5448858141899109, Lr:0.0001\n",
      "Epoch 2, Step: 515, Loss: 0.7875575423240662, Lr:0.0001\n",
      "Epoch 2, Step: 516, Loss: 0.3167685568332672, Lr:0.0001\n",
      "Epoch 2, Step: 517, Loss: 0.2247404009103775, Lr:0.0001\n",
      "Epoch 2, Step: 518, Loss: 0.386069118976593, Lr:0.0001\n",
      "Epoch 2, Step: 519, Loss: 0.29837721586227417, Lr:0.0001\n",
      "Epoch 2, Step: 520, Loss: 0.34903520345687866, Lr:0.0001\n",
      "Epoch 2, Step: 521, Loss: 0.4219636023044586, Lr:0.0001\n",
      "Epoch 2, Step: 522, Loss: 0.35438215732574463, Lr:0.0001\n",
      "Epoch 2, Step: 523, Loss: 0.2818961441516876, Lr:0.0001\n",
      "Epoch 2, Step: 524, Loss: 0.4856218695640564, Lr:0.0001\n",
      "Epoch 2, Step: 525, Loss: 0.34212300181388855, Lr:0.0001\n",
      "Epoch 2, Step: 526, Loss: 0.611119270324707, Lr:0.0001\n",
      "Epoch 2, Step: 527, Loss: 0.41570332646369934, Lr:0.0001\n",
      "Epoch 2, Step: 528, Loss: 0.40423843264579773, Lr:0.0001\n",
      "Epoch 2, Step: 529, Loss: 0.21631620824337006, Lr:0.0001\n",
      "Epoch 2, Step: 530, Loss: 0.2010008990764618, Lr:0.0001\n",
      "Epoch 2, Step: 531, Loss: 0.3755514323711395, Lr:0.0001\n",
      "Epoch 2, Step: 532, Loss: 0.34553688764572144, Lr:0.0001\n",
      "Epoch 2, Step: 533, Loss: 0.8057495355606079, Lr:0.0001\n",
      "Epoch 2, Step: 534, Loss: 0.3232850134372711, Lr:0.0001\n",
      "Epoch 2, Step: 535, Loss: 0.44195786118507385, Lr:0.0001\n",
      "Epoch 2, Step: 536, Loss: 0.32143938541412354, Lr:0.0001\n",
      "Epoch 2, Step: 537, Loss: 0.2033282369375229, Lr:0.0001\n",
      "Epoch 2, Step: 538, Loss: 0.5129592418670654, Lr:0.0001\n",
      "Epoch 2, Step: 539, Loss: 0.5523729920387268, Lr:0.0001\n",
      "Epoch 2, Step: 540, Loss: 0.23590780794620514, Lr:0.0001\n",
      "Epoch 2, Step: 541, Loss: 0.3151410222053528, Lr:0.0001\n",
      "Epoch 2, Step: 542, Loss: 0.25443321466445923, Lr:0.0001\n",
      "Epoch 2, Step: 543, Loss: 0.34997063875198364, Lr:0.0001\n",
      "Epoch 2, Step: 544, Loss: 0.36048623919487, Lr:0.0001\n",
      "Epoch 2, Step: 545, Loss: 0.6097628474235535, Lr:0.0001\n",
      "Epoch 2, Step: 546, Loss: 0.5006531476974487, Lr:0.0001\n",
      "Epoch 2, Step: 547, Loss: 0.5879994034767151, Lr:0.0001\n",
      "Epoch 2, Step: 548, Loss: 0.14316602051258087, Lr:0.0001\n",
      "Epoch 2, Step: 549, Loss: 0.3121618628501892, Lr:0.0001\n",
      "Epoch 2, Step: 550, Loss: 0.24985668063163757, Lr:0.0001\n",
      "Epoch 2, Step: 551, Loss: 0.23010319471359253, Lr:0.0001\n",
      "Epoch 2, Step: 552, Loss: 0.5323278903961182, Lr:0.0001\n",
      "Epoch 2, Step: 553, Loss: 0.2578244209289551, Lr:0.0001\n",
      "Epoch 2, Step: 554, Loss: 0.2228642702102661, Lr:0.0001\n",
      "Epoch 2, Step: 555, Loss: 0.3585946559906006, Lr:0.0001\n",
      "Epoch 2, Step: 556, Loss: 0.1562705934047699, Lr:0.0001\n",
      "Epoch 2, Step: 557, Loss: 0.41076698899269104, Lr:0.0001\n",
      "Epoch 2, Step: 558, Loss: 0.2867015302181244, Lr:0.0001\n",
      "Epoch 2, Step: 559, Loss: 0.2165510207414627, Lr:0.0001\n",
      "Epoch 2, Step: 560, Loss: 0.47495925426483154, Lr:0.0001\n",
      "Epoch 2, Step: 561, Loss: 0.15268653631210327, Lr:0.0001\n",
      "Epoch 2, Step: 562, Loss: 0.2616841495037079, Lr:0.0001\n",
      "Epoch 2, Step: 563, Loss: 0.3717738687992096, Lr:0.0001\n",
      "Epoch 2, Step: 564, Loss: 0.5424715876579285, Lr:0.0001\n",
      "Epoch 2, Step: 565, Loss: 0.38630345463752747, Lr:0.0001\n",
      "Epoch 2, Step: 566, Loss: 0.40463531017303467, Lr:0.0001\n",
      "Epoch 2, Step: 567, Loss: 0.5595299601554871, Lr:0.0001\n",
      "Epoch 2, Step: 568, Loss: 0.36591440439224243, Lr:0.0001\n",
      "Epoch 2, Step: 569, Loss: 0.48992881178855896, Lr:0.0001\n",
      "Epoch 2, Step: 570, Loss: 0.140667125582695, Lr:0.0001\n",
      "Epoch 2, Step: 571, Loss: 0.31762024760246277, Lr:0.0001\n",
      "Epoch 2, Step: 572, Loss: 0.9941175580024719, Lr:0.0001\n",
      "Epoch 2, Step: 573, Loss: 0.3564031720161438, Lr:0.0001\n",
      "Epoch 2, Step: 574, Loss: 0.322919636964798, Lr:0.0001\n",
      "Epoch 2, Step: 575, Loss: 0.3580338954925537, Lr:0.0001\n",
      "Epoch 2, Step: 576, Loss: 0.8391964435577393, Lr:0.0001\n",
      "Epoch 2, Step: 577, Loss: 0.11409997940063477, Lr:0.0001\n",
      "Epoch 2, Step: 578, Loss: 0.05207028612494469, Lr:0.0001\n",
      "Epoch 2, Step: 579, Loss: 0.1577141135931015, Lr:0.0001\n",
      "Epoch 2, Step: 580, Loss: 0.2810083329677582, Lr:0.0001\n",
      "Epoch 2, Step: 581, Loss: 0.31802549958229065, Lr:0.0001\n",
      "Epoch 2, Step: 582, Loss: 0.5988006591796875, Lr:0.0001\n",
      "Epoch 2, Step: 583, Loss: 0.18104660511016846, Lr:0.0001\n",
      "Epoch 2, Step: 584, Loss: 0.26806944608688354, Lr:0.0001\n",
      "Epoch 2, Step: 585, Loss: 0.5274737477302551, Lr:0.0001\n",
      "Epoch 2, Step: 586, Loss: 0.25221744179725647, Lr:0.0001\n",
      "Epoch 2, Step: 587, Loss: 0.2184503823518753, Lr:0.0001\n",
      "Epoch 2, Step: 588, Loss: 0.24677015841007233, Lr:0.0001\n",
      "Epoch 2, Step: 589, Loss: 0.40560317039489746, Lr:0.0001\n",
      "Epoch 2, Step: 590, Loss: 0.40972450375556946, Lr:0.0001\n",
      "Epoch 2, Step: 591, Loss: 0.5753439664840698, Lr:0.0001\n",
      "Epoch 2, Step: 592, Loss: 0.2130236178636551, Lr:0.0001\n",
      "Epoch 2, Step: 593, Loss: 0.17193542420864105, Lr:0.0001\n",
      "Epoch 2, Step: 594, Loss: 0.16585278511047363, Lr:0.0001\n",
      "Epoch 2, Step: 595, Loss: 0.6212359666824341, Lr:0.0001\n",
      "Epoch 2, Step: 596, Loss: 0.37823766469955444, Lr:0.0001\n",
      "Epoch 2, Step: 597, Loss: 0.0952640101313591, Lr:0.0001\n",
      "Epoch 2, Step: 598, Loss: 0.1894279569387436, Lr:0.0001\n",
      "Epoch 2, Step: 599, Loss: 0.0949445441365242, Lr:0.0001\n",
      "Epoch 2, Step: 600, Loss: 0.38544565439224243, Lr:0.0001\n",
      "Epoch 2, Step: 601, Loss: 0.4965416491031647, Lr:0.0001\n",
      "Epoch 2, Step: 602, Loss: 0.44421109557151794, Lr:0.0001\n",
      "Epoch 2, Step: 603, Loss: 0.3639802634716034, Lr:0.0001\n",
      "Epoch 2, Step: 604, Loss: 0.24553042650222778, Lr:0.0001\n",
      "Epoch 2, Step: 605, Loss: 0.8121477365493774, Lr:0.0001\n",
      "Epoch 2, Step: 606, Loss: 0.30303481221199036, Lr:0.0001\n",
      "Epoch 2, Step: 607, Loss: 0.2741929888725281, Lr:0.0001\n",
      "Epoch 2, Step: 608, Loss: 0.27143561840057373, Lr:0.0001\n",
      "Epoch 2, Step: 609, Loss: 0.41702786087989807, Lr:0.0001\n",
      "Epoch 2, Step: 610, Loss: 0.38343510031700134, Lr:0.0001\n",
      "Epoch 2, Step: 611, Loss: 0.4211729168891907, Lr:0.0001\n",
      "Epoch 2, Step: 612, Loss: 0.22173485159873962, Lr:0.0001\n",
      "Epoch 2, Step: 613, Loss: 0.4036514461040497, Lr:0.0001\n",
      "Epoch 2, Step: 614, Loss: 0.2713136076927185, Lr:0.0001\n",
      "Epoch 2, Step: 615, Loss: 0.3075324296951294, Lr:0.0001\n",
      "Epoch 2, Step: 616, Loss: 0.21488121151924133, Lr:0.0001\n",
      "Epoch 2, Step: 617, Loss: 0.5231082439422607, Lr:0.0001\n",
      "Epoch 2, Step: 618, Loss: 0.14461903274059296, Lr:0.0001\n",
      "Epoch 2, Step: 619, Loss: 0.19708049297332764, Lr:0.0001\n",
      "Epoch 2, Step: 620, Loss: 0.3371654152870178, Lr:0.0001\n",
      "Epoch 2, Step: 621, Loss: 0.1956205517053604, Lr:0.0001\n",
      "Epoch 2, Step: 622, Loss: 0.6692075133323669, Lr:0.0001\n",
      "Epoch 2, Step: 623, Loss: 0.36165139079093933, Lr:0.0001\n",
      "Epoch 2, Step: 624, Loss: 0.3216838836669922, Lr:0.0001\n",
      "Epoch 2, Step: 625, Loss: 0.4162853956222534, Lr:0.0001\n",
      "Epoch 2, Step: 626, Loss: 0.14369003474712372, Lr:0.0001\n",
      "Epoch 2, Step: 627, Loss: 0.2443506270647049, Lr:0.0001\n",
      "Epoch 2, Step: 628, Loss: 0.13891491293907166, Lr:0.0001\n",
      "Epoch 2, Step: 629, Loss: 0.2063508927822113, Lr:0.0001\n",
      "Epoch 2, Step: 630, Loss: 0.3605678677558899, Lr:0.0001\n",
      "Epoch 2, Step: 631, Loss: 0.3168756067752838, Lr:0.0001\n",
      "Epoch 2, Step: 632, Loss: 0.21971270442008972, Lr:0.0001\n",
      "Epoch 2, Step: 633, Loss: 0.3658325672149658, Lr:0.0001\n",
      "Epoch 2, Step: 634, Loss: 0.3971395492553711, Lr:0.0001\n",
      "Epoch 2, Step: 635, Loss: 0.2617751359939575, Lr:0.0001\n",
      "Epoch 2, Step: 636, Loss: 0.12265872210264206, Lr:0.0001\n",
      "Epoch 2, Step: 637, Loss: 0.1436588168144226, Lr:0.0001\n",
      "Epoch 2, Step: 638, Loss: 0.3533117175102234, Lr:0.0001\n",
      "Epoch 2, Step: 639, Loss: 0.4959567189216614, Lr:0.0001\n",
      "Epoch 2, Step: 640, Loss: 0.23619689047336578, Lr:0.0001\n",
      "Epoch 2, Step: 641, Loss: 0.13431672751903534, Lr:0.0001\n",
      "Epoch 2, Step: 642, Loss: 0.5765267014503479, Lr:0.0001\n",
      "Epoch 2, Step: 643, Loss: 0.23736652731895447, Lr:0.0001\n",
      "Epoch 2, Step: 644, Loss: 0.3534924387931824, Lr:0.0001\n",
      "Epoch 2, Step: 645, Loss: 0.3735477030277252, Lr:0.0001\n",
      "Epoch 2, Step: 646, Loss: 0.14543792605400085, Lr:0.0001\n",
      "Epoch 2, Step: 647, Loss: 0.1022733822464943, Lr:0.0001\n",
      "Epoch 2, Step: 648, Loss: 0.2107907235622406, Lr:0.0001\n",
      "Epoch 2, Step: 649, Loss: 0.43618956208229065, Lr:0.0001\n",
      "Epoch 2, Step: 650, Loss: 0.5750184059143066, Lr:0.0001\n",
      "Epoch 2, Step: 651, Loss: 0.3011276125907898, Lr:0.0001\n",
      "Epoch 2, Step: 652, Loss: 0.3440495431423187, Lr:0.0001\n",
      "Epoch 2, Step: 653, Loss: 0.20442010462284088, Lr:0.0001\n",
      "Epoch 2, Step: 654, Loss: 0.5369349122047424, Lr:0.0001\n",
      "Epoch 2, Step: 655, Loss: 0.27464985847473145, Lr:0.0001\n",
      "Epoch 2, Step: 656, Loss: 0.5198000073432922, Lr:0.0001\n",
      "Epoch 2, Step: 657, Loss: 0.15541915595531464, Lr:0.0001\n",
      "Epoch 2, Step: 658, Loss: 0.4953325688838959, Lr:0.0001\n",
      "Epoch 2, Step: 659, Loss: 0.3487337827682495, Lr:0.0001\n",
      "Epoch 2, Step: 660, Loss: 0.4229000508785248, Lr:0.0001\n",
      "Epoch 2, Step: 661, Loss: 0.3734724521636963, Lr:0.0001\n",
      "Epoch 2, Step: 662, Loss: 0.3302763104438782, Lr:0.0001\n",
      "Epoch 2, Step: 663, Loss: 0.41581010818481445, Lr:0.0001\n",
      "Epoch 2, Step: 664, Loss: 0.2241450548171997, Lr:0.0001\n",
      "Epoch 2, Step: 665, Loss: 0.2916138470172882, Lr:0.0001\n",
      "Epoch 2, Step: 666, Loss: 0.10643480718135834, Lr:0.0001\n",
      "Epoch 2, Step: 667, Loss: 0.17766794562339783, Lr:0.0001\n",
      "Epoch 2, Step: 668, Loss: 0.5725584030151367, Lr:0.0001\n",
      "Epoch 2, Step: 669, Loss: 0.35128217935562134, Lr:0.0001\n",
      "Epoch 2, Step: 670, Loss: 0.16655267775058746, Lr:0.0001\n",
      "Epoch 2, Step: 671, Loss: 0.26008960604667664, Lr:0.0001\n",
      "Epoch 2, Step: 672, Loss: 0.3845255672931671, Lr:0.0001\n",
      "Epoch 2, Step: 673, Loss: 0.3519163131713867, Lr:0.0001\n",
      "Epoch 2, Step: 674, Loss: 0.4365138113498688, Lr:0.0001\n",
      "Epoch 2, Step: 675, Loss: 0.32640478014945984, Lr:0.0001\n",
      "Epoch 2, Step: 676, Loss: 0.3334849774837494, Lr:0.0001\n",
      "Epoch 2, Step: 677, Loss: 0.15818874537944794, Lr:0.0001\n",
      "Epoch 2, Step: 678, Loss: 0.6460040211677551, Lr:0.0001\n",
      "Epoch 2, Step: 679, Loss: 0.32109591364860535, Lr:0.0001\n",
      "Epoch 2, Step: 680, Loss: 0.32206860184669495, Lr:0.0001\n",
      "Epoch 2, Step: 681, Loss: 0.2714591324329376, Lr:0.0001\n",
      "Epoch 2, Step: 682, Loss: 0.19041088223457336, Lr:0.0001\n",
      "Epoch 2, Step: 683, Loss: 0.33241358399391174, Lr:0.0001\n",
      "Epoch 2, Step: 684, Loss: 0.27263569831848145, Lr:0.0001\n",
      "Epoch 2, Step: 685, Loss: 0.6170027852058411, Lr:0.0001\n",
      "Epoch 2, Step: 686, Loss: 0.3105922341346741, Lr:0.0001\n",
      "Epoch 2, Step: 687, Loss: 0.14795763790607452, Lr:0.0001\n",
      "Epoch 2, Step: 688, Loss: 0.349595308303833, Lr:0.0001\n",
      "Epoch 2, Step: 689, Loss: 0.2357364147901535, Lr:0.0001\n",
      "Epoch 2, Step: 690, Loss: 0.10807008296251297, Lr:0.0001\n",
      "Epoch 2, Step: 691, Loss: 0.6036360263824463, Lr:0.0001\n",
      "Epoch 2, Step: 692, Loss: 0.24487219750881195, Lr:0.0001\n",
      "Epoch 2, Step: 693, Loss: 0.23209260404109955, Lr:0.0001\n",
      "Epoch 2, Step: 694, Loss: 0.3538077473640442, Lr:0.0001\n",
      "Epoch 2, Step: 695, Loss: 0.674308717250824, Lr:0.0001\n",
      "Epoch 2, Step: 696, Loss: 0.30669528245925903, Lr:0.0001\n",
      "Epoch 2, Step: 697, Loss: 0.15016821026802063, Lr:0.0001\n",
      "Epoch 2, Step: 698, Loss: 0.1188911572098732, Lr:0.0001\n",
      "Epoch 2, Step: 699, Loss: 0.10696469992399216, Lr:0.0001\n",
      "Epoch 2, Step: 700, Loss: 0.4613429307937622, Lr:0.0001\n",
      "Epoch 2, Step: 701, Loss: 0.4157542586326599, Lr:0.0001\n",
      "Epoch 2, Step: 702, Loss: 0.6561649441719055, Lr:0.0001\n",
      "Epoch 2, Step: 703, Loss: 0.2392907440662384, Lr:0.0001\n",
      "Epoch 2, Step: 704, Loss: 0.5012502074241638, Lr:0.0001\n",
      "Epoch 2, Step: 705, Loss: 0.21768918633460999, Lr:0.0001\n",
      "Epoch 2, Step: 706, Loss: 0.816311240196228, Lr:0.0001\n",
      "Epoch 2, Step: 707, Loss: 0.4350234568119049, Lr:0.0001\n",
      "Epoch 2, Step: 708, Loss: 0.39574944972991943, Lr:0.0001\n",
      "Epoch 2, Step: 709, Loss: 0.24942827224731445, Lr:0.0001\n",
      "Epoch 2, Step: 710, Loss: 0.1979619562625885, Lr:0.0001\n",
      "Epoch 2, Step: 711, Loss: 0.31152966618537903, Lr:0.0001\n",
      "Epoch 2, Step: 712, Loss: 0.4261517822742462, Lr:0.0001\n",
      "Epoch 2, Step: 713, Loss: 0.22393202781677246, Lr:0.0001\n",
      "Epoch 2, Step: 714, Loss: 0.40797701478004456, Lr:0.0001\n",
      "Epoch 2, Step: 715, Loss: 0.392578125, Lr:0.0001\n",
      "Epoch 2, Step: 716, Loss: 0.10222294181585312, Lr:0.0001\n",
      "Epoch 2, Step: 717, Loss: 0.13635464012622833, Lr:0.0001\n",
      "Epoch 2, Step: 718, Loss: 0.05992447957396507, Lr:0.0001\n",
      "Epoch 2, Step: 719, Loss: 0.8482459187507629, Lr:0.0001\n",
      "Epoch 2, Step: 720, Loss: 0.19606004655361176, Lr:0.0001\n",
      "Epoch 2, Step: 721, Loss: 0.10429618507623672, Lr:0.0001\n",
      "Epoch 2, Step: 722, Loss: 0.15404993295669556, Lr:0.0001\n",
      "Epoch 2, Step: 723, Loss: 0.46053874492645264, Lr:0.0001\n",
      "Epoch 2, Step: 724, Loss: 0.18912237882614136, Lr:0.0001\n",
      "Epoch 2, Step: 725, Loss: 0.2998717427253723, Lr:0.0001\n",
      "Epoch 2, Step: 726, Loss: 0.28669214248657227, Lr:0.0001\n",
      "Epoch 2, Step: 727, Loss: 0.47316378355026245, Lr:0.0001\n",
      "Epoch 2, Step: 728, Loss: 0.44307154417037964, Lr:0.0001\n",
      "Epoch 2, Step: 729, Loss: 0.2079080492258072, Lr:0.0001\n",
      "Epoch 2, Step: 730, Loss: 0.10922864824533463, Lr:0.0001\n",
      "Epoch 2, Step: 731, Loss: 0.38978034257888794, Lr:0.0001\n",
      "Epoch 2, Step: 732, Loss: 0.16943220794200897, Lr:0.0001\n",
      "Epoch 2, Step: 733, Loss: 0.4277793765068054, Lr:0.0001\n",
      "Epoch 2, Step: 734, Loss: 0.35412970185279846, Lr:0.0001\n",
      "Epoch 2, Step: 735, Loss: 0.17492079734802246, Lr:0.0001\n",
      "Epoch 2, Step: 736, Loss: 0.39775651693344116, Lr:0.0001\n",
      "Epoch 2, Step: 737, Loss: 0.17698612809181213, Lr:0.0001\n",
      "Epoch 2, Step: 738, Loss: 0.28146782517433167, Lr:0.0001\n",
      "Epoch 2, Step: 739, Loss: 0.14378422498703003, Lr:0.0001\n",
      "Epoch 2, Step: 740, Loss: 0.2565821409225464, Lr:0.0001\n",
      "Epoch 2, Step: 741, Loss: 0.485524445772171, Lr:0.0001\n",
      "Epoch 2, Step: 742, Loss: 0.1853083372116089, Lr:0.0001\n",
      "Epoch 2, Step: 743, Loss: 0.4991312623023987, Lr:0.0001\n",
      "Epoch 2, Step: 744, Loss: 0.42406660318374634, Lr:0.0001\n",
      "Epoch 2, Step: 745, Loss: 0.18648795783519745, Lr:0.0001\n",
      "Epoch 2, Step: 746, Loss: 0.39484915137290955, Lr:0.0001\n",
      "Epoch 2, Step: 747, Loss: 0.4839303493499756, Lr:0.0001\n",
      "Epoch 2, Step: 748, Loss: 0.2628391683101654, Lr:0.0001\n",
      "Epoch 2, Step: 749, Loss: 0.09082414209842682, Lr:0.0001\n",
      "Epoch 2, Step: 750, Loss: 0.30475443601608276, Lr:0.0001\n",
      "Epoch 2, Step: 751, Loss: 0.3405151069164276, Lr:0.0001\n",
      "Epoch 2, Step: 752, Loss: 0.4106431007385254, Lr:0.0001\n",
      "Epoch 2, Step: 753, Loss: 0.8418216109275818, Lr:0.0001\n",
      "Epoch 2, Step: 754, Loss: 0.3327850103378296, Lr:0.0001\n",
      "Epoch 2, Step: 755, Loss: 0.46739500761032104, Lr:0.0001\n",
      "Epoch 2, Step: 756, Loss: 0.3164623975753784, Lr:0.0001\n",
      "Epoch 2, Step: 757, Loss: 0.38645437359809875, Lr:0.0001\n",
      "Epoch 2, Step: 758, Loss: 0.20433971285820007, Lr:0.0001\n",
      "Epoch 2, Step: 759, Loss: 0.2537095546722412, Lr:0.0001\n",
      "Epoch 2, Step: 760, Loss: 0.15697278082370758, Lr:0.0001\n",
      "Epoch 2, Step: 761, Loss: 0.457958847284317, Lr:0.0001\n",
      "Epoch 2, Step: 762, Loss: 0.4252617061138153, Lr:0.0001\n",
      "Epoch 2, Step: 763, Loss: 0.07682835310697556, Lr:0.0001\n",
      "Epoch 2, Step: 764, Loss: 0.27140453457832336, Lr:0.0001\n",
      "Epoch 2, Step: 765, Loss: 0.3990646302700043, Lr:0.0001\n",
      "Epoch 2, Step: 766, Loss: 0.13610073924064636, Lr:0.0001\n",
      "Epoch 2, Step: 767, Loss: 0.23065833747386932, Lr:0.0001\n",
      "Epoch 2, Step: 768, Loss: 0.3470548093318939, Lr:0.0001\n",
      "Epoch 2, Step: 769, Loss: 0.48947060108184814, Lr:0.0001\n",
      "Epoch 2, Step: 770, Loss: 0.14719407260417938, Lr:0.0001\n",
      "Epoch 2, Step: 771, Loss: 0.05689055100083351, Lr:0.0001\n",
      "Epoch 2, Step: 772, Loss: 0.1185067817568779, Lr:0.0001\n",
      "Epoch 2, Step: 773, Loss: 0.4272221326828003, Lr:0.0001\n",
      "Epoch 2, Step: 774, Loss: 0.24239112436771393, Lr:0.0001\n",
      "Epoch 2, Step: 775, Loss: 0.18503335118293762, Lr:0.0001\n",
      "Epoch 2, Step: 776, Loss: 0.32285428047180176, Lr:0.0001\n",
      "Epoch 2, Step: 777, Loss: 0.568645715713501, Lr:0.0001\n",
      "Epoch 2, Step: 778, Loss: 0.4241970181465149, Lr:0.0001\n",
      "Epoch 2, Step: 779, Loss: 0.3698863387107849, Lr:0.0001\n",
      "Epoch 2, Step: 780, Loss: 0.2199055403470993, Lr:0.0001\n",
      "Epoch 2, Step: 781, Loss: 0.18963830173015594, Lr:0.0001\n",
      "Epoch 2, Step: 782, Loss: 0.29768499732017517, Lr:0.0001\n",
      "Epoch 2, Step: 783, Loss: 0.12771150469779968, Lr:0.0001\n",
      "Epoch 2, Step: 784, Loss: 0.0761210173368454, Lr:0.0001\n",
      "Epoch 2, Step: 785, Loss: 0.07996438443660736, Lr:0.0001\n",
      "Epoch 2, Step: 786, Loss: 0.43461349606513977, Lr:0.0001\n",
      "Epoch 2, Step: 787, Loss: 0.1801307201385498, Lr:0.0001\n",
      "Epoch 2, Step: 788, Loss: 0.19422081112861633, Lr:0.0001\n",
      "Epoch 2, Step: 789, Loss: 0.22248566150665283, Lr:0.0001\n",
      "Epoch 2, Step: 790, Loss: 0.22112347185611725, Lr:0.0001\n",
      "Epoch 2, Step: 791, Loss: 0.1307699829339981, Lr:0.0001\n",
      "Epoch 2, Step: 792, Loss: 0.6046776175498962, Lr:0.0001\n",
      "Epoch 2, Step: 793, Loss: 0.14379173517227173, Lr:0.0001\n",
      "Epoch 2, Step: 794, Loss: 0.27753254771232605, Lr:0.0001\n",
      "Epoch 2, Step: 795, Loss: 0.15184934437274933, Lr:0.0001\n",
      "Epoch 2, Step: 796, Loss: 0.11204627901315689, Lr:0.0001\n",
      "Epoch 2, Step: 797, Loss: 0.08292946964502335, Lr:0.0001\n",
      "Epoch 2, Step: 798, Loss: 0.5247335433959961, Lr:0.0001\n",
      "Epoch 2, Step: 799, Loss: 0.31247907876968384, Lr:0.0001\n",
      "Epoch 2, Step: 800, Loss: 0.39359188079833984, Lr:0.0001\n",
      "Epoch 2, Step: 801, Loss: 0.6817564964294434, Lr:0.0001\n",
      "Epoch 2, Step: 802, Loss: 0.40580740571022034, Lr:0.0001\n",
      "Epoch 2, Step: 803, Loss: 0.22287780046463013, Lr:0.0001\n",
      "Epoch 2, Step: 804, Loss: 0.32447925209999084, Lr:0.0001\n",
      "Epoch 2, Step: 805, Loss: 0.09784600883722305, Lr:0.0001\n",
      "Epoch 2, Step: 806, Loss: 0.21011877059936523, Lr:0.0001\n",
      "Epoch 2, Step: 807, Loss: 0.21552178263664246, Lr:0.0001\n",
      "Epoch 2, Step: 808, Loss: 0.4636182188987732, Lr:0.0001\n",
      "Epoch 2, Step: 809, Loss: 0.10827890038490295, Lr:0.0001\n",
      "Epoch 2, Step: 810, Loss: 0.04237990081310272, Lr:0.0001\n",
      "Epoch 2, Step: 811, Loss: 0.10430723428726196, Lr:0.0001\n",
      "Epoch 2, Step: 812, Loss: 0.3703433871269226, Lr:0.0001\n",
      "Epoch 2, Step: 813, Loss: 0.39632919430732727, Lr:0.0001\n",
      "Epoch 2, Step: 814, Loss: 1.0735576152801514, Lr:0.0001\n",
      "Epoch 2, Step: 815, Loss: 0.167618989944458, Lr:0.0001\n",
      "Epoch 2, Step: 816, Loss: 0.16430383920669556, Lr:0.0001\n",
      "Epoch 2, Step: 817, Loss: 0.48700910806655884, Lr:0.0001\n",
      "Epoch 2, Step: 818, Loss: 0.4052046537399292, Lr:0.0001\n",
      "Epoch 2, Step: 819, Loss: 0.49439242482185364, Lr:0.0001\n",
      "Epoch 2, Step: 820, Loss: 0.13915318250656128, Lr:0.0001\n",
      "Epoch 2, Step: 821, Loss: 0.3654366135597229, Lr:0.0001\n",
      "Epoch 2, Step: 822, Loss: 0.2198302298784256, Lr:0.0001\n",
      "Epoch 2, Step: 823, Loss: 0.6838053464889526, Lr:0.0001\n",
      "Epoch 2, Step: 824, Loss: 0.23737363517284393, Lr:0.0001\n",
      "Epoch 2, Step: 825, Loss: 0.2935522794723511, Lr:0.0001\n",
      "Epoch 2, Step: 826, Loss: 0.45888909697532654, Lr:0.0001\n",
      "Epoch 2, Step: 827, Loss: 0.34837251901626587, Lr:0.0001\n",
      "Epoch 2, Step: 828, Loss: 0.2738182246685028, Lr:0.0001\n",
      "Epoch 2, Step: 829, Loss: 0.17993566393852234, Lr:0.0001\n",
      "Epoch 2, Step: 830, Loss: 0.3928191363811493, Lr:0.0001\n",
      "Epoch 2, Step: 831, Loss: 0.17349418997764587, Lr:0.0001\n",
      "Epoch 2, Step: 832, Loss: 0.41311922669410706, Lr:0.0001\n",
      "Epoch 2, Step: 833, Loss: 0.29092589020729065, Lr:0.0001\n",
      "Epoch 2, Step: 834, Loss: 0.36552897095680237, Lr:0.0001\n",
      "Epoch 2, Step: 835, Loss: 0.10246027261018753, Lr:0.0001\n",
      "Epoch 2, Step: 836, Loss: 0.6825565695762634, Lr:0.0001\n",
      "Epoch 2, Step: 837, Loss: 0.17507235705852509, Lr:0.0001\n",
      "Epoch 2, Step: 838, Loss: 0.2904907763004303, Lr:0.0001\n",
      "Epoch 2, Step: 839, Loss: 1.005454659461975, Lr:0.0001\n",
      "Epoch 2, Step: 840, Loss: 0.6114966869354248, Lr:0.0001\n",
      "Epoch 2, Step: 841, Loss: 0.2804085314273834, Lr:0.0001\n",
      "Epoch 2, Step: 842, Loss: 0.14815959334373474, Lr:0.0001\n",
      "Epoch 2, Step: 843, Loss: 0.14971065521240234, Lr:0.0001\n",
      "Epoch 2, Step: 844, Loss: 0.33346956968307495, Lr:0.0001\n",
      "Epoch 2, Step: 845, Loss: 0.20551751554012299, Lr:0.0001\n",
      "Epoch 2, Step: 846, Loss: 0.1923600435256958, Lr:0.0001\n",
      "Epoch 2, Step: 847, Loss: 0.19063200056552887, Lr:0.0001\n",
      "Epoch 2, Step: 848, Loss: 0.27130573987960815, Lr:0.0001\n",
      "Epoch 2, Step: 849, Loss: 0.3750055432319641, Lr:0.0001\n",
      "Epoch 2, Step: 850, Loss: 0.24047237634658813, Lr:0.0001\n",
      "Epoch 2, Step: 851, Loss: 0.5099961757659912, Lr:0.0001\n",
      "Epoch 2, Step: 852, Loss: 0.2182527482509613, Lr:0.0001\n",
      "Epoch 2, Step: 853, Loss: 0.562089204788208, Lr:0.0001\n",
      "Epoch 2, Step: 854, Loss: 0.09861276298761368, Lr:0.0001\n",
      "Epoch 2, Step: 855, Loss: 0.3425152599811554, Lr:0.0001\n",
      "Epoch 2, Step: 856, Loss: 0.241542249917984, Lr:0.0001\n",
      "Epoch 2, Step: 857, Loss: 0.39330220222473145, Lr:0.0001\n",
      "Epoch 2, Step: 858, Loss: 0.4517763555049896, Lr:0.0001\n",
      "Epoch 2, Step: 859, Loss: 0.21259921789169312, Lr:0.0001\n",
      "Epoch 2, Step: 860, Loss: 0.4562748074531555, Lr:0.0001\n",
      "Epoch 2, Step: 861, Loss: 0.16058099269866943, Lr:0.0001\n",
      "Epoch 2, Step: 862, Loss: 0.2004508376121521, Lr:0.0001\n",
      "Epoch 2, Step: 863, Loss: 0.15636444091796875, Lr:0.0001\n",
      "Epoch 2, Step: 864, Loss: 0.4365934133529663, Lr:0.0001\n",
      "Epoch 2, Step: 865, Loss: 0.2645786702632904, Lr:0.0001\n",
      "Epoch 2, Step: 866, Loss: 0.14769388735294342, Lr:0.0001\n",
      "Epoch 2, Step: 867, Loss: 0.4956505298614502, Lr:0.0001\n",
      "Epoch 2, Step: 868, Loss: 0.23623262345790863, Lr:0.0001\n",
      "Epoch 2, Step: 869, Loss: 0.27531200647354126, Lr:0.0001\n",
      "Epoch 2, Step: 870, Loss: 0.23225361108779907, Lr:0.0001\n",
      "Epoch 2, Step: 871, Loss: 0.3485562205314636, Lr:0.0001\n",
      "Epoch 2, Step: 872, Loss: 0.506175696849823, Lr:0.0001\n",
      "Epoch 2, Step: 873, Loss: 0.4168577492237091, Lr:0.0001\n",
      "Epoch 2, Step: 874, Loss: 0.3683459162712097, Lr:0.0001\n",
      "Epoch 2, Step: 875, Loss: 0.7189343571662903, Lr:0.0001\n",
      "Epoch 2, Step: 876, Loss: 0.502197802066803, Lr:0.0001\n",
      "Epoch 2, Step: 877, Loss: 0.46361464262008667, Lr:0.0001\n",
      "Epoch 2, Step: 878, Loss: 0.345957487821579, Lr:0.0001\n",
      "Epoch 2, Step: 879, Loss: 0.2699395418167114, Lr:0.0001\n",
      "Epoch 2, Step: 880, Loss: 0.3352494537830353, Lr:0.0001\n",
      "Epoch 2, Step: 881, Loss: 0.38660097122192383, Lr:0.0001\n",
      "Epoch 2, Step: 882, Loss: 0.3261065185070038, Lr:0.0001\n",
      "Epoch 2, Step: 883, Loss: 0.2532663345336914, Lr:0.0001\n",
      "Epoch 2, Step: 884, Loss: 0.3306889235973358, Lr:0.0001\n",
      "Epoch 2, Step: 885, Loss: 0.16878220438957214, Lr:0.0001\n",
      "Epoch 2, Step: 886, Loss: 0.09712836146354675, Lr:0.0001\n",
      "Epoch 2, Step: 887, Loss: 0.4050558805465698, Lr:0.0001\n",
      "Epoch 2, Step: 888, Loss: 0.3324899673461914, Lr:0.0001\n",
      "Epoch 2, Step: 889, Loss: 0.5566864013671875, Lr:0.0001\n",
      "Epoch 2, Step: 890, Loss: 0.17733539640903473, Lr:0.0001\n",
      "Epoch 2, Step: 891, Loss: 0.37038516998291016, Lr:0.0001\n",
      "Epoch 2, Step: 892, Loss: 0.3776688277721405, Lr:0.0001\n",
      "Epoch 2, Step: 893, Loss: 0.2322259098291397, Lr:0.0001\n",
      "Epoch 2, Step: 894, Loss: 0.3978695571422577, Lr:0.0001\n",
      "Epoch 2, Step: 895, Loss: 0.21142683923244476, Lr:0.0001\n",
      "Epoch 2, Step: 896, Loss: 0.10341005027294159, Lr:0.0001\n",
      "Epoch 2, Step: 897, Loss: 0.2291298359632492, Lr:0.0001\n",
      "Epoch 2, Step: 898, Loss: 0.32244908809661865, Lr:0.0001\n",
      "Epoch 2, Step: 899, Loss: 0.1508873850107193, Lr:0.0001\n",
      "Epoch 2, Step: 900, Loss: 0.2606779932975769, Lr:0.0001\n",
      "Epoch 2, Step: 901, Loss: 0.4590989053249359, Lr:0.0001\n",
      "Epoch 2, Step: 902, Loss: 0.4374527931213379, Lr:0.0001\n",
      "Epoch 2, Step: 903, Loss: 0.11051705479621887, Lr:0.0001\n",
      "Epoch 2, Step: 904, Loss: 0.24366812407970428, Lr:0.0001\n",
      "Epoch 2, Step: 905, Loss: 0.29847946763038635, Lr:0.0001\n",
      "Epoch 2, Step: 906, Loss: 0.6360699534416199, Lr:0.0001\n",
      "Epoch 2, Step: 907, Loss: 0.4385472238063812, Lr:0.0001\n",
      "Epoch 2, Step: 908, Loss: 0.32974973320961, Lr:0.0001\n",
      "Epoch 2, Step: 909, Loss: 0.20691566169261932, Lr:0.0001\n",
      "Epoch 2, Step: 910, Loss: 0.267027884721756, Lr:0.0001\n",
      "Epoch 2, Step: 911, Loss: 0.6089325547218323, Lr:0.0001\n",
      "Epoch 2, Step: 912, Loss: 0.07260848581790924, Lr:0.0001\n",
      "Epoch 2, Step: 913, Loss: 0.22318044304847717, Lr:0.0001\n",
      "Epoch 2, Step: 914, Loss: 0.5482980608940125, Lr:0.0001\n",
      "Epoch 2, Step: 915, Loss: 0.39836809039115906, Lr:0.0001\n",
      "Epoch 2, Step: 916, Loss: 0.3271610736846924, Lr:0.0001\n",
      "Epoch 2, Step: 917, Loss: 0.29644057154655457, Lr:0.0001\n",
      "Epoch 2, Step: 918, Loss: 0.19599422812461853, Lr:0.0001\n",
      "Epoch 2, Step: 919, Loss: 0.2105208933353424, Lr:0.0001\n",
      "Epoch 2, Step: 920, Loss: 0.2896759510040283, Lr:0.0001\n",
      "Epoch 2, Step: 921, Loss: 0.19963164627552032, Lr:0.0001\n",
      "Epoch 2, Step: 922, Loss: 0.31759315729141235, Lr:0.0001\n",
      "Epoch 2, Step: 923, Loss: 0.31622275710105896, Lr:0.0001\n",
      "Epoch 2, Step: 924, Loss: 0.424398273229599, Lr:0.0001\n",
      "Epoch 2, Step: 925, Loss: 0.2186278998851776, Lr:0.0001\n",
      "Epoch 2, Step: 926, Loss: 0.49871379137039185, Lr:0.0001\n",
      "Epoch 2, Step: 927, Loss: 0.3377918601036072, Lr:0.0001\n",
      "Epoch 2, Step: 928, Loss: 0.37108924984931946, Lr:0.0001\n",
      "Epoch 2, Step: 929, Loss: 0.5916913747787476, Lr:0.0001\n",
      "Epoch 2, Step: 930, Loss: 0.6426751613616943, Lr:0.0001\n",
      "Epoch 2, Step: 931, Loss: 0.29023247957229614, Lr:0.0001\n",
      "Epoch 2, Step: 932, Loss: 0.055329225957393646, Lr:0.0001\n",
      "Epoch 2, Step: 933, Loss: 0.25754866003990173, Lr:0.0001\n",
      "Epoch 2, Step: 934, Loss: 0.12206782400608063, Lr:0.0001\n",
      "Epoch 2, Step: 935, Loss: 0.592176616191864, Lr:0.0001\n",
      "Epoch 2, Step: 936, Loss: 0.26377245783805847, Lr:0.0001\n",
      "Epoch 2, Step: 937, Loss: 0.2507246434688568, Lr:0.0001\n",
      "Epoch 2, Step: 938, Loss: 0.2831396162509918, Lr:0.0001\n",
      "Epoch 2, Step: 939, Loss: 0.4193406105041504, Lr:0.0001\n",
      "Epoch 2, Step: 940, Loss: 0.16096201539039612, Lr:0.0001\n",
      "Epoch 2, Step: 941, Loss: 1.110784649848938, Lr:0.0001\n",
      "Epoch 2, Step: 942, Loss: 0.058608125895261765, Lr:0.0001\n",
      "Epoch 2, Step: 943, Loss: 0.5439196228981018, Lr:0.0001\n",
      "Epoch 2, Step: 944, Loss: 0.2902016043663025, Lr:0.0001\n",
      "Epoch 2, Step: 945, Loss: 0.17563284933567047, Lr:0.0001\n",
      "Epoch 2, Step: 946, Loss: 0.37302011251449585, Lr:0.0001\n",
      "Epoch 2, Step: 947, Loss: 0.3817604184150696, Lr:0.0001\n",
      "Epoch 2, Step: 948, Loss: 0.35114237666130066, Lr:0.0001\n",
      "Epoch 2, Step: 949, Loss: 0.26153579354286194, Lr:0.0001\n",
      "Epoch 2, Step: 950, Loss: 0.28560736775398254, Lr:0.0001\n",
      "Epoch 2, Step: 951, Loss: 0.4645746052265167, Lr:0.0001\n",
      "Epoch 2, Step: 952, Loss: 0.25354406237602234, Lr:0.0001\n",
      "Epoch 2, Step: 953, Loss: 0.2865608036518097, Lr:0.0001\n",
      "Epoch 2, Step: 954, Loss: 0.3456583321094513, Lr:0.0001\n",
      "Epoch 2, Step: 955, Loss: 0.3015039265155792, Lr:0.0001\n",
      "Epoch 2, Step: 956, Loss: 0.6681862473487854, Lr:0.0001\n",
      "Epoch 2, Step: 957, Loss: 0.456960529088974, Lr:0.0001\n",
      "Epoch 2, Step: 958, Loss: 0.3698791265487671, Lr:0.0001\n",
      "Epoch 2, Step: 959, Loss: 0.2606405019760132, Lr:0.0001\n",
      "Epoch 2, Step: 960, Loss: 0.660698652267456, Lr:0.0001\n",
      "Epoch 2, Step: 961, Loss: 0.1515098363161087, Lr:0.0001\n",
      "Epoch 2, Step: 962, Loss: 0.5490039587020874, Lr:0.0001\n",
      "Epoch 2, Step: 963, Loss: 0.23539571464061737, Lr:0.0001\n",
      "Epoch 2, Step: 964, Loss: 0.4033288061618805, Lr:0.0001\n",
      "Epoch 2, Step: 965, Loss: 0.23097118735313416, Lr:0.0001\n",
      "Epoch 2, Step: 966, Loss: 0.672756016254425, Lr:0.0001\n",
      "Epoch 2, Step: 967, Loss: 0.3886187672615051, Lr:0.0001\n",
      "Epoch 2, Step: 968, Loss: 0.2570793926715851, Lr:0.0001\n",
      "Epoch 2, Step: 969, Loss: 0.24756953120231628, Lr:0.0001\n",
      "Epoch 2, Step: 970, Loss: 0.5921816825866699, Lr:0.0001\n",
      "Epoch 2, Step: 971, Loss: 0.4146827757358551, Lr:0.0001\n",
      "Epoch 2, Step: 972, Loss: 0.24078598618507385, Lr:0.0001\n",
      "Epoch 2, Step: 973, Loss: 0.2423093318939209, Lr:0.0001\n",
      "Epoch 2, Step: 974, Loss: 0.25454965233802795, Lr:0.0001\n",
      "Epoch 2, Step: 975, Loss: 0.303966224193573, Lr:0.0001\n",
      "Epoch 2, Step: 976, Loss: 0.5336005091667175, Lr:0.0001\n",
      "Epoch 2, Step: 977, Loss: 0.17828921973705292, Lr:0.0001\n",
      "Epoch 2, Step: 978, Loss: 0.43548983335494995, Lr:0.0001\n",
      "Epoch 2, Step: 979, Loss: 0.5480874180793762, Lr:0.0001\n",
      "Epoch 2, Step: 980, Loss: 0.5062538981437683, Lr:0.0001\n",
      "Epoch 2, Step: 981, Loss: 0.44610920548439026, Lr:0.0001\n",
      "Epoch 2, Step: 982, Loss: 0.1854609251022339, Lr:0.0001\n",
      "Epoch 2, Step: 983, Loss: 0.3597598969936371, Lr:0.0001\n",
      "Epoch 2, Step: 984, Loss: 0.5935609936714172, Lr:0.0001\n",
      "Epoch 2, Step: 985, Loss: 0.15793775022029877, Lr:0.0001\n",
      "Epoch 2, Step: 986, Loss: 0.40068066120147705, Lr:0.0001\n",
      "Epoch 2, Step: 987, Loss: 0.2914341986179352, Lr:0.0001\n",
      "Epoch 2, Step: 988, Loss: 0.2683873772621155, Lr:0.0001\n",
      "Epoch 2, Step: 989, Loss: 0.39857131242752075, Lr:0.0001\n",
      "Epoch 2, Step: 990, Loss: 0.25968438386917114, Lr:0.0001\n",
      "Epoch 2, Step: 991, Loss: 0.1413571834564209, Lr:0.0001\n",
      "Epoch 2, Step: 992, Loss: 0.23385870456695557, Lr:0.0001\n",
      "Epoch 2, Step: 993, Loss: 0.3098539710044861, Lr:0.0001\n",
      "Epoch 2, Step: 994, Loss: 0.5344434976577759, Lr:0.0001\n",
      "Epoch 2, Step: 995, Loss: 0.363328218460083, Lr:0.0001\n",
      "Epoch 2, Step: 996, Loss: 0.40759381651878357, Lr:0.0001\n",
      "Epoch 2, Step: 997, Loss: 0.07332689315080643, Lr:0.0001\n",
      "Epoch 2, Step: 998, Loss: 0.2721904516220093, Lr:0.0001\n",
      "Epoch 2, Step: 999, Loss: 0.10861814767122269, Lr:0.0001\n",
      "Epoch 2, Step: 1000, Loss: 0.19050341844558716, Lr:0.0001\n",
      "Epoch 2, Step: 1001, Loss: 0.27347084879875183, Lr:0.0001\n",
      "Epoch 2, Step: 1002, Loss: 0.17254620790481567, Lr:0.0001\n",
      "Epoch 2, Step: 1003, Loss: 0.17616890370845795, Lr:0.0001\n",
      "Epoch 2, Step: 1004, Loss: 0.24757543206214905, Lr:0.0001\n",
      "Epoch 2, Step: 1005, Loss: 0.2370334267616272, Lr:0.0001\n",
      "Epoch 2, Step: 1006, Loss: 0.4943632483482361, Lr:0.0001\n",
      "Epoch 2, Step: 1007, Loss: 0.27594193816185, Lr:0.0001\n",
      "Epoch 2, Step: 1008, Loss: 0.2580093741416931, Lr:0.0001\n",
      "Epoch 2, Step: 1009, Loss: 0.11052719503641129, Lr:0.0001\n",
      "Epoch 2, Step: 1010, Loss: 0.34211498498916626, Lr:0.0001\n",
      "Epoch 2, Step: 1011, Loss: 0.32505396008491516, Lr:0.0001\n",
      "Epoch 2, Step: 1012, Loss: 0.06569157540798187, Lr:0.0001\n",
      "Epoch 2, Step: 1013, Loss: 0.10163307189941406, Lr:0.0001\n",
      "Epoch 2, Step: 1014, Loss: 0.08325080573558807, Lr:0.0001\n",
      "Epoch 2, Step: 1015, Loss: 0.1132771298289299, Lr:0.0001\n",
      "Epoch 2, Step: 1016, Loss: 0.33579397201538086, Lr:0.0001\n",
      "Epoch 2, Step: 1017, Loss: 0.37459588050842285, Lr:0.0001\n",
      "Epoch 2, Step: 1018, Loss: 0.04074398800730705, Lr:0.0001\n",
      "Epoch 2, Step: 1019, Loss: 0.39764660596847534, Lr:0.0001\n",
      "Epoch 2, Step: 1020, Loss: 0.21019302308559418, Lr:0.0001\n",
      "Epoch 2, Step: 1021, Loss: 0.2489331215620041, Lr:0.0001\n",
      "Epoch 2, Step: 1022, Loss: 0.2367454618215561, Lr:0.0001\n",
      "Epoch 2, Step: 1023, Loss: 0.2893022894859314, Lr:0.0001\n",
      "Epoch 2, Step: 1024, Loss: 0.24225640296936035, Lr:0.0001\n",
      "Epoch 2, Step: 1025, Loss: 0.1752159744501114, Lr:0.0001\n",
      "Epoch 2, Step: 1026, Loss: 0.44107484817504883, Lr:0.0001\n",
      "Epoch 2, Step: 1027, Loss: 0.45958366990089417, Lr:0.0001\n",
      "Epoch 2, Step: 1028, Loss: 0.09981992840766907, Lr:0.0001\n",
      "Epoch 2, Step: 1029, Loss: 0.3012796640396118, Lr:0.0001\n",
      "Epoch 2, Step: 1030, Loss: 0.2112821787595749, Lr:0.0001\n",
      "Epoch 2, Step: 1031, Loss: 0.15263710916042328, Lr:0.0001\n",
      "Epoch 2, Step: 1032, Loss: 0.20898333191871643, Lr:0.0001\n",
      "Epoch 2, Step: 1033, Loss: 0.19584015011787415, Lr:0.0001\n",
      "Epoch 2, Step: 1034, Loss: 0.1683984249830246, Lr:0.0001\n",
      "Epoch 2, Step: 1035, Loss: 0.35115745663642883, Lr:0.0001\n",
      "Epoch 2, Step: 1036, Loss: 0.217997208237648, Lr:0.0001\n",
      "Epoch 2, Step: 1037, Loss: 0.3341034948825836, Lr:0.0001\n",
      "Epoch 2, Step: 1038, Loss: 0.29033204913139343, Lr:0.0001\n",
      "Epoch 2, Step: 1039, Loss: 0.6607462167739868, Lr:0.0001\n",
      "Epoch 2, Step: 1040, Loss: 0.09619561582803726, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 2\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:16 loss: 0.5175 (0.5175) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.2918 data: 0.1078 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:12 loss: 0.1196 (0.1783) acc1: 93.7500 (93.7500) acc5: 100.0000 (100.0000) time: 0.2821 data: 0.1072 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.1406 (0.1964) acc1: 93.7500 (93.1548) acc5: 100.0000 (100.0000) time: 0.2847 data: 0.1086 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.2267 (0.3910) acc1: 93.7500 (85.8871) acc5: 100.0000 (100.0000) time: 0.2893 data: 0.1120 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.4975 (0.4365) acc1: 81.2500 (84.2988) acc5: 100.0000 (100.0000) time: 0.2958 data: 0.1180 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.4975 (0.4258) acc1: 81.2500 (85.0490) acc5: 100.0000 (100.0000) time: 0.2968 data: 0.1185 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.1693 (0.4512) acc1: 93.7500 (85.3575) acc5: 100.0000 (100.0000) time: 0.2798 data: 0.1107 max mem: 15137\n",
      "Test: Total time: 0:00:15 (0.2855 s / it)\n",
      "* Acc@1 85.358 Acc@5 100.000 loss 0.451\n",
      "Accuracy of the network on the 881 test image: 85.4%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 3, Step: 0, Loss: 0.5508057475090027, Lr:0.0001\n",
      "Epoch 3, Step: 1, Loss: 0.45510154962539673, Lr:0.0001\n",
      "Epoch 3, Step: 2, Loss: 0.3692765235900879, Lr:0.0001\n",
      "Epoch 3, Step: 3, Loss: 0.33136144280433655, Lr:0.0001\n",
      "Epoch 3, Step: 4, Loss: 0.4090426564216614, Lr:0.0001\n",
      "Epoch 3, Step: 5, Loss: 0.2796018421649933, Lr:0.0001\n",
      "Epoch 3, Step: 6, Loss: 0.3089042007923126, Lr:0.0001\n",
      "Epoch 3, Step: 7, Loss: 0.35291561484336853, Lr:0.0001\n",
      "Epoch 3, Step: 8, Loss: 0.10285548120737076, Lr:0.0001\n",
      "Epoch 3, Step: 9, Loss: 0.14050167798995972, Lr:0.0001\n",
      "Epoch 3, Step: 10, Loss: 0.15596823394298553, Lr:0.0001\n",
      "Epoch 3, Step: 11, Loss: 0.267576664686203, Lr:0.0001\n",
      "Epoch 3, Step: 12, Loss: 0.32446256279945374, Lr:0.0001\n",
      "Epoch 3, Step: 13, Loss: 0.22837500274181366, Lr:0.0001\n",
      "Epoch 3, Step: 14, Loss: 0.20322301983833313, Lr:0.0001\n",
      "Epoch 3, Step: 15, Loss: 0.4834454357624054, Lr:0.0001\n",
      "Epoch 3, Step: 16, Loss: 0.5056679844856262, Lr:0.0001\n",
      "Epoch 3, Step: 17, Loss: 0.2420671135187149, Lr:0.0001\n",
      "Epoch 3, Step: 18, Loss: 0.36102598905563354, Lr:0.0001\n",
      "Epoch 3, Step: 19, Loss: 0.2551981806755066, Lr:0.0001\n",
      "Epoch 3, Step: 20, Loss: 0.23495261371135712, Lr:0.0001\n",
      "Epoch 3, Step: 21, Loss: 0.20347529649734497, Lr:0.0001\n",
      "Epoch 3, Step: 22, Loss: 0.08145341277122498, Lr:0.0001\n",
      "Epoch 3, Step: 23, Loss: 0.3801305294036865, Lr:0.0001\n",
      "Epoch 3, Step: 24, Loss: 0.3520190715789795, Lr:0.0001\n",
      "Epoch 3, Step: 25, Loss: 0.2621174454689026, Lr:0.0001\n",
      "Epoch 3, Step: 26, Loss: 0.5432857871055603, Lr:0.0001\n",
      "Epoch 3, Step: 27, Loss: 0.2612321972846985, Lr:0.0001\n",
      "Epoch 3, Step: 28, Loss: 0.40112435817718506, Lr:0.0001\n",
      "Epoch 3, Step: 29, Loss: 0.1862129271030426, Lr:0.0001\n",
      "Epoch 3, Step: 30, Loss: 0.09374148398637772, Lr:0.0001\n",
      "Epoch 3, Step: 31, Loss: 0.5356936454772949, Lr:0.0001\n",
      "Epoch 3, Step: 32, Loss: 0.1613340675830841, Lr:0.0001\n",
      "Epoch 3, Step: 33, Loss: 0.26188138127326965, Lr:0.0001\n",
      "Epoch 3, Step: 34, Loss: 0.22833070158958435, Lr:0.0001\n",
      "Epoch 3, Step: 35, Loss: 0.23236103355884552, Lr:0.0001\n",
      "Epoch 3, Step: 36, Loss: 0.3445756733417511, Lr:0.0001\n",
      "Epoch 3, Step: 37, Loss: 0.3939656913280487, Lr:0.0001\n",
      "Epoch 3, Step: 38, Loss: 0.165230393409729, Lr:0.0001\n",
      "Epoch 3, Step: 39, Loss: 0.6137886047363281, Lr:0.0001\n",
      "Epoch 3, Step: 40, Loss: 0.2975032329559326, Lr:0.0001\n",
      "Epoch 3, Step: 41, Loss: 0.19829483330249786, Lr:0.0001\n",
      "Epoch 3, Step: 42, Loss: 0.2802819013595581, Lr:0.0001\n",
      "Epoch 3, Step: 43, Loss: 0.24404053390026093, Lr:0.0001\n",
      "Epoch 3, Step: 44, Loss: 0.22968536615371704, Lr:0.0001\n",
      "Epoch 3, Step: 45, Loss: 0.11238394677639008, Lr:0.0001\n",
      "Epoch 3, Step: 46, Loss: 0.2544440031051636, Lr:0.0001\n",
      "Epoch 3, Step: 47, Loss: 0.28051459789276123, Lr:0.0001\n",
      "Epoch 3, Step: 48, Loss: 0.143460214138031, Lr:0.0001\n",
      "Epoch 3, Step: 49, Loss: 0.056754883378744125, Lr:0.0001\n",
      "Epoch 3, Step: 50, Loss: 0.33770620822906494, Lr:0.0001\n",
      "Epoch 3, Step: 51, Loss: 0.29726430773735046, Lr:0.0001\n",
      "Epoch 3, Step: 52, Loss: 0.2782379388809204, Lr:0.0001\n",
      "Epoch 3, Step: 53, Loss: 0.5213501453399658, Lr:0.0001\n",
      "Epoch 3, Step: 54, Loss: 0.47718149423599243, Lr:0.0001\n",
      "Epoch 3, Step: 55, Loss: 0.15549680590629578, Lr:0.0001\n",
      "Epoch 3, Step: 56, Loss: 0.28403276205062866, Lr:0.0001\n",
      "Epoch 3, Step: 57, Loss: 0.4906443655490875, Lr:0.0001\n",
      "Epoch 3, Step: 58, Loss: 0.1779320240020752, Lr:0.0001\n",
      "Epoch 3, Step: 59, Loss: 0.2010599821805954, Lr:0.0001\n",
      "Epoch 3, Step: 60, Loss: 1.0507999658584595, Lr:0.0001\n",
      "Epoch 3, Step: 61, Loss: 0.31268417835235596, Lr:0.0001\n",
      "Epoch 3, Step: 62, Loss: 0.09142247587442398, Lr:0.0001\n",
      "Epoch 3, Step: 63, Loss: 0.23440687358379364, Lr:0.0001\n",
      "Epoch 3, Step: 64, Loss: 0.7226709127426147, Lr:0.0001\n",
      "Epoch 3, Step: 65, Loss: 0.2578692138195038, Lr:0.0001\n",
      "Epoch 3, Step: 66, Loss: 0.27996665239334106, Lr:0.0001\n",
      "Epoch 3, Step: 67, Loss: 0.24821507930755615, Lr:0.0001\n",
      "Epoch 3, Step: 68, Loss: 0.3196687698364258, Lr:0.0001\n",
      "Epoch 3, Step: 69, Loss: 0.3472071588039398, Lr:0.0001\n",
      "Epoch 3, Step: 70, Loss: 0.23584628105163574, Lr:0.0001\n",
      "Epoch 3, Step: 71, Loss: 0.09417087584733963, Lr:0.0001\n",
      "Epoch 3, Step: 72, Loss: 0.17110885679721832, Lr:0.0001\n",
      "Epoch 3, Step: 73, Loss: 0.31161248683929443, Lr:0.0001\n",
      "Epoch 3, Step: 74, Loss: 0.46614137291908264, Lr:0.0001\n",
      "Epoch 3, Step: 75, Loss: 0.48881179094314575, Lr:0.0001\n",
      "Epoch 3, Step: 76, Loss: 0.49713391065597534, Lr:0.0001\n",
      "Epoch 3, Step: 77, Loss: 0.2513435184955597, Lr:0.0001\n",
      "Epoch 3, Step: 78, Loss: 0.4453115165233612, Lr:0.0001\n",
      "Epoch 3, Step: 79, Loss: 0.2232280820608139, Lr:0.0001\n",
      "Epoch 3, Step: 80, Loss: 0.29822278022766113, Lr:0.0001\n",
      "Epoch 3, Step: 81, Loss: 0.2505110502243042, Lr:0.0001\n",
      "Epoch 3, Step: 82, Loss: 0.19990311563014984, Lr:0.0001\n",
      "Epoch 3, Step: 83, Loss: 0.2602631747722626, Lr:0.0001\n",
      "Epoch 3, Step: 84, Loss: 0.6220649480819702, Lr:0.0001\n",
      "Epoch 3, Step: 85, Loss: 0.4401913285255432, Lr:0.0001\n",
      "Epoch 3, Step: 86, Loss: 0.18801936507225037, Lr:0.0001\n",
      "Epoch 3, Step: 87, Loss: 0.052240509539842606, Lr:0.0001\n",
      "Epoch 3, Step: 88, Loss: 0.10602777451276779, Lr:0.0001\n",
      "Epoch 3, Step: 89, Loss: 0.22108395397663116, Lr:0.0001\n",
      "Epoch 3, Step: 90, Loss: 0.38914328813552856, Lr:0.0001\n",
      "Epoch 3, Step: 91, Loss: 0.38671785593032837, Lr:0.0001\n",
      "Epoch 3, Step: 92, Loss: 0.23602786660194397, Lr:0.0001\n",
      "Epoch 3, Step: 93, Loss: 0.4729747176170349, Lr:0.0001\n",
      "Epoch 3, Step: 94, Loss: 0.19088244438171387, Lr:0.0001\n",
      "Epoch 3, Step: 95, Loss: 0.21193595230579376, Lr:0.0001\n",
      "Epoch 3, Step: 96, Loss: 0.2809545695781708, Lr:0.0001\n",
      "Epoch 3, Step: 97, Loss: 0.47944700717926025, Lr:0.0001\n",
      "Epoch 3, Step: 98, Loss: 0.12350695580244064, Lr:0.0001\n",
      "Epoch 3, Step: 99, Loss: 0.7731413841247559, Lr:0.0001\n",
      "Epoch 3, Step: 100, Loss: 0.09068738669157028, Lr:0.0001\n",
      "Epoch 3, Step: 101, Loss: 0.4613840878009796, Lr:0.0001\n",
      "Epoch 3, Step: 102, Loss: 0.5596974492073059, Lr:0.0001\n",
      "Epoch 3, Step: 103, Loss: 0.4468514323234558, Lr:0.0001\n",
      "Epoch 3, Step: 104, Loss: 0.2772158980369568, Lr:0.0001\n",
      "Epoch 3, Step: 105, Loss: 0.23365211486816406, Lr:0.0001\n",
      "Epoch 3, Step: 106, Loss: 0.2399986982345581, Lr:0.0001\n",
      "Epoch 3, Step: 107, Loss: 0.25605741143226624, Lr:0.0001\n",
      "Epoch 3, Step: 108, Loss: 0.20740871131420135, Lr:0.0001\n",
      "Epoch 3, Step: 109, Loss: 0.1007569283246994, Lr:0.0001\n",
      "Epoch 3, Step: 110, Loss: 0.3300022780895233, Lr:0.0001\n",
      "Epoch 3, Step: 111, Loss: 0.4578198194503784, Lr:0.0001\n",
      "Epoch 3, Step: 112, Loss: 0.2500387132167816, Lr:0.0001\n",
      "Epoch 3, Step: 113, Loss: 0.6945241093635559, Lr:0.0001\n",
      "Epoch 3, Step: 114, Loss: 0.1945073902606964, Lr:0.0001\n",
      "Epoch 3, Step: 115, Loss: 0.10373900085687637, Lr:0.0001\n",
      "Epoch 3, Step: 116, Loss: 0.2150411754846573, Lr:0.0001\n",
      "Epoch 3, Step: 117, Loss: 0.33226680755615234, Lr:0.0001\n",
      "Epoch 3, Step: 118, Loss: 0.33422860503196716, Lr:0.0001\n",
      "Epoch 3, Step: 119, Loss: 0.3640679121017456, Lr:0.0001\n",
      "Epoch 3, Step: 120, Loss: 0.3846694231033325, Lr:0.0001\n",
      "Epoch 3, Step: 121, Loss: 0.4362776279449463, Lr:0.0001\n",
      "Epoch 3, Step: 122, Loss: 0.39061734080314636, Lr:0.0001\n",
      "Epoch 3, Step: 123, Loss: 0.4146188199520111, Lr:0.0001\n",
      "Epoch 3, Step: 124, Loss: 0.1509987711906433, Lr:0.0001\n",
      "Epoch 3, Step: 125, Loss: 0.5286218523979187, Lr:0.0001\n",
      "Epoch 3, Step: 126, Loss: 0.21643580496311188, Lr:0.0001\n",
      "Epoch 3, Step: 127, Loss: 0.14150279760360718, Lr:0.0001\n",
      "Epoch 3, Step: 128, Loss: 0.1418658345937729, Lr:0.0001\n",
      "Epoch 3, Step: 129, Loss: 0.13538427650928497, Lr:0.0001\n",
      "Epoch 3, Step: 130, Loss: 0.6207277774810791, Lr:0.0001\n",
      "Epoch 3, Step: 131, Loss: 0.13480783998966217, Lr:0.0001\n",
      "Epoch 3, Step: 132, Loss: 0.40218958258628845, Lr:0.0001\n",
      "Epoch 3, Step: 133, Loss: 0.14469684660434723, Lr:0.0001\n",
      "Epoch 3, Step: 134, Loss: 0.9860910177230835, Lr:0.0001\n",
      "Epoch 3, Step: 135, Loss: 0.3064453601837158, Lr:0.0001\n",
      "Epoch 3, Step: 136, Loss: 0.26544883847236633, Lr:0.0001\n",
      "Epoch 3, Step: 137, Loss: 0.8422588109970093, Lr:0.0001\n",
      "Epoch 3, Step: 138, Loss: 0.3258882164955139, Lr:0.0001\n",
      "Epoch 3, Step: 139, Loss: 0.16699261963367462, Lr:0.0001\n",
      "Epoch 3, Step: 140, Loss: 0.15446102619171143, Lr:0.0001\n",
      "Epoch 3, Step: 141, Loss: 0.3989962935447693, Lr:0.0001\n",
      "Epoch 3, Step: 142, Loss: 0.3131951689720154, Lr:0.0001\n",
      "Epoch 3, Step: 143, Loss: 0.23226064443588257, Lr:0.0001\n",
      "Epoch 3, Step: 144, Loss: 0.47341668605804443, Lr:0.0001\n",
      "Epoch 3, Step: 145, Loss: 0.18789216876029968, Lr:0.0001\n",
      "Epoch 3, Step: 146, Loss: 0.16115164756774902, Lr:0.0001\n",
      "Epoch 3, Step: 147, Loss: 0.6309506893157959, Lr:0.0001\n",
      "Epoch 3, Step: 148, Loss: 0.5824818015098572, Lr:0.0001\n",
      "Epoch 3, Step: 149, Loss: 0.2197117954492569, Lr:0.0001\n",
      "Epoch 3, Step: 150, Loss: 0.17538432776927948, Lr:0.0001\n",
      "Epoch 3, Step: 151, Loss: 0.3910149335861206, Lr:0.0001\n",
      "Epoch 3, Step: 152, Loss: 0.18744057416915894, Lr:0.0001\n",
      "Epoch 3, Step: 153, Loss: 0.31608089804649353, Lr:0.0001\n",
      "Epoch 3, Step: 154, Loss: 0.25921377539634705, Lr:0.0001\n",
      "Epoch 3, Step: 155, Loss: 0.4125995635986328, Lr:0.0001\n",
      "Epoch 3, Step: 156, Loss: 0.5511580109596252, Lr:0.0001\n",
      "Epoch 3, Step: 157, Loss: 0.22586610913276672, Lr:0.0001\n",
      "Epoch 3, Step: 158, Loss: 0.1861424595117569, Lr:0.0001\n",
      "Epoch 3, Step: 159, Loss: 0.46309641003608704, Lr:0.0001\n",
      "Epoch 3, Step: 160, Loss: 0.17771366238594055, Lr:0.0001\n",
      "Epoch 3, Step: 161, Loss: 0.58134925365448, Lr:0.0001\n",
      "Epoch 3, Step: 162, Loss: 0.32824766635894775, Lr:0.0001\n",
      "Epoch 3, Step: 163, Loss: 0.14977975189685822, Lr:0.0001\n",
      "Epoch 3, Step: 164, Loss: 0.42244261503219604, Lr:0.0001\n",
      "Epoch 3, Step: 165, Loss: 0.17573274672031403, Lr:0.0001\n",
      "Epoch 3, Step: 166, Loss: 0.10416833311319351, Lr:0.0001\n",
      "Epoch 3, Step: 167, Loss: 0.13182394206523895, Lr:0.0001\n",
      "Epoch 3, Step: 168, Loss: 0.40550053119659424, Lr:0.0001\n",
      "Epoch 3, Step: 169, Loss: 0.20977894961833954, Lr:0.0001\n",
      "Epoch 3, Step: 170, Loss: 0.13371948897838593, Lr:0.0001\n",
      "Epoch 3, Step: 171, Loss: 0.3001898527145386, Lr:0.0001\n",
      "Epoch 3, Step: 172, Loss: 0.3334961235523224, Lr:0.0001\n",
      "Epoch 3, Step: 173, Loss: 0.39384138584136963, Lr:0.0001\n",
      "Epoch 3, Step: 174, Loss: 0.2234826683998108, Lr:0.0001\n",
      "Epoch 3, Step: 175, Loss: 0.1600845456123352, Lr:0.0001\n",
      "Epoch 3, Step: 176, Loss: 0.12396760284900665, Lr:0.0001\n",
      "Epoch 3, Step: 177, Loss: 0.2143896073102951, Lr:0.0001\n",
      "Epoch 3, Step: 178, Loss: 0.44799792766571045, Lr:0.0001\n",
      "Epoch 3, Step: 179, Loss: 0.2704344093799591, Lr:0.0001\n",
      "Epoch 3, Step: 180, Loss: 0.19268813729286194, Lr:0.0001\n",
      "Epoch 3, Step: 181, Loss: 0.305203378200531, Lr:0.0001\n",
      "Epoch 3, Step: 182, Loss: 0.46613407135009766, Lr:0.0001\n",
      "Epoch 3, Step: 183, Loss: 0.16302286088466644, Lr:0.0001\n",
      "Epoch 3, Step: 184, Loss: 0.2766369879245758, Lr:0.0001\n",
      "Epoch 3, Step: 185, Loss: 0.579951822757721, Lr:0.0001\n",
      "Epoch 3, Step: 186, Loss: 0.20343708992004395, Lr:0.0001\n",
      "Epoch 3, Step: 187, Loss: 0.41529905796051025, Lr:0.0001\n",
      "Epoch 3, Step: 188, Loss: 0.6827968955039978, Lr:0.0001\n",
      "Epoch 3, Step: 189, Loss: 0.10438397526741028, Lr:0.0001\n",
      "Epoch 3, Step: 190, Loss: 0.1938047856092453, Lr:0.0001\n",
      "Epoch 3, Step: 191, Loss: 0.24381999671459198, Lr:0.0001\n",
      "Epoch 3, Step: 192, Loss: 0.7471660375595093, Lr:0.0001\n",
      "Epoch 3, Step: 193, Loss: 0.20266589522361755, Lr:0.0001\n",
      "Epoch 3, Step: 194, Loss: 0.1579207330942154, Lr:0.0001\n",
      "Epoch 3, Step: 195, Loss: 0.3224795162677765, Lr:0.0001\n",
      "Epoch 3, Step: 196, Loss: 0.26547205448150635, Lr:0.0001\n",
      "Epoch 3, Step: 197, Loss: 0.4509615898132324, Lr:0.0001\n",
      "Epoch 3, Step: 198, Loss: 0.3599449694156647, Lr:0.0001\n",
      "Epoch 3, Step: 199, Loss: 0.4441080391407013, Lr:0.0001\n",
      "Epoch 3, Step: 200, Loss: 0.410770982503891, Lr:0.0001\n",
      "Epoch 3, Step: 201, Loss: 0.2798307538032532, Lr:0.0001\n",
      "Epoch 3, Step: 202, Loss: 0.2310384213924408, Lr:0.0001\n",
      "Epoch 3, Step: 203, Loss: 0.14522846043109894, Lr:0.0001\n",
      "Epoch 3, Step: 204, Loss: 0.14306879043579102, Lr:0.0001\n",
      "Epoch 3, Step: 205, Loss: 0.37625786662101746, Lr:0.0001\n",
      "Epoch 3, Step: 206, Loss: 0.3153020739555359, Lr:0.0001\n",
      "Epoch 3, Step: 207, Loss: 0.18604117631912231, Lr:0.0001\n",
      "Epoch 3, Step: 208, Loss: 0.10536475479602814, Lr:0.0001\n",
      "Epoch 3, Step: 209, Loss: 0.2586977183818817, Lr:0.0001\n",
      "Epoch 3, Step: 210, Loss: 0.23490165174007416, Lr:0.0001\n",
      "Epoch 3, Step: 211, Loss: 0.6269901990890503, Lr:0.0001\n",
      "Epoch 3, Step: 212, Loss: 0.4640410542488098, Lr:0.0001\n",
      "Epoch 3, Step: 213, Loss: 0.34743010997772217, Lr:0.0001\n",
      "Epoch 3, Step: 214, Loss: 0.2696072459220886, Lr:0.0001\n",
      "Epoch 3, Step: 215, Loss: 0.1544845700263977, Lr:0.0001\n",
      "Epoch 3, Step: 216, Loss: 0.21260878443717957, Lr:0.0001\n",
      "Epoch 3, Step: 217, Loss: 0.07142128050327301, Lr:0.0001\n",
      "Epoch 3, Step: 218, Loss: 0.4249475598335266, Lr:0.0001\n",
      "Epoch 3, Step: 219, Loss: 0.30625858902931213, Lr:0.0001\n",
      "Epoch 3, Step: 220, Loss: 0.260883629322052, Lr:0.0001\n",
      "Epoch 3, Step: 221, Loss: 0.27786165475845337, Lr:0.0001\n",
      "Epoch 3, Step: 222, Loss: 0.12987026572227478, Lr:0.0001\n",
      "Epoch 3, Step: 223, Loss: 0.14883853495121002, Lr:0.0001\n",
      "Epoch 3, Step: 224, Loss: 0.21357361972332, Lr:0.0001\n",
      "Epoch 3, Step: 225, Loss: 0.5093055367469788, Lr:0.0001\n",
      "Epoch 3, Step: 226, Loss: 0.16668690741062164, Lr:0.0001\n",
      "Epoch 3, Step: 227, Loss: 0.12421993911266327, Lr:0.0001\n",
      "Epoch 3, Step: 228, Loss: 0.23425734043121338, Lr:0.0001\n",
      "Epoch 3, Step: 229, Loss: 0.1540071964263916, Lr:0.0001\n",
      "Epoch 3, Step: 230, Loss: 0.15327204763889313, Lr:0.0001\n",
      "Epoch 3, Step: 231, Loss: 0.20050275325775146, Lr:0.0001\n",
      "Epoch 3, Step: 232, Loss: 0.595253586769104, Lr:0.0001\n",
      "Epoch 3, Step: 233, Loss: 0.2298559844493866, Lr:0.0001\n",
      "Epoch 3, Step: 234, Loss: 0.536338210105896, Lr:0.0001\n",
      "Epoch 3, Step: 235, Loss: 0.34304356575012207, Lr:0.0001\n",
      "Epoch 3, Step: 236, Loss: 0.2755705416202545, Lr:0.0001\n",
      "Epoch 3, Step: 237, Loss: 0.3073127865791321, Lr:0.0001\n",
      "Epoch 3, Step: 238, Loss: 0.46980521082878113, Lr:0.0001\n",
      "Epoch 3, Step: 239, Loss: 0.28818002343177795, Lr:0.0001\n",
      "Epoch 3, Step: 240, Loss: 0.3879929184913635, Lr:0.0001\n",
      "Epoch 3, Step: 241, Loss: 0.464337557554245, Lr:0.0001\n",
      "Epoch 3, Step: 242, Loss: 0.18780839443206787, Lr:0.0001\n",
      "Epoch 3, Step: 243, Loss: 0.3262818157672882, Lr:0.0001\n",
      "Epoch 3, Step: 244, Loss: 0.24550706148147583, Lr:0.0001\n",
      "Epoch 3, Step: 245, Loss: 0.21727871894836426, Lr:0.0001\n",
      "Epoch 3, Step: 246, Loss: 0.37915778160095215, Lr:0.0001\n",
      "Epoch 3, Step: 247, Loss: 0.31523463129997253, Lr:0.0001\n",
      "Epoch 3, Step: 248, Loss: 0.32849961519241333, Lr:0.0001\n",
      "Epoch 3, Step: 249, Loss: 0.4546681344509125, Lr:0.0001\n",
      "Epoch 3, Step: 250, Loss: 0.1962646245956421, Lr:0.0001\n",
      "Epoch 3, Step: 251, Loss: 0.39644187688827515, Lr:0.0001\n",
      "Epoch 3, Step: 252, Loss: 0.1651196926832199, Lr:0.0001\n",
      "Epoch 3, Step: 253, Loss: 0.2494126856327057, Lr:0.0001\n",
      "Epoch 3, Step: 254, Loss: 0.22407059371471405, Lr:0.0001\n",
      "Epoch 3, Step: 255, Loss: 0.2973843812942505, Lr:0.0001\n",
      "Epoch 3, Step: 256, Loss: 0.44135594367980957, Lr:0.0001\n",
      "Epoch 3, Step: 257, Loss: 0.06580369174480438, Lr:0.0001\n",
      "Epoch 3, Step: 258, Loss: 0.35691577196121216, Lr:0.0001\n",
      "Epoch 3, Step: 259, Loss: 0.34470534324645996, Lr:0.0001\n",
      "Epoch 3, Step: 260, Loss: 0.2862232029438019, Lr:0.0001\n",
      "Epoch 3, Step: 261, Loss: 0.291165828704834, Lr:0.0001\n",
      "Epoch 3, Step: 262, Loss: 0.42001017928123474, Lr:0.0001\n",
      "Epoch 3, Step: 263, Loss: 0.25119754672050476, Lr:0.0001\n",
      "Epoch 3, Step: 264, Loss: 0.3975057601928711, Lr:0.0001\n",
      "Epoch 3, Step: 265, Loss: 0.08671340346336365, Lr:0.0001\n",
      "Epoch 3, Step: 266, Loss: 0.3620654344558716, Lr:0.0001\n",
      "Epoch 3, Step: 267, Loss: 0.34824395179748535, Lr:0.0001\n",
      "Epoch 3, Step: 268, Loss: 0.5395690202713013, Lr:0.0001\n",
      "Epoch 3, Step: 269, Loss: 0.3958069086074829, Lr:0.0001\n",
      "Epoch 3, Step: 270, Loss: 0.3752080500125885, Lr:0.0001\n",
      "Epoch 3, Step: 271, Loss: 0.34313276410102844, Lr:0.0001\n",
      "Epoch 3, Step: 272, Loss: 0.3509364128112793, Lr:0.0001\n",
      "Epoch 3, Step: 273, Loss: 0.14751315116882324, Lr:0.0001\n",
      "Epoch 3, Step: 274, Loss: 0.3434664011001587, Lr:0.0001\n",
      "Epoch 3, Step: 275, Loss: 0.17459115386009216, Lr:0.0001\n",
      "Epoch 3, Step: 276, Loss: 0.3511407673358917, Lr:0.0001\n",
      "Epoch 3, Step: 277, Loss: 0.121100053191185, Lr:0.0001\n",
      "Epoch 3, Step: 278, Loss: 0.24579325318336487, Lr:0.0001\n",
      "Epoch 3, Step: 279, Loss: 0.281934529542923, Lr:0.0001\n",
      "Epoch 3, Step: 280, Loss: 0.2567579746246338, Lr:0.0001\n",
      "Epoch 3, Step: 281, Loss: 0.3573814034461975, Lr:0.0001\n",
      "Epoch 3, Step: 282, Loss: 0.23568077385425568, Lr:0.0001\n",
      "Epoch 3, Step: 283, Loss: 0.24885298311710358, Lr:0.0001\n",
      "Epoch 3, Step: 284, Loss: 0.2946726083755493, Lr:0.0001\n",
      "Epoch 3, Step: 285, Loss: 0.845524787902832, Lr:0.0001\n",
      "Epoch 3, Step: 286, Loss: 0.39666301012039185, Lr:0.0001\n",
      "Epoch 3, Step: 287, Loss: 0.18871363997459412, Lr:0.0001\n",
      "Epoch 3, Step: 288, Loss: 0.25102630257606506, Lr:0.0001\n",
      "Epoch 3, Step: 289, Loss: 0.31583356857299805, Lr:0.0001\n",
      "Epoch 3, Step: 290, Loss: 0.3683485686779022, Lr:0.0001\n",
      "Epoch 3, Step: 291, Loss: 0.2242615818977356, Lr:0.0001\n",
      "Epoch 3, Step: 292, Loss: 0.2792559266090393, Lr:0.0001\n",
      "Epoch 3, Step: 293, Loss: 0.2182721048593521, Lr:0.0001\n",
      "Epoch 3, Step: 294, Loss: 0.2504327893257141, Lr:0.0001\n",
      "Epoch 3, Step: 295, Loss: 0.3069676160812378, Lr:0.0001\n",
      "Epoch 3, Step: 296, Loss: 0.6476580500602722, Lr:0.0001\n",
      "Epoch 3, Step: 297, Loss: 0.29895153641700745, Lr:0.0001\n",
      "Epoch 3, Step: 298, Loss: 0.2447933405637741, Lr:0.0001\n",
      "Epoch 3, Step: 299, Loss: 0.1966911256313324, Lr:0.0001\n",
      "Epoch 3, Step: 300, Loss: 0.28276610374450684, Lr:0.0001\n",
      "Epoch 3, Step: 301, Loss: 0.3667280972003937, Lr:0.0001\n",
      "Epoch 3, Step: 302, Loss: 0.16410472989082336, Lr:0.0001\n",
      "Epoch 3, Step: 303, Loss: 0.11718624085187912, Lr:0.0001\n",
      "Epoch 3, Step: 304, Loss: 0.21644048392772675, Lr:0.0001\n",
      "Epoch 3, Step: 305, Loss: 0.3972342908382416, Lr:0.0001\n",
      "Epoch 3, Step: 306, Loss: 0.48428598046302795, Lr:0.0001\n",
      "Epoch 3, Step: 307, Loss: 0.2012537568807602, Lr:0.0001\n",
      "Epoch 3, Step: 308, Loss: 0.28881019353866577, Lr:0.0001\n",
      "Epoch 3, Step: 309, Loss: 0.44318124651908875, Lr:0.0001\n",
      "Epoch 3, Step: 310, Loss: 0.45066094398498535, Lr:0.0001\n",
      "Epoch 3, Step: 311, Loss: 0.22126594185829163, Lr:0.0001\n",
      "Epoch 3, Step: 312, Loss: 0.23816843330860138, Lr:0.0001\n",
      "Epoch 3, Step: 313, Loss: 0.21748432517051697, Lr:0.0001\n",
      "Epoch 3, Step: 314, Loss: 0.39026403427124023, Lr:0.0001\n",
      "Epoch 3, Step: 315, Loss: 0.2840133607387543, Lr:0.0001\n",
      "Epoch 3, Step: 316, Loss: 0.6051836609840393, Lr:0.0001\n",
      "Epoch 3, Step: 317, Loss: 0.25015509128570557, Lr:0.0001\n",
      "Epoch 3, Step: 318, Loss: 0.21946540474891663, Lr:0.0001\n",
      "Epoch 3, Step: 319, Loss: 0.18592090904712677, Lr:0.0001\n",
      "Epoch 3, Step: 320, Loss: 0.09149092435836792, Lr:0.0001\n",
      "Epoch 3, Step: 321, Loss: 0.12835033237934113, Lr:0.0001\n",
      "Epoch 3, Step: 322, Loss: 0.13341613113880157, Lr:0.0001\n",
      "Epoch 3, Step: 323, Loss: 0.13790947198867798, Lr:0.0001\n",
      "Epoch 3, Step: 324, Loss: 0.2484346330165863, Lr:0.0001\n",
      "Epoch 3, Step: 325, Loss: 0.1673223078250885, Lr:0.0001\n",
      "Epoch 3, Step: 326, Loss: 0.16366392374038696, Lr:0.0001\n",
      "Epoch 3, Step: 327, Loss: 0.2657906413078308, Lr:0.0001\n",
      "Epoch 3, Step: 328, Loss: 0.13840539753437042, Lr:0.0001\n",
      "Epoch 3, Step: 329, Loss: 0.43265506625175476, Lr:0.0001\n",
      "Epoch 3, Step: 330, Loss: 0.1458180993795395, Lr:0.0001\n",
      "Epoch 3, Step: 331, Loss: 0.39860838651657104, Lr:0.0001\n",
      "Epoch 3, Step: 332, Loss: 0.1288737952709198, Lr:0.0001\n",
      "Epoch 3, Step: 333, Loss: 0.6952406764030457, Lr:0.0001\n",
      "Epoch 3, Step: 334, Loss: 0.45101600885391235, Lr:0.0001\n",
      "Epoch 3, Step: 335, Loss: 0.19707024097442627, Lr:0.0001\n",
      "Epoch 3, Step: 336, Loss: 0.24293720722198486, Lr:0.0001\n",
      "Epoch 3, Step: 337, Loss: 0.23813773691654205, Lr:0.0001\n",
      "Epoch 3, Step: 338, Loss: 0.15719863772392273, Lr:0.0001\n",
      "Epoch 3, Step: 339, Loss: 0.387568861246109, Lr:0.0001\n",
      "Epoch 3, Step: 340, Loss: 0.4684653580188751, Lr:0.0001\n",
      "Epoch 3, Step: 341, Loss: 0.35650044679641724, Lr:0.0001\n",
      "Epoch 3, Step: 342, Loss: 0.08412245661020279, Lr:0.0001\n",
      "Epoch 3, Step: 343, Loss: 0.39846906065940857, Lr:0.0001\n",
      "Epoch 3, Step: 344, Loss: 0.10203471779823303, Lr:0.0001\n",
      "Epoch 3, Step: 345, Loss: 0.2875829041004181, Lr:0.0001\n",
      "Epoch 3, Step: 346, Loss: 0.16677910089492798, Lr:0.0001\n",
      "Epoch 3, Step: 347, Loss: 0.19970545172691345, Lr:0.0001\n",
      "Epoch 3, Step: 348, Loss: 0.4295705258846283, Lr:0.0001\n",
      "Epoch 3, Step: 349, Loss: 0.4315516948699951, Lr:0.0001\n",
      "Epoch 3, Step: 350, Loss: 0.17508336901664734, Lr:0.0001\n",
      "Epoch 3, Step: 351, Loss: 0.8012076020240784, Lr:0.0001\n",
      "Epoch 3, Step: 352, Loss: 0.4218544065952301, Lr:0.0001\n",
      "Epoch 3, Step: 353, Loss: 0.2602200508117676, Lr:0.0001\n",
      "Epoch 3, Step: 354, Loss: 0.19638173282146454, Lr:0.0001\n",
      "Epoch 3, Step: 355, Loss: 0.2435159832239151, Lr:0.0001\n",
      "Epoch 3, Step: 356, Loss: 0.25938937067985535, Lr:0.0001\n",
      "Epoch 3, Step: 357, Loss: 0.20151609182357788, Lr:0.0001\n",
      "Epoch 3, Step: 358, Loss: 0.11187034100294113, Lr:0.0001\n",
      "Epoch 3, Step: 359, Loss: 0.42866384983062744, Lr:0.0001\n",
      "Epoch 3, Step: 360, Loss: 0.22202832996845245, Lr:0.0001\n",
      "Epoch 3, Step: 361, Loss: 0.2803047299385071, Lr:0.0001\n",
      "Epoch 3, Step: 362, Loss: 0.15812402963638306, Lr:0.0001\n",
      "Epoch 3, Step: 363, Loss: 0.15410174429416656, Lr:0.0001\n",
      "Epoch 3, Step: 364, Loss: 0.41587528586387634, Lr:0.0001\n",
      "Epoch 3, Step: 365, Loss: 0.3504548966884613, Lr:0.0001\n",
      "Epoch 3, Step: 366, Loss: 0.16146521270275116, Lr:0.0001\n",
      "Epoch 3, Step: 367, Loss: 0.2679400146007538, Lr:0.0001\n",
      "Epoch 3, Step: 368, Loss: 0.363951712846756, Lr:0.0001\n",
      "Epoch 3, Step: 369, Loss: 0.28292399644851685, Lr:0.0001\n",
      "Epoch 3, Step: 370, Loss: 0.21113698184490204, Lr:0.0001\n",
      "Epoch 3, Step: 371, Loss: 0.1336199790239334, Lr:0.0001\n",
      "Epoch 3, Step: 372, Loss: 0.6681104898452759, Lr:0.0001\n",
      "Epoch 3, Step: 373, Loss: 0.19211670756340027, Lr:0.0001\n",
      "Epoch 3, Step: 374, Loss: 0.2653177082538605, Lr:0.0001\n",
      "Epoch 3, Step: 375, Loss: 0.031544387340545654, Lr:0.0001\n",
      "Epoch 3, Step: 376, Loss: 0.4545004665851593, Lr:0.0001\n",
      "Epoch 3, Step: 377, Loss: 0.114337258040905, Lr:0.0001\n",
      "Epoch 3, Step: 378, Loss: 0.04349867254495621, Lr:0.0001\n",
      "Epoch 3, Step: 379, Loss: 0.29816800355911255, Lr:0.0001\n",
      "Epoch 3, Step: 380, Loss: 0.11288082599639893, Lr:0.0001\n",
      "Epoch 3, Step: 381, Loss: 0.2365541160106659, Lr:0.0001\n",
      "Epoch 3, Step: 382, Loss: 0.09369058907032013, Lr:0.0001\n",
      "Epoch 3, Step: 383, Loss: 0.5135200023651123, Lr:0.0001\n",
      "Epoch 3, Step: 384, Loss: 0.3012613356113434, Lr:0.0001\n",
      "Epoch 3, Step: 385, Loss: 0.547593355178833, Lr:0.0001\n",
      "Epoch 3, Step: 386, Loss: 0.4637293815612793, Lr:0.0001\n",
      "Epoch 3, Step: 387, Loss: 0.06351375579833984, Lr:0.0001\n",
      "Epoch 3, Step: 388, Loss: 0.10559947043657303, Lr:0.0001\n",
      "Epoch 3, Step: 389, Loss: 0.11979123204946518, Lr:0.0001\n",
      "Epoch 3, Step: 390, Loss: 0.4099385142326355, Lr:0.0001\n",
      "Epoch 3, Step: 391, Loss: 0.17703713476657867, Lr:0.0001\n",
      "Epoch 3, Step: 392, Loss: 0.5124493837356567, Lr:0.0001\n",
      "Epoch 3, Step: 393, Loss: 0.27713528275489807, Lr:0.0001\n",
      "Epoch 3, Step: 394, Loss: 0.21579821407794952, Lr:0.0001\n",
      "Epoch 3, Step: 395, Loss: 0.1213982030749321, Lr:0.0001\n",
      "Epoch 3, Step: 396, Loss: 0.39573922753334045, Lr:0.0001\n",
      "Epoch 3, Step: 397, Loss: 0.3558602035045624, Lr:0.0001\n",
      "Epoch 3, Step: 398, Loss: 0.5017433166503906, Lr:0.0001\n",
      "Epoch 3, Step: 399, Loss: 0.08728624135255814, Lr:0.0001\n",
      "Epoch 3, Step: 400, Loss: 0.4036034047603607, Lr:0.0001\n",
      "Epoch 3, Step: 401, Loss: 0.35614845156669617, Lr:0.0001\n",
      "Epoch 3, Step: 402, Loss: 0.16466325521469116, Lr:0.0001\n",
      "Epoch 3, Step: 403, Loss: 0.3792650103569031, Lr:0.0001\n",
      "Epoch 3, Step: 404, Loss: 0.660179853439331, Lr:0.0001\n",
      "Epoch 3, Step: 405, Loss: 0.4011928141117096, Lr:0.0001\n",
      "Epoch 3, Step: 406, Loss: 0.225575253367424, Lr:0.0001\n",
      "Epoch 3, Step: 407, Loss: 0.49856048822402954, Lr:0.0001\n",
      "Epoch 3, Step: 408, Loss: 0.16591361165046692, Lr:0.0001\n",
      "Epoch 3, Step: 409, Loss: 0.3173004984855652, Lr:0.0001\n",
      "Epoch 3, Step: 410, Loss: 0.2545124292373657, Lr:0.0001\n",
      "Epoch 3, Step: 411, Loss: 0.15107332170009613, Lr:0.0001\n",
      "Epoch 3, Step: 412, Loss: 0.20102575421333313, Lr:0.0001\n",
      "Epoch 3, Step: 413, Loss: 0.4264974296092987, Lr:0.0001\n",
      "Epoch 3, Step: 414, Loss: 0.12296076864004135, Lr:0.0001\n",
      "Epoch 3, Step: 415, Loss: 0.2931079864501953, Lr:0.0001\n",
      "Epoch 3, Step: 416, Loss: 0.14788565039634705, Lr:0.0001\n",
      "Epoch 3, Step: 417, Loss: 0.3593822121620178, Lr:0.0001\n",
      "Epoch 3, Step: 418, Loss: 0.2340320646762848, Lr:0.0001\n",
      "Epoch 3, Step: 419, Loss: 0.2193632274866104, Lr:0.0001\n",
      "Epoch 3, Step: 420, Loss: 0.1853196620941162, Lr:0.0001\n",
      "Epoch 3, Step: 421, Loss: 0.39266106486320496, Lr:0.0001\n",
      "Epoch 3, Step: 422, Loss: 0.4327317178249359, Lr:0.0001\n",
      "Epoch 3, Step: 423, Loss: 0.5185340642929077, Lr:0.0001\n",
      "Epoch 3, Step: 424, Loss: 0.6219098567962646, Lr:0.0001\n",
      "Epoch 3, Step: 425, Loss: 0.603015124797821, Lr:0.0001\n",
      "Epoch 3, Step: 426, Loss: 0.041152868419885635, Lr:0.0001\n",
      "Epoch 3, Step: 427, Loss: 0.35581421852111816, Lr:0.0001\n",
      "Epoch 3, Step: 428, Loss: 0.2664966881275177, Lr:0.0001\n",
      "Epoch 3, Step: 429, Loss: 0.25884535908699036, Lr:0.0001\n",
      "Epoch 3, Step: 430, Loss: 0.21187768876552582, Lr:0.0001\n",
      "Epoch 3, Step: 431, Loss: 0.2368224561214447, Lr:0.0001\n",
      "Epoch 3, Step: 432, Loss: 0.38738706707954407, Lr:0.0001\n",
      "Epoch 3, Step: 433, Loss: 0.4920928180217743, Lr:0.0001\n",
      "Epoch 3, Step: 434, Loss: 0.1516512781381607, Lr:0.0001\n",
      "Epoch 3, Step: 435, Loss: 0.11655381321907043, Lr:0.0001\n",
      "Epoch 3, Step: 436, Loss: 0.08973685652017593, Lr:0.0001\n",
      "Epoch 3, Step: 437, Loss: 0.11345259845256805, Lr:0.0001\n",
      "Epoch 3, Step: 438, Loss: 0.2682528793811798, Lr:0.0001\n",
      "Epoch 3, Step: 439, Loss: 0.2063407301902771, Lr:0.0001\n",
      "Epoch 3, Step: 440, Loss: 0.17074549198150635, Lr:0.0001\n",
      "Epoch 3, Step: 441, Loss: 0.4714561402797699, Lr:0.0001\n",
      "Epoch 3, Step: 442, Loss: 0.24033798277378082, Lr:0.0001\n",
      "Epoch 3, Step: 443, Loss: 0.2677321434020996, Lr:0.0001\n",
      "Epoch 3, Step: 444, Loss: 0.2509884834289551, Lr:0.0001\n",
      "Epoch 3, Step: 445, Loss: 0.3960445821285248, Lr:0.0001\n",
      "Epoch 3, Step: 446, Loss: 0.07658090442419052, Lr:0.0001\n",
      "Epoch 3, Step: 447, Loss: 0.26225441694259644, Lr:0.0001\n",
      "Epoch 3, Step: 448, Loss: 0.2516086995601654, Lr:0.0001\n",
      "Epoch 3, Step: 449, Loss: 0.13880790770053864, Lr:0.0001\n",
      "Epoch 3, Step: 450, Loss: 0.21593041718006134, Lr:0.0001\n",
      "Epoch 3, Step: 451, Loss: 0.17640070617198944, Lr:0.0001\n",
      "Epoch 3, Step: 452, Loss: 0.23453505337238312, Lr:0.0001\n",
      "Epoch 3, Step: 453, Loss: 0.2123860865831375, Lr:0.0001\n",
      "Epoch 3, Step: 454, Loss: 0.1430370956659317, Lr:0.0001\n",
      "Epoch 3, Step: 455, Loss: 0.15134991705417633, Lr:0.0001\n",
      "Epoch 3, Step: 456, Loss: 0.16739554703235626, Lr:0.0001\n",
      "Epoch 3, Step: 457, Loss: 0.07996457070112228, Lr:0.0001\n",
      "Epoch 3, Step: 458, Loss: 0.2561907172203064, Lr:0.0001\n",
      "Epoch 3, Step: 459, Loss: 0.09366054087877274, Lr:0.0001\n",
      "Epoch 3, Step: 460, Loss: 0.18408244848251343, Lr:0.0001\n",
      "Epoch 3, Step: 461, Loss: 0.3249962031841278, Lr:0.0001\n",
      "Epoch 3, Step: 462, Loss: 0.5827405452728271, Lr:0.0001\n",
      "Epoch 3, Step: 463, Loss: 0.38802385330200195, Lr:0.0001\n",
      "Epoch 3, Step: 464, Loss: 0.39623570442199707, Lr:0.0001\n",
      "Epoch 3, Step: 465, Loss: 0.1532798558473587, Lr:0.0001\n",
      "Epoch 3, Step: 466, Loss: 0.20040594041347504, Lr:0.0001\n",
      "Epoch 3, Step: 467, Loss: 0.09637594223022461, Lr:0.0001\n",
      "Epoch 3, Step: 468, Loss: 0.13664492964744568, Lr:0.0001\n",
      "Epoch 3, Step: 469, Loss: 0.18385645747184753, Lr:0.0001\n",
      "Epoch 3, Step: 470, Loss: 0.10861947387456894, Lr:0.0001\n",
      "Epoch 3, Step: 471, Loss: 0.07670015096664429, Lr:0.0001\n",
      "Epoch 3, Step: 472, Loss: 0.09646698087453842, Lr:0.0001\n",
      "Epoch 3, Step: 473, Loss: 0.5757375359535217, Lr:0.0001\n",
      "Epoch 3, Step: 474, Loss: 0.07709918916225433, Lr:0.0001\n",
      "Epoch 3, Step: 475, Loss: 0.38909897208213806, Lr:0.0001\n",
      "Epoch 3, Step: 476, Loss: 0.2952868640422821, Lr:0.0001\n",
      "Epoch 3, Step: 477, Loss: 0.2052915245294571, Lr:0.0001\n",
      "Epoch 3, Step: 478, Loss: 0.7353595495223999, Lr:0.0001\n",
      "Epoch 3, Step: 479, Loss: 0.14656755328178406, Lr:0.0001\n",
      "Epoch 3, Step: 480, Loss: 0.07099748402833939, Lr:0.0001\n",
      "Epoch 3, Step: 481, Loss: 0.11300927400588989, Lr:0.0001\n",
      "Epoch 3, Step: 482, Loss: 0.18485483527183533, Lr:0.0001\n",
      "Epoch 3, Step: 483, Loss: 0.16179534792900085, Lr:0.0001\n",
      "Epoch 3, Step: 484, Loss: 0.16380570828914642, Lr:0.0001\n",
      "Epoch 3, Step: 485, Loss: 0.1265188455581665, Lr:0.0001\n",
      "Epoch 3, Step: 486, Loss: 0.5073447227478027, Lr:0.0001\n",
      "Epoch 3, Step: 487, Loss: 0.2551653981208801, Lr:0.0001\n",
      "Epoch 3, Step: 488, Loss: 0.3282802700996399, Lr:0.0001\n",
      "Epoch 3, Step: 489, Loss: 0.26328709721565247, Lr:0.0001\n",
      "Epoch 3, Step: 490, Loss: 0.7573024034500122, Lr:0.0001\n",
      "Epoch 3, Step: 491, Loss: 0.279163122177124, Lr:0.0001\n",
      "Epoch 3, Step: 492, Loss: 0.12290330976247787, Lr:0.0001\n",
      "Epoch 3, Step: 493, Loss: 0.21614576876163483, Lr:0.0001\n",
      "Epoch 3, Step: 494, Loss: 0.47089624404907227, Lr:0.0001\n",
      "Epoch 3, Step: 495, Loss: 0.6889445781707764, Lr:0.0001\n",
      "Epoch 3, Step: 496, Loss: 0.6684808135032654, Lr:0.0001\n",
      "Epoch 3, Step: 497, Loss: 0.239369198679924, Lr:0.0001\n",
      "Epoch 3, Step: 498, Loss: 0.19688481092453003, Lr:0.0001\n",
      "Epoch 3, Step: 499, Loss: 0.6202886700630188, Lr:0.0001\n",
      "Epoch 3, Step: 500, Loss: 0.11297738552093506, Lr:0.0001\n",
      "Epoch 3, Step: 501, Loss: 0.31024473905563354, Lr:0.0001\n",
      "Epoch 3, Step: 502, Loss: 0.31849759817123413, Lr:0.0001\n",
      "Epoch 3, Step: 503, Loss: 0.4583872854709625, Lr:0.0001\n",
      "Epoch 3, Step: 504, Loss: 0.2311497926712036, Lr:0.0001\n",
      "Epoch 3, Step: 505, Loss: 0.15395794808864594, Lr:0.0001\n",
      "Epoch 3, Step: 506, Loss: 0.27338317036628723, Lr:0.0001\n",
      "Epoch 3, Step: 507, Loss: 0.34401994943618774, Lr:0.0001\n",
      "Epoch 3, Step: 508, Loss: 0.1398351639509201, Lr:0.0001\n",
      "Epoch 3, Step: 509, Loss: 0.265000581741333, Lr:0.0001\n",
      "Epoch 3, Step: 510, Loss: 0.4894897937774658, Lr:0.0001\n",
      "Epoch 3, Step: 511, Loss: 0.4373709559440613, Lr:0.0001\n",
      "Epoch 3, Step: 512, Loss: 0.23310308158397675, Lr:0.0001\n",
      "Epoch 3, Step: 513, Loss: 0.4643879532814026, Lr:0.0001\n",
      "Epoch 3, Step: 514, Loss: 0.41358402371406555, Lr:0.0001\n",
      "Epoch 3, Step: 515, Loss: 0.3463357985019684, Lr:0.0001\n",
      "Epoch 3, Step: 516, Loss: 0.4552094340324402, Lr:0.0001\n",
      "Epoch 3, Step: 517, Loss: 0.17947128415107727, Lr:0.0001\n",
      "Epoch 3, Step: 518, Loss: 0.20783351361751556, Lr:0.0001\n",
      "Epoch 3, Step: 519, Loss: 0.12751035392284393, Lr:0.0001\n",
      "Epoch 3, Step: 520, Loss: 0.1730915606021881, Lr:0.0001\n",
      "Epoch 3, Step: 521, Loss: 0.17642360925674438, Lr:0.0001\n",
      "Epoch 3, Step: 522, Loss: 0.14351633191108704, Lr:0.0001\n",
      "Epoch 3, Step: 523, Loss: 0.147195503115654, Lr:0.0001\n",
      "Epoch 3, Step: 524, Loss: 0.3760761022567749, Lr:0.0001\n",
      "Epoch 3, Step: 525, Loss: 0.2378920167684555, Lr:0.0001\n",
      "Epoch 3, Step: 526, Loss: 0.32461750507354736, Lr:0.0001\n",
      "Epoch 3, Step: 527, Loss: 0.6716874837875366, Lr:0.0001\n",
      "Epoch 3, Step: 528, Loss: 0.275863915681839, Lr:0.0001\n",
      "Epoch 3, Step: 529, Loss: 0.4390348792076111, Lr:0.0001\n",
      "Epoch 3, Step: 530, Loss: 0.5863835215568542, Lr:0.0001\n",
      "Epoch 3, Step: 531, Loss: 0.11346469074487686, Lr:0.0001\n",
      "Epoch 3, Step: 532, Loss: 0.2559761703014374, Lr:0.0001\n",
      "Epoch 3, Step: 533, Loss: 0.17492713034152985, Lr:0.0001\n",
      "Epoch 3, Step: 534, Loss: 0.15771958231925964, Lr:0.0001\n",
      "Epoch 3, Step: 535, Loss: 0.25841790437698364, Lr:0.0001\n",
      "Epoch 3, Step: 536, Loss: 0.2857709527015686, Lr:0.0001\n",
      "Epoch 3, Step: 537, Loss: 0.3897658884525299, Lr:0.0001\n",
      "Epoch 3, Step: 538, Loss: 0.3482537567615509, Lr:0.0001\n",
      "Epoch 3, Step: 539, Loss: 0.11232441663742065, Lr:0.0001\n",
      "Epoch 3, Step: 540, Loss: 0.11252020299434662, Lr:0.0001\n",
      "Epoch 3, Step: 541, Loss: 0.18358950316905975, Lr:0.0001\n",
      "Epoch 3, Step: 542, Loss: 0.41139012575149536, Lr:0.0001\n",
      "Epoch 3, Step: 543, Loss: 0.31437474489212036, Lr:0.0001\n",
      "Epoch 3, Step: 544, Loss: 0.41517800092697144, Lr:0.0001\n",
      "Epoch 3, Step: 545, Loss: 0.2915060818195343, Lr:0.0001\n",
      "Epoch 3, Step: 546, Loss: 0.17743860185146332, Lr:0.0001\n",
      "Epoch 3, Step: 547, Loss: 0.23699204623699188, Lr:0.0001\n",
      "Epoch 3, Step: 548, Loss: 0.4416823983192444, Lr:0.0001\n",
      "Epoch 3, Step: 549, Loss: 0.177107036113739, Lr:0.0001\n",
      "Epoch 3, Step: 550, Loss: 0.19291849434375763, Lr:0.0001\n",
      "Epoch 3, Step: 551, Loss: 0.7558726072311401, Lr:0.0001\n",
      "Epoch 3, Step: 552, Loss: 0.5457733869552612, Lr:0.0001\n",
      "Epoch 3, Step: 553, Loss: 0.3406246602535248, Lr:0.0001\n",
      "Epoch 3, Step: 554, Loss: 0.27833420038223267, Lr:0.0001\n",
      "Epoch 3, Step: 555, Loss: 0.11176459491252899, Lr:0.0001\n",
      "Epoch 3, Step: 556, Loss: 0.1262146234512329, Lr:0.0001\n",
      "Epoch 3, Step: 557, Loss: 0.16566836833953857, Lr:0.0001\n",
      "Epoch 3, Step: 558, Loss: 0.2304190993309021, Lr:0.0001\n",
      "Epoch 3, Step: 559, Loss: 0.3167751431465149, Lr:0.0001\n",
      "Epoch 3, Step: 560, Loss: 0.15482451021671295, Lr:0.0001\n",
      "Epoch 3, Step: 561, Loss: 0.29451099038124084, Lr:0.0001\n",
      "Epoch 3, Step: 562, Loss: 0.15541338920593262, Lr:0.0001\n",
      "Epoch 3, Step: 563, Loss: 0.23433434963226318, Lr:0.0001\n",
      "Epoch 3, Step: 564, Loss: 0.4745436906814575, Lr:0.0001\n",
      "Epoch 3, Step: 565, Loss: 0.6627334356307983, Lr:0.0001\n",
      "Epoch 3, Step: 566, Loss: 0.18738849461078644, Lr:0.0001\n",
      "Epoch 3, Step: 567, Loss: 0.05881113559007645, Lr:0.0001\n",
      "Epoch 3, Step: 568, Loss: 0.25035151839256287, Lr:0.0001\n",
      "Epoch 3, Step: 569, Loss: 0.27252230048179626, Lr:0.0001\n",
      "Epoch 3, Step: 570, Loss: 0.43343618512153625, Lr:0.0001\n",
      "Epoch 3, Step: 571, Loss: 0.3665452301502228, Lr:0.0001\n",
      "Epoch 3, Step: 572, Loss: 0.1893872320652008, Lr:0.0001\n",
      "Epoch 3, Step: 573, Loss: 0.4101882576942444, Lr:0.0001\n",
      "Epoch 3, Step: 574, Loss: 0.3469691872596741, Lr:0.0001\n",
      "Epoch 3, Step: 575, Loss: 0.1752920150756836, Lr:0.0001\n",
      "Epoch 3, Step: 576, Loss: 0.20519551634788513, Lr:0.0001\n",
      "Epoch 3, Step: 577, Loss: 0.5210062861442566, Lr:0.0001\n",
      "Epoch 3, Step: 578, Loss: 0.2685919404029846, Lr:0.0001\n",
      "Epoch 3, Step: 579, Loss: 0.3073699176311493, Lr:0.0001\n",
      "Epoch 3, Step: 580, Loss: 0.1491066813468933, Lr:0.0001\n",
      "Epoch 3, Step: 581, Loss: 0.3091239631175995, Lr:0.0001\n",
      "Epoch 3, Step: 582, Loss: 0.30837753415107727, Lr:0.0001\n",
      "Epoch 3, Step: 583, Loss: 0.19528786838054657, Lr:0.0001\n",
      "Epoch 3, Step: 584, Loss: 0.34665632247924805, Lr:0.0001\n",
      "Epoch 3, Step: 585, Loss: 0.19849833846092224, Lr:0.0001\n",
      "Epoch 3, Step: 586, Loss: 0.26698237657546997, Lr:0.0001\n",
      "Epoch 3, Step: 587, Loss: 0.46735185384750366, Lr:0.0001\n",
      "Epoch 3, Step: 588, Loss: 0.12735050916671753, Lr:0.0001\n",
      "Epoch 3, Step: 589, Loss: 0.15709546208381653, Lr:0.0001\n",
      "Epoch 3, Step: 590, Loss: 0.10932474583387375, Lr:0.0001\n",
      "Epoch 3, Step: 591, Loss: 0.41207993030548096, Lr:0.0001\n",
      "Epoch 3, Step: 592, Loss: 0.20503923296928406, Lr:0.0001\n",
      "Epoch 3, Step: 593, Loss: 0.1793511062860489, Lr:0.0001\n",
      "Epoch 3, Step: 594, Loss: 0.1499389410018921, Lr:0.0001\n",
      "Epoch 3, Step: 595, Loss: 0.5135636329650879, Lr:0.0001\n",
      "Epoch 3, Step: 596, Loss: 0.13247092068195343, Lr:0.0001\n",
      "Epoch 3, Step: 597, Loss: 0.4419645667076111, Lr:0.0001\n",
      "Epoch 3, Step: 598, Loss: 0.2930296063423157, Lr:0.0001\n",
      "Epoch 3, Step: 599, Loss: 0.31299737095832825, Lr:0.0001\n",
      "Epoch 3, Step: 600, Loss: 0.13055062294006348, Lr:0.0001\n",
      "Epoch 3, Step: 601, Loss: 0.28467264771461487, Lr:0.0001\n",
      "Epoch 3, Step: 602, Loss: 0.13507215678691864, Lr:0.0001\n",
      "Epoch 3, Step: 603, Loss: 0.1397416591644287, Lr:0.0001\n",
      "Epoch 3, Step: 604, Loss: 1.6352249383926392, Lr:0.0001\n",
      "Epoch 3, Step: 605, Loss: 0.6549120545387268, Lr:0.0001\n",
      "Epoch 3, Step: 606, Loss: 0.5732710361480713, Lr:0.0001\n",
      "Epoch 3, Step: 607, Loss: 0.33795586228370667, Lr:0.0001\n",
      "Epoch 3, Step: 608, Loss: 0.4290406405925751, Lr:0.0001\n",
      "Epoch 3, Step: 609, Loss: 0.3529745638370514, Lr:0.0001\n",
      "Epoch 3, Step: 610, Loss: 0.41316846013069153, Lr:0.0001\n",
      "Epoch 3, Step: 611, Loss: 0.42823147773742676, Lr:0.0001\n",
      "Epoch 3, Step: 612, Loss: 0.11051961034536362, Lr:0.0001\n",
      "Epoch 3, Step: 613, Loss: 0.35103484988212585, Lr:0.0001\n",
      "Epoch 3, Step: 614, Loss: 0.2880025804042816, Lr:0.0001\n",
      "Epoch 3, Step: 615, Loss: 0.4761831760406494, Lr:0.0001\n",
      "Epoch 3, Step: 616, Loss: 0.5452257394790649, Lr:0.0001\n",
      "Epoch 3, Step: 617, Loss: 0.23545728623867035, Lr:0.0001\n",
      "Epoch 3, Step: 618, Loss: 0.11916177719831467, Lr:0.0001\n",
      "Epoch 3, Step: 619, Loss: 0.288411408662796, Lr:0.0001\n",
      "Epoch 3, Step: 620, Loss: 0.6519858241081238, Lr:0.0001\n",
      "Epoch 3, Step: 621, Loss: 0.1804269254207611, Lr:0.0001\n",
      "Epoch 3, Step: 622, Loss: 0.24078696966171265, Lr:0.0001\n",
      "Epoch 3, Step: 623, Loss: 0.21244893968105316, Lr:0.0001\n",
      "Epoch 3, Step: 624, Loss: 0.4829680025577545, Lr:0.0001\n",
      "Epoch 3, Step: 625, Loss: 0.21069443225860596, Lr:0.0001\n",
      "Epoch 3, Step: 626, Loss: 0.0865238755941391, Lr:0.0001\n",
      "Epoch 3, Step: 627, Loss: 0.33033809065818787, Lr:0.0001\n",
      "Epoch 3, Step: 628, Loss: 0.4978058338165283, Lr:0.0001\n",
      "Epoch 3, Step: 629, Loss: 0.2066788226366043, Lr:0.0001\n",
      "Epoch 3, Step: 630, Loss: 0.3025533854961395, Lr:0.0001\n",
      "Epoch 3, Step: 631, Loss: 0.11393885314464569, Lr:0.0001\n",
      "Epoch 3, Step: 632, Loss: 0.5714307427406311, Lr:0.0001\n",
      "Epoch 3, Step: 633, Loss: 0.3671649098396301, Lr:0.0001\n",
      "Epoch 3, Step: 634, Loss: 0.27313077449798584, Lr:0.0001\n",
      "Epoch 3, Step: 635, Loss: 0.30583661794662476, Lr:0.0001\n",
      "Epoch 3, Step: 636, Loss: 0.36959463357925415, Lr:0.0001\n",
      "Epoch 3, Step: 637, Loss: 0.24854406714439392, Lr:0.0001\n",
      "Epoch 3, Step: 638, Loss: 0.3647625148296356, Lr:0.0001\n",
      "Epoch 3, Step: 639, Loss: 0.43891268968582153, Lr:0.0001\n",
      "Epoch 3, Step: 640, Loss: 0.20802947878837585, Lr:0.0001\n",
      "Epoch 3, Step: 641, Loss: 0.07673099637031555, Lr:0.0001\n",
      "Epoch 3, Step: 642, Loss: 0.36832377314567566, Lr:0.0001\n",
      "Epoch 3, Step: 643, Loss: 0.26447588205337524, Lr:0.0001\n",
      "Epoch 3, Step: 644, Loss: 0.31035417318344116, Lr:0.0001\n",
      "Epoch 3, Step: 645, Loss: 0.3510408103466034, Lr:0.0001\n",
      "Epoch 3, Step: 646, Loss: 0.2232183963060379, Lr:0.0001\n",
      "Epoch 3, Step: 647, Loss: 0.23296479880809784, Lr:0.0001\n",
      "Epoch 3, Step: 648, Loss: 0.29263004660606384, Lr:0.0001\n",
      "Epoch 3, Step: 649, Loss: 0.2059568613767624, Lr:0.0001\n",
      "Epoch 3, Step: 650, Loss: 0.4086765944957733, Lr:0.0001\n",
      "Epoch 3, Step: 651, Loss: 0.5830479264259338, Lr:0.0001\n",
      "Epoch 3, Step: 652, Loss: 0.46094977855682373, Lr:0.0001\n",
      "Epoch 3, Step: 653, Loss: 0.30918318033218384, Lr:0.0001\n",
      "Epoch 3, Step: 654, Loss: 0.3946230709552765, Lr:0.0001\n",
      "Epoch 3, Step: 655, Loss: 0.2997663617134094, Lr:0.0001\n",
      "Epoch 3, Step: 656, Loss: 0.22926506400108337, Lr:0.0001\n",
      "Epoch 3, Step: 657, Loss: 0.22521188855171204, Lr:0.0001\n",
      "Epoch 3, Step: 658, Loss: 0.2959096431732178, Lr:0.0001\n",
      "Epoch 3, Step: 659, Loss: 0.33957988023757935, Lr:0.0001\n",
      "Epoch 3, Step: 660, Loss: 0.3523470461368561, Lr:0.0001\n",
      "Epoch 3, Step: 661, Loss: 0.25467297434806824, Lr:0.0001\n",
      "Epoch 3, Step: 662, Loss: 0.21007582545280457, Lr:0.0001\n",
      "Epoch 3, Step: 663, Loss: 0.3257477581501007, Lr:0.0001\n",
      "Epoch 3, Step: 664, Loss: 0.3678685128688812, Lr:0.0001\n",
      "Epoch 3, Step: 665, Loss: 0.3828907608985901, Lr:0.0001\n",
      "Epoch 3, Step: 666, Loss: 0.32342714071273804, Lr:0.0001\n",
      "Epoch 3, Step: 667, Loss: 0.43435361981391907, Lr:0.0001\n",
      "Epoch 3, Step: 668, Loss: 0.29668569564819336, Lr:0.0001\n",
      "Epoch 3, Step: 669, Loss: 0.2338014394044876, Lr:0.0001\n",
      "Epoch 3, Step: 670, Loss: 0.16140107810497284, Lr:0.0001\n",
      "Epoch 3, Step: 671, Loss: 0.11687177419662476, Lr:0.0001\n",
      "Epoch 3, Step: 672, Loss: 0.604463517665863, Lr:0.0001\n",
      "Epoch 3, Step: 673, Loss: 0.4332607388496399, Lr:0.0001\n",
      "Epoch 3, Step: 674, Loss: 0.3447181284427643, Lr:0.0001\n",
      "Epoch 3, Step: 675, Loss: 0.23505143821239471, Lr:0.0001\n",
      "Epoch 3, Step: 676, Loss: 0.24607108533382416, Lr:0.0001\n",
      "Epoch 3, Step: 677, Loss: 0.6217380166053772, Lr:0.0001\n",
      "Epoch 3, Step: 678, Loss: 0.2914343476295471, Lr:0.0001\n",
      "Epoch 3, Step: 679, Loss: 0.2933799922466278, Lr:0.0001\n",
      "Epoch 3, Step: 680, Loss: 0.24690911173820496, Lr:0.0001\n",
      "Epoch 3, Step: 681, Loss: 0.1840793937444687, Lr:0.0001\n",
      "Epoch 3, Step: 682, Loss: 0.33258429169654846, Lr:0.0001\n",
      "Epoch 3, Step: 683, Loss: 0.24649755656719208, Lr:0.0001\n",
      "Epoch 3, Step: 684, Loss: 0.17027923464775085, Lr:0.0001\n",
      "Epoch 3, Step: 685, Loss: 0.34653329849243164, Lr:0.0001\n",
      "Epoch 3, Step: 686, Loss: 0.147771954536438, Lr:0.0001\n",
      "Epoch 3, Step: 687, Loss: 0.23435497283935547, Lr:0.0001\n",
      "Epoch 3, Step: 688, Loss: 0.23861098289489746, Lr:0.0001\n",
      "Epoch 3, Step: 689, Loss: 0.09342591464519501, Lr:0.0001\n",
      "Epoch 3, Step: 690, Loss: 0.40125784277915955, Lr:0.0001\n",
      "Epoch 3, Step: 691, Loss: 0.15525424480438232, Lr:0.0001\n",
      "Epoch 3, Step: 692, Loss: 0.19389383494853973, Lr:0.0001\n",
      "Epoch 3, Step: 693, Loss: 0.26995721459388733, Lr:0.0001\n",
      "Epoch 3, Step: 694, Loss: 0.22382043302059174, Lr:0.0001\n",
      "Epoch 3, Step: 695, Loss: 0.286892831325531, Lr:0.0001\n",
      "Epoch 3, Step: 696, Loss: 0.15861083567142487, Lr:0.0001\n",
      "Epoch 3, Step: 697, Loss: 0.09100174903869629, Lr:0.0001\n",
      "Epoch 3, Step: 698, Loss: 0.06630994379520416, Lr:0.0001\n",
      "Epoch 3, Step: 699, Loss: 0.2865004539489746, Lr:0.0001\n",
      "Epoch 3, Step: 700, Loss: 0.15955084562301636, Lr:0.0001\n",
      "Epoch 3, Step: 701, Loss: 0.048222851008176804, Lr:0.0001\n",
      "Epoch 3, Step: 702, Loss: 0.16634513437747955, Lr:0.0001\n",
      "Epoch 3, Step: 703, Loss: 0.188913494348526, Lr:0.0001\n",
      "Epoch 3, Step: 704, Loss: 0.10621678829193115, Lr:0.0001\n",
      "Epoch 3, Step: 705, Loss: 0.13409458100795746, Lr:0.0001\n",
      "Epoch 3, Step: 706, Loss: 0.1990026831626892, Lr:0.0001\n",
      "Epoch 3, Step: 707, Loss: 0.15045857429504395, Lr:0.0001\n",
      "Epoch 3, Step: 708, Loss: 0.35998931527137756, Lr:0.0001\n",
      "Epoch 3, Step: 709, Loss: 0.35542577505111694, Lr:0.0001\n",
      "Epoch 3, Step: 710, Loss: 0.2368006408214569, Lr:0.0001\n",
      "Epoch 3, Step: 711, Loss: 0.33773982524871826, Lr:0.0001\n",
      "Epoch 3, Step: 712, Loss: 0.4072960615158081, Lr:0.0001\n",
      "Epoch 3, Step: 713, Loss: 0.06370729207992554, Lr:0.0001\n",
      "Epoch 3, Step: 714, Loss: 0.4704095721244812, Lr:0.0001\n",
      "Epoch 3, Step: 715, Loss: 0.3717448115348816, Lr:0.0001\n",
      "Epoch 3, Step: 716, Loss: 0.38426539301872253, Lr:0.0001\n",
      "Epoch 3, Step: 717, Loss: 0.13917933404445648, Lr:0.0001\n",
      "Epoch 3, Step: 718, Loss: 0.18404598534107208, Lr:0.0001\n",
      "Epoch 3, Step: 719, Loss: 0.20795156061649323, Lr:0.0001\n",
      "Epoch 3, Step: 720, Loss: 0.2168993055820465, Lr:0.0001\n",
      "Epoch 3, Step: 721, Loss: 0.1274951547384262, Lr:0.0001\n",
      "Epoch 3, Step: 722, Loss: 0.346697598695755, Lr:0.0001\n",
      "Epoch 3, Step: 723, Loss: 0.5142989158630371, Lr:0.0001\n",
      "Epoch 3, Step: 724, Loss: 0.20345182716846466, Lr:0.0001\n",
      "Epoch 3, Step: 725, Loss: 0.12961870431900024, Lr:0.0001\n",
      "Epoch 3, Step: 726, Loss: 0.44706618785858154, Lr:0.0001\n",
      "Epoch 3, Step: 727, Loss: 0.5871406197547913, Lr:0.0001\n",
      "Epoch 3, Step: 728, Loss: 0.3643327057361603, Lr:0.0001\n",
      "Epoch 3, Step: 729, Loss: 0.09229305386543274, Lr:0.0001\n",
      "Epoch 3, Step: 730, Loss: 0.21847222745418549, Lr:0.0001\n",
      "Epoch 3, Step: 731, Loss: 0.09010171890258789, Lr:0.0001\n",
      "Epoch 3, Step: 732, Loss: 0.060116011649370193, Lr:0.0001\n",
      "Epoch 3, Step: 733, Loss: 0.23361638188362122, Lr:0.0001\n",
      "Epoch 3, Step: 734, Loss: 0.1744937002658844, Lr:0.0001\n",
      "Epoch 3, Step: 735, Loss: 0.47613877058029175, Lr:0.0001\n",
      "Epoch 3, Step: 736, Loss: 0.46560588479042053, Lr:0.0001\n",
      "Epoch 3, Step: 737, Loss: 0.46849972009658813, Lr:0.0001\n",
      "Epoch 3, Step: 738, Loss: 0.22805416584014893, Lr:0.0001\n",
      "Epoch 3, Step: 739, Loss: 0.030123425647616386, Lr:0.0001\n",
      "Epoch 3, Step: 740, Loss: 0.65456223487854, Lr:0.0001\n",
      "Epoch 3, Step: 741, Loss: 0.23632052540779114, Lr:0.0001\n",
      "Epoch 3, Step: 742, Loss: 0.2810559570789337, Lr:0.0001\n",
      "Epoch 3, Step: 743, Loss: 0.1670359969139099, Lr:0.0001\n",
      "Epoch 3, Step: 744, Loss: 0.2826308012008667, Lr:0.0001\n",
      "Epoch 3, Step: 745, Loss: 0.12288322299718857, Lr:0.0001\n",
      "Epoch 3, Step: 746, Loss: 0.32506728172302246, Lr:0.0001\n",
      "Epoch 3, Step: 747, Loss: 0.1436617523431778, Lr:0.0001\n",
      "Epoch 3, Step: 748, Loss: 0.4426290988922119, Lr:0.0001\n",
      "Epoch 3, Step: 749, Loss: 0.16868259012699127, Lr:0.0001\n",
      "Epoch 3, Step: 750, Loss: 0.47872331738471985, Lr:0.0001\n",
      "Epoch 3, Step: 751, Loss: 0.10776671022176743, Lr:0.0001\n",
      "Epoch 3, Step: 752, Loss: 0.3196795582771301, Lr:0.0001\n",
      "Epoch 3, Step: 753, Loss: 0.34781137108802795, Lr:0.0001\n",
      "Epoch 3, Step: 754, Loss: 0.6421977281570435, Lr:0.0001\n",
      "Epoch 3, Step: 755, Loss: 0.3283088803291321, Lr:0.0001\n",
      "Epoch 3, Step: 756, Loss: 0.14666873216629028, Lr:0.0001\n",
      "Epoch 3, Step: 757, Loss: 0.4289284944534302, Lr:0.0001\n",
      "Epoch 3, Step: 758, Loss: 0.21876531839370728, Lr:0.0001\n",
      "Epoch 3, Step: 759, Loss: 0.12355893105268478, Lr:0.0001\n",
      "Epoch 3, Step: 760, Loss: 0.18468084931373596, Lr:0.0001\n",
      "Epoch 3, Step: 761, Loss: 0.06423825025558472, Lr:0.0001\n",
      "Epoch 3, Step: 762, Loss: 0.1656763106584549, Lr:0.0001\n",
      "Epoch 3, Step: 763, Loss: 0.4578801989555359, Lr:0.0001\n",
      "Epoch 3, Step: 764, Loss: 0.1542627215385437, Lr:0.0001\n",
      "Epoch 3, Step: 765, Loss: 0.4342390298843384, Lr:0.0001\n",
      "Epoch 3, Step: 766, Loss: 0.4520540237426758, Lr:0.0001\n",
      "Epoch 3, Step: 767, Loss: 0.10184133052825928, Lr:0.0001\n",
      "Epoch 3, Step: 768, Loss: 0.2362566590309143, Lr:0.0001\n",
      "Epoch 3, Step: 769, Loss: 0.07691816985607147, Lr:0.0001\n",
      "Epoch 3, Step: 770, Loss: 0.19846691191196442, Lr:0.0001\n",
      "Epoch 3, Step: 771, Loss: 0.16815155744552612, Lr:0.0001\n",
      "Epoch 3, Step: 772, Loss: 0.3859953284263611, Lr:0.0001\n",
      "Epoch 3, Step: 773, Loss: 0.2895686626434326, Lr:0.0001\n",
      "Epoch 3, Step: 774, Loss: 0.47893965244293213, Lr:0.0001\n",
      "Epoch 3, Step: 775, Loss: 0.14714930951595306, Lr:0.0001\n",
      "Epoch 3, Step: 776, Loss: 0.1261289119720459, Lr:0.0001\n",
      "Epoch 3, Step: 777, Loss: 0.46910977363586426, Lr:0.0001\n",
      "Epoch 3, Step: 778, Loss: 0.4828258454799652, Lr:0.0001\n",
      "Epoch 3, Step: 779, Loss: 0.16896694898605347, Lr:0.0001\n",
      "Epoch 3, Step: 780, Loss: 0.04206933453679085, Lr:0.0001\n",
      "Epoch 3, Step: 781, Loss: 0.24241036176681519, Lr:0.0001\n",
      "Epoch 3, Step: 782, Loss: 0.6727311611175537, Lr:0.0001\n",
      "Epoch 3, Step: 783, Loss: 0.25896114110946655, Lr:0.0001\n",
      "Epoch 3, Step: 784, Loss: 0.29959994554519653, Lr:0.0001\n",
      "Epoch 3, Step: 785, Loss: 0.14448776841163635, Lr:0.0001\n",
      "Epoch 3, Step: 786, Loss: 0.30513301491737366, Lr:0.0001\n",
      "Epoch 3, Step: 787, Loss: 0.3747701048851013, Lr:0.0001\n",
      "Epoch 3, Step: 788, Loss: 0.3675191402435303, Lr:0.0001\n",
      "Epoch 3, Step: 789, Loss: 0.2371816337108612, Lr:0.0001\n",
      "Epoch 3, Step: 790, Loss: 0.17848190665245056, Lr:0.0001\n",
      "Epoch 3, Step: 791, Loss: 0.32798999547958374, Lr:0.0001\n",
      "Epoch 3, Step: 792, Loss: 0.19573603570461273, Lr:0.0001\n",
      "Epoch 3, Step: 793, Loss: 0.4014763832092285, Lr:0.0001\n",
      "Epoch 3, Step: 794, Loss: 0.24472227692604065, Lr:0.0001\n",
      "Epoch 3, Step: 795, Loss: 0.23886562883853912, Lr:0.0001\n",
      "Epoch 3, Step: 796, Loss: 0.5592867732048035, Lr:0.0001\n",
      "Epoch 3, Step: 797, Loss: 0.05565604194998741, Lr:0.0001\n",
      "Epoch 3, Step: 798, Loss: 0.1410713642835617, Lr:0.0001\n",
      "Epoch 3, Step: 799, Loss: 0.4881964921951294, Lr:0.0001\n",
      "Epoch 3, Step: 800, Loss: 0.2880854308605194, Lr:0.0001\n",
      "Epoch 3, Step: 801, Loss: 0.05905936658382416, Lr:0.0001\n",
      "Epoch 3, Step: 802, Loss: 0.28919291496276855, Lr:0.0001\n",
      "Epoch 3, Step: 803, Loss: 0.5163249969482422, Lr:0.0001\n",
      "Epoch 3, Step: 804, Loss: 0.3943047523498535, Lr:0.0001\n",
      "Epoch 3, Step: 805, Loss: 0.4327108561992645, Lr:0.0001\n",
      "Epoch 3, Step: 806, Loss: 0.22935867309570312, Lr:0.0001\n",
      "Epoch 3, Step: 807, Loss: 0.3186771273612976, Lr:0.0001\n",
      "Epoch 3, Step: 808, Loss: 0.3048114776611328, Lr:0.0001\n",
      "Epoch 3, Step: 809, Loss: 0.4672843813896179, Lr:0.0001\n",
      "Epoch 3, Step: 810, Loss: 0.245543971657753, Lr:0.0001\n",
      "Epoch 3, Step: 811, Loss: 0.4047752618789673, Lr:0.0001\n",
      "Epoch 3, Step: 812, Loss: 0.09862156212329865, Lr:0.0001\n",
      "Epoch 3, Step: 813, Loss: 0.34974396228790283, Lr:0.0001\n",
      "Epoch 3, Step: 814, Loss: 0.227770134806633, Lr:0.0001\n",
      "Epoch 3, Step: 815, Loss: 0.776486337184906, Lr:0.0001\n",
      "Epoch 3, Step: 816, Loss: 0.232334703207016, Lr:0.0001\n",
      "Epoch 3, Step: 817, Loss: 0.12074407935142517, Lr:0.0001\n",
      "Epoch 3, Step: 818, Loss: 0.22415515780448914, Lr:0.0001\n",
      "Epoch 3, Step: 819, Loss: 0.14506478607654572, Lr:0.0001\n",
      "Epoch 3, Step: 820, Loss: 0.13771939277648926, Lr:0.0001\n",
      "Epoch 3, Step: 821, Loss: 0.24458058178424835, Lr:0.0001\n",
      "Epoch 3, Step: 822, Loss: 0.37165674567222595, Lr:0.0001\n",
      "Epoch 3, Step: 823, Loss: 0.13268031179904938, Lr:0.0001\n",
      "Epoch 3, Step: 824, Loss: 0.29070746898651123, Lr:0.0001\n",
      "Epoch 3, Step: 825, Loss: 0.2558446228504181, Lr:0.0001\n",
      "Epoch 3, Step: 826, Loss: 0.16608920693397522, Lr:0.0001\n",
      "Epoch 3, Step: 827, Loss: 0.4250411093235016, Lr:0.0001\n",
      "Epoch 3, Step: 828, Loss: 0.24179837107658386, Lr:0.0001\n",
      "Epoch 3, Step: 829, Loss: 0.3627470135688782, Lr:0.0001\n",
      "Epoch 3, Step: 830, Loss: 0.45671626925468445, Lr:0.0001\n",
      "Epoch 3, Step: 831, Loss: 0.13443437218666077, Lr:0.0001\n",
      "Epoch 3, Step: 832, Loss: 0.22115765511989594, Lr:0.0001\n",
      "Epoch 3, Step: 833, Loss: 0.1449149250984192, Lr:0.0001\n",
      "Epoch 3, Step: 834, Loss: 0.12720927596092224, Lr:0.0001\n",
      "Epoch 3, Step: 835, Loss: 0.212039053440094, Lr:0.0001\n",
      "Epoch 3, Step: 836, Loss: 0.4233050048351288, Lr:0.0001\n",
      "Epoch 3, Step: 837, Loss: 0.6016334295272827, Lr:0.0001\n",
      "Epoch 3, Step: 838, Loss: 0.42364731431007385, Lr:0.0001\n",
      "Epoch 3, Step: 839, Loss: 0.133504718542099, Lr:0.0001\n",
      "Epoch 3, Step: 840, Loss: 0.2302372306585312, Lr:0.0001\n",
      "Epoch 3, Step: 841, Loss: 0.4013619124889374, Lr:0.0001\n",
      "Epoch 3, Step: 842, Loss: 0.4542493522167206, Lr:0.0001\n",
      "Epoch 3, Step: 843, Loss: 0.20654895901679993, Lr:0.0001\n",
      "Epoch 3, Step: 844, Loss: 0.3861277401447296, Lr:0.0001\n",
      "Epoch 3, Step: 845, Loss: 0.1792902946472168, Lr:0.0001\n",
      "Epoch 3, Step: 846, Loss: 0.09113955497741699, Lr:0.0001\n",
      "Epoch 3, Step: 847, Loss: 0.2920265197753906, Lr:0.0001\n",
      "Epoch 3, Step: 848, Loss: 0.3052515685558319, Lr:0.0001\n",
      "Epoch 3, Step: 849, Loss: 0.12321490049362183, Lr:0.0001\n",
      "Epoch 3, Step: 850, Loss: 0.18738926947116852, Lr:0.0001\n",
      "Epoch 3, Step: 851, Loss: 0.19035184383392334, Lr:0.0001\n",
      "Epoch 3, Step: 852, Loss: 0.16578041017055511, Lr:0.0001\n",
      "Epoch 3, Step: 853, Loss: 0.3327481150627136, Lr:0.0001\n",
      "Epoch 3, Step: 854, Loss: 0.4546654224395752, Lr:0.0001\n",
      "Epoch 3, Step: 855, Loss: 0.054116636514663696, Lr:0.0001\n",
      "Epoch 3, Step: 856, Loss: 0.2044539749622345, Lr:0.0001\n",
      "Epoch 3, Step: 857, Loss: 0.18048962950706482, Lr:0.0001\n",
      "Epoch 3, Step: 858, Loss: 0.6729126572608948, Lr:0.0001\n",
      "Epoch 3, Step: 859, Loss: 0.21573829650878906, Lr:0.0001\n",
      "Epoch 3, Step: 860, Loss: 0.19659407436847687, Lr:0.0001\n",
      "Epoch 3, Step: 861, Loss: 0.38205739855766296, Lr:0.0001\n",
      "Epoch 3, Step: 862, Loss: 0.2252843677997589, Lr:0.0001\n",
      "Epoch 3, Step: 863, Loss: 0.3602025508880615, Lr:0.0001\n",
      "Epoch 3, Step: 864, Loss: 0.31825387477874756, Lr:0.0001\n",
      "Epoch 3, Step: 865, Loss: 0.14455658197402954, Lr:0.0001\n",
      "Epoch 3, Step: 866, Loss: 0.24805483222007751, Lr:0.0001\n",
      "Epoch 3, Step: 867, Loss: 0.33705535531044006, Lr:0.0001\n",
      "Epoch 3, Step: 868, Loss: 0.15925459563732147, Lr:0.0001\n",
      "Epoch 3, Step: 869, Loss: 0.4340648651123047, Lr:0.0001\n",
      "Epoch 3, Step: 870, Loss: 0.1756005585193634, Lr:0.0001\n",
      "Epoch 3, Step: 871, Loss: 0.10814367979764938, Lr:0.0001\n",
      "Epoch 3, Step: 872, Loss: 0.2722930908203125, Lr:0.0001\n",
      "Epoch 3, Step: 873, Loss: 0.26985496282577515, Lr:0.0001\n",
      "Epoch 3, Step: 874, Loss: 0.3761545419692993, Lr:0.0001\n",
      "Epoch 3, Step: 875, Loss: 0.118985615670681, Lr:0.0001\n",
      "Epoch 3, Step: 876, Loss: 0.3447885811328888, Lr:0.0001\n",
      "Epoch 3, Step: 877, Loss: 0.3406016230583191, Lr:0.0001\n",
      "Epoch 3, Step: 878, Loss: 0.12690167129039764, Lr:0.0001\n",
      "Epoch 3, Step: 879, Loss: 0.3900756537914276, Lr:0.0001\n",
      "Epoch 3, Step: 880, Loss: 0.15206970274448395, Lr:0.0001\n",
      "Epoch 3, Step: 881, Loss: 0.12057287991046906, Lr:0.0001\n",
      "Epoch 3, Step: 882, Loss: 0.4480879604816437, Lr:0.0001\n",
      "Epoch 3, Step: 883, Loss: 0.130862295627594, Lr:0.0001\n",
      "Epoch 3, Step: 884, Loss: 0.21450068056583405, Lr:0.0001\n",
      "Epoch 3, Step: 885, Loss: 0.21582935750484467, Lr:0.0001\n",
      "Epoch 3, Step: 886, Loss: 0.6838892698287964, Lr:0.0001\n",
      "Epoch 3, Step: 887, Loss: 0.2683068513870239, Lr:0.0001\n",
      "Epoch 3, Step: 888, Loss: 0.23500218987464905, Lr:0.0001\n",
      "Epoch 3, Step: 889, Loss: 0.49949896335601807, Lr:0.0001\n",
      "Epoch 3, Step: 890, Loss: 0.33670443296432495, Lr:0.0001\n",
      "Epoch 3, Step: 891, Loss: 0.5462915897369385, Lr:0.0001\n",
      "Epoch 3, Step: 892, Loss: 0.29133889079093933, Lr:0.0001\n",
      "Epoch 3, Step: 893, Loss: 0.20158222317695618, Lr:0.0001\n",
      "Epoch 3, Step: 894, Loss: 0.19677527248859406, Lr:0.0001\n",
      "Epoch 3, Step: 895, Loss: 0.10842912644147873, Lr:0.0001\n",
      "Epoch 3, Step: 896, Loss: 0.2214147299528122, Lr:0.0001\n",
      "Epoch 3, Step: 897, Loss: 0.24387265741825104, Lr:0.0001\n",
      "Epoch 3, Step: 898, Loss: 0.13919489085674286, Lr:0.0001\n",
      "Epoch 3, Step: 899, Loss: 0.25611332058906555, Lr:0.0001\n",
      "Epoch 3, Step: 900, Loss: 0.3188249170780182, Lr:0.0001\n",
      "Epoch 3, Step: 901, Loss: 0.26757869124412537, Lr:0.0001\n",
      "Epoch 3, Step: 902, Loss: 0.4024958312511444, Lr:0.0001\n",
      "Epoch 3, Step: 903, Loss: 0.37567654252052307, Lr:0.0001\n",
      "Epoch 3, Step: 904, Loss: 0.08327214419841766, Lr:0.0001\n",
      "Epoch 3, Step: 905, Loss: 0.32412877678871155, Lr:0.0001\n",
      "Epoch 3, Step: 906, Loss: 0.19362828135490417, Lr:0.0001\n",
      "Epoch 3, Step: 907, Loss: 0.11767502129077911, Lr:0.0001\n",
      "Epoch 3, Step: 908, Loss: 0.15477803349494934, Lr:0.0001\n",
      "Epoch 3, Step: 909, Loss: 0.471706360578537, Lr:0.0001\n",
      "Epoch 3, Step: 910, Loss: 0.2645426094532013, Lr:0.0001\n",
      "Epoch 3, Step: 911, Loss: 0.1821925938129425, Lr:0.0001\n",
      "Epoch 3, Step: 912, Loss: 0.1342352330684662, Lr:0.0001\n",
      "Epoch 3, Step: 913, Loss: 0.537297248840332, Lr:0.0001\n",
      "Epoch 3, Step: 914, Loss: 0.18934054672718048, Lr:0.0001\n",
      "Epoch 3, Step: 915, Loss: 0.1959902048110962, Lr:0.0001\n",
      "Epoch 3, Step: 916, Loss: 0.1609947234392166, Lr:0.0001\n",
      "Epoch 3, Step: 917, Loss: 0.24039298295974731, Lr:0.0001\n",
      "Epoch 3, Step: 918, Loss: 0.2802686095237732, Lr:0.0001\n",
      "Epoch 3, Step: 919, Loss: 0.29223790764808655, Lr:0.0001\n",
      "Epoch 3, Step: 920, Loss: 0.3731123208999634, Lr:0.0001\n",
      "Epoch 3, Step: 921, Loss: 0.23720958828926086, Lr:0.0001\n",
      "Epoch 3, Step: 922, Loss: 0.09453587979078293, Lr:0.0001\n",
      "Epoch 3, Step: 923, Loss: 0.16956180334091187, Lr:0.0001\n",
      "Epoch 3, Step: 924, Loss: 0.2138357013463974, Lr:0.0001\n",
      "Epoch 3, Step: 925, Loss: 0.21017974615097046, Lr:0.0001\n",
      "Epoch 3, Step: 926, Loss: 0.7515406608581543, Lr:0.0001\n",
      "Epoch 3, Step: 927, Loss: 0.12082155048847198, Lr:0.0001\n",
      "Epoch 3, Step: 928, Loss: 0.32508397102355957, Lr:0.0001\n",
      "Epoch 3, Step: 929, Loss: 0.1489126980304718, Lr:0.0001\n",
      "Epoch 3, Step: 930, Loss: 0.12537015974521637, Lr:0.0001\n",
      "Epoch 3, Step: 931, Loss: 0.11610844731330872, Lr:0.0001\n",
      "Epoch 3, Step: 932, Loss: 0.17120957374572754, Lr:0.0001\n",
      "Epoch 3, Step: 933, Loss: 0.20441576838493347, Lr:0.0001\n",
      "Epoch 3, Step: 934, Loss: 0.2335648238658905, Lr:0.0001\n",
      "Epoch 3, Step: 935, Loss: 0.439039409160614, Lr:0.0001\n",
      "Epoch 3, Step: 936, Loss: 0.11160150915384293, Lr:0.0001\n",
      "Epoch 3, Step: 937, Loss: 0.34558576345443726, Lr:0.0001\n",
      "Epoch 3, Step: 938, Loss: 0.31397944688796997, Lr:0.0001\n",
      "Epoch 3, Step: 939, Loss: 0.26997554302215576, Lr:0.0001\n",
      "Epoch 3, Step: 940, Loss: 0.3419552743434906, Lr:0.0001\n",
      "Epoch 3, Step: 941, Loss: 0.16453981399536133, Lr:0.0001\n",
      "Epoch 3, Step: 942, Loss: 0.3582687973976135, Lr:0.0001\n",
      "Epoch 3, Step: 943, Loss: 0.29918280243873596, Lr:0.0001\n",
      "Epoch 3, Step: 944, Loss: 0.16813480854034424, Lr:0.0001\n",
      "Epoch 3, Step: 945, Loss: 0.17921195924282074, Lr:0.0001\n",
      "Epoch 3, Step: 946, Loss: 0.15055795013904572, Lr:0.0001\n",
      "Epoch 3, Step: 947, Loss: 0.3569459915161133, Lr:0.0001\n",
      "Epoch 3, Step: 948, Loss: 0.12385216355323792, Lr:0.0001\n",
      "Epoch 3, Step: 949, Loss: 0.22962817549705505, Lr:0.0001\n",
      "Epoch 3, Step: 950, Loss: 0.1188075840473175, Lr:0.0001\n",
      "Epoch 3, Step: 951, Loss: 0.3314911127090454, Lr:0.0001\n",
      "Epoch 3, Step: 952, Loss: 0.1599711924791336, Lr:0.0001\n",
      "Epoch 3, Step: 953, Loss: 0.015254327096045017, Lr:0.0001\n",
      "Epoch 3, Step: 954, Loss: 0.2328977882862091, Lr:0.0001\n",
      "Epoch 3, Step: 955, Loss: 0.21272549033164978, Lr:0.0001\n",
      "Epoch 3, Step: 956, Loss: 0.41849759221076965, Lr:0.0001\n",
      "Epoch 3, Step: 957, Loss: 0.42597463726997375, Lr:0.0001\n",
      "Epoch 3, Step: 958, Loss: 0.37613043189048767, Lr:0.0001\n",
      "Epoch 3, Step: 959, Loss: 0.07529480755329132, Lr:0.0001\n",
      "Epoch 3, Step: 960, Loss: 0.40546777844429016, Lr:0.0001\n",
      "Epoch 3, Step: 961, Loss: 0.19306111335754395, Lr:0.0001\n",
      "Epoch 3, Step: 962, Loss: 0.42084360122680664, Lr:0.0001\n",
      "Epoch 3, Step: 963, Loss: 0.11010853201150894, Lr:0.0001\n",
      "Epoch 3, Step: 964, Loss: 0.2144630253314972, Lr:0.0001\n",
      "Epoch 3, Step: 965, Loss: 0.20982620120048523, Lr:0.0001\n",
      "Epoch 3, Step: 966, Loss: 0.16900430619716644, Lr:0.0001\n",
      "Epoch 3, Step: 967, Loss: 0.5318405032157898, Lr:0.0001\n",
      "Epoch 3, Step: 968, Loss: 0.21255697309970856, Lr:0.0001\n",
      "Epoch 3, Step: 969, Loss: 0.320352703332901, Lr:0.0001\n",
      "Epoch 3, Step: 970, Loss: 0.25559312105178833, Lr:0.0001\n",
      "Epoch 3, Step: 971, Loss: 0.5005606412887573, Lr:0.0001\n",
      "Epoch 3, Step: 972, Loss: 0.48862308263778687, Lr:0.0001\n",
      "Epoch 3, Step: 973, Loss: 0.1902628093957901, Lr:0.0001\n",
      "Epoch 3, Step: 974, Loss: 0.16869893670082092, Lr:0.0001\n",
      "Epoch 3, Step: 975, Loss: 0.37831899523735046, Lr:0.0001\n",
      "Epoch 3, Step: 976, Loss: 0.7772514820098877, Lr:0.0001\n",
      "Epoch 3, Step: 977, Loss: 0.3334841728210449, Lr:0.0001\n",
      "Epoch 3, Step: 978, Loss: 0.4004979133605957, Lr:0.0001\n",
      "Epoch 3, Step: 979, Loss: 0.3303263485431671, Lr:0.0001\n",
      "Epoch 3, Step: 980, Loss: 0.13491199910640717, Lr:0.0001\n",
      "Epoch 3, Step: 981, Loss: 0.23185035586357117, Lr:0.0001\n",
      "Epoch 3, Step: 982, Loss: 0.20110994577407837, Lr:0.0001\n",
      "Epoch 3, Step: 983, Loss: 0.30999451875686646, Lr:0.0001\n",
      "Epoch 3, Step: 984, Loss: 0.09847056120634079, Lr:0.0001\n",
      "Epoch 3, Step: 985, Loss: 0.14713872969150543, Lr:0.0001\n",
      "Epoch 3, Step: 986, Loss: 0.5546156167984009, Lr:0.0001\n",
      "Epoch 3, Step: 987, Loss: 0.19776766002178192, Lr:0.0001\n",
      "Epoch 3, Step: 988, Loss: 0.15896420180797577, Lr:0.0001\n",
      "Epoch 3, Step: 989, Loss: 0.1917201578617096, Lr:0.0001\n",
      "Epoch 3, Step: 990, Loss: 0.28070905804634094, Lr:0.0001\n",
      "Epoch 3, Step: 991, Loss: 0.3404773473739624, Lr:0.0001\n",
      "Epoch 3, Step: 992, Loss: 0.16633416712284088, Lr:0.0001\n",
      "Epoch 3, Step: 993, Loss: 0.38816580176353455, Lr:0.0001\n",
      "Epoch 3, Step: 994, Loss: 0.19939614832401276, Lr:0.0001\n",
      "Epoch 3, Step: 995, Loss: 0.18708860874176025, Lr:0.0001\n",
      "Epoch 3, Step: 996, Loss: 0.17663319408893585, Lr:0.0001\n",
      "Epoch 3, Step: 997, Loss: 0.8053880333900452, Lr:0.0001\n",
      "Epoch 3, Step: 998, Loss: 0.1181744933128357, Lr:0.0001\n",
      "Epoch 3, Step: 999, Loss: 0.3061333894729614, Lr:0.0001\n",
      "Epoch 3, Step: 1000, Loss: 0.35665059089660645, Lr:0.0001\n",
      "Epoch 3, Step: 1001, Loss: 0.2960967719554901, Lr:0.0001\n",
      "Epoch 3, Step: 1002, Loss: 0.6236939430236816, Lr:0.0001\n",
      "Epoch 3, Step: 1003, Loss: 0.13311095535755157, Lr:0.0001\n",
      "Epoch 3, Step: 1004, Loss: 0.16166181862354279, Lr:0.0001\n",
      "Epoch 3, Step: 1005, Loss: 0.1694348305463791, Lr:0.0001\n",
      "Epoch 3, Step: 1006, Loss: 0.5406157970428467, Lr:0.0001\n",
      "Epoch 3, Step: 1007, Loss: 0.3136708736419678, Lr:0.0001\n",
      "Epoch 3, Step: 1008, Loss: 0.13923628628253937, Lr:0.0001\n",
      "Epoch 3, Step: 1009, Loss: 0.21326027810573578, Lr:0.0001\n",
      "Epoch 3, Step: 1010, Loss: 0.128767728805542, Lr:0.0001\n",
      "Epoch 3, Step: 1011, Loss: 0.3147124648094177, Lr:0.0001\n",
      "Epoch 3, Step: 1012, Loss: 0.298199862241745, Lr:0.0001\n",
      "Epoch 3, Step: 1013, Loss: 0.8846181631088257, Lr:0.0001\n",
      "Epoch 3, Step: 1014, Loss: 0.11688201874494553, Lr:0.0001\n",
      "Epoch 3, Step: 1015, Loss: 0.2800818979740143, Lr:0.0001\n",
      "Epoch 3, Step: 1016, Loss: 0.5760363936424255, Lr:0.0001\n",
      "Epoch 3, Step: 1017, Loss: 0.22821484506130219, Lr:0.0001\n",
      "Epoch 3, Step: 1018, Loss: 0.3560795485973358, Lr:0.0001\n",
      "Epoch 3, Step: 1019, Loss: 0.4929722845554352, Lr:0.0001\n",
      "Epoch 3, Step: 1020, Loss: 0.2860300540924072, Lr:0.0001\n",
      "Epoch 3, Step: 1021, Loss: 0.15910542011260986, Lr:0.0001\n",
      "Epoch 3, Step: 1022, Loss: 0.5853008031845093, Lr:0.0001\n",
      "Epoch 3, Step: 1023, Loss: 0.47650280594825745, Lr:0.0001\n",
      "Epoch 3, Step: 1024, Loss: 0.24490293860435486, Lr:0.0001\n",
      "Epoch 3, Step: 1025, Loss: 0.25289639830589294, Lr:0.0001\n",
      "Epoch 3, Step: 1026, Loss: 0.16695812344551086, Lr:0.0001\n",
      "Epoch 3, Step: 1027, Loss: 0.2854241728782654, Lr:0.0001\n",
      "Epoch 3, Step: 1028, Loss: 0.3723067045211792, Lr:0.0001\n",
      "Epoch 3, Step: 1029, Loss: 0.40374353528022766, Lr:0.0001\n",
      "Epoch 3, Step: 1030, Loss: 0.1994290053844452, Lr:0.0001\n",
      "Epoch 3, Step: 1031, Loss: 0.14143070578575134, Lr:0.0001\n",
      "Epoch 3, Step: 1032, Loss: 0.22951751947402954, Lr:0.0001\n",
      "Epoch 3, Step: 1033, Loss: 0.12109729647636414, Lr:0.0001\n",
      "Epoch 3, Step: 1034, Loss: 0.31196966767311096, Lr:0.0001\n",
      "Epoch 3, Step: 1035, Loss: 0.12021467089653015, Lr:0.0001\n",
      "Epoch 3, Step: 1036, Loss: 0.3145584166049957, Lr:0.0001\n",
      "Epoch 3, Step: 1037, Loss: 0.2870623469352722, Lr:0.0001\n",
      "Epoch 3, Step: 1038, Loss: 0.21176941692829132, Lr:0.0001\n",
      "Epoch 3, Step: 1039, Loss: 0.3478058874607086, Lr:0.0001\n",
      "Epoch 3, Step: 1040, Loss: 0.18821954727172852, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 3\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:15 loss: 1.7644 (1.7644) acc1: 50.0000 (50.0000) acc5: 100.0000 (100.0000) time: 0.2835 data: 0.1148 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.6970 (0.7924) acc1: 68.7500 (71.5909) acc5: 100.0000 (100.0000) time: 0.2970 data: 0.1186 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.5496 (0.7124) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.2959 data: 0.1175 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.4482 (0.6366) acc1: 75.0000 (76.2097) acc5: 100.0000 (100.0000) time: 0.2951 data: 0.1179 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.4042 (0.5973) acc1: 81.2500 (76.9817) acc5: 100.0000 (100.0000) time: 0.2979 data: 0.1198 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.4439 (0.6064) acc1: 75.0000 (77.0833) acc5: 100.0000 (100.0000) time: 0.2992 data: 0.1204 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.3450 (0.6420) acc1: 75.0000 (77.0715) acc5: 100.0000 (100.0000) time: 0.2869 data: 0.1148 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.2928 s / it)\n",
      "* Acc@1 77.072 Acc@5 100.000 loss 0.642\n",
      "Accuracy of the network on the 881 test image: 77.1%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 4, Step: 0, Loss: 0.10074039548635483, Lr:0.0001\n",
      "Epoch 4, Step: 1, Loss: 0.10708481073379517, Lr:0.0001\n",
      "Epoch 4, Step: 2, Loss: 0.3431069552898407, Lr:0.0001\n",
      "Epoch 4, Step: 3, Loss: 0.11937684565782547, Lr:0.0001\n",
      "Epoch 4, Step: 4, Loss: 0.40720292925834656, Lr:0.0001\n",
      "Epoch 4, Step: 5, Loss: 0.16399431228637695, Lr:0.0001\n",
      "Epoch 4, Step: 6, Loss: 0.09452372789382935, Lr:0.0001\n",
      "Epoch 4, Step: 7, Loss: 0.3112247586250305, Lr:0.0001\n",
      "Epoch 4, Step: 8, Loss: 0.3425789475440979, Lr:0.0001\n",
      "Epoch 4, Step: 9, Loss: 0.16452178359031677, Lr:0.0001\n",
      "Epoch 4, Step: 10, Loss: 0.3671441078186035, Lr:0.0001\n",
      "Epoch 4, Step: 11, Loss: 0.16092368960380554, Lr:0.0001\n",
      "Epoch 4, Step: 12, Loss: 0.22569610178470612, Lr:0.0001\n",
      "Epoch 4, Step: 13, Loss: 0.17362259328365326, Lr:0.0001\n",
      "Epoch 4, Step: 14, Loss: 0.08843329548835754, Lr:0.0001\n",
      "Epoch 4, Step: 15, Loss: 0.09116388857364655, Lr:0.0001\n",
      "Epoch 4, Step: 16, Loss: 0.19779935479164124, Lr:0.0001\n",
      "Epoch 4, Step: 17, Loss: 0.40381067991256714, Lr:0.0001\n",
      "Epoch 4, Step: 18, Loss: 0.4175395369529724, Lr:0.0001\n",
      "Epoch 4, Step: 19, Loss: 0.0325431153178215, Lr:0.0001\n",
      "Epoch 4, Step: 20, Loss: 0.07022695243358612, Lr:0.0001\n",
      "Epoch 4, Step: 21, Loss: 0.3088553249835968, Lr:0.0001\n",
      "Epoch 4, Step: 22, Loss: 0.3083302974700928, Lr:0.0001\n",
      "Epoch 4, Step: 23, Loss: 0.1979854553937912, Lr:0.0001\n",
      "Epoch 4, Step: 24, Loss: 0.011962308548390865, Lr:0.0001\n",
      "Epoch 4, Step: 25, Loss: 0.21276181936264038, Lr:0.0001\n",
      "Epoch 4, Step: 26, Loss: 0.2453593760728836, Lr:0.0001\n",
      "Epoch 4, Step: 27, Loss: 0.3254161477088928, Lr:0.0001\n",
      "Epoch 4, Step: 28, Loss: 0.12115371972322464, Lr:0.0001\n",
      "Epoch 4, Step: 29, Loss: 0.6149085164070129, Lr:0.0001\n",
      "Epoch 4, Step: 30, Loss: 0.16643597185611725, Lr:0.0001\n",
      "Epoch 4, Step: 31, Loss: 0.0901094377040863, Lr:0.0001\n",
      "Epoch 4, Step: 32, Loss: 0.30653291940689087, Lr:0.0001\n",
      "Epoch 4, Step: 33, Loss: 0.46525290608406067, Lr:0.0001\n",
      "Epoch 4, Step: 34, Loss: 0.25406813621520996, Lr:0.0001\n",
      "Epoch 4, Step: 35, Loss: 0.2567211985588074, Lr:0.0001\n",
      "Epoch 4, Step: 36, Loss: 0.12903641164302826, Lr:0.0001\n",
      "Epoch 4, Step: 37, Loss: 0.09584564715623856, Lr:0.0001\n",
      "Epoch 4, Step: 38, Loss: 0.07279206812381744, Lr:0.0001\n",
      "Epoch 4, Step: 39, Loss: 0.6263272762298584, Lr:0.0001\n",
      "Epoch 4, Step: 40, Loss: 0.0422782227396965, Lr:0.0001\n",
      "Epoch 4, Step: 41, Loss: 0.37004023790359497, Lr:0.0001\n",
      "Epoch 4, Step: 42, Loss: 0.133144810795784, Lr:0.0001\n",
      "Epoch 4, Step: 43, Loss: 0.37354618310928345, Lr:0.0001\n",
      "Epoch 4, Step: 44, Loss: 0.1489913910627365, Lr:0.0001\n",
      "Epoch 4, Step: 45, Loss: 0.075694240629673, Lr:0.0001\n",
      "Epoch 4, Step: 46, Loss: 0.42974305152893066, Lr:0.0001\n",
      "Epoch 4, Step: 47, Loss: 0.3348182439804077, Lr:0.0001\n",
      "Epoch 4, Step: 48, Loss: 0.02578343264758587, Lr:0.0001\n",
      "Epoch 4, Step: 49, Loss: 0.24239911139011383, Lr:0.0001\n",
      "Epoch 4, Step: 50, Loss: 0.17987418174743652, Lr:0.0001\n",
      "Epoch 4, Step: 51, Loss: 0.28961098194122314, Lr:0.0001\n",
      "Epoch 4, Step: 52, Loss: 0.1419246643781662, Lr:0.0001\n",
      "Epoch 4, Step: 53, Loss: 0.17189383506774902, Lr:0.0001\n",
      "Epoch 4, Step: 54, Loss: 0.07246781885623932, Lr:0.0001\n",
      "Epoch 4, Step: 55, Loss: 0.20083490014076233, Lr:0.0001\n",
      "Epoch 4, Step: 56, Loss: 0.17699173092842102, Lr:0.0001\n",
      "Epoch 4, Step: 57, Loss: 0.1532687544822693, Lr:0.0001\n",
      "Epoch 4, Step: 58, Loss: 0.21146845817565918, Lr:0.0001\n",
      "Epoch 4, Step: 59, Loss: 0.20398500561714172, Lr:0.0001\n",
      "Epoch 4, Step: 60, Loss: 0.2542976140975952, Lr:0.0001\n",
      "Epoch 4, Step: 61, Loss: 0.30180585384368896, Lr:0.0001\n",
      "Epoch 4, Step: 62, Loss: 0.27984362840652466, Lr:0.0001\n",
      "Epoch 4, Step: 63, Loss: 0.42622944712638855, Lr:0.0001\n",
      "Epoch 4, Step: 64, Loss: 0.17475321888923645, Lr:0.0001\n",
      "Epoch 4, Step: 65, Loss: 0.23650504648685455, Lr:0.0001\n",
      "Epoch 4, Step: 66, Loss: 0.2710942029953003, Lr:0.0001\n",
      "Epoch 4, Step: 67, Loss: 0.1463964730501175, Lr:0.0001\n",
      "Epoch 4, Step: 68, Loss: 0.10566580295562744, Lr:0.0001\n",
      "Epoch 4, Step: 69, Loss: 0.257274866104126, Lr:0.0001\n",
      "Epoch 4, Step: 70, Loss: 0.3541642427444458, Lr:0.0001\n",
      "Epoch 4, Step: 71, Loss: 0.04016771912574768, Lr:0.0001\n",
      "Epoch 4, Step: 72, Loss: 0.17643795907497406, Lr:0.0001\n",
      "Epoch 4, Step: 73, Loss: 0.19419442117214203, Lr:0.0001\n",
      "Epoch 4, Step: 74, Loss: 0.4195276200771332, Lr:0.0001\n",
      "Epoch 4, Step: 75, Loss: 0.11103580892086029, Lr:0.0001\n",
      "Epoch 4, Step: 76, Loss: 0.029609939083456993, Lr:0.0001\n",
      "Epoch 4, Step: 77, Loss: 0.2692497968673706, Lr:0.0001\n",
      "Epoch 4, Step: 78, Loss: 0.23141440749168396, Lr:0.0001\n",
      "Epoch 4, Step: 79, Loss: 0.10580391436815262, Lr:0.0001\n",
      "Epoch 4, Step: 80, Loss: 0.16941164433956146, Lr:0.0001\n",
      "Epoch 4, Step: 81, Loss: 0.20914068818092346, Lr:0.0001\n",
      "Epoch 4, Step: 82, Loss: 0.3743017613887787, Lr:0.0001\n",
      "Epoch 4, Step: 83, Loss: 0.27222031354904175, Lr:0.0001\n",
      "Epoch 4, Step: 84, Loss: 0.24393735826015472, Lr:0.0001\n",
      "Epoch 4, Step: 85, Loss: 0.12668360769748688, Lr:0.0001\n",
      "Epoch 4, Step: 86, Loss: 0.6082722544670105, Lr:0.0001\n",
      "Epoch 4, Step: 87, Loss: 0.1986805945634842, Lr:0.0001\n",
      "Epoch 4, Step: 88, Loss: 0.3510724902153015, Lr:0.0001\n",
      "Epoch 4, Step: 89, Loss: 0.15614575147628784, Lr:0.0001\n",
      "Epoch 4, Step: 90, Loss: 0.5918680429458618, Lr:0.0001\n",
      "Epoch 4, Step: 91, Loss: 0.4021005630493164, Lr:0.0001\n",
      "Epoch 4, Step: 92, Loss: 0.30274349451065063, Lr:0.0001\n",
      "Epoch 4, Step: 93, Loss: 0.16336661577224731, Lr:0.0001\n",
      "Epoch 4, Step: 94, Loss: 0.24978865683078766, Lr:0.0001\n",
      "Epoch 4, Step: 95, Loss: 0.818044900894165, Lr:0.0001\n",
      "Epoch 4, Step: 96, Loss: 0.20058785378932953, Lr:0.0001\n",
      "Epoch 4, Step: 97, Loss: 0.17721861600875854, Lr:0.0001\n",
      "Epoch 4, Step: 98, Loss: 0.1127418652176857, Lr:0.0001\n",
      "Epoch 4, Step: 99, Loss: 0.12733164429664612, Lr:0.0001\n",
      "Epoch 4, Step: 100, Loss: 0.0469595268368721, Lr:0.0001\n",
      "Epoch 4, Step: 101, Loss: 0.3316165506839752, Lr:0.0001\n",
      "Epoch 4, Step: 102, Loss: 0.2760509252548218, Lr:0.0001\n",
      "Epoch 4, Step: 103, Loss: 0.10023737698793411, Lr:0.0001\n",
      "Epoch 4, Step: 104, Loss: 0.09491048008203506, Lr:0.0001\n",
      "Epoch 4, Step: 105, Loss: 0.2702779471874237, Lr:0.0001\n",
      "Epoch 4, Step: 106, Loss: 0.2571912407875061, Lr:0.0001\n",
      "Epoch 4, Step: 107, Loss: 0.18074753880500793, Lr:0.0001\n",
      "Epoch 4, Step: 108, Loss: 0.09447862207889557, Lr:0.0001\n",
      "Epoch 4, Step: 109, Loss: 0.2814258337020874, Lr:0.0001\n",
      "Epoch 4, Step: 110, Loss: 0.23070856928825378, Lr:0.0001\n",
      "Epoch 4, Step: 111, Loss: 0.1955590397119522, Lr:0.0001\n",
      "Epoch 4, Step: 112, Loss: 0.5891782641410828, Lr:0.0001\n",
      "Epoch 4, Step: 113, Loss: 0.1110248863697052, Lr:0.0001\n",
      "Epoch 4, Step: 114, Loss: 0.4822728633880615, Lr:0.0001\n",
      "Epoch 4, Step: 115, Loss: 0.23109544813632965, Lr:0.0001\n",
      "Epoch 4, Step: 116, Loss: 0.39743223786354065, Lr:0.0001\n",
      "Epoch 4, Step: 117, Loss: 0.5151492357254028, Lr:0.0001\n",
      "Epoch 4, Step: 118, Loss: 0.10125759243965149, Lr:0.0001\n",
      "Epoch 4, Step: 119, Loss: 0.3487646281719208, Lr:0.0001\n",
      "Epoch 4, Step: 120, Loss: 0.486727237701416, Lr:0.0001\n",
      "Epoch 4, Step: 121, Loss: 0.08577457070350647, Lr:0.0001\n",
      "Epoch 4, Step: 122, Loss: 0.3262278437614441, Lr:0.0001\n",
      "Epoch 4, Step: 123, Loss: 0.43689578771591187, Lr:0.0001\n",
      "Epoch 4, Step: 124, Loss: 0.29278919100761414, Lr:0.0001\n",
      "Epoch 4, Step: 125, Loss: 0.27041783928871155, Lr:0.0001\n",
      "Epoch 4, Step: 126, Loss: 0.13754133880138397, Lr:0.0001\n",
      "Epoch 4, Step: 127, Loss: 0.15725842118263245, Lr:0.0001\n",
      "Epoch 4, Step: 128, Loss: 0.23721984028816223, Lr:0.0001\n",
      "Epoch 4, Step: 129, Loss: 0.2944749593734741, Lr:0.0001\n",
      "Epoch 4, Step: 130, Loss: 0.301169753074646, Lr:0.0001\n",
      "Epoch 4, Step: 131, Loss: 0.3403104543685913, Lr:0.0001\n",
      "Epoch 4, Step: 132, Loss: 0.1938466876745224, Lr:0.0001\n",
      "Epoch 4, Step: 133, Loss: 0.28227779269218445, Lr:0.0001\n",
      "Epoch 4, Step: 134, Loss: 0.15961629152297974, Lr:0.0001\n",
      "Epoch 4, Step: 135, Loss: 0.3073033094406128, Lr:0.0001\n",
      "Epoch 4, Step: 136, Loss: 0.22225502133369446, Lr:0.0001\n",
      "Epoch 4, Step: 137, Loss: 0.42730364203453064, Lr:0.0001\n",
      "Epoch 4, Step: 138, Loss: 0.25099074840545654, Lr:0.0001\n",
      "Epoch 4, Step: 139, Loss: 0.25008028745651245, Lr:0.0001\n",
      "Epoch 4, Step: 140, Loss: 0.2597614526748657, Lr:0.0001\n",
      "Epoch 4, Step: 141, Loss: 0.42894795536994934, Lr:0.0001\n",
      "Epoch 4, Step: 142, Loss: 0.35018396377563477, Lr:0.0001\n",
      "Epoch 4, Step: 143, Loss: 0.4539353847503662, Lr:0.0001\n",
      "Epoch 4, Step: 144, Loss: 0.2270863652229309, Lr:0.0001\n",
      "Epoch 4, Step: 145, Loss: 0.15423816442489624, Lr:0.0001\n",
      "Epoch 4, Step: 146, Loss: 0.15234807133674622, Lr:0.0001\n",
      "Epoch 4, Step: 147, Loss: 0.20270408689975739, Lr:0.0001\n",
      "Epoch 4, Step: 148, Loss: 0.27277880907058716, Lr:0.0001\n",
      "Epoch 4, Step: 149, Loss: 0.13938434422016144, Lr:0.0001\n",
      "Epoch 4, Step: 150, Loss: 0.2206656038761139, Lr:0.0001\n",
      "Epoch 4, Step: 151, Loss: 0.3466765582561493, Lr:0.0001\n",
      "Epoch 4, Step: 152, Loss: 0.15399044752120972, Lr:0.0001\n",
      "Epoch 4, Step: 153, Loss: 0.3204665780067444, Lr:0.0001\n",
      "Epoch 4, Step: 154, Loss: 0.4531557857990265, Lr:0.0001\n",
      "Epoch 4, Step: 155, Loss: 0.40546560287475586, Lr:0.0001\n",
      "Epoch 4, Step: 156, Loss: 0.20850184559822083, Lr:0.0001\n",
      "Epoch 4, Step: 157, Loss: 0.22021108865737915, Lr:0.0001\n",
      "Epoch 4, Step: 158, Loss: 0.4826463758945465, Lr:0.0001\n",
      "Epoch 4, Step: 159, Loss: 0.17172537744045258, Lr:0.0001\n",
      "Epoch 4, Step: 160, Loss: 0.1949600875377655, Lr:0.0001\n",
      "Epoch 4, Step: 161, Loss: 0.23896366357803345, Lr:0.0001\n",
      "Epoch 4, Step: 162, Loss: 0.08342801779508591, Lr:0.0001\n",
      "Epoch 4, Step: 163, Loss: 0.36829739809036255, Lr:0.0001\n",
      "Epoch 4, Step: 164, Loss: 0.11770442128181458, Lr:0.0001\n",
      "Epoch 4, Step: 165, Loss: 0.5293985605239868, Lr:0.0001\n",
      "Epoch 4, Step: 166, Loss: 0.2504892945289612, Lr:0.0001\n",
      "Epoch 4, Step: 167, Loss: 0.10351648926734924, Lr:0.0001\n",
      "Epoch 4, Step: 168, Loss: 0.1592654287815094, Lr:0.0001\n",
      "Epoch 4, Step: 169, Loss: 0.06579431891441345, Lr:0.0001\n",
      "Epoch 4, Step: 170, Loss: 0.21390925347805023, Lr:0.0001\n",
      "Epoch 4, Step: 171, Loss: 0.36010032892227173, Lr:0.0001\n",
      "Epoch 4, Step: 172, Loss: 0.19767141342163086, Lr:0.0001\n",
      "Epoch 4, Step: 173, Loss: 0.32240286469459534, Lr:0.0001\n",
      "Epoch 4, Step: 174, Loss: 0.06478961557149887, Lr:0.0001\n",
      "Epoch 4, Step: 175, Loss: 0.42463380098342896, Lr:0.0001\n",
      "Epoch 4, Step: 176, Loss: 0.19589421153068542, Lr:0.0001\n",
      "Epoch 4, Step: 177, Loss: 0.46371227502822876, Lr:0.0001\n",
      "Epoch 4, Step: 178, Loss: 0.25949135422706604, Lr:0.0001\n",
      "Epoch 4, Step: 179, Loss: 0.3459886312484741, Lr:0.0001\n",
      "Epoch 4, Step: 180, Loss: 0.07553485780954361, Lr:0.0001\n",
      "Epoch 4, Step: 181, Loss: 0.06324458867311478, Lr:0.0001\n",
      "Epoch 4, Step: 182, Loss: 0.2545454502105713, Lr:0.0001\n",
      "Epoch 4, Step: 183, Loss: 0.637069821357727, Lr:0.0001\n",
      "Epoch 4, Step: 184, Loss: 0.08918827772140503, Lr:0.0001\n",
      "Epoch 4, Step: 185, Loss: 0.34387606382369995, Lr:0.0001\n",
      "Epoch 4, Step: 186, Loss: 0.5754788517951965, Lr:0.0001\n",
      "Epoch 4, Step: 187, Loss: 0.033871907740831375, Lr:0.0001\n",
      "Epoch 4, Step: 188, Loss: 0.13534130156040192, Lr:0.0001\n",
      "Epoch 4, Step: 189, Loss: 0.05753171443939209, Lr:0.0001\n",
      "Epoch 4, Step: 190, Loss: 0.2185148149728775, Lr:0.0001\n",
      "Epoch 4, Step: 191, Loss: 0.21933341026306152, Lr:0.0001\n",
      "Epoch 4, Step: 192, Loss: 0.17396919429302216, Lr:0.0001\n",
      "Epoch 4, Step: 193, Loss: 0.31347042322158813, Lr:0.0001\n",
      "Epoch 4, Step: 194, Loss: 0.4784054756164551, Lr:0.0001\n",
      "Epoch 4, Step: 195, Loss: 0.3217013478279114, Lr:0.0001\n",
      "Epoch 4, Step: 196, Loss: 0.32336267828941345, Lr:0.0001\n",
      "Epoch 4, Step: 197, Loss: 0.2415851652622223, Lr:0.0001\n",
      "Epoch 4, Step: 198, Loss: 0.08998279273509979, Lr:0.0001\n",
      "Epoch 4, Step: 199, Loss: 0.19699224829673767, Lr:0.0001\n",
      "Epoch 4, Step: 200, Loss: 0.36099401116371155, Lr:0.0001\n",
      "Epoch 4, Step: 201, Loss: 0.7369241714477539, Lr:0.0001\n",
      "Epoch 4, Step: 202, Loss: 0.15841151773929596, Lr:0.0001\n",
      "Epoch 4, Step: 203, Loss: 0.10407192260026932, Lr:0.0001\n",
      "Epoch 4, Step: 204, Loss: 0.19144053757190704, Lr:0.0001\n",
      "Epoch 4, Step: 205, Loss: 0.27482447028160095, Lr:0.0001\n",
      "Epoch 4, Step: 206, Loss: 0.17257201671600342, Lr:0.0001\n",
      "Epoch 4, Step: 207, Loss: 0.09124118834733963, Lr:0.0001\n",
      "Epoch 4, Step: 208, Loss: 0.1705627739429474, Lr:0.0001\n",
      "Epoch 4, Step: 209, Loss: 1.3727549314498901, Lr:0.0001\n",
      "Epoch 4, Step: 210, Loss: 0.1526743769645691, Lr:0.0001\n",
      "Epoch 4, Step: 211, Loss: 0.2790609300136566, Lr:0.0001\n",
      "Epoch 4, Step: 212, Loss: 0.32359403371810913, Lr:0.0001\n",
      "Epoch 4, Step: 213, Loss: 0.22554254531860352, Lr:0.0001\n",
      "Epoch 4, Step: 214, Loss: 0.37621164321899414, Lr:0.0001\n",
      "Epoch 4, Step: 215, Loss: 0.083807572722435, Lr:0.0001\n",
      "Epoch 4, Step: 216, Loss: 0.32987675070762634, Lr:0.0001\n",
      "Epoch 4, Step: 217, Loss: 0.17808975279331207, Lr:0.0001\n",
      "Epoch 4, Step: 218, Loss: 0.18248328566551208, Lr:0.0001\n",
      "Epoch 4, Step: 219, Loss: 0.24643388390541077, Lr:0.0001\n",
      "Epoch 4, Step: 220, Loss: 0.505317211151123, Lr:0.0001\n",
      "Epoch 4, Step: 221, Loss: 0.2969339191913605, Lr:0.0001\n",
      "Epoch 4, Step: 222, Loss: 0.1266469806432724, Lr:0.0001\n",
      "Epoch 4, Step: 223, Loss: 0.24307465553283691, Lr:0.0001\n",
      "Epoch 4, Step: 224, Loss: 0.3217478096485138, Lr:0.0001\n",
      "Epoch 4, Step: 225, Loss: 0.23731453716754913, Lr:0.0001\n",
      "Epoch 4, Step: 226, Loss: 0.2133634090423584, Lr:0.0001\n",
      "Epoch 4, Step: 227, Loss: 0.12160569429397583, Lr:0.0001\n",
      "Epoch 4, Step: 228, Loss: 0.2917165458202362, Lr:0.0001\n",
      "Epoch 4, Step: 229, Loss: 0.10211378335952759, Lr:0.0001\n",
      "Epoch 4, Step: 230, Loss: 0.40587693452835083, Lr:0.0001\n",
      "Epoch 4, Step: 231, Loss: 0.5506234765052795, Lr:0.0001\n",
      "Epoch 4, Step: 232, Loss: 0.283158540725708, Lr:0.0001\n",
      "Epoch 4, Step: 233, Loss: 0.2565823197364807, Lr:0.0001\n",
      "Epoch 4, Step: 234, Loss: 0.47711899876594543, Lr:0.0001\n",
      "Epoch 4, Step: 235, Loss: 0.24832181632518768, Lr:0.0001\n",
      "Epoch 4, Step: 236, Loss: 0.12531507015228271, Lr:0.0001\n",
      "Epoch 4, Step: 237, Loss: 0.2748948037624359, Lr:0.0001\n",
      "Epoch 4, Step: 238, Loss: 0.17822247743606567, Lr:0.0001\n",
      "Epoch 4, Step: 239, Loss: 0.5821653604507446, Lr:0.0001\n",
      "Epoch 4, Step: 240, Loss: 0.1269873082637787, Lr:0.0001\n",
      "Epoch 4, Step: 241, Loss: 0.3047238290309906, Lr:0.0001\n",
      "Epoch 4, Step: 242, Loss: 0.279115229845047, Lr:0.0001\n",
      "Epoch 4, Step: 243, Loss: 0.22910788655281067, Lr:0.0001\n",
      "Epoch 4, Step: 244, Loss: 0.3165423572063446, Lr:0.0001\n",
      "Epoch 4, Step: 245, Loss: 0.24762345850467682, Lr:0.0001\n",
      "Epoch 4, Step: 246, Loss: 0.1762312650680542, Lr:0.0001\n",
      "Epoch 4, Step: 247, Loss: 0.29830941557884216, Lr:0.0001\n",
      "Epoch 4, Step: 248, Loss: 0.3529117703437805, Lr:0.0001\n",
      "Epoch 4, Step: 249, Loss: 0.10987721383571625, Lr:0.0001\n",
      "Epoch 4, Step: 250, Loss: 0.3010808825492859, Lr:0.0001\n",
      "Epoch 4, Step: 251, Loss: 0.05391772836446762, Lr:0.0001\n",
      "Epoch 4, Step: 252, Loss: 0.32040706276893616, Lr:0.0001\n",
      "Epoch 4, Step: 253, Loss: 0.09106321632862091, Lr:0.0001\n",
      "Epoch 4, Step: 254, Loss: 0.2884413003921509, Lr:0.0001\n",
      "Epoch 4, Step: 255, Loss: 0.32812145352363586, Lr:0.0001\n",
      "Epoch 4, Step: 256, Loss: 0.2633819580078125, Lr:0.0001\n",
      "Epoch 4, Step: 257, Loss: 0.18052281439304352, Lr:0.0001\n",
      "Epoch 4, Step: 258, Loss: 0.14010664820671082, Lr:0.0001\n",
      "Epoch 4, Step: 259, Loss: 0.3992411494255066, Lr:0.0001\n",
      "Epoch 4, Step: 260, Loss: 0.17395645380020142, Lr:0.0001\n",
      "Epoch 4, Step: 261, Loss: 0.15512748062610626, Lr:0.0001\n",
      "Epoch 4, Step: 262, Loss: 0.8943772315979004, Lr:0.0001\n",
      "Epoch 4, Step: 263, Loss: 0.2949793040752411, Lr:0.0001\n",
      "Epoch 4, Step: 264, Loss: 0.12120364606380463, Lr:0.0001\n",
      "Epoch 4, Step: 265, Loss: 0.2995622456073761, Lr:0.0001\n",
      "Epoch 4, Step: 266, Loss: 0.32361820340156555, Lr:0.0001\n",
      "Epoch 4, Step: 267, Loss: 0.287055104970932, Lr:0.0001\n",
      "Epoch 4, Step: 268, Loss: 0.1305791735649109, Lr:0.0001\n",
      "Epoch 4, Step: 269, Loss: 0.08126826584339142, Lr:0.0001\n",
      "Epoch 4, Step: 270, Loss: 0.24694713950157166, Lr:0.0001\n",
      "Epoch 4, Step: 271, Loss: 0.29500555992126465, Lr:0.0001\n",
      "Epoch 4, Step: 272, Loss: 0.31643015146255493, Lr:0.0001\n",
      "Epoch 4, Step: 273, Loss: 0.22033104300498962, Lr:0.0001\n",
      "Epoch 4, Step: 274, Loss: 0.35381290316581726, Lr:0.0001\n",
      "Epoch 4, Step: 275, Loss: 0.5101576447486877, Lr:0.0001\n",
      "Epoch 4, Step: 276, Loss: 0.09625495225191116, Lr:0.0001\n",
      "Epoch 4, Step: 277, Loss: 0.2307935655117035, Lr:0.0001\n",
      "Epoch 4, Step: 278, Loss: 0.5875675082206726, Lr:0.0001\n",
      "Epoch 4, Step: 279, Loss: 0.2027338445186615, Lr:0.0001\n",
      "Epoch 4, Step: 280, Loss: 0.1781611442565918, Lr:0.0001\n",
      "Epoch 4, Step: 281, Loss: 0.2703065574169159, Lr:0.0001\n",
      "Epoch 4, Step: 282, Loss: 0.18728597462177277, Lr:0.0001\n",
      "Epoch 4, Step: 283, Loss: 0.44101861119270325, Lr:0.0001\n",
      "Epoch 4, Step: 284, Loss: 0.3800826370716095, Lr:0.0001\n",
      "Epoch 4, Step: 285, Loss: 0.13303688168525696, Lr:0.0001\n",
      "Epoch 4, Step: 286, Loss: 0.3278283178806305, Lr:0.0001\n",
      "Epoch 4, Step: 287, Loss: 0.2053665816783905, Lr:0.0001\n",
      "Epoch 4, Step: 288, Loss: 0.220293790102005, Lr:0.0001\n",
      "Epoch 4, Step: 289, Loss: 0.4342004358768463, Lr:0.0001\n",
      "Epoch 4, Step: 290, Loss: 0.15148226916790009, Lr:0.0001\n",
      "Epoch 4, Step: 291, Loss: 0.437563955783844, Lr:0.0001\n",
      "Epoch 4, Step: 292, Loss: 0.0556822344660759, Lr:0.0001\n",
      "Epoch 4, Step: 293, Loss: 0.2141759693622589, Lr:0.0001\n",
      "Epoch 4, Step: 294, Loss: 0.33730649948120117, Lr:0.0001\n",
      "Epoch 4, Step: 295, Loss: 0.33285388350486755, Lr:0.0001\n",
      "Epoch 4, Step: 296, Loss: 0.16044116020202637, Lr:0.0001\n",
      "Epoch 4, Step: 297, Loss: 0.6600593328475952, Lr:0.0001\n",
      "Epoch 4, Step: 298, Loss: 0.13723815977573395, Lr:0.0001\n",
      "Epoch 4, Step: 299, Loss: 0.1420603096485138, Lr:0.0001\n",
      "Epoch 4, Step: 300, Loss: 0.077977754175663, Lr:0.0001\n",
      "Epoch 4, Step: 301, Loss: 0.4162658452987671, Lr:0.0001\n",
      "Epoch 4, Step: 302, Loss: 0.5265579223632812, Lr:0.0001\n",
      "Epoch 4, Step: 303, Loss: 0.16497191786766052, Lr:0.0001\n",
      "Epoch 4, Step: 304, Loss: 0.2613793909549713, Lr:0.0001\n",
      "Epoch 4, Step: 305, Loss: 0.09468541294336319, Lr:0.0001\n",
      "Epoch 4, Step: 306, Loss: 0.37856972217559814, Lr:0.0001\n",
      "Epoch 4, Step: 307, Loss: 0.14709140360355377, Lr:0.0001\n",
      "Epoch 4, Step: 308, Loss: 0.30091845989227295, Lr:0.0001\n",
      "Epoch 4, Step: 309, Loss: 0.2488671839237213, Lr:0.0001\n",
      "Epoch 4, Step: 310, Loss: 0.27708008885383606, Lr:0.0001\n",
      "Epoch 4, Step: 311, Loss: 0.21324338018894196, Lr:0.0001\n",
      "Epoch 4, Step: 312, Loss: 0.04871474206447601, Lr:0.0001\n",
      "Epoch 4, Step: 313, Loss: 0.28938162326812744, Lr:0.0001\n",
      "Epoch 4, Step: 314, Loss: 0.1296936422586441, Lr:0.0001\n",
      "Epoch 4, Step: 315, Loss: 0.2891816794872284, Lr:0.0001\n",
      "Epoch 4, Step: 316, Loss: 0.3604581356048584, Lr:0.0001\n",
      "Epoch 4, Step: 317, Loss: 0.19177184998989105, Lr:0.0001\n",
      "Epoch 4, Step: 318, Loss: 0.17151671648025513, Lr:0.0001\n",
      "Epoch 4, Step: 319, Loss: 0.1900722235441208, Lr:0.0001\n",
      "Epoch 4, Step: 320, Loss: 0.24893063306808472, Lr:0.0001\n",
      "Epoch 4, Step: 321, Loss: 0.1364418864250183, Lr:0.0001\n",
      "Epoch 4, Step: 322, Loss: 0.4199477732181549, Lr:0.0001\n",
      "Epoch 4, Step: 323, Loss: 0.3246808350086212, Lr:0.0001\n",
      "Epoch 4, Step: 324, Loss: 0.28487157821655273, Lr:0.0001\n",
      "Epoch 4, Step: 325, Loss: 0.21713152527809143, Lr:0.0001\n",
      "Epoch 4, Step: 326, Loss: 0.1663132905960083, Lr:0.0001\n",
      "Epoch 4, Step: 327, Loss: 0.17236706614494324, Lr:0.0001\n",
      "Epoch 4, Step: 328, Loss: 0.19062666594982147, Lr:0.0001\n",
      "Epoch 4, Step: 329, Loss: 0.1768563687801361, Lr:0.0001\n",
      "Epoch 4, Step: 330, Loss: 0.2749526798725128, Lr:0.0001\n",
      "Epoch 4, Step: 331, Loss: 0.20129896700382233, Lr:0.0001\n",
      "Epoch 4, Step: 332, Loss: 0.2948078215122223, Lr:0.0001\n",
      "Epoch 4, Step: 333, Loss: 0.6052286624908447, Lr:0.0001\n",
      "Epoch 4, Step: 334, Loss: 0.1486949324607849, Lr:0.0001\n",
      "Epoch 4, Step: 335, Loss: 0.20890513062477112, Lr:0.0001\n",
      "Epoch 4, Step: 336, Loss: 0.22500701248645782, Lr:0.0001\n",
      "Epoch 4, Step: 337, Loss: 0.2640579044818878, Lr:0.0001\n",
      "Epoch 4, Step: 338, Loss: 0.16918286681175232, Lr:0.0001\n",
      "Epoch 4, Step: 339, Loss: 0.09534509479999542, Lr:0.0001\n",
      "Epoch 4, Step: 340, Loss: 0.3805273771286011, Lr:0.0001\n",
      "Epoch 4, Step: 341, Loss: 0.054262250661849976, Lr:0.0001\n",
      "Epoch 4, Step: 342, Loss: 0.16036437451839447, Lr:0.0001\n",
      "Epoch 4, Step: 343, Loss: 0.09799462556838989, Lr:0.0001\n",
      "Epoch 4, Step: 344, Loss: 0.24637819826602936, Lr:0.0001\n",
      "Epoch 4, Step: 345, Loss: 0.18926385045051575, Lr:0.0001\n",
      "Epoch 4, Step: 346, Loss: 0.4644404947757721, Lr:0.0001\n",
      "Epoch 4, Step: 347, Loss: 0.23580661416053772, Lr:0.0001\n",
      "Epoch 4, Step: 348, Loss: 0.5048064589500427, Lr:0.0001\n",
      "Epoch 4, Step: 349, Loss: 0.0749085545539856, Lr:0.0001\n",
      "Epoch 4, Step: 350, Loss: 0.10229894518852234, Lr:0.0001\n",
      "Epoch 4, Step: 351, Loss: 0.27296993136405945, Lr:0.0001\n",
      "Epoch 4, Step: 352, Loss: 0.22121897339820862, Lr:0.0001\n",
      "Epoch 4, Step: 353, Loss: 0.1320514976978302, Lr:0.0001\n",
      "Epoch 4, Step: 354, Loss: 0.3262103796005249, Lr:0.0001\n",
      "Epoch 4, Step: 355, Loss: 0.11618627607822418, Lr:0.0001\n",
      "Epoch 4, Step: 356, Loss: 0.8950425982475281, Lr:0.0001\n",
      "Epoch 4, Step: 357, Loss: 0.31111031770706177, Lr:0.0001\n",
      "Epoch 4, Step: 358, Loss: 0.046909209340810776, Lr:0.0001\n",
      "Epoch 4, Step: 359, Loss: 0.23548835515975952, Lr:0.0001\n",
      "Epoch 4, Step: 360, Loss: 0.3268945813179016, Lr:0.0001\n",
      "Epoch 4, Step: 361, Loss: 0.544524073600769, Lr:0.0001\n",
      "Epoch 4, Step: 362, Loss: 0.256753146648407, Lr:0.0001\n",
      "Epoch 4, Step: 363, Loss: 0.15463636815547943, Lr:0.0001\n",
      "Epoch 4, Step: 364, Loss: 0.21122321486473083, Lr:0.0001\n",
      "Epoch 4, Step: 365, Loss: 0.11365660279989243, Lr:0.0001\n",
      "Epoch 4, Step: 366, Loss: 0.3211158812046051, Lr:0.0001\n",
      "Epoch 4, Step: 367, Loss: 0.3190595507621765, Lr:0.0001\n",
      "Epoch 4, Step: 368, Loss: 0.268693208694458, Lr:0.0001\n",
      "Epoch 4, Step: 369, Loss: 0.2019469141960144, Lr:0.0001\n",
      "Epoch 4, Step: 370, Loss: 0.3644050657749176, Lr:0.0001\n",
      "Epoch 4, Step: 371, Loss: 0.08213342726230621, Lr:0.0001\n",
      "Epoch 4, Step: 372, Loss: 0.33561375737190247, Lr:0.0001\n",
      "Epoch 4, Step: 373, Loss: 0.2000158429145813, Lr:0.0001\n",
      "Epoch 4, Step: 374, Loss: 0.3772692084312439, Lr:0.0001\n",
      "Epoch 4, Step: 375, Loss: 0.5064378976821899, Lr:0.0001\n",
      "Epoch 4, Step: 376, Loss: 0.3381575047969818, Lr:0.0001\n",
      "Epoch 4, Step: 377, Loss: 0.3128666281700134, Lr:0.0001\n",
      "Epoch 4, Step: 378, Loss: 0.11109759658575058, Lr:0.0001\n",
      "Epoch 4, Step: 379, Loss: 0.33198076486587524, Lr:0.0001\n",
      "Epoch 4, Step: 380, Loss: 0.10659429430961609, Lr:0.0001\n",
      "Epoch 4, Step: 381, Loss: 0.17164158821105957, Lr:0.0001\n",
      "Epoch 4, Step: 382, Loss: 0.24182312190532684, Lr:0.0001\n",
      "Epoch 4, Step: 383, Loss: 0.1701861321926117, Lr:0.0001\n",
      "Epoch 4, Step: 384, Loss: 0.38435256481170654, Lr:0.0001\n",
      "Epoch 4, Step: 385, Loss: 0.4237220585346222, Lr:0.0001\n",
      "Epoch 4, Step: 386, Loss: 0.38852038979530334, Lr:0.0001\n",
      "Epoch 4, Step: 387, Loss: 0.39449623227119446, Lr:0.0001\n",
      "Epoch 4, Step: 388, Loss: 0.1388838142156601, Lr:0.0001\n",
      "Epoch 4, Step: 389, Loss: 0.15139368176460266, Lr:0.0001\n",
      "Epoch 4, Step: 390, Loss: 0.2933262288570404, Lr:0.0001\n",
      "Epoch 4, Step: 391, Loss: 0.11396199464797974, Lr:0.0001\n",
      "Epoch 4, Step: 392, Loss: 0.5570055246353149, Lr:0.0001\n",
      "Epoch 4, Step: 393, Loss: 0.2781866788864136, Lr:0.0001\n",
      "Epoch 4, Step: 394, Loss: 0.13788914680480957, Lr:0.0001\n",
      "Epoch 4, Step: 395, Loss: 0.3880438208580017, Lr:0.0001\n",
      "Epoch 4, Step: 396, Loss: 0.2738895118236542, Lr:0.0001\n",
      "Epoch 4, Step: 397, Loss: 0.2987147867679596, Lr:0.0001\n",
      "Epoch 4, Step: 398, Loss: 0.22627845406532288, Lr:0.0001\n",
      "Epoch 4, Step: 399, Loss: 0.574657142162323, Lr:0.0001\n",
      "Epoch 4, Step: 400, Loss: 0.1290840357542038, Lr:0.0001\n",
      "Epoch 4, Step: 401, Loss: 0.2795813977718353, Lr:0.0001\n",
      "Epoch 4, Step: 402, Loss: 0.19352634251117706, Lr:0.0001\n",
      "Epoch 4, Step: 403, Loss: 0.16399921476840973, Lr:0.0001\n",
      "Epoch 4, Step: 404, Loss: 0.6428239941596985, Lr:0.0001\n",
      "Epoch 4, Step: 405, Loss: 0.43859362602233887, Lr:0.0001\n",
      "Epoch 4, Step: 406, Loss: 0.26581665873527527, Lr:0.0001\n",
      "Epoch 4, Step: 407, Loss: 0.28703808784484863, Lr:0.0001\n",
      "Epoch 4, Step: 408, Loss: 0.3665522336959839, Lr:0.0001\n",
      "Epoch 4, Step: 409, Loss: 0.2380361109972, Lr:0.0001\n",
      "Epoch 4, Step: 410, Loss: 0.11800084263086319, Lr:0.0001\n",
      "Epoch 4, Step: 411, Loss: 0.04424570873379707, Lr:0.0001\n",
      "Epoch 4, Step: 412, Loss: 0.14662069082260132, Lr:0.0001\n",
      "Epoch 4, Step: 413, Loss: 0.3054041564464569, Lr:0.0001\n",
      "Epoch 4, Step: 414, Loss: 0.20140425860881805, Lr:0.0001\n",
      "Epoch 4, Step: 415, Loss: 0.361393004655838, Lr:0.0001\n",
      "Epoch 4, Step: 416, Loss: 0.21328963339328766, Lr:0.0001\n",
      "Epoch 4, Step: 417, Loss: 0.28192338347435, Lr:0.0001\n",
      "Epoch 4, Step: 418, Loss: 0.15636827051639557, Lr:0.0001\n",
      "Epoch 4, Step: 419, Loss: 0.2325548678636551, Lr:0.0001\n",
      "Epoch 4, Step: 420, Loss: 0.1043039932847023, Lr:0.0001\n",
      "Epoch 4, Step: 421, Loss: 0.38459405303001404, Lr:0.0001\n",
      "Epoch 4, Step: 422, Loss: 0.10263488441705704, Lr:0.0001\n",
      "Epoch 4, Step: 423, Loss: 0.4880305826663971, Lr:0.0001\n",
      "Epoch 4, Step: 424, Loss: 0.1894414871931076, Lr:0.0001\n",
      "Epoch 4, Step: 425, Loss: 0.07784134894609451, Lr:0.0001\n",
      "Epoch 4, Step: 426, Loss: 0.4180060625076294, Lr:0.0001\n",
      "Epoch 4, Step: 427, Loss: 0.06949663162231445, Lr:0.0001\n",
      "Epoch 4, Step: 428, Loss: 0.4056953191757202, Lr:0.0001\n",
      "Epoch 4, Step: 429, Loss: 0.11024102568626404, Lr:0.0001\n",
      "Epoch 4, Step: 430, Loss: 0.09702819585800171, Lr:0.0001\n",
      "Epoch 4, Step: 431, Loss: 0.37980636954307556, Lr:0.0001\n",
      "Epoch 4, Step: 432, Loss: 0.2441038191318512, Lr:0.0001\n",
      "Epoch 4, Step: 433, Loss: 0.4978589415550232, Lr:0.0001\n",
      "Epoch 4, Step: 434, Loss: 0.25919777154922485, Lr:0.0001\n",
      "Epoch 4, Step: 435, Loss: 0.2833957374095917, Lr:0.0001\n",
      "Epoch 4, Step: 436, Loss: 0.08105989545583725, Lr:0.0001\n",
      "Epoch 4, Step: 437, Loss: 0.15404289960861206, Lr:0.0001\n",
      "Epoch 4, Step: 438, Loss: 0.23131163418293, Lr:0.0001\n",
      "Epoch 4, Step: 439, Loss: 0.12806279957294464, Lr:0.0001\n",
      "Epoch 4, Step: 440, Loss: 0.06559300422668457, Lr:0.0001\n",
      "Epoch 4, Step: 441, Loss: 0.06748532503843307, Lr:0.0001\n",
      "Epoch 4, Step: 442, Loss: 0.7552180886268616, Lr:0.0001\n",
      "Epoch 4, Step: 443, Loss: 0.29860347509384155, Lr:0.0001\n",
      "Epoch 4, Step: 444, Loss: 0.3470378518104553, Lr:0.0001\n",
      "Epoch 4, Step: 445, Loss: 0.11206871271133423, Lr:0.0001\n",
      "Epoch 4, Step: 446, Loss: 0.19867554306983948, Lr:0.0001\n",
      "Epoch 4, Step: 447, Loss: 0.17177677154541016, Lr:0.0001\n",
      "Epoch 4, Step: 448, Loss: 0.04244052991271019, Lr:0.0001\n",
      "Epoch 4, Step: 449, Loss: 0.02792455442249775, Lr:0.0001\n",
      "Epoch 4, Step: 450, Loss: 0.2704602777957916, Lr:0.0001\n",
      "Epoch 4, Step: 451, Loss: 0.39492809772491455, Lr:0.0001\n",
      "Epoch 4, Step: 452, Loss: 0.05341119319200516, Lr:0.0001\n",
      "Epoch 4, Step: 453, Loss: 0.16127553582191467, Lr:0.0001\n",
      "Epoch 4, Step: 454, Loss: 0.44611555337905884, Lr:0.0001\n",
      "Epoch 4, Step: 455, Loss: 0.1110730916261673, Lr:0.0001\n",
      "Epoch 4, Step: 456, Loss: 0.31581994891166687, Lr:0.0001\n",
      "Epoch 4, Step: 457, Loss: 1.5779898166656494, Lr:0.0001\n",
      "Epoch 4, Step: 458, Loss: 0.34022045135498047, Lr:0.0001\n",
      "Epoch 4, Step: 459, Loss: 0.21202580630779266, Lr:0.0001\n",
      "Epoch 4, Step: 460, Loss: 0.1285676509141922, Lr:0.0001\n",
      "Epoch 4, Step: 461, Loss: 0.07323659956455231, Lr:0.0001\n",
      "Epoch 4, Step: 462, Loss: 0.11183483153581619, Lr:0.0001\n",
      "Epoch 4, Step: 463, Loss: 0.32848596572875977, Lr:0.0001\n",
      "Epoch 4, Step: 464, Loss: 0.16565650701522827, Lr:0.0001\n",
      "Epoch 4, Step: 465, Loss: 0.17669646441936493, Lr:0.0001\n",
      "Epoch 4, Step: 466, Loss: 0.14379194378852844, Lr:0.0001\n",
      "Epoch 4, Step: 467, Loss: 0.30852261185646057, Lr:0.0001\n",
      "Epoch 4, Step: 468, Loss: 0.257250040769577, Lr:0.0001\n",
      "Epoch 4, Step: 469, Loss: 0.2962307035923004, Lr:0.0001\n",
      "Epoch 4, Step: 470, Loss: 0.4053332507610321, Lr:0.0001\n",
      "Epoch 4, Step: 471, Loss: 0.34820178151130676, Lr:0.0001\n",
      "Epoch 4, Step: 472, Loss: 0.2993942201137543, Lr:0.0001\n",
      "Epoch 4, Step: 473, Loss: 0.19929663836956024, Lr:0.0001\n",
      "Epoch 4, Step: 474, Loss: 0.31437012553215027, Lr:0.0001\n",
      "Epoch 4, Step: 475, Loss: 0.677466869354248, Lr:0.0001\n",
      "Epoch 4, Step: 476, Loss: 0.35135042667388916, Lr:0.0001\n",
      "Epoch 4, Step: 477, Loss: 0.3871869444847107, Lr:0.0001\n",
      "Epoch 4, Step: 478, Loss: 0.06147576868534088, Lr:0.0001\n",
      "Epoch 4, Step: 479, Loss: 0.5499226450920105, Lr:0.0001\n",
      "Epoch 4, Step: 480, Loss: 0.26650410890579224, Lr:0.0001\n",
      "Epoch 4, Step: 481, Loss: 0.7566598057746887, Lr:0.0001\n",
      "Epoch 4, Step: 482, Loss: 0.17531630396842957, Lr:0.0001\n",
      "Epoch 4, Step: 483, Loss: 0.3018673062324524, Lr:0.0001\n",
      "Epoch 4, Step: 484, Loss: 0.4502682685852051, Lr:0.0001\n",
      "Epoch 4, Step: 485, Loss: 0.17389976978302002, Lr:0.0001\n",
      "Epoch 4, Step: 486, Loss: 0.4843692183494568, Lr:0.0001\n",
      "Epoch 4, Step: 487, Loss: 0.1858351081609726, Lr:0.0001\n",
      "Epoch 4, Step: 488, Loss: 0.2465490847826004, Lr:0.0001\n",
      "Epoch 4, Step: 489, Loss: 0.23768900334835052, Lr:0.0001\n",
      "Epoch 4, Step: 490, Loss: 0.14815686643123627, Lr:0.0001\n",
      "Epoch 4, Step: 491, Loss: 0.4279762804508209, Lr:0.0001\n",
      "Epoch 4, Step: 492, Loss: 0.26518505811691284, Lr:0.0001\n",
      "Epoch 4, Step: 493, Loss: 0.19360731542110443, Lr:0.0001\n",
      "Epoch 4, Step: 494, Loss: 0.07139546424150467, Lr:0.0001\n",
      "Epoch 4, Step: 495, Loss: 0.35553938150405884, Lr:0.0001\n",
      "Epoch 4, Step: 496, Loss: 0.23006467521190643, Lr:0.0001\n",
      "Epoch 4, Step: 497, Loss: 0.21902604401111603, Lr:0.0001\n",
      "Epoch 4, Step: 498, Loss: 0.15669068694114685, Lr:0.0001\n",
      "Epoch 4, Step: 499, Loss: 0.6173201203346252, Lr:0.0001\n",
      "Epoch 4, Step: 500, Loss: 0.20135580003261566, Lr:0.0001\n",
      "Epoch 4, Step: 501, Loss: 0.7103992700576782, Lr:0.0001\n",
      "Epoch 4, Step: 502, Loss: 0.5163847804069519, Lr:0.0001\n",
      "Epoch 4, Step: 503, Loss: 0.48115628957748413, Lr:0.0001\n",
      "Epoch 4, Step: 504, Loss: 0.2736872434616089, Lr:0.0001\n",
      "Epoch 4, Step: 505, Loss: 0.299500435590744, Lr:0.0001\n",
      "Epoch 4, Step: 506, Loss: 0.3909218907356262, Lr:0.0001\n",
      "Epoch 4, Step: 507, Loss: 0.1864408552646637, Lr:0.0001\n",
      "Epoch 4, Step: 508, Loss: 0.12461570650339127, Lr:0.0001\n",
      "Epoch 4, Step: 509, Loss: 0.14152756333351135, Lr:0.0001\n",
      "Epoch 4, Step: 510, Loss: 0.13641905784606934, Lr:0.0001\n",
      "Epoch 4, Step: 511, Loss: 0.22079689800739288, Lr:0.0001\n",
      "Epoch 4, Step: 512, Loss: 0.26891598105430603, Lr:0.0001\n",
      "Epoch 4, Step: 513, Loss: 0.2440228909254074, Lr:0.0001\n",
      "Epoch 4, Step: 514, Loss: 0.1896389275789261, Lr:0.0001\n",
      "Epoch 4, Step: 515, Loss: 0.08951647579669952, Lr:0.0001\n",
      "Epoch 4, Step: 516, Loss: 0.12518192827701569, Lr:0.0001\n",
      "Epoch 4, Step: 517, Loss: 0.44154325127601624, Lr:0.0001\n",
      "Epoch 4, Step: 518, Loss: 0.15238536894321442, Lr:0.0001\n",
      "Epoch 4, Step: 519, Loss: 0.26529136300086975, Lr:0.0001\n",
      "Epoch 4, Step: 520, Loss: 0.5147272348403931, Lr:0.0001\n",
      "Epoch 4, Step: 521, Loss: 0.3305749297142029, Lr:0.0001\n",
      "Epoch 4, Step: 522, Loss: 0.3681003749370575, Lr:0.0001\n",
      "Epoch 4, Step: 523, Loss: 0.2824811339378357, Lr:0.0001\n",
      "Epoch 4, Step: 524, Loss: 0.7582974433898926, Lr:0.0001\n",
      "Epoch 4, Step: 525, Loss: 0.26636871695518494, Lr:0.0001\n",
      "Epoch 4, Step: 526, Loss: 0.13883380591869354, Lr:0.0001\n",
      "Epoch 4, Step: 527, Loss: 0.05372016876935959, Lr:0.0001\n",
      "Epoch 4, Step: 528, Loss: 0.16442716121673584, Lr:0.0001\n",
      "Epoch 4, Step: 529, Loss: 0.3790956139564514, Lr:0.0001\n",
      "Epoch 4, Step: 530, Loss: 0.20834428071975708, Lr:0.0001\n",
      "Epoch 4, Step: 531, Loss: 0.3468012511730194, Lr:0.0001\n",
      "Epoch 4, Step: 532, Loss: 0.3841562271118164, Lr:0.0001\n",
      "Epoch 4, Step: 533, Loss: 0.3388488292694092, Lr:0.0001\n",
      "Epoch 4, Step: 534, Loss: 0.26580920815467834, Lr:0.0001\n",
      "Epoch 4, Step: 535, Loss: 0.2944340407848358, Lr:0.0001\n",
      "Epoch 4, Step: 536, Loss: 0.0613623708486557, Lr:0.0001\n",
      "Epoch 4, Step: 537, Loss: 0.11048950999975204, Lr:0.0001\n",
      "Epoch 4, Step: 538, Loss: 0.25481292605400085, Lr:0.0001\n",
      "Epoch 4, Step: 539, Loss: 0.28195720911026, Lr:0.0001\n",
      "Epoch 4, Step: 540, Loss: 0.2680562138557434, Lr:0.0001\n",
      "Epoch 4, Step: 541, Loss: 0.3280218839645386, Lr:0.0001\n",
      "Epoch 4, Step: 542, Loss: 0.3383633494377136, Lr:0.0001\n",
      "Epoch 4, Step: 543, Loss: 0.22498668730258942, Lr:0.0001\n",
      "Epoch 4, Step: 544, Loss: 0.2001599818468094, Lr:0.0001\n",
      "Epoch 4, Step: 545, Loss: 0.28701508045196533, Lr:0.0001\n",
      "Epoch 4, Step: 546, Loss: 0.5456035137176514, Lr:0.0001\n",
      "Epoch 4, Step: 547, Loss: 0.24202559888362885, Lr:0.0001\n",
      "Epoch 4, Step: 548, Loss: 0.05884983018040657, Lr:0.0001\n",
      "Epoch 4, Step: 549, Loss: 0.34050124883651733, Lr:0.0001\n",
      "Epoch 4, Step: 550, Loss: 0.15817518532276154, Lr:0.0001\n",
      "Epoch 4, Step: 551, Loss: 0.47499385476112366, Lr:0.0001\n",
      "Epoch 4, Step: 552, Loss: 0.2263432890176773, Lr:0.0001\n",
      "Epoch 4, Step: 553, Loss: 0.27551761269569397, Lr:0.0001\n",
      "Epoch 4, Step: 554, Loss: 0.16947948932647705, Lr:0.0001\n",
      "Epoch 4, Step: 555, Loss: 0.24028269946575165, Lr:0.0001\n",
      "Epoch 4, Step: 556, Loss: 0.19876237213611603, Lr:0.0001\n",
      "Epoch 4, Step: 557, Loss: 0.0659090131521225, Lr:0.0001\n",
      "Epoch 4, Step: 558, Loss: 0.212397500872612, Lr:0.0001\n",
      "Epoch 4, Step: 559, Loss: 0.2502845823764801, Lr:0.0001\n",
      "Epoch 4, Step: 560, Loss: 0.27867498993873596, Lr:0.0001\n",
      "Epoch 4, Step: 561, Loss: 0.4205319583415985, Lr:0.0001\n",
      "Epoch 4, Step: 562, Loss: 0.12638512253761292, Lr:0.0001\n",
      "Epoch 4, Step: 563, Loss: 0.31955012679100037, Lr:0.0001\n",
      "Epoch 4, Step: 564, Loss: 0.27728208899497986, Lr:0.0001\n",
      "Epoch 4, Step: 565, Loss: 0.5835740566253662, Lr:0.0001\n",
      "Epoch 4, Step: 566, Loss: 0.17025116086006165, Lr:0.0001\n",
      "Epoch 4, Step: 567, Loss: 0.18546824157238007, Lr:0.0001\n",
      "Epoch 4, Step: 568, Loss: 0.14070528745651245, Lr:0.0001\n",
      "Epoch 4, Step: 569, Loss: 0.37405723333358765, Lr:0.0001\n",
      "Epoch 4, Step: 570, Loss: 0.34946224093437195, Lr:0.0001\n",
      "Epoch 4, Step: 571, Loss: 0.17885783314704895, Lr:0.0001\n",
      "Epoch 4, Step: 572, Loss: 0.13566629588603973, Lr:0.0001\n",
      "Epoch 4, Step: 573, Loss: 0.3410743474960327, Lr:0.0001\n",
      "Epoch 4, Step: 574, Loss: 0.40652602910995483, Lr:0.0001\n",
      "Epoch 4, Step: 575, Loss: 0.14289553463459015, Lr:0.0001\n",
      "Epoch 4, Step: 576, Loss: 0.22496452927589417, Lr:0.0001\n",
      "Epoch 4, Step: 577, Loss: 0.5236674547195435, Lr:0.0001\n",
      "Epoch 4, Step: 578, Loss: 0.22456024587154388, Lr:0.0001\n",
      "Epoch 4, Step: 579, Loss: 0.16169138252735138, Lr:0.0001\n",
      "Epoch 4, Step: 580, Loss: 0.0465891994535923, Lr:0.0001\n",
      "Epoch 4, Step: 581, Loss: 0.6647123098373413, Lr:0.0001\n",
      "Epoch 4, Step: 582, Loss: 0.1629926562309265, Lr:0.0001\n",
      "Epoch 4, Step: 583, Loss: 0.25731196999549866, Lr:0.0001\n",
      "Epoch 4, Step: 584, Loss: 0.04238169640302658, Lr:0.0001\n",
      "Epoch 4, Step: 585, Loss: 0.13932055234909058, Lr:0.0001\n",
      "Epoch 4, Step: 586, Loss: 0.11531636118888855, Lr:0.0001\n",
      "Epoch 4, Step: 587, Loss: 0.0623430572450161, Lr:0.0001\n",
      "Epoch 4, Step: 588, Loss: 0.13634470105171204, Lr:0.0001\n",
      "Epoch 4, Step: 589, Loss: 0.09593852609395981, Lr:0.0001\n",
      "Epoch 4, Step: 590, Loss: 0.2536865174770355, Lr:0.0001\n",
      "Epoch 4, Step: 591, Loss: 0.33119747042655945, Lr:0.0001\n",
      "Epoch 4, Step: 592, Loss: 0.6233314871788025, Lr:0.0001\n",
      "Epoch 4, Step: 593, Loss: 0.4244151711463928, Lr:0.0001\n",
      "Epoch 4, Step: 594, Loss: 0.10891225188970566, Lr:0.0001\n",
      "Epoch 4, Step: 595, Loss: 0.07454467564821243, Lr:0.0001\n",
      "Epoch 4, Step: 596, Loss: 0.1846882402896881, Lr:0.0001\n",
      "Epoch 4, Step: 597, Loss: 0.16007523238658905, Lr:0.0001\n",
      "Epoch 4, Step: 598, Loss: 0.3532733917236328, Lr:0.0001\n",
      "Epoch 4, Step: 599, Loss: 0.1795276403427124, Lr:0.0001\n",
      "Epoch 4, Step: 600, Loss: 0.23025919497013092, Lr:0.0001\n",
      "Epoch 4, Step: 601, Loss: 0.33043602108955383, Lr:0.0001\n",
      "Epoch 4, Step: 602, Loss: 0.4886060953140259, Lr:0.0001\n",
      "Epoch 4, Step: 603, Loss: 0.4019429385662079, Lr:0.0001\n",
      "Epoch 4, Step: 604, Loss: 0.3108427822589874, Lr:0.0001\n",
      "Epoch 4, Step: 605, Loss: 0.16350379586219788, Lr:0.0001\n",
      "Epoch 4, Step: 606, Loss: 0.06446728855371475, Lr:0.0001\n",
      "Epoch 4, Step: 607, Loss: 0.19117513298988342, Lr:0.0001\n",
      "Epoch 4, Step: 608, Loss: 0.1593882441520691, Lr:0.0001\n",
      "Epoch 4, Step: 609, Loss: 0.08550718426704407, Lr:0.0001\n",
      "Epoch 4, Step: 610, Loss: 0.2672988772392273, Lr:0.0001\n",
      "Epoch 4, Step: 611, Loss: 0.34496110677719116, Lr:0.0001\n",
      "Epoch 4, Step: 612, Loss: 0.39891812205314636, Lr:0.0001\n",
      "Epoch 4, Step: 613, Loss: 0.6180757880210876, Lr:0.0001\n",
      "Epoch 4, Step: 614, Loss: 0.39079979062080383, Lr:0.0001\n",
      "Epoch 4, Step: 615, Loss: 0.17791077494621277, Lr:0.0001\n",
      "Epoch 4, Step: 616, Loss: 0.24163678288459778, Lr:0.0001\n",
      "Epoch 4, Step: 617, Loss: 0.05150051787495613, Lr:0.0001\n",
      "Epoch 4, Step: 618, Loss: 0.13291218876838684, Lr:0.0001\n",
      "Epoch 4, Step: 619, Loss: 0.04110328480601311, Lr:0.0001\n",
      "Epoch 4, Step: 620, Loss: 0.2816939353942871, Lr:0.0001\n",
      "Epoch 4, Step: 621, Loss: 0.08750565350055695, Lr:0.0001\n",
      "Epoch 4, Step: 622, Loss: 0.251616507768631, Lr:0.0001\n",
      "Epoch 4, Step: 623, Loss: 0.24542585015296936, Lr:0.0001\n",
      "Epoch 4, Step: 624, Loss: 0.19807063043117523, Lr:0.0001\n",
      "Epoch 4, Step: 625, Loss: 0.3581220507621765, Lr:0.0001\n",
      "Epoch 4, Step: 626, Loss: 0.3559366762638092, Lr:0.0001\n",
      "Epoch 4, Step: 627, Loss: 0.15287663042545319, Lr:0.0001\n",
      "Epoch 4, Step: 628, Loss: 0.24253316223621368, Lr:0.0001\n",
      "Epoch 4, Step: 629, Loss: 0.29906508326530457, Lr:0.0001\n",
      "Epoch 4, Step: 630, Loss: 0.20134229958057404, Lr:0.0001\n",
      "Epoch 4, Step: 631, Loss: 0.23056215047836304, Lr:0.0001\n",
      "Epoch 4, Step: 632, Loss: 0.18319754302501678, Lr:0.0001\n",
      "Epoch 4, Step: 633, Loss: 0.21374689042568207, Lr:0.0001\n",
      "Epoch 4, Step: 634, Loss: 0.36581897735595703, Lr:0.0001\n",
      "Epoch 4, Step: 635, Loss: 0.1257142871618271, Lr:0.0001\n",
      "Epoch 4, Step: 636, Loss: 0.2581956684589386, Lr:0.0001\n",
      "Epoch 4, Step: 637, Loss: 0.1131768524646759, Lr:0.0001\n",
      "Epoch 4, Step: 638, Loss: 0.2168048769235611, Lr:0.0001\n",
      "Epoch 4, Step: 639, Loss: 0.2609124183654785, Lr:0.0001\n",
      "Epoch 4, Step: 640, Loss: 0.19818536937236786, Lr:0.0001\n",
      "Epoch 4, Step: 641, Loss: 0.17171768844127655, Lr:0.0001\n",
      "Epoch 4, Step: 642, Loss: 0.36848878860473633, Lr:0.0001\n",
      "Epoch 4, Step: 643, Loss: 0.281293123960495, Lr:0.0001\n",
      "Epoch 4, Step: 644, Loss: 0.10729103535413742, Lr:0.0001\n",
      "Epoch 4, Step: 645, Loss: 0.5771768689155579, Lr:0.0001\n",
      "Epoch 4, Step: 646, Loss: 0.1771688014268875, Lr:0.0001\n",
      "Epoch 4, Step: 647, Loss: 0.05183489993214607, Lr:0.0001\n",
      "Epoch 4, Step: 648, Loss: 0.3776076138019562, Lr:0.0001\n",
      "Epoch 4, Step: 649, Loss: 0.1036568135023117, Lr:0.0001\n",
      "Epoch 4, Step: 650, Loss: 0.43281012773513794, Lr:0.0001\n",
      "Epoch 4, Step: 651, Loss: 0.5190578103065491, Lr:0.0001\n",
      "Epoch 4, Step: 652, Loss: 0.14716540277004242, Lr:0.0001\n",
      "Epoch 4, Step: 653, Loss: 0.19268299639225006, Lr:0.0001\n",
      "Epoch 4, Step: 654, Loss: 0.5558378100395203, Lr:0.0001\n",
      "Epoch 4, Step: 655, Loss: 0.5514602661132812, Lr:0.0001\n",
      "Epoch 4, Step: 656, Loss: 0.23638999462127686, Lr:0.0001\n",
      "Epoch 4, Step: 657, Loss: 0.4580170810222626, Lr:0.0001\n",
      "Epoch 4, Step: 658, Loss: 0.16511400043964386, Lr:0.0001\n",
      "Epoch 4, Step: 659, Loss: 0.4009128510951996, Lr:0.0001\n",
      "Epoch 4, Step: 660, Loss: 0.20091795921325684, Lr:0.0001\n",
      "Epoch 4, Step: 661, Loss: 0.057596009224653244, Lr:0.0001\n",
      "Epoch 4, Step: 662, Loss: 0.23729844391345978, Lr:0.0001\n",
      "Epoch 4, Step: 663, Loss: 0.2532852590084076, Lr:0.0001\n",
      "Epoch 4, Step: 664, Loss: 0.3873683512210846, Lr:0.0001\n",
      "Epoch 4, Step: 665, Loss: 0.3751913011074066, Lr:0.0001\n",
      "Epoch 4, Step: 666, Loss: 0.01754893735051155, Lr:0.0001\n",
      "Epoch 4, Step: 667, Loss: 0.5434627532958984, Lr:0.0001\n",
      "Epoch 4, Step: 668, Loss: 0.362532377243042, Lr:0.0001\n",
      "Epoch 4, Step: 669, Loss: 0.12018237262964249, Lr:0.0001\n",
      "Epoch 4, Step: 670, Loss: 0.4283253848552704, Lr:0.0001\n",
      "Epoch 4, Step: 671, Loss: 0.2993578314781189, Lr:0.0001\n",
      "Epoch 4, Step: 672, Loss: 0.22795678675174713, Lr:0.0001\n",
      "Epoch 4, Step: 673, Loss: 0.5071502923965454, Lr:0.0001\n",
      "Epoch 4, Step: 674, Loss: 0.5860419869422913, Lr:0.0001\n",
      "Epoch 4, Step: 675, Loss: 0.18384303152561188, Lr:0.0001\n",
      "Epoch 4, Step: 676, Loss: 0.22990752756595612, Lr:0.0001\n",
      "Epoch 4, Step: 677, Loss: 0.10795825719833374, Lr:0.0001\n",
      "Epoch 4, Step: 678, Loss: 0.06705348938703537, Lr:0.0001\n",
      "Epoch 4, Step: 679, Loss: 0.41363322734832764, Lr:0.0001\n",
      "Epoch 4, Step: 680, Loss: 0.4596123993396759, Lr:0.0001\n",
      "Epoch 4, Step: 681, Loss: 0.3565452992916107, Lr:0.0001\n",
      "Epoch 4, Step: 682, Loss: 0.20611147582530975, Lr:0.0001\n",
      "Epoch 4, Step: 683, Loss: 0.08142966777086258, Lr:0.0001\n",
      "Epoch 4, Step: 684, Loss: 0.15412501990795135, Lr:0.0001\n",
      "Epoch 4, Step: 685, Loss: 0.24580129981040955, Lr:0.0001\n",
      "Epoch 4, Step: 686, Loss: 0.5268008708953857, Lr:0.0001\n",
      "Epoch 4, Step: 687, Loss: 0.20288248360157013, Lr:0.0001\n",
      "Epoch 4, Step: 688, Loss: 0.2129204124212265, Lr:0.0001\n",
      "Epoch 4, Step: 689, Loss: 0.21931636333465576, Lr:0.0001\n",
      "Epoch 4, Step: 690, Loss: 1.0496156215667725, Lr:0.0001\n",
      "Epoch 4, Step: 691, Loss: 0.5242348313331604, Lr:0.0001\n",
      "Epoch 4, Step: 692, Loss: 0.6346420049667358, Lr:0.0001\n",
      "Epoch 4, Step: 693, Loss: 0.17372822761535645, Lr:0.0001\n",
      "Epoch 4, Step: 694, Loss: 0.1571529507637024, Lr:0.0001\n",
      "Epoch 4, Step: 695, Loss: 0.547407865524292, Lr:0.0001\n",
      "Epoch 4, Step: 696, Loss: 0.38668718934059143, Lr:0.0001\n",
      "Epoch 4, Step: 697, Loss: 0.12712740898132324, Lr:0.0001\n",
      "Epoch 4, Step: 698, Loss: 0.23469671607017517, Lr:0.0001\n",
      "Epoch 4, Step: 699, Loss: 0.39343276619911194, Lr:0.0001\n",
      "Epoch 4, Step: 700, Loss: 0.38031888008117676, Lr:0.0001\n",
      "Epoch 4, Step: 701, Loss: 0.18278886377811432, Lr:0.0001\n",
      "Epoch 4, Step: 702, Loss: 0.13045719265937805, Lr:0.0001\n",
      "Epoch 4, Step: 703, Loss: 0.22717779874801636, Lr:0.0001\n",
      "Epoch 4, Step: 704, Loss: 0.8297119736671448, Lr:0.0001\n",
      "Epoch 4, Step: 705, Loss: 0.038345929235219955, Lr:0.0001\n",
      "Epoch 4, Step: 706, Loss: 0.33029040694236755, Lr:0.0001\n",
      "Epoch 4, Step: 707, Loss: 0.22004343569278717, Lr:0.0001\n",
      "Epoch 4, Step: 708, Loss: 0.4151502251625061, Lr:0.0001\n",
      "Epoch 4, Step: 709, Loss: 0.3558400273323059, Lr:0.0001\n",
      "Epoch 4, Step: 710, Loss: 0.11819370090961456, Lr:0.0001\n",
      "Epoch 4, Step: 711, Loss: 0.21904665231704712, Lr:0.0001\n",
      "Epoch 4, Step: 712, Loss: 0.3028470575809479, Lr:0.0001\n",
      "Epoch 4, Step: 713, Loss: 0.17176677286624908, Lr:0.0001\n",
      "Epoch 4, Step: 714, Loss: 0.23988500237464905, Lr:0.0001\n",
      "Epoch 4, Step: 715, Loss: 0.6124321222305298, Lr:0.0001\n",
      "Epoch 4, Step: 716, Loss: 0.5206224322319031, Lr:0.0001\n",
      "Epoch 4, Step: 717, Loss: 0.23828479647636414, Lr:0.0001\n",
      "Epoch 4, Step: 718, Loss: 0.14814169704914093, Lr:0.0001\n",
      "Epoch 4, Step: 719, Loss: 0.2928222417831421, Lr:0.0001\n",
      "Epoch 4, Step: 720, Loss: 0.4098733961582184, Lr:0.0001\n",
      "Epoch 4, Step: 721, Loss: 0.22005678713321686, Lr:0.0001\n",
      "Epoch 4, Step: 722, Loss: 0.26808780431747437, Lr:0.0001\n",
      "Epoch 4, Step: 723, Loss: 0.3587533235549927, Lr:0.0001\n",
      "Epoch 4, Step: 724, Loss: 0.29533281922340393, Lr:0.0001\n",
      "Epoch 4, Step: 725, Loss: 0.14476537704467773, Lr:0.0001\n",
      "Epoch 4, Step: 726, Loss: 0.12210825830698013, Lr:0.0001\n",
      "Epoch 4, Step: 727, Loss: 0.32466262578964233, Lr:0.0001\n",
      "Epoch 4, Step: 728, Loss: 0.19261933863162994, Lr:0.0001\n",
      "Epoch 4, Step: 729, Loss: 0.03344465419650078, Lr:0.0001\n",
      "Epoch 4, Step: 730, Loss: 0.3190196454524994, Lr:0.0001\n",
      "Epoch 4, Step: 731, Loss: 0.3640899658203125, Lr:0.0001\n",
      "Epoch 4, Step: 732, Loss: 0.15954038500785828, Lr:0.0001\n",
      "Epoch 4, Step: 733, Loss: 0.1477351188659668, Lr:0.0001\n",
      "Epoch 4, Step: 734, Loss: 0.1413184404373169, Lr:0.0001\n",
      "Epoch 4, Step: 735, Loss: 0.3433578610420227, Lr:0.0001\n",
      "Epoch 4, Step: 736, Loss: 0.7832908630371094, Lr:0.0001\n",
      "Epoch 4, Step: 737, Loss: 0.1470581740140915, Lr:0.0001\n",
      "Epoch 4, Step: 738, Loss: 0.26427170634269714, Lr:0.0001\n",
      "Epoch 4, Step: 739, Loss: 0.11261523514986038, Lr:0.0001\n",
      "Epoch 4, Step: 740, Loss: 0.15864111483097076, Lr:0.0001\n",
      "Epoch 4, Step: 741, Loss: 0.1608114093542099, Lr:0.0001\n",
      "Epoch 4, Step: 742, Loss: 0.08851079642772675, Lr:0.0001\n",
      "Epoch 4, Step: 743, Loss: 0.23781436681747437, Lr:0.0001\n",
      "Epoch 4, Step: 744, Loss: 0.11424947530031204, Lr:0.0001\n",
      "Epoch 4, Step: 745, Loss: 0.46398645639419556, Lr:0.0001\n",
      "Epoch 4, Step: 746, Loss: 0.10611460357904434, Lr:0.0001\n",
      "Epoch 4, Step: 747, Loss: 0.2118508368730545, Lr:0.0001\n",
      "Epoch 4, Step: 748, Loss: 0.12417832762002945, Lr:0.0001\n",
      "Epoch 4, Step: 749, Loss: 0.15499813854694366, Lr:0.0001\n",
      "Epoch 4, Step: 750, Loss: 0.12563441693782806, Lr:0.0001\n",
      "Epoch 4, Step: 751, Loss: 0.48351946473121643, Lr:0.0001\n",
      "Epoch 4, Step: 752, Loss: 0.26810094714164734, Lr:0.0001\n",
      "Epoch 4, Step: 753, Loss: 0.350801020860672, Lr:0.0001\n",
      "Epoch 4, Step: 754, Loss: 0.5826607346534729, Lr:0.0001\n",
      "Epoch 4, Step: 755, Loss: 0.22068047523498535, Lr:0.0001\n",
      "Epoch 4, Step: 756, Loss: 0.2437131255865097, Lr:0.0001\n",
      "Epoch 4, Step: 757, Loss: 0.4516962170600891, Lr:0.0001\n",
      "Epoch 4, Step: 758, Loss: 0.15069520473480225, Lr:0.0001\n",
      "Epoch 4, Step: 759, Loss: 0.13188283145427704, Lr:0.0001\n",
      "Epoch 4, Step: 760, Loss: 0.5157479047775269, Lr:0.0001\n",
      "Epoch 4, Step: 761, Loss: 0.09726187586784363, Lr:0.0001\n",
      "Epoch 4, Step: 762, Loss: 0.4653685688972473, Lr:0.0001\n",
      "Epoch 4, Step: 763, Loss: 0.2387169748544693, Lr:0.0001\n",
      "Epoch 4, Step: 764, Loss: 0.24329979717731476, Lr:0.0001\n",
      "Epoch 4, Step: 765, Loss: 0.23926924169063568, Lr:0.0001\n",
      "Epoch 4, Step: 766, Loss: 0.26299771666526794, Lr:0.0001\n",
      "Epoch 4, Step: 767, Loss: 0.10072674602270126, Lr:0.0001\n",
      "Epoch 4, Step: 768, Loss: 0.08749839663505554, Lr:0.0001\n",
      "Epoch 4, Step: 769, Loss: 0.18431295454502106, Lr:0.0001\n",
      "Epoch 4, Step: 770, Loss: 0.19535112380981445, Lr:0.0001\n",
      "Epoch 4, Step: 771, Loss: 0.22459110617637634, Lr:0.0001\n",
      "Epoch 4, Step: 772, Loss: 0.43874335289001465, Lr:0.0001\n",
      "Epoch 4, Step: 773, Loss: 0.18812671303749084, Lr:0.0001\n",
      "Epoch 4, Step: 774, Loss: 0.18428395688533783, Lr:0.0001\n",
      "Epoch 4, Step: 775, Loss: 0.08595320582389832, Lr:0.0001\n",
      "Epoch 4, Step: 776, Loss: 0.4989943504333496, Lr:0.0001\n",
      "Epoch 4, Step: 777, Loss: 0.33212828636169434, Lr:0.0001\n",
      "Epoch 4, Step: 778, Loss: 0.06952381134033203, Lr:0.0001\n",
      "Epoch 4, Step: 779, Loss: 0.20894066989421844, Lr:0.0001\n",
      "Epoch 4, Step: 780, Loss: 0.17272645235061646, Lr:0.0001\n",
      "Epoch 4, Step: 781, Loss: 0.10468184947967529, Lr:0.0001\n",
      "Epoch 4, Step: 782, Loss: 0.19327522814273834, Lr:0.0001\n",
      "Epoch 4, Step: 783, Loss: 0.14780747890472412, Lr:0.0001\n",
      "Epoch 4, Step: 784, Loss: 0.384021520614624, Lr:0.0001\n",
      "Epoch 4, Step: 785, Loss: 0.43235892057418823, Lr:0.0001\n",
      "Epoch 4, Step: 786, Loss: 0.12771129608154297, Lr:0.0001\n",
      "Epoch 4, Step: 787, Loss: 0.16012251377105713, Lr:0.0001\n",
      "Epoch 4, Step: 788, Loss: 0.5179206132888794, Lr:0.0001\n",
      "Epoch 4, Step: 789, Loss: 0.12424018979072571, Lr:0.0001\n",
      "Epoch 4, Step: 790, Loss: 0.13847599923610687, Lr:0.0001\n",
      "Epoch 4, Step: 791, Loss: 0.185774028301239, Lr:0.0001\n",
      "Epoch 4, Step: 792, Loss: 0.5004795789718628, Lr:0.0001\n",
      "Epoch 4, Step: 793, Loss: 0.1361556351184845, Lr:0.0001\n",
      "Epoch 4, Step: 794, Loss: 0.4979875087738037, Lr:0.0001\n",
      "Epoch 4, Step: 795, Loss: 0.2709943354129791, Lr:0.0001\n",
      "Epoch 4, Step: 796, Loss: 0.27683642506599426, Lr:0.0001\n",
      "Epoch 4, Step: 797, Loss: 0.23099574446678162, Lr:0.0001\n",
      "Epoch 4, Step: 798, Loss: 0.3367508053779602, Lr:0.0001\n",
      "Epoch 4, Step: 799, Loss: 0.28456491231918335, Lr:0.0001\n",
      "Epoch 4, Step: 800, Loss: 0.08526482433080673, Lr:0.0001\n",
      "Epoch 4, Step: 801, Loss: 0.177876278758049, Lr:0.0001\n",
      "Epoch 4, Step: 802, Loss: 0.2784193754196167, Lr:0.0001\n",
      "Epoch 4, Step: 803, Loss: 0.2421451210975647, Lr:0.0001\n",
      "Epoch 4, Step: 804, Loss: 0.4254522919654846, Lr:0.0001\n",
      "Epoch 4, Step: 805, Loss: 0.31516483426094055, Lr:0.0001\n",
      "Epoch 4, Step: 806, Loss: 0.12083634734153748, Lr:0.0001\n",
      "Epoch 4, Step: 807, Loss: 0.36644601821899414, Lr:0.0001\n",
      "Epoch 4, Step: 808, Loss: 0.223471537232399, Lr:0.0001\n",
      "Epoch 4, Step: 809, Loss: 0.6263728141784668, Lr:0.0001\n",
      "Epoch 4, Step: 810, Loss: 0.3446158766746521, Lr:0.0001\n",
      "Epoch 4, Step: 811, Loss: 0.160330668091774, Lr:0.0001\n",
      "Epoch 4, Step: 812, Loss: 0.30483394861221313, Lr:0.0001\n",
      "Epoch 4, Step: 813, Loss: 0.05393611267209053, Lr:0.0001\n",
      "Epoch 4, Step: 814, Loss: 0.3040234446525574, Lr:0.0001\n",
      "Epoch 4, Step: 815, Loss: 0.34456729888916016, Lr:0.0001\n",
      "Epoch 4, Step: 816, Loss: 0.08528018742799759, Lr:0.0001\n",
      "Epoch 4, Step: 817, Loss: 0.21953421831130981, Lr:0.0001\n",
      "Epoch 4, Step: 818, Loss: 0.08042337000370026, Lr:0.0001\n",
      "Epoch 4, Step: 819, Loss: 0.14486458897590637, Lr:0.0001\n",
      "Epoch 4, Step: 820, Loss: 0.1643885225057602, Lr:0.0001\n",
      "Epoch 4, Step: 821, Loss: 0.20019444823265076, Lr:0.0001\n",
      "Epoch 4, Step: 822, Loss: 0.23263050615787506, Lr:0.0001\n",
      "Epoch 4, Step: 823, Loss: 0.1827576458454132, Lr:0.0001\n",
      "Epoch 4, Step: 824, Loss: 0.15112358331680298, Lr:0.0001\n",
      "Epoch 4, Step: 825, Loss: 0.1909482330083847, Lr:0.0001\n",
      "Epoch 4, Step: 826, Loss: 0.22285498678684235, Lr:0.0001\n",
      "Epoch 4, Step: 827, Loss: 0.160428985953331, Lr:0.0001\n",
      "Epoch 4, Step: 828, Loss: 0.38594889640808105, Lr:0.0001\n",
      "Epoch 4, Step: 829, Loss: 0.3084859549999237, Lr:0.0001\n",
      "Epoch 4, Step: 830, Loss: 0.13288062810897827, Lr:0.0001\n",
      "Epoch 4, Step: 831, Loss: 0.5853375196456909, Lr:0.0001\n",
      "Epoch 4, Step: 832, Loss: 0.1462162435054779, Lr:0.0001\n",
      "Epoch 4, Step: 833, Loss: 0.1553611159324646, Lr:0.0001\n",
      "Epoch 4, Step: 834, Loss: 0.13654714822769165, Lr:0.0001\n",
      "Epoch 4, Step: 835, Loss: 0.1791100651025772, Lr:0.0001\n",
      "Epoch 4, Step: 836, Loss: 0.17231033742427826, Lr:0.0001\n",
      "Epoch 4, Step: 837, Loss: 0.27760791778564453, Lr:0.0001\n",
      "Epoch 4, Step: 838, Loss: 0.1723109781742096, Lr:0.0001\n",
      "Epoch 4, Step: 839, Loss: 0.21004557609558105, Lr:0.0001\n",
      "Epoch 4, Step: 840, Loss: 0.15217559039592743, Lr:0.0001\n",
      "Epoch 4, Step: 841, Loss: 0.2884317934513092, Lr:0.0001\n",
      "Epoch 4, Step: 842, Loss: 0.04801476374268532, Lr:0.0001\n",
      "Epoch 4, Step: 843, Loss: 0.3098675012588501, Lr:0.0001\n",
      "Epoch 4, Step: 844, Loss: 0.19384455680847168, Lr:0.0001\n",
      "Epoch 4, Step: 845, Loss: 0.23540128767490387, Lr:0.0001\n",
      "Epoch 4, Step: 846, Loss: 0.21256227791309357, Lr:0.0001\n",
      "Epoch 4, Step: 847, Loss: 0.24932809174060822, Lr:0.0001\n",
      "Epoch 4, Step: 848, Loss: 0.14345701038837433, Lr:0.0001\n",
      "Epoch 4, Step: 849, Loss: 0.4055376350879669, Lr:0.0001\n",
      "Epoch 4, Step: 850, Loss: 0.20519129931926727, Lr:0.0001\n",
      "Epoch 4, Step: 851, Loss: 0.13272042572498322, Lr:0.0001\n",
      "Epoch 4, Step: 852, Loss: 0.4288201928138733, Lr:0.0001\n",
      "Epoch 4, Step: 853, Loss: 0.4002826511859894, Lr:0.0001\n",
      "Epoch 4, Step: 854, Loss: 0.22606226801872253, Lr:0.0001\n",
      "Epoch 4, Step: 855, Loss: 0.24408580362796783, Lr:0.0001\n",
      "Epoch 4, Step: 856, Loss: 0.26161450147628784, Lr:0.0001\n",
      "Epoch 4, Step: 857, Loss: 0.17016874253749847, Lr:0.0001\n",
      "Epoch 4, Step: 858, Loss: 0.26448750495910645, Lr:0.0001\n",
      "Epoch 4, Step: 859, Loss: 0.30299797654151917, Lr:0.0001\n",
      "Epoch 4, Step: 860, Loss: 0.21275916695594788, Lr:0.0001\n",
      "Epoch 4, Step: 861, Loss: 0.27207398414611816, Lr:0.0001\n",
      "Epoch 4, Step: 862, Loss: 0.11955646425485611, Lr:0.0001\n",
      "Epoch 4, Step: 863, Loss: 0.24613229930400848, Lr:0.0001\n",
      "Epoch 4, Step: 864, Loss: 0.19689702987670898, Lr:0.0001\n",
      "Epoch 4, Step: 865, Loss: 0.26317694783210754, Lr:0.0001\n",
      "Epoch 4, Step: 866, Loss: 0.14535614848136902, Lr:0.0001\n",
      "Epoch 4, Step: 867, Loss: 0.6280604600906372, Lr:0.0001\n",
      "Epoch 4, Step: 868, Loss: 0.1712912619113922, Lr:0.0001\n",
      "Epoch 4, Step: 869, Loss: 0.204519584774971, Lr:0.0001\n",
      "Epoch 4, Step: 870, Loss: 0.37066587805747986, Lr:0.0001\n",
      "Epoch 4, Step: 871, Loss: 0.21614526212215424, Lr:0.0001\n",
      "Epoch 4, Step: 872, Loss: 0.29559364914894104, Lr:0.0001\n",
      "Epoch 4, Step: 873, Loss: 0.27952703833580017, Lr:0.0001\n",
      "Epoch 4, Step: 874, Loss: 0.3527087867259979, Lr:0.0001\n",
      "Epoch 4, Step: 875, Loss: 0.14479421079158783, Lr:0.0001\n",
      "Epoch 4, Step: 876, Loss: 0.05732167884707451, Lr:0.0001\n",
      "Epoch 4, Step: 877, Loss: 0.1282738447189331, Lr:0.0001\n",
      "Epoch 4, Step: 878, Loss: 0.08536922931671143, Lr:0.0001\n",
      "Epoch 4, Step: 879, Loss: 0.15074169635772705, Lr:0.0001\n",
      "Epoch 4, Step: 880, Loss: 0.08678727596998215, Lr:0.0001\n",
      "Epoch 4, Step: 881, Loss: 0.19585715234279633, Lr:0.0001\n",
      "Epoch 4, Step: 882, Loss: 0.4234868288040161, Lr:0.0001\n",
      "Epoch 4, Step: 883, Loss: 0.1431470364332199, Lr:0.0001\n",
      "Epoch 4, Step: 884, Loss: 0.40865665674209595, Lr:0.0001\n",
      "Epoch 4, Step: 885, Loss: 0.2082975208759308, Lr:0.0001\n",
      "Epoch 4, Step: 886, Loss: 0.24064666032791138, Lr:0.0001\n",
      "Epoch 4, Step: 887, Loss: 0.2572546601295471, Lr:0.0001\n",
      "Epoch 4, Step: 888, Loss: 0.22694022953510284, Lr:0.0001\n",
      "Epoch 4, Step: 889, Loss: 0.19147169589996338, Lr:0.0001\n",
      "Epoch 4, Step: 890, Loss: 0.17098288238048553, Lr:0.0001\n",
      "Epoch 4, Step: 891, Loss: 0.08880501985549927, Lr:0.0001\n",
      "Epoch 4, Step: 892, Loss: 0.2029479295015335, Lr:0.0001\n",
      "Epoch 4, Step: 893, Loss: 0.28895288705825806, Lr:0.0001\n",
      "Epoch 4, Step: 894, Loss: 0.14283469319343567, Lr:0.0001\n",
      "Epoch 4, Step: 895, Loss: 0.07086150348186493, Lr:0.0001\n",
      "Epoch 4, Step: 896, Loss: 0.1109461709856987, Lr:0.0001\n",
      "Epoch 4, Step: 897, Loss: 0.26140138506889343, Lr:0.0001\n",
      "Epoch 4, Step: 898, Loss: 0.32244694232940674, Lr:0.0001\n",
      "Epoch 4, Step: 899, Loss: 0.4205378592014313, Lr:0.0001\n",
      "Epoch 4, Step: 900, Loss: 0.3835452198982239, Lr:0.0001\n",
      "Epoch 4, Step: 901, Loss: 0.08643945306539536, Lr:0.0001\n",
      "Epoch 4, Step: 902, Loss: 0.14960086345672607, Lr:0.0001\n",
      "Epoch 4, Step: 903, Loss: 0.15025824308395386, Lr:0.0001\n",
      "Epoch 4, Step: 904, Loss: 0.11830423027276993, Lr:0.0001\n",
      "Epoch 4, Step: 905, Loss: 0.3718976676464081, Lr:0.0001\n",
      "Epoch 4, Step: 906, Loss: 0.08935723453760147, Lr:0.0001\n",
      "Epoch 4, Step: 907, Loss: 0.04451698809862137, Lr:0.0001\n",
      "Epoch 4, Step: 908, Loss: 0.23999139666557312, Lr:0.0001\n",
      "Epoch 4, Step: 909, Loss: 0.1376204937696457, Lr:0.0001\n",
      "Epoch 4, Step: 910, Loss: 0.5915821194648743, Lr:0.0001\n",
      "Epoch 4, Step: 911, Loss: 0.5765319466590881, Lr:0.0001\n",
      "Epoch 4, Step: 912, Loss: 0.14264285564422607, Lr:0.0001\n",
      "Epoch 4, Step: 913, Loss: 0.1691577285528183, Lr:0.0001\n",
      "Epoch 4, Step: 914, Loss: 0.15038534998893738, Lr:0.0001\n",
      "Epoch 4, Step: 915, Loss: 0.09760035574436188, Lr:0.0001\n",
      "Epoch 4, Step: 916, Loss: 0.17291495203971863, Lr:0.0001\n",
      "Epoch 4, Step: 917, Loss: 0.369442343711853, Lr:0.0001\n",
      "Epoch 4, Step: 918, Loss: 0.12750743329524994, Lr:0.0001\n",
      "Epoch 4, Step: 919, Loss: 0.15903587639331818, Lr:0.0001\n",
      "Epoch 4, Step: 920, Loss: 0.19822269678115845, Lr:0.0001\n",
      "Epoch 4, Step: 921, Loss: 0.2478305995464325, Lr:0.0001\n",
      "Epoch 4, Step: 922, Loss: 0.06739272177219391, Lr:0.0001\n",
      "Epoch 4, Step: 923, Loss: 0.09760135412216187, Lr:0.0001\n",
      "Epoch 4, Step: 924, Loss: 0.22915132343769073, Lr:0.0001\n",
      "Epoch 4, Step: 925, Loss: 0.5141069293022156, Lr:0.0001\n",
      "Epoch 4, Step: 926, Loss: 0.36847469210624695, Lr:0.0001\n",
      "Epoch 4, Step: 927, Loss: 0.2900640070438385, Lr:0.0001\n",
      "Epoch 4, Step: 928, Loss: 0.5259324908256531, Lr:0.0001\n",
      "Epoch 4, Step: 929, Loss: 0.3864017128944397, Lr:0.0001\n",
      "Epoch 4, Step: 930, Loss: 0.09486125409603119, Lr:0.0001\n",
      "Epoch 4, Step: 931, Loss: 0.17479100823402405, Lr:0.0001\n",
      "Epoch 4, Step: 932, Loss: 0.2997889816761017, Lr:0.0001\n",
      "Epoch 4, Step: 933, Loss: 0.27552905678749084, Lr:0.0001\n",
      "Epoch 4, Step: 934, Loss: 0.24374040961265564, Lr:0.0001\n",
      "Epoch 4, Step: 935, Loss: 0.45557963848114014, Lr:0.0001\n",
      "Epoch 4, Step: 936, Loss: 0.22126753628253937, Lr:0.0001\n",
      "Epoch 4, Step: 937, Loss: 0.2064085304737091, Lr:0.0001\n",
      "Epoch 4, Step: 938, Loss: 0.2517785131931305, Lr:0.0001\n",
      "Epoch 4, Step: 939, Loss: 0.06312309205532074, Lr:0.0001\n",
      "Epoch 4, Step: 940, Loss: 0.2025957703590393, Lr:0.0001\n",
      "Epoch 4, Step: 941, Loss: 0.10597241669893265, Lr:0.0001\n",
      "Epoch 4, Step: 942, Loss: 0.11847253888845444, Lr:0.0001\n",
      "Epoch 4, Step: 943, Loss: 0.2958560585975647, Lr:0.0001\n",
      "Epoch 4, Step: 944, Loss: 0.11767277866601944, Lr:0.0001\n",
      "Epoch 4, Step: 945, Loss: 0.3905434012413025, Lr:0.0001\n",
      "Epoch 4, Step: 946, Loss: 0.1111811175942421, Lr:0.0001\n",
      "Epoch 4, Step: 947, Loss: 0.30936118960380554, Lr:0.0001\n",
      "Epoch 4, Step: 948, Loss: 0.20584827661514282, Lr:0.0001\n",
      "Epoch 4, Step: 949, Loss: 0.4175250232219696, Lr:0.0001\n",
      "Epoch 4, Step: 950, Loss: 0.18326754868030548, Lr:0.0001\n",
      "Epoch 4, Step: 951, Loss: 0.2774204909801483, Lr:0.0001\n",
      "Epoch 4, Step: 952, Loss: 0.2879054546356201, Lr:0.0001\n",
      "Epoch 4, Step: 953, Loss: 0.29939496517181396, Lr:0.0001\n",
      "Epoch 4, Step: 954, Loss: 0.27091431617736816, Lr:0.0001\n",
      "Epoch 4, Step: 955, Loss: 0.10256322473287582, Lr:0.0001\n",
      "Epoch 4, Step: 956, Loss: 0.4380064904689789, Lr:0.0001\n",
      "Epoch 4, Step: 957, Loss: 0.05669877305626869, Lr:0.0001\n",
      "Epoch 4, Step: 958, Loss: 0.2225589156150818, Lr:0.0001\n",
      "Epoch 4, Step: 959, Loss: 0.16412411630153656, Lr:0.0001\n",
      "Epoch 4, Step: 960, Loss: 0.06273174285888672, Lr:0.0001\n",
      "Epoch 4, Step: 961, Loss: 0.4970253109931946, Lr:0.0001\n",
      "Epoch 4, Step: 962, Loss: 0.16013486683368683, Lr:0.0001\n",
      "Epoch 4, Step: 963, Loss: 0.37198489904403687, Lr:0.0001\n",
      "Epoch 4, Step: 964, Loss: 0.130437433719635, Lr:0.0001\n",
      "Epoch 4, Step: 965, Loss: 0.07285233587026596, Lr:0.0001\n",
      "Epoch 4, Step: 966, Loss: 0.17625121772289276, Lr:0.0001\n",
      "Epoch 4, Step: 967, Loss: 0.3375050723552704, Lr:0.0001\n",
      "Epoch 4, Step: 968, Loss: 0.2688486874103546, Lr:0.0001\n",
      "Epoch 4, Step: 969, Loss: 0.09028033167123795, Lr:0.0001\n",
      "Epoch 4, Step: 970, Loss: 1.1154459714889526, Lr:0.0001\n",
      "Epoch 4, Step: 971, Loss: 0.2390761375427246, Lr:0.0001\n",
      "Epoch 4, Step: 972, Loss: 0.057917796075344086, Lr:0.0001\n",
      "Epoch 4, Step: 973, Loss: 0.44436317682266235, Lr:0.0001\n",
      "Epoch 4, Step: 974, Loss: 0.29653221368789673, Lr:0.0001\n",
      "Epoch 4, Step: 975, Loss: 0.21433256566524506, Lr:0.0001\n",
      "Epoch 4, Step: 976, Loss: 0.15941497683525085, Lr:0.0001\n",
      "Epoch 4, Step: 977, Loss: 0.12034685164690018, Lr:0.0001\n",
      "Epoch 4, Step: 978, Loss: 0.12140923738479614, Lr:0.0001\n",
      "Epoch 4, Step: 979, Loss: 0.069959856569767, Lr:0.0001\n",
      "Epoch 4, Step: 980, Loss: 0.2981506586074829, Lr:0.0001\n",
      "Epoch 4, Step: 981, Loss: 0.2203039675951004, Lr:0.0001\n",
      "Epoch 4, Step: 982, Loss: 0.21872040629386902, Lr:0.0001\n",
      "Epoch 4, Step: 983, Loss: 0.3371351659297943, Lr:0.0001\n",
      "Epoch 4, Step: 984, Loss: 0.1210276335477829, Lr:0.0001\n",
      "Epoch 4, Step: 985, Loss: 0.12585130333900452, Lr:0.0001\n",
      "Epoch 4, Step: 986, Loss: 0.18513378500938416, Lr:0.0001\n",
      "Epoch 4, Step: 987, Loss: 0.2505723536014557, Lr:0.0001\n",
      "Epoch 4, Step: 988, Loss: 0.056571364402770996, Lr:0.0001\n",
      "Epoch 4, Step: 989, Loss: 0.241622656583786, Lr:0.0001\n",
      "Epoch 4, Step: 990, Loss: 0.3889162540435791, Lr:0.0001\n",
      "Epoch 4, Step: 991, Loss: 0.18011821806430817, Lr:0.0001\n",
      "Epoch 4, Step: 992, Loss: 0.33326971530914307, Lr:0.0001\n",
      "Epoch 4, Step: 993, Loss: 0.0764264464378357, Lr:0.0001\n",
      "Epoch 4, Step: 994, Loss: 0.11149635910987854, Lr:0.0001\n",
      "Epoch 4, Step: 995, Loss: 0.7136000990867615, Lr:0.0001\n",
      "Epoch 4, Step: 996, Loss: 0.260395348072052, Lr:0.0001\n",
      "Epoch 4, Step: 997, Loss: 0.18912574648857117, Lr:0.0001\n",
      "Epoch 4, Step: 998, Loss: 0.2659212648868561, Lr:0.0001\n",
      "Epoch 4, Step: 999, Loss: 0.1989930421113968, Lr:0.0001\n",
      "Epoch 4, Step: 1000, Loss: 0.12734538316726685, Lr:0.0001\n",
      "Epoch 4, Step: 1001, Loss: 0.3284408748149872, Lr:0.0001\n",
      "Epoch 4, Step: 1002, Loss: 0.31291598081588745, Lr:0.0001\n",
      "Epoch 4, Step: 1003, Loss: 0.178231880068779, Lr:0.0001\n",
      "Epoch 4, Step: 1004, Loss: 0.19137704372406006, Lr:0.0001\n",
      "Epoch 4, Step: 1005, Loss: 0.39777788519859314, Lr:0.0001\n",
      "Epoch 4, Step: 1006, Loss: 0.15261532366275787, Lr:0.0001\n",
      "Epoch 4, Step: 1007, Loss: 0.12589465081691742, Lr:0.0001\n",
      "Epoch 4, Step: 1008, Loss: 0.18956686556339264, Lr:0.0001\n",
      "Epoch 4, Step: 1009, Loss: 0.19980137050151825, Lr:0.0001\n",
      "Epoch 4, Step: 1010, Loss: 0.44971367716789246, Lr:0.0001\n",
      "Epoch 4, Step: 1011, Loss: 0.043757982552051544, Lr:0.0001\n",
      "Epoch 4, Step: 1012, Loss: 0.3479694128036499, Lr:0.0001\n",
      "Epoch 4, Step: 1013, Loss: 0.26157668232917786, Lr:0.0001\n",
      "Epoch 4, Step: 1014, Loss: 0.36888423562049866, Lr:0.0001\n",
      "Epoch 4, Step: 1015, Loss: 0.09704102575778961, Lr:0.0001\n",
      "Epoch 4, Step: 1016, Loss: 0.2834794521331787, Lr:0.0001\n",
      "Epoch 4, Step: 1017, Loss: 0.12906208634376526, Lr:0.0001\n",
      "Epoch 4, Step: 1018, Loss: 0.49308228492736816, Lr:0.0001\n",
      "Epoch 4, Step: 1019, Loss: 0.12424886226654053, Lr:0.0001\n",
      "Epoch 4, Step: 1020, Loss: 0.2191164344549179, Lr:0.0001\n",
      "Epoch 4, Step: 1021, Loss: 0.20755885541439056, Lr:0.0001\n",
      "Epoch 4, Step: 1022, Loss: 0.3259712755680084, Lr:0.0001\n",
      "Epoch 4, Step: 1023, Loss: 0.35407567024230957, Lr:0.0001\n",
      "Epoch 4, Step: 1024, Loss: 0.6492186188697815, Lr:0.0001\n",
      "Epoch 4, Step: 1025, Loss: 0.12633904814720154, Lr:0.0001\n",
      "Epoch 4, Step: 1026, Loss: 0.2710600793361664, Lr:0.0001\n",
      "Epoch 4, Step: 1027, Loss: 0.11282378435134888, Lr:0.0001\n",
      "Epoch 4, Step: 1028, Loss: 0.12006967514753342, Lr:0.0001\n",
      "Epoch 4, Step: 1029, Loss: 0.1938307136297226, Lr:0.0001\n",
      "Epoch 4, Step: 1030, Loss: 0.27280333638191223, Lr:0.0001\n",
      "Epoch 4, Step: 1031, Loss: 0.48815226554870605, Lr:0.0001\n",
      "Epoch 4, Step: 1032, Loss: 0.3042719066143036, Lr:0.0001\n",
      "Epoch 4, Step: 1033, Loss: 0.2927257716655731, Lr:0.0001\n",
      "Epoch 4, Step: 1034, Loss: 0.24240298569202423, Lr:0.0001\n",
      "Epoch 4, Step: 1035, Loss: 0.35443443059921265, Lr:0.0001\n",
      "Epoch 4, Step: 1036, Loss: 0.13028331100940704, Lr:0.0001\n",
      "Epoch 4, Step: 1037, Loss: 0.31457948684692383, Lr:0.0001\n",
      "Epoch 4, Step: 1038, Loss: 0.3660030663013458, Lr:0.0001\n",
      "Epoch 4, Step: 1039, Loss: 0.14802178740501404, Lr:0.0001\n",
      "Epoch 4, Step: 1040, Loss: 0.14007189869880676, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 4\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:16 loss: 0.4332 (0.4332) acc1: 81.2500 (81.2500) acc5: 100.0000 (100.0000) time: 0.2906 data: 0.1224 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.0143 (0.1095) acc1: 100.0000 (96.0227) acc5: 100.0000 (100.0000) time: 0.2913 data: 0.1147 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0143 (0.1073) acc1: 100.0000 (96.7262) acc5: 100.0000 (100.0000) time: 0.2980 data: 0.1153 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.1615 (0.4392) acc1: 93.7500 (86.8952) acc5: 100.0000 (100.0000) time: 0.3009 data: 0.1204 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.8803 (0.5554) acc1: 62.5000 (83.0793) acc5: 100.0000 (100.0000) time: 0.2993 data: 0.1250 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.1102 (0.4920) acc1: 93.7500 (84.6814) acc5: 100.0000 (100.0000) time: 0.2998 data: 0.1237 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0312 (0.4538) acc1: 100.0000 (85.6981) acc5: 100.0000 (100.0000) time: 0.2857 data: 0.1162 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.2934 s / it)\n",
      "* Acc@1 85.698 Acc@5 100.000 loss 0.454\n",
      "Accuracy of the network on the 881 test image: 85.7%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 5, Step: 0, Loss: 0.0946945920586586, Lr:0.0001\n",
      "Epoch 5, Step: 1, Loss: 0.27325916290283203, Lr:0.0001\n",
      "Epoch 5, Step: 2, Loss: 0.2017619013786316, Lr:0.0001\n",
      "Epoch 5, Step: 3, Loss: 0.12302331626415253, Lr:0.0001\n",
      "Epoch 5, Step: 4, Loss: 0.3242000341415405, Lr:0.0001\n",
      "Epoch 5, Step: 5, Loss: 0.0976811870932579, Lr:0.0001\n",
      "Epoch 5, Step: 6, Loss: 0.12222647666931152, Lr:0.0001\n",
      "Epoch 5, Step: 7, Loss: 0.20480553805828094, Lr:0.0001\n",
      "Epoch 5, Step: 8, Loss: 0.27128535509109497, Lr:0.0001\n",
      "Epoch 5, Step: 9, Loss: 0.1680484563112259, Lr:0.0001\n",
      "Epoch 5, Step: 10, Loss: 0.29896050691604614, Lr:0.0001\n",
      "Epoch 5, Step: 11, Loss: 0.2731110453605652, Lr:0.0001\n",
      "Epoch 5, Step: 12, Loss: 0.48349735140800476, Lr:0.0001\n",
      "Epoch 5, Step: 13, Loss: 0.21168547868728638, Lr:0.0001\n",
      "Epoch 5, Step: 14, Loss: 0.051264483481645584, Lr:0.0001\n",
      "Epoch 5, Step: 15, Loss: 0.1205718070268631, Lr:0.0001\n",
      "Epoch 5, Step: 16, Loss: 0.1368907392024994, Lr:0.0001\n",
      "Epoch 5, Step: 17, Loss: 0.159002885222435, Lr:0.0001\n",
      "Epoch 5, Step: 18, Loss: 0.1957598477602005, Lr:0.0001\n",
      "Epoch 5, Step: 19, Loss: 0.12912306189537048, Lr:0.0001\n",
      "Epoch 5, Step: 20, Loss: 0.15490001440048218, Lr:0.0001\n",
      "Epoch 5, Step: 21, Loss: 0.17816297709941864, Lr:0.0001\n",
      "Epoch 5, Step: 22, Loss: 0.39336511492729187, Lr:0.0001\n",
      "Epoch 5, Step: 23, Loss: 0.1283293217420578, Lr:0.0001\n",
      "Epoch 5, Step: 24, Loss: 0.10192801803350449, Lr:0.0001\n",
      "Epoch 5, Step: 25, Loss: 0.34399348497390747, Lr:0.0001\n",
      "Epoch 5, Step: 26, Loss: 0.1571277529001236, Lr:0.0001\n",
      "Epoch 5, Step: 27, Loss: 0.1432277113199234, Lr:0.0001\n",
      "Epoch 5, Step: 28, Loss: 0.14982891082763672, Lr:0.0001\n",
      "Epoch 5, Step: 29, Loss: 0.23016344010829926, Lr:0.0001\n",
      "Epoch 5, Step: 30, Loss: 0.040971409529447556, Lr:0.0001\n",
      "Epoch 5, Step: 31, Loss: 0.36065325140953064, Lr:0.0001\n",
      "Epoch 5, Step: 32, Loss: 0.417125403881073, Lr:0.0001\n",
      "Epoch 5, Step: 33, Loss: 0.08341497927904129, Lr:0.0001\n",
      "Epoch 5, Step: 34, Loss: 0.12383922934532166, Lr:0.0001\n",
      "Epoch 5, Step: 35, Loss: 0.28725045919418335, Lr:0.0001\n",
      "Epoch 5, Step: 36, Loss: 0.6319762468338013, Lr:0.0001\n",
      "Epoch 5, Step: 37, Loss: 0.39516159892082214, Lr:0.0001\n",
      "Epoch 5, Step: 38, Loss: 0.28256797790527344, Lr:0.0001\n",
      "Epoch 5, Step: 39, Loss: 0.1133885309100151, Lr:0.0001\n",
      "Epoch 5, Step: 40, Loss: 0.058945320546627045, Lr:0.0001\n",
      "Epoch 5, Step: 41, Loss: 0.03686893358826637, Lr:0.0001\n",
      "Epoch 5, Step: 42, Loss: 0.10441189259290695, Lr:0.0001\n",
      "Epoch 5, Step: 43, Loss: 0.11981156468391418, Lr:0.0001\n",
      "Epoch 5, Step: 44, Loss: 0.0848996639251709, Lr:0.0001\n",
      "Epoch 5, Step: 45, Loss: 0.4444085955619812, Lr:0.0001\n",
      "Epoch 5, Step: 46, Loss: 0.16228324174880981, Lr:0.0001\n",
      "Epoch 5, Step: 47, Loss: 0.1565781831741333, Lr:0.0001\n",
      "Epoch 5, Step: 48, Loss: 0.278901070356369, Lr:0.0001\n",
      "Epoch 5, Step: 49, Loss: 0.11210300773382187, Lr:0.0001\n",
      "Epoch 5, Step: 50, Loss: 0.4275652766227722, Lr:0.0001\n",
      "Epoch 5, Step: 51, Loss: 0.030261626467108727, Lr:0.0001\n",
      "Epoch 5, Step: 52, Loss: 0.29702988266944885, Lr:0.0001\n",
      "Epoch 5, Step: 53, Loss: 0.06644795089960098, Lr:0.0001\n",
      "Epoch 5, Step: 54, Loss: 0.6199363470077515, Lr:0.0001\n",
      "Epoch 5, Step: 55, Loss: 0.5824182629585266, Lr:0.0001\n",
      "Epoch 5, Step: 56, Loss: 0.1334807276725769, Lr:0.0001\n",
      "Epoch 5, Step: 57, Loss: 0.214141383767128, Lr:0.0001\n",
      "Epoch 5, Step: 58, Loss: 0.20860087871551514, Lr:0.0001\n",
      "Epoch 5, Step: 59, Loss: 0.10240275412797928, Lr:0.0001\n",
      "Epoch 5, Step: 60, Loss: 0.07481982558965683, Lr:0.0001\n",
      "Epoch 5, Step: 61, Loss: 0.34979480504989624, Lr:0.0001\n",
      "Epoch 5, Step: 62, Loss: 0.08556199073791504, Lr:0.0001\n",
      "Epoch 5, Step: 63, Loss: 0.1753777265548706, Lr:0.0001\n",
      "Epoch 5, Step: 64, Loss: 0.07565942406654358, Lr:0.0001\n",
      "Epoch 5, Step: 65, Loss: 0.20273961126804352, Lr:0.0001\n",
      "Epoch 5, Step: 66, Loss: 0.19276633858680725, Lr:0.0001\n",
      "Epoch 5, Step: 67, Loss: 0.49488407373428345, Lr:0.0001\n",
      "Epoch 5, Step: 68, Loss: 0.3951594829559326, Lr:0.0001\n",
      "Epoch 5, Step: 69, Loss: 0.32749587297439575, Lr:0.0001\n",
      "Epoch 5, Step: 70, Loss: 0.1345149278640747, Lr:0.0001\n",
      "Epoch 5, Step: 71, Loss: 0.20861932635307312, Lr:0.0001\n",
      "Epoch 5, Step: 72, Loss: 0.41643163561820984, Lr:0.0001\n",
      "Epoch 5, Step: 73, Loss: 0.217976376414299, Lr:0.0001\n",
      "Epoch 5, Step: 74, Loss: 0.13801781833171844, Lr:0.0001\n",
      "Epoch 5, Step: 75, Loss: 0.20539191365242004, Lr:0.0001\n",
      "Epoch 5, Step: 76, Loss: 0.3346330225467682, Lr:0.0001\n",
      "Epoch 5, Step: 77, Loss: 0.10110895335674286, Lr:0.0001\n",
      "Epoch 5, Step: 78, Loss: 0.08327987045049667, Lr:0.0001\n",
      "Epoch 5, Step: 79, Loss: 0.15307393670082092, Lr:0.0001\n",
      "Epoch 5, Step: 80, Loss: 0.14629897475242615, Lr:0.0001\n",
      "Epoch 5, Step: 81, Loss: 0.4442710876464844, Lr:0.0001\n",
      "Epoch 5, Step: 82, Loss: 0.24475893378257751, Lr:0.0001\n",
      "Epoch 5, Step: 83, Loss: 0.21875107288360596, Lr:0.0001\n",
      "Epoch 5, Step: 84, Loss: 0.07229377329349518, Lr:0.0001\n",
      "Epoch 5, Step: 85, Loss: 0.1173110380768776, Lr:0.0001\n",
      "Epoch 5, Step: 86, Loss: 0.07860974222421646, Lr:0.0001\n",
      "Epoch 5, Step: 87, Loss: 0.20578764379024506, Lr:0.0001\n",
      "Epoch 5, Step: 88, Loss: 0.16648860275745392, Lr:0.0001\n",
      "Epoch 5, Step: 89, Loss: 0.07944943010807037, Lr:0.0001\n",
      "Epoch 5, Step: 90, Loss: 0.25838226079940796, Lr:0.0001\n",
      "Epoch 5, Step: 91, Loss: 0.2705824375152588, Lr:0.0001\n",
      "Epoch 5, Step: 92, Loss: 0.04645828902721405, Lr:0.0001\n",
      "Epoch 5, Step: 93, Loss: 0.1897365152835846, Lr:0.0001\n",
      "Epoch 5, Step: 94, Loss: 0.2025699019432068, Lr:0.0001\n",
      "Epoch 5, Step: 95, Loss: 0.27571651339530945, Lr:0.0001\n",
      "Epoch 5, Step: 96, Loss: 0.20600110292434692, Lr:0.0001\n",
      "Epoch 5, Step: 97, Loss: 0.23647236824035645, Lr:0.0001\n",
      "Epoch 5, Step: 98, Loss: 0.27325230836868286, Lr:0.0001\n",
      "Epoch 5, Step: 99, Loss: 0.17595243453979492, Lr:0.0001\n",
      "Epoch 5, Step: 100, Loss: 0.20967458188533783, Lr:0.0001\n",
      "Epoch 5, Step: 101, Loss: 0.4790939390659332, Lr:0.0001\n",
      "Epoch 5, Step: 102, Loss: 0.14207330346107483, Lr:0.0001\n",
      "Epoch 5, Step: 103, Loss: 0.3747740089893341, Lr:0.0001\n",
      "Epoch 5, Step: 104, Loss: 0.09677539020776749, Lr:0.0001\n",
      "Epoch 5, Step: 105, Loss: 0.033789053559303284, Lr:0.0001\n",
      "Epoch 5, Step: 106, Loss: 0.3069506585597992, Lr:0.0001\n",
      "Epoch 5, Step: 107, Loss: 0.13535727560520172, Lr:0.0001\n",
      "Epoch 5, Step: 108, Loss: 0.48602229356765747, Lr:0.0001\n",
      "Epoch 5, Step: 109, Loss: 0.5948242545127869, Lr:0.0001\n",
      "Epoch 5, Step: 110, Loss: 0.1520831435918808, Lr:0.0001\n",
      "Epoch 5, Step: 111, Loss: 0.18823052942752838, Lr:0.0001\n",
      "Epoch 5, Step: 112, Loss: 0.27350351214408875, Lr:0.0001\n",
      "Epoch 5, Step: 113, Loss: 0.0876203253865242, Lr:0.0001\n",
      "Epoch 5, Step: 114, Loss: 0.242781862616539, Lr:0.0001\n",
      "Epoch 5, Step: 115, Loss: 0.17563846707344055, Lr:0.0001\n",
      "Epoch 5, Step: 116, Loss: 0.1677962839603424, Lr:0.0001\n",
      "Epoch 5, Step: 117, Loss: 0.10269075632095337, Lr:0.0001\n",
      "Epoch 5, Step: 118, Loss: 0.26205137372016907, Lr:0.0001\n",
      "Epoch 5, Step: 119, Loss: 0.3587092459201813, Lr:0.0001\n",
      "Epoch 5, Step: 120, Loss: 0.2856665551662445, Lr:0.0001\n",
      "Epoch 5, Step: 121, Loss: 0.4091643691062927, Lr:0.0001\n",
      "Epoch 5, Step: 122, Loss: 0.10006122291088104, Lr:0.0001\n",
      "Epoch 5, Step: 123, Loss: 0.1201157420873642, Lr:0.0001\n",
      "Epoch 5, Step: 124, Loss: 0.44961196184158325, Lr:0.0001\n",
      "Epoch 5, Step: 125, Loss: 0.1580805480480194, Lr:0.0001\n",
      "Epoch 5, Step: 126, Loss: 0.14550696313381195, Lr:0.0001\n",
      "Epoch 5, Step: 127, Loss: 0.6075180172920227, Lr:0.0001\n",
      "Epoch 5, Step: 128, Loss: 0.2640329599380493, Lr:0.0001\n",
      "Epoch 5, Step: 129, Loss: 0.4233954846858978, Lr:0.0001\n",
      "Epoch 5, Step: 130, Loss: 0.1518508791923523, Lr:0.0001\n",
      "Epoch 5, Step: 131, Loss: 0.14325356483459473, Lr:0.0001\n",
      "Epoch 5, Step: 132, Loss: 0.40782061219215393, Lr:0.0001\n",
      "Epoch 5, Step: 133, Loss: 0.08703549951314926, Lr:0.0001\n",
      "Epoch 5, Step: 134, Loss: 0.08049944788217545, Lr:0.0001\n",
      "Epoch 5, Step: 135, Loss: 0.2817375361919403, Lr:0.0001\n",
      "Epoch 5, Step: 136, Loss: 0.31425178050994873, Lr:0.0001\n",
      "Epoch 5, Step: 137, Loss: 0.577331006526947, Lr:0.0001\n",
      "Epoch 5, Step: 138, Loss: 0.08470236510038376, Lr:0.0001\n",
      "Epoch 5, Step: 139, Loss: 0.4029361605644226, Lr:0.0001\n",
      "Epoch 5, Step: 140, Loss: 0.23942728340625763, Lr:0.0001\n",
      "Epoch 5, Step: 141, Loss: 0.7186152935028076, Lr:0.0001\n",
      "Epoch 5, Step: 142, Loss: 0.27292338013648987, Lr:0.0001\n",
      "Epoch 5, Step: 143, Loss: 0.2827325463294983, Lr:0.0001\n",
      "Epoch 5, Step: 144, Loss: 0.28585904836654663, Lr:0.0001\n",
      "Epoch 5, Step: 145, Loss: 0.23431172966957092, Lr:0.0001\n",
      "Epoch 5, Step: 146, Loss: 0.28517162799835205, Lr:0.0001\n",
      "Epoch 5, Step: 147, Loss: 0.10143308341503143, Lr:0.0001\n",
      "Epoch 5, Step: 148, Loss: 0.44521984457969666, Lr:0.0001\n",
      "Epoch 5, Step: 149, Loss: 0.07310740649700165, Lr:0.0001\n",
      "Epoch 5, Step: 150, Loss: 0.4208400249481201, Lr:0.0001\n",
      "Epoch 5, Step: 151, Loss: 0.3279178738594055, Lr:0.0001\n",
      "Epoch 5, Step: 152, Loss: 0.17779755592346191, Lr:0.0001\n",
      "Epoch 5, Step: 153, Loss: 0.36880677938461304, Lr:0.0001\n",
      "Epoch 5, Step: 154, Loss: 0.2732982635498047, Lr:0.0001\n",
      "Epoch 5, Step: 155, Loss: 0.8107327222824097, Lr:0.0001\n",
      "Epoch 5, Step: 156, Loss: 0.2757405638694763, Lr:0.0001\n",
      "Epoch 5, Step: 157, Loss: 0.19994805753231049, Lr:0.0001\n",
      "Epoch 5, Step: 158, Loss: 0.20283100008964539, Lr:0.0001\n",
      "Epoch 5, Step: 159, Loss: 0.28684356808662415, Lr:0.0001\n",
      "Epoch 5, Step: 160, Loss: 0.19516780972480774, Lr:0.0001\n",
      "Epoch 5, Step: 161, Loss: 0.2549992799758911, Lr:0.0001\n",
      "Epoch 5, Step: 162, Loss: 0.18139956891536713, Lr:0.0001\n",
      "Epoch 5, Step: 163, Loss: 0.05482253432273865, Lr:0.0001\n",
      "Epoch 5, Step: 164, Loss: 0.11615872383117676, Lr:0.0001\n",
      "Epoch 5, Step: 165, Loss: 0.04529960826039314, Lr:0.0001\n",
      "Epoch 5, Step: 166, Loss: 0.26134705543518066, Lr:0.0001\n",
      "Epoch 5, Step: 167, Loss: 0.30207306146621704, Lr:0.0001\n",
      "Epoch 5, Step: 168, Loss: 0.13166284561157227, Lr:0.0001\n",
      "Epoch 5, Step: 169, Loss: 0.19407717883586884, Lr:0.0001\n",
      "Epoch 5, Step: 170, Loss: 0.12195991724729538, Lr:0.0001\n",
      "Epoch 5, Step: 171, Loss: 0.14288006722927094, Lr:0.0001\n",
      "Epoch 5, Step: 172, Loss: 0.16366399824619293, Lr:0.0001\n",
      "Epoch 5, Step: 173, Loss: 0.13141991198062897, Lr:0.0001\n",
      "Epoch 5, Step: 174, Loss: 0.30230554938316345, Lr:0.0001\n",
      "Epoch 5, Step: 175, Loss: 0.16314250230789185, Lr:0.0001\n",
      "Epoch 5, Step: 176, Loss: 0.32445305585861206, Lr:0.0001\n",
      "Epoch 5, Step: 177, Loss: 0.17021110653877258, Lr:0.0001\n",
      "Epoch 5, Step: 178, Loss: 0.2770932912826538, Lr:0.0001\n",
      "Epoch 5, Step: 179, Loss: 0.34726646542549133, Lr:0.0001\n",
      "Epoch 5, Step: 180, Loss: 0.10599436610937119, Lr:0.0001\n",
      "Epoch 5, Step: 181, Loss: 0.3192006051540375, Lr:0.0001\n",
      "Epoch 5, Step: 182, Loss: 0.44702956080436707, Lr:0.0001\n",
      "Epoch 5, Step: 183, Loss: 0.16366952657699585, Lr:0.0001\n",
      "Epoch 5, Step: 184, Loss: 0.13330218195915222, Lr:0.0001\n",
      "Epoch 5, Step: 185, Loss: 0.36637401580810547, Lr:0.0001\n",
      "Epoch 5, Step: 186, Loss: 0.07453575730323792, Lr:0.0001\n",
      "Epoch 5, Step: 187, Loss: 0.15998715162277222, Lr:0.0001\n",
      "Epoch 5, Step: 188, Loss: 0.6215516328811646, Lr:0.0001\n",
      "Epoch 5, Step: 189, Loss: 0.09446638077497482, Lr:0.0001\n",
      "Epoch 5, Step: 190, Loss: 0.803267240524292, Lr:0.0001\n",
      "Epoch 5, Step: 191, Loss: 0.4397939145565033, Lr:0.0001\n",
      "Epoch 5, Step: 192, Loss: 0.18788976967334747, Lr:0.0001\n",
      "Epoch 5, Step: 193, Loss: 0.1393175572156906, Lr:0.0001\n",
      "Epoch 5, Step: 194, Loss: 0.45585036277770996, Lr:0.0001\n",
      "Epoch 5, Step: 195, Loss: 0.7179077863693237, Lr:0.0001\n",
      "Epoch 5, Step: 196, Loss: 0.19166748225688934, Lr:0.0001\n",
      "Epoch 5, Step: 197, Loss: 0.13004127144813538, Lr:0.0001\n",
      "Epoch 5, Step: 198, Loss: 0.25832509994506836, Lr:0.0001\n",
      "Epoch 5, Step: 199, Loss: 0.272723525762558, Lr:0.0001\n",
      "Epoch 5, Step: 200, Loss: 0.41409504413604736, Lr:0.0001\n",
      "Epoch 5, Step: 201, Loss: 0.2724451422691345, Lr:0.0001\n",
      "Epoch 5, Step: 202, Loss: 0.13509903848171234, Lr:0.0001\n",
      "Epoch 5, Step: 203, Loss: 0.6492400169372559, Lr:0.0001\n",
      "Epoch 5, Step: 204, Loss: 0.18314242362976074, Lr:0.0001\n",
      "Epoch 5, Step: 205, Loss: 0.2230709046125412, Lr:0.0001\n",
      "Epoch 5, Step: 206, Loss: 0.11790310591459274, Lr:0.0001\n",
      "Epoch 5, Step: 207, Loss: 0.28053098917007446, Lr:0.0001\n",
      "Epoch 5, Step: 208, Loss: 0.35858243703842163, Lr:0.0001\n",
      "Epoch 5, Step: 209, Loss: 0.6683270335197449, Lr:0.0001\n",
      "Epoch 5, Step: 210, Loss: 0.18473662436008453, Lr:0.0001\n",
      "Epoch 5, Step: 211, Loss: 0.07495211809873581, Lr:0.0001\n",
      "Epoch 5, Step: 212, Loss: 0.1026095524430275, Lr:0.0001\n",
      "Epoch 5, Step: 213, Loss: 0.6495265960693359, Lr:0.0001\n",
      "Epoch 5, Step: 214, Loss: 0.32491132616996765, Lr:0.0001\n",
      "Epoch 5, Step: 215, Loss: 0.128592386841774, Lr:0.0001\n",
      "Epoch 5, Step: 216, Loss: 0.39378786087036133, Lr:0.0001\n",
      "Epoch 5, Step: 217, Loss: 0.44436877965927124, Lr:0.0001\n",
      "Epoch 5, Step: 218, Loss: 0.3532603681087494, Lr:0.0001\n",
      "Epoch 5, Step: 219, Loss: 0.10400897264480591, Lr:0.0001\n",
      "Epoch 5, Step: 220, Loss: 0.07868325710296631, Lr:0.0001\n",
      "Epoch 5, Step: 221, Loss: 0.16115416586399078, Lr:0.0001\n",
      "Epoch 5, Step: 222, Loss: 0.08463957160711288, Lr:0.0001\n",
      "Epoch 5, Step: 223, Loss: 0.3511931598186493, Lr:0.0001\n",
      "Epoch 5, Step: 224, Loss: 0.1835891753435135, Lr:0.0001\n",
      "Epoch 5, Step: 225, Loss: 0.2506585121154785, Lr:0.0001\n",
      "Epoch 5, Step: 226, Loss: 0.19263717532157898, Lr:0.0001\n",
      "Epoch 5, Step: 227, Loss: 0.3469223976135254, Lr:0.0001\n",
      "Epoch 5, Step: 228, Loss: 0.5814736485481262, Lr:0.0001\n",
      "Epoch 5, Step: 229, Loss: 0.18827243149280548, Lr:0.0001\n",
      "Epoch 5, Step: 230, Loss: 0.41668465733528137, Lr:0.0001\n",
      "Epoch 5, Step: 231, Loss: 0.5032040476799011, Lr:0.0001\n",
      "Epoch 5, Step: 232, Loss: 0.44108614325523376, Lr:0.0001\n",
      "Epoch 5, Step: 233, Loss: 0.4801292419433594, Lr:0.0001\n",
      "Epoch 5, Step: 234, Loss: 0.2759341597557068, Lr:0.0001\n",
      "Epoch 5, Step: 235, Loss: 0.10269821435213089, Lr:0.0001\n",
      "Epoch 5, Step: 236, Loss: 0.06944914907217026, Lr:0.0001\n",
      "Epoch 5, Step: 237, Loss: 0.254682719707489, Lr:0.0001\n",
      "Epoch 5, Step: 238, Loss: 0.36444857716560364, Lr:0.0001\n",
      "Epoch 5, Step: 239, Loss: 0.2706473767757416, Lr:0.0001\n",
      "Epoch 5, Step: 240, Loss: 0.27530044317245483, Lr:0.0001\n",
      "Epoch 5, Step: 241, Loss: 0.16577738523483276, Lr:0.0001\n",
      "Epoch 5, Step: 242, Loss: 0.18186138570308685, Lr:0.0001\n",
      "Epoch 5, Step: 243, Loss: 0.39895057678222656, Lr:0.0001\n",
      "Epoch 5, Step: 244, Loss: 0.05233820155262947, Lr:0.0001\n",
      "Epoch 5, Step: 245, Loss: 0.09978064894676208, Lr:0.0001\n",
      "Epoch 5, Step: 246, Loss: 0.7706301808357239, Lr:0.0001\n",
      "Epoch 5, Step: 247, Loss: 0.14418953657150269, Lr:0.0001\n",
      "Epoch 5, Step: 248, Loss: 0.16911078989505768, Lr:0.0001\n",
      "Epoch 5, Step: 249, Loss: 0.3204929530620575, Lr:0.0001\n",
      "Epoch 5, Step: 250, Loss: 0.1827647089958191, Lr:0.0001\n",
      "Epoch 5, Step: 251, Loss: 0.12517037987709045, Lr:0.0001\n",
      "Epoch 5, Step: 252, Loss: 0.27387893199920654, Lr:0.0001\n",
      "Epoch 5, Step: 253, Loss: 0.15452171862125397, Lr:0.0001\n",
      "Epoch 5, Step: 254, Loss: 0.07160382717847824, Lr:0.0001\n",
      "Epoch 5, Step: 255, Loss: 0.20169898867607117, Lr:0.0001\n",
      "Epoch 5, Step: 256, Loss: 0.10245345532894135, Lr:0.0001\n",
      "Epoch 5, Step: 257, Loss: 0.04838092252612114, Lr:0.0001\n",
      "Epoch 5, Step: 258, Loss: 0.15338066220283508, Lr:0.0001\n",
      "Epoch 5, Step: 259, Loss: 0.4884586036205292, Lr:0.0001\n",
      "Epoch 5, Step: 260, Loss: 0.36837291717529297, Lr:0.0001\n",
      "Epoch 5, Step: 261, Loss: 0.3281685411930084, Lr:0.0001\n",
      "Epoch 5, Step: 262, Loss: 0.2673724591732025, Lr:0.0001\n",
      "Epoch 5, Step: 263, Loss: 0.2965095341205597, Lr:0.0001\n",
      "Epoch 5, Step: 264, Loss: 0.05475630611181259, Lr:0.0001\n",
      "Epoch 5, Step: 265, Loss: 0.45818567276000977, Lr:0.0001\n",
      "Epoch 5, Step: 266, Loss: 0.2266674041748047, Lr:0.0001\n",
      "Epoch 5, Step: 267, Loss: 0.23902790248394012, Lr:0.0001\n",
      "Epoch 5, Step: 268, Loss: 0.31373071670532227, Lr:0.0001\n",
      "Epoch 5, Step: 269, Loss: 0.05392232909798622, Lr:0.0001\n",
      "Epoch 5, Step: 270, Loss: 0.2074229121208191, Lr:0.0001\n",
      "Epoch 5, Step: 271, Loss: 0.29698729515075684, Lr:0.0001\n",
      "Epoch 5, Step: 272, Loss: 0.3204995393753052, Lr:0.0001\n",
      "Epoch 5, Step: 273, Loss: 0.16316364705562592, Lr:0.0001\n",
      "Epoch 5, Step: 274, Loss: 0.07479095458984375, Lr:0.0001\n",
      "Epoch 5, Step: 275, Loss: 0.4786638915538788, Lr:0.0001\n",
      "Epoch 5, Step: 276, Loss: 0.3004071116447449, Lr:0.0001\n",
      "Epoch 5, Step: 277, Loss: 0.1593468189239502, Lr:0.0001\n",
      "Epoch 5, Step: 278, Loss: 0.2265097200870514, Lr:0.0001\n",
      "Epoch 5, Step: 279, Loss: 0.25392869114875793, Lr:0.0001\n",
      "Epoch 5, Step: 280, Loss: 0.1808827817440033, Lr:0.0001\n",
      "Epoch 5, Step: 281, Loss: 0.7083372473716736, Lr:0.0001\n",
      "Epoch 5, Step: 282, Loss: 0.43607690930366516, Lr:0.0001\n",
      "Epoch 5, Step: 283, Loss: 0.04622707888484001, Lr:0.0001\n",
      "Epoch 5, Step: 284, Loss: 0.45035189390182495, Lr:0.0001\n",
      "Epoch 5, Step: 285, Loss: 0.37601950764656067, Lr:0.0001\n",
      "Epoch 5, Step: 286, Loss: 0.2781236171722412, Lr:0.0001\n",
      "Epoch 5, Step: 287, Loss: 0.17838020622730255, Lr:0.0001\n",
      "Epoch 5, Step: 288, Loss: 0.343558669090271, Lr:0.0001\n",
      "Epoch 5, Step: 289, Loss: 0.0820992961525917, Lr:0.0001\n",
      "Epoch 5, Step: 290, Loss: 0.04093977436423302, Lr:0.0001\n",
      "Epoch 5, Step: 291, Loss: 0.3080710470676422, Lr:0.0001\n",
      "Epoch 5, Step: 292, Loss: 0.1523086428642273, Lr:0.0001\n",
      "Epoch 5, Step: 293, Loss: 0.17133906483650208, Lr:0.0001\n",
      "Epoch 5, Step: 294, Loss: 0.05410037934780121, Lr:0.0001\n",
      "Epoch 5, Step: 295, Loss: 0.1355641633272171, Lr:0.0001\n",
      "Epoch 5, Step: 296, Loss: 0.42025503516197205, Lr:0.0001\n",
      "Epoch 5, Step: 297, Loss: 0.13956338167190552, Lr:0.0001\n",
      "Epoch 5, Step: 298, Loss: 0.1518951952457428, Lr:0.0001\n",
      "Epoch 5, Step: 299, Loss: 0.2270677387714386, Lr:0.0001\n",
      "Epoch 5, Step: 300, Loss: 0.1457451581954956, Lr:0.0001\n",
      "Epoch 5, Step: 301, Loss: 0.1256624162197113, Lr:0.0001\n",
      "Epoch 5, Step: 302, Loss: 0.2555801570415497, Lr:0.0001\n",
      "Epoch 5, Step: 303, Loss: 0.20353764295578003, Lr:0.0001\n",
      "Epoch 5, Step: 304, Loss: 0.057525742799043655, Lr:0.0001\n",
      "Epoch 5, Step: 305, Loss: 0.17731867730617523, Lr:0.0001\n",
      "Epoch 5, Step: 306, Loss: 0.05307943373918533, Lr:0.0001\n",
      "Epoch 5, Step: 307, Loss: 0.13521350920200348, Lr:0.0001\n",
      "Epoch 5, Step: 308, Loss: 0.15277384221553802, Lr:0.0001\n",
      "Epoch 5, Step: 309, Loss: 0.10050781816244125, Lr:0.0001\n",
      "Epoch 5, Step: 310, Loss: 0.15101058781147003, Lr:0.0001\n",
      "Epoch 5, Step: 311, Loss: 0.2137632668018341, Lr:0.0001\n",
      "Epoch 5, Step: 312, Loss: 0.24376241862773895, Lr:0.0001\n",
      "Epoch 5, Step: 313, Loss: 0.19031266868114471, Lr:0.0001\n",
      "Epoch 5, Step: 314, Loss: 0.11422164738178253, Lr:0.0001\n",
      "Epoch 5, Step: 315, Loss: 0.2528579533100128, Lr:0.0001\n",
      "Epoch 5, Step: 316, Loss: 0.27890411019325256, Lr:0.0001\n",
      "Epoch 5, Step: 317, Loss: 0.34985026717185974, Lr:0.0001\n",
      "Epoch 5, Step: 318, Loss: 0.3166763186454773, Lr:0.0001\n",
      "Epoch 5, Step: 319, Loss: 0.13630150258541107, Lr:0.0001\n",
      "Epoch 5, Step: 320, Loss: 0.3602088987827301, Lr:0.0001\n",
      "Epoch 5, Step: 321, Loss: 0.09432471543550491, Lr:0.0001\n",
      "Epoch 5, Step: 322, Loss: 0.046634476631879807, Lr:0.0001\n",
      "Epoch 5, Step: 323, Loss: 0.40262770652770996, Lr:0.0001\n",
      "Epoch 5, Step: 324, Loss: 0.4680761694908142, Lr:0.0001\n",
      "Epoch 5, Step: 325, Loss: 0.1468932330608368, Lr:0.0001\n",
      "Epoch 5, Step: 326, Loss: 0.24082879722118378, Lr:0.0001\n",
      "Epoch 5, Step: 327, Loss: 0.32015863060951233, Lr:0.0001\n",
      "Epoch 5, Step: 328, Loss: 0.0965016707777977, Lr:0.0001\n",
      "Epoch 5, Step: 329, Loss: 0.36125612258911133, Lr:0.0001\n",
      "Epoch 5, Step: 330, Loss: 0.20939812064170837, Lr:0.0001\n",
      "Epoch 5, Step: 331, Loss: 0.4339134395122528, Lr:0.0001\n",
      "Epoch 5, Step: 332, Loss: 0.2657107412815094, Lr:0.0001\n",
      "Epoch 5, Step: 333, Loss: 0.18206244707107544, Lr:0.0001\n",
      "Epoch 5, Step: 334, Loss: 0.2281380444765091, Lr:0.0001\n",
      "Epoch 5, Step: 335, Loss: 0.08404535800218582, Lr:0.0001\n",
      "Epoch 5, Step: 336, Loss: 0.28362804651260376, Lr:0.0001\n",
      "Epoch 5, Step: 337, Loss: 0.2890600562095642, Lr:0.0001\n",
      "Epoch 5, Step: 338, Loss: 0.2762768566608429, Lr:0.0001\n",
      "Epoch 5, Step: 339, Loss: 0.08068902045488358, Lr:0.0001\n",
      "Epoch 5, Step: 340, Loss: 0.17102080583572388, Lr:0.0001\n",
      "Epoch 5, Step: 341, Loss: 0.365776926279068, Lr:0.0001\n",
      "Epoch 5, Step: 342, Loss: 0.02802227810025215, Lr:0.0001\n",
      "Epoch 5, Step: 343, Loss: 0.19126735627651215, Lr:0.0001\n",
      "Epoch 5, Step: 344, Loss: 0.08495520055294037, Lr:0.0001\n",
      "Epoch 5, Step: 345, Loss: 0.36539945006370544, Lr:0.0001\n",
      "Epoch 5, Step: 346, Loss: 0.3158693015575409, Lr:0.0001\n",
      "Epoch 5, Step: 347, Loss: 0.39734935760498047, Lr:0.0001\n",
      "Epoch 5, Step: 348, Loss: 0.21459634602069855, Lr:0.0001\n",
      "Epoch 5, Step: 349, Loss: 0.11225737631320953, Lr:0.0001\n",
      "Epoch 5, Step: 350, Loss: 0.16495828330516815, Lr:0.0001\n",
      "Epoch 5, Step: 351, Loss: 0.37929633259773254, Lr:0.0001\n",
      "Epoch 5, Step: 352, Loss: 0.049188755452632904, Lr:0.0001\n",
      "Epoch 5, Step: 353, Loss: 0.3147108852863312, Lr:0.0001\n",
      "Epoch 5, Step: 354, Loss: 0.1463751494884491, Lr:0.0001\n",
      "Epoch 5, Step: 355, Loss: 0.23114733397960663, Lr:0.0001\n",
      "Epoch 5, Step: 356, Loss: 0.3384672999382019, Lr:0.0001\n",
      "Epoch 5, Step: 357, Loss: 0.09145861864089966, Lr:0.0001\n",
      "Epoch 5, Step: 358, Loss: 0.2092355638742447, Lr:0.0001\n",
      "Epoch 5, Step: 359, Loss: 0.21712517738342285, Lr:0.0001\n",
      "Epoch 5, Step: 360, Loss: 0.2116444706916809, Lr:0.0001\n",
      "Epoch 5, Step: 361, Loss: 0.13167178630828857, Lr:0.0001\n",
      "Epoch 5, Step: 362, Loss: 0.2780286967754364, Lr:0.0001\n",
      "Epoch 5, Step: 363, Loss: 0.31661394238471985, Lr:0.0001\n",
      "Epoch 5, Step: 364, Loss: 0.38004058599472046, Lr:0.0001\n",
      "Epoch 5, Step: 365, Loss: 0.07775703817605972, Lr:0.0001\n",
      "Epoch 5, Step: 366, Loss: 0.3244398832321167, Lr:0.0001\n",
      "Epoch 5, Step: 367, Loss: 0.18116389214992523, Lr:0.0001\n",
      "Epoch 5, Step: 368, Loss: 0.1979016810655594, Lr:0.0001\n",
      "Epoch 5, Step: 369, Loss: 0.2357020080089569, Lr:0.0001\n",
      "Epoch 5, Step: 370, Loss: 0.20335033535957336, Lr:0.0001\n",
      "Epoch 5, Step: 371, Loss: 0.13047246634960175, Lr:0.0001\n",
      "Epoch 5, Step: 372, Loss: 0.17589274048805237, Lr:0.0001\n",
      "Epoch 5, Step: 373, Loss: 0.19493617117404938, Lr:0.0001\n",
      "Epoch 5, Step: 374, Loss: 0.3929099440574646, Lr:0.0001\n",
      "Epoch 5, Step: 375, Loss: 0.07517296820878983, Lr:0.0001\n",
      "Epoch 5, Step: 376, Loss: 0.4071432650089264, Lr:0.0001\n",
      "Epoch 5, Step: 377, Loss: 0.26682302355766296, Lr:0.0001\n",
      "Epoch 5, Step: 378, Loss: 0.15812958776950836, Lr:0.0001\n",
      "Epoch 5, Step: 379, Loss: 0.39453768730163574, Lr:0.0001\n",
      "Epoch 5, Step: 380, Loss: 0.48250001668930054, Lr:0.0001\n",
      "Epoch 5, Step: 381, Loss: 0.07749833166599274, Lr:0.0001\n",
      "Epoch 5, Step: 382, Loss: 0.38056305050849915, Lr:0.0001\n",
      "Epoch 5, Step: 383, Loss: 0.22494395077228546, Lr:0.0001\n",
      "Epoch 5, Step: 384, Loss: 0.19612638652324677, Lr:0.0001\n",
      "Epoch 5, Step: 385, Loss: 0.2046356499195099, Lr:0.0001\n",
      "Epoch 5, Step: 386, Loss: 0.4946019649505615, Lr:0.0001\n",
      "Epoch 5, Step: 387, Loss: 0.37242233753204346, Lr:0.0001\n",
      "Epoch 5, Step: 388, Loss: 0.1648741066455841, Lr:0.0001\n",
      "Epoch 5, Step: 389, Loss: 1.080997347831726, Lr:0.0001\n",
      "Epoch 5, Step: 390, Loss: 0.2074604630470276, Lr:0.0001\n",
      "Epoch 5, Step: 391, Loss: 0.17837972939014435, Lr:0.0001\n",
      "Epoch 5, Step: 392, Loss: 0.14660640060901642, Lr:0.0001\n",
      "Epoch 5, Step: 393, Loss: 0.27409422397613525, Lr:0.0001\n",
      "Epoch 5, Step: 394, Loss: 0.33420324325561523, Lr:0.0001\n",
      "Epoch 5, Step: 395, Loss: 0.04673166200518608, Lr:0.0001\n",
      "Epoch 5, Step: 396, Loss: 0.37218862771987915, Lr:0.0001\n",
      "Epoch 5, Step: 397, Loss: 0.22534796595573425, Lr:0.0001\n",
      "Epoch 5, Step: 398, Loss: 0.4011092185974121, Lr:0.0001\n",
      "Epoch 5, Step: 399, Loss: 0.5495886206626892, Lr:0.0001\n",
      "Epoch 5, Step: 400, Loss: 0.2886020243167877, Lr:0.0001\n",
      "Epoch 5, Step: 401, Loss: 0.5751758813858032, Lr:0.0001\n",
      "Epoch 5, Step: 402, Loss: 0.3310737609863281, Lr:0.0001\n",
      "Epoch 5, Step: 403, Loss: 0.1392669379711151, Lr:0.0001\n",
      "Epoch 5, Step: 404, Loss: 0.625258207321167, Lr:0.0001\n",
      "Epoch 5, Step: 405, Loss: 0.2574288845062256, Lr:0.0001\n",
      "Epoch 5, Step: 406, Loss: 0.054448239505290985, Lr:0.0001\n",
      "Epoch 5, Step: 407, Loss: 0.13876497745513916, Lr:0.0001\n",
      "Epoch 5, Step: 408, Loss: 0.294969767332077, Lr:0.0001\n",
      "Epoch 5, Step: 409, Loss: 0.10110502690076828, Lr:0.0001\n",
      "Epoch 5, Step: 410, Loss: 0.2878340482711792, Lr:0.0001\n",
      "Epoch 5, Step: 411, Loss: 0.06172783300280571, Lr:0.0001\n",
      "Epoch 5, Step: 412, Loss: 0.11176051199436188, Lr:0.0001\n",
      "Epoch 5, Step: 413, Loss: 0.49742063879966736, Lr:0.0001\n",
      "Epoch 5, Step: 414, Loss: 0.2580518424510956, Lr:0.0001\n",
      "Epoch 5, Step: 415, Loss: 0.38680005073547363, Lr:0.0001\n",
      "Epoch 5, Step: 416, Loss: 0.1784653663635254, Lr:0.0001\n",
      "Epoch 5, Step: 417, Loss: 0.14505791664123535, Lr:0.0001\n",
      "Epoch 5, Step: 418, Loss: 0.48808592557907104, Lr:0.0001\n",
      "Epoch 5, Step: 419, Loss: 0.09158549457788467, Lr:0.0001\n",
      "Epoch 5, Step: 420, Loss: 0.22382928431034088, Lr:0.0001\n",
      "Epoch 5, Step: 421, Loss: 0.11355340480804443, Lr:0.0001\n",
      "Epoch 5, Step: 422, Loss: 0.4676850140094757, Lr:0.0001\n",
      "Epoch 5, Step: 423, Loss: 0.19562722742557526, Lr:0.0001\n",
      "Epoch 5, Step: 424, Loss: 0.196042999625206, Lr:0.0001\n",
      "Epoch 5, Step: 425, Loss: 0.0841013714671135, Lr:0.0001\n",
      "Epoch 5, Step: 426, Loss: 0.040742285549640656, Lr:0.0001\n",
      "Epoch 5, Step: 427, Loss: 0.11448711156845093, Lr:0.0001\n",
      "Epoch 5, Step: 428, Loss: 0.2487914115190506, Lr:0.0001\n",
      "Epoch 5, Step: 429, Loss: 0.13430969417095184, Lr:0.0001\n",
      "Epoch 5, Step: 430, Loss: 0.27098023891448975, Lr:0.0001\n",
      "Epoch 5, Step: 431, Loss: 0.25030356645584106, Lr:0.0001\n",
      "Epoch 5, Step: 432, Loss: 0.4740191102027893, Lr:0.0001\n",
      "Epoch 5, Step: 433, Loss: 0.20237432420253754, Lr:0.0001\n",
      "Epoch 5, Step: 434, Loss: 0.4122846722602844, Lr:0.0001\n",
      "Epoch 5, Step: 435, Loss: 0.2281903475522995, Lr:0.0001\n",
      "Epoch 5, Step: 436, Loss: 0.18640048801898956, Lr:0.0001\n",
      "Epoch 5, Step: 437, Loss: 0.17378409206867218, Lr:0.0001\n",
      "Epoch 5, Step: 438, Loss: 0.2766859233379364, Lr:0.0001\n",
      "Epoch 5, Step: 439, Loss: 0.09422268718481064, Lr:0.0001\n",
      "Epoch 5, Step: 440, Loss: 0.11341769993305206, Lr:0.0001\n",
      "Epoch 5, Step: 441, Loss: 0.10980793833732605, Lr:0.0001\n",
      "Epoch 5, Step: 442, Loss: 0.4312867820262909, Lr:0.0001\n",
      "Epoch 5, Step: 443, Loss: 0.38845163583755493, Lr:0.0001\n",
      "Epoch 5, Step: 444, Loss: 0.17175979912281036, Lr:0.0001\n",
      "Epoch 5, Step: 445, Loss: 0.40631231665611267, Lr:0.0001\n",
      "Epoch 5, Step: 446, Loss: 0.2911771237850189, Lr:0.0001\n",
      "Epoch 5, Step: 447, Loss: 0.3687942922115326, Lr:0.0001\n",
      "Epoch 5, Step: 448, Loss: 0.2848409116268158, Lr:0.0001\n",
      "Epoch 5, Step: 449, Loss: 0.05246332660317421, Lr:0.0001\n",
      "Epoch 5, Step: 450, Loss: 0.1515018194913864, Lr:0.0001\n",
      "Epoch 5, Step: 451, Loss: 0.15041899681091309, Lr:0.0001\n",
      "Epoch 5, Step: 452, Loss: 0.18599145114421844, Lr:0.0001\n",
      "Epoch 5, Step: 453, Loss: 0.09283425658941269, Lr:0.0001\n",
      "Epoch 5, Step: 454, Loss: 0.08463534712791443, Lr:0.0001\n",
      "Epoch 5, Step: 455, Loss: 0.16587863862514496, Lr:0.0001\n",
      "Epoch 5, Step: 456, Loss: 0.158049076795578, Lr:0.0001\n",
      "Epoch 5, Step: 457, Loss: 0.14306625723838806, Lr:0.0001\n",
      "Epoch 5, Step: 458, Loss: 0.2837560474872589, Lr:0.0001\n",
      "Epoch 5, Step: 459, Loss: 0.19484397768974304, Lr:0.0001\n",
      "Epoch 5, Step: 460, Loss: 0.33052703738212585, Lr:0.0001\n",
      "Epoch 5, Step: 461, Loss: 0.12772436439990997, Lr:0.0001\n",
      "Epoch 5, Step: 462, Loss: 0.4843253791332245, Lr:0.0001\n",
      "Epoch 5, Step: 463, Loss: 0.519041895866394, Lr:0.0001\n",
      "Epoch 5, Step: 464, Loss: 0.27874693274497986, Lr:0.0001\n",
      "Epoch 5, Step: 465, Loss: 0.23275496065616608, Lr:0.0001\n",
      "Epoch 5, Step: 466, Loss: 0.19399267435073853, Lr:0.0001\n",
      "Epoch 5, Step: 467, Loss: 0.07435695827007294, Lr:0.0001\n",
      "Epoch 5, Step: 468, Loss: 0.4086174964904785, Lr:0.0001\n",
      "Epoch 5, Step: 469, Loss: 0.09941120445728302, Lr:0.0001\n",
      "Epoch 5, Step: 470, Loss: 0.23199881613254547, Lr:0.0001\n",
      "Epoch 5, Step: 471, Loss: 0.3433728516101837, Lr:0.0001\n",
      "Epoch 5, Step: 472, Loss: 0.21854057908058167, Lr:0.0001\n",
      "Epoch 5, Step: 473, Loss: 0.14812573790550232, Lr:0.0001\n",
      "Epoch 5, Step: 474, Loss: 0.08918283879756927, Lr:0.0001\n",
      "Epoch 5, Step: 475, Loss: 0.28838613629341125, Lr:0.0001\n",
      "Epoch 5, Step: 476, Loss: 0.33803504705429077, Lr:0.0001\n",
      "Epoch 5, Step: 477, Loss: 0.06955409795045853, Lr:0.0001\n",
      "Epoch 5, Step: 478, Loss: 0.17835739254951477, Lr:0.0001\n",
      "Epoch 5, Step: 479, Loss: 0.1807495653629303, Lr:0.0001\n",
      "Epoch 5, Step: 480, Loss: 0.09502539038658142, Lr:0.0001\n",
      "Epoch 5, Step: 481, Loss: 0.17152829468250275, Lr:0.0001\n",
      "Epoch 5, Step: 482, Loss: 0.310467928647995, Lr:0.0001\n",
      "Epoch 5, Step: 483, Loss: 0.169955313205719, Lr:0.0001\n",
      "Epoch 5, Step: 484, Loss: 0.3253939747810364, Lr:0.0001\n",
      "Epoch 5, Step: 485, Loss: 0.23584966361522675, Lr:0.0001\n",
      "Epoch 5, Step: 486, Loss: 0.3806231617927551, Lr:0.0001\n",
      "Epoch 5, Step: 487, Loss: 0.1289340704679489, Lr:0.0001\n",
      "Epoch 5, Step: 488, Loss: 0.3960750997066498, Lr:0.0001\n",
      "Epoch 5, Step: 489, Loss: 0.18795379996299744, Lr:0.0001\n",
      "Epoch 5, Step: 490, Loss: 0.4120560884475708, Lr:0.0001\n",
      "Epoch 5, Step: 491, Loss: 0.12474031001329422, Lr:0.0001\n",
      "Epoch 5, Step: 492, Loss: 0.2892761528491974, Lr:0.0001\n",
      "Epoch 5, Step: 493, Loss: 0.08364564925432205, Lr:0.0001\n",
      "Epoch 5, Step: 494, Loss: 0.1222674772143364, Lr:0.0001\n",
      "Epoch 5, Step: 495, Loss: 0.14820164442062378, Lr:0.0001\n",
      "Epoch 5, Step: 496, Loss: 0.3166641294956207, Lr:0.0001\n",
      "Epoch 5, Step: 497, Loss: 0.24176272749900818, Lr:0.0001\n",
      "Epoch 5, Step: 498, Loss: 0.2507813572883606, Lr:0.0001\n",
      "Epoch 5, Step: 499, Loss: 0.050394970923662186, Lr:0.0001\n",
      "Epoch 5, Step: 500, Loss: 0.3616749942302704, Lr:0.0001\n",
      "Epoch 5, Step: 501, Loss: 0.05177616700530052, Lr:0.0001\n",
      "Epoch 5, Step: 502, Loss: 0.23812668025493622, Lr:0.0001\n",
      "Epoch 5, Step: 503, Loss: 0.09571865200996399, Lr:0.0001\n",
      "Epoch 5, Step: 504, Loss: 0.3253431022167206, Lr:0.0001\n",
      "Epoch 5, Step: 505, Loss: 0.17167238891124725, Lr:0.0001\n",
      "Epoch 5, Step: 506, Loss: 0.11729011684656143, Lr:0.0001\n",
      "Epoch 5, Step: 507, Loss: 0.04801969230175018, Lr:0.0001\n",
      "Epoch 5, Step: 508, Loss: 0.20255127549171448, Lr:0.0001\n",
      "Epoch 5, Step: 509, Loss: 0.03452892601490021, Lr:0.0001\n",
      "Epoch 5, Step: 510, Loss: 0.14210742712020874, Lr:0.0001\n",
      "Epoch 5, Step: 511, Loss: 0.3811027705669403, Lr:0.0001\n",
      "Epoch 5, Step: 512, Loss: 0.19438153505325317, Lr:0.0001\n",
      "Epoch 5, Step: 513, Loss: 0.3426455855369568, Lr:0.0001\n",
      "Epoch 5, Step: 514, Loss: 0.5278903841972351, Lr:0.0001\n",
      "Epoch 5, Step: 515, Loss: 0.1871766597032547, Lr:0.0001\n",
      "Epoch 5, Step: 516, Loss: 0.5975619554519653, Lr:0.0001\n",
      "Epoch 5, Step: 517, Loss: 0.1272788643836975, Lr:0.0001\n",
      "Epoch 5, Step: 518, Loss: 0.1008215993642807, Lr:0.0001\n",
      "Epoch 5, Step: 519, Loss: 0.20406292378902435, Lr:0.0001\n",
      "Epoch 5, Step: 520, Loss: 0.334670752286911, Lr:0.0001\n",
      "Epoch 5, Step: 521, Loss: 0.3899681568145752, Lr:0.0001\n",
      "Epoch 5, Step: 522, Loss: 0.3414146602153778, Lr:0.0001\n",
      "Epoch 5, Step: 523, Loss: 0.494144082069397, Lr:0.0001\n",
      "Epoch 5, Step: 524, Loss: 0.43424367904663086, Lr:0.0001\n",
      "Epoch 5, Step: 525, Loss: 0.24720054864883423, Lr:0.0001\n",
      "Epoch 5, Step: 526, Loss: 0.10505163669586182, Lr:0.0001\n",
      "Epoch 5, Step: 527, Loss: 0.39013928174972534, Lr:0.0001\n",
      "Epoch 5, Step: 528, Loss: 0.06295285373926163, Lr:0.0001\n",
      "Epoch 5, Step: 529, Loss: 0.4417693316936493, Lr:0.0001\n",
      "Epoch 5, Step: 530, Loss: 0.30737951397895813, Lr:0.0001\n",
      "Epoch 5, Step: 531, Loss: 0.09628412127494812, Lr:0.0001\n",
      "Epoch 5, Step: 532, Loss: 0.09203144907951355, Lr:0.0001\n",
      "Epoch 5, Step: 533, Loss: 0.1759921908378601, Lr:0.0001\n",
      "Epoch 5, Step: 534, Loss: 0.31218454241752625, Lr:0.0001\n",
      "Epoch 5, Step: 535, Loss: 0.06721404194831848, Lr:0.0001\n",
      "Epoch 5, Step: 536, Loss: 0.2886512875556946, Lr:0.0001\n",
      "Epoch 5, Step: 537, Loss: 0.36578068137168884, Lr:0.0001\n",
      "Epoch 5, Step: 538, Loss: 0.17762424051761627, Lr:0.0001\n",
      "Epoch 5, Step: 539, Loss: 0.42942866683006287, Lr:0.0001\n",
      "Epoch 5, Step: 540, Loss: 0.18152444064617157, Lr:0.0001\n",
      "Epoch 5, Step: 541, Loss: 0.4312512278556824, Lr:0.0001\n",
      "Epoch 5, Step: 542, Loss: 0.5481211543083191, Lr:0.0001\n",
      "Epoch 5, Step: 543, Loss: 0.16978725790977478, Lr:0.0001\n",
      "Epoch 5, Step: 544, Loss: 0.20859205722808838, Lr:0.0001\n",
      "Epoch 5, Step: 545, Loss: 0.16850754618644714, Lr:0.0001\n",
      "Epoch 5, Step: 546, Loss: 0.35262906551361084, Lr:0.0001\n",
      "Epoch 5, Step: 547, Loss: 0.2697257697582245, Lr:0.0001\n",
      "Epoch 5, Step: 548, Loss: 0.1899200826883316, Lr:0.0001\n",
      "Epoch 5, Step: 549, Loss: 0.24751245975494385, Lr:0.0001\n",
      "Epoch 5, Step: 550, Loss: 0.21756383776664734, Lr:0.0001\n",
      "Epoch 5, Step: 551, Loss: 0.3238886892795563, Lr:0.0001\n",
      "Epoch 5, Step: 552, Loss: 0.34494897723197937, Lr:0.0001\n",
      "Epoch 5, Step: 553, Loss: 0.1433771401643753, Lr:0.0001\n",
      "Epoch 5, Step: 554, Loss: 0.3695174753665924, Lr:0.0001\n",
      "Epoch 5, Step: 555, Loss: 0.2631825804710388, Lr:0.0001\n",
      "Epoch 5, Step: 556, Loss: 0.09109534323215485, Lr:0.0001\n",
      "Epoch 5, Step: 557, Loss: 0.14689677953720093, Lr:0.0001\n",
      "Epoch 5, Step: 558, Loss: 0.14029854536056519, Lr:0.0001\n",
      "Epoch 5, Step: 559, Loss: 0.01689702272415161, Lr:0.0001\n",
      "Epoch 5, Step: 560, Loss: 0.2205982357263565, Lr:0.0001\n",
      "Epoch 5, Step: 561, Loss: 0.13256870210170746, Lr:0.0001\n",
      "Epoch 5, Step: 562, Loss: 0.2428859919309616, Lr:0.0001\n",
      "Epoch 5, Step: 563, Loss: 0.41087037324905396, Lr:0.0001\n",
      "Epoch 5, Step: 564, Loss: 0.19489464163780212, Lr:0.0001\n",
      "Epoch 5, Step: 565, Loss: 0.5278616547584534, Lr:0.0001\n",
      "Epoch 5, Step: 566, Loss: 0.027872785925865173, Lr:0.0001\n",
      "Epoch 5, Step: 567, Loss: 0.1871747374534607, Lr:0.0001\n",
      "Epoch 5, Step: 568, Loss: 0.09249565750360489, Lr:0.0001\n",
      "Epoch 5, Step: 569, Loss: 0.3425099849700928, Lr:0.0001\n",
      "Epoch 5, Step: 570, Loss: 0.09038597345352173, Lr:0.0001\n",
      "Epoch 5, Step: 571, Loss: 0.24944080412387848, Lr:0.0001\n",
      "Epoch 5, Step: 572, Loss: 0.19302059710025787, Lr:0.0001\n",
      "Epoch 5, Step: 573, Loss: 0.2659832239151001, Lr:0.0001\n",
      "Epoch 5, Step: 574, Loss: 0.11363634467124939, Lr:0.0001\n",
      "Epoch 5, Step: 575, Loss: 0.15443497896194458, Lr:0.0001\n",
      "Epoch 5, Step: 576, Loss: 0.14354398846626282, Lr:0.0001\n",
      "Epoch 5, Step: 577, Loss: 0.18788769841194153, Lr:0.0001\n",
      "Epoch 5, Step: 578, Loss: 0.2738792598247528, Lr:0.0001\n",
      "Epoch 5, Step: 579, Loss: 0.07939013838768005, Lr:0.0001\n",
      "Epoch 5, Step: 580, Loss: 0.11444789916276932, Lr:0.0001\n",
      "Epoch 5, Step: 581, Loss: 0.10936307162046432, Lr:0.0001\n",
      "Epoch 5, Step: 582, Loss: 0.0997680276632309, Lr:0.0001\n",
      "Epoch 5, Step: 583, Loss: 0.2158464789390564, Lr:0.0001\n",
      "Epoch 5, Step: 584, Loss: 0.26380655169487, Lr:0.0001\n",
      "Epoch 5, Step: 585, Loss: 0.4216778874397278, Lr:0.0001\n",
      "Epoch 5, Step: 586, Loss: 0.047436513006687164, Lr:0.0001\n",
      "Epoch 5, Step: 587, Loss: 0.23188287019729614, Lr:0.0001\n",
      "Epoch 5, Step: 588, Loss: 0.1612967550754547, Lr:0.0001\n",
      "Epoch 5, Step: 589, Loss: 0.10518106073141098, Lr:0.0001\n",
      "Epoch 5, Step: 590, Loss: 0.2948479950428009, Lr:0.0001\n",
      "Epoch 5, Step: 591, Loss: 0.13793569803237915, Lr:0.0001\n",
      "Epoch 5, Step: 592, Loss: 0.2116425335407257, Lr:0.0001\n",
      "Epoch 5, Step: 593, Loss: 0.22307351231575012, Lr:0.0001\n",
      "Epoch 5, Step: 594, Loss: 0.21325434744358063, Lr:0.0001\n",
      "Epoch 5, Step: 595, Loss: 0.10197218507528305, Lr:0.0001\n",
      "Epoch 5, Step: 596, Loss: 0.1694544106721878, Lr:0.0001\n",
      "Epoch 5, Step: 597, Loss: 0.12395501136779785, Lr:0.0001\n",
      "Epoch 5, Step: 598, Loss: 0.3639969825744629, Lr:0.0001\n",
      "Epoch 5, Step: 599, Loss: 0.32555025815963745, Lr:0.0001\n",
      "Epoch 5, Step: 600, Loss: 0.09408041834831238, Lr:0.0001\n",
      "Epoch 5, Step: 601, Loss: 0.15472154319286346, Lr:0.0001\n",
      "Epoch 5, Step: 602, Loss: 0.14413359761238098, Lr:0.0001\n",
      "Epoch 5, Step: 603, Loss: 0.427484393119812, Lr:0.0001\n",
      "Epoch 5, Step: 604, Loss: 0.6781076788902283, Lr:0.0001\n",
      "Epoch 5, Step: 605, Loss: 0.17981134355068207, Lr:0.0001\n",
      "Epoch 5, Step: 606, Loss: 0.1132645532488823, Lr:0.0001\n",
      "Epoch 5, Step: 607, Loss: 0.1351025402545929, Lr:0.0001\n",
      "Epoch 5, Step: 608, Loss: 0.4051190912723541, Lr:0.0001\n",
      "Epoch 5, Step: 609, Loss: 0.23112007975578308, Lr:0.0001\n",
      "Epoch 5, Step: 610, Loss: 0.0929565280675888, Lr:0.0001\n",
      "Epoch 5, Step: 611, Loss: 0.282924085855484, Lr:0.0001\n",
      "Epoch 5, Step: 612, Loss: 0.21401594579219818, Lr:0.0001\n",
      "Epoch 5, Step: 613, Loss: 0.1272992491722107, Lr:0.0001\n",
      "Epoch 5, Step: 614, Loss: 0.03954882174730301, Lr:0.0001\n",
      "Epoch 5, Step: 615, Loss: 0.0910293236374855, Lr:0.0001\n",
      "Epoch 5, Step: 616, Loss: 0.029182754456996918, Lr:0.0001\n",
      "Epoch 5, Step: 617, Loss: 0.10357815027236938, Lr:0.0001\n",
      "Epoch 5, Step: 618, Loss: 0.30606091022491455, Lr:0.0001\n",
      "Epoch 5, Step: 619, Loss: 0.48440849781036377, Lr:0.0001\n",
      "Epoch 5, Step: 620, Loss: 0.14009207487106323, Lr:0.0001\n",
      "Epoch 5, Step: 621, Loss: 0.3235480785369873, Lr:0.0001\n",
      "Epoch 5, Step: 622, Loss: 0.034757401794195175, Lr:0.0001\n",
      "Epoch 5, Step: 623, Loss: 0.2156910002231598, Lr:0.0001\n",
      "Epoch 5, Step: 624, Loss: 0.3823150098323822, Lr:0.0001\n",
      "Epoch 5, Step: 625, Loss: 0.253360390663147, Lr:0.0001\n",
      "Epoch 5, Step: 626, Loss: 0.1138094961643219, Lr:0.0001\n",
      "Epoch 5, Step: 627, Loss: 0.26995524764060974, Lr:0.0001\n",
      "Epoch 5, Step: 628, Loss: 0.2573056221008301, Lr:0.0001\n",
      "Epoch 5, Step: 629, Loss: 0.5107786059379578, Lr:0.0001\n",
      "Epoch 5, Step: 630, Loss: 0.26559367775917053, Lr:0.0001\n",
      "Epoch 5, Step: 631, Loss: 0.21083512902259827, Lr:0.0001\n",
      "Epoch 5, Step: 632, Loss: 0.17181040346622467, Lr:0.0001\n",
      "Epoch 5, Step: 633, Loss: 0.08211197704076767, Lr:0.0001\n",
      "Epoch 5, Step: 634, Loss: 0.18208874762058258, Lr:0.0001\n",
      "Epoch 5, Step: 635, Loss: 0.2115483433008194, Lr:0.0001\n",
      "Epoch 5, Step: 636, Loss: 0.29747554659843445, Lr:0.0001\n",
      "Epoch 5, Step: 637, Loss: 0.3826002776622772, Lr:0.0001\n",
      "Epoch 5, Step: 638, Loss: 0.16817885637283325, Lr:0.0001\n",
      "Epoch 5, Step: 639, Loss: 0.21945485472679138, Lr:0.0001\n",
      "Epoch 5, Step: 640, Loss: 0.2004821002483368, Lr:0.0001\n",
      "Epoch 5, Step: 641, Loss: 0.10581671446561813, Lr:0.0001\n",
      "Epoch 5, Step: 642, Loss: 0.23807404935359955, Lr:0.0001\n",
      "Epoch 5, Step: 643, Loss: 0.36499014496803284, Lr:0.0001\n",
      "Epoch 5, Step: 644, Loss: 0.19733071327209473, Lr:0.0001\n",
      "Epoch 5, Step: 645, Loss: 0.30360496044158936, Lr:0.0001\n",
      "Epoch 5, Step: 646, Loss: 0.23833349347114563, Lr:0.0001\n",
      "Epoch 5, Step: 647, Loss: 0.25823816657066345, Lr:0.0001\n",
      "Epoch 5, Step: 648, Loss: 0.14880676567554474, Lr:0.0001\n",
      "Epoch 5, Step: 649, Loss: 0.5950285196304321, Lr:0.0001\n",
      "Epoch 5, Step: 650, Loss: 0.2410840392112732, Lr:0.0001\n",
      "Epoch 5, Step: 651, Loss: 0.06426654756069183, Lr:0.0001\n",
      "Epoch 5, Step: 652, Loss: 0.15667963027954102, Lr:0.0001\n",
      "Epoch 5, Step: 653, Loss: 0.4070051610469818, Lr:0.0001\n",
      "Epoch 5, Step: 654, Loss: 0.12065299600362778, Lr:0.0001\n",
      "Epoch 5, Step: 655, Loss: 0.0854518860578537, Lr:0.0001\n",
      "Epoch 5, Step: 656, Loss: 0.34456920623779297, Lr:0.0001\n",
      "Epoch 5, Step: 657, Loss: 0.058160752058029175, Lr:0.0001\n",
      "Epoch 5, Step: 658, Loss: 0.2505902051925659, Lr:0.0001\n",
      "Epoch 5, Step: 659, Loss: 0.15861855447292328, Lr:0.0001\n",
      "Epoch 5, Step: 660, Loss: 0.09146115928888321, Lr:0.0001\n",
      "Epoch 5, Step: 661, Loss: 0.1499330848455429, Lr:0.0001\n",
      "Epoch 5, Step: 662, Loss: 0.22758063673973083, Lr:0.0001\n",
      "Epoch 5, Step: 663, Loss: 0.25321176648139954, Lr:0.0001\n",
      "Epoch 5, Step: 664, Loss: 0.10534483939409256, Lr:0.0001\n",
      "Epoch 5, Step: 665, Loss: 0.1741228997707367, Lr:0.0001\n",
      "Epoch 5, Step: 666, Loss: 0.2141319215297699, Lr:0.0001\n",
      "Epoch 5, Step: 667, Loss: 0.26267966628074646, Lr:0.0001\n",
      "Epoch 5, Step: 668, Loss: 0.1532967984676361, Lr:0.0001\n",
      "Epoch 5, Step: 669, Loss: 0.29689648747444153, Lr:0.0001\n",
      "Epoch 5, Step: 670, Loss: 0.09119116514921188, Lr:0.0001\n",
      "Epoch 5, Step: 671, Loss: 0.3425261378288269, Lr:0.0001\n",
      "Epoch 5, Step: 672, Loss: 0.15660595893859863, Lr:0.0001\n",
      "Epoch 5, Step: 673, Loss: 0.2236405313014984, Lr:0.0001\n",
      "Epoch 5, Step: 674, Loss: 0.19871161878108978, Lr:0.0001\n",
      "Epoch 5, Step: 675, Loss: 0.27307605743408203, Lr:0.0001\n",
      "Epoch 5, Step: 676, Loss: 0.19643935561180115, Lr:0.0001\n",
      "Epoch 5, Step: 677, Loss: 0.07915946841239929, Lr:0.0001\n",
      "Epoch 5, Step: 678, Loss: 0.3789823651313782, Lr:0.0001\n",
      "Epoch 5, Step: 679, Loss: 0.25395292043685913, Lr:0.0001\n",
      "Epoch 5, Step: 680, Loss: 0.27627381682395935, Lr:0.0001\n",
      "Epoch 5, Step: 681, Loss: 0.14797446131706238, Lr:0.0001\n",
      "Epoch 5, Step: 682, Loss: 0.526133120059967, Lr:0.0001\n",
      "Epoch 5, Step: 683, Loss: 0.18632018566131592, Lr:0.0001\n",
      "Epoch 5, Step: 684, Loss: 0.2919480800628662, Lr:0.0001\n",
      "Epoch 5, Step: 685, Loss: 0.3855089843273163, Lr:0.0001\n",
      "Epoch 5, Step: 686, Loss: 0.29451194405555725, Lr:0.0001\n",
      "Epoch 5, Step: 687, Loss: 0.4775203466415405, Lr:0.0001\n",
      "Epoch 5, Step: 688, Loss: 0.08655933290719986, Lr:0.0001\n",
      "Epoch 5, Step: 689, Loss: 0.17436575889587402, Lr:0.0001\n",
      "Epoch 5, Step: 690, Loss: 0.12946201860904694, Lr:0.0001\n",
      "Epoch 5, Step: 691, Loss: 0.17848876118659973, Lr:0.0001\n",
      "Epoch 5, Step: 692, Loss: 0.0907222107052803, Lr:0.0001\n",
      "Epoch 5, Step: 693, Loss: 0.09002742916345596, Lr:0.0001\n",
      "Epoch 5, Step: 694, Loss: 0.24265211820602417, Lr:0.0001\n",
      "Epoch 5, Step: 695, Loss: 0.21298937499523163, Lr:0.0001\n",
      "Epoch 5, Step: 696, Loss: 0.26855897903442383, Lr:0.0001\n",
      "Epoch 5, Step: 697, Loss: 0.2545475363731384, Lr:0.0001\n",
      "Epoch 5, Step: 698, Loss: 0.4864179790019989, Lr:0.0001\n",
      "Epoch 5, Step: 699, Loss: 0.31147244572639465, Lr:0.0001\n",
      "Epoch 5, Step: 700, Loss: 0.28669822216033936, Lr:0.0001\n",
      "Epoch 5, Step: 701, Loss: 0.3141343891620636, Lr:0.0001\n",
      "Epoch 5, Step: 702, Loss: 0.21715675294399261, Lr:0.0001\n",
      "Epoch 5, Step: 703, Loss: 0.41403186321258545, Lr:0.0001\n",
      "Epoch 5, Step: 704, Loss: 0.11477558314800262, Lr:0.0001\n",
      "Epoch 5, Step: 705, Loss: 0.1631719022989273, Lr:0.0001\n",
      "Epoch 5, Step: 706, Loss: 0.4055655598640442, Lr:0.0001\n",
      "Epoch 5, Step: 707, Loss: 0.13909055292606354, Lr:0.0001\n",
      "Epoch 5, Step: 708, Loss: 0.15612319111824036, Lr:0.0001\n",
      "Epoch 5, Step: 709, Loss: 0.09583144634962082, Lr:0.0001\n",
      "Epoch 5, Step: 710, Loss: 0.38740086555480957, Lr:0.0001\n",
      "Epoch 5, Step: 711, Loss: 0.2180989533662796, Lr:0.0001\n",
      "Epoch 5, Step: 712, Loss: 0.10431332141160965, Lr:0.0001\n",
      "Epoch 5, Step: 713, Loss: 0.2058660238981247, Lr:0.0001\n",
      "Epoch 5, Step: 714, Loss: 0.23403410613536835, Lr:0.0001\n",
      "Epoch 5, Step: 715, Loss: 0.20294198393821716, Lr:0.0001\n",
      "Epoch 5, Step: 716, Loss: 0.42205506563186646, Lr:0.0001\n",
      "Epoch 5, Step: 717, Loss: 0.23409394919872284, Lr:0.0001\n",
      "Epoch 5, Step: 718, Loss: 0.16304504871368408, Lr:0.0001\n",
      "Epoch 5, Step: 719, Loss: 0.516578733921051, Lr:0.0001\n",
      "Epoch 5, Step: 720, Loss: 0.03383057937026024, Lr:0.0001\n",
      "Epoch 5, Step: 721, Loss: 0.33814606070518494, Lr:0.0001\n",
      "Epoch 5, Step: 722, Loss: 0.2045879364013672, Lr:0.0001\n",
      "Epoch 5, Step: 723, Loss: 0.27002641558647156, Lr:0.0001\n",
      "Epoch 5, Step: 724, Loss: 0.15019237995147705, Lr:0.0001\n",
      "Epoch 5, Step: 725, Loss: 0.2353963553905487, Lr:0.0001\n",
      "Epoch 5, Step: 726, Loss: 0.21275874972343445, Lr:0.0001\n",
      "Epoch 5, Step: 727, Loss: 0.09609878808259964, Lr:0.0001\n",
      "Epoch 5, Step: 728, Loss: 0.32111743092536926, Lr:0.0001\n",
      "Epoch 5, Step: 729, Loss: 0.06158005818724632, Lr:0.0001\n",
      "Epoch 5, Step: 730, Loss: 0.3628388047218323, Lr:0.0001\n",
      "Epoch 5, Step: 731, Loss: 0.33023667335510254, Lr:0.0001\n",
      "Epoch 5, Step: 732, Loss: 0.4478330612182617, Lr:0.0001\n",
      "Epoch 5, Step: 733, Loss: 0.22696726024150848, Lr:0.0001\n",
      "Epoch 5, Step: 734, Loss: 0.19686034321784973, Lr:0.0001\n",
      "Epoch 5, Step: 735, Loss: 0.3151928186416626, Lr:0.0001\n",
      "Epoch 5, Step: 736, Loss: 0.39401814341545105, Lr:0.0001\n",
      "Epoch 5, Step: 737, Loss: 0.17272526025772095, Lr:0.0001\n",
      "Epoch 5, Step: 738, Loss: 0.3634975850582123, Lr:0.0001\n",
      "Epoch 5, Step: 739, Loss: 0.5589057207107544, Lr:0.0001\n",
      "Epoch 5, Step: 740, Loss: 0.5221598744392395, Lr:0.0001\n",
      "Epoch 5, Step: 741, Loss: 0.5503679513931274, Lr:0.0001\n",
      "Epoch 5, Step: 742, Loss: 0.22539159655570984, Lr:0.0001\n",
      "Epoch 5, Step: 743, Loss: 0.20054291188716888, Lr:0.0001\n",
      "Epoch 5, Step: 744, Loss: 0.2660345435142517, Lr:0.0001\n",
      "Epoch 5, Step: 745, Loss: 0.45347219705581665, Lr:0.0001\n",
      "Epoch 5, Step: 746, Loss: 0.3200031816959381, Lr:0.0001\n",
      "Epoch 5, Step: 747, Loss: 0.3704386353492737, Lr:0.0001\n",
      "Epoch 5, Step: 748, Loss: 0.18264219164848328, Lr:0.0001\n",
      "Epoch 5, Step: 749, Loss: 0.20997241139411926, Lr:0.0001\n",
      "Epoch 5, Step: 750, Loss: 0.31001126766204834, Lr:0.0001\n",
      "Epoch 5, Step: 751, Loss: 0.3438398241996765, Lr:0.0001\n",
      "Epoch 5, Step: 752, Loss: 0.3741316497325897, Lr:0.0001\n",
      "Epoch 5, Step: 753, Loss: 0.13421541452407837, Lr:0.0001\n",
      "Epoch 5, Step: 754, Loss: 0.32374268770217896, Lr:0.0001\n",
      "Epoch 5, Step: 755, Loss: 0.14532358944416046, Lr:0.0001\n",
      "Epoch 5, Step: 756, Loss: 0.23917356133460999, Lr:0.0001\n",
      "Epoch 5, Step: 757, Loss: 0.10378391295671463, Lr:0.0001\n",
      "Epoch 5, Step: 758, Loss: 0.07535194605588913, Lr:0.0001\n",
      "Epoch 5, Step: 759, Loss: 0.47112590074539185, Lr:0.0001\n",
      "Epoch 5, Step: 760, Loss: 0.19900915026664734, Lr:0.0001\n",
      "Epoch 5, Step: 761, Loss: 0.822215735912323, Lr:0.0001\n",
      "Epoch 5, Step: 762, Loss: 0.19935040175914764, Lr:0.0001\n",
      "Epoch 5, Step: 763, Loss: 0.09498672932386398, Lr:0.0001\n",
      "Epoch 5, Step: 764, Loss: 0.3011007308959961, Lr:0.0001\n",
      "Epoch 5, Step: 765, Loss: 0.29075226187705994, Lr:0.0001\n",
      "Epoch 5, Step: 766, Loss: 0.06269467622041702, Lr:0.0001\n",
      "Epoch 5, Step: 767, Loss: 0.057404763996601105, Lr:0.0001\n",
      "Epoch 5, Step: 768, Loss: 0.44901156425476074, Lr:0.0001\n",
      "Epoch 5, Step: 769, Loss: 0.26894959807395935, Lr:0.0001\n",
      "Epoch 5, Step: 770, Loss: 0.18678703904151917, Lr:0.0001\n",
      "Epoch 5, Step: 771, Loss: 0.11545095592737198, Lr:0.0001\n",
      "Epoch 5, Step: 772, Loss: 0.21217162907123566, Lr:0.0001\n",
      "Epoch 5, Step: 773, Loss: 0.43339094519615173, Lr:0.0001\n",
      "Epoch 5, Step: 774, Loss: 0.3579193651676178, Lr:0.0001\n",
      "Epoch 5, Step: 775, Loss: 0.03312491625547409, Lr:0.0001\n",
      "Epoch 5, Step: 776, Loss: 0.2160281538963318, Lr:0.0001\n",
      "Epoch 5, Step: 777, Loss: 0.16612684726715088, Lr:0.0001\n",
      "Epoch 5, Step: 778, Loss: 0.35533833503723145, Lr:0.0001\n",
      "Epoch 5, Step: 779, Loss: 0.37770795822143555, Lr:0.0001\n",
      "Epoch 5, Step: 780, Loss: 0.16256698966026306, Lr:0.0001\n",
      "Epoch 5, Step: 781, Loss: 0.38993361592292786, Lr:0.0001\n",
      "Epoch 5, Step: 782, Loss: 0.3208256959915161, Lr:0.0001\n",
      "Epoch 5, Step: 783, Loss: 0.11227213591337204, Lr:0.0001\n",
      "Epoch 5, Step: 784, Loss: 0.524953305721283, Lr:0.0001\n",
      "Epoch 5, Step: 785, Loss: 0.19836868345737457, Lr:0.0001\n",
      "Epoch 5, Step: 786, Loss: 0.22960877418518066, Lr:0.0001\n",
      "Epoch 5, Step: 787, Loss: 0.25003355741500854, Lr:0.0001\n",
      "Epoch 5, Step: 788, Loss: 0.32694724202156067, Lr:0.0001\n",
      "Epoch 5, Step: 789, Loss: 0.07588570564985275, Lr:0.0001\n",
      "Epoch 5, Step: 790, Loss: 0.22504398226737976, Lr:0.0001\n",
      "Epoch 5, Step: 791, Loss: 0.5294088125228882, Lr:0.0001\n",
      "Epoch 5, Step: 792, Loss: 0.18749737739562988, Lr:0.0001\n",
      "Epoch 5, Step: 793, Loss: 0.03741012513637543, Lr:0.0001\n",
      "Epoch 5, Step: 794, Loss: 0.4297245740890503, Lr:0.0001\n",
      "Epoch 5, Step: 795, Loss: 0.26024767756462097, Lr:0.0001\n",
      "Epoch 5, Step: 796, Loss: 0.30064377188682556, Lr:0.0001\n",
      "Epoch 5, Step: 797, Loss: 0.2754233479499817, Lr:0.0001\n",
      "Epoch 5, Step: 798, Loss: 0.18917523324489594, Lr:0.0001\n",
      "Epoch 5, Step: 799, Loss: 0.07713006436824799, Lr:0.0001\n",
      "Epoch 5, Step: 800, Loss: 0.6688917279243469, Lr:0.0001\n",
      "Epoch 5, Step: 801, Loss: 0.5729527473449707, Lr:0.0001\n",
      "Epoch 5, Step: 802, Loss: 0.4048383831977844, Lr:0.0001\n",
      "Epoch 5, Step: 803, Loss: 0.26258987188339233, Lr:0.0001\n",
      "Epoch 5, Step: 804, Loss: 0.1689557284116745, Lr:0.0001\n",
      "Epoch 5, Step: 805, Loss: 0.1309717446565628, Lr:0.0001\n",
      "Epoch 5, Step: 806, Loss: 0.45866310596466064, Lr:0.0001\n",
      "Epoch 5, Step: 807, Loss: 0.24224570393562317, Lr:0.0001\n",
      "Epoch 5, Step: 808, Loss: 0.06031949073076248, Lr:0.0001\n",
      "Epoch 5, Step: 809, Loss: 0.27112939953804016, Lr:0.0001\n",
      "Epoch 5, Step: 810, Loss: 0.1569495052099228, Lr:0.0001\n",
      "Epoch 5, Step: 811, Loss: 0.1336197853088379, Lr:0.0001\n",
      "Epoch 5, Step: 812, Loss: 0.11376256495714188, Lr:0.0001\n",
      "Epoch 5, Step: 813, Loss: 0.3626962900161743, Lr:0.0001\n",
      "Epoch 5, Step: 814, Loss: 0.2131945639848709, Lr:0.0001\n",
      "Epoch 5, Step: 815, Loss: 0.3326241075992584, Lr:0.0001\n",
      "Epoch 5, Step: 816, Loss: 0.2450971007347107, Lr:0.0001\n",
      "Epoch 5, Step: 817, Loss: 0.342869371175766, Lr:0.0001\n",
      "Epoch 5, Step: 818, Loss: 0.2033359408378601, Lr:0.0001\n",
      "Epoch 5, Step: 819, Loss: 0.22893169522285461, Lr:0.0001\n",
      "Epoch 5, Step: 820, Loss: 0.4025938808917999, Lr:0.0001\n",
      "Epoch 5, Step: 821, Loss: 0.18187932670116425, Lr:0.0001\n",
      "Epoch 5, Step: 822, Loss: 0.09448430687189102, Lr:0.0001\n",
      "Epoch 5, Step: 823, Loss: 0.20169447362422943, Lr:0.0001\n",
      "Epoch 5, Step: 824, Loss: 0.13866299390792847, Lr:0.0001\n",
      "Epoch 5, Step: 825, Loss: 0.410290390253067, Lr:0.0001\n",
      "Epoch 5, Step: 826, Loss: 0.2283741980791092, Lr:0.0001\n",
      "Epoch 5, Step: 827, Loss: 0.2577674984931946, Lr:0.0001\n",
      "Epoch 5, Step: 828, Loss: 0.3208308815956116, Lr:0.0001\n",
      "Epoch 5, Step: 829, Loss: 0.17373721301555634, Lr:0.0001\n",
      "Epoch 5, Step: 830, Loss: 0.0680207833647728, Lr:0.0001\n",
      "Epoch 5, Step: 831, Loss: 0.5748174786567688, Lr:0.0001\n",
      "Epoch 5, Step: 832, Loss: 0.33939552307128906, Lr:0.0001\n",
      "Epoch 5, Step: 833, Loss: 0.15451551973819733, Lr:0.0001\n",
      "Epoch 5, Step: 834, Loss: 0.05031245946884155, Lr:0.0001\n",
      "Epoch 5, Step: 835, Loss: 0.1899271160364151, Lr:0.0001\n",
      "Epoch 5, Step: 836, Loss: 0.1677461415529251, Lr:0.0001\n",
      "Epoch 5, Step: 837, Loss: 0.11334270238876343, Lr:0.0001\n",
      "Epoch 5, Step: 838, Loss: 0.18000580370426178, Lr:0.0001\n",
      "Epoch 5, Step: 839, Loss: 0.06867629289627075, Lr:0.0001\n",
      "Epoch 5, Step: 840, Loss: 0.15683592855930328, Lr:0.0001\n",
      "Epoch 5, Step: 841, Loss: 0.17555062472820282, Lr:0.0001\n",
      "Epoch 5, Step: 842, Loss: 0.3430383503437042, Lr:0.0001\n",
      "Epoch 5, Step: 843, Loss: 0.16189579665660858, Lr:0.0001\n",
      "Epoch 5, Step: 844, Loss: 0.1137162446975708, Lr:0.0001\n",
      "Epoch 5, Step: 845, Loss: 0.11918643116950989, Lr:0.0001\n",
      "Epoch 5, Step: 846, Loss: 0.2860576808452606, Lr:0.0001\n",
      "Epoch 5, Step: 847, Loss: 0.07852815836668015, Lr:0.0001\n",
      "Epoch 5, Step: 848, Loss: 0.18479172885417938, Lr:0.0001\n",
      "Epoch 5, Step: 849, Loss: 0.22430481016635895, Lr:0.0001\n",
      "Epoch 5, Step: 850, Loss: 0.29177865386009216, Lr:0.0001\n",
      "Epoch 5, Step: 851, Loss: 0.24209913611412048, Lr:0.0001\n",
      "Epoch 5, Step: 852, Loss: 0.0725879818201065, Lr:0.0001\n",
      "Epoch 5, Step: 853, Loss: 0.1465172916650772, Lr:0.0001\n",
      "Epoch 5, Step: 854, Loss: 0.04702429845929146, Lr:0.0001\n",
      "Epoch 5, Step: 855, Loss: 0.08783827722072601, Lr:0.0001\n",
      "Epoch 5, Step: 856, Loss: 0.10304639488458633, Lr:0.0001\n",
      "Epoch 5, Step: 857, Loss: 0.21661190688610077, Lr:0.0001\n",
      "Epoch 5, Step: 858, Loss: 0.18842166662216187, Lr:0.0001\n",
      "Epoch 5, Step: 859, Loss: 0.12870320677757263, Lr:0.0001\n",
      "Epoch 5, Step: 860, Loss: 0.16536705195903778, Lr:0.0001\n",
      "Epoch 5, Step: 861, Loss: 0.3943186402320862, Lr:0.0001\n",
      "Epoch 5, Step: 862, Loss: 0.48065710067749023, Lr:0.0001\n",
      "Epoch 5, Step: 863, Loss: 0.15004338324069977, Lr:0.0001\n",
      "Epoch 5, Step: 864, Loss: 0.32866448163986206, Lr:0.0001\n",
      "Epoch 5, Step: 865, Loss: 0.13446274399757385, Lr:0.0001\n",
      "Epoch 5, Step: 866, Loss: 0.4696761965751648, Lr:0.0001\n",
      "Epoch 5, Step: 867, Loss: 0.20752361416816711, Lr:0.0001\n",
      "Epoch 5, Step: 868, Loss: 0.22265508770942688, Lr:0.0001\n",
      "Epoch 5, Step: 869, Loss: 0.031803734600543976, Lr:0.0001\n",
      "Epoch 5, Step: 870, Loss: 0.04722898080945015, Lr:0.0001\n",
      "Epoch 5, Step: 871, Loss: 0.07132292538881302, Lr:0.0001\n",
      "Epoch 5, Step: 872, Loss: 0.08064113557338715, Lr:0.0001\n",
      "Epoch 5, Step: 873, Loss: 0.49909621477127075, Lr:0.0001\n",
      "Epoch 5, Step: 874, Loss: 0.15257535874843597, Lr:0.0001\n",
      "Epoch 5, Step: 875, Loss: 0.14453929662704468, Lr:0.0001\n",
      "Epoch 5, Step: 876, Loss: 0.4014464020729065, Lr:0.0001\n",
      "Epoch 5, Step: 877, Loss: 0.2858108580112457, Lr:0.0001\n",
      "Epoch 5, Step: 878, Loss: 0.18232540786266327, Lr:0.0001\n",
      "Epoch 5, Step: 879, Loss: 0.23715727031230927, Lr:0.0001\n",
      "Epoch 5, Step: 880, Loss: 0.22011864185333252, Lr:0.0001\n",
      "Epoch 5, Step: 881, Loss: 0.4550509452819824, Lr:0.0001\n",
      "Epoch 5, Step: 882, Loss: 0.07006041705608368, Lr:0.0001\n",
      "Epoch 5, Step: 883, Loss: 0.10440832376480103, Lr:0.0001\n",
      "Epoch 5, Step: 884, Loss: 0.2043120563030243, Lr:0.0001\n",
      "Epoch 5, Step: 885, Loss: 0.38420069217681885, Lr:0.0001\n",
      "Epoch 5, Step: 886, Loss: 0.29271450638771057, Lr:0.0001\n",
      "Epoch 5, Step: 887, Loss: 0.1809462308883667, Lr:0.0001\n",
      "Epoch 5, Step: 888, Loss: 0.3152497708797455, Lr:0.0001\n",
      "Epoch 5, Step: 889, Loss: 0.22415819764137268, Lr:0.0001\n",
      "Epoch 5, Step: 890, Loss: 0.30309173464775085, Lr:0.0001\n",
      "Epoch 5, Step: 891, Loss: 0.23889824748039246, Lr:0.0001\n",
      "Epoch 5, Step: 892, Loss: 0.21980887651443481, Lr:0.0001\n",
      "Epoch 5, Step: 893, Loss: 0.01992492750287056, Lr:0.0001\n",
      "Epoch 5, Step: 894, Loss: 0.24005617201328278, Lr:0.0001\n",
      "Epoch 5, Step: 895, Loss: 0.09131546318531036, Lr:0.0001\n",
      "Epoch 5, Step: 896, Loss: 0.4059182405471802, Lr:0.0001\n",
      "Epoch 5, Step: 897, Loss: 0.5081758499145508, Lr:0.0001\n",
      "Epoch 5, Step: 898, Loss: 0.11556380242109299, Lr:0.0001\n",
      "Epoch 5, Step: 899, Loss: 0.09587027877569199, Lr:0.0001\n",
      "Epoch 5, Step: 900, Loss: 0.1593322604894638, Lr:0.0001\n",
      "Epoch 5, Step: 901, Loss: 0.290731817483902, Lr:0.0001\n",
      "Epoch 5, Step: 902, Loss: 0.08657553046941757, Lr:0.0001\n",
      "Epoch 5, Step: 903, Loss: 0.08200409263372421, Lr:0.0001\n",
      "Epoch 5, Step: 904, Loss: 0.10576570779085159, Lr:0.0001\n",
      "Epoch 5, Step: 905, Loss: 0.11583413928747177, Lr:0.0001\n",
      "Epoch 5, Step: 906, Loss: 0.3380987346172333, Lr:0.0001\n",
      "Epoch 5, Step: 907, Loss: 0.08555741608142853, Lr:0.0001\n",
      "Epoch 5, Step: 908, Loss: 0.1826232671737671, Lr:0.0001\n",
      "Epoch 5, Step: 909, Loss: 0.08846751600503922, Lr:0.0001\n",
      "Epoch 5, Step: 910, Loss: 0.4816942811012268, Lr:0.0001\n",
      "Epoch 5, Step: 911, Loss: 0.2266654670238495, Lr:0.0001\n",
      "Epoch 5, Step: 912, Loss: 0.35024577379226685, Lr:0.0001\n",
      "Epoch 5, Step: 913, Loss: 0.20810289680957794, Lr:0.0001\n",
      "Epoch 5, Step: 914, Loss: 0.38889017701148987, Lr:0.0001\n",
      "Epoch 5, Step: 915, Loss: 0.4628036320209503, Lr:0.0001\n",
      "Epoch 5, Step: 916, Loss: 0.2433457374572754, Lr:0.0001\n",
      "Epoch 5, Step: 917, Loss: 0.7801482677459717, Lr:0.0001\n",
      "Epoch 5, Step: 918, Loss: 0.07656271755695343, Lr:0.0001\n",
      "Epoch 5, Step: 919, Loss: 0.2684786915779114, Lr:0.0001\n",
      "Epoch 5, Step: 920, Loss: 0.1450916975736618, Lr:0.0001\n",
      "Epoch 5, Step: 921, Loss: 0.13954615592956543, Lr:0.0001\n",
      "Epoch 5, Step: 922, Loss: 0.1518072932958603, Lr:0.0001\n",
      "Epoch 5, Step: 923, Loss: 0.14707545936107635, Lr:0.0001\n",
      "Epoch 5, Step: 924, Loss: 0.24516208469867706, Lr:0.0001\n",
      "Epoch 5, Step: 925, Loss: 0.23633593320846558, Lr:0.0001\n",
      "Epoch 5, Step: 926, Loss: 0.2877817153930664, Lr:0.0001\n",
      "Epoch 5, Step: 927, Loss: 0.07457494735717773, Lr:0.0001\n",
      "Epoch 5, Step: 928, Loss: 0.11615167558193207, Lr:0.0001\n",
      "Epoch 5, Step: 929, Loss: 0.5845139026641846, Lr:0.0001\n",
      "Epoch 5, Step: 930, Loss: 0.11982544511556625, Lr:0.0001\n",
      "Epoch 5, Step: 931, Loss: 0.15982064604759216, Lr:0.0001\n",
      "Epoch 5, Step: 932, Loss: 0.19965395331382751, Lr:0.0001\n",
      "Epoch 5, Step: 933, Loss: 0.23007771372795105, Lr:0.0001\n",
      "Epoch 5, Step: 934, Loss: 0.16622795164585114, Lr:0.0001\n",
      "Epoch 5, Step: 935, Loss: 0.07594567537307739, Lr:0.0001\n",
      "Epoch 5, Step: 936, Loss: 0.19123266637325287, Lr:0.0001\n",
      "Epoch 5, Step: 937, Loss: 0.297200083732605, Lr:0.0001\n",
      "Epoch 5, Step: 938, Loss: 0.31642991304397583, Lr:0.0001\n",
      "Epoch 5, Step: 939, Loss: 0.23707103729248047, Lr:0.0001\n",
      "Epoch 5, Step: 940, Loss: 0.2791930139064789, Lr:0.0001\n",
      "Epoch 5, Step: 941, Loss: 0.0730229988694191, Lr:0.0001\n",
      "Epoch 5, Step: 942, Loss: 0.06948059797286987, Lr:0.0001\n",
      "Epoch 5, Step: 943, Loss: 0.1827612966299057, Lr:0.0001\n",
      "Epoch 5, Step: 944, Loss: 0.3691587448120117, Lr:0.0001\n",
      "Epoch 5, Step: 945, Loss: 0.26171597838401794, Lr:0.0001\n",
      "Epoch 5, Step: 946, Loss: 0.2376725971698761, Lr:0.0001\n",
      "Epoch 5, Step: 947, Loss: 0.15459762513637543, Lr:0.0001\n",
      "Epoch 5, Step: 948, Loss: 0.19565944373607635, Lr:0.0001\n",
      "Epoch 5, Step: 949, Loss: 0.30410236120224, Lr:0.0001\n",
      "Epoch 5, Step: 950, Loss: 0.1774853765964508, Lr:0.0001\n",
      "Epoch 5, Step: 951, Loss: 0.059734590351581573, Lr:0.0001\n",
      "Epoch 5, Step: 952, Loss: 0.09077462553977966, Lr:0.0001\n",
      "Epoch 5, Step: 953, Loss: 0.3523894250392914, Lr:0.0001\n",
      "Epoch 5, Step: 954, Loss: 0.19398652017116547, Lr:0.0001\n",
      "Epoch 5, Step: 955, Loss: 0.1274363100528717, Lr:0.0001\n",
      "Epoch 5, Step: 956, Loss: 0.3465806245803833, Lr:0.0001\n",
      "Epoch 5, Step: 957, Loss: 0.3451269865036011, Lr:0.0001\n",
      "Epoch 5, Step: 958, Loss: 0.33870813250541687, Lr:0.0001\n",
      "Epoch 5, Step: 959, Loss: 0.33128294348716736, Lr:0.0001\n",
      "Epoch 5, Step: 960, Loss: 0.04295024275779724, Lr:0.0001\n",
      "Epoch 5, Step: 961, Loss: 0.2959301471710205, Lr:0.0001\n",
      "Epoch 5, Step: 962, Loss: 0.26083970069885254, Lr:0.0001\n",
      "Epoch 5, Step: 963, Loss: 0.08518634736537933, Lr:0.0001\n",
      "Epoch 5, Step: 964, Loss: 0.33169353008270264, Lr:0.0001\n",
      "Epoch 5, Step: 965, Loss: 0.13329631090164185, Lr:0.0001\n",
      "Epoch 5, Step: 966, Loss: 0.23051945865154266, Lr:0.0001\n",
      "Epoch 5, Step: 967, Loss: 0.16305728256702423, Lr:0.0001\n",
      "Epoch 5, Step: 968, Loss: 0.1198873370885849, Lr:0.0001\n",
      "Epoch 5, Step: 969, Loss: 0.1722942292690277, Lr:0.0001\n",
      "Epoch 5, Step: 970, Loss: 0.06277142465114594, Lr:0.0001\n",
      "Epoch 5, Step: 971, Loss: 0.16807793080806732, Lr:0.0001\n",
      "Epoch 5, Step: 972, Loss: 0.06513647735118866, Lr:0.0001\n",
      "Epoch 5, Step: 973, Loss: 0.08472645282745361, Lr:0.0001\n",
      "Epoch 5, Step: 974, Loss: 0.2125099152326584, Lr:0.0001\n",
      "Epoch 5, Step: 975, Loss: 0.19720374047756195, Lr:0.0001\n",
      "Epoch 5, Step: 976, Loss: 0.057669006288051605, Lr:0.0001\n",
      "Epoch 5, Step: 977, Loss: 0.3159261643886566, Lr:0.0001\n",
      "Epoch 5, Step: 978, Loss: 0.21999439597129822, Lr:0.0001\n",
      "Epoch 5, Step: 979, Loss: 0.130623921751976, Lr:0.0001\n",
      "Epoch 5, Step: 980, Loss: 0.29812687635421753, Lr:0.0001\n",
      "Epoch 5, Step: 981, Loss: 0.19029542803764343, Lr:0.0001\n",
      "Epoch 5, Step: 982, Loss: 0.10517283529043198, Lr:0.0001\n",
      "Epoch 5, Step: 983, Loss: 0.22022745013237, Lr:0.0001\n",
      "Epoch 5, Step: 984, Loss: 0.05845119431614876, Lr:0.0001\n",
      "Epoch 5, Step: 985, Loss: 0.21936294436454773, Lr:0.0001\n",
      "Epoch 5, Step: 986, Loss: 0.24766381084918976, Lr:0.0001\n",
      "Epoch 5, Step: 987, Loss: 0.09968368709087372, Lr:0.0001\n",
      "Epoch 5, Step: 988, Loss: 0.10806556046009064, Lr:0.0001\n",
      "Epoch 5, Step: 989, Loss: 0.14862744510173798, Lr:0.0001\n",
      "Epoch 5, Step: 990, Loss: 0.1813756227493286, Lr:0.0001\n",
      "Epoch 5, Step: 991, Loss: 0.1477859616279602, Lr:0.0001\n",
      "Epoch 5, Step: 992, Loss: 0.02269216999411583, Lr:0.0001\n",
      "Epoch 5, Step: 993, Loss: 0.028377268463373184, Lr:0.0001\n",
      "Epoch 5, Step: 994, Loss: 0.19086593389511108, Lr:0.0001\n",
      "Epoch 5, Step: 995, Loss: 0.032753340899944305, Lr:0.0001\n",
      "Epoch 5, Step: 996, Loss: 0.01744639314711094, Lr:0.0001\n",
      "Epoch 5, Step: 997, Loss: 0.055354855954647064, Lr:0.0001\n",
      "Epoch 5, Step: 998, Loss: 0.19900980591773987, Lr:0.0001\n",
      "Epoch 5, Step: 999, Loss: 0.14018285274505615, Lr:0.0001\n",
      "Epoch 5, Step: 1000, Loss: 0.10200890898704529, Lr:0.0001\n",
      "Epoch 5, Step: 1001, Loss: 0.15128545463085175, Lr:0.0001\n",
      "Epoch 5, Step: 1002, Loss: 0.2139059603214264, Lr:0.0001\n",
      "Epoch 5, Step: 1003, Loss: 0.6439288258552551, Lr:0.0001\n",
      "Epoch 5, Step: 1004, Loss: 0.1761905699968338, Lr:0.0001\n",
      "Epoch 5, Step: 1005, Loss: 0.5429465770721436, Lr:0.0001\n",
      "Epoch 5, Step: 1006, Loss: 0.08084951341152191, Lr:0.0001\n",
      "Epoch 5, Step: 1007, Loss: 0.342943400144577, Lr:0.0001\n",
      "Epoch 5, Step: 1008, Loss: 0.04052572324872017, Lr:0.0001\n",
      "Epoch 5, Step: 1009, Loss: 0.3555280268192291, Lr:0.0001\n",
      "Epoch 5, Step: 1010, Loss: 0.11028898507356644, Lr:0.0001\n",
      "Epoch 5, Step: 1011, Loss: 0.2542417049407959, Lr:0.0001\n",
      "Epoch 5, Step: 1012, Loss: 0.09942648559808731, Lr:0.0001\n",
      "Epoch 5, Step: 1013, Loss: 0.18072465062141418, Lr:0.0001\n",
      "Epoch 5, Step: 1014, Loss: 0.1766541749238968, Lr:0.0001\n",
      "Epoch 5, Step: 1015, Loss: 0.07631923258304596, Lr:0.0001\n",
      "Epoch 5, Step: 1016, Loss: 0.6333706378936768, Lr:0.0001\n",
      "Epoch 5, Step: 1017, Loss: 0.05500206723809242, Lr:0.0001\n",
      "Epoch 5, Step: 1018, Loss: 0.036044348031282425, Lr:0.0001\n",
      "Epoch 5, Step: 1019, Loss: 0.08051952719688416, Lr:0.0001\n",
      "Epoch 5, Step: 1020, Loss: 0.6057225465774536, Lr:0.0001\n",
      "Epoch 5, Step: 1021, Loss: 0.2678336203098297, Lr:0.0001\n",
      "Epoch 5, Step: 1022, Loss: 0.30224642157554626, Lr:0.0001\n",
      "Epoch 5, Step: 1023, Loss: 0.21169579029083252, Lr:0.0001\n",
      "Epoch 5, Step: 1024, Loss: 0.17539730668067932, Lr:0.0001\n",
      "Epoch 5, Step: 1025, Loss: 0.19874843955039978, Lr:0.0001\n",
      "Epoch 5, Step: 1026, Loss: 0.3440151512622833, Lr:0.0001\n",
      "Epoch 5, Step: 1027, Loss: 0.21703124046325684, Lr:0.0001\n",
      "Epoch 5, Step: 1028, Loss: 0.1631666123867035, Lr:0.0001\n",
      "Epoch 5, Step: 1029, Loss: 0.2690487802028656, Lr:0.0001\n",
      "Epoch 5, Step: 1030, Loss: 0.40652790665626526, Lr:0.0001\n",
      "Epoch 5, Step: 1031, Loss: 0.2640922963619232, Lr:0.0001\n",
      "Epoch 5, Step: 1032, Loss: 0.09741665422916412, Lr:0.0001\n",
      "Epoch 5, Step: 1033, Loss: 0.3671325445175171, Lr:0.0001\n",
      "Epoch 5, Step: 1034, Loss: 0.43791472911834717, Lr:0.0001\n",
      "Epoch 5, Step: 1035, Loss: 0.3807424008846283, Lr:0.0001\n",
      "Epoch 5, Step: 1036, Loss: 0.029902389273047447, Lr:0.0001\n",
      "Epoch 5, Step: 1037, Loss: 0.21931028366088867, Lr:0.0001\n",
      "Epoch 5, Step: 1038, Loss: 0.14066873490810394, Lr:0.0001\n",
      "Epoch 5, Step: 1039, Loss: 0.18637193739414215, Lr:0.0001\n",
      "Epoch 5, Step: 1040, Loss: 0.17597734928131104, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 5\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:16 loss: 0.9321 (0.9321) acc1: 68.7500 (68.7500) acc5: 100.0000 (100.0000) time: 0.2974 data: 0.1206 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.0922 (0.2549) acc1: 93.7500 (90.3409) acc5: 100.0000 (100.0000) time: 0.2890 data: 0.1138 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0774 (0.2950) acc1: 93.7500 (91.0714) acc5: 100.0000 (100.0000) time: 0.2909 data: 0.1147 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.3765 (0.4409) acc1: 87.5000 (85.6855) acc5: 100.0000 (100.0000) time: 0.2962 data: 0.1175 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.4732 (0.4260) acc1: 81.2500 (85.6707) acc5: 100.0000 (100.0000) time: 0.2968 data: 0.1198 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.2467 (0.4273) acc1: 87.5000 (85.5392) acc5: 100.0000 (100.0000) time: 0.2975 data: 0.1223 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.1768 (0.4473) acc1: 87.5000 (85.5846) acc5: 100.0000 (100.0000) time: 0.2861 data: 0.1166 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.2904 s / it)\n",
      "* Acc@1 85.585 Acc@5 100.000 loss 0.447\n",
      "Accuracy of the network on the 881 test image: 85.6%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 6, Step: 0, Loss: 0.4826882481575012, Lr:0.0001\n",
      "Epoch 6, Step: 1, Loss: 0.0790925920009613, Lr:0.0001\n",
      "Epoch 6, Step: 2, Loss: 0.21293851733207703, Lr:0.0001\n",
      "Epoch 6, Step: 3, Loss: 0.25531941652297974, Lr:0.0001\n",
      "Epoch 6, Step: 4, Loss: 0.5893059968948364, Lr:0.0001\n",
      "Epoch 6, Step: 5, Loss: 0.11809268593788147, Lr:0.0001\n",
      "Epoch 6, Step: 6, Loss: 0.04869328811764717, Lr:0.0001\n",
      "Epoch 6, Step: 7, Loss: 0.23984023928642273, Lr:0.0001\n",
      "Epoch 6, Step: 8, Loss: 0.08220858126878738, Lr:0.0001\n",
      "Epoch 6, Step: 9, Loss: 0.048816412687301636, Lr:0.0001\n",
      "Epoch 6, Step: 10, Loss: 0.5989406108856201, Lr:0.0001\n",
      "Epoch 6, Step: 11, Loss: 0.26785919070243835, Lr:0.0001\n",
      "Epoch 6, Step: 12, Loss: 0.056723564863204956, Lr:0.0001\n",
      "Epoch 6, Step: 13, Loss: 0.13463272154331207, Lr:0.0001\n",
      "Epoch 6, Step: 14, Loss: 0.5667285323143005, Lr:0.0001\n",
      "Epoch 6, Step: 15, Loss: 0.05212150886654854, Lr:0.0001\n",
      "Epoch 6, Step: 16, Loss: 0.6484706997871399, Lr:0.0001\n",
      "Epoch 6, Step: 17, Loss: 0.15878647565841675, Lr:0.0001\n",
      "Epoch 6, Step: 18, Loss: 0.2378997653722763, Lr:0.0001\n",
      "Epoch 6, Step: 19, Loss: 0.167668879032135, Lr:0.0001\n",
      "Epoch 6, Step: 20, Loss: 0.40649670362472534, Lr:0.0001\n",
      "Epoch 6, Step: 21, Loss: 0.12700915336608887, Lr:0.0001\n",
      "Epoch 6, Step: 22, Loss: 0.09022054821252823, Lr:0.0001\n",
      "Epoch 6, Step: 23, Loss: 0.21769064664840698, Lr:0.0001\n",
      "Epoch 6, Step: 24, Loss: 0.11955107748508453, Lr:0.0001\n",
      "Epoch 6, Step: 25, Loss: 0.17363856732845306, Lr:0.0001\n",
      "Epoch 6, Step: 26, Loss: 0.40650832653045654, Lr:0.0001\n",
      "Epoch 6, Step: 27, Loss: 0.07218166440725327, Lr:0.0001\n",
      "Epoch 6, Step: 28, Loss: 0.11175539344549179, Lr:0.0001\n",
      "Epoch 6, Step: 29, Loss: 0.1547602415084839, Lr:0.0001\n",
      "Epoch 6, Step: 30, Loss: 0.4551880657672882, Lr:0.0001\n",
      "Epoch 6, Step: 31, Loss: 0.17051555216312408, Lr:0.0001\n",
      "Epoch 6, Step: 32, Loss: 0.11834484338760376, Lr:0.0001\n",
      "Epoch 6, Step: 33, Loss: 0.2074320912361145, Lr:0.0001\n",
      "Epoch 6, Step: 34, Loss: 0.33296307921409607, Lr:0.0001\n",
      "Epoch 6, Step: 35, Loss: 0.2172033190727234, Lr:0.0001\n",
      "Epoch 6, Step: 36, Loss: 0.2174025923013687, Lr:0.0001\n",
      "Epoch 6, Step: 37, Loss: 0.17921100556850433, Lr:0.0001\n",
      "Epoch 6, Step: 38, Loss: 0.053153786808252335, Lr:0.0001\n",
      "Epoch 6, Step: 39, Loss: 0.3946913182735443, Lr:0.0001\n",
      "Epoch 6, Step: 40, Loss: 0.46715885400772095, Lr:0.0001\n",
      "Epoch 6, Step: 41, Loss: 0.19502750039100647, Lr:0.0001\n",
      "Epoch 6, Step: 42, Loss: 0.17354053258895874, Lr:0.0001\n",
      "Epoch 6, Step: 43, Loss: 0.3243502676486969, Lr:0.0001\n",
      "Epoch 6, Step: 44, Loss: 0.08967257291078568, Lr:0.0001\n",
      "Epoch 6, Step: 45, Loss: 0.14979508519172668, Lr:0.0001\n",
      "Epoch 6, Step: 46, Loss: 0.08217606693506241, Lr:0.0001\n",
      "Epoch 6, Step: 47, Loss: 0.04281379282474518, Lr:0.0001\n",
      "Epoch 6, Step: 48, Loss: 0.16815930604934692, Lr:0.0001\n",
      "Epoch 6, Step: 49, Loss: 0.2694806456565857, Lr:0.0001\n",
      "Epoch 6, Step: 50, Loss: 0.13567674160003662, Lr:0.0001\n",
      "Epoch 6, Step: 51, Loss: 0.13833008706569672, Lr:0.0001\n",
      "Epoch 6, Step: 52, Loss: 0.3567712903022766, Lr:0.0001\n",
      "Epoch 6, Step: 53, Loss: 0.20308169722557068, Lr:0.0001\n",
      "Epoch 6, Step: 54, Loss: 0.07464297860860825, Lr:0.0001\n",
      "Epoch 6, Step: 55, Loss: 0.1269148886203766, Lr:0.0001\n",
      "Epoch 6, Step: 56, Loss: 0.03954755514860153, Lr:0.0001\n",
      "Epoch 6, Step: 57, Loss: 0.03541608527302742, Lr:0.0001\n",
      "Epoch 6, Step: 58, Loss: 0.581417977809906, Lr:0.0001\n",
      "Epoch 6, Step: 59, Loss: 0.290715754032135, Lr:0.0001\n",
      "Epoch 6, Step: 60, Loss: 0.04323464632034302, Lr:0.0001\n",
      "Epoch 6, Step: 61, Loss: 0.31633007526397705, Lr:0.0001\n",
      "Epoch 6, Step: 62, Loss: 0.09923524409532547, Lr:0.0001\n",
      "Epoch 6, Step: 63, Loss: 0.2182871401309967, Lr:0.0001\n",
      "Epoch 6, Step: 64, Loss: 0.17422990500926971, Lr:0.0001\n",
      "Epoch 6, Step: 65, Loss: 0.09258092939853668, Lr:0.0001\n",
      "Epoch 6, Step: 66, Loss: 0.32500943541526794, Lr:0.0001\n",
      "Epoch 6, Step: 67, Loss: 0.20986546576023102, Lr:0.0001\n",
      "Epoch 6, Step: 68, Loss: 0.1735784113407135, Lr:0.0001\n",
      "Epoch 6, Step: 69, Loss: 0.16932503879070282, Lr:0.0001\n",
      "Epoch 6, Step: 70, Loss: 0.13332752883434296, Lr:0.0001\n",
      "Epoch 6, Step: 71, Loss: 0.29293057322502136, Lr:0.0001\n",
      "Epoch 6, Step: 72, Loss: 0.14438112080097198, Lr:0.0001\n",
      "Epoch 6, Step: 73, Loss: 0.4048107862472534, Lr:0.0001\n",
      "Epoch 6, Step: 74, Loss: 0.6304357051849365, Lr:0.0001\n",
      "Epoch 6, Step: 75, Loss: 0.24583680927753448, Lr:0.0001\n",
      "Epoch 6, Step: 76, Loss: 0.16973090171813965, Lr:0.0001\n",
      "Epoch 6, Step: 77, Loss: 0.3175632059574127, Lr:0.0001\n",
      "Epoch 6, Step: 78, Loss: 0.24404916167259216, Lr:0.0001\n",
      "Epoch 6, Step: 79, Loss: 0.053232934325933456, Lr:0.0001\n",
      "Epoch 6, Step: 80, Loss: 0.5198958516120911, Lr:0.0001\n",
      "Epoch 6, Step: 81, Loss: 0.27115896344184875, Lr:0.0001\n",
      "Epoch 6, Step: 82, Loss: 0.3704875409603119, Lr:0.0001\n",
      "Epoch 6, Step: 83, Loss: 0.22976383566856384, Lr:0.0001\n",
      "Epoch 6, Step: 84, Loss: 0.054217249155044556, Lr:0.0001\n",
      "Epoch 6, Step: 85, Loss: 0.1486356109380722, Lr:0.0001\n",
      "Epoch 6, Step: 86, Loss: 0.10776226967573166, Lr:0.0001\n",
      "Epoch 6, Step: 87, Loss: 0.10813446342945099, Lr:0.0001\n",
      "Epoch 6, Step: 88, Loss: 0.5636023283004761, Lr:0.0001\n",
      "Epoch 6, Step: 89, Loss: 0.4509853422641754, Lr:0.0001\n",
      "Epoch 6, Step: 90, Loss: 0.03759336099028587, Lr:0.0001\n",
      "Epoch 6, Step: 91, Loss: 0.20828938484191895, Lr:0.0001\n",
      "Epoch 6, Step: 92, Loss: 0.16774702072143555, Lr:0.0001\n",
      "Epoch 6, Step: 93, Loss: 0.24401214718818665, Lr:0.0001\n",
      "Epoch 6, Step: 94, Loss: 0.1718338131904602, Lr:0.0001\n",
      "Epoch 6, Step: 95, Loss: 0.18150724470615387, Lr:0.0001\n",
      "Epoch 6, Step: 96, Loss: 0.17008444666862488, Lr:0.0001\n",
      "Epoch 6, Step: 97, Loss: 0.4758254289627075, Lr:0.0001\n",
      "Epoch 6, Step: 98, Loss: 0.7335598468780518, Lr:0.0001\n",
      "Epoch 6, Step: 99, Loss: 0.27258679270744324, Lr:0.0001\n",
      "Epoch 6, Step: 100, Loss: 0.18680965900421143, Lr:0.0001\n",
      "Epoch 6, Step: 101, Loss: 0.3085407316684723, Lr:0.0001\n",
      "Epoch 6, Step: 102, Loss: 0.10220536589622498, Lr:0.0001\n",
      "Epoch 6, Step: 103, Loss: 0.37251418828964233, Lr:0.0001\n",
      "Epoch 6, Step: 104, Loss: 0.29302990436553955, Lr:0.0001\n",
      "Epoch 6, Step: 105, Loss: 0.3176642656326294, Lr:0.0001\n",
      "Epoch 6, Step: 106, Loss: 0.2402808666229248, Lr:0.0001\n",
      "Epoch 6, Step: 107, Loss: 0.18594394624233246, Lr:0.0001\n",
      "Epoch 6, Step: 108, Loss: 0.112615667283535, Lr:0.0001\n",
      "Epoch 6, Step: 109, Loss: 0.10089072585105896, Lr:0.0001\n",
      "Epoch 6, Step: 110, Loss: 0.10725512355566025, Lr:0.0001\n",
      "Epoch 6, Step: 111, Loss: 0.6301059126853943, Lr:0.0001\n",
      "Epoch 6, Step: 112, Loss: 0.07992187887430191, Lr:0.0001\n",
      "Epoch 6, Step: 113, Loss: 0.1608894169330597, Lr:0.0001\n",
      "Epoch 6, Step: 114, Loss: 0.2515544295310974, Lr:0.0001\n",
      "Epoch 6, Step: 115, Loss: 0.2868584990501404, Lr:0.0001\n",
      "Epoch 6, Step: 116, Loss: 0.10515739768743515, Lr:0.0001\n",
      "Epoch 6, Step: 117, Loss: 0.2213841676712036, Lr:0.0001\n",
      "Epoch 6, Step: 118, Loss: 0.11785288900136948, Lr:0.0001\n",
      "Epoch 6, Step: 119, Loss: 0.1219920814037323, Lr:0.0001\n",
      "Epoch 6, Step: 120, Loss: 0.06973471492528915, Lr:0.0001\n",
      "Epoch 6, Step: 121, Loss: 0.05056716874241829, Lr:0.0001\n",
      "Epoch 6, Step: 122, Loss: 0.23244330286979675, Lr:0.0001\n",
      "Epoch 6, Step: 123, Loss: 0.1805506944656372, Lr:0.0001\n",
      "Epoch 6, Step: 124, Loss: 0.06607096642255783, Lr:0.0001\n",
      "Epoch 6, Step: 125, Loss: 0.04204215854406357, Lr:0.0001\n",
      "Epoch 6, Step: 126, Loss: 0.050102442502975464, Lr:0.0001\n",
      "Epoch 6, Step: 127, Loss: 0.12935036420822144, Lr:0.0001\n",
      "Epoch 6, Step: 128, Loss: 0.19680321216583252, Lr:0.0001\n",
      "Epoch 6, Step: 129, Loss: 0.13054530322551727, Lr:0.0001\n",
      "Epoch 6, Step: 130, Loss: 0.13931484520435333, Lr:0.0001\n",
      "Epoch 6, Step: 131, Loss: 0.1313856989145279, Lr:0.0001\n",
      "Epoch 6, Step: 132, Loss: 0.1946173459291458, Lr:0.0001\n",
      "Epoch 6, Step: 133, Loss: 0.28266340494155884, Lr:0.0001\n",
      "Epoch 6, Step: 134, Loss: 0.1313587725162506, Lr:0.0001\n",
      "Epoch 6, Step: 135, Loss: 0.20770062506198883, Lr:0.0001\n",
      "Epoch 6, Step: 136, Loss: 0.3704449534416199, Lr:0.0001\n",
      "Epoch 6, Step: 137, Loss: 0.015740439295768738, Lr:0.0001\n",
      "Epoch 6, Step: 138, Loss: 0.2730960547924042, Lr:0.0001\n",
      "Epoch 6, Step: 139, Loss: 0.22532296180725098, Lr:0.0001\n",
      "Epoch 6, Step: 140, Loss: 0.03457280993461609, Lr:0.0001\n",
      "Epoch 6, Step: 141, Loss: 0.154727965593338, Lr:0.0001\n",
      "Epoch 6, Step: 142, Loss: 0.03617963194847107, Lr:0.0001\n",
      "Epoch 6, Step: 143, Loss: 0.1973465532064438, Lr:0.0001\n",
      "Epoch 6, Step: 144, Loss: 0.1191323921084404, Lr:0.0001\n",
      "Epoch 6, Step: 145, Loss: 0.11081235855817795, Lr:0.0001\n",
      "Epoch 6, Step: 146, Loss: 0.12692886590957642, Lr:0.0001\n",
      "Epoch 6, Step: 147, Loss: 0.30106121301651, Lr:0.0001\n",
      "Epoch 6, Step: 148, Loss: 0.21080514788627625, Lr:0.0001\n",
      "Epoch 6, Step: 149, Loss: 0.15068882703781128, Lr:0.0001\n",
      "Epoch 6, Step: 150, Loss: 0.12286633998155594, Lr:0.0001\n",
      "Epoch 6, Step: 151, Loss: 0.09790671616792679, Lr:0.0001\n",
      "Epoch 6, Step: 152, Loss: 0.2231033742427826, Lr:0.0001\n",
      "Epoch 6, Step: 153, Loss: 0.3168589472770691, Lr:0.0001\n",
      "Epoch 6, Step: 154, Loss: 0.3082008957862854, Lr:0.0001\n",
      "Epoch 6, Step: 155, Loss: 0.20456042885780334, Lr:0.0001\n",
      "Epoch 6, Step: 156, Loss: 0.27430233359336853, Lr:0.0001\n",
      "Epoch 6, Step: 157, Loss: 0.10161617398262024, Lr:0.0001\n",
      "Epoch 6, Step: 158, Loss: 0.266105055809021, Lr:0.0001\n",
      "Epoch 6, Step: 159, Loss: 0.2510765790939331, Lr:0.0001\n",
      "Epoch 6, Step: 160, Loss: 0.01885971799492836, Lr:0.0001\n",
      "Epoch 6, Step: 161, Loss: 0.15250015258789062, Lr:0.0001\n",
      "Epoch 6, Step: 162, Loss: 0.3667881190776825, Lr:0.0001\n",
      "Epoch 6, Step: 163, Loss: 0.20197610557079315, Lr:0.0001\n",
      "Epoch 6, Step: 164, Loss: 0.07089503109455109, Lr:0.0001\n",
      "Epoch 6, Step: 165, Loss: 0.5563907623291016, Lr:0.0001\n",
      "Epoch 6, Step: 166, Loss: 0.3475969433784485, Lr:0.0001\n",
      "Epoch 6, Step: 167, Loss: 0.22745543718338013, Lr:0.0001\n",
      "Epoch 6, Step: 168, Loss: 0.2267339676618576, Lr:0.0001\n",
      "Epoch 6, Step: 169, Loss: 0.15224379301071167, Lr:0.0001\n",
      "Epoch 6, Step: 170, Loss: 0.05862823873758316, Lr:0.0001\n",
      "Epoch 6, Step: 171, Loss: 0.2083970606327057, Lr:0.0001\n",
      "Epoch 6, Step: 172, Loss: 0.054169051349163055, Lr:0.0001\n",
      "Epoch 6, Step: 173, Loss: 0.0885816216468811, Lr:0.0001\n",
      "Epoch 6, Step: 174, Loss: 0.16662198305130005, Lr:0.0001\n",
      "Epoch 6, Step: 175, Loss: 0.13095732033252716, Lr:0.0001\n",
      "Epoch 6, Step: 176, Loss: 0.10611606389284134, Lr:0.0001\n",
      "Epoch 6, Step: 177, Loss: 0.12001794576644897, Lr:0.0001\n",
      "Epoch 6, Step: 178, Loss: 0.26351508498191833, Lr:0.0001\n",
      "Epoch 6, Step: 179, Loss: 0.21182136237621307, Lr:0.0001\n",
      "Epoch 6, Step: 180, Loss: 0.40109217166900635, Lr:0.0001\n",
      "Epoch 6, Step: 181, Loss: 0.3142564296722412, Lr:0.0001\n",
      "Epoch 6, Step: 182, Loss: 0.1037362813949585, Lr:0.0001\n",
      "Epoch 6, Step: 183, Loss: 0.2663598358631134, Lr:0.0001\n",
      "Epoch 6, Step: 184, Loss: 0.17304590344429016, Lr:0.0001\n",
      "Epoch 6, Step: 185, Loss: 0.03977809101343155, Lr:0.0001\n",
      "Epoch 6, Step: 186, Loss: 0.4329257607460022, Lr:0.0001\n",
      "Epoch 6, Step: 187, Loss: 0.2745314836502075, Lr:0.0001\n",
      "Epoch 6, Step: 188, Loss: 0.06625571846961975, Lr:0.0001\n",
      "Epoch 6, Step: 189, Loss: 0.1343512088060379, Lr:0.0001\n",
      "Epoch 6, Step: 190, Loss: 0.1184130385518074, Lr:0.0001\n",
      "Epoch 6, Step: 191, Loss: 0.029967810958623886, Lr:0.0001\n",
      "Epoch 6, Step: 192, Loss: 0.11596357822418213, Lr:0.0001\n",
      "Epoch 6, Step: 193, Loss: 0.3334021270275116, Lr:0.0001\n",
      "Epoch 6, Step: 194, Loss: 0.2325325459241867, Lr:0.0001\n",
      "Epoch 6, Step: 195, Loss: 0.6692931652069092, Lr:0.0001\n",
      "Epoch 6, Step: 196, Loss: 0.04101606458425522, Lr:0.0001\n",
      "Epoch 6, Step: 197, Loss: 0.22467577457427979, Lr:0.0001\n",
      "Epoch 6, Step: 198, Loss: 0.192406564950943, Lr:0.0001\n",
      "Epoch 6, Step: 199, Loss: 0.25766241550445557, Lr:0.0001\n",
      "Epoch 6, Step: 200, Loss: 0.5182806849479675, Lr:0.0001\n",
      "Epoch 6, Step: 201, Loss: 0.36683470010757446, Lr:0.0001\n",
      "Epoch 6, Step: 202, Loss: 0.10840313881635666, Lr:0.0001\n",
      "Epoch 6, Step: 203, Loss: 0.1168445348739624, Lr:0.0001\n",
      "Epoch 6, Step: 204, Loss: 0.14647310972213745, Lr:0.0001\n",
      "Epoch 6, Step: 205, Loss: 0.16604295372962952, Lr:0.0001\n",
      "Epoch 6, Step: 206, Loss: 0.092996746301651, Lr:0.0001\n",
      "Epoch 6, Step: 207, Loss: 0.16188524663448334, Lr:0.0001\n",
      "Epoch 6, Step: 208, Loss: 0.17969147861003876, Lr:0.0001\n",
      "Epoch 6, Step: 209, Loss: 0.06663520634174347, Lr:0.0001\n",
      "Epoch 6, Step: 210, Loss: 0.2174764722585678, Lr:0.0001\n",
      "Epoch 6, Step: 211, Loss: 0.1086883619427681, Lr:0.0001\n",
      "Epoch 6, Step: 212, Loss: 0.0937747210264206, Lr:0.0001\n",
      "Epoch 6, Step: 213, Loss: 0.06136103719472885, Lr:0.0001\n",
      "Epoch 6, Step: 214, Loss: 0.14979664981365204, Lr:0.0001\n",
      "Epoch 6, Step: 215, Loss: 0.14788106083869934, Lr:0.0001\n",
      "Epoch 6, Step: 216, Loss: 0.1841093897819519, Lr:0.0001\n",
      "Epoch 6, Step: 217, Loss: 0.36923760175704956, Lr:0.0001\n",
      "Epoch 6, Step: 218, Loss: 0.2501280903816223, Lr:0.0001\n",
      "Epoch 6, Step: 219, Loss: 0.14015300571918488, Lr:0.0001\n",
      "Epoch 6, Step: 220, Loss: 0.3298826813697815, Lr:0.0001\n",
      "Epoch 6, Step: 221, Loss: 0.1862059235572815, Lr:0.0001\n",
      "Epoch 6, Step: 222, Loss: 0.5414214134216309, Lr:0.0001\n",
      "Epoch 6, Step: 223, Loss: 0.0715353786945343, Lr:0.0001\n",
      "Epoch 6, Step: 224, Loss: 0.12394142150878906, Lr:0.0001\n",
      "Epoch 6, Step: 225, Loss: 0.14668531715869904, Lr:0.0001\n",
      "Epoch 6, Step: 226, Loss: 0.020390307530760765, Lr:0.0001\n",
      "Epoch 6, Step: 227, Loss: 0.13548888266086578, Lr:0.0001\n",
      "Epoch 6, Step: 228, Loss: 0.20769450068473816, Lr:0.0001\n",
      "Epoch 6, Step: 229, Loss: 0.11697086691856384, Lr:0.0001\n",
      "Epoch 6, Step: 230, Loss: 0.10671491175889969, Lr:0.0001\n",
      "Epoch 6, Step: 231, Loss: 0.18537700176239014, Lr:0.0001\n",
      "Epoch 6, Step: 232, Loss: 0.10144039243459702, Lr:0.0001\n",
      "Epoch 6, Step: 233, Loss: 0.12474869936704636, Lr:0.0001\n",
      "Epoch 6, Step: 234, Loss: 0.0610072985291481, Lr:0.0001\n",
      "Epoch 6, Step: 235, Loss: 0.1802305430173874, Lr:0.0001\n",
      "Epoch 6, Step: 236, Loss: 0.37115350365638733, Lr:0.0001\n",
      "Epoch 6, Step: 237, Loss: 0.10896569490432739, Lr:0.0001\n",
      "Epoch 6, Step: 238, Loss: 0.17210718989372253, Lr:0.0001\n",
      "Epoch 6, Step: 239, Loss: 0.18662776052951813, Lr:0.0001\n",
      "Epoch 6, Step: 240, Loss: 0.15958115458488464, Lr:0.0001\n",
      "Epoch 6, Step: 241, Loss: 0.0789685919880867, Lr:0.0001\n",
      "Epoch 6, Step: 242, Loss: 0.3637312352657318, Lr:0.0001\n",
      "Epoch 6, Step: 243, Loss: 0.09814430773258209, Lr:0.0001\n",
      "Epoch 6, Step: 244, Loss: 0.03890092298388481, Lr:0.0001\n",
      "Epoch 6, Step: 245, Loss: 0.10298334062099457, Lr:0.0001\n",
      "Epoch 6, Step: 246, Loss: 0.1096208319067955, Lr:0.0001\n",
      "Epoch 6, Step: 247, Loss: 0.13209141790866852, Lr:0.0001\n",
      "Epoch 6, Step: 248, Loss: 0.03378020226955414, Lr:0.0001\n",
      "Epoch 6, Step: 249, Loss: 0.14448146522045135, Lr:0.0001\n",
      "Epoch 6, Step: 250, Loss: 0.08020403236150742, Lr:0.0001\n",
      "Epoch 6, Step: 251, Loss: 0.2236437201499939, Lr:0.0001\n",
      "Epoch 6, Step: 252, Loss: 0.4803491532802582, Lr:0.0001\n",
      "Epoch 6, Step: 253, Loss: 0.1430521160364151, Lr:0.0001\n",
      "Epoch 6, Step: 254, Loss: 0.16321521997451782, Lr:0.0001\n",
      "Epoch 6, Step: 255, Loss: 0.2129678875207901, Lr:0.0001\n",
      "Epoch 6, Step: 256, Loss: 0.5929107069969177, Lr:0.0001\n",
      "Epoch 6, Step: 257, Loss: 0.21640728414058685, Lr:0.0001\n",
      "Epoch 6, Step: 258, Loss: 0.12183377146720886, Lr:0.0001\n",
      "Epoch 6, Step: 259, Loss: 0.41236376762390137, Lr:0.0001\n",
      "Epoch 6, Step: 260, Loss: 0.22810599207878113, Lr:0.0001\n",
      "Epoch 6, Step: 261, Loss: 0.1123536080121994, Lr:0.0001\n",
      "Epoch 6, Step: 262, Loss: 0.06468171626329422, Lr:0.0001\n",
      "Epoch 6, Step: 263, Loss: 0.14692682027816772, Lr:0.0001\n",
      "Epoch 6, Step: 264, Loss: 0.15022805333137512, Lr:0.0001\n",
      "Epoch 6, Step: 265, Loss: 0.3023373484611511, Lr:0.0001\n",
      "Epoch 6, Step: 266, Loss: 0.06907953321933746, Lr:0.0001\n",
      "Epoch 6, Step: 267, Loss: 0.1923697292804718, Lr:0.0001\n",
      "Epoch 6, Step: 268, Loss: 0.10306507349014282, Lr:0.0001\n",
      "Epoch 6, Step: 269, Loss: 0.05529613792896271, Lr:0.0001\n",
      "Epoch 6, Step: 270, Loss: 0.32885393500328064, Lr:0.0001\n",
      "Epoch 6, Step: 271, Loss: 0.2485821396112442, Lr:0.0001\n",
      "Epoch 6, Step: 272, Loss: 0.20055852830410004, Lr:0.0001\n",
      "Epoch 6, Step: 273, Loss: 0.029393482953310013, Lr:0.0001\n",
      "Epoch 6, Step: 274, Loss: 0.19474461674690247, Lr:0.0001\n",
      "Epoch 6, Step: 275, Loss: 0.6981760263442993, Lr:0.0001\n",
      "Epoch 6, Step: 276, Loss: 0.25926727056503296, Lr:0.0001\n",
      "Epoch 6, Step: 277, Loss: 0.15678350627422333, Lr:0.0001\n",
      "Epoch 6, Step: 278, Loss: 0.5065352916717529, Lr:0.0001\n",
      "Epoch 6, Step: 279, Loss: 0.12711553275585175, Lr:0.0001\n",
      "Epoch 6, Step: 280, Loss: 0.18464353680610657, Lr:0.0001\n",
      "Epoch 6, Step: 281, Loss: 0.17697729170322418, Lr:0.0001\n",
      "Epoch 6, Step: 282, Loss: 0.2834596037864685, Lr:0.0001\n",
      "Epoch 6, Step: 283, Loss: 0.1334458738565445, Lr:0.0001\n",
      "Epoch 6, Step: 284, Loss: 0.21889886260032654, Lr:0.0001\n",
      "Epoch 6, Step: 285, Loss: 0.23159478604793549, Lr:0.0001\n",
      "Epoch 6, Step: 286, Loss: 1.1355003118515015, Lr:0.0001\n",
      "Epoch 6, Step: 287, Loss: 0.16638076305389404, Lr:0.0001\n",
      "Epoch 6, Step: 288, Loss: 0.18472284078598022, Lr:0.0001\n",
      "Epoch 6, Step: 289, Loss: 0.1636461764574051, Lr:0.0001\n",
      "Epoch 6, Step: 290, Loss: 0.2145586907863617, Lr:0.0001\n",
      "Epoch 6, Step: 291, Loss: 0.05838468670845032, Lr:0.0001\n",
      "Epoch 6, Step: 292, Loss: 0.10903623700141907, Lr:0.0001\n",
      "Epoch 6, Step: 293, Loss: 0.23311056196689606, Lr:0.0001\n",
      "Epoch 6, Step: 294, Loss: 0.2315404862165451, Lr:0.0001\n",
      "Epoch 6, Step: 295, Loss: 0.1364980936050415, Lr:0.0001\n",
      "Epoch 6, Step: 296, Loss: 0.08596496284008026, Lr:0.0001\n",
      "Epoch 6, Step: 297, Loss: 0.18369463086128235, Lr:0.0001\n",
      "Epoch 6, Step: 298, Loss: 0.14645765721797943, Lr:0.0001\n",
      "Epoch 6, Step: 299, Loss: 0.12699049711227417, Lr:0.0001\n",
      "Epoch 6, Step: 300, Loss: 0.3192998766899109, Lr:0.0001\n",
      "Epoch 6, Step: 301, Loss: 0.22930239140987396, Lr:0.0001\n",
      "Epoch 6, Step: 302, Loss: 0.42026442289352417, Lr:0.0001\n",
      "Epoch 6, Step: 303, Loss: 0.13546930253505707, Lr:0.0001\n",
      "Epoch 6, Step: 304, Loss: 0.207162544131279, Lr:0.0001\n",
      "Epoch 6, Step: 305, Loss: 0.02234402485191822, Lr:0.0001\n",
      "Epoch 6, Step: 306, Loss: 0.07848634570837021, Lr:0.0001\n",
      "Epoch 6, Step: 307, Loss: 0.3067481815814972, Lr:0.0001\n",
      "Epoch 6, Step: 308, Loss: 0.1835973858833313, Lr:0.0001\n",
      "Epoch 6, Step: 309, Loss: 0.3488596975803375, Lr:0.0001\n",
      "Epoch 6, Step: 310, Loss: 0.2230949103832245, Lr:0.0001\n",
      "Epoch 6, Step: 311, Loss: 0.26021862030029297, Lr:0.0001\n",
      "Epoch 6, Step: 312, Loss: 0.22878633439540863, Lr:0.0001\n",
      "Epoch 6, Step: 313, Loss: 0.19802358746528625, Lr:0.0001\n",
      "Epoch 6, Step: 314, Loss: 0.3774217665195465, Lr:0.0001\n",
      "Epoch 6, Step: 315, Loss: 0.06989015638828278, Lr:0.0001\n",
      "Epoch 6, Step: 316, Loss: 0.2423429787158966, Lr:0.0001\n",
      "Epoch 6, Step: 317, Loss: 0.3362163305282593, Lr:0.0001\n",
      "Epoch 6, Step: 318, Loss: 0.028558161109685898, Lr:0.0001\n",
      "Epoch 6, Step: 319, Loss: 0.30322614312171936, Lr:0.0001\n",
      "Epoch 6, Step: 320, Loss: 0.1285589039325714, Lr:0.0001\n",
      "Epoch 6, Step: 321, Loss: 0.5628455281257629, Lr:0.0001\n",
      "Epoch 6, Step: 322, Loss: 0.1008845716714859, Lr:0.0001\n",
      "Epoch 6, Step: 323, Loss: 0.08224935829639435, Lr:0.0001\n",
      "Epoch 6, Step: 324, Loss: 0.09117154031991959, Lr:0.0001\n",
      "Epoch 6, Step: 325, Loss: 0.1421721875667572, Lr:0.0001\n",
      "Epoch 6, Step: 326, Loss: 0.1172143816947937, Lr:0.0001\n",
      "Epoch 6, Step: 327, Loss: 0.25401541590690613, Lr:0.0001\n",
      "Epoch 6, Step: 328, Loss: 0.5550198554992676, Lr:0.0001\n",
      "Epoch 6, Step: 329, Loss: 0.18037213385105133, Lr:0.0001\n",
      "Epoch 6, Step: 330, Loss: 0.1742953360080719, Lr:0.0001\n",
      "Epoch 6, Step: 331, Loss: 0.06465868651866913, Lr:0.0001\n",
      "Epoch 6, Step: 332, Loss: 0.14290398359298706, Lr:0.0001\n",
      "Epoch 6, Step: 333, Loss: 0.309065043926239, Lr:0.0001\n",
      "Epoch 6, Step: 334, Loss: 0.2700183093547821, Lr:0.0001\n",
      "Epoch 6, Step: 335, Loss: 0.11006935685873032, Lr:0.0001\n",
      "Epoch 6, Step: 336, Loss: 0.1933397501707077, Lr:0.0001\n",
      "Epoch 6, Step: 337, Loss: 0.3145051896572113, Lr:0.0001\n",
      "Epoch 6, Step: 338, Loss: 0.3023032546043396, Lr:0.0001\n",
      "Epoch 6, Step: 339, Loss: 0.5132514834403992, Lr:0.0001\n",
      "Epoch 6, Step: 340, Loss: 0.05111364647746086, Lr:0.0001\n",
      "Epoch 6, Step: 341, Loss: 0.42961007356643677, Lr:0.0001\n",
      "Epoch 6, Step: 342, Loss: 0.048268869519233704, Lr:0.0001\n",
      "Epoch 6, Step: 343, Loss: 0.2359054535627365, Lr:0.0001\n",
      "Epoch 6, Step: 344, Loss: 0.32814687490463257, Lr:0.0001\n",
      "Epoch 6, Step: 345, Loss: 0.1551917940378189, Lr:0.0001\n",
      "Epoch 6, Step: 346, Loss: 0.16071733832359314, Lr:0.0001\n",
      "Epoch 6, Step: 347, Loss: 0.09945102035999298, Lr:0.0001\n",
      "Epoch 6, Step: 348, Loss: 0.19351965188980103, Lr:0.0001\n",
      "Epoch 6, Step: 349, Loss: 0.30536529421806335, Lr:0.0001\n",
      "Epoch 6, Step: 350, Loss: 0.40354806184768677, Lr:0.0001\n",
      "Epoch 6, Step: 351, Loss: 0.1976555436849594, Lr:0.0001\n",
      "Epoch 6, Step: 352, Loss: 0.058833882212638855, Lr:0.0001\n",
      "Epoch 6, Step: 353, Loss: 0.05997176840901375, Lr:0.0001\n",
      "Epoch 6, Step: 354, Loss: 0.13877186179161072, Lr:0.0001\n",
      "Epoch 6, Step: 355, Loss: 0.1160188615322113, Lr:0.0001\n",
      "Epoch 6, Step: 356, Loss: 0.2931217551231384, Lr:0.0001\n",
      "Epoch 6, Step: 357, Loss: 0.2285607010126114, Lr:0.0001\n",
      "Epoch 6, Step: 358, Loss: 0.46013370156288147, Lr:0.0001\n",
      "Epoch 6, Step: 359, Loss: 0.24786625802516937, Lr:0.0001\n",
      "Epoch 6, Step: 360, Loss: 0.15665888786315918, Lr:0.0001\n",
      "Epoch 6, Step: 361, Loss: 0.15872780978679657, Lr:0.0001\n",
      "Epoch 6, Step: 362, Loss: 0.12396404147148132, Lr:0.0001\n",
      "Epoch 6, Step: 363, Loss: 0.10003867745399475, Lr:0.0001\n",
      "Epoch 6, Step: 364, Loss: 0.09637852013111115, Lr:0.0001\n",
      "Epoch 6, Step: 365, Loss: 0.10172140598297119, Lr:0.0001\n",
      "Epoch 6, Step: 366, Loss: 0.2592707574367523, Lr:0.0001\n",
      "Epoch 6, Step: 367, Loss: 0.1256219893693924, Lr:0.0001\n",
      "Epoch 6, Step: 368, Loss: 0.3249441385269165, Lr:0.0001\n",
      "Epoch 6, Step: 369, Loss: 0.041346047073602676, Lr:0.0001\n",
      "Epoch 6, Step: 370, Loss: 0.19898375868797302, Lr:0.0001\n",
      "Epoch 6, Step: 371, Loss: 0.33390024304389954, Lr:0.0001\n",
      "Epoch 6, Step: 372, Loss: 0.030503718182444572, Lr:0.0001\n",
      "Epoch 6, Step: 373, Loss: 0.2197660505771637, Lr:0.0001\n",
      "Epoch 6, Step: 374, Loss: 0.3245925307273865, Lr:0.0001\n",
      "Epoch 6, Step: 375, Loss: 0.18633678555488586, Lr:0.0001\n",
      "Epoch 6, Step: 376, Loss: 0.37580400705337524, Lr:0.0001\n",
      "Epoch 6, Step: 377, Loss: 0.03884444385766983, Lr:0.0001\n",
      "Epoch 6, Step: 378, Loss: 0.022737039253115654, Lr:0.0001\n",
      "Epoch 6, Step: 379, Loss: 0.41403764486312866, Lr:0.0001\n",
      "Epoch 6, Step: 380, Loss: 0.213626429438591, Lr:0.0001\n",
      "Epoch 6, Step: 381, Loss: 0.09490679949522018, Lr:0.0001\n",
      "Epoch 6, Step: 382, Loss: 0.44340670108795166, Lr:0.0001\n",
      "Epoch 6, Step: 383, Loss: 0.6575430035591125, Lr:0.0001\n",
      "Epoch 6, Step: 384, Loss: 0.6493932604789734, Lr:0.0001\n",
      "Epoch 6, Step: 385, Loss: 0.06738382577896118, Lr:0.0001\n",
      "Epoch 6, Step: 386, Loss: 0.09058204293251038, Lr:0.0001\n",
      "Epoch 6, Step: 387, Loss: 0.2673281133174896, Lr:0.0001\n",
      "Epoch 6, Step: 388, Loss: 0.14899283647537231, Lr:0.0001\n",
      "Epoch 6, Step: 389, Loss: 0.5874585509300232, Lr:0.0001\n",
      "Epoch 6, Step: 390, Loss: 0.21996299922466278, Lr:0.0001\n",
      "Epoch 6, Step: 391, Loss: 0.12064970284700394, Lr:0.0001\n",
      "Epoch 6, Step: 392, Loss: 0.18456949293613434, Lr:0.0001\n",
      "Epoch 6, Step: 393, Loss: 0.09409883618354797, Lr:0.0001\n",
      "Epoch 6, Step: 394, Loss: 0.1051308885216713, Lr:0.0001\n",
      "Epoch 6, Step: 395, Loss: 0.11613303422927856, Lr:0.0001\n",
      "Epoch 6, Step: 396, Loss: 0.03694615885615349, Lr:0.0001\n",
      "Epoch 6, Step: 397, Loss: 0.219828262925148, Lr:0.0001\n",
      "Epoch 6, Step: 398, Loss: 0.20980240404605865, Lr:0.0001\n",
      "Epoch 6, Step: 399, Loss: 0.15130320191383362, Lr:0.0001\n",
      "Epoch 6, Step: 400, Loss: 0.26512858271598816, Lr:0.0001\n",
      "Epoch 6, Step: 401, Loss: 0.2440185546875, Lr:0.0001\n",
      "Epoch 6, Step: 402, Loss: 0.6539440751075745, Lr:0.0001\n",
      "Epoch 6, Step: 403, Loss: 0.36762192845344543, Lr:0.0001\n",
      "Epoch 6, Step: 404, Loss: 0.17386895418167114, Lr:0.0001\n",
      "Epoch 6, Step: 405, Loss: 0.1841745674610138, Lr:0.0001\n",
      "Epoch 6, Step: 406, Loss: 0.025117089971899986, Lr:0.0001\n",
      "Epoch 6, Step: 407, Loss: 0.33735331892967224, Lr:0.0001\n",
      "Epoch 6, Step: 408, Loss: 0.06010771915316582, Lr:0.0001\n",
      "Epoch 6, Step: 409, Loss: 0.10896945744752884, Lr:0.0001\n",
      "Epoch 6, Step: 410, Loss: 0.3006301820278168, Lr:0.0001\n",
      "Epoch 6, Step: 411, Loss: 0.24872316420078278, Lr:0.0001\n",
      "Epoch 6, Step: 412, Loss: 0.16024886071681976, Lr:0.0001\n",
      "Epoch 6, Step: 413, Loss: 0.11000656336545944, Lr:0.0001\n",
      "Epoch 6, Step: 414, Loss: 0.23518386483192444, Lr:0.0001\n",
      "Epoch 6, Step: 415, Loss: 0.03704691678285599, Lr:0.0001\n",
      "Epoch 6, Step: 416, Loss: 0.22637507319450378, Lr:0.0001\n",
      "Epoch 6, Step: 417, Loss: 0.5452800989151001, Lr:0.0001\n",
      "Epoch 6, Step: 418, Loss: 0.09594472497701645, Lr:0.0001\n",
      "Epoch 6, Step: 419, Loss: 0.4174872934818268, Lr:0.0001\n",
      "Epoch 6, Step: 420, Loss: 0.2855493426322937, Lr:0.0001\n",
      "Epoch 6, Step: 421, Loss: 0.17146694660186768, Lr:0.0001\n",
      "Epoch 6, Step: 422, Loss: 0.05166131258010864, Lr:0.0001\n",
      "Epoch 6, Step: 423, Loss: 0.05280940234661102, Lr:0.0001\n",
      "Epoch 6, Step: 424, Loss: 0.29336434602737427, Lr:0.0001\n",
      "Epoch 6, Step: 425, Loss: 0.037942204624414444, Lr:0.0001\n",
      "Epoch 6, Step: 426, Loss: 0.19933487474918365, Lr:0.0001\n",
      "Epoch 6, Step: 427, Loss: 0.3237414062023163, Lr:0.0001\n",
      "Epoch 6, Step: 428, Loss: 0.14458876848220825, Lr:0.0001\n",
      "Epoch 6, Step: 429, Loss: 0.12037397921085358, Lr:0.0001\n",
      "Epoch 6, Step: 430, Loss: 0.47458016872406006, Lr:0.0001\n",
      "Epoch 6, Step: 431, Loss: 0.37157291173934937, Lr:0.0001\n",
      "Epoch 6, Step: 432, Loss: 0.31371986865997314, Lr:0.0001\n",
      "Epoch 6, Step: 433, Loss: 0.3817192614078522, Lr:0.0001\n",
      "Epoch 6, Step: 434, Loss: 0.1052408218383789, Lr:0.0001\n",
      "Epoch 6, Step: 435, Loss: 0.20081660151481628, Lr:0.0001\n",
      "Epoch 6, Step: 436, Loss: 0.36419153213500977, Lr:0.0001\n",
      "Epoch 6, Step: 437, Loss: 0.35122576355934143, Lr:0.0001\n",
      "Epoch 6, Step: 438, Loss: 0.1725936084985733, Lr:0.0001\n",
      "Epoch 6, Step: 439, Loss: 0.22457003593444824, Lr:0.0001\n",
      "Epoch 6, Step: 440, Loss: 0.22804564237594604, Lr:0.0001\n",
      "Epoch 6, Step: 441, Loss: 0.14955592155456543, Lr:0.0001\n",
      "Epoch 6, Step: 442, Loss: 0.17674019932746887, Lr:0.0001\n",
      "Epoch 6, Step: 443, Loss: 0.2502555251121521, Lr:0.0001\n",
      "Epoch 6, Step: 444, Loss: 0.11460769921541214, Lr:0.0001\n",
      "Epoch 6, Step: 445, Loss: 0.10736466944217682, Lr:0.0001\n",
      "Epoch 6, Step: 446, Loss: 0.04253385215997696, Lr:0.0001\n",
      "Epoch 6, Step: 447, Loss: 0.036237262189388275, Lr:0.0001\n",
      "Epoch 6, Step: 448, Loss: 0.15050317347049713, Lr:0.0001\n",
      "Epoch 6, Step: 449, Loss: 0.23830461502075195, Lr:0.0001\n",
      "Epoch 6, Step: 450, Loss: 0.23699450492858887, Lr:0.0001\n",
      "Epoch 6, Step: 451, Loss: 0.11440254747867584, Lr:0.0001\n",
      "Epoch 6, Step: 452, Loss: 0.06884678453207016, Lr:0.0001\n",
      "Epoch 6, Step: 453, Loss: 0.12058980762958527, Lr:0.0001\n",
      "Epoch 6, Step: 454, Loss: 0.17915494740009308, Lr:0.0001\n",
      "Epoch 6, Step: 455, Loss: 0.06381188333034515, Lr:0.0001\n",
      "Epoch 6, Step: 456, Loss: 0.284334659576416, Lr:0.0001\n",
      "Epoch 6, Step: 457, Loss: 0.1622190773487091, Lr:0.0001\n",
      "Epoch 6, Step: 458, Loss: 0.09013556689023972, Lr:0.0001\n",
      "Epoch 6, Step: 459, Loss: 0.11059628427028656, Lr:0.0001\n",
      "Epoch 6, Step: 460, Loss: 0.19310300052165985, Lr:0.0001\n",
      "Epoch 6, Step: 461, Loss: 0.3180958330631256, Lr:0.0001\n",
      "Epoch 6, Step: 462, Loss: 0.22035929560661316, Lr:0.0001\n",
      "Epoch 6, Step: 463, Loss: 0.1738404929637909, Lr:0.0001\n",
      "Epoch 6, Step: 464, Loss: 0.14547783136367798, Lr:0.0001\n",
      "Epoch 6, Step: 465, Loss: 0.4332420229911804, Lr:0.0001\n",
      "Epoch 6, Step: 466, Loss: 0.11367472261190414, Lr:0.0001\n",
      "Epoch 6, Step: 467, Loss: 0.10451673716306686, Lr:0.0001\n",
      "Epoch 6, Step: 468, Loss: 0.12855617702007294, Lr:0.0001\n",
      "Epoch 6, Step: 469, Loss: 0.1367008090019226, Lr:0.0001\n",
      "Epoch 6, Step: 470, Loss: 0.08550648391246796, Lr:0.0001\n",
      "Epoch 6, Step: 471, Loss: 0.17548392713069916, Lr:0.0001\n",
      "Epoch 6, Step: 472, Loss: 0.22703303396701813, Lr:0.0001\n",
      "Epoch 6, Step: 473, Loss: 0.16085627675056458, Lr:0.0001\n",
      "Epoch 6, Step: 474, Loss: 0.312862753868103, Lr:0.0001\n",
      "Epoch 6, Step: 475, Loss: 0.2162281572818756, Lr:0.0001\n",
      "Epoch 6, Step: 476, Loss: 0.6227405667304993, Lr:0.0001\n",
      "Epoch 6, Step: 477, Loss: 0.23187147080898285, Lr:0.0001\n",
      "Epoch 6, Step: 478, Loss: 0.08751481026411057, Lr:0.0001\n",
      "Epoch 6, Step: 479, Loss: 0.3958165943622589, Lr:0.0001\n",
      "Epoch 6, Step: 480, Loss: 0.2753148674964905, Lr:0.0001\n",
      "Epoch 6, Step: 481, Loss: 0.26648327708244324, Lr:0.0001\n",
      "Epoch 6, Step: 482, Loss: 0.12469711154699326, Lr:0.0001\n",
      "Epoch 6, Step: 483, Loss: 0.12197286635637283, Lr:0.0001\n",
      "Epoch 6, Step: 484, Loss: 0.2940383851528168, Lr:0.0001\n",
      "Epoch 6, Step: 485, Loss: 0.18938587605953217, Lr:0.0001\n",
      "Epoch 6, Step: 486, Loss: 0.08319386839866638, Lr:0.0001\n",
      "Epoch 6, Step: 487, Loss: 0.4630643427371979, Lr:0.0001\n",
      "Epoch 6, Step: 488, Loss: 0.1736212521791458, Lr:0.0001\n",
      "Epoch 6, Step: 489, Loss: 0.20613214373588562, Lr:0.0001\n",
      "Epoch 6, Step: 490, Loss: 0.12731701135635376, Lr:0.0001\n",
      "Epoch 6, Step: 491, Loss: 0.08370436728000641, Lr:0.0001\n",
      "Epoch 6, Step: 492, Loss: 0.24083493649959564, Lr:0.0001\n",
      "Epoch 6, Step: 493, Loss: 0.10197442770004272, Lr:0.0001\n",
      "Epoch 6, Step: 494, Loss: 0.17775826156139374, Lr:0.0001\n",
      "Epoch 6, Step: 495, Loss: 0.1839958131313324, Lr:0.0001\n",
      "Epoch 6, Step: 496, Loss: 0.27005529403686523, Lr:0.0001\n",
      "Epoch 6, Step: 497, Loss: 0.17129822075366974, Lr:0.0001\n",
      "Epoch 6, Step: 498, Loss: 0.24118535220623016, Lr:0.0001\n",
      "Epoch 6, Step: 499, Loss: 0.1510842740535736, Lr:0.0001\n",
      "Epoch 6, Step: 500, Loss: 1.164370059967041, Lr:0.0001\n",
      "Epoch 6, Step: 501, Loss: 0.32239246368408203, Lr:0.0001\n",
      "Epoch 6, Step: 502, Loss: 0.11535415053367615, Lr:0.0001\n",
      "Epoch 6, Step: 503, Loss: 0.08201311528682709, Lr:0.0001\n",
      "Epoch 6, Step: 504, Loss: 0.08948980271816254, Lr:0.0001\n",
      "Epoch 6, Step: 505, Loss: 0.037928506731987, Lr:0.0001\n",
      "Epoch 6, Step: 506, Loss: 0.1789238452911377, Lr:0.0001\n",
      "Epoch 6, Step: 507, Loss: 0.3043665885925293, Lr:0.0001\n",
      "Epoch 6, Step: 508, Loss: 0.541475772857666, Lr:0.0001\n",
      "Epoch 6, Step: 509, Loss: 0.10943718254566193, Lr:0.0001\n",
      "Epoch 6, Step: 510, Loss: 0.19366183876991272, Lr:0.0001\n",
      "Epoch 6, Step: 511, Loss: 0.13232585787773132, Lr:0.0001\n",
      "Epoch 6, Step: 512, Loss: 0.09166490286588669, Lr:0.0001\n",
      "Epoch 6, Step: 513, Loss: 0.042757101356983185, Lr:0.0001\n",
      "Epoch 6, Step: 514, Loss: 0.03351743519306183, Lr:0.0001\n",
      "Epoch 6, Step: 515, Loss: 0.025502149015665054, Lr:0.0001\n",
      "Epoch 6, Step: 516, Loss: 0.336906760931015, Lr:0.0001\n",
      "Epoch 6, Step: 517, Loss: 0.1021198034286499, Lr:0.0001\n",
      "Epoch 6, Step: 518, Loss: 0.11276235431432724, Lr:0.0001\n",
      "Epoch 6, Step: 519, Loss: 0.24692821502685547, Lr:0.0001\n",
      "Epoch 6, Step: 520, Loss: 0.25807276368141174, Lr:0.0001\n",
      "Epoch 6, Step: 521, Loss: 0.6375559568405151, Lr:0.0001\n",
      "Epoch 6, Step: 522, Loss: 0.09766334295272827, Lr:0.0001\n",
      "Epoch 6, Step: 523, Loss: 0.7237444519996643, Lr:0.0001\n",
      "Epoch 6, Step: 524, Loss: 0.011458158493041992, Lr:0.0001\n",
      "Epoch 6, Step: 525, Loss: 0.09311211854219437, Lr:0.0001\n",
      "Epoch 6, Step: 526, Loss: 0.1525951474905014, Lr:0.0001\n",
      "Epoch 6, Step: 527, Loss: 0.09454859048128128, Lr:0.0001\n",
      "Epoch 6, Step: 528, Loss: 0.5622895956039429, Lr:0.0001\n",
      "Epoch 6, Step: 529, Loss: 0.27540814876556396, Lr:0.0001\n",
      "Epoch 6, Step: 530, Loss: 0.448762446641922, Lr:0.0001\n",
      "Epoch 6, Step: 531, Loss: 0.08508690446615219, Lr:0.0001\n",
      "Epoch 6, Step: 532, Loss: 0.2625078856945038, Lr:0.0001\n",
      "Epoch 6, Step: 533, Loss: 0.04321128875017166, Lr:0.0001\n",
      "Epoch 6, Step: 534, Loss: 0.3438532054424286, Lr:0.0001\n",
      "Epoch 6, Step: 535, Loss: 0.15657788515090942, Lr:0.0001\n",
      "Epoch 6, Step: 536, Loss: 0.2047114074230194, Lr:0.0001\n",
      "Epoch 6, Step: 537, Loss: 0.0423094779253006, Lr:0.0001\n",
      "Epoch 6, Step: 538, Loss: 0.481148362159729, Lr:0.0001\n",
      "Epoch 6, Step: 539, Loss: 0.30966025590896606, Lr:0.0001\n",
      "Epoch 6, Step: 540, Loss: 0.09066568315029144, Lr:0.0001\n",
      "Epoch 6, Step: 541, Loss: 0.1193932592868805, Lr:0.0001\n",
      "Epoch 6, Step: 542, Loss: 0.6350793242454529, Lr:0.0001\n",
      "Epoch 6, Step: 543, Loss: 0.1260077953338623, Lr:0.0001\n",
      "Epoch 6, Step: 544, Loss: 0.3025984466075897, Lr:0.0001\n",
      "Epoch 6, Step: 545, Loss: 0.30084487795829773, Lr:0.0001\n",
      "Epoch 6, Step: 546, Loss: 0.42181143164634705, Lr:0.0001\n",
      "Epoch 6, Step: 547, Loss: 0.2719007134437561, Lr:0.0001\n",
      "Epoch 6, Step: 548, Loss: 0.14728638529777527, Lr:0.0001\n",
      "Epoch 6, Step: 549, Loss: 0.22337959706783295, Lr:0.0001\n",
      "Epoch 6, Step: 550, Loss: 0.11166874319314957, Lr:0.0001\n",
      "Epoch 6, Step: 551, Loss: 0.06938798725605011, Lr:0.0001\n",
      "Epoch 6, Step: 552, Loss: 0.03925209492444992, Lr:0.0001\n",
      "Epoch 6, Step: 553, Loss: 0.17900148034095764, Lr:0.0001\n",
      "Epoch 6, Step: 554, Loss: 0.06653059273958206, Lr:0.0001\n",
      "Epoch 6, Step: 555, Loss: 0.2423059046268463, Lr:0.0001\n",
      "Epoch 6, Step: 556, Loss: 0.23388153314590454, Lr:0.0001\n",
      "Epoch 6, Step: 557, Loss: 0.13163068890571594, Lr:0.0001\n",
      "Epoch 6, Step: 558, Loss: 0.07347037643194199, Lr:0.0001\n",
      "Epoch 6, Step: 559, Loss: 0.11322227865457535, Lr:0.0001\n",
      "Epoch 6, Step: 560, Loss: 0.15169736742973328, Lr:0.0001\n",
      "Epoch 6, Step: 561, Loss: 0.15507067739963531, Lr:0.0001\n",
      "Epoch 6, Step: 562, Loss: 0.17030204832553864, Lr:0.0001\n",
      "Epoch 6, Step: 563, Loss: 0.1177109032869339, Lr:0.0001\n",
      "Epoch 6, Step: 564, Loss: 0.40614891052246094, Lr:0.0001\n",
      "Epoch 6, Step: 565, Loss: 0.2809106707572937, Lr:0.0001\n",
      "Epoch 6, Step: 566, Loss: 0.08427426218986511, Lr:0.0001\n",
      "Epoch 6, Step: 567, Loss: 0.1279793679714203, Lr:0.0001\n",
      "Epoch 6, Step: 568, Loss: 0.25277042388916016, Lr:0.0001\n",
      "Epoch 6, Step: 569, Loss: 0.18239566683769226, Lr:0.0001\n",
      "Epoch 6, Step: 570, Loss: 0.38819968700408936, Lr:0.0001\n",
      "Epoch 6, Step: 571, Loss: 0.210322305560112, Lr:0.0001\n",
      "Epoch 6, Step: 572, Loss: 0.24319133162498474, Lr:0.0001\n",
      "Epoch 6, Step: 573, Loss: 0.2076493352651596, Lr:0.0001\n",
      "Epoch 6, Step: 574, Loss: 0.04058806225657463, Lr:0.0001\n",
      "Epoch 6, Step: 575, Loss: 0.341779500246048, Lr:0.0001\n",
      "Epoch 6, Step: 576, Loss: 0.4872722923755646, Lr:0.0001\n",
      "Epoch 6, Step: 577, Loss: 0.6041167974472046, Lr:0.0001\n",
      "Epoch 6, Step: 578, Loss: 0.25126585364341736, Lr:0.0001\n",
      "Epoch 6, Step: 579, Loss: 0.24268564581871033, Lr:0.0001\n",
      "Epoch 6, Step: 580, Loss: 0.18316784501075745, Lr:0.0001\n",
      "Epoch 6, Step: 581, Loss: 0.08021477609872818, Lr:0.0001\n",
      "Epoch 6, Step: 582, Loss: 0.07526636868715286, Lr:0.0001\n",
      "Epoch 6, Step: 583, Loss: 0.07541833817958832, Lr:0.0001\n",
      "Epoch 6, Step: 584, Loss: 0.17914767563343048, Lr:0.0001\n",
      "Epoch 6, Step: 585, Loss: 0.39068448543548584, Lr:0.0001\n",
      "Epoch 6, Step: 586, Loss: 0.5255001187324524, Lr:0.0001\n",
      "Epoch 6, Step: 587, Loss: 0.24464961886405945, Lr:0.0001\n",
      "Epoch 6, Step: 588, Loss: 0.21147260069847107, Lr:0.0001\n",
      "Epoch 6, Step: 589, Loss: 0.15742461383342743, Lr:0.0001\n",
      "Epoch 6, Step: 590, Loss: 0.2879745364189148, Lr:0.0001\n",
      "Epoch 6, Step: 591, Loss: 0.3559401035308838, Lr:0.0001\n",
      "Epoch 6, Step: 592, Loss: 0.06575271487236023, Lr:0.0001\n",
      "Epoch 6, Step: 593, Loss: 0.2619314193725586, Lr:0.0001\n",
      "Epoch 6, Step: 594, Loss: 0.06701993197202682, Lr:0.0001\n",
      "Epoch 6, Step: 595, Loss: 0.6529638171195984, Lr:0.0001\n",
      "Epoch 6, Step: 596, Loss: 0.1165018305182457, Lr:0.0001\n",
      "Epoch 6, Step: 597, Loss: 0.33965033292770386, Lr:0.0001\n",
      "Epoch 6, Step: 598, Loss: 0.39181244373321533, Lr:0.0001\n",
      "Epoch 6, Step: 599, Loss: 0.18464387953281403, Lr:0.0001\n",
      "Epoch 6, Step: 600, Loss: 0.2277652621269226, Lr:0.0001\n",
      "Epoch 6, Step: 601, Loss: 0.14455603063106537, Lr:0.0001\n",
      "Epoch 6, Step: 602, Loss: 0.3469005227088928, Lr:0.0001\n",
      "Epoch 6, Step: 603, Loss: 0.36184611916542053, Lr:0.0001\n",
      "Epoch 6, Step: 604, Loss: 0.17434193193912506, Lr:0.0001\n",
      "Epoch 6, Step: 605, Loss: 0.16017132997512817, Lr:0.0001\n",
      "Epoch 6, Step: 606, Loss: 0.5628646016120911, Lr:0.0001\n",
      "Epoch 6, Step: 607, Loss: 0.11136848479509354, Lr:0.0001\n",
      "Epoch 6, Step: 608, Loss: 0.1229701042175293, Lr:0.0001\n",
      "Epoch 6, Step: 609, Loss: 0.2178466022014618, Lr:0.0001\n",
      "Epoch 6, Step: 610, Loss: 0.06983970105648041, Lr:0.0001\n",
      "Epoch 6, Step: 611, Loss: 0.37564632296562195, Lr:0.0001\n",
      "Epoch 6, Step: 612, Loss: 0.8659464120864868, Lr:0.0001\n",
      "Epoch 6, Step: 613, Loss: 0.08124776184558868, Lr:0.0001\n",
      "Epoch 6, Step: 614, Loss: 0.057765647768974304, Lr:0.0001\n",
      "Epoch 6, Step: 615, Loss: 0.050309307873249054, Lr:0.0001\n",
      "Epoch 6, Step: 616, Loss: 0.3403245806694031, Lr:0.0001\n",
      "Epoch 6, Step: 617, Loss: 0.18383730947971344, Lr:0.0001\n",
      "Epoch 6, Step: 618, Loss: 0.06277161836624146, Lr:0.0001\n",
      "Epoch 6, Step: 619, Loss: 0.11073285341262817, Lr:0.0001\n",
      "Epoch 6, Step: 620, Loss: 0.16798491775989532, Lr:0.0001\n",
      "Epoch 6, Step: 621, Loss: 0.1170320138335228, Lr:0.0001\n",
      "Epoch 6, Step: 622, Loss: 0.1437085121870041, Lr:0.0001\n",
      "Epoch 6, Step: 623, Loss: 0.30272185802459717, Lr:0.0001\n",
      "Epoch 6, Step: 624, Loss: 0.23198823630809784, Lr:0.0001\n",
      "Epoch 6, Step: 625, Loss: 0.10954514145851135, Lr:0.0001\n",
      "Epoch 6, Step: 626, Loss: 0.0478171743452549, Lr:0.0001\n",
      "Epoch 6, Step: 627, Loss: 0.19224846363067627, Lr:0.0001\n",
      "Epoch 6, Step: 628, Loss: 0.2334853857755661, Lr:0.0001\n",
      "Epoch 6, Step: 629, Loss: 0.08626704663038254, Lr:0.0001\n",
      "Epoch 6, Step: 630, Loss: 0.3512660562992096, Lr:0.0001\n",
      "Epoch 6, Step: 631, Loss: 0.14464576542377472, Lr:0.0001\n",
      "Epoch 6, Step: 632, Loss: 0.1990300714969635, Lr:0.0001\n",
      "Epoch 6, Step: 633, Loss: 0.21037782728672028, Lr:0.0001\n",
      "Epoch 6, Step: 634, Loss: 0.10637572407722473, Lr:0.0001\n",
      "Epoch 6, Step: 635, Loss: 0.14914773404598236, Lr:0.0001\n",
      "Epoch 6, Step: 636, Loss: 0.27318647503852844, Lr:0.0001\n",
      "Epoch 6, Step: 637, Loss: 0.05828608572483063, Lr:0.0001\n",
      "Epoch 6, Step: 638, Loss: 0.758446455001831, Lr:0.0001\n",
      "Epoch 6, Step: 639, Loss: 0.4036051630973816, Lr:0.0001\n",
      "Epoch 6, Step: 640, Loss: 0.10948885232210159, Lr:0.0001\n",
      "Epoch 6, Step: 641, Loss: 0.2703438997268677, Lr:0.0001\n",
      "Epoch 6, Step: 642, Loss: 0.21085678040981293, Lr:0.0001\n",
      "Epoch 6, Step: 643, Loss: 0.23211613297462463, Lr:0.0001\n",
      "Epoch 6, Step: 644, Loss: 0.29069703817367554, Lr:0.0001\n",
      "Epoch 6, Step: 645, Loss: 0.30833011865615845, Lr:0.0001\n",
      "Epoch 6, Step: 646, Loss: 0.24767710268497467, Lr:0.0001\n",
      "Epoch 6, Step: 647, Loss: 0.09832701086997986, Lr:0.0001\n",
      "Epoch 6, Step: 648, Loss: 0.08962546288967133, Lr:0.0001\n",
      "Epoch 6, Step: 649, Loss: 0.1753598302602768, Lr:0.0001\n",
      "Epoch 6, Step: 650, Loss: 0.2921246588230133, Lr:0.0001\n",
      "Epoch 6, Step: 651, Loss: 0.07339891046285629, Lr:0.0001\n",
      "Epoch 6, Step: 652, Loss: 0.10602764040231705, Lr:0.0001\n",
      "Epoch 6, Step: 653, Loss: 0.21809504926204681, Lr:0.0001\n",
      "Epoch 6, Step: 654, Loss: 0.10744613409042358, Lr:0.0001\n",
      "Epoch 6, Step: 655, Loss: 0.23665697872638702, Lr:0.0001\n",
      "Epoch 6, Step: 656, Loss: 0.04769954830408096, Lr:0.0001\n",
      "Epoch 6, Step: 657, Loss: 0.05757741630077362, Lr:0.0001\n",
      "Epoch 6, Step: 658, Loss: 0.10217328369617462, Lr:0.0001\n",
      "Epoch 6, Step: 659, Loss: 0.24834607541561127, Lr:0.0001\n",
      "Epoch 6, Step: 660, Loss: 0.13544489443302155, Lr:0.0001\n",
      "Epoch 6, Step: 661, Loss: 0.4283173978328705, Lr:0.0001\n",
      "Epoch 6, Step: 662, Loss: 0.12186496704816818, Lr:0.0001\n",
      "Epoch 6, Step: 663, Loss: 0.08881332725286484, Lr:0.0001\n",
      "Epoch 6, Step: 664, Loss: 0.009197484701871872, Lr:0.0001\n",
      "Epoch 6, Step: 665, Loss: 0.21320956945419312, Lr:0.0001\n",
      "Epoch 6, Step: 666, Loss: 0.15568724274635315, Lr:0.0001\n",
      "Epoch 6, Step: 667, Loss: 0.41457870602607727, Lr:0.0001\n",
      "Epoch 6, Step: 668, Loss: 0.2211742103099823, Lr:0.0001\n",
      "Epoch 6, Step: 669, Loss: 0.044667646288871765, Lr:0.0001\n",
      "Epoch 6, Step: 670, Loss: 0.022837258875370026, Lr:0.0001\n",
      "Epoch 6, Step: 671, Loss: 0.13212774693965912, Lr:0.0001\n",
      "Epoch 6, Step: 672, Loss: 0.30428650975227356, Lr:0.0001\n",
      "Epoch 6, Step: 673, Loss: 0.12817828357219696, Lr:0.0001\n",
      "Epoch 6, Step: 674, Loss: 0.019530100747942924, Lr:0.0001\n",
      "Epoch 6, Step: 675, Loss: 0.08513820916414261, Lr:0.0001\n",
      "Epoch 6, Step: 676, Loss: 0.2827537953853607, Lr:0.0001\n",
      "Epoch 6, Step: 677, Loss: 0.23884105682373047, Lr:0.0001\n",
      "Epoch 6, Step: 678, Loss: 0.031230706721544266, Lr:0.0001\n",
      "Epoch 6, Step: 679, Loss: 0.11218339204788208, Lr:0.0001\n",
      "Epoch 6, Step: 680, Loss: 0.15329651534557343, Lr:0.0001\n",
      "Epoch 6, Step: 681, Loss: 0.23541688919067383, Lr:0.0001\n",
      "Epoch 6, Step: 682, Loss: 0.18618807196617126, Lr:0.0001\n",
      "Epoch 6, Step: 683, Loss: 0.23797602951526642, Lr:0.0001\n",
      "Epoch 6, Step: 684, Loss: 0.07255341857671738, Lr:0.0001\n",
      "Epoch 6, Step: 685, Loss: 0.1676713079214096, Lr:0.0001\n",
      "Epoch 6, Step: 686, Loss: 0.40656816959381104, Lr:0.0001\n",
      "Epoch 6, Step: 687, Loss: 0.1014731153845787, Lr:0.0001\n",
      "Epoch 6, Step: 688, Loss: 0.25292956829071045, Lr:0.0001\n",
      "Epoch 6, Step: 689, Loss: 0.14435765147209167, Lr:0.0001\n",
      "Epoch 6, Step: 690, Loss: 0.08833840489387512, Lr:0.0001\n",
      "Epoch 6, Step: 691, Loss: 0.20381730794906616, Lr:0.0001\n",
      "Epoch 6, Step: 692, Loss: 0.08067746460437775, Lr:0.0001\n",
      "Epoch 6, Step: 693, Loss: 0.07299824059009552, Lr:0.0001\n",
      "Epoch 6, Step: 694, Loss: 0.11970017850399017, Lr:0.0001\n",
      "Epoch 6, Step: 695, Loss: 0.16988727450370789, Lr:0.0001\n",
      "Epoch 6, Step: 696, Loss: 0.49714934825897217, Lr:0.0001\n",
      "Epoch 6, Step: 697, Loss: 0.20112480223178864, Lr:0.0001\n",
      "Epoch 6, Step: 698, Loss: 0.1362084150314331, Lr:0.0001\n",
      "Epoch 6, Step: 699, Loss: 0.02932811714708805, Lr:0.0001\n",
      "Epoch 6, Step: 700, Loss: 0.07187876850366592, Lr:0.0001\n",
      "Epoch 6, Step: 701, Loss: 0.15482193231582642, Lr:0.0001\n",
      "Epoch 6, Step: 702, Loss: 0.08267826586961746, Lr:0.0001\n",
      "Epoch 6, Step: 703, Loss: 0.2580776512622833, Lr:0.0001\n",
      "Epoch 6, Step: 704, Loss: 0.18873153626918793, Lr:0.0001\n",
      "Epoch 6, Step: 705, Loss: 0.3196004629135132, Lr:0.0001\n",
      "Epoch 6, Step: 706, Loss: 0.05318291112780571, Lr:0.0001\n",
      "Epoch 6, Step: 707, Loss: 0.16839860379695892, Lr:0.0001\n",
      "Epoch 6, Step: 708, Loss: 0.13327541947364807, Lr:0.0001\n",
      "Epoch 6, Step: 709, Loss: 0.30019423365592957, Lr:0.0001\n",
      "Epoch 6, Step: 710, Loss: 0.03107643686234951, Lr:0.0001\n",
      "Epoch 6, Step: 711, Loss: 0.08008332550525665, Lr:0.0001\n",
      "Epoch 6, Step: 712, Loss: 0.31657522916793823, Lr:0.0001\n",
      "Epoch 6, Step: 713, Loss: 0.08509312570095062, Lr:0.0001\n",
      "Epoch 6, Step: 714, Loss: 0.30572256445884705, Lr:0.0001\n",
      "Epoch 6, Step: 715, Loss: 0.14271332323551178, Lr:0.0001\n",
      "Epoch 6, Step: 716, Loss: 0.020737946033477783, Lr:0.0001\n",
      "Epoch 6, Step: 717, Loss: 0.16720174252986908, Lr:0.0001\n",
      "Epoch 6, Step: 718, Loss: 0.227836012840271, Lr:0.0001\n",
      "Epoch 6, Step: 719, Loss: 0.33167555928230286, Lr:0.0001\n",
      "Epoch 6, Step: 720, Loss: 0.19754701852798462, Lr:0.0001\n",
      "Epoch 6, Step: 721, Loss: 0.10107887536287308, Lr:0.0001\n",
      "Epoch 6, Step: 722, Loss: 0.24592213332653046, Lr:0.0001\n",
      "Epoch 6, Step: 723, Loss: 0.1610502004623413, Lr:0.0001\n",
      "Epoch 6, Step: 724, Loss: 0.35310715436935425, Lr:0.0001\n",
      "Epoch 6, Step: 725, Loss: 0.15877079963684082, Lr:0.0001\n",
      "Epoch 6, Step: 726, Loss: 0.2644296884536743, Lr:0.0001\n",
      "Epoch 6, Step: 727, Loss: 0.04723156988620758, Lr:0.0001\n",
      "Epoch 6, Step: 728, Loss: 0.1371420919895172, Lr:0.0001\n",
      "Epoch 6, Step: 729, Loss: 0.2924429774284363, Lr:0.0001\n",
      "Epoch 6, Step: 730, Loss: 0.07550842314958572, Lr:0.0001\n",
      "Epoch 6, Step: 731, Loss: 0.08436009287834167, Lr:0.0001\n",
      "Epoch 6, Step: 732, Loss: 0.517446756362915, Lr:0.0001\n",
      "Epoch 6, Step: 733, Loss: 0.2628577947616577, Lr:0.0001\n",
      "Epoch 6, Step: 734, Loss: 0.04948345571756363, Lr:0.0001\n",
      "Epoch 6, Step: 735, Loss: 0.4438718259334564, Lr:0.0001\n",
      "Epoch 6, Step: 736, Loss: 0.2563880980014801, Lr:0.0001\n",
      "Epoch 6, Step: 737, Loss: 0.20927956700325012, Lr:0.0001\n",
      "Epoch 6, Step: 738, Loss: 0.5526021718978882, Lr:0.0001\n",
      "Epoch 6, Step: 739, Loss: 0.07062406837940216, Lr:0.0001\n",
      "Epoch 6, Step: 740, Loss: 0.10592548549175262, Lr:0.0001\n",
      "Epoch 6, Step: 741, Loss: 0.4217838644981384, Lr:0.0001\n",
      "Epoch 6, Step: 742, Loss: 0.1574319303035736, Lr:0.0001\n",
      "Epoch 6, Step: 743, Loss: 0.30888158082962036, Lr:0.0001\n",
      "Epoch 6, Step: 744, Loss: 0.2675815522670746, Lr:0.0001\n",
      "Epoch 6, Step: 745, Loss: 0.06519980728626251, Lr:0.0001\n",
      "Epoch 6, Step: 746, Loss: 0.14610396325588226, Lr:0.0001\n",
      "Epoch 6, Step: 747, Loss: 0.15159517526626587, Lr:0.0001\n",
      "Epoch 6, Step: 748, Loss: 0.40615105628967285, Lr:0.0001\n",
      "Epoch 6, Step: 749, Loss: 0.4087231457233429, Lr:0.0001\n",
      "Epoch 6, Step: 750, Loss: 0.19113104045391083, Lr:0.0001\n",
      "Epoch 6, Step: 751, Loss: 0.35979095101356506, Lr:0.0001\n",
      "Epoch 6, Step: 752, Loss: 0.28197234869003296, Lr:0.0001\n",
      "Epoch 6, Step: 753, Loss: 0.29451513290405273, Lr:0.0001\n",
      "Epoch 6, Step: 754, Loss: 0.4148341715335846, Lr:0.0001\n",
      "Epoch 6, Step: 755, Loss: 0.39778438210487366, Lr:0.0001\n",
      "Epoch 6, Step: 756, Loss: 0.4806159734725952, Lr:0.0001\n",
      "Epoch 6, Step: 757, Loss: 0.3240933120250702, Lr:0.0001\n",
      "Epoch 6, Step: 758, Loss: 0.11767418682575226, Lr:0.0001\n",
      "Epoch 6, Step: 759, Loss: 0.22502268850803375, Lr:0.0001\n",
      "Epoch 6, Step: 760, Loss: 0.40382346510887146, Lr:0.0001\n",
      "Epoch 6, Step: 761, Loss: 0.21694086492061615, Lr:0.0001\n",
      "Epoch 6, Step: 762, Loss: 0.3513789474964142, Lr:0.0001\n",
      "Epoch 6, Step: 763, Loss: 0.14750295877456665, Lr:0.0001\n",
      "Epoch 6, Step: 764, Loss: 0.23251087963581085, Lr:0.0001\n",
      "Epoch 6, Step: 765, Loss: 0.3680493235588074, Lr:0.0001\n",
      "Epoch 6, Step: 766, Loss: 0.11290173977613449, Lr:0.0001\n",
      "Epoch 6, Step: 767, Loss: 0.12105153501033783, Lr:0.0001\n",
      "Epoch 6, Step: 768, Loss: 0.1482146978378296, Lr:0.0001\n",
      "Epoch 6, Step: 769, Loss: 0.11981713771820068, Lr:0.0001\n",
      "Epoch 6, Step: 770, Loss: 0.2703048288822174, Lr:0.0001\n",
      "Epoch 6, Step: 771, Loss: 0.17614981532096863, Lr:0.0001\n",
      "Epoch 6, Step: 772, Loss: 0.16423481702804565, Lr:0.0001\n",
      "Epoch 6, Step: 773, Loss: 0.7484176754951477, Lr:0.0001\n",
      "Epoch 6, Step: 774, Loss: 0.2839812636375427, Lr:0.0001\n",
      "Epoch 6, Step: 775, Loss: 0.11428376287221909, Lr:0.0001\n",
      "Epoch 6, Step: 776, Loss: 0.1642773300409317, Lr:0.0001\n",
      "Epoch 6, Step: 777, Loss: 0.12283757328987122, Lr:0.0001\n",
      "Epoch 6, Step: 778, Loss: 0.10305081307888031, Lr:0.0001\n",
      "Epoch 6, Step: 779, Loss: 0.05823724344372749, Lr:0.0001\n",
      "Epoch 6, Step: 780, Loss: 0.11867526918649673, Lr:0.0001\n",
      "Epoch 6, Step: 781, Loss: 0.7400063872337341, Lr:0.0001\n",
      "Epoch 6, Step: 782, Loss: 0.3239392936229706, Lr:0.0001\n",
      "Epoch 6, Step: 783, Loss: 0.05832784250378609, Lr:0.0001\n",
      "Epoch 6, Step: 784, Loss: 0.12886911630630493, Lr:0.0001\n",
      "Epoch 6, Step: 785, Loss: 0.08566653728485107, Lr:0.0001\n",
      "Epoch 6, Step: 786, Loss: 0.16771948337554932, Lr:0.0001\n",
      "Epoch 6, Step: 787, Loss: 0.3016846776008606, Lr:0.0001\n",
      "Epoch 6, Step: 788, Loss: 0.07223966717720032, Lr:0.0001\n",
      "Epoch 6, Step: 789, Loss: 0.20648057758808136, Lr:0.0001\n",
      "Epoch 6, Step: 790, Loss: 0.19072654843330383, Lr:0.0001\n",
      "Epoch 6, Step: 791, Loss: 0.16993483901023865, Lr:0.0001\n",
      "Epoch 6, Step: 792, Loss: 0.19527019560337067, Lr:0.0001\n",
      "Epoch 6, Step: 793, Loss: 0.23014986515045166, Lr:0.0001\n",
      "Epoch 6, Step: 794, Loss: 0.07828330248594284, Lr:0.0001\n",
      "Epoch 6, Step: 795, Loss: 0.12368512153625488, Lr:0.0001\n",
      "Epoch 6, Step: 796, Loss: 0.354529470205307, Lr:0.0001\n",
      "Epoch 6, Step: 797, Loss: 0.5528638958930969, Lr:0.0001\n",
      "Epoch 6, Step: 798, Loss: 0.15151844918727875, Lr:0.0001\n",
      "Epoch 6, Step: 799, Loss: 0.17656517028808594, Lr:0.0001\n",
      "Epoch 6, Step: 800, Loss: 0.24427594244480133, Lr:0.0001\n",
      "Epoch 6, Step: 801, Loss: 0.1822373867034912, Lr:0.0001\n",
      "Epoch 6, Step: 802, Loss: 0.3796330690383911, Lr:0.0001\n",
      "Epoch 6, Step: 803, Loss: 1.4031816720962524, Lr:0.0001\n",
      "Epoch 6, Step: 804, Loss: 0.32707008719444275, Lr:0.0001\n",
      "Epoch 6, Step: 805, Loss: 0.38535594940185547, Lr:0.0001\n",
      "Epoch 6, Step: 806, Loss: 0.12096437811851501, Lr:0.0001\n",
      "Epoch 6, Step: 807, Loss: 0.4891212582588196, Lr:0.0001\n",
      "Epoch 6, Step: 808, Loss: 0.298501193523407, Lr:0.0001\n",
      "Epoch 6, Step: 809, Loss: 0.26436614990234375, Lr:0.0001\n",
      "Epoch 6, Step: 810, Loss: 0.20516565442085266, Lr:0.0001\n",
      "Epoch 6, Step: 811, Loss: 0.05490049347281456, Lr:0.0001\n",
      "Epoch 6, Step: 812, Loss: 0.10221903026103973, Lr:0.0001\n",
      "Epoch 6, Step: 813, Loss: 0.1787182241678238, Lr:0.0001\n",
      "Epoch 6, Step: 814, Loss: 0.22173595428466797, Lr:0.0001\n",
      "Epoch 6, Step: 815, Loss: 0.47116416692733765, Lr:0.0001\n",
      "Epoch 6, Step: 816, Loss: 0.29198557138442993, Lr:0.0001\n",
      "Epoch 6, Step: 817, Loss: 0.7669163346290588, Lr:0.0001\n",
      "Epoch 6, Step: 818, Loss: 0.08172591775655746, Lr:0.0001\n",
      "Epoch 6, Step: 819, Loss: 0.3952101469039917, Lr:0.0001\n",
      "Epoch 6, Step: 820, Loss: 0.27326932549476624, Lr:0.0001\n",
      "Epoch 6, Step: 821, Loss: 0.13907694816589355, Lr:0.0001\n",
      "Epoch 6, Step: 822, Loss: 0.0488121323287487, Lr:0.0001\n",
      "Epoch 6, Step: 823, Loss: 0.23134708404541016, Lr:0.0001\n",
      "Epoch 6, Step: 824, Loss: 0.47326046228408813, Lr:0.0001\n",
      "Epoch 6, Step: 825, Loss: 0.46374329924583435, Lr:0.0001\n",
      "Epoch 6, Step: 826, Loss: 0.06149602308869362, Lr:0.0001\n",
      "Epoch 6, Step: 827, Loss: 0.2329852432012558, Lr:0.0001\n",
      "Epoch 6, Step: 828, Loss: 0.2595808804035187, Lr:0.0001\n",
      "Epoch 6, Step: 829, Loss: 0.33660706877708435, Lr:0.0001\n",
      "Epoch 6, Step: 830, Loss: 0.22360509634017944, Lr:0.0001\n",
      "Epoch 6, Step: 831, Loss: 0.1734997183084488, Lr:0.0001\n",
      "Epoch 6, Step: 832, Loss: 0.08004246652126312, Lr:0.0001\n",
      "Epoch 6, Step: 833, Loss: 0.3128695785999298, Lr:0.0001\n",
      "Epoch 6, Step: 834, Loss: 0.20111297070980072, Lr:0.0001\n",
      "Epoch 6, Step: 835, Loss: 0.08056722581386566, Lr:0.0001\n",
      "Epoch 6, Step: 836, Loss: 0.3043689429759979, Lr:0.0001\n",
      "Epoch 6, Step: 837, Loss: 0.19561707973480225, Lr:0.0001\n",
      "Epoch 6, Step: 838, Loss: 0.3480609357357025, Lr:0.0001\n",
      "Epoch 6, Step: 839, Loss: 0.5107150077819824, Lr:0.0001\n",
      "Epoch 6, Step: 840, Loss: 0.15702858567237854, Lr:0.0001\n",
      "Epoch 6, Step: 841, Loss: 0.3427049517631531, Lr:0.0001\n",
      "Epoch 6, Step: 842, Loss: 0.3216966986656189, Lr:0.0001\n",
      "Epoch 6, Step: 843, Loss: 0.09609729796648026, Lr:0.0001\n",
      "Epoch 6, Step: 844, Loss: 0.14236800372600555, Lr:0.0001\n",
      "Epoch 6, Step: 845, Loss: 0.14617817103862762, Lr:0.0001\n",
      "Epoch 6, Step: 846, Loss: 0.11319296807050705, Lr:0.0001\n",
      "Epoch 6, Step: 847, Loss: 0.1351933777332306, Lr:0.0001\n",
      "Epoch 6, Step: 848, Loss: 0.3999135494232178, Lr:0.0001\n",
      "Epoch 6, Step: 849, Loss: 0.36660996079444885, Lr:0.0001\n",
      "Epoch 6, Step: 850, Loss: 0.10348035395145416, Lr:0.0001\n",
      "Epoch 6, Step: 851, Loss: 0.0595463365316391, Lr:0.0001\n",
      "Epoch 6, Step: 852, Loss: 0.5417097210884094, Lr:0.0001\n",
      "Epoch 6, Step: 853, Loss: 0.15654203295707703, Lr:0.0001\n",
      "Epoch 6, Step: 854, Loss: 0.22668208181858063, Lr:0.0001\n",
      "Epoch 6, Step: 855, Loss: 0.30916911363601685, Lr:0.0001\n",
      "Epoch 6, Step: 856, Loss: 0.14381143450737, Lr:0.0001\n",
      "Epoch 6, Step: 857, Loss: 0.2069617509841919, Lr:0.0001\n",
      "Epoch 6, Step: 858, Loss: 0.24754150211811066, Lr:0.0001\n",
      "Epoch 6, Step: 859, Loss: 0.054410215467214584, Lr:0.0001\n",
      "Epoch 6, Step: 860, Loss: 0.06845439970493317, Lr:0.0001\n",
      "Epoch 6, Step: 861, Loss: 0.2190096378326416, Lr:0.0001\n",
      "Epoch 6, Step: 862, Loss: 0.3717101514339447, Lr:0.0001\n",
      "Epoch 6, Step: 863, Loss: 0.1708974540233612, Lr:0.0001\n",
      "Epoch 6, Step: 864, Loss: 0.16371065378189087, Lr:0.0001\n",
      "Epoch 6, Step: 865, Loss: 0.11894229799509048, Lr:0.0001\n",
      "Epoch 6, Step: 866, Loss: 0.18534649908542633, Lr:0.0001\n",
      "Epoch 6, Step: 867, Loss: 0.11480317264795303, Lr:0.0001\n",
      "Epoch 6, Step: 868, Loss: 0.1615026295185089, Lr:0.0001\n",
      "Epoch 6, Step: 869, Loss: 0.17171838879585266, Lr:0.0001\n",
      "Epoch 6, Step: 870, Loss: 0.4183087646961212, Lr:0.0001\n",
      "Epoch 6, Step: 871, Loss: 0.08517652004957199, Lr:0.0001\n",
      "Epoch 6, Step: 872, Loss: 0.10068149864673615, Lr:0.0001\n",
      "Epoch 6, Step: 873, Loss: 0.21140003204345703, Lr:0.0001\n",
      "Epoch 6, Step: 874, Loss: 0.03936458379030228, Lr:0.0001\n",
      "Epoch 6, Step: 875, Loss: 0.278409481048584, Lr:0.0001\n",
      "Epoch 6, Step: 876, Loss: 0.05088905990123749, Lr:0.0001\n",
      "Epoch 6, Step: 877, Loss: 0.1292114108800888, Lr:0.0001\n",
      "Epoch 6, Step: 878, Loss: 0.2385091334581375, Lr:0.0001\n",
      "Epoch 6, Step: 879, Loss: 0.1664964109659195, Lr:0.0001\n",
      "Epoch 6, Step: 880, Loss: 0.12871386110782623, Lr:0.0001\n",
      "Epoch 6, Step: 881, Loss: 0.14101289212703705, Lr:0.0001\n",
      "Epoch 6, Step: 882, Loss: 0.33538371324539185, Lr:0.0001\n",
      "Epoch 6, Step: 883, Loss: 0.11315266042947769, Lr:0.0001\n",
      "Epoch 6, Step: 884, Loss: 0.039664413779973984, Lr:0.0001\n",
      "Epoch 6, Step: 885, Loss: 0.28151777386665344, Lr:0.0001\n",
      "Epoch 6, Step: 886, Loss: 0.34122151136398315, Lr:0.0001\n",
      "Epoch 6, Step: 887, Loss: 0.11701616644859314, Lr:0.0001\n",
      "Epoch 6, Step: 888, Loss: 0.28869667649269104, Lr:0.0001\n",
      "Epoch 6, Step: 889, Loss: 0.3668641746044159, Lr:0.0001\n",
      "Epoch 6, Step: 890, Loss: 0.17509053647518158, Lr:0.0001\n",
      "Epoch 6, Step: 891, Loss: 0.037057727575302124, Lr:0.0001\n",
      "Epoch 6, Step: 892, Loss: 0.18541721999645233, Lr:0.0001\n",
      "Epoch 6, Step: 893, Loss: 0.2115362584590912, Lr:0.0001\n",
      "Epoch 6, Step: 894, Loss: 0.06971964240074158, Lr:0.0001\n",
      "Epoch 6, Step: 895, Loss: 0.1699199229478836, Lr:0.0001\n",
      "Epoch 6, Step: 896, Loss: 0.3461020886898041, Lr:0.0001\n",
      "Epoch 6, Step: 897, Loss: 0.3439977169036865, Lr:0.0001\n",
      "Epoch 6, Step: 898, Loss: 0.46394214034080505, Lr:0.0001\n",
      "Epoch 6, Step: 899, Loss: 0.07443059980869293, Lr:0.0001\n",
      "Epoch 6, Step: 900, Loss: 0.07708533853292465, Lr:0.0001\n",
      "Epoch 6, Step: 901, Loss: 0.05260440334677696, Lr:0.0001\n",
      "Epoch 6, Step: 902, Loss: 0.513077974319458, Lr:0.0001\n",
      "Epoch 6, Step: 903, Loss: 0.43267324566841125, Lr:0.0001\n",
      "Epoch 6, Step: 904, Loss: 0.061503052711486816, Lr:0.0001\n",
      "Epoch 6, Step: 905, Loss: 0.08607890456914902, Lr:0.0001\n",
      "Epoch 6, Step: 906, Loss: 0.15309545397758484, Lr:0.0001\n",
      "Epoch 6, Step: 907, Loss: 0.12212447077035904, Lr:0.0001\n",
      "Epoch 6, Step: 908, Loss: 0.06145340949296951, Lr:0.0001\n",
      "Epoch 6, Step: 909, Loss: 0.1992950588464737, Lr:0.0001\n",
      "Epoch 6, Step: 910, Loss: 0.5649526119232178, Lr:0.0001\n",
      "Epoch 6, Step: 911, Loss: 0.15639618039131165, Lr:0.0001\n",
      "Epoch 6, Step: 912, Loss: 0.2584141194820404, Lr:0.0001\n",
      "Epoch 6, Step: 913, Loss: 0.11155227571725845, Lr:0.0001\n",
      "Epoch 6, Step: 914, Loss: 0.37007713317871094, Lr:0.0001\n",
      "Epoch 6, Step: 915, Loss: 0.3571662902832031, Lr:0.0001\n",
      "Epoch 6, Step: 916, Loss: 0.6138054728507996, Lr:0.0001\n",
      "Epoch 6, Step: 917, Loss: 0.21583028137683868, Lr:0.0001\n",
      "Epoch 6, Step: 918, Loss: 0.6880395412445068, Lr:0.0001\n",
      "Epoch 6, Step: 919, Loss: 0.19746235013008118, Lr:0.0001\n",
      "Epoch 6, Step: 920, Loss: 0.17475658655166626, Lr:0.0001\n",
      "Epoch 6, Step: 921, Loss: 0.2034911960363388, Lr:0.0001\n",
      "Epoch 6, Step: 922, Loss: 0.12271420657634735, Lr:0.0001\n",
      "Epoch 6, Step: 923, Loss: 0.4437343180179596, Lr:0.0001\n",
      "Epoch 6, Step: 924, Loss: 0.07689736783504486, Lr:0.0001\n",
      "Epoch 6, Step: 925, Loss: 0.135422021150589, Lr:0.0001\n",
      "Epoch 6, Step: 926, Loss: 0.19935153424739838, Lr:0.0001\n",
      "Epoch 6, Step: 927, Loss: 0.02881482243537903, Lr:0.0001\n",
      "Epoch 6, Step: 928, Loss: 0.12990085780620575, Lr:0.0001\n",
      "Epoch 6, Step: 929, Loss: 0.07303325086832047, Lr:0.0001\n",
      "Epoch 6, Step: 930, Loss: 0.10417274385690689, Lr:0.0001\n",
      "Epoch 6, Step: 931, Loss: 0.02529856376349926, Lr:0.0001\n",
      "Epoch 6, Step: 932, Loss: 0.35841599106788635, Lr:0.0001\n",
      "Epoch 6, Step: 933, Loss: 0.4957440495491028, Lr:0.0001\n",
      "Epoch 6, Step: 934, Loss: 0.22781556844711304, Lr:0.0001\n",
      "Epoch 6, Step: 935, Loss: 0.2860260009765625, Lr:0.0001\n",
      "Epoch 6, Step: 936, Loss: 0.3363414406776428, Lr:0.0001\n",
      "Epoch 6, Step: 937, Loss: 0.16527505218982697, Lr:0.0001\n",
      "Epoch 6, Step: 938, Loss: 0.18234983086585999, Lr:0.0001\n",
      "Epoch 6, Step: 939, Loss: 0.04785512015223503, Lr:0.0001\n",
      "Epoch 6, Step: 940, Loss: 0.21592921018600464, Lr:0.0001\n",
      "Epoch 6, Step: 941, Loss: 0.21783427894115448, Lr:0.0001\n",
      "Epoch 6, Step: 942, Loss: 0.06346704810857773, Lr:0.0001\n",
      "Epoch 6, Step: 943, Loss: 0.04756537824869156, Lr:0.0001\n",
      "Epoch 6, Step: 944, Loss: 0.22581535577774048, Lr:0.0001\n",
      "Epoch 6, Step: 945, Loss: 0.13471293449401855, Lr:0.0001\n",
      "Epoch 6, Step: 946, Loss: 0.25309330224990845, Lr:0.0001\n",
      "Epoch 6, Step: 947, Loss: 0.08266660571098328, Lr:0.0001\n",
      "Epoch 6, Step: 948, Loss: 0.25857415795326233, Lr:0.0001\n",
      "Epoch 6, Step: 949, Loss: 0.3567509055137634, Lr:0.0001\n",
      "Epoch 6, Step: 950, Loss: 0.2072722166776657, Lr:0.0001\n",
      "Epoch 6, Step: 951, Loss: 0.30286407470703125, Lr:0.0001\n",
      "Epoch 6, Step: 952, Loss: 0.22097118198871613, Lr:0.0001\n",
      "Epoch 6, Step: 953, Loss: 0.27158334851264954, Lr:0.0001\n",
      "Epoch 6, Step: 954, Loss: 0.2459782063961029, Lr:0.0001\n",
      "Epoch 6, Step: 955, Loss: 0.3064020276069641, Lr:0.0001\n",
      "Epoch 6, Step: 956, Loss: 0.2050837129354477, Lr:0.0001\n",
      "Epoch 6, Step: 957, Loss: 0.23252007365226746, Lr:0.0001\n",
      "Epoch 6, Step: 958, Loss: 0.15553408861160278, Lr:0.0001\n",
      "Epoch 6, Step: 959, Loss: 0.2402007132768631, Lr:0.0001\n",
      "Epoch 6, Step: 960, Loss: 0.0365995354950428, Lr:0.0001\n",
      "Epoch 6, Step: 961, Loss: 0.16423070430755615, Lr:0.0001\n",
      "Epoch 6, Step: 962, Loss: 0.2362804114818573, Lr:0.0001\n",
      "Epoch 6, Step: 963, Loss: 0.34977179765701294, Lr:0.0001\n",
      "Epoch 6, Step: 964, Loss: 0.0566682443022728, Lr:0.0001\n",
      "Epoch 6, Step: 965, Loss: 0.18325509130954742, Lr:0.0001\n",
      "Epoch 6, Step: 966, Loss: 0.20403313636779785, Lr:0.0001\n",
      "Epoch 6, Step: 967, Loss: 0.07327447831630707, Lr:0.0001\n",
      "Epoch 6, Step: 968, Loss: 0.2694539725780487, Lr:0.0001\n",
      "Epoch 6, Step: 969, Loss: 0.14624319970607758, Lr:0.0001\n",
      "Epoch 6, Step: 970, Loss: 0.15279489755630493, Lr:0.0001\n",
      "Epoch 6, Step: 971, Loss: 0.1736488938331604, Lr:0.0001\n",
      "Epoch 6, Step: 972, Loss: 0.2450702041387558, Lr:0.0001\n",
      "Epoch 6, Step: 973, Loss: 0.1720348298549652, Lr:0.0001\n",
      "Epoch 6, Step: 974, Loss: 0.06497690081596375, Lr:0.0001\n",
      "Epoch 6, Step: 975, Loss: 0.10097473114728928, Lr:0.0001\n",
      "Epoch 6, Step: 976, Loss: 0.23367685079574585, Lr:0.0001\n",
      "Epoch 6, Step: 977, Loss: 0.034717705100774765, Lr:0.0001\n",
      "Epoch 6, Step: 978, Loss: 0.3301115334033966, Lr:0.0001\n",
      "Epoch 6, Step: 979, Loss: 0.11182709783315659, Lr:0.0001\n",
      "Epoch 6, Step: 980, Loss: 0.2550807595252991, Lr:0.0001\n",
      "Epoch 6, Step: 981, Loss: 0.08081626147031784, Lr:0.0001\n",
      "Epoch 6, Step: 982, Loss: 0.1412266343832016, Lr:0.0001\n",
      "Epoch 6, Step: 983, Loss: 0.12450426071882248, Lr:0.0001\n",
      "Epoch 6, Step: 984, Loss: 0.08676441758871078, Lr:0.0001\n",
      "Epoch 6, Step: 985, Loss: 0.05710385739803314, Lr:0.0001\n",
      "Epoch 6, Step: 986, Loss: 0.20526829361915588, Lr:0.0001\n",
      "Epoch 6, Step: 987, Loss: 0.43525782227516174, Lr:0.0001\n",
      "Epoch 6, Step: 988, Loss: 0.05920412018895149, Lr:0.0001\n",
      "Epoch 6, Step: 989, Loss: 0.20974822342395782, Lr:0.0001\n",
      "Epoch 6, Step: 990, Loss: 0.3037432134151459, Lr:0.0001\n",
      "Epoch 6, Step: 991, Loss: 0.18031606078147888, Lr:0.0001\n",
      "Epoch 6, Step: 992, Loss: 0.09688986837863922, Lr:0.0001\n",
      "Epoch 6, Step: 993, Loss: 0.3020278215408325, Lr:0.0001\n",
      "Epoch 6, Step: 994, Loss: 0.291963130235672, Lr:0.0001\n",
      "Epoch 6, Step: 995, Loss: 0.3416818678379059, Lr:0.0001\n",
      "Epoch 6, Step: 996, Loss: 0.14957576990127563, Lr:0.0001\n",
      "Epoch 6, Step: 997, Loss: 0.40263423323631287, Lr:0.0001\n",
      "Epoch 6, Step: 998, Loss: 0.1616685837507248, Lr:0.0001\n",
      "Epoch 6, Step: 999, Loss: 0.3490338921546936, Lr:0.0001\n",
      "Epoch 6, Step: 1000, Loss: 0.026187900453805923, Lr:0.0001\n",
      "Epoch 6, Step: 1001, Loss: 0.08808369189500809, Lr:0.0001\n",
      "Epoch 6, Step: 1002, Loss: 0.20493027567863464, Lr:0.0001\n",
      "Epoch 6, Step: 1003, Loss: 0.2305150330066681, Lr:0.0001\n",
      "Epoch 6, Step: 1004, Loss: 0.08542357385158539, Lr:0.0001\n",
      "Epoch 6, Step: 1005, Loss: 0.2413509339094162, Lr:0.0001\n",
      "Epoch 6, Step: 1006, Loss: 0.18300700187683105, Lr:0.0001\n",
      "Epoch 6, Step: 1007, Loss: 0.5182161927223206, Lr:0.0001\n",
      "Epoch 6, Step: 1008, Loss: 0.2872583866119385, Lr:0.0001\n",
      "Epoch 6, Step: 1009, Loss: 0.16074234247207642, Lr:0.0001\n",
      "Epoch 6, Step: 1010, Loss: 0.10706965625286102, Lr:0.0001\n",
      "Epoch 6, Step: 1011, Loss: 0.08540631830692291, Lr:0.0001\n",
      "Epoch 6, Step: 1012, Loss: 0.20510059595108032, Lr:0.0001\n",
      "Epoch 6, Step: 1013, Loss: 0.09139715135097504, Lr:0.0001\n",
      "Epoch 6, Step: 1014, Loss: 0.2062479555606842, Lr:0.0001\n",
      "Epoch 6, Step: 1015, Loss: 0.05106457322835922, Lr:0.0001\n",
      "Epoch 6, Step: 1016, Loss: 0.1525641679763794, Lr:0.0001\n",
      "Epoch 6, Step: 1017, Loss: 0.09417222440242767, Lr:0.0001\n",
      "Epoch 6, Step: 1018, Loss: 0.15973913669586182, Lr:0.0001\n",
      "Epoch 6, Step: 1019, Loss: 0.29713326692581177, Lr:0.0001\n",
      "Epoch 6, Step: 1020, Loss: 0.23875629901885986, Lr:0.0001\n",
      "Epoch 6, Step: 1021, Loss: 0.07572861760854721, Lr:0.0001\n",
      "Epoch 6, Step: 1022, Loss: 0.20145820081233978, Lr:0.0001\n",
      "Epoch 6, Step: 1023, Loss: 0.027134619653224945, Lr:0.0001\n",
      "Epoch 6, Step: 1024, Loss: 0.24536359310150146, Lr:0.0001\n",
      "Epoch 6, Step: 1025, Loss: 0.39516735076904297, Lr:0.0001\n",
      "Epoch 6, Step: 1026, Loss: 0.008412937633693218, Lr:0.0001\n",
      "Epoch 6, Step: 1027, Loss: 0.2821274995803833, Lr:0.0001\n",
      "Epoch 6, Step: 1028, Loss: 0.07722800225019455, Lr:0.0001\n",
      "Epoch 6, Step: 1029, Loss: 0.20357632637023926, Lr:0.0001\n",
      "Epoch 6, Step: 1030, Loss: 0.288426011800766, Lr:0.0001\n",
      "Epoch 6, Step: 1031, Loss: 0.0420592837035656, Lr:0.0001\n",
      "Epoch 6, Step: 1032, Loss: 0.3764636814594269, Lr:0.0001\n",
      "Epoch 6, Step: 1033, Loss: 0.3201553523540497, Lr:0.0001\n",
      "Epoch 6, Step: 1034, Loss: 0.1868802011013031, Lr:0.0001\n",
      "Epoch 6, Step: 1035, Loss: 0.18066054582595825, Lr:0.0001\n",
      "Epoch 6, Step: 1036, Loss: 0.326985627412796, Lr:0.0001\n",
      "Epoch 6, Step: 1037, Loss: 0.07868655771017075, Lr:0.0001\n",
      "Epoch 6, Step: 1038, Loss: 0.21001088619232178, Lr:0.0001\n",
      "Epoch 6, Step: 1039, Loss: 0.11659497767686844, Lr:0.0001\n",
      "Epoch 6, Step: 1040, Loss: 0.06891416013240814, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 6\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:16 loss: 0.6355 (0.6355) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.3023 data: 0.1215 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.0474 (0.1001) acc1: 100.0000 (96.5909) acc5: 100.0000 (100.0000) time: 0.3029 data: 0.1168 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0474 (0.1172) acc1: 100.0000 (96.1310) acc5: 100.0000 (100.0000) time: 0.3025 data: 0.1180 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.0980 (0.2116) acc1: 93.7500 (90.7258) acc5: 100.0000 (100.0000) time: 0.3041 data: 0.1203 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.2291 (0.2175) acc1: 87.5000 (90.5488) acc5: 100.0000 (100.0000) time: 0.3057 data: 0.1248 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.2291 (0.2442) acc1: 87.5000 (89.7059) acc5: 100.0000 (100.0000) time: 0.3074 data: 0.1266 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.2091 (0.2540) acc1: 87.5000 (89.3303) acc5: 100.0000 (100.0000) time: 0.2946 data: 0.1200 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.3004 s / it)\n",
      "* Acc@1 89.330 Acc@5 100.000 loss 0.254\n",
      "Accuracy of the network on the 881 test image: 89.3%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 7, Step: 0, Loss: 0.2735098898410797, Lr:0.0001\n",
      "Epoch 7, Step: 1, Loss: 0.028920110315084457, Lr:0.0001\n",
      "Epoch 7, Step: 2, Loss: 0.1205756664276123, Lr:0.0001\n",
      "Epoch 7, Step: 3, Loss: 0.15462535619735718, Lr:0.0001\n",
      "Epoch 7, Step: 4, Loss: 0.1433061808347702, Lr:0.0001\n",
      "Epoch 7, Step: 5, Loss: 0.32901841402053833, Lr:0.0001\n",
      "Epoch 7, Step: 6, Loss: 0.17931775748729706, Lr:0.0001\n",
      "Epoch 7, Step: 7, Loss: 0.059307899326086044, Lr:0.0001\n",
      "Epoch 7, Step: 8, Loss: 0.3436518907546997, Lr:0.0001\n",
      "Epoch 7, Step: 9, Loss: 0.05545332282781601, Lr:0.0001\n",
      "Epoch 7, Step: 10, Loss: 0.17284150421619415, Lr:0.0001\n",
      "Epoch 7, Step: 11, Loss: 0.0596151165664196, Lr:0.0001\n",
      "Epoch 7, Step: 12, Loss: 0.03807950019836426, Lr:0.0001\n",
      "Epoch 7, Step: 13, Loss: 0.219534233212471, Lr:0.0001\n",
      "Epoch 7, Step: 14, Loss: 0.06111845374107361, Lr:0.0001\n",
      "Epoch 7, Step: 15, Loss: 0.09679526090621948, Lr:0.0001\n",
      "Epoch 7, Step: 16, Loss: 0.17580044269561768, Lr:0.0001\n",
      "Epoch 7, Step: 17, Loss: 0.0829615518450737, Lr:0.0001\n",
      "Epoch 7, Step: 18, Loss: 0.10605102777481079, Lr:0.0001\n",
      "Epoch 7, Step: 19, Loss: 0.2639840543270111, Lr:0.0001\n",
      "Epoch 7, Step: 20, Loss: 0.12962983548641205, Lr:0.0001\n",
      "Epoch 7, Step: 21, Loss: 0.06930689513683319, Lr:0.0001\n",
      "Epoch 7, Step: 22, Loss: 0.0721018835902214, Lr:0.0001\n",
      "Epoch 7, Step: 23, Loss: 0.24223968386650085, Lr:0.0001\n",
      "Epoch 7, Step: 24, Loss: 0.45465055108070374, Lr:0.0001\n",
      "Epoch 7, Step: 25, Loss: 0.145594984292984, Lr:0.0001\n",
      "Epoch 7, Step: 26, Loss: 0.09253638237714767, Lr:0.0001\n",
      "Epoch 7, Step: 27, Loss: 0.07142499834299088, Lr:0.0001\n",
      "Epoch 7, Step: 28, Loss: 0.11127978563308716, Lr:0.0001\n",
      "Epoch 7, Step: 29, Loss: 0.2185763716697693, Lr:0.0001\n",
      "Epoch 7, Step: 30, Loss: 0.10714655369520187, Lr:0.0001\n",
      "Epoch 7, Step: 31, Loss: 0.06602536141872406, Lr:0.0001\n",
      "Epoch 7, Step: 32, Loss: 0.17526675760746002, Lr:0.0001\n",
      "Epoch 7, Step: 33, Loss: 0.21812313795089722, Lr:0.0001\n",
      "Epoch 7, Step: 34, Loss: 0.11748894304037094, Lr:0.0001\n",
      "Epoch 7, Step: 35, Loss: 0.04431811347603798, Lr:0.0001\n",
      "Epoch 7, Step: 36, Loss: 0.08580825477838516, Lr:0.0001\n",
      "Epoch 7, Step: 37, Loss: 0.03799431025981903, Lr:0.0001\n",
      "Epoch 7, Step: 38, Loss: 0.07736586034297943, Lr:0.0001\n",
      "Epoch 7, Step: 39, Loss: 0.161405548453331, Lr:0.0001\n",
      "Epoch 7, Step: 40, Loss: 0.31574711203575134, Lr:0.0001\n",
      "Epoch 7, Step: 41, Loss: 0.17048168182373047, Lr:0.0001\n",
      "Epoch 7, Step: 42, Loss: 0.07491853088140488, Lr:0.0001\n",
      "Epoch 7, Step: 43, Loss: 0.2431793361902237, Lr:0.0001\n",
      "Epoch 7, Step: 44, Loss: 0.2718963623046875, Lr:0.0001\n",
      "Epoch 7, Step: 45, Loss: 0.47099485993385315, Lr:0.0001\n",
      "Epoch 7, Step: 46, Loss: 0.10643397271633148, Lr:0.0001\n",
      "Epoch 7, Step: 47, Loss: 0.3106590509414673, Lr:0.0001\n",
      "Epoch 7, Step: 48, Loss: 0.09865345805883408, Lr:0.0001\n",
      "Epoch 7, Step: 49, Loss: 0.2063375562429428, Lr:0.0001\n",
      "Epoch 7, Step: 50, Loss: 0.10227303206920624, Lr:0.0001\n",
      "Epoch 7, Step: 51, Loss: 0.2536250054836273, Lr:0.0001\n",
      "Epoch 7, Step: 52, Loss: 0.06355467438697815, Lr:0.0001\n",
      "Epoch 7, Step: 53, Loss: 0.09622036665678024, Lr:0.0001\n",
      "Epoch 7, Step: 54, Loss: 0.08357178419828415, Lr:0.0001\n",
      "Epoch 7, Step: 55, Loss: 0.32995063066482544, Lr:0.0001\n",
      "Epoch 7, Step: 56, Loss: 0.1537071317434311, Lr:0.0001\n",
      "Epoch 7, Step: 57, Loss: 0.40852025151252747, Lr:0.0001\n",
      "Epoch 7, Step: 58, Loss: 0.2204871028661728, Lr:0.0001\n",
      "Epoch 7, Step: 59, Loss: 0.12124032527208328, Lr:0.0001\n",
      "Epoch 7, Step: 60, Loss: 0.6100355386734009, Lr:0.0001\n",
      "Epoch 7, Step: 61, Loss: 0.10435733199119568, Lr:0.0001\n",
      "Epoch 7, Step: 62, Loss: 0.06182149052619934, Lr:0.0001\n",
      "Epoch 7, Step: 63, Loss: 0.2807319164276123, Lr:0.0001\n",
      "Epoch 7, Step: 64, Loss: 0.3134930729866028, Lr:0.0001\n",
      "Epoch 7, Step: 65, Loss: 0.11686765402555466, Lr:0.0001\n",
      "Epoch 7, Step: 66, Loss: 0.17618423700332642, Lr:0.0001\n",
      "Epoch 7, Step: 67, Loss: 0.19222389161586761, Lr:0.0001\n",
      "Epoch 7, Step: 68, Loss: 0.27963846921920776, Lr:0.0001\n",
      "Epoch 7, Step: 69, Loss: 0.12899982929229736, Lr:0.0001\n",
      "Epoch 7, Step: 70, Loss: 0.21569231152534485, Lr:0.0001\n",
      "Epoch 7, Step: 71, Loss: 0.3089669644832611, Lr:0.0001\n",
      "Epoch 7, Step: 72, Loss: 0.14101837575435638, Lr:0.0001\n",
      "Epoch 7, Step: 73, Loss: 0.019413437694311142, Lr:0.0001\n",
      "Epoch 7, Step: 74, Loss: 0.07146719098091125, Lr:0.0001\n",
      "Epoch 7, Step: 75, Loss: 0.2925942838191986, Lr:0.0001\n",
      "Epoch 7, Step: 76, Loss: 0.35061684250831604, Lr:0.0001\n",
      "Epoch 7, Step: 77, Loss: 0.36008724570274353, Lr:0.0001\n",
      "Epoch 7, Step: 78, Loss: 0.12508125603199005, Lr:0.0001\n",
      "Epoch 7, Step: 79, Loss: 0.20290228724479675, Lr:0.0001\n",
      "Epoch 7, Step: 80, Loss: 0.33425745368003845, Lr:0.0001\n",
      "Epoch 7, Step: 81, Loss: 0.1195848137140274, Lr:0.0001\n",
      "Epoch 7, Step: 82, Loss: 0.0469064936041832, Lr:0.0001\n",
      "Epoch 7, Step: 83, Loss: 0.17676909267902374, Lr:0.0001\n",
      "Epoch 7, Step: 84, Loss: 0.2619592547416687, Lr:0.0001\n",
      "Epoch 7, Step: 85, Loss: 0.0861879289150238, Lr:0.0001\n",
      "Epoch 7, Step: 86, Loss: 0.03707306832075119, Lr:0.0001\n",
      "Epoch 7, Step: 87, Loss: 0.18725602328777313, Lr:0.0001\n",
      "Epoch 7, Step: 88, Loss: 0.11446891725063324, Lr:0.0001\n",
      "Epoch 7, Step: 89, Loss: 0.12637262046337128, Lr:0.0001\n",
      "Epoch 7, Step: 90, Loss: 0.2117336392402649, Lr:0.0001\n",
      "Epoch 7, Step: 91, Loss: 0.21445028483867645, Lr:0.0001\n",
      "Epoch 7, Step: 92, Loss: 0.10030236095190048, Lr:0.0001\n",
      "Epoch 7, Step: 93, Loss: 0.058817703276872635, Lr:0.0001\n",
      "Epoch 7, Step: 94, Loss: 0.025161199271678925, Lr:0.0001\n",
      "Epoch 7, Step: 95, Loss: 0.09523914009332657, Lr:0.0001\n",
      "Epoch 7, Step: 96, Loss: 0.15689297020435333, Lr:0.0001\n",
      "Epoch 7, Step: 97, Loss: 0.20664216578006744, Lr:0.0001\n",
      "Epoch 7, Step: 98, Loss: 0.15860441327095032, Lr:0.0001\n",
      "Epoch 7, Step: 99, Loss: 0.09779567271471024, Lr:0.0001\n",
      "Epoch 7, Step: 100, Loss: 0.2558232247829437, Lr:0.0001\n",
      "Epoch 7, Step: 101, Loss: 0.37139448523521423, Lr:0.0001\n",
      "Epoch 7, Step: 102, Loss: 0.054793186485767365, Lr:0.0001\n",
      "Epoch 7, Step: 103, Loss: 0.2522374093532562, Lr:0.0001\n",
      "Epoch 7, Step: 104, Loss: 0.09585694223642349, Lr:0.0001\n",
      "Epoch 7, Step: 105, Loss: 0.18578355014324188, Lr:0.0001\n",
      "Epoch 7, Step: 106, Loss: 0.29633164405822754, Lr:0.0001\n",
      "Epoch 7, Step: 107, Loss: 0.45944756269454956, Lr:0.0001\n",
      "Epoch 7, Step: 108, Loss: 0.10898672044277191, Lr:0.0001\n",
      "Epoch 7, Step: 109, Loss: 0.027606826275587082, Lr:0.0001\n",
      "Epoch 7, Step: 110, Loss: 0.13440363109111786, Lr:0.0001\n",
      "Epoch 7, Step: 111, Loss: 0.16668060421943665, Lr:0.0001\n",
      "Epoch 7, Step: 112, Loss: 0.10207211226224899, Lr:0.0001\n",
      "Epoch 7, Step: 113, Loss: 0.2379792481660843, Lr:0.0001\n",
      "Epoch 7, Step: 114, Loss: 0.09758975356817245, Lr:0.0001\n",
      "Epoch 7, Step: 115, Loss: 0.07896974682807922, Lr:0.0001\n",
      "Epoch 7, Step: 116, Loss: 0.3594413995742798, Lr:0.0001\n",
      "Epoch 7, Step: 117, Loss: 0.29961180686950684, Lr:0.0001\n",
      "Epoch 7, Step: 118, Loss: 0.006477569229900837, Lr:0.0001\n",
      "Epoch 7, Step: 119, Loss: 0.08151086419820786, Lr:0.0001\n",
      "Epoch 7, Step: 120, Loss: 0.32478269934654236, Lr:0.0001\n",
      "Epoch 7, Step: 121, Loss: 0.2782119810581207, Lr:0.0001\n",
      "Epoch 7, Step: 122, Loss: 0.2019508332014084, Lr:0.0001\n",
      "Epoch 7, Step: 123, Loss: 0.18622621893882751, Lr:0.0001\n",
      "Epoch 7, Step: 124, Loss: 0.6533889174461365, Lr:0.0001\n",
      "Epoch 7, Step: 125, Loss: 0.15827657282352448, Lr:0.0001\n",
      "Epoch 7, Step: 126, Loss: 0.2371797263622284, Lr:0.0001\n",
      "Epoch 7, Step: 127, Loss: 0.05426272004842758, Lr:0.0001\n",
      "Epoch 7, Step: 128, Loss: 0.1073179841041565, Lr:0.0001\n",
      "Epoch 7, Step: 129, Loss: 0.11696410924196243, Lr:0.0001\n",
      "Epoch 7, Step: 130, Loss: 0.20996659994125366, Lr:0.0001\n",
      "Epoch 7, Step: 131, Loss: 0.13745759427547455, Lr:0.0001\n",
      "Epoch 7, Step: 132, Loss: 0.0708051472902298, Lr:0.0001\n",
      "Epoch 7, Step: 133, Loss: 0.11523230373859406, Lr:0.0001\n",
      "Epoch 7, Step: 134, Loss: 0.543770968914032, Lr:0.0001\n",
      "Epoch 7, Step: 135, Loss: 0.10254817456007004, Lr:0.0001\n",
      "Epoch 7, Step: 136, Loss: 0.1555723249912262, Lr:0.0001\n",
      "Epoch 7, Step: 137, Loss: 0.4573269784450531, Lr:0.0001\n",
      "Epoch 7, Step: 138, Loss: 0.14362703263759613, Lr:0.0001\n",
      "Epoch 7, Step: 139, Loss: 0.3571307361125946, Lr:0.0001\n",
      "Epoch 7, Step: 140, Loss: 0.1165362000465393, Lr:0.0001\n",
      "Epoch 7, Step: 141, Loss: 0.19353142380714417, Lr:0.0001\n",
      "Epoch 7, Step: 142, Loss: 0.07647828757762909, Lr:0.0001\n",
      "Epoch 7, Step: 143, Loss: 0.08572285622358322, Lr:0.0001\n",
      "Epoch 7, Step: 144, Loss: 0.05437459796667099, Lr:0.0001\n",
      "Epoch 7, Step: 145, Loss: 0.3154623508453369, Lr:0.0001\n",
      "Epoch 7, Step: 146, Loss: 0.01951098069548607, Lr:0.0001\n",
      "Epoch 7, Step: 147, Loss: 0.1946583092212677, Lr:0.0001\n",
      "Epoch 7, Step: 148, Loss: 0.10125879943370819, Lr:0.0001\n",
      "Epoch 7, Step: 149, Loss: 0.18739165365695953, Lr:0.0001\n",
      "Epoch 7, Step: 150, Loss: 0.04073217883706093, Lr:0.0001\n",
      "Epoch 7, Step: 151, Loss: 0.036374256014823914, Lr:0.0001\n",
      "Epoch 7, Step: 152, Loss: 0.1186118796467781, Lr:0.0001\n",
      "Epoch 7, Step: 153, Loss: 0.1928524225950241, Lr:0.0001\n",
      "Epoch 7, Step: 154, Loss: 0.46925637125968933, Lr:0.0001\n",
      "Epoch 7, Step: 155, Loss: 0.2146628499031067, Lr:0.0001\n",
      "Epoch 7, Step: 156, Loss: 0.13672176003456116, Lr:0.0001\n",
      "Epoch 7, Step: 157, Loss: 0.15048882365226746, Lr:0.0001\n",
      "Epoch 7, Step: 158, Loss: 0.054882798343896866, Lr:0.0001\n",
      "Epoch 7, Step: 159, Loss: 0.09092067182064056, Lr:0.0001\n",
      "Epoch 7, Step: 160, Loss: 0.2841108441352844, Lr:0.0001\n",
      "Epoch 7, Step: 161, Loss: 0.06000573933124542, Lr:0.0001\n",
      "Epoch 7, Step: 162, Loss: 0.06513012200593948, Lr:0.0001\n",
      "Epoch 7, Step: 163, Loss: 0.40176060795783997, Lr:0.0001\n",
      "Epoch 7, Step: 164, Loss: 0.40550607442855835, Lr:0.0001\n",
      "Epoch 7, Step: 165, Loss: 0.09646003693342209, Lr:0.0001\n",
      "Epoch 7, Step: 166, Loss: 0.2752099335193634, Lr:0.0001\n",
      "Epoch 7, Step: 167, Loss: 0.23151424527168274, Lr:0.0001\n",
      "Epoch 7, Step: 168, Loss: 0.14022770524024963, Lr:0.0001\n",
      "Epoch 7, Step: 169, Loss: 0.08284430205821991, Lr:0.0001\n",
      "Epoch 7, Step: 170, Loss: 0.01264934241771698, Lr:0.0001\n",
      "Epoch 7, Step: 171, Loss: 0.25933799147605896, Lr:0.0001\n",
      "Epoch 7, Step: 172, Loss: 0.1853158175945282, Lr:0.0001\n",
      "Epoch 7, Step: 173, Loss: 0.2352268248796463, Lr:0.0001\n",
      "Epoch 7, Step: 174, Loss: 0.1895378679037094, Lr:0.0001\n",
      "Epoch 7, Step: 175, Loss: 0.050718195736408234, Lr:0.0001\n",
      "Epoch 7, Step: 176, Loss: 0.04903436079621315, Lr:0.0001\n",
      "Epoch 7, Step: 177, Loss: 0.059640541672706604, Lr:0.0001\n",
      "Epoch 7, Step: 178, Loss: 0.18104353547096252, Lr:0.0001\n",
      "Epoch 7, Step: 179, Loss: 0.2475183755159378, Lr:0.0001\n",
      "Epoch 7, Step: 180, Loss: 0.11085624247789383, Lr:0.0001\n",
      "Epoch 7, Step: 181, Loss: 0.16053694486618042, Lr:0.0001\n",
      "Epoch 7, Step: 182, Loss: 0.33322933316230774, Lr:0.0001\n",
      "Epoch 7, Step: 183, Loss: 0.10666057467460632, Lr:0.0001\n",
      "Epoch 7, Step: 184, Loss: 0.02814898081123829, Lr:0.0001\n",
      "Epoch 7, Step: 185, Loss: 0.05583195760846138, Lr:0.0001\n",
      "Epoch 7, Step: 186, Loss: 0.4045848846435547, Lr:0.0001\n",
      "Epoch 7, Step: 187, Loss: 0.09727494418621063, Lr:0.0001\n",
      "Epoch 7, Step: 188, Loss: 0.07324410229921341, Lr:0.0001\n",
      "Epoch 7, Step: 189, Loss: 0.2840041220188141, Lr:0.0001\n",
      "Epoch 7, Step: 190, Loss: 0.11609749495983124, Lr:0.0001\n",
      "Epoch 7, Step: 191, Loss: 0.1027991846203804, Lr:0.0001\n",
      "Epoch 7, Step: 192, Loss: 0.1388191431760788, Lr:0.0001\n",
      "Epoch 7, Step: 193, Loss: 0.31383559107780457, Lr:0.0001\n",
      "Epoch 7, Step: 194, Loss: 0.43067580461502075, Lr:0.0001\n",
      "Epoch 7, Step: 195, Loss: 0.07691971212625504, Lr:0.0001\n",
      "Epoch 7, Step: 196, Loss: 0.5576663613319397, Lr:0.0001\n",
      "Epoch 7, Step: 197, Loss: 0.2759920656681061, Lr:0.0001\n",
      "Epoch 7, Step: 198, Loss: 0.40851080417633057, Lr:0.0001\n",
      "Epoch 7, Step: 199, Loss: 0.0891028493642807, Lr:0.0001\n",
      "Epoch 7, Step: 200, Loss: 0.16517511010169983, Lr:0.0001\n",
      "Epoch 7, Step: 201, Loss: 0.28163036704063416, Lr:0.0001\n",
      "Epoch 7, Step: 202, Loss: 0.18101392686367035, Lr:0.0001\n",
      "Epoch 7, Step: 203, Loss: 0.2751495838165283, Lr:0.0001\n",
      "Epoch 7, Step: 204, Loss: 0.09693753719329834, Lr:0.0001\n",
      "Epoch 7, Step: 205, Loss: 0.12747037410736084, Lr:0.0001\n",
      "Epoch 7, Step: 206, Loss: 0.21104273200035095, Lr:0.0001\n",
      "Epoch 7, Step: 207, Loss: 0.0941348522901535, Lr:0.0001\n",
      "Epoch 7, Step: 208, Loss: 0.3404999077320099, Lr:0.0001\n",
      "Epoch 7, Step: 209, Loss: 0.1576918661594391, Lr:0.0001\n",
      "Epoch 7, Step: 210, Loss: 0.1858791708946228, Lr:0.0001\n",
      "Epoch 7, Step: 211, Loss: 0.12075189501047134, Lr:0.0001\n",
      "Epoch 7, Step: 212, Loss: 0.05289224907755852, Lr:0.0001\n",
      "Epoch 7, Step: 213, Loss: 0.4324248731136322, Lr:0.0001\n",
      "Epoch 7, Step: 214, Loss: 0.4637685716152191, Lr:0.0001\n",
      "Epoch 7, Step: 215, Loss: 0.06658530235290527, Lr:0.0001\n",
      "Epoch 7, Step: 216, Loss: 0.2322872281074524, Lr:0.0001\n",
      "Epoch 7, Step: 217, Loss: 0.05263802781701088, Lr:0.0001\n",
      "Epoch 7, Step: 218, Loss: 0.3282170295715332, Lr:0.0001\n",
      "Epoch 7, Step: 219, Loss: 0.16240085661411285, Lr:0.0001\n",
      "Epoch 7, Step: 220, Loss: 0.06691969186067581, Lr:0.0001\n",
      "Epoch 7, Step: 221, Loss: 0.1591169238090515, Lr:0.0001\n",
      "Epoch 7, Step: 222, Loss: 0.38051873445510864, Lr:0.0001\n",
      "Epoch 7, Step: 223, Loss: 0.07313036918640137, Lr:0.0001\n",
      "Epoch 7, Step: 224, Loss: 0.8236693143844604, Lr:0.0001\n",
      "Epoch 7, Step: 225, Loss: 0.21529845893383026, Lr:0.0001\n",
      "Epoch 7, Step: 226, Loss: 0.24390825629234314, Lr:0.0001\n",
      "Epoch 7, Step: 227, Loss: 0.0466059148311615, Lr:0.0001\n",
      "Epoch 7, Step: 228, Loss: 0.16251137852668762, Lr:0.0001\n",
      "Epoch 7, Step: 229, Loss: 0.22756262123584747, Lr:0.0001\n",
      "Epoch 7, Step: 230, Loss: 0.05539210885763168, Lr:0.0001\n",
      "Epoch 7, Step: 231, Loss: 0.13050581514835358, Lr:0.0001\n",
      "Epoch 7, Step: 232, Loss: 0.14412063360214233, Lr:0.0001\n",
      "Epoch 7, Step: 233, Loss: 0.16333141922950745, Lr:0.0001\n",
      "Epoch 7, Step: 234, Loss: 0.11601701378822327, Lr:0.0001\n",
      "Epoch 7, Step: 235, Loss: 0.061888687312603, Lr:0.0001\n",
      "Epoch 7, Step: 236, Loss: 0.351811021566391, Lr:0.0001\n",
      "Epoch 7, Step: 237, Loss: 0.020903022959828377, Lr:0.0001\n",
      "Epoch 7, Step: 238, Loss: 0.24033226072788239, Lr:0.0001\n",
      "Epoch 7, Step: 239, Loss: 0.10801399499177933, Lr:0.0001\n",
      "Epoch 7, Step: 240, Loss: 0.37947770953178406, Lr:0.0001\n",
      "Epoch 7, Step: 241, Loss: 0.13015027344226837, Lr:0.0001\n",
      "Epoch 7, Step: 242, Loss: 0.1659693717956543, Lr:0.0001\n",
      "Epoch 7, Step: 243, Loss: 0.11643059551715851, Lr:0.0001\n",
      "Epoch 7, Step: 244, Loss: 0.1422155797481537, Lr:0.0001\n",
      "Epoch 7, Step: 245, Loss: 0.11572204530239105, Lr:0.0001\n",
      "Epoch 7, Step: 246, Loss: 0.053923819214105606, Lr:0.0001\n",
      "Epoch 7, Step: 247, Loss: 0.15333004295825958, Lr:0.0001\n",
      "Epoch 7, Step: 248, Loss: 0.08668777346611023, Lr:0.0001\n",
      "Epoch 7, Step: 249, Loss: 0.06856213510036469, Lr:0.0001\n",
      "Epoch 7, Step: 250, Loss: 0.07943099737167358, Lr:0.0001\n",
      "Epoch 7, Step: 251, Loss: 0.2836727201938629, Lr:0.0001\n",
      "Epoch 7, Step: 252, Loss: 0.07808287441730499, Lr:0.0001\n",
      "Epoch 7, Step: 253, Loss: 0.16936689615249634, Lr:0.0001\n",
      "Epoch 7, Step: 254, Loss: 0.03696063533425331, Lr:0.0001\n",
      "Epoch 7, Step: 255, Loss: 0.10629895329475403, Lr:0.0001\n",
      "Epoch 7, Step: 256, Loss: 0.030797867104411125, Lr:0.0001\n",
      "Epoch 7, Step: 257, Loss: 0.19089892506599426, Lr:0.0001\n",
      "Epoch 7, Step: 258, Loss: 0.19184257090091705, Lr:0.0001\n",
      "Epoch 7, Step: 259, Loss: 0.27686604857444763, Lr:0.0001\n",
      "Epoch 7, Step: 260, Loss: 0.014804467558860779, Lr:0.0001\n",
      "Epoch 7, Step: 261, Loss: 0.07757726311683655, Lr:0.0001\n",
      "Epoch 7, Step: 262, Loss: 0.25199776887893677, Lr:0.0001\n",
      "Epoch 7, Step: 263, Loss: 0.13874243199825287, Lr:0.0001\n",
      "Epoch 7, Step: 264, Loss: 0.539600670337677, Lr:0.0001\n",
      "Epoch 7, Step: 265, Loss: 0.017014484852552414, Lr:0.0001\n",
      "Epoch 7, Step: 266, Loss: 0.0777512714266777, Lr:0.0001\n",
      "Epoch 7, Step: 267, Loss: 0.11810695379972458, Lr:0.0001\n",
      "Epoch 7, Step: 268, Loss: 0.18914982676506042, Lr:0.0001\n",
      "Epoch 7, Step: 269, Loss: 0.49443304538726807, Lr:0.0001\n",
      "Epoch 7, Step: 270, Loss: 0.18165451288223267, Lr:0.0001\n",
      "Epoch 7, Step: 271, Loss: 0.13809828460216522, Lr:0.0001\n",
      "Epoch 7, Step: 272, Loss: 0.13837577402591705, Lr:0.0001\n",
      "Epoch 7, Step: 273, Loss: 0.23895061016082764, Lr:0.0001\n",
      "Epoch 7, Step: 274, Loss: 0.18267686665058136, Lr:0.0001\n",
      "Epoch 7, Step: 275, Loss: 0.12685734033584595, Lr:0.0001\n",
      "Epoch 7, Step: 276, Loss: 0.013183443807065487, Lr:0.0001\n",
      "Epoch 7, Step: 277, Loss: 0.17146094143390656, Lr:0.0001\n",
      "Epoch 7, Step: 278, Loss: 0.24807259440422058, Lr:0.0001\n",
      "Epoch 7, Step: 279, Loss: 0.13929058611392975, Lr:0.0001\n",
      "Epoch 7, Step: 280, Loss: 0.33278000354766846, Lr:0.0001\n",
      "Epoch 7, Step: 281, Loss: 0.39695045351982117, Lr:0.0001\n",
      "Epoch 7, Step: 282, Loss: 0.05623709410429001, Lr:0.0001\n",
      "Epoch 7, Step: 283, Loss: 0.06421280652284622, Lr:0.0001\n",
      "Epoch 7, Step: 284, Loss: 0.16013303399085999, Lr:0.0001\n",
      "Epoch 7, Step: 285, Loss: 0.13814139366149902, Lr:0.0001\n",
      "Epoch 7, Step: 286, Loss: 0.0828535258769989, Lr:0.0001\n",
      "Epoch 7, Step: 287, Loss: 0.4639014005661011, Lr:0.0001\n",
      "Epoch 7, Step: 288, Loss: 0.03785831108689308, Lr:0.0001\n",
      "Epoch 7, Step: 289, Loss: 0.12710893154144287, Lr:0.0001\n",
      "Epoch 7, Step: 290, Loss: 0.22799736261367798, Lr:0.0001\n",
      "Epoch 7, Step: 291, Loss: 0.25374671816825867, Lr:0.0001\n",
      "Epoch 7, Step: 292, Loss: 0.04020238295197487, Lr:0.0001\n",
      "Epoch 7, Step: 293, Loss: 0.04812541976571083, Lr:0.0001\n",
      "Epoch 7, Step: 294, Loss: 0.36288660764694214, Lr:0.0001\n",
      "Epoch 7, Step: 295, Loss: 0.17841821908950806, Lr:0.0001\n",
      "Epoch 7, Step: 296, Loss: 0.1774752289056778, Lr:0.0001\n",
      "Epoch 7, Step: 297, Loss: 0.19241292774677277, Lr:0.0001\n",
      "Epoch 7, Step: 298, Loss: 0.3235388994216919, Lr:0.0001\n",
      "Epoch 7, Step: 299, Loss: 0.2705160081386566, Lr:0.0001\n",
      "Epoch 7, Step: 300, Loss: 0.23728416860103607, Lr:0.0001\n",
      "Epoch 7, Step: 301, Loss: 0.3425180912017822, Lr:0.0001\n",
      "Epoch 7, Step: 302, Loss: 0.23213881254196167, Lr:0.0001\n",
      "Epoch 7, Step: 303, Loss: 0.4706445038318634, Lr:0.0001\n",
      "Epoch 7, Step: 304, Loss: 0.22409921884536743, Lr:0.0001\n",
      "Epoch 7, Step: 305, Loss: 0.04239226132631302, Lr:0.0001\n",
      "Epoch 7, Step: 306, Loss: 0.2631288468837738, Lr:0.0001\n",
      "Epoch 7, Step: 307, Loss: 0.10884469747543335, Lr:0.0001\n",
      "Epoch 7, Step: 308, Loss: 0.08357372134923935, Lr:0.0001\n",
      "Epoch 7, Step: 309, Loss: 0.20219501852989197, Lr:0.0001\n",
      "Epoch 7, Step: 310, Loss: 0.22681134939193726, Lr:0.0001\n",
      "Epoch 7, Step: 311, Loss: 0.37086567282676697, Lr:0.0001\n",
      "Epoch 7, Step: 312, Loss: 0.27275657653808594, Lr:0.0001\n",
      "Epoch 7, Step: 313, Loss: 0.2648639678955078, Lr:0.0001\n",
      "Epoch 7, Step: 314, Loss: 0.4494890868663788, Lr:0.0001\n",
      "Epoch 7, Step: 315, Loss: 0.25352421402931213, Lr:0.0001\n",
      "Epoch 7, Step: 316, Loss: 0.09427718073129654, Lr:0.0001\n",
      "Epoch 7, Step: 317, Loss: 0.679273247718811, Lr:0.0001\n",
      "Epoch 7, Step: 318, Loss: 0.2666027247905731, Lr:0.0001\n",
      "Epoch 7, Step: 319, Loss: 0.5032623410224915, Lr:0.0001\n",
      "Epoch 7, Step: 320, Loss: 0.10429824888706207, Lr:0.0001\n",
      "Epoch 7, Step: 321, Loss: 0.17723298072814941, Lr:0.0001\n",
      "Epoch 7, Step: 322, Loss: 0.07568461447954178, Lr:0.0001\n",
      "Epoch 7, Step: 323, Loss: 0.21369613707065582, Lr:0.0001\n",
      "Epoch 7, Step: 324, Loss: 0.12263597548007965, Lr:0.0001\n",
      "Epoch 7, Step: 325, Loss: 0.12308771908283234, Lr:0.0001\n",
      "Epoch 7, Step: 326, Loss: 0.0716533362865448, Lr:0.0001\n",
      "Epoch 7, Step: 327, Loss: 0.24357885122299194, Lr:0.0001\n",
      "Epoch 7, Step: 328, Loss: 0.5562909841537476, Lr:0.0001\n",
      "Epoch 7, Step: 329, Loss: 0.13877125084400177, Lr:0.0001\n",
      "Epoch 7, Step: 330, Loss: 0.3372178077697754, Lr:0.0001\n",
      "Epoch 7, Step: 331, Loss: 0.20980624854564667, Lr:0.0001\n",
      "Epoch 7, Step: 332, Loss: 0.15446078777313232, Lr:0.0001\n",
      "Epoch 7, Step: 333, Loss: 0.24515996873378754, Lr:0.0001\n",
      "Epoch 7, Step: 334, Loss: 0.15097549557685852, Lr:0.0001\n",
      "Epoch 7, Step: 335, Loss: 0.14100760221481323, Lr:0.0001\n",
      "Epoch 7, Step: 336, Loss: 0.21257764101028442, Lr:0.0001\n",
      "Epoch 7, Step: 337, Loss: 0.19551047682762146, Lr:0.0001\n",
      "Epoch 7, Step: 338, Loss: 0.32672688364982605, Lr:0.0001\n",
      "Epoch 7, Step: 339, Loss: 0.04797811433672905, Lr:0.0001\n",
      "Epoch 7, Step: 340, Loss: 0.2954479455947876, Lr:0.0001\n",
      "Epoch 7, Step: 341, Loss: 0.20673218369483948, Lr:0.0001\n",
      "Epoch 7, Step: 342, Loss: 0.11763464659452438, Lr:0.0001\n",
      "Epoch 7, Step: 343, Loss: 0.11588280647993088, Lr:0.0001\n",
      "Epoch 7, Step: 344, Loss: 0.05329466238617897, Lr:0.0001\n",
      "Epoch 7, Step: 345, Loss: 0.3107586205005646, Lr:0.0001\n",
      "Epoch 7, Step: 346, Loss: 0.13746672868728638, Lr:0.0001\n",
      "Epoch 7, Step: 347, Loss: 0.18674471974372864, Lr:0.0001\n",
      "Epoch 7, Step: 348, Loss: 0.4183954894542694, Lr:0.0001\n",
      "Epoch 7, Step: 349, Loss: 0.2579488158226013, Lr:0.0001\n",
      "Epoch 7, Step: 350, Loss: 0.22949443757534027, Lr:0.0001\n",
      "Epoch 7, Step: 351, Loss: 0.2192317396402359, Lr:0.0001\n",
      "Epoch 7, Step: 352, Loss: 0.04688365012407303, Lr:0.0001\n",
      "Epoch 7, Step: 353, Loss: 0.145233154296875, Lr:0.0001\n",
      "Epoch 7, Step: 354, Loss: 0.1962994933128357, Lr:0.0001\n",
      "Epoch 7, Step: 355, Loss: 0.34380605816841125, Lr:0.0001\n",
      "Epoch 7, Step: 356, Loss: 0.3687680959701538, Lr:0.0001\n",
      "Epoch 7, Step: 357, Loss: 0.1837846040725708, Lr:0.0001\n",
      "Epoch 7, Step: 358, Loss: 0.1226973906159401, Lr:0.0001\n",
      "Epoch 7, Step: 359, Loss: 0.10693978518247604, Lr:0.0001\n",
      "Epoch 7, Step: 360, Loss: 0.1422189623117447, Lr:0.0001\n",
      "Epoch 7, Step: 361, Loss: 0.3496318459510803, Lr:0.0001\n",
      "Epoch 7, Step: 362, Loss: 0.25570398569107056, Lr:0.0001\n",
      "Epoch 7, Step: 363, Loss: 0.07153210043907166, Lr:0.0001\n",
      "Epoch 7, Step: 364, Loss: 0.023034468293190002, Lr:0.0001\n",
      "Epoch 7, Step: 365, Loss: 0.3520509600639343, Lr:0.0001\n",
      "Epoch 7, Step: 366, Loss: 0.138016939163208, Lr:0.0001\n",
      "Epoch 7, Step: 367, Loss: 0.29906365275382996, Lr:0.0001\n",
      "Epoch 7, Step: 368, Loss: 0.461361825466156, Lr:0.0001\n",
      "Epoch 7, Step: 369, Loss: 0.28017646074295044, Lr:0.0001\n",
      "Epoch 7, Step: 370, Loss: 0.16263122856616974, Lr:0.0001\n",
      "Epoch 7, Step: 371, Loss: 0.2852383255958557, Lr:0.0001\n",
      "Epoch 7, Step: 372, Loss: 0.26986876130104065, Lr:0.0001\n",
      "Epoch 7, Step: 373, Loss: 0.2873189151287079, Lr:0.0001\n",
      "Epoch 7, Step: 374, Loss: 0.11290193349123001, Lr:0.0001\n",
      "Epoch 7, Step: 375, Loss: 0.10841918736696243, Lr:0.0001\n",
      "Epoch 7, Step: 376, Loss: 0.02317226119339466, Lr:0.0001\n",
      "Epoch 7, Step: 377, Loss: 0.156614750623703, Lr:0.0001\n",
      "Epoch 7, Step: 378, Loss: 0.09634187072515488, Lr:0.0001\n",
      "Epoch 7, Step: 379, Loss: 0.07040543854236603, Lr:0.0001\n",
      "Epoch 7, Step: 380, Loss: 0.08614634722471237, Lr:0.0001\n",
      "Epoch 7, Step: 381, Loss: 0.020513758063316345, Lr:0.0001\n",
      "Epoch 7, Step: 382, Loss: 0.41779130697250366, Lr:0.0001\n",
      "Epoch 7, Step: 383, Loss: 0.056787651032209396, Lr:0.0001\n",
      "Epoch 7, Step: 384, Loss: 0.5309667587280273, Lr:0.0001\n",
      "Epoch 7, Step: 385, Loss: 0.09909327328205109, Lr:0.0001\n",
      "Epoch 7, Step: 386, Loss: 0.244430273771286, Lr:0.0001\n",
      "Epoch 7, Step: 387, Loss: 0.105034239590168, Lr:0.0001\n",
      "Epoch 7, Step: 388, Loss: 0.05696311593055725, Lr:0.0001\n",
      "Epoch 7, Step: 389, Loss: 0.3513247072696686, Lr:0.0001\n",
      "Epoch 7, Step: 390, Loss: 0.21800461411476135, Lr:0.0001\n",
      "Epoch 7, Step: 391, Loss: 0.16395023465156555, Lr:0.0001\n",
      "Epoch 7, Step: 392, Loss: 0.41172364354133606, Lr:0.0001\n",
      "Epoch 7, Step: 393, Loss: 0.14478807151317596, Lr:0.0001\n",
      "Epoch 7, Step: 394, Loss: 0.0668298527598381, Lr:0.0001\n",
      "Epoch 7, Step: 395, Loss: 0.08537987619638443, Lr:0.0001\n",
      "Epoch 7, Step: 396, Loss: 0.08466678112745285, Lr:0.0001\n",
      "Epoch 7, Step: 397, Loss: 0.12590330839157104, Lr:0.0001\n",
      "Epoch 7, Step: 398, Loss: 0.0987502783536911, Lr:0.0001\n",
      "Epoch 7, Step: 399, Loss: 0.10287868976593018, Lr:0.0001\n",
      "Epoch 7, Step: 400, Loss: 0.04501214250922203, Lr:0.0001\n",
      "Epoch 7, Step: 401, Loss: 0.07734743505716324, Lr:0.0001\n",
      "Epoch 7, Step: 402, Loss: 0.35473889112472534, Lr:0.0001\n",
      "Epoch 7, Step: 403, Loss: 0.521393358707428, Lr:0.0001\n",
      "Epoch 7, Step: 404, Loss: 0.1672613024711609, Lr:0.0001\n",
      "Epoch 7, Step: 405, Loss: 0.16065005958080292, Lr:0.0001\n",
      "Epoch 7, Step: 406, Loss: 0.32077473402023315, Lr:0.0001\n",
      "Epoch 7, Step: 407, Loss: 0.051592785865068436, Lr:0.0001\n",
      "Epoch 7, Step: 408, Loss: 0.3481805622577667, Lr:0.0001\n",
      "Epoch 7, Step: 409, Loss: 0.34626659750938416, Lr:0.0001\n",
      "Epoch 7, Step: 410, Loss: 0.11706414073705673, Lr:0.0001\n",
      "Epoch 7, Step: 411, Loss: 0.1381617784500122, Lr:0.0001\n",
      "Epoch 7, Step: 412, Loss: 0.2972574532032013, Lr:0.0001\n",
      "Epoch 7, Step: 413, Loss: 0.049312446266412735, Lr:0.0001\n",
      "Epoch 7, Step: 414, Loss: 0.20306746661663055, Lr:0.0001\n",
      "Epoch 7, Step: 415, Loss: 0.0959114208817482, Lr:0.0001\n",
      "Epoch 7, Step: 416, Loss: 0.1624571979045868, Lr:0.0001\n",
      "Epoch 7, Step: 417, Loss: 0.1169378012418747, Lr:0.0001\n",
      "Epoch 7, Step: 418, Loss: 0.132315531373024, Lr:0.0001\n",
      "Epoch 7, Step: 419, Loss: 0.045540325343608856, Lr:0.0001\n",
      "Epoch 7, Step: 420, Loss: 0.01349902804940939, Lr:0.0001\n",
      "Epoch 7, Step: 421, Loss: 0.23234307765960693, Lr:0.0001\n",
      "Epoch 7, Step: 422, Loss: 0.2112618237733841, Lr:0.0001\n",
      "Epoch 7, Step: 423, Loss: 0.2053019404411316, Lr:0.0001\n",
      "Epoch 7, Step: 424, Loss: 0.43406182527542114, Lr:0.0001\n",
      "Epoch 7, Step: 425, Loss: 0.26881250739097595, Lr:0.0001\n",
      "Epoch 7, Step: 426, Loss: 0.16685709357261658, Lr:0.0001\n",
      "Epoch 7, Step: 427, Loss: 0.0818127691745758, Lr:0.0001\n",
      "Epoch 7, Step: 428, Loss: 0.18796905875205994, Lr:0.0001\n",
      "Epoch 7, Step: 429, Loss: 0.05576036497950554, Lr:0.0001\n",
      "Epoch 7, Step: 430, Loss: 0.18590369820594788, Lr:0.0001\n",
      "Epoch 7, Step: 431, Loss: 0.10284120589494705, Lr:0.0001\n",
      "Epoch 7, Step: 432, Loss: 0.36078882217407227, Lr:0.0001\n",
      "Epoch 7, Step: 433, Loss: 0.052068911492824554, Lr:0.0001\n",
      "Epoch 7, Step: 434, Loss: 0.2147507667541504, Lr:0.0001\n",
      "Epoch 7, Step: 435, Loss: 0.07263850420713425, Lr:0.0001\n",
      "Epoch 7, Step: 436, Loss: 0.48056235909461975, Lr:0.0001\n",
      "Epoch 7, Step: 437, Loss: 0.026026662439107895, Lr:0.0001\n",
      "Epoch 7, Step: 438, Loss: 0.1338346302509308, Lr:0.0001\n",
      "Epoch 7, Step: 439, Loss: 0.13516682386398315, Lr:0.0001\n",
      "Epoch 7, Step: 440, Loss: 0.170144721865654, Lr:0.0001\n",
      "Epoch 7, Step: 441, Loss: 0.07532046735286713, Lr:0.0001\n",
      "Epoch 7, Step: 442, Loss: 0.15396475791931152, Lr:0.0001\n",
      "Epoch 7, Step: 443, Loss: 0.21482934057712555, Lr:0.0001\n",
      "Epoch 7, Step: 444, Loss: 0.037716761231422424, Lr:0.0001\n",
      "Epoch 7, Step: 445, Loss: 0.09117721021175385, Lr:0.0001\n",
      "Epoch 7, Step: 446, Loss: 0.20382827520370483, Lr:0.0001\n",
      "Epoch 7, Step: 447, Loss: 0.058846235275268555, Lr:0.0001\n",
      "Epoch 7, Step: 448, Loss: 0.2518473267555237, Lr:0.0001\n",
      "Epoch 7, Step: 449, Loss: 0.10704749077558517, Lr:0.0001\n",
      "Epoch 7, Step: 450, Loss: 0.26146388053894043, Lr:0.0001\n",
      "Epoch 7, Step: 451, Loss: 0.08024436235427856, Lr:0.0001\n",
      "Epoch 7, Step: 452, Loss: 0.03434070199728012, Lr:0.0001\n",
      "Epoch 7, Step: 453, Loss: 0.06410061568021774, Lr:0.0001\n",
      "Epoch 7, Step: 454, Loss: 0.040442630648612976, Lr:0.0001\n",
      "Epoch 7, Step: 455, Loss: 0.12282468378543854, Lr:0.0001\n",
      "Epoch 7, Step: 456, Loss: 0.30928879976272583, Lr:0.0001\n",
      "Epoch 7, Step: 457, Loss: 0.19365514814853668, Lr:0.0001\n",
      "Epoch 7, Step: 458, Loss: 0.10964899510145187, Lr:0.0001\n",
      "Epoch 7, Step: 459, Loss: 0.10352300107479095, Lr:0.0001\n",
      "Epoch 7, Step: 460, Loss: 0.27352583408355713, Lr:0.0001\n",
      "Epoch 7, Step: 461, Loss: 0.09245781600475311, Lr:0.0001\n",
      "Epoch 7, Step: 462, Loss: 0.16796427965164185, Lr:0.0001\n",
      "Epoch 7, Step: 463, Loss: 0.4226451814174652, Lr:0.0001\n",
      "Epoch 7, Step: 464, Loss: 0.15717050433158875, Lr:0.0001\n",
      "Epoch 7, Step: 465, Loss: 0.07605519890785217, Lr:0.0001\n",
      "Epoch 7, Step: 466, Loss: 0.1032700464129448, Lr:0.0001\n",
      "Epoch 7, Step: 467, Loss: 0.012529809027910233, Lr:0.0001\n",
      "Epoch 7, Step: 468, Loss: 0.24193944036960602, Lr:0.0001\n",
      "Epoch 7, Step: 469, Loss: 0.4128939211368561, Lr:0.0001\n",
      "Epoch 7, Step: 470, Loss: 0.18571750819683075, Lr:0.0001\n",
      "Epoch 7, Step: 471, Loss: 0.1695338934659958, Lr:0.0001\n",
      "Epoch 7, Step: 472, Loss: 0.06574589759111404, Lr:0.0001\n",
      "Epoch 7, Step: 473, Loss: 0.10116075724363327, Lr:0.0001\n",
      "Epoch 7, Step: 474, Loss: 0.07871066778898239, Lr:0.0001\n",
      "Epoch 7, Step: 475, Loss: 0.16762904822826385, Lr:0.0001\n",
      "Epoch 7, Step: 476, Loss: 0.37779852747917175, Lr:0.0001\n",
      "Epoch 7, Step: 477, Loss: 0.2196737676858902, Lr:0.0001\n",
      "Epoch 7, Step: 478, Loss: 0.2503901422023773, Lr:0.0001\n",
      "Epoch 7, Step: 479, Loss: 0.34986069798469543, Lr:0.0001\n",
      "Epoch 7, Step: 480, Loss: 0.10567692667245865, Lr:0.0001\n",
      "Epoch 7, Step: 481, Loss: 0.3680539131164551, Lr:0.0001\n",
      "Epoch 7, Step: 482, Loss: 0.10968361049890518, Lr:0.0001\n",
      "Epoch 7, Step: 483, Loss: 0.07974229753017426, Lr:0.0001\n",
      "Epoch 7, Step: 484, Loss: 0.04779848828911781, Lr:0.0001\n",
      "Epoch 7, Step: 485, Loss: 0.08040611445903778, Lr:0.0001\n",
      "Epoch 7, Step: 486, Loss: 0.06837067753076553, Lr:0.0001\n",
      "Epoch 7, Step: 487, Loss: 0.1301584243774414, Lr:0.0001\n",
      "Epoch 7, Step: 488, Loss: 0.09505931288003922, Lr:0.0001\n",
      "Epoch 7, Step: 489, Loss: 0.1287802904844284, Lr:0.0001\n",
      "Epoch 7, Step: 490, Loss: 0.5374079346656799, Lr:0.0001\n",
      "Epoch 7, Step: 491, Loss: 0.23069730401039124, Lr:0.0001\n",
      "Epoch 7, Step: 492, Loss: 0.12450474500656128, Lr:0.0001\n",
      "Epoch 7, Step: 493, Loss: 0.16982068121433258, Lr:0.0001\n",
      "Epoch 7, Step: 494, Loss: 0.20940926671028137, Lr:0.0001\n",
      "Epoch 7, Step: 495, Loss: 0.08869120478630066, Lr:0.0001\n",
      "Epoch 7, Step: 496, Loss: 0.27167707681655884, Lr:0.0001\n",
      "Epoch 7, Step: 497, Loss: 0.15248826146125793, Lr:0.0001\n",
      "Epoch 7, Step: 498, Loss: 0.022097066044807434, Lr:0.0001\n",
      "Epoch 7, Step: 499, Loss: 0.2823030948638916, Lr:0.0001\n",
      "Epoch 7, Step: 500, Loss: 0.08211950957775116, Lr:0.0001\n",
      "Epoch 7, Step: 501, Loss: 0.18463009595870972, Lr:0.0001\n",
      "Epoch 7, Step: 502, Loss: 0.6127169132232666, Lr:0.0001\n",
      "Epoch 7, Step: 503, Loss: 0.5054963231086731, Lr:0.0001\n",
      "Epoch 7, Step: 504, Loss: 0.062471285462379456, Lr:0.0001\n",
      "Epoch 7, Step: 505, Loss: 0.041530877351760864, Lr:0.0001\n",
      "Epoch 7, Step: 506, Loss: 0.22063903510570526, Lr:0.0001\n",
      "Epoch 7, Step: 507, Loss: 0.08251247555017471, Lr:0.0001\n",
      "Epoch 7, Step: 508, Loss: 0.30335918068885803, Lr:0.0001\n",
      "Epoch 7, Step: 509, Loss: 0.20934171974658966, Lr:0.0001\n",
      "Epoch 7, Step: 510, Loss: 0.12374195456504822, Lr:0.0001\n",
      "Epoch 7, Step: 511, Loss: 0.012244325131177902, Lr:0.0001\n",
      "Epoch 7, Step: 512, Loss: 0.06164482980966568, Lr:0.0001\n",
      "Epoch 7, Step: 513, Loss: 0.05406949669122696, Lr:0.0001\n",
      "Epoch 7, Step: 514, Loss: 0.221481055021286, Lr:0.0001\n",
      "Epoch 7, Step: 515, Loss: 0.14789871871471405, Lr:0.0001\n",
      "Epoch 7, Step: 516, Loss: 0.0672663152217865, Lr:0.0001\n",
      "Epoch 7, Step: 517, Loss: 0.05934498831629753, Lr:0.0001\n",
      "Epoch 7, Step: 518, Loss: 0.06519687920808792, Lr:0.0001\n",
      "Epoch 7, Step: 519, Loss: 0.6236016154289246, Lr:0.0001\n",
      "Epoch 7, Step: 520, Loss: 0.12535125017166138, Lr:0.0001\n",
      "Epoch 7, Step: 521, Loss: 0.1284235268831253, Lr:0.0001\n",
      "Epoch 7, Step: 522, Loss: 0.27144575119018555, Lr:0.0001\n",
      "Epoch 7, Step: 523, Loss: 0.053309280425310135, Lr:0.0001\n",
      "Epoch 7, Step: 524, Loss: 0.15516085922718048, Lr:0.0001\n",
      "Epoch 7, Step: 525, Loss: 0.8655164241790771, Lr:0.0001\n",
      "Epoch 7, Step: 526, Loss: 0.23923374712467194, Lr:0.0001\n",
      "Epoch 7, Step: 527, Loss: 0.23654337227344513, Lr:0.0001\n",
      "Epoch 7, Step: 528, Loss: 0.4402872920036316, Lr:0.0001\n",
      "Epoch 7, Step: 529, Loss: 0.30443158745765686, Lr:0.0001\n",
      "Epoch 7, Step: 530, Loss: 0.04043954983353615, Lr:0.0001\n",
      "Epoch 7, Step: 531, Loss: 0.03376538306474686, Lr:0.0001\n",
      "Epoch 7, Step: 532, Loss: 0.02274686098098755, Lr:0.0001\n",
      "Epoch 7, Step: 533, Loss: 0.1348249763250351, Lr:0.0001\n",
      "Epoch 7, Step: 534, Loss: 0.08323612064123154, Lr:0.0001\n",
      "Epoch 7, Step: 535, Loss: 0.07461956143379211, Lr:0.0001\n",
      "Epoch 7, Step: 536, Loss: 0.07739880681037903, Lr:0.0001\n",
      "Epoch 7, Step: 537, Loss: 0.23054522275924683, Lr:0.0001\n",
      "Epoch 7, Step: 538, Loss: 0.04859413579106331, Lr:0.0001\n",
      "Epoch 7, Step: 539, Loss: 0.43547168374061584, Lr:0.0001\n",
      "Epoch 7, Step: 540, Loss: 0.2022588700056076, Lr:0.0001\n",
      "Epoch 7, Step: 541, Loss: 0.22084492444992065, Lr:0.0001\n",
      "Epoch 7, Step: 542, Loss: 0.06518901884555817, Lr:0.0001\n",
      "Epoch 7, Step: 543, Loss: 0.3846571147441864, Lr:0.0001\n",
      "Epoch 7, Step: 544, Loss: 0.11600169539451599, Lr:0.0001\n",
      "Epoch 7, Step: 545, Loss: 0.20401309430599213, Lr:0.0001\n",
      "Epoch 7, Step: 546, Loss: 0.35149213671684265, Lr:0.0001\n",
      "Epoch 7, Step: 547, Loss: 0.2178616225719452, Lr:0.0001\n",
      "Epoch 7, Step: 548, Loss: 0.0706857293844223, Lr:0.0001\n",
      "Epoch 7, Step: 549, Loss: 0.04403698071837425, Lr:0.0001\n",
      "Epoch 7, Step: 550, Loss: 0.400895893573761, Lr:0.0001\n",
      "Epoch 7, Step: 551, Loss: 0.07358787208795547, Lr:0.0001\n",
      "Epoch 7, Step: 552, Loss: 0.05233762413263321, Lr:0.0001\n",
      "Epoch 7, Step: 553, Loss: 0.08161378651857376, Lr:0.0001\n",
      "Epoch 7, Step: 554, Loss: 0.06866263598203659, Lr:0.0001\n",
      "Epoch 7, Step: 555, Loss: 0.3823879659175873, Lr:0.0001\n",
      "Epoch 7, Step: 556, Loss: 0.13639982044696808, Lr:0.0001\n",
      "Epoch 7, Step: 557, Loss: 0.168330579996109, Lr:0.0001\n",
      "Epoch 7, Step: 558, Loss: 0.21220843493938446, Lr:0.0001\n",
      "Epoch 7, Step: 559, Loss: 0.11123751103878021, Lr:0.0001\n",
      "Epoch 7, Step: 560, Loss: 0.3420865535736084, Lr:0.0001\n",
      "Epoch 7, Step: 561, Loss: 0.17679163813591003, Lr:0.0001\n",
      "Epoch 7, Step: 562, Loss: 0.09865441173315048, Lr:0.0001\n",
      "Epoch 7, Step: 563, Loss: 0.2181575447320938, Lr:0.0001\n",
      "Epoch 7, Step: 564, Loss: 0.31802403926849365, Lr:0.0001\n",
      "Epoch 7, Step: 565, Loss: 0.1261892467737198, Lr:0.0001\n",
      "Epoch 7, Step: 566, Loss: 0.08809204399585724, Lr:0.0001\n",
      "Epoch 7, Step: 567, Loss: 0.011703445576131344, Lr:0.0001\n",
      "Epoch 7, Step: 568, Loss: 0.10676272213459015, Lr:0.0001\n",
      "Epoch 7, Step: 569, Loss: 0.4792518615722656, Lr:0.0001\n",
      "Epoch 7, Step: 570, Loss: 0.268767774105072, Lr:0.0001\n",
      "Epoch 7, Step: 571, Loss: 0.11289231479167938, Lr:0.0001\n",
      "Epoch 7, Step: 572, Loss: 0.08121759444475174, Lr:0.0001\n",
      "Epoch 7, Step: 573, Loss: 0.10702851414680481, Lr:0.0001\n",
      "Epoch 7, Step: 574, Loss: 0.2565652132034302, Lr:0.0001\n",
      "Epoch 7, Step: 575, Loss: 0.21491959691047668, Lr:0.0001\n",
      "Epoch 7, Step: 576, Loss: 0.18047159910202026, Lr:0.0001\n",
      "Epoch 7, Step: 577, Loss: 0.1796487271785736, Lr:0.0001\n",
      "Epoch 7, Step: 578, Loss: 0.10444143414497375, Lr:0.0001\n",
      "Epoch 7, Step: 579, Loss: 0.16060574352741241, Lr:0.0001\n",
      "Epoch 7, Step: 580, Loss: 0.1777813583612442, Lr:0.0001\n",
      "Epoch 7, Step: 581, Loss: 0.6172078251838684, Lr:0.0001\n",
      "Epoch 7, Step: 582, Loss: 0.17393885552883148, Lr:0.0001\n",
      "Epoch 7, Step: 583, Loss: 0.049050647765398026, Lr:0.0001\n",
      "Epoch 7, Step: 584, Loss: 0.3723566234111786, Lr:0.0001\n",
      "Epoch 7, Step: 585, Loss: 0.4520237445831299, Lr:0.0001\n",
      "Epoch 7, Step: 586, Loss: 0.17066580057144165, Lr:0.0001\n",
      "Epoch 7, Step: 587, Loss: 0.08142168819904327, Lr:0.0001\n",
      "Epoch 7, Step: 588, Loss: 0.19845353066921234, Lr:0.0001\n",
      "Epoch 7, Step: 589, Loss: 0.2875779867172241, Lr:0.0001\n",
      "Epoch 7, Step: 590, Loss: 0.2576446533203125, Lr:0.0001\n",
      "Epoch 7, Step: 591, Loss: 0.11956357210874557, Lr:0.0001\n",
      "Epoch 7, Step: 592, Loss: 0.2840699851512909, Lr:0.0001\n",
      "Epoch 7, Step: 593, Loss: 0.1096370592713356, Lr:0.0001\n",
      "Epoch 7, Step: 594, Loss: 0.7786141633987427, Lr:0.0001\n",
      "Epoch 7, Step: 595, Loss: 0.04302739351987839, Lr:0.0001\n",
      "Epoch 7, Step: 596, Loss: 0.06221730262041092, Lr:0.0001\n",
      "Epoch 7, Step: 597, Loss: 0.3282257914543152, Lr:0.0001\n",
      "Epoch 7, Step: 598, Loss: 0.04730097949504852, Lr:0.0001\n",
      "Epoch 7, Step: 599, Loss: 0.19455420970916748, Lr:0.0001\n",
      "Epoch 7, Step: 600, Loss: 0.19836312532424927, Lr:0.0001\n",
      "Epoch 7, Step: 601, Loss: 0.0607534758746624, Lr:0.0001\n",
      "Epoch 7, Step: 602, Loss: 0.11354418098926544, Lr:0.0001\n",
      "Epoch 7, Step: 603, Loss: 0.020766837522387505, Lr:0.0001\n",
      "Epoch 7, Step: 604, Loss: 0.32148343324661255, Lr:0.0001\n",
      "Epoch 7, Step: 605, Loss: 0.4672451317310333, Lr:0.0001\n",
      "Epoch 7, Step: 606, Loss: 0.20287640392780304, Lr:0.0001\n",
      "Epoch 7, Step: 607, Loss: 0.11073098331689835, Lr:0.0001\n",
      "Epoch 7, Step: 608, Loss: 0.2527833580970764, Lr:0.0001\n",
      "Epoch 7, Step: 609, Loss: 0.1848309189081192, Lr:0.0001\n",
      "Epoch 7, Step: 610, Loss: 0.03320423513650894, Lr:0.0001\n",
      "Epoch 7, Step: 611, Loss: 0.03622027859091759, Lr:0.0001\n",
      "Epoch 7, Step: 612, Loss: 0.19832445681095123, Lr:0.0001\n",
      "Epoch 7, Step: 613, Loss: 0.07055570185184479, Lr:0.0001\n",
      "Epoch 7, Step: 614, Loss: 0.3172493278980255, Lr:0.0001\n",
      "Epoch 7, Step: 615, Loss: 0.45876359939575195, Lr:0.0001\n",
      "Epoch 7, Step: 616, Loss: 0.11408909410238266, Lr:0.0001\n",
      "Epoch 7, Step: 617, Loss: 0.15132996439933777, Lr:0.0001\n",
      "Epoch 7, Step: 618, Loss: 0.09769861400127411, Lr:0.0001\n",
      "Epoch 7, Step: 619, Loss: 0.17278501391410828, Lr:0.0001\n",
      "Epoch 7, Step: 620, Loss: 0.16721734404563904, Lr:0.0001\n",
      "Epoch 7, Step: 621, Loss: 0.2688370943069458, Lr:0.0001\n",
      "Epoch 7, Step: 622, Loss: 0.06973083317279816, Lr:0.0001\n",
      "Epoch 7, Step: 623, Loss: 0.1554802805185318, Lr:0.0001\n",
      "Epoch 7, Step: 624, Loss: 0.12184961140155792, Lr:0.0001\n",
      "Epoch 7, Step: 625, Loss: 0.16252519190311432, Lr:0.0001\n",
      "Epoch 7, Step: 626, Loss: 0.0998731330037117, Lr:0.0001\n",
      "Epoch 7, Step: 627, Loss: 0.049791235476732254, Lr:0.0001\n",
      "Epoch 7, Step: 628, Loss: 0.11050516366958618, Lr:0.0001\n",
      "Epoch 7, Step: 629, Loss: 0.1655546873807907, Lr:0.0001\n",
      "Epoch 7, Step: 630, Loss: 0.3195217549800873, Lr:0.0001\n",
      "Epoch 7, Step: 631, Loss: 0.21438385546207428, Lr:0.0001\n",
      "Epoch 7, Step: 632, Loss: 0.20728503167629242, Lr:0.0001\n",
      "Epoch 7, Step: 633, Loss: 0.37893444299697876, Lr:0.0001\n",
      "Epoch 7, Step: 634, Loss: 0.11067292094230652, Lr:0.0001\n",
      "Epoch 7, Step: 635, Loss: 0.1747473180294037, Lr:0.0001\n",
      "Epoch 7, Step: 636, Loss: 0.0849626287817955, Lr:0.0001\n",
      "Epoch 7, Step: 637, Loss: 0.012156740762293339, Lr:0.0001\n",
      "Epoch 7, Step: 638, Loss: 0.022468995302915573, Lr:0.0001\n",
      "Epoch 7, Step: 639, Loss: 0.03757792338728905, Lr:0.0001\n",
      "Epoch 7, Step: 640, Loss: 0.6971089839935303, Lr:0.0001\n",
      "Epoch 7, Step: 641, Loss: 0.010906138457357883, Lr:0.0001\n",
      "Epoch 7, Step: 642, Loss: 0.04219267517328262, Lr:0.0001\n",
      "Epoch 7, Step: 643, Loss: 0.014745758846402168, Lr:0.0001\n",
      "Epoch 7, Step: 644, Loss: 0.2517603039741516, Lr:0.0001\n",
      "Epoch 7, Step: 645, Loss: 0.3401699662208557, Lr:0.0001\n",
      "Epoch 7, Step: 646, Loss: 0.06514950096607208, Lr:0.0001\n",
      "Epoch 7, Step: 647, Loss: 0.15381880104541779, Lr:0.0001\n",
      "Epoch 7, Step: 648, Loss: 0.17042139172554016, Lr:0.0001\n",
      "Epoch 7, Step: 649, Loss: 0.04966025799512863, Lr:0.0001\n",
      "Epoch 7, Step: 650, Loss: 0.18809467554092407, Lr:0.0001\n",
      "Epoch 7, Step: 651, Loss: 0.0552867129445076, Lr:0.0001\n",
      "Epoch 7, Step: 652, Loss: 0.18787647783756256, Lr:0.0001\n",
      "Epoch 7, Step: 653, Loss: 0.35574260354042053, Lr:0.0001\n",
      "Epoch 7, Step: 654, Loss: 0.2441752851009369, Lr:0.0001\n",
      "Epoch 7, Step: 655, Loss: 0.28252482414245605, Lr:0.0001\n",
      "Epoch 7, Step: 656, Loss: 0.0422075018286705, Lr:0.0001\n",
      "Epoch 7, Step: 657, Loss: 0.09079217165708542, Lr:0.0001\n",
      "Epoch 7, Step: 658, Loss: 0.017660392448306084, Lr:0.0001\n",
      "Epoch 7, Step: 659, Loss: 0.1513310670852661, Lr:0.0001\n",
      "Epoch 7, Step: 660, Loss: 0.10017452389001846, Lr:0.0001\n",
      "Epoch 7, Step: 661, Loss: 0.11738793551921844, Lr:0.0001\n",
      "Epoch 7, Step: 662, Loss: 0.22177855670452118, Lr:0.0001\n",
      "Epoch 7, Step: 663, Loss: 0.49047234654426575, Lr:0.0001\n",
      "Epoch 7, Step: 664, Loss: 0.07998351752758026, Lr:0.0001\n",
      "Epoch 7, Step: 665, Loss: 0.16132096946239471, Lr:0.0001\n",
      "Epoch 7, Step: 666, Loss: 0.28161299228668213, Lr:0.0001\n",
      "Epoch 7, Step: 667, Loss: 0.06926542520523071, Lr:0.0001\n",
      "Epoch 7, Step: 668, Loss: 0.2907175123691559, Lr:0.0001\n",
      "Epoch 7, Step: 669, Loss: 0.0655863955616951, Lr:0.0001\n",
      "Epoch 7, Step: 670, Loss: 0.03584412857890129, Lr:0.0001\n",
      "Epoch 7, Step: 671, Loss: 0.2907103896141052, Lr:0.0001\n",
      "Epoch 7, Step: 672, Loss: 0.061729878187179565, Lr:0.0001\n",
      "Epoch 7, Step: 673, Loss: 0.017107395455241203, Lr:0.0001\n",
      "Epoch 7, Step: 674, Loss: 0.06645752489566803, Lr:0.0001\n",
      "Epoch 7, Step: 675, Loss: 0.28516221046447754, Lr:0.0001\n",
      "Epoch 7, Step: 676, Loss: 0.08831332623958588, Lr:0.0001\n",
      "Epoch 7, Step: 677, Loss: 0.3488274812698364, Lr:0.0001\n",
      "Epoch 7, Step: 678, Loss: 0.03398120403289795, Lr:0.0001\n",
      "Epoch 7, Step: 679, Loss: 0.12444239854812622, Lr:0.0001\n",
      "Epoch 7, Step: 680, Loss: 0.3201620876789093, Lr:0.0001\n",
      "Epoch 7, Step: 681, Loss: 0.019417233765125275, Lr:0.0001\n",
      "Epoch 7, Step: 682, Loss: 0.35756152868270874, Lr:0.0001\n",
      "Epoch 7, Step: 683, Loss: 0.05860516056418419, Lr:0.0001\n",
      "Epoch 7, Step: 684, Loss: 0.09583329409360886, Lr:0.0001\n",
      "Epoch 7, Step: 685, Loss: 0.19343963265419006, Lr:0.0001\n",
      "Epoch 7, Step: 686, Loss: 0.26392579078674316, Lr:0.0001\n",
      "Epoch 7, Step: 687, Loss: 0.7307782173156738, Lr:0.0001\n",
      "Epoch 7, Step: 688, Loss: 0.1746102124452591, Lr:0.0001\n",
      "Epoch 7, Step: 689, Loss: 0.2979043424129486, Lr:0.0001\n",
      "Epoch 7, Step: 690, Loss: 0.16353943943977356, Lr:0.0001\n",
      "Epoch 7, Step: 691, Loss: 0.37607529759407043, Lr:0.0001\n",
      "Epoch 7, Step: 692, Loss: 0.029287511482834816, Lr:0.0001\n",
      "Epoch 7, Step: 693, Loss: 0.026467343792319298, Lr:0.0001\n",
      "Epoch 7, Step: 694, Loss: 0.18994756042957306, Lr:0.0001\n",
      "Epoch 7, Step: 695, Loss: 0.19669759273529053, Lr:0.0001\n",
      "Epoch 7, Step: 696, Loss: 0.23813298344612122, Lr:0.0001\n",
      "Epoch 7, Step: 697, Loss: 0.5401539206504822, Lr:0.0001\n",
      "Epoch 7, Step: 698, Loss: 0.2941611409187317, Lr:0.0001\n",
      "Epoch 7, Step: 699, Loss: 0.22798249125480652, Lr:0.0001\n",
      "Epoch 7, Step: 700, Loss: 0.1509479433298111, Lr:0.0001\n",
      "Epoch 7, Step: 701, Loss: 0.4271748960018158, Lr:0.0001\n",
      "Epoch 7, Step: 702, Loss: 0.21466697752475739, Lr:0.0001\n",
      "Epoch 7, Step: 703, Loss: 0.2960406541824341, Lr:0.0001\n",
      "Epoch 7, Step: 704, Loss: 0.11388371884822845, Lr:0.0001\n",
      "Epoch 7, Step: 705, Loss: 0.09612201899290085, Lr:0.0001\n",
      "Epoch 7, Step: 706, Loss: 0.19420668482780457, Lr:0.0001\n",
      "Epoch 7, Step: 707, Loss: 0.143682599067688, Lr:0.0001\n",
      "Epoch 7, Step: 708, Loss: 0.08948890119791031, Lr:0.0001\n",
      "Epoch 7, Step: 709, Loss: 0.23775692284107208, Lr:0.0001\n",
      "Epoch 7, Step: 710, Loss: 0.1647890955209732, Lr:0.0001\n",
      "Epoch 7, Step: 711, Loss: 0.1422848105430603, Lr:0.0001\n",
      "Epoch 7, Step: 712, Loss: 0.07823994010686874, Lr:0.0001\n",
      "Epoch 7, Step: 713, Loss: 0.07918187230825424, Lr:0.0001\n",
      "Epoch 7, Step: 714, Loss: 0.24233542382717133, Lr:0.0001\n",
      "Epoch 7, Step: 715, Loss: 0.2638375163078308, Lr:0.0001\n",
      "Epoch 7, Step: 716, Loss: 0.11466765403747559, Lr:0.0001\n",
      "Epoch 7, Step: 717, Loss: 0.4104601740837097, Lr:0.0001\n",
      "Epoch 7, Step: 718, Loss: 0.05379543453454971, Lr:0.0001\n",
      "Epoch 7, Step: 719, Loss: 0.0927547812461853, Lr:0.0001\n",
      "Epoch 7, Step: 720, Loss: 0.2807651460170746, Lr:0.0001\n",
      "Epoch 7, Step: 721, Loss: 0.07667906582355499, Lr:0.0001\n",
      "Epoch 7, Step: 722, Loss: 0.14104698598384857, Lr:0.0001\n",
      "Epoch 7, Step: 723, Loss: 0.031181860715150833, Lr:0.0001\n",
      "Epoch 7, Step: 724, Loss: 0.20046579837799072, Lr:0.0001\n",
      "Epoch 7, Step: 725, Loss: 0.050421278923749924, Lr:0.0001\n",
      "Epoch 7, Step: 726, Loss: 0.21081048250198364, Lr:0.0001\n",
      "Epoch 7, Step: 727, Loss: 0.08484266698360443, Lr:0.0001\n",
      "Epoch 7, Step: 728, Loss: 0.05943422019481659, Lr:0.0001\n",
      "Epoch 7, Step: 729, Loss: 0.15664367377758026, Lr:0.0001\n",
      "Epoch 7, Step: 730, Loss: 0.23832611739635468, Lr:0.0001\n",
      "Epoch 7, Step: 731, Loss: 0.1208648830652237, Lr:0.0001\n",
      "Epoch 7, Step: 732, Loss: 0.13583095371723175, Lr:0.0001\n",
      "Epoch 7, Step: 733, Loss: 0.12411447614431381, Lr:0.0001\n",
      "Epoch 7, Step: 734, Loss: 0.13211500644683838, Lr:0.0001\n",
      "Epoch 7, Step: 735, Loss: 0.21985842287540436, Lr:0.0001\n",
      "Epoch 7, Step: 736, Loss: 0.21909162402153015, Lr:0.0001\n",
      "Epoch 7, Step: 737, Loss: 0.06502947211265564, Lr:0.0001\n",
      "Epoch 7, Step: 738, Loss: 0.22154401242733002, Lr:0.0001\n",
      "Epoch 7, Step: 739, Loss: 0.11820336431264877, Lr:0.0001\n",
      "Epoch 7, Step: 740, Loss: 0.03769733011722565, Lr:0.0001\n",
      "Epoch 7, Step: 741, Loss: 0.10445563495159149, Lr:0.0001\n",
      "Epoch 7, Step: 742, Loss: 0.0856461301445961, Lr:0.0001\n",
      "Epoch 7, Step: 743, Loss: 0.1839575171470642, Lr:0.0001\n",
      "Epoch 7, Step: 744, Loss: 0.17574644088745117, Lr:0.0001\n",
      "Epoch 7, Step: 745, Loss: 0.0391029454767704, Lr:0.0001\n",
      "Epoch 7, Step: 746, Loss: 0.263494610786438, Lr:0.0001\n",
      "Epoch 7, Step: 747, Loss: 0.0897042453289032, Lr:0.0001\n",
      "Epoch 7, Step: 748, Loss: 0.23772954940795898, Lr:0.0001\n",
      "Epoch 7, Step: 749, Loss: 0.13617247343063354, Lr:0.0001\n",
      "Epoch 7, Step: 750, Loss: 0.01078222505748272, Lr:0.0001\n",
      "Epoch 7, Step: 751, Loss: 0.02246338687837124, Lr:0.0001\n",
      "Epoch 7, Step: 752, Loss: 0.041733358055353165, Lr:0.0001\n",
      "Epoch 7, Step: 753, Loss: 0.059872619807720184, Lr:0.0001\n",
      "Epoch 7, Step: 754, Loss: 0.165949285030365, Lr:0.0001\n",
      "Epoch 7, Step: 755, Loss: 0.11539843678474426, Lr:0.0001\n",
      "Epoch 7, Step: 756, Loss: 0.03713399916887283, Lr:0.0001\n",
      "Epoch 7, Step: 757, Loss: 0.4763762652873993, Lr:0.0001\n",
      "Epoch 7, Step: 758, Loss: 0.0609615184366703, Lr:0.0001\n",
      "Epoch 7, Step: 759, Loss: 0.35108187794685364, Lr:0.0001\n",
      "Epoch 7, Step: 760, Loss: 0.18223151564598083, Lr:0.0001\n",
      "Epoch 7, Step: 761, Loss: 0.17688246071338654, Lr:0.0001\n",
      "Epoch 7, Step: 762, Loss: 0.02867501974105835, Lr:0.0001\n",
      "Epoch 7, Step: 763, Loss: 0.06718581914901733, Lr:0.0001\n",
      "Epoch 7, Step: 764, Loss: 0.07739242166280746, Lr:0.0001\n",
      "Epoch 7, Step: 765, Loss: 0.4268087148666382, Lr:0.0001\n",
      "Epoch 7, Step: 766, Loss: 0.5326862335205078, Lr:0.0001\n",
      "Epoch 7, Step: 767, Loss: 0.06102101504802704, Lr:0.0001\n",
      "Epoch 7, Step: 768, Loss: 0.23306258022785187, Lr:0.0001\n",
      "Epoch 7, Step: 769, Loss: 0.046427175402641296, Lr:0.0001\n",
      "Epoch 7, Step: 770, Loss: 0.08465228229761124, Lr:0.0001\n",
      "Epoch 7, Step: 771, Loss: 0.0303817018866539, Lr:0.0001\n",
      "Epoch 7, Step: 772, Loss: 0.3266970217227936, Lr:0.0001\n",
      "Epoch 7, Step: 773, Loss: 0.515365719795227, Lr:0.0001\n",
      "Epoch 7, Step: 774, Loss: 0.20617860555648804, Lr:0.0001\n",
      "Epoch 7, Step: 775, Loss: 0.12320607900619507, Lr:0.0001\n",
      "Epoch 7, Step: 776, Loss: 0.10805068165063858, Lr:0.0001\n",
      "Epoch 7, Step: 777, Loss: 0.18013493716716766, Lr:0.0001\n",
      "Epoch 7, Step: 778, Loss: 0.22522065043449402, Lr:0.0001\n",
      "Epoch 7, Step: 779, Loss: 0.17342375218868256, Lr:0.0001\n",
      "Epoch 7, Step: 780, Loss: 0.27650001645088196, Lr:0.0001\n",
      "Epoch 7, Step: 781, Loss: 0.08078766614198685, Lr:0.0001\n",
      "Epoch 7, Step: 782, Loss: 0.26655763387680054, Lr:0.0001\n",
      "Epoch 7, Step: 783, Loss: 0.1653306484222412, Lr:0.0001\n",
      "Epoch 7, Step: 784, Loss: 0.11903642117977142, Lr:0.0001\n",
      "Epoch 7, Step: 785, Loss: 0.18425631523132324, Lr:0.0001\n",
      "Epoch 7, Step: 786, Loss: 0.10598839819431305, Lr:0.0001\n",
      "Epoch 7, Step: 787, Loss: 0.20116935670375824, Lr:0.0001\n",
      "Epoch 7, Step: 788, Loss: 0.11522196233272552, Lr:0.0001\n",
      "Epoch 7, Step: 789, Loss: 0.05357882380485535, Lr:0.0001\n",
      "Epoch 7, Step: 790, Loss: 0.1104852482676506, Lr:0.0001\n",
      "Epoch 7, Step: 791, Loss: 0.05699620023369789, Lr:0.0001\n",
      "Epoch 7, Step: 792, Loss: 0.0628613606095314, Lr:0.0001\n",
      "Epoch 7, Step: 793, Loss: 0.05010504275560379, Lr:0.0001\n",
      "Epoch 7, Step: 794, Loss: 0.10492627322673798, Lr:0.0001\n",
      "Epoch 7, Step: 795, Loss: 0.6958029270172119, Lr:0.0001\n",
      "Epoch 7, Step: 796, Loss: 0.2099340260028839, Lr:0.0001\n",
      "Epoch 7, Step: 797, Loss: 0.23143216967582703, Lr:0.0001\n",
      "Epoch 7, Step: 798, Loss: 0.08267638832330704, Lr:0.0001\n",
      "Epoch 7, Step: 799, Loss: 0.01989120990037918, Lr:0.0001\n",
      "Epoch 7, Step: 800, Loss: 0.3207142651081085, Lr:0.0001\n",
      "Epoch 7, Step: 801, Loss: 0.6018321514129639, Lr:0.0001\n",
      "Epoch 7, Step: 802, Loss: 0.027656761929392815, Lr:0.0001\n",
      "Epoch 7, Step: 803, Loss: 0.1773834526538849, Lr:0.0001\n",
      "Epoch 7, Step: 804, Loss: 0.06848429888486862, Lr:0.0001\n",
      "Epoch 7, Step: 805, Loss: 0.09175586700439453, Lr:0.0001\n",
      "Epoch 7, Step: 806, Loss: 0.15200093388557434, Lr:0.0001\n",
      "Epoch 7, Step: 807, Loss: 0.07749800384044647, Lr:0.0001\n",
      "Epoch 7, Step: 808, Loss: 0.12619920074939728, Lr:0.0001\n",
      "Epoch 7, Step: 809, Loss: 0.018911855295300484, Lr:0.0001\n",
      "Epoch 7, Step: 810, Loss: 0.0869365707039833, Lr:0.0001\n",
      "Epoch 7, Step: 811, Loss: 0.06415348500013351, Lr:0.0001\n",
      "Epoch 7, Step: 812, Loss: 0.11159738153219223, Lr:0.0001\n",
      "Epoch 7, Step: 813, Loss: 0.06978490203619003, Lr:0.0001\n",
      "Epoch 7, Step: 814, Loss: 0.21630702912807465, Lr:0.0001\n",
      "Epoch 7, Step: 815, Loss: 0.4453118145465851, Lr:0.0001\n",
      "Epoch 7, Step: 816, Loss: 0.20357677340507507, Lr:0.0001\n",
      "Epoch 7, Step: 817, Loss: 0.16681335866451263, Lr:0.0001\n",
      "Epoch 7, Step: 818, Loss: 0.309732586145401, Lr:0.0001\n",
      "Epoch 7, Step: 819, Loss: 0.11195848137140274, Lr:0.0001\n",
      "Epoch 7, Step: 820, Loss: 0.2585104703903198, Lr:0.0001\n",
      "Epoch 7, Step: 821, Loss: 0.1653611660003662, Lr:0.0001\n",
      "Epoch 7, Step: 822, Loss: 0.19152399897575378, Lr:0.0001\n",
      "Epoch 7, Step: 823, Loss: 0.2107107788324356, Lr:0.0001\n",
      "Epoch 7, Step: 824, Loss: 0.09250698983669281, Lr:0.0001\n",
      "Epoch 7, Step: 825, Loss: 0.10081402212381363, Lr:0.0001\n",
      "Epoch 7, Step: 826, Loss: 0.12742488086223602, Lr:0.0001\n",
      "Epoch 7, Step: 827, Loss: 0.21155983209609985, Lr:0.0001\n",
      "Epoch 7, Step: 828, Loss: 0.0248554777354002, Lr:0.0001\n",
      "Epoch 7, Step: 829, Loss: 0.18402191996574402, Lr:0.0001\n",
      "Epoch 7, Step: 830, Loss: 0.041611094027757645, Lr:0.0001\n",
      "Epoch 7, Step: 831, Loss: 0.05945279821753502, Lr:0.0001\n",
      "Epoch 7, Step: 832, Loss: 0.04811277985572815, Lr:0.0001\n",
      "Epoch 7, Step: 833, Loss: 0.4554072320461273, Lr:0.0001\n",
      "Epoch 7, Step: 834, Loss: 0.2452264428138733, Lr:0.0001\n",
      "Epoch 7, Step: 835, Loss: 0.2213255763053894, Lr:0.0001\n",
      "Epoch 7, Step: 836, Loss: 0.2338961511850357, Lr:0.0001\n",
      "Epoch 7, Step: 837, Loss: 0.15663984417915344, Lr:0.0001\n",
      "Epoch 7, Step: 838, Loss: 0.041718803346157074, Lr:0.0001\n",
      "Epoch 7, Step: 839, Loss: 0.10097987949848175, Lr:0.0001\n",
      "Epoch 7, Step: 840, Loss: 0.11980821937322617, Lr:0.0001\n",
      "Epoch 7, Step: 841, Loss: 0.2150619626045227, Lr:0.0001\n",
      "Epoch 7, Step: 842, Loss: 0.3774043619632721, Lr:0.0001\n",
      "Epoch 7, Step: 843, Loss: 0.31631410121917725, Lr:0.0001\n",
      "Epoch 7, Step: 844, Loss: 0.03815087676048279, Lr:0.0001\n",
      "Epoch 7, Step: 845, Loss: 0.20518237352371216, Lr:0.0001\n",
      "Epoch 7, Step: 846, Loss: 0.14791777729988098, Lr:0.0001\n",
      "Epoch 7, Step: 847, Loss: 0.12885484099388123, Lr:0.0001\n",
      "Epoch 7, Step: 848, Loss: 0.2373836785554886, Lr:0.0001\n",
      "Epoch 7, Step: 849, Loss: 0.4537760019302368, Lr:0.0001\n",
      "Epoch 7, Step: 850, Loss: 0.41311976313591003, Lr:0.0001\n",
      "Epoch 7, Step: 851, Loss: 0.057805947959423065, Lr:0.0001\n",
      "Epoch 7, Step: 852, Loss: 0.2980656623840332, Lr:0.0001\n",
      "Epoch 7, Step: 853, Loss: 0.3266584873199463, Lr:0.0001\n",
      "Epoch 7, Step: 854, Loss: 0.026806026697158813, Lr:0.0001\n",
      "Epoch 7, Step: 855, Loss: 0.17558997869491577, Lr:0.0001\n",
      "Epoch 7, Step: 856, Loss: 0.4952554404735565, Lr:0.0001\n",
      "Epoch 7, Step: 857, Loss: 0.028934404253959656, Lr:0.0001\n",
      "Epoch 7, Step: 858, Loss: 0.22311869263648987, Lr:0.0001\n",
      "Epoch 7, Step: 859, Loss: 0.3260617256164551, Lr:0.0001\n",
      "Epoch 7, Step: 860, Loss: 0.06422390788793564, Lr:0.0001\n",
      "Epoch 7, Step: 861, Loss: 0.18074198067188263, Lr:0.0001\n",
      "Epoch 7, Step: 862, Loss: 0.35905662178993225, Lr:0.0001\n",
      "Epoch 7, Step: 863, Loss: 0.08279705047607422, Lr:0.0001\n",
      "Epoch 7, Step: 864, Loss: 0.05860774591565132, Lr:0.0001\n",
      "Epoch 7, Step: 865, Loss: 0.40001481771469116, Lr:0.0001\n",
      "Epoch 7, Step: 866, Loss: 0.5237126350402832, Lr:0.0001\n",
      "Epoch 7, Step: 867, Loss: 0.08628672361373901, Lr:0.0001\n",
      "Epoch 7, Step: 868, Loss: 0.09525036811828613, Lr:0.0001\n",
      "Epoch 7, Step: 869, Loss: 0.18063391745090485, Lr:0.0001\n",
      "Epoch 7, Step: 870, Loss: 0.10519657284021378, Lr:0.0001\n",
      "Epoch 7, Step: 871, Loss: 0.19987940788269043, Lr:0.0001\n",
      "Epoch 7, Step: 872, Loss: 0.3141400218009949, Lr:0.0001\n",
      "Epoch 7, Step: 873, Loss: 0.18824942409992218, Lr:0.0001\n",
      "Epoch 7, Step: 874, Loss: 0.0660472959280014, Lr:0.0001\n",
      "Epoch 7, Step: 875, Loss: 0.07545094192028046, Lr:0.0001\n",
      "Epoch 7, Step: 876, Loss: 0.06539630144834518, Lr:0.0001\n",
      "Epoch 7, Step: 877, Loss: 0.2317325472831726, Lr:0.0001\n",
      "Epoch 7, Step: 878, Loss: 0.19881387054920197, Lr:0.0001\n",
      "Epoch 7, Step: 879, Loss: 0.11469583958387375, Lr:0.0001\n",
      "Epoch 7, Step: 880, Loss: 0.2861895263195038, Lr:0.0001\n",
      "Epoch 7, Step: 881, Loss: 0.2603856921195984, Lr:0.0001\n",
      "Epoch 7, Step: 882, Loss: 0.06585625559091568, Lr:0.0001\n",
      "Epoch 7, Step: 883, Loss: 0.29814356565475464, Lr:0.0001\n",
      "Epoch 7, Step: 884, Loss: 0.17511147260665894, Lr:0.0001\n",
      "Epoch 7, Step: 885, Loss: 0.21566221117973328, Lr:0.0001\n",
      "Epoch 7, Step: 886, Loss: 0.13508518040180206, Lr:0.0001\n",
      "Epoch 7, Step: 887, Loss: 0.23772162199020386, Lr:0.0001\n",
      "Epoch 7, Step: 888, Loss: 0.22248484194278717, Lr:0.0001\n",
      "Epoch 7, Step: 889, Loss: 0.4065961539745331, Lr:0.0001\n",
      "Epoch 7, Step: 890, Loss: 0.24592891335487366, Lr:0.0001\n",
      "Epoch 7, Step: 891, Loss: 0.2983974814414978, Lr:0.0001\n",
      "Epoch 7, Step: 892, Loss: 0.11194805800914764, Lr:0.0001\n",
      "Epoch 7, Step: 893, Loss: 0.3703624904155731, Lr:0.0001\n",
      "Epoch 7, Step: 894, Loss: 0.11044321209192276, Lr:0.0001\n",
      "Epoch 7, Step: 895, Loss: 0.30891725420951843, Lr:0.0001\n",
      "Epoch 7, Step: 896, Loss: 0.17338114976882935, Lr:0.0001\n",
      "Epoch 7, Step: 897, Loss: 0.16649967432022095, Lr:0.0001\n",
      "Epoch 7, Step: 898, Loss: 0.02303232252597809, Lr:0.0001\n",
      "Epoch 7, Step: 899, Loss: 0.06527549773454666, Lr:0.0001\n",
      "Epoch 7, Step: 900, Loss: 0.052898142486810684, Lr:0.0001\n",
      "Epoch 7, Step: 901, Loss: 0.09171777963638306, Lr:0.0001\n",
      "Epoch 7, Step: 902, Loss: 0.0684521272778511, Lr:0.0001\n",
      "Epoch 7, Step: 903, Loss: 0.22246317565441132, Lr:0.0001\n",
      "Epoch 7, Step: 904, Loss: 0.03719969093799591, Lr:0.0001\n",
      "Epoch 7, Step: 905, Loss: 0.26479315757751465, Lr:0.0001\n",
      "Epoch 7, Step: 906, Loss: 0.20442208647727966, Lr:0.0001\n",
      "Epoch 7, Step: 907, Loss: 0.22624941170215607, Lr:0.0001\n",
      "Epoch 7, Step: 908, Loss: 0.03008747659623623, Lr:0.0001\n",
      "Epoch 7, Step: 909, Loss: 0.17298798263072968, Lr:0.0001\n",
      "Epoch 7, Step: 910, Loss: 0.12243438512086868, Lr:0.0001\n",
      "Epoch 7, Step: 911, Loss: 0.4858390688896179, Lr:0.0001\n",
      "Epoch 7, Step: 912, Loss: 0.2490047663450241, Lr:0.0001\n",
      "Epoch 7, Step: 913, Loss: 0.4583200216293335, Lr:0.0001\n",
      "Epoch 7, Step: 914, Loss: 0.07601112127304077, Lr:0.0001\n",
      "Epoch 7, Step: 915, Loss: 0.16700701415538788, Lr:0.0001\n",
      "Epoch 7, Step: 916, Loss: 0.06030698120594025, Lr:0.0001\n",
      "Epoch 7, Step: 917, Loss: 0.022732239216566086, Lr:0.0001\n",
      "Epoch 7, Step: 918, Loss: 0.20886212587356567, Lr:0.0001\n",
      "Epoch 7, Step: 919, Loss: 0.04287828505039215, Lr:0.0001\n",
      "Epoch 7, Step: 920, Loss: 0.35136011242866516, Lr:0.0001\n",
      "Epoch 7, Step: 921, Loss: 0.01602357253432274, Lr:0.0001\n",
      "Epoch 7, Step: 922, Loss: 0.1252250075340271, Lr:0.0001\n",
      "Epoch 7, Step: 923, Loss: 0.3763483464717865, Lr:0.0001\n",
      "Epoch 7, Step: 924, Loss: 0.05110831558704376, Lr:0.0001\n",
      "Epoch 7, Step: 925, Loss: 0.060600485652685165, Lr:0.0001\n",
      "Epoch 7, Step: 926, Loss: 0.06375707685947418, Lr:0.0001\n",
      "Epoch 7, Step: 927, Loss: 0.04214460775256157, Lr:0.0001\n",
      "Epoch 7, Step: 928, Loss: 0.08188693970441818, Lr:0.0001\n",
      "Epoch 7, Step: 929, Loss: 0.0856810137629509, Lr:0.0001\n",
      "Epoch 7, Step: 930, Loss: 0.09981819242238998, Lr:0.0001\n",
      "Epoch 7, Step: 931, Loss: 0.11461152136325836, Lr:0.0001\n",
      "Epoch 7, Step: 932, Loss: 0.19831208884716034, Lr:0.0001\n",
      "Epoch 7, Step: 933, Loss: 0.20694485306739807, Lr:0.0001\n",
      "Epoch 7, Step: 934, Loss: 0.17026740312576294, Lr:0.0001\n",
      "Epoch 7, Step: 935, Loss: 0.1254127472639084, Lr:0.0001\n",
      "Epoch 7, Step: 936, Loss: 0.03872968256473541, Lr:0.0001\n",
      "Epoch 7, Step: 937, Loss: 0.26222628355026245, Lr:0.0001\n",
      "Epoch 7, Step: 938, Loss: 0.1180388331413269, Lr:0.0001\n",
      "Epoch 7, Step: 939, Loss: 0.10613848268985748, Lr:0.0001\n",
      "Epoch 7, Step: 940, Loss: 0.16928265988826752, Lr:0.0001\n",
      "Epoch 7, Step: 941, Loss: 0.08088812977075577, Lr:0.0001\n",
      "Epoch 7, Step: 942, Loss: 0.18685291707515717, Lr:0.0001\n",
      "Epoch 7, Step: 943, Loss: 0.3173084855079651, Lr:0.0001\n",
      "Epoch 7, Step: 944, Loss: 0.27037084102630615, Lr:0.0001\n",
      "Epoch 7, Step: 945, Loss: 0.37422239780426025, Lr:0.0001\n",
      "Epoch 7, Step: 946, Loss: 0.34852924942970276, Lr:0.0001\n",
      "Epoch 7, Step: 947, Loss: 0.1690666228532791, Lr:0.0001\n",
      "Epoch 7, Step: 948, Loss: 0.43147143721580505, Lr:0.0001\n",
      "Epoch 7, Step: 949, Loss: 0.10560785979032516, Lr:0.0001\n",
      "Epoch 7, Step: 950, Loss: 0.09298403561115265, Lr:0.0001\n",
      "Epoch 7, Step: 951, Loss: 0.39528873562812805, Lr:0.0001\n",
      "Epoch 7, Step: 952, Loss: 0.09153977036476135, Lr:0.0001\n",
      "Epoch 7, Step: 953, Loss: 0.2955998182296753, Lr:0.0001\n",
      "Epoch 7, Step: 954, Loss: 0.5241588354110718, Lr:0.0001\n",
      "Epoch 7, Step: 955, Loss: 0.11995704472064972, Lr:0.0001\n",
      "Epoch 7, Step: 956, Loss: 0.08991342782974243, Lr:0.0001\n",
      "Epoch 7, Step: 957, Loss: 0.35486242175102234, Lr:0.0001\n",
      "Epoch 7, Step: 958, Loss: 0.09355960041284561, Lr:0.0001\n",
      "Epoch 7, Step: 959, Loss: 0.15936195850372314, Lr:0.0001\n",
      "Epoch 7, Step: 960, Loss: 0.27708783745765686, Lr:0.0001\n",
      "Epoch 7, Step: 961, Loss: 0.0725264921784401, Lr:0.0001\n",
      "Epoch 7, Step: 962, Loss: 0.03309950977563858, Lr:0.0001\n",
      "Epoch 7, Step: 963, Loss: 0.48947370052337646, Lr:0.0001\n",
      "Epoch 7, Step: 964, Loss: 0.22448000311851501, Lr:0.0001\n",
      "Epoch 7, Step: 965, Loss: 0.18316367268562317, Lr:0.0001\n",
      "Epoch 7, Step: 966, Loss: 0.22004000842571259, Lr:0.0001\n",
      "Epoch 7, Step: 967, Loss: 0.057407185435295105, Lr:0.0001\n",
      "Epoch 7, Step: 968, Loss: 0.09113595634698868, Lr:0.0001\n",
      "Epoch 7, Step: 969, Loss: 0.16439782083034515, Lr:0.0001\n",
      "Epoch 7, Step: 970, Loss: 0.08419983088970184, Lr:0.0001\n",
      "Epoch 7, Step: 971, Loss: 0.03256911784410477, Lr:0.0001\n",
      "Epoch 7, Step: 972, Loss: 0.46878838539123535, Lr:0.0001\n",
      "Epoch 7, Step: 973, Loss: 0.18839150667190552, Lr:0.0001\n",
      "Epoch 7, Step: 974, Loss: 0.3628073036670685, Lr:0.0001\n",
      "Epoch 7, Step: 975, Loss: 0.3338389992713928, Lr:0.0001\n",
      "Epoch 7, Step: 976, Loss: 0.244184210896492, Lr:0.0001\n",
      "Epoch 7, Step: 977, Loss: 0.19338390231132507, Lr:0.0001\n",
      "Epoch 7, Step: 978, Loss: 0.2587762176990509, Lr:0.0001\n",
      "Epoch 7, Step: 979, Loss: 0.43279358744621277, Lr:0.0001\n",
      "Epoch 7, Step: 980, Loss: 0.19163532555103302, Lr:0.0001\n",
      "Epoch 7, Step: 981, Loss: 0.0421542264521122, Lr:0.0001\n",
      "Epoch 7, Step: 982, Loss: 0.32815471291542053, Lr:0.0001\n",
      "Epoch 7, Step: 983, Loss: 0.24549826979637146, Lr:0.0001\n",
      "Epoch 7, Step: 984, Loss: 0.03210150822997093, Lr:0.0001\n",
      "Epoch 7, Step: 985, Loss: 0.18012483417987823, Lr:0.0001\n",
      "Epoch 7, Step: 986, Loss: 0.21404847502708435, Lr:0.0001\n",
      "Epoch 7, Step: 987, Loss: 0.10048066079616547, Lr:0.0001\n",
      "Epoch 7, Step: 988, Loss: 0.13178549706935883, Lr:0.0001\n",
      "Epoch 7, Step: 989, Loss: 0.17542418837547302, Lr:0.0001\n",
      "Epoch 7, Step: 990, Loss: 0.2761646509170532, Lr:0.0001\n",
      "Epoch 7, Step: 991, Loss: 0.3226544260978699, Lr:0.0001\n",
      "Epoch 7, Step: 992, Loss: 0.16804289817810059, Lr:0.0001\n",
      "Epoch 7, Step: 993, Loss: 0.2881503999233246, Lr:0.0001\n",
      "Epoch 7, Step: 994, Loss: 0.13009095191955566, Lr:0.0001\n",
      "Epoch 7, Step: 995, Loss: 0.3431398570537567, Lr:0.0001\n",
      "Epoch 7, Step: 996, Loss: 0.12366349250078201, Lr:0.0001\n",
      "Epoch 7, Step: 997, Loss: 0.2014659345149994, Lr:0.0001\n",
      "Epoch 7, Step: 998, Loss: 0.14981980621814728, Lr:0.0001\n",
      "Epoch 7, Step: 999, Loss: 0.07981949299573898, Lr:0.0001\n",
      "Epoch 7, Step: 1000, Loss: 0.2168273627758026, Lr:0.0001\n",
      "Epoch 7, Step: 1001, Loss: 0.009683055803179741, Lr:0.0001\n",
      "Epoch 7, Step: 1002, Loss: 0.04257166013121605, Lr:0.0001\n",
      "Epoch 7, Step: 1003, Loss: 0.2249036729335785, Lr:0.0001\n",
      "Epoch 7, Step: 1004, Loss: 0.06641533225774765, Lr:0.0001\n",
      "Epoch 7, Step: 1005, Loss: 0.2160106897354126, Lr:0.0001\n",
      "Epoch 7, Step: 1006, Loss: 0.019857317209243774, Lr:0.0001\n",
      "Epoch 7, Step: 1007, Loss: 0.030829070135951042, Lr:0.0001\n",
      "Epoch 7, Step: 1008, Loss: 0.3441530168056488, Lr:0.0001\n",
      "Epoch 7, Step: 1009, Loss: 0.12680713832378387, Lr:0.0001\n",
      "Epoch 7, Step: 1010, Loss: 0.35598018765449524, Lr:0.0001\n",
      "Epoch 7, Step: 1011, Loss: 0.18553271889686584, Lr:0.0001\n",
      "Epoch 7, Step: 1012, Loss: 0.3595641851425171, Lr:0.0001\n",
      "Epoch 7, Step: 1013, Loss: 0.17350730299949646, Lr:0.0001\n",
      "Epoch 7, Step: 1014, Loss: 0.03203636407852173, Lr:0.0001\n",
      "Epoch 7, Step: 1015, Loss: 0.3406759202480316, Lr:0.0001\n",
      "Epoch 7, Step: 1016, Loss: 0.13271600008010864, Lr:0.0001\n",
      "Epoch 7, Step: 1017, Loss: 0.14550787210464478, Lr:0.0001\n",
      "Epoch 7, Step: 1018, Loss: 0.15369002521038055, Lr:0.0001\n",
      "Epoch 7, Step: 1019, Loss: 0.21088223159313202, Lr:0.0001\n",
      "Epoch 7, Step: 1020, Loss: 0.04493816941976547, Lr:0.0001\n",
      "Epoch 7, Step: 1021, Loss: 0.15375873446464539, Lr:0.0001\n",
      "Epoch 7, Step: 1022, Loss: 0.14331115782260895, Lr:0.0001\n",
      "Epoch 7, Step: 1023, Loss: 0.03139134496450424, Lr:0.0001\n",
      "Epoch 7, Step: 1024, Loss: 0.2329641431570053, Lr:0.0001\n",
      "Epoch 7, Step: 1025, Loss: 0.12606406211853027, Lr:0.0001\n",
      "Epoch 7, Step: 1026, Loss: 0.35457098484039307, Lr:0.0001\n",
      "Epoch 7, Step: 1027, Loss: 0.10702583193778992, Lr:0.0001\n",
      "Epoch 7, Step: 1028, Loss: 0.23975536227226257, Lr:0.0001\n",
      "Epoch 7, Step: 1029, Loss: 0.08370132744312286, Lr:0.0001\n",
      "Epoch 7, Step: 1030, Loss: 0.2597423791885376, Lr:0.0001\n",
      "Epoch 7, Step: 1031, Loss: 0.14370325207710266, Lr:0.0001\n",
      "Epoch 7, Step: 1032, Loss: 0.0915159061551094, Lr:0.0001\n",
      "Epoch 7, Step: 1033, Loss: 0.09989471733570099, Lr:0.0001\n",
      "Epoch 7, Step: 1034, Loss: 0.3322674334049225, Lr:0.0001\n",
      "Epoch 7, Step: 1035, Loss: 0.14054398238658905, Lr:0.0001\n",
      "Epoch 7, Step: 1036, Loss: 0.10088406503200531, Lr:0.0001\n",
      "Epoch 7, Step: 1037, Loss: 0.2860586643218994, Lr:0.0001\n",
      "Epoch 7, Step: 1038, Loss: 0.007183026988059282, Lr:0.0001\n",
      "Epoch 7, Step: 1039, Loss: 0.19224412739276886, Lr:0.0001\n",
      "Epoch 7, Step: 1040, Loss: 0.24008925259113312, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 7\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:17 loss: 0.4941 (0.4941) acc1: 93.7500 (93.7500) acc5: 100.0000 (100.0000) time: 0.3147 data: 0.1160 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.0069 (0.0718) acc1: 100.0000 (98.2955) acc5: 100.0000 (100.0000) time: 0.2884 data: 0.1104 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0066 (0.0677) acc1: 100.0000 (98.2143) acc5: 100.0000 (100.0000) time: 0.2843 data: 0.1076 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.0225 (0.2345) acc1: 100.0000 (92.3387) acc5: 100.0000 (100.0000) time: 0.2899 data: 0.1076 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.3802 (0.2990) acc1: 81.2500 (90.2439) acc5: 100.0000 (100.0000) time: 0.2982 data: 0.1136 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.2173 (0.2881) acc1: 87.5000 (90.1961) acc5: 100.0000 (100.0000) time: 0.2974 data: 0.1168 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.1261 (0.3046) acc1: 93.7500 (90.0114) acc5: 100.0000 (100.0000) time: 0.2852 data: 0.1117 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.2883 s / it)\n",
      "* Acc@1 90.011 Acc@5 100.000 loss 0.305\n",
      "Accuracy of the network on the 881 test image: 90.0%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 8, Step: 0, Loss: 0.11589919775724411, Lr:0.0001\n",
      "Epoch 8, Step: 1, Loss: 0.019469553604722023, Lr:0.0001\n",
      "Epoch 8, Step: 2, Loss: 0.1404256969690323, Lr:0.0001\n",
      "Epoch 8, Step: 3, Loss: 0.1155976802110672, Lr:0.0001\n",
      "Epoch 8, Step: 4, Loss: 0.10844585299491882, Lr:0.0001\n",
      "Epoch 8, Step: 5, Loss: 0.371118426322937, Lr:0.0001\n",
      "Epoch 8, Step: 6, Loss: 0.2224830687046051, Lr:0.0001\n",
      "Epoch 8, Step: 7, Loss: 0.048935417085886, Lr:0.0001\n",
      "Epoch 8, Step: 8, Loss: 0.19701072573661804, Lr:0.0001\n",
      "Epoch 8, Step: 9, Loss: 0.15467560291290283, Lr:0.0001\n",
      "Epoch 8, Step: 10, Loss: 0.08185674250125885, Lr:0.0001\n",
      "Epoch 8, Step: 11, Loss: 0.2512173056602478, Lr:0.0001\n",
      "Epoch 8, Step: 12, Loss: 0.26611825823783875, Lr:0.0001\n",
      "Epoch 8, Step: 13, Loss: 0.07861968874931335, Lr:0.0001\n",
      "Epoch 8, Step: 14, Loss: 0.21985840797424316, Lr:0.0001\n",
      "Epoch 8, Step: 15, Loss: 0.07991105318069458, Lr:0.0001\n",
      "Epoch 8, Step: 16, Loss: 0.21624824404716492, Lr:0.0001\n",
      "Epoch 8, Step: 17, Loss: 0.14088179171085358, Lr:0.0001\n",
      "Epoch 8, Step: 18, Loss: 0.1280549168586731, Lr:0.0001\n",
      "Epoch 8, Step: 19, Loss: 0.06934507936239243, Lr:0.0001\n",
      "Epoch 8, Step: 20, Loss: 0.0069136228412389755, Lr:0.0001\n",
      "Epoch 8, Step: 21, Loss: 0.13452067971229553, Lr:0.0001\n",
      "Epoch 8, Step: 22, Loss: 0.026814864948391914, Lr:0.0001\n",
      "Epoch 8, Step: 23, Loss: 0.15089374780654907, Lr:0.0001\n",
      "Epoch 8, Step: 24, Loss: 0.2248455286026001, Lr:0.0001\n",
      "Epoch 8, Step: 25, Loss: 0.13605409860610962, Lr:0.0001\n",
      "Epoch 8, Step: 26, Loss: 0.4653097987174988, Lr:0.0001\n",
      "Epoch 8, Step: 27, Loss: 0.20655883848667145, Lr:0.0001\n",
      "Epoch 8, Step: 28, Loss: 0.3331407308578491, Lr:0.0001\n",
      "Epoch 8, Step: 29, Loss: 0.05324486270546913, Lr:0.0001\n",
      "Epoch 8, Step: 30, Loss: 0.07052437961101532, Lr:0.0001\n",
      "Epoch 8, Step: 31, Loss: 0.0844394639134407, Lr:0.0001\n",
      "Epoch 8, Step: 32, Loss: 0.21327130496501923, Lr:0.0001\n",
      "Epoch 8, Step: 33, Loss: 0.1613043248653412, Lr:0.0001\n",
      "Epoch 8, Step: 34, Loss: 0.08691667020320892, Lr:0.0001\n",
      "Epoch 8, Step: 35, Loss: 0.1809009611606598, Lr:0.0001\n",
      "Epoch 8, Step: 36, Loss: 0.345346599817276, Lr:0.0001\n",
      "Epoch 8, Step: 37, Loss: 0.016291657462716103, Lr:0.0001\n",
      "Epoch 8, Step: 38, Loss: 0.10249173641204834, Lr:0.0001\n",
      "Epoch 8, Step: 39, Loss: 0.3260367214679718, Lr:0.0001\n",
      "Epoch 8, Step: 40, Loss: 0.041442569345235825, Lr:0.0001\n",
      "Epoch 8, Step: 41, Loss: 0.07814902067184448, Lr:0.0001\n",
      "Epoch 8, Step: 42, Loss: 0.19872432947158813, Lr:0.0001\n",
      "Epoch 8, Step: 43, Loss: 0.1539800614118576, Lr:0.0001\n",
      "Epoch 8, Step: 44, Loss: 0.08115021884441376, Lr:0.0001\n",
      "Epoch 8, Step: 45, Loss: 0.1823939085006714, Lr:0.0001\n",
      "Epoch 8, Step: 46, Loss: 0.039176393300294876, Lr:0.0001\n",
      "Epoch 8, Step: 47, Loss: 0.22968007624149323, Lr:0.0001\n",
      "Epoch 8, Step: 48, Loss: 0.07025055587291718, Lr:0.0001\n",
      "Epoch 8, Step: 49, Loss: 0.10063275694847107, Lr:0.0001\n",
      "Epoch 8, Step: 50, Loss: 0.18244697153568268, Lr:0.0001\n",
      "Epoch 8, Step: 51, Loss: 0.21123464405536652, Lr:0.0001\n",
      "Epoch 8, Step: 52, Loss: 0.02325470931828022, Lr:0.0001\n",
      "Epoch 8, Step: 53, Loss: 0.06439898908138275, Lr:0.0001\n",
      "Epoch 8, Step: 54, Loss: 1.1080195903778076, Lr:0.0001\n",
      "Epoch 8, Step: 55, Loss: 0.23666828870773315, Lr:0.0001\n",
      "Epoch 8, Step: 56, Loss: 0.09651748090982437, Lr:0.0001\n",
      "Epoch 8, Step: 57, Loss: 0.16577988862991333, Lr:0.0001\n",
      "Epoch 8, Step: 58, Loss: 0.13308367133140564, Lr:0.0001\n",
      "Epoch 8, Step: 59, Loss: 0.1304229497909546, Lr:0.0001\n",
      "Epoch 8, Step: 60, Loss: 0.040676530450582504, Lr:0.0001\n",
      "Epoch 8, Step: 61, Loss: 0.4573442041873932, Lr:0.0001\n",
      "Epoch 8, Step: 62, Loss: 0.023893404752016068, Lr:0.0001\n",
      "Epoch 8, Step: 63, Loss: 0.26918116211891174, Lr:0.0001\n",
      "Epoch 8, Step: 64, Loss: 0.06394273787736893, Lr:0.0001\n",
      "Epoch 8, Step: 65, Loss: 0.11482783406972885, Lr:0.0001\n",
      "Epoch 8, Step: 66, Loss: 0.07279889285564423, Lr:0.0001\n",
      "Epoch 8, Step: 67, Loss: 0.323103666305542, Lr:0.0001\n",
      "Epoch 8, Step: 68, Loss: 0.19592608511447906, Lr:0.0001\n",
      "Epoch 8, Step: 69, Loss: 0.11754993349313736, Lr:0.0001\n",
      "Epoch 8, Step: 70, Loss: 0.28564485907554626, Lr:0.0001\n",
      "Epoch 8, Step: 71, Loss: 0.3104740083217621, Lr:0.0001\n",
      "Epoch 8, Step: 72, Loss: 0.04860442876815796, Lr:0.0001\n",
      "Epoch 8, Step: 73, Loss: 0.39980825781822205, Lr:0.0001\n",
      "Epoch 8, Step: 74, Loss: 0.36297109723091125, Lr:0.0001\n",
      "Epoch 8, Step: 75, Loss: 0.13719122111797333, Lr:0.0001\n",
      "Epoch 8, Step: 76, Loss: 0.023274431005120277, Lr:0.0001\n",
      "Epoch 8, Step: 77, Loss: 0.4954093396663666, Lr:0.0001\n",
      "Epoch 8, Step: 78, Loss: 0.24053092300891876, Lr:0.0001\n",
      "Epoch 8, Step: 79, Loss: 0.12018276751041412, Lr:0.0001\n",
      "Epoch 8, Step: 80, Loss: 0.11517706513404846, Lr:0.0001\n",
      "Epoch 8, Step: 81, Loss: 0.3021097481250763, Lr:0.0001\n",
      "Epoch 8, Step: 82, Loss: 0.06062241271138191, Lr:0.0001\n",
      "Epoch 8, Step: 83, Loss: 0.14338932931423187, Lr:0.0001\n",
      "Epoch 8, Step: 84, Loss: 0.028018496930599213, Lr:0.0001\n",
      "Epoch 8, Step: 85, Loss: 0.13798943161964417, Lr:0.0001\n",
      "Epoch 8, Step: 86, Loss: 0.07629171013832092, Lr:0.0001\n",
      "Epoch 8, Step: 87, Loss: 0.0873698741197586, Lr:0.0001\n",
      "Epoch 8, Step: 88, Loss: 0.094195157289505, Lr:0.0001\n",
      "Epoch 8, Step: 89, Loss: 0.1315869837999344, Lr:0.0001\n",
      "Epoch 8, Step: 90, Loss: 0.11813495308160782, Lr:0.0001\n",
      "Epoch 8, Step: 91, Loss: 0.11717593669891357, Lr:0.0001\n",
      "Epoch 8, Step: 92, Loss: 0.11658868193626404, Lr:0.0001\n",
      "Epoch 8, Step: 93, Loss: 0.21565687656402588, Lr:0.0001\n",
      "Epoch 8, Step: 94, Loss: 0.08427884429693222, Lr:0.0001\n",
      "Epoch 8, Step: 95, Loss: 0.11406762897968292, Lr:0.0001\n",
      "Epoch 8, Step: 96, Loss: 0.08879365772008896, Lr:0.0001\n",
      "Epoch 8, Step: 97, Loss: 0.22169092297554016, Lr:0.0001\n",
      "Epoch 8, Step: 98, Loss: 0.06883872300386429, Lr:0.0001\n",
      "Epoch 8, Step: 99, Loss: 0.12236623466014862, Lr:0.0001\n",
      "Epoch 8, Step: 100, Loss: 0.07634158432483673, Lr:0.0001\n",
      "Epoch 8, Step: 101, Loss: 0.03917890042066574, Lr:0.0001\n",
      "Epoch 8, Step: 102, Loss: 0.16681595146656036, Lr:0.0001\n",
      "Epoch 8, Step: 103, Loss: 0.22940966486930847, Lr:0.0001\n",
      "Epoch 8, Step: 104, Loss: 0.27800101041793823, Lr:0.0001\n",
      "Epoch 8, Step: 105, Loss: 0.0954190194606781, Lr:0.0001\n",
      "Epoch 8, Step: 106, Loss: 0.09251286089420319, Lr:0.0001\n",
      "Epoch 8, Step: 107, Loss: 0.20953874289989471, Lr:0.0001\n",
      "Epoch 8, Step: 108, Loss: 0.11457157880067825, Lr:0.0001\n",
      "Epoch 8, Step: 109, Loss: 0.25001880526542664, Lr:0.0001\n",
      "Epoch 8, Step: 110, Loss: 0.08973105996847153, Lr:0.0001\n",
      "Epoch 8, Step: 111, Loss: 0.2628987431526184, Lr:0.0001\n",
      "Epoch 8, Step: 112, Loss: 0.060299038887023926, Lr:0.0001\n",
      "Epoch 8, Step: 113, Loss: 0.19333596527576447, Lr:0.0001\n",
      "Epoch 8, Step: 114, Loss: 0.3524506688117981, Lr:0.0001\n",
      "Epoch 8, Step: 115, Loss: 0.3389909565448761, Lr:0.0001\n",
      "Epoch 8, Step: 116, Loss: 0.31826335191726685, Lr:0.0001\n",
      "Epoch 8, Step: 117, Loss: 0.055249642580747604, Lr:0.0001\n",
      "Epoch 8, Step: 118, Loss: 0.08055847883224487, Lr:0.0001\n",
      "Epoch 8, Step: 119, Loss: 0.5002726316452026, Lr:0.0001\n",
      "Epoch 8, Step: 120, Loss: 0.07285100221633911, Lr:0.0001\n",
      "Epoch 8, Step: 121, Loss: 0.09852191805839539, Lr:0.0001\n",
      "Epoch 8, Step: 122, Loss: 0.0450076200067997, Lr:0.0001\n",
      "Epoch 8, Step: 123, Loss: 0.4042244255542755, Lr:0.0001\n",
      "Epoch 8, Step: 124, Loss: 0.42560169100761414, Lr:0.0001\n",
      "Epoch 8, Step: 125, Loss: 0.17503288388252258, Lr:0.0001\n",
      "Epoch 8, Step: 126, Loss: 0.1871173083782196, Lr:0.0001\n",
      "Epoch 8, Step: 127, Loss: 0.02684803307056427, Lr:0.0001\n",
      "Epoch 8, Step: 128, Loss: 0.07942803204059601, Lr:0.0001\n",
      "Epoch 8, Step: 129, Loss: 0.07962849736213684, Lr:0.0001\n",
      "Epoch 8, Step: 130, Loss: 0.35868194699287415, Lr:0.0001\n",
      "Epoch 8, Step: 131, Loss: 0.49214306473731995, Lr:0.0001\n",
      "Epoch 8, Step: 132, Loss: 0.3322148025035858, Lr:0.0001\n",
      "Epoch 8, Step: 133, Loss: 0.29567110538482666, Lr:0.0001\n",
      "Epoch 8, Step: 134, Loss: 0.10467396676540375, Lr:0.0001\n",
      "Epoch 8, Step: 135, Loss: 0.04701833799481392, Lr:0.0001\n",
      "Epoch 8, Step: 136, Loss: 0.15529543161392212, Lr:0.0001\n",
      "Epoch 8, Step: 137, Loss: 0.16287970542907715, Lr:0.0001\n",
      "Epoch 8, Step: 138, Loss: 0.10133510828018188, Lr:0.0001\n",
      "Epoch 8, Step: 139, Loss: 0.0935908779501915, Lr:0.0001\n",
      "Epoch 8, Step: 140, Loss: 0.3162270486354828, Lr:0.0001\n",
      "Epoch 8, Step: 141, Loss: 0.04538530856370926, Lr:0.0001\n",
      "Epoch 8, Step: 142, Loss: 0.08337026089429855, Lr:0.0001\n",
      "Epoch 8, Step: 143, Loss: 0.1575566977262497, Lr:0.0001\n",
      "Epoch 8, Step: 144, Loss: 0.12901125848293304, Lr:0.0001\n",
      "Epoch 8, Step: 145, Loss: 0.13786581158638, Lr:0.0001\n",
      "Epoch 8, Step: 146, Loss: 0.3309619426727295, Lr:0.0001\n",
      "Epoch 8, Step: 147, Loss: 0.2861202359199524, Lr:0.0001\n",
      "Epoch 8, Step: 148, Loss: 0.04665926471352577, Lr:0.0001\n",
      "Epoch 8, Step: 149, Loss: 0.05480903014540672, Lr:0.0001\n",
      "Epoch 8, Step: 150, Loss: 0.3936060667037964, Lr:0.0001\n",
      "Epoch 8, Step: 151, Loss: 0.23383814096450806, Lr:0.0001\n",
      "Epoch 8, Step: 152, Loss: 0.03840283676981926, Lr:0.0001\n",
      "Epoch 8, Step: 153, Loss: 0.2361273318529129, Lr:0.0001\n",
      "Epoch 8, Step: 154, Loss: 0.061791837215423584, Lr:0.0001\n",
      "Epoch 8, Step: 155, Loss: 0.020231764763593674, Lr:0.0001\n",
      "Epoch 8, Step: 156, Loss: 0.12168247252702713, Lr:0.0001\n",
      "Epoch 8, Step: 157, Loss: 0.04247705638408661, Lr:0.0001\n",
      "Epoch 8, Step: 158, Loss: 0.10167388617992401, Lr:0.0001\n",
      "Epoch 8, Step: 159, Loss: 0.18150055408477783, Lr:0.0001\n",
      "Epoch 8, Step: 160, Loss: 0.34623095393180847, Lr:0.0001\n",
      "Epoch 8, Step: 161, Loss: 0.03068562224507332, Lr:0.0001\n",
      "Epoch 8, Step: 162, Loss: 0.15977194905281067, Lr:0.0001\n",
      "Epoch 8, Step: 163, Loss: 0.16300295293331146, Lr:0.0001\n",
      "Epoch 8, Step: 164, Loss: 0.4089258313179016, Lr:0.0001\n",
      "Epoch 8, Step: 165, Loss: 0.16176532208919525, Lr:0.0001\n",
      "Epoch 8, Step: 166, Loss: 0.011759200133383274, Lr:0.0001\n",
      "Epoch 8, Step: 167, Loss: 0.19572848081588745, Lr:0.0001\n",
      "Epoch 8, Step: 168, Loss: 0.06607021391391754, Lr:0.0001\n",
      "Epoch 8, Step: 169, Loss: 0.24337221682071686, Lr:0.0001\n",
      "Epoch 8, Step: 170, Loss: 0.09543242305517197, Lr:0.0001\n",
      "Epoch 8, Step: 171, Loss: 0.13930436968803406, Lr:0.0001\n",
      "Epoch 8, Step: 172, Loss: 0.1704937070608139, Lr:0.0001\n",
      "Epoch 8, Step: 173, Loss: 0.04207511246204376, Lr:0.0001\n",
      "Epoch 8, Step: 174, Loss: 0.1907167285680771, Lr:0.0001\n",
      "Epoch 8, Step: 175, Loss: 0.34929829835891724, Lr:0.0001\n",
      "Epoch 8, Step: 176, Loss: 0.11742334812879562, Lr:0.0001\n",
      "Epoch 8, Step: 177, Loss: 0.19702522456645966, Lr:0.0001\n",
      "Epoch 8, Step: 178, Loss: 0.12352796643972397, Lr:0.0001\n",
      "Epoch 8, Step: 179, Loss: 0.13034717738628387, Lr:0.0001\n",
      "Epoch 8, Step: 180, Loss: 0.1964302957057953, Lr:0.0001\n",
      "Epoch 8, Step: 181, Loss: 0.05961082875728607, Lr:0.0001\n",
      "Epoch 8, Step: 182, Loss: 0.12497036159038544, Lr:0.0001\n",
      "Epoch 8, Step: 183, Loss: 0.051880788058042526, Lr:0.0001\n",
      "Epoch 8, Step: 184, Loss: 0.13488143682479858, Lr:0.0001\n",
      "Epoch 8, Step: 185, Loss: 0.2884474992752075, Lr:0.0001\n",
      "Epoch 8, Step: 186, Loss: 0.10254067182540894, Lr:0.0001\n",
      "Epoch 8, Step: 187, Loss: 0.15007002651691437, Lr:0.0001\n",
      "Epoch 8, Step: 188, Loss: 0.33229294419288635, Lr:0.0001\n",
      "Epoch 8, Step: 189, Loss: 0.39695703983306885, Lr:0.0001\n",
      "Epoch 8, Step: 190, Loss: 0.06143493950366974, Lr:0.0001\n",
      "Epoch 8, Step: 191, Loss: 0.038575515151023865, Lr:0.0001\n",
      "Epoch 8, Step: 192, Loss: 0.13949841260910034, Lr:0.0001\n",
      "Epoch 8, Step: 193, Loss: 0.1739281862974167, Lr:0.0001\n",
      "Epoch 8, Step: 194, Loss: 0.10411760210990906, Lr:0.0001\n",
      "Epoch 8, Step: 195, Loss: 0.9199996590614319, Lr:0.0001\n",
      "Epoch 8, Step: 196, Loss: 0.2827959656715393, Lr:0.0001\n",
      "Epoch 8, Step: 197, Loss: 0.05348042771220207, Lr:0.0001\n",
      "Epoch 8, Step: 198, Loss: 0.1752288043498993, Lr:0.0001\n",
      "Epoch 8, Step: 199, Loss: 0.2131108194589615, Lr:0.0001\n",
      "Epoch 8, Step: 200, Loss: 0.2832639813423157, Lr:0.0001\n",
      "Epoch 8, Step: 201, Loss: 0.046118903905153275, Lr:0.0001\n",
      "Epoch 8, Step: 202, Loss: 0.006154460832476616, Lr:0.0001\n",
      "Epoch 8, Step: 203, Loss: 0.3869532644748688, Lr:0.0001\n",
      "Epoch 8, Step: 204, Loss: 0.08714362233877182, Lr:0.0001\n",
      "Epoch 8, Step: 205, Loss: 0.14379803836345673, Lr:0.0001\n",
      "Epoch 8, Step: 206, Loss: 0.13343946635723114, Lr:0.0001\n",
      "Epoch 8, Step: 207, Loss: 0.5321921706199646, Lr:0.0001\n",
      "Epoch 8, Step: 208, Loss: 0.07915106415748596, Lr:0.0001\n",
      "Epoch 8, Step: 209, Loss: 0.10068599134683609, Lr:0.0001\n",
      "Epoch 8, Step: 210, Loss: 0.6878216862678528, Lr:0.0001\n",
      "Epoch 8, Step: 211, Loss: 0.4445101022720337, Lr:0.0001\n",
      "Epoch 8, Step: 212, Loss: 0.24728180468082428, Lr:0.0001\n",
      "Epoch 8, Step: 213, Loss: 0.08589578419923782, Lr:0.0001\n",
      "Epoch 8, Step: 214, Loss: 0.3193320631980896, Lr:0.0001\n",
      "Epoch 8, Step: 215, Loss: 0.05175018683075905, Lr:0.0001\n",
      "Epoch 8, Step: 216, Loss: 0.03622041642665863, Lr:0.0001\n",
      "Epoch 8, Step: 217, Loss: 0.07353844493627548, Lr:0.0001\n",
      "Epoch 8, Step: 218, Loss: 0.06492412090301514, Lr:0.0001\n",
      "Epoch 8, Step: 219, Loss: 0.05596471205353737, Lr:0.0001\n",
      "Epoch 8, Step: 220, Loss: 0.05229644849896431, Lr:0.0001\n",
      "Epoch 8, Step: 221, Loss: 0.02118717133998871, Lr:0.0001\n",
      "Epoch 8, Step: 222, Loss: 0.15592065453529358, Lr:0.0001\n",
      "Epoch 8, Step: 223, Loss: 0.32636910676956177, Lr:0.0001\n",
      "Epoch 8, Step: 224, Loss: 0.10112293809652328, Lr:0.0001\n",
      "Epoch 8, Step: 225, Loss: 0.08957023173570633, Lr:0.0001\n",
      "Epoch 8, Step: 226, Loss: 0.3115440011024475, Lr:0.0001\n",
      "Epoch 8, Step: 227, Loss: 0.2995435893535614, Lr:0.0001\n",
      "Epoch 8, Step: 228, Loss: 0.1842854917049408, Lr:0.0001\n",
      "Epoch 8, Step: 229, Loss: 0.1630115956068039, Lr:0.0001\n",
      "Epoch 8, Step: 230, Loss: 0.2734721601009369, Lr:0.0001\n",
      "Epoch 8, Step: 231, Loss: 0.042125023901462555, Lr:0.0001\n",
      "Epoch 8, Step: 232, Loss: 0.24290288984775543, Lr:0.0001\n",
      "Epoch 8, Step: 233, Loss: 0.21395863592624664, Lr:0.0001\n",
      "Epoch 8, Step: 234, Loss: 0.06085934489965439, Lr:0.0001\n",
      "Epoch 8, Step: 235, Loss: 0.09408724308013916, Lr:0.0001\n",
      "Epoch 8, Step: 236, Loss: 0.182229682803154, Lr:0.0001\n",
      "Epoch 8, Step: 237, Loss: 0.04973629117012024, Lr:0.0001\n",
      "Epoch 8, Step: 238, Loss: 0.06533420085906982, Lr:0.0001\n",
      "Epoch 8, Step: 239, Loss: 0.041846200823783875, Lr:0.0001\n",
      "Epoch 8, Step: 240, Loss: 0.2729471027851105, Lr:0.0001\n",
      "Epoch 8, Step: 241, Loss: 0.0738593339920044, Lr:0.0001\n",
      "Epoch 8, Step: 242, Loss: 0.3483723998069763, Lr:0.0001\n",
      "Epoch 8, Step: 243, Loss: 0.19833798706531525, Lr:0.0001\n",
      "Epoch 8, Step: 244, Loss: 0.187159463763237, Lr:0.0001\n",
      "Epoch 8, Step: 245, Loss: 0.2542884349822998, Lr:0.0001\n",
      "Epoch 8, Step: 246, Loss: 0.005892759654670954, Lr:0.0001\n",
      "Epoch 8, Step: 247, Loss: 0.3016848862171173, Lr:0.0001\n",
      "Epoch 8, Step: 248, Loss: 0.1607522815465927, Lr:0.0001\n",
      "Epoch 8, Step: 249, Loss: 0.19140669703483582, Lr:0.0001\n",
      "Epoch 8, Step: 250, Loss: 0.17866173386573792, Lr:0.0001\n",
      "Epoch 8, Step: 251, Loss: 0.3818565011024475, Lr:0.0001\n",
      "Epoch 8, Step: 252, Loss: 0.10237573087215424, Lr:0.0001\n",
      "Epoch 8, Step: 253, Loss: 0.08610657602548599, Lr:0.0001\n",
      "Epoch 8, Step: 254, Loss: 0.3082912266254425, Lr:0.0001\n",
      "Epoch 8, Step: 255, Loss: 0.01608215644955635, Lr:0.0001\n",
      "Epoch 8, Step: 256, Loss: 0.15763583779335022, Lr:0.0001\n",
      "Epoch 8, Step: 257, Loss: 0.14983859658241272, Lr:0.0001\n",
      "Epoch 8, Step: 258, Loss: 0.13745862245559692, Lr:0.0001\n",
      "Epoch 8, Step: 259, Loss: 0.22305071353912354, Lr:0.0001\n",
      "Epoch 8, Step: 260, Loss: 0.12943974137306213, Lr:0.0001\n",
      "Epoch 8, Step: 261, Loss: 0.16138388216495514, Lr:0.0001\n",
      "Epoch 8, Step: 262, Loss: 0.22809286415576935, Lr:0.0001\n",
      "Epoch 8, Step: 263, Loss: 0.01104594673961401, Lr:0.0001\n",
      "Epoch 8, Step: 264, Loss: 0.32021284103393555, Lr:0.0001\n",
      "Epoch 8, Step: 265, Loss: 0.4398635923862457, Lr:0.0001\n",
      "Epoch 8, Step: 266, Loss: 0.03710261732339859, Lr:0.0001\n",
      "Epoch 8, Step: 267, Loss: 0.27852627635002136, Lr:0.0001\n",
      "Epoch 8, Step: 268, Loss: 0.031843408942222595, Lr:0.0001\n",
      "Epoch 8, Step: 269, Loss: 0.27849990129470825, Lr:0.0001\n",
      "Epoch 8, Step: 270, Loss: 0.04874018207192421, Lr:0.0001\n",
      "Epoch 8, Step: 271, Loss: 0.2842816710472107, Lr:0.0001\n",
      "Epoch 8, Step: 272, Loss: 0.10060922801494598, Lr:0.0001\n",
      "Epoch 8, Step: 273, Loss: 0.2612995505332947, Lr:0.0001\n",
      "Epoch 8, Step: 274, Loss: 0.18695373833179474, Lr:0.0001\n",
      "Epoch 8, Step: 275, Loss: 0.04557959362864494, Lr:0.0001\n",
      "Epoch 8, Step: 276, Loss: 0.3571152687072754, Lr:0.0001\n",
      "Epoch 8, Step: 277, Loss: 0.10926243662834167, Lr:0.0001\n",
      "Epoch 8, Step: 278, Loss: 0.11126428842544556, Lr:0.0001\n",
      "Epoch 8, Step: 279, Loss: 0.19458121061325073, Lr:0.0001\n",
      "Epoch 8, Step: 280, Loss: 0.07259664684534073, Lr:0.0001\n",
      "Epoch 8, Step: 281, Loss: 0.26273494958877563, Lr:0.0001\n",
      "Epoch 8, Step: 282, Loss: 0.12018517404794693, Lr:0.0001\n",
      "Epoch 8, Step: 283, Loss: 0.1744336038827896, Lr:0.0001\n",
      "Epoch 8, Step: 284, Loss: 0.11867137253284454, Lr:0.0001\n",
      "Epoch 8, Step: 285, Loss: 0.2277730405330658, Lr:0.0001\n",
      "Epoch 8, Step: 286, Loss: 0.3661591112613678, Lr:0.0001\n",
      "Epoch 8, Step: 287, Loss: 0.16540111601352692, Lr:0.0001\n",
      "Epoch 8, Step: 288, Loss: 0.4377627372741699, Lr:0.0001\n",
      "Epoch 8, Step: 289, Loss: 0.16284966468811035, Lr:0.0001\n",
      "Epoch 8, Step: 290, Loss: 0.33750519156455994, Lr:0.0001\n",
      "Epoch 8, Step: 291, Loss: 0.21804431080818176, Lr:0.0001\n",
      "Epoch 8, Step: 292, Loss: 0.1070607602596283, Lr:0.0001\n",
      "Epoch 8, Step: 293, Loss: 0.10023463517427444, Lr:0.0001\n",
      "Epoch 8, Step: 294, Loss: 0.4074488878250122, Lr:0.0001\n",
      "Epoch 8, Step: 295, Loss: 0.10955163091421127, Lr:0.0001\n",
      "Epoch 8, Step: 296, Loss: 0.17457665503025055, Lr:0.0001\n",
      "Epoch 8, Step: 297, Loss: 0.22574913501739502, Lr:0.0001\n",
      "Epoch 8, Step: 298, Loss: 0.15608935058116913, Lr:0.0001\n",
      "Epoch 8, Step: 299, Loss: 0.13000579178333282, Lr:0.0001\n",
      "Epoch 8, Step: 300, Loss: 0.17152920365333557, Lr:0.0001\n",
      "Epoch 8, Step: 301, Loss: 0.387961745262146, Lr:0.0001\n",
      "Epoch 8, Step: 302, Loss: 0.11967183649539948, Lr:0.0001\n",
      "Epoch 8, Step: 303, Loss: 0.36593249440193176, Lr:0.0001\n",
      "Epoch 8, Step: 304, Loss: 0.08233743906021118, Lr:0.0001\n",
      "Epoch 8, Step: 305, Loss: 0.12471771240234375, Lr:0.0001\n",
      "Epoch 8, Step: 306, Loss: 0.09623190015554428, Lr:0.0001\n",
      "Epoch 8, Step: 307, Loss: 0.10717938095331192, Lr:0.0001\n",
      "Epoch 8, Step: 308, Loss: 0.11701469868421555, Lr:0.0001\n",
      "Epoch 8, Step: 309, Loss: 0.1816556453704834, Lr:0.0001\n",
      "Epoch 8, Step: 310, Loss: 0.19395825266838074, Lr:0.0001\n",
      "Epoch 8, Step: 311, Loss: 0.27243077754974365, Lr:0.0001\n",
      "Epoch 8, Step: 312, Loss: 0.2510136365890503, Lr:0.0001\n",
      "Epoch 8, Step: 313, Loss: 0.16708147525787354, Lr:0.0001\n",
      "Epoch 8, Step: 314, Loss: 0.13153532147407532, Lr:0.0001\n",
      "Epoch 8, Step: 315, Loss: 0.21230575442314148, Lr:0.0001\n",
      "Epoch 8, Step: 316, Loss: 0.08552426099777222, Lr:0.0001\n",
      "Epoch 8, Step: 317, Loss: 0.2877357006072998, Lr:0.0001\n",
      "Epoch 8, Step: 318, Loss: 0.11376237869262695, Lr:0.0001\n",
      "Epoch 8, Step: 319, Loss: 0.012597749009728432, Lr:0.0001\n",
      "Epoch 8, Step: 320, Loss: 0.07143799215555191, Lr:0.0001\n",
      "Epoch 8, Step: 321, Loss: 0.08179726451635361, Lr:0.0001\n",
      "Epoch 8, Step: 322, Loss: 0.4967082738876343, Lr:0.0001\n",
      "Epoch 8, Step: 323, Loss: 0.15249836444854736, Lr:0.0001\n",
      "Epoch 8, Step: 324, Loss: 0.15048256516456604, Lr:0.0001\n",
      "Epoch 8, Step: 325, Loss: 0.07176879048347473, Lr:0.0001\n",
      "Epoch 8, Step: 326, Loss: 0.1316148191690445, Lr:0.0001\n",
      "Epoch 8, Step: 327, Loss: 0.04591669142246246, Lr:0.0001\n",
      "Epoch 8, Step: 328, Loss: 0.08251091092824936, Lr:0.0001\n",
      "Epoch 8, Step: 329, Loss: 0.27791106700897217, Lr:0.0001\n",
      "Epoch 8, Step: 330, Loss: 0.07453115284442902, Lr:0.0001\n",
      "Epoch 8, Step: 331, Loss: 0.11467190086841583, Lr:0.0001\n",
      "Epoch 8, Step: 332, Loss: 0.13393008708953857, Lr:0.0001\n",
      "Epoch 8, Step: 333, Loss: 0.08339931070804596, Lr:0.0001\n",
      "Epoch 8, Step: 334, Loss: 0.2175440490245819, Lr:0.0001\n",
      "Epoch 8, Step: 335, Loss: 0.5665656924247742, Lr:0.0001\n",
      "Epoch 8, Step: 336, Loss: 0.07059105485677719, Lr:0.0001\n",
      "Epoch 8, Step: 337, Loss: 0.16805791854858398, Lr:0.0001\n",
      "Epoch 8, Step: 338, Loss: 0.05089139565825462, Lr:0.0001\n",
      "Epoch 8, Step: 339, Loss: 0.05216309428215027, Lr:0.0001\n",
      "Epoch 8, Step: 340, Loss: 0.2498176097869873, Lr:0.0001\n",
      "Epoch 8, Step: 341, Loss: 0.05804537981748581, Lr:0.0001\n",
      "Epoch 8, Step: 342, Loss: 0.1521860957145691, Lr:0.0001\n",
      "Epoch 8, Step: 343, Loss: 0.04661194235086441, Lr:0.0001\n",
      "Epoch 8, Step: 344, Loss: 0.1791207492351532, Lr:0.0001\n",
      "Epoch 8, Step: 345, Loss: 0.07321212440729141, Lr:0.0001\n",
      "Epoch 8, Step: 346, Loss: 0.11803198605775833, Lr:0.0001\n",
      "Epoch 8, Step: 347, Loss: 0.2415376752614975, Lr:0.0001\n",
      "Epoch 8, Step: 348, Loss: 0.06572332233190536, Lr:0.0001\n",
      "Epoch 8, Step: 349, Loss: 0.12162954360246658, Lr:0.0001\n",
      "Epoch 8, Step: 350, Loss: 0.2039550542831421, Lr:0.0001\n",
      "Epoch 8, Step: 351, Loss: 0.018257059156894684, Lr:0.0001\n",
      "Epoch 8, Step: 352, Loss: 0.044825002551078796, Lr:0.0001\n",
      "Epoch 8, Step: 353, Loss: 0.21385176479816437, Lr:0.0001\n",
      "Epoch 8, Step: 354, Loss: 0.0695258155465126, Lr:0.0001\n",
      "Epoch 8, Step: 355, Loss: 0.08078653365373611, Lr:0.0001\n",
      "Epoch 8, Step: 356, Loss: 0.3111913204193115, Lr:0.0001\n",
      "Epoch 8, Step: 357, Loss: 0.08348201215267181, Lr:0.0001\n",
      "Epoch 8, Step: 358, Loss: 0.29711806774139404, Lr:0.0001\n",
      "Epoch 8, Step: 359, Loss: 0.3799167573451996, Lr:0.0001\n",
      "Epoch 8, Step: 360, Loss: 0.05804058164358139, Lr:0.0001\n",
      "Epoch 8, Step: 361, Loss: 0.2033863514661789, Lr:0.0001\n",
      "Epoch 8, Step: 362, Loss: 0.04936880245804787, Lr:0.0001\n",
      "Epoch 8, Step: 363, Loss: 0.1446123868227005, Lr:0.0001\n",
      "Epoch 8, Step: 364, Loss: 0.06844554841518402, Lr:0.0001\n",
      "Epoch 8, Step: 365, Loss: 0.16611799597740173, Lr:0.0001\n",
      "Epoch 8, Step: 366, Loss: 0.17765963077545166, Lr:0.0001\n",
      "Epoch 8, Step: 367, Loss: 0.20036981999874115, Lr:0.0001\n",
      "Epoch 8, Step: 368, Loss: 0.19025209546089172, Lr:0.0001\n",
      "Epoch 8, Step: 369, Loss: 0.3015531003475189, Lr:0.0001\n",
      "Epoch 8, Step: 370, Loss: 0.2838119864463806, Lr:0.0001\n",
      "Epoch 8, Step: 371, Loss: 0.1075889840722084, Lr:0.0001\n",
      "Epoch 8, Step: 372, Loss: 0.08968302607536316, Lr:0.0001\n",
      "Epoch 8, Step: 373, Loss: 0.2803468704223633, Lr:0.0001\n",
      "Epoch 8, Step: 374, Loss: 0.14606986939907074, Lr:0.0001\n",
      "Epoch 8, Step: 375, Loss: 0.1437990665435791, Lr:0.0001\n",
      "Epoch 8, Step: 376, Loss: 0.3018965423107147, Lr:0.0001\n",
      "Epoch 8, Step: 377, Loss: 0.13431471586227417, Lr:0.0001\n",
      "Epoch 8, Step: 378, Loss: 0.1709364801645279, Lr:0.0001\n",
      "Epoch 8, Step: 379, Loss: 0.12253334373235703, Lr:0.0001\n",
      "Epoch 8, Step: 380, Loss: 0.3528222143650055, Lr:0.0001\n",
      "Epoch 8, Step: 381, Loss: 0.008304288610816002, Lr:0.0001\n",
      "Epoch 8, Step: 382, Loss: 0.20174160599708557, Lr:0.0001\n",
      "Epoch 8, Step: 383, Loss: 0.09928560256958008, Lr:0.0001\n",
      "Epoch 8, Step: 384, Loss: 0.2429352104663849, Lr:0.0001\n",
      "Epoch 8, Step: 385, Loss: 0.4073299169540405, Lr:0.0001\n",
      "Epoch 8, Step: 386, Loss: 0.28247037529945374, Lr:0.0001\n",
      "Epoch 8, Step: 387, Loss: 0.1808309257030487, Lr:0.0001\n",
      "Epoch 8, Step: 388, Loss: 0.27578458189964294, Lr:0.0001\n",
      "Epoch 8, Step: 389, Loss: 0.15238222479820251, Lr:0.0001\n",
      "Epoch 8, Step: 390, Loss: 0.050059974193573, Lr:0.0001\n",
      "Epoch 8, Step: 391, Loss: 0.10852842032909393, Lr:0.0001\n",
      "Epoch 8, Step: 392, Loss: 0.22332927584648132, Lr:0.0001\n",
      "Epoch 8, Step: 393, Loss: 0.128949835896492, Lr:0.0001\n",
      "Epoch 8, Step: 394, Loss: 0.04468684270977974, Lr:0.0001\n",
      "Epoch 8, Step: 395, Loss: 0.06165774539113045, Lr:0.0001\n",
      "Epoch 8, Step: 396, Loss: 0.19034771621227264, Lr:0.0001\n",
      "Epoch 8, Step: 397, Loss: 0.060130517929792404, Lr:0.0001\n",
      "Epoch 8, Step: 398, Loss: 0.09937649965286255, Lr:0.0001\n",
      "Epoch 8, Step: 399, Loss: 0.12875503301620483, Lr:0.0001\n",
      "Epoch 8, Step: 400, Loss: 0.3077593147754669, Lr:0.0001\n",
      "Epoch 8, Step: 401, Loss: 0.22679628431797028, Lr:0.0001\n",
      "Epoch 8, Step: 402, Loss: 0.12980720400810242, Lr:0.0001\n",
      "Epoch 8, Step: 403, Loss: 0.10994640737771988, Lr:0.0001\n",
      "Epoch 8, Step: 404, Loss: 0.1113576740026474, Lr:0.0001\n",
      "Epoch 8, Step: 405, Loss: 0.07841434329748154, Lr:0.0001\n",
      "Epoch 8, Step: 406, Loss: 0.10924605280160904, Lr:0.0001\n",
      "Epoch 8, Step: 407, Loss: 0.17445522546768188, Lr:0.0001\n",
      "Epoch 8, Step: 408, Loss: 0.04035118222236633, Lr:0.0001\n",
      "Epoch 8, Step: 409, Loss: 0.07824155688285828, Lr:0.0001\n",
      "Epoch 8, Step: 410, Loss: 0.2252054661512375, Lr:0.0001\n",
      "Epoch 8, Step: 411, Loss: 0.12358375638723373, Lr:0.0001\n",
      "Epoch 8, Step: 412, Loss: 0.10815953463315964, Lr:0.0001\n",
      "Epoch 8, Step: 413, Loss: 0.25019627809524536, Lr:0.0001\n",
      "Epoch 8, Step: 414, Loss: 0.03496601805090904, Lr:0.0001\n",
      "Epoch 8, Step: 415, Loss: 0.3192979693412781, Lr:0.0001\n",
      "Epoch 8, Step: 416, Loss: 0.031118614599108696, Lr:0.0001\n",
      "Epoch 8, Step: 417, Loss: 0.30923473834991455, Lr:0.0001\n",
      "Epoch 8, Step: 418, Loss: 0.11562057584524155, Lr:0.0001\n",
      "Epoch 8, Step: 419, Loss: 0.09268908202648163, Lr:0.0001\n",
      "Epoch 8, Step: 420, Loss: 0.011849592439830303, Lr:0.0001\n",
      "Epoch 8, Step: 421, Loss: 0.2851096987724304, Lr:0.0001\n",
      "Epoch 8, Step: 422, Loss: 0.08949559926986694, Lr:0.0001\n",
      "Epoch 8, Step: 423, Loss: 0.08397921174764633, Lr:0.0001\n",
      "Epoch 8, Step: 424, Loss: 0.03397870063781738, Lr:0.0001\n",
      "Epoch 8, Step: 425, Loss: 0.0596565306186676, Lr:0.0001\n",
      "Epoch 8, Step: 426, Loss: 0.06591219455003738, Lr:0.0001\n",
      "Epoch 8, Step: 427, Loss: 0.11208650469779968, Lr:0.0001\n",
      "Epoch 8, Step: 428, Loss: 0.08725564181804657, Lr:0.0001\n",
      "Epoch 8, Step: 429, Loss: 0.03591213747859001, Lr:0.0001\n",
      "Epoch 8, Step: 430, Loss: 0.049518756568431854, Lr:0.0001\n",
      "Epoch 8, Step: 431, Loss: 0.059444040060043335, Lr:0.0001\n",
      "Epoch 8, Step: 432, Loss: 0.04933988302946091, Lr:0.0001\n",
      "Epoch 8, Step: 433, Loss: 0.04593038931488991, Lr:0.0001\n",
      "Epoch 8, Step: 434, Loss: 0.3036653697490692, Lr:0.0001\n",
      "Epoch 8, Step: 435, Loss: 0.2296483814716339, Lr:0.0001\n",
      "Epoch 8, Step: 436, Loss: 0.26183852553367615, Lr:0.0001\n",
      "Epoch 8, Step: 437, Loss: 0.4572693109512329, Lr:0.0001\n",
      "Epoch 8, Step: 438, Loss: 0.35481971502304077, Lr:0.0001\n",
      "Epoch 8, Step: 439, Loss: 0.2127513885498047, Lr:0.0001\n",
      "Epoch 8, Step: 440, Loss: 0.23236866295337677, Lr:0.0001\n",
      "Epoch 8, Step: 441, Loss: 0.0641314908862114, Lr:0.0001\n",
      "Epoch 8, Step: 442, Loss: 0.13028965890407562, Lr:0.0001\n",
      "Epoch 8, Step: 443, Loss: 0.14580172300338745, Lr:0.0001\n",
      "Epoch 8, Step: 444, Loss: 0.09566767513751984, Lr:0.0001\n",
      "Epoch 8, Step: 445, Loss: 0.1436680555343628, Lr:0.0001\n",
      "Epoch 8, Step: 446, Loss: 0.14997096359729767, Lr:0.0001\n",
      "Epoch 8, Step: 447, Loss: 0.21153908967971802, Lr:0.0001\n",
      "Epoch 8, Step: 448, Loss: 0.23528413474559784, Lr:0.0001\n",
      "Epoch 8, Step: 449, Loss: 0.19656343758106232, Lr:0.0001\n",
      "Epoch 8, Step: 450, Loss: 0.05808963254094124, Lr:0.0001\n",
      "Epoch 8, Step: 451, Loss: 0.0681125745177269, Lr:0.0001\n",
      "Epoch 8, Step: 452, Loss: 0.3829341530799866, Lr:0.0001\n",
      "Epoch 8, Step: 453, Loss: 0.2226477861404419, Lr:0.0001\n",
      "Epoch 8, Step: 454, Loss: 0.0657939463853836, Lr:0.0001\n",
      "Epoch 8, Step: 455, Loss: 0.1372658759355545, Lr:0.0001\n",
      "Epoch 8, Step: 456, Loss: 0.35818618535995483, Lr:0.0001\n",
      "Epoch 8, Step: 457, Loss: 0.4628775119781494, Lr:0.0001\n",
      "Epoch 8, Step: 458, Loss: 0.10537910461425781, Lr:0.0001\n",
      "Epoch 8, Step: 459, Loss: 0.26566195487976074, Lr:0.0001\n",
      "Epoch 8, Step: 460, Loss: 0.1593761295080185, Lr:0.0001\n",
      "Epoch 8, Step: 461, Loss: 0.12317273020744324, Lr:0.0001\n",
      "Epoch 8, Step: 462, Loss: 0.46738460659980774, Lr:0.0001\n",
      "Epoch 8, Step: 463, Loss: 0.11921784281730652, Lr:0.0001\n",
      "Epoch 8, Step: 464, Loss: 0.11161156743764877, Lr:0.0001\n",
      "Epoch 8, Step: 465, Loss: 0.0715409368276596, Lr:0.0001\n",
      "Epoch 8, Step: 466, Loss: 0.03484004735946655, Lr:0.0001\n",
      "Epoch 8, Step: 467, Loss: 0.070463627576828, Lr:0.0001\n",
      "Epoch 8, Step: 468, Loss: 0.07888679951429367, Lr:0.0001\n",
      "Epoch 8, Step: 469, Loss: 0.18291911482810974, Lr:0.0001\n",
      "Epoch 8, Step: 470, Loss: 0.1861935257911682, Lr:0.0001\n",
      "Epoch 8, Step: 471, Loss: 0.04890657588839531, Lr:0.0001\n",
      "Epoch 8, Step: 472, Loss: 0.040361400693655014, Lr:0.0001\n",
      "Epoch 8, Step: 473, Loss: 0.28238484263420105, Lr:0.0001\n",
      "Epoch 8, Step: 474, Loss: 0.3806684613227844, Lr:0.0001\n",
      "Epoch 8, Step: 475, Loss: 0.2594486176967621, Lr:0.0001\n",
      "Epoch 8, Step: 476, Loss: 0.09515628218650818, Lr:0.0001\n",
      "Epoch 8, Step: 477, Loss: 0.19115063548088074, Lr:0.0001\n",
      "Epoch 8, Step: 478, Loss: 0.2285998910665512, Lr:0.0001\n",
      "Epoch 8, Step: 479, Loss: 0.1650611013174057, Lr:0.0001\n",
      "Epoch 8, Step: 480, Loss: 0.02592303976416588, Lr:0.0001\n",
      "Epoch 8, Step: 481, Loss: 0.14189688861370087, Lr:0.0001\n",
      "Epoch 8, Step: 482, Loss: 0.12844128906726837, Lr:0.0001\n",
      "Epoch 8, Step: 483, Loss: 0.031063027679920197, Lr:0.0001\n",
      "Epoch 8, Step: 484, Loss: 0.13602018356323242, Lr:0.0001\n",
      "Epoch 8, Step: 485, Loss: 0.0998113751411438, Lr:0.0001\n",
      "Epoch 8, Step: 486, Loss: 0.13099123537540436, Lr:0.0001\n",
      "Epoch 8, Step: 487, Loss: 0.10761918127536774, Lr:0.0001\n",
      "Epoch 8, Step: 488, Loss: 0.14262424409389496, Lr:0.0001\n",
      "Epoch 8, Step: 489, Loss: 0.10013866424560547, Lr:0.0001\n",
      "Epoch 8, Step: 490, Loss: 0.0756143182516098, Lr:0.0001\n",
      "Epoch 8, Step: 491, Loss: 0.12316950410604477, Lr:0.0001\n",
      "Epoch 8, Step: 492, Loss: 0.0792061910033226, Lr:0.0001\n",
      "Epoch 8, Step: 493, Loss: 0.08979113399982452, Lr:0.0001\n",
      "Epoch 8, Step: 494, Loss: 0.18201643228530884, Lr:0.0001\n",
      "Epoch 8, Step: 495, Loss: 0.08722230792045593, Lr:0.0001\n",
      "Epoch 8, Step: 496, Loss: 0.20182687044143677, Lr:0.0001\n",
      "Epoch 8, Step: 497, Loss: 0.06734776496887207, Lr:0.0001\n",
      "Epoch 8, Step: 498, Loss: 0.23364460468292236, Lr:0.0001\n",
      "Epoch 8, Step: 499, Loss: 0.01846727356314659, Lr:0.0001\n",
      "Epoch 8, Step: 500, Loss: 0.04128221422433853, Lr:0.0001\n",
      "Epoch 8, Step: 501, Loss: 0.14758579432964325, Lr:0.0001\n",
      "Epoch 8, Step: 502, Loss: 0.16538554430007935, Lr:0.0001\n",
      "Epoch 8, Step: 503, Loss: 0.09518172591924667, Lr:0.0001\n",
      "Epoch 8, Step: 504, Loss: 0.042461782693862915, Lr:0.0001\n",
      "Epoch 8, Step: 505, Loss: 0.06062356010079384, Lr:0.0001\n",
      "Epoch 8, Step: 506, Loss: 0.12996499240398407, Lr:0.0001\n",
      "Epoch 8, Step: 507, Loss: 0.11712455004453659, Lr:0.0001\n",
      "Epoch 8, Step: 508, Loss: 0.36723563075065613, Lr:0.0001\n",
      "Epoch 8, Step: 509, Loss: 0.03658250719308853, Lr:0.0001\n",
      "Epoch 8, Step: 510, Loss: 0.0759519413113594, Lr:0.0001\n",
      "Epoch 8, Step: 511, Loss: 0.40167540311813354, Lr:0.0001\n",
      "Epoch 8, Step: 512, Loss: 0.10520269721746445, Lr:0.0001\n",
      "Epoch 8, Step: 513, Loss: 0.11884238570928574, Lr:0.0001\n",
      "Epoch 8, Step: 514, Loss: 0.3117809593677521, Lr:0.0001\n",
      "Epoch 8, Step: 515, Loss: 0.3796862065792084, Lr:0.0001\n",
      "Epoch 8, Step: 516, Loss: 0.024706730619072914, Lr:0.0001\n",
      "Epoch 8, Step: 517, Loss: 0.02963377721607685, Lr:0.0001\n",
      "Epoch 8, Step: 518, Loss: 0.12619683146476746, Lr:0.0001\n",
      "Epoch 8, Step: 519, Loss: 0.3915775418281555, Lr:0.0001\n",
      "Epoch 8, Step: 520, Loss: 0.05614621192216873, Lr:0.0001\n",
      "Epoch 8, Step: 521, Loss: 0.33031952381134033, Lr:0.0001\n",
      "Epoch 8, Step: 522, Loss: 0.11078954488039017, Lr:0.0001\n",
      "Epoch 8, Step: 523, Loss: 0.3104134202003479, Lr:0.0001\n",
      "Epoch 8, Step: 524, Loss: 0.15031668543815613, Lr:0.0001\n",
      "Epoch 8, Step: 525, Loss: 0.3144776523113251, Lr:0.0001\n",
      "Epoch 8, Step: 526, Loss: 0.10622899979352951, Lr:0.0001\n",
      "Epoch 8, Step: 527, Loss: 0.3551860749721527, Lr:0.0001\n",
      "Epoch 8, Step: 528, Loss: 0.27325284481048584, Lr:0.0001\n",
      "Epoch 8, Step: 529, Loss: 0.7250851392745972, Lr:0.0001\n",
      "Epoch 8, Step: 530, Loss: 0.22366102039813995, Lr:0.0001\n",
      "Epoch 8, Step: 531, Loss: 0.07136504352092743, Lr:0.0001\n",
      "Epoch 8, Step: 532, Loss: 0.07006380707025528, Lr:0.0001\n",
      "Epoch 8, Step: 533, Loss: 0.3194302022457123, Lr:0.0001\n",
      "Epoch 8, Step: 534, Loss: 0.11440908163785934, Lr:0.0001\n",
      "Epoch 8, Step: 535, Loss: 0.45926791429519653, Lr:0.0001\n",
      "Epoch 8, Step: 536, Loss: 0.2836986482143402, Lr:0.0001\n",
      "Epoch 8, Step: 537, Loss: 0.23165202140808105, Lr:0.0001\n",
      "Epoch 8, Step: 538, Loss: 0.5037786960601807, Lr:0.0001\n",
      "Epoch 8, Step: 539, Loss: 0.09214568138122559, Lr:0.0001\n",
      "Epoch 8, Step: 540, Loss: 0.2437264621257782, Lr:0.0001\n",
      "Epoch 8, Step: 541, Loss: 0.27616867423057556, Lr:0.0001\n",
      "Epoch 8, Step: 542, Loss: 0.10472089797258377, Lr:0.0001\n",
      "Epoch 8, Step: 543, Loss: 0.09391378611326218, Lr:0.0001\n",
      "Epoch 8, Step: 544, Loss: 0.24527306854724884, Lr:0.0001\n",
      "Epoch 8, Step: 545, Loss: 0.12316146492958069, Lr:0.0001\n",
      "Epoch 8, Step: 546, Loss: 0.22454765439033508, Lr:0.0001\n",
      "Epoch 8, Step: 547, Loss: 0.11548156291246414, Lr:0.0001\n",
      "Epoch 8, Step: 548, Loss: 0.23328951001167297, Lr:0.0001\n",
      "Epoch 8, Step: 549, Loss: 0.03187599033117294, Lr:0.0001\n",
      "Epoch 8, Step: 550, Loss: 0.11012546718120575, Lr:0.0001\n",
      "Epoch 8, Step: 551, Loss: 0.11191298812627792, Lr:0.0001\n",
      "Epoch 8, Step: 552, Loss: 0.24983690679073334, Lr:0.0001\n",
      "Epoch 8, Step: 553, Loss: 0.20384177565574646, Lr:0.0001\n",
      "Epoch 8, Step: 554, Loss: 0.1382523477077484, Lr:0.0001\n",
      "Epoch 8, Step: 555, Loss: 0.36521968245506287, Lr:0.0001\n",
      "Epoch 8, Step: 556, Loss: 0.11493849754333496, Lr:0.0001\n",
      "Epoch 8, Step: 557, Loss: 0.18052370846271515, Lr:0.0001\n",
      "Epoch 8, Step: 558, Loss: 0.3851926028728485, Lr:0.0001\n",
      "Epoch 8, Step: 559, Loss: 0.09216870367527008, Lr:0.0001\n",
      "Epoch 8, Step: 560, Loss: 0.074395090341568, Lr:0.0001\n",
      "Epoch 8, Step: 561, Loss: 0.2810764014720917, Lr:0.0001\n",
      "Epoch 8, Step: 562, Loss: 0.18983080983161926, Lr:0.0001\n",
      "Epoch 8, Step: 563, Loss: 0.08375532925128937, Lr:0.0001\n",
      "Epoch 8, Step: 564, Loss: 0.06552344560623169, Lr:0.0001\n",
      "Epoch 8, Step: 565, Loss: 0.2110520601272583, Lr:0.0001\n",
      "Epoch 8, Step: 566, Loss: 0.08358439803123474, Lr:0.0001\n",
      "Epoch 8, Step: 567, Loss: 0.07378063350915909, Lr:0.0001\n",
      "Epoch 8, Step: 568, Loss: 0.2005435973405838, Lr:0.0001\n",
      "Epoch 8, Step: 569, Loss: 0.10325368493795395, Lr:0.0001\n",
      "Epoch 8, Step: 570, Loss: 0.2623368799686432, Lr:0.0001\n",
      "Epoch 8, Step: 571, Loss: 0.07412934303283691, Lr:0.0001\n",
      "Epoch 8, Step: 572, Loss: 0.10083881765604019, Lr:0.0001\n",
      "Epoch 8, Step: 573, Loss: 0.025492969900369644, Lr:0.0001\n",
      "Epoch 8, Step: 574, Loss: 0.01642853394150734, Lr:0.0001\n",
      "Epoch 8, Step: 575, Loss: 0.30860278010368347, Lr:0.0001\n",
      "Epoch 8, Step: 576, Loss: 0.07190579175949097, Lr:0.0001\n",
      "Epoch 8, Step: 577, Loss: 0.2618425190448761, Lr:0.0001\n",
      "Epoch 8, Step: 578, Loss: 0.3668738305568695, Lr:0.0001\n",
      "Epoch 8, Step: 579, Loss: 0.06064656376838684, Lr:0.0001\n",
      "Epoch 8, Step: 580, Loss: 0.14873966574668884, Lr:0.0001\n",
      "Epoch 8, Step: 581, Loss: 0.1590573638677597, Lr:0.0001\n",
      "Epoch 8, Step: 582, Loss: 0.04416002705693245, Lr:0.0001\n",
      "Epoch 8, Step: 583, Loss: 0.30519765615463257, Lr:0.0001\n",
      "Epoch 8, Step: 584, Loss: 0.07149675488471985, Lr:0.0001\n",
      "Epoch 8, Step: 585, Loss: 0.05619508773088455, Lr:0.0001\n",
      "Epoch 8, Step: 586, Loss: 0.05998281389474869, Lr:0.0001\n",
      "Epoch 8, Step: 587, Loss: 0.07525777071714401, Lr:0.0001\n",
      "Epoch 8, Step: 588, Loss: 0.10602056980133057, Lr:0.0001\n",
      "Epoch 8, Step: 589, Loss: 0.054772939532995224, Lr:0.0001\n",
      "Epoch 8, Step: 590, Loss: 0.5384699106216431, Lr:0.0001\n",
      "Epoch 8, Step: 591, Loss: 0.48737460374832153, Lr:0.0001\n",
      "Epoch 8, Step: 592, Loss: 0.3598839342594147, Lr:0.0001\n",
      "Epoch 8, Step: 593, Loss: 0.18393376469612122, Lr:0.0001\n",
      "Epoch 8, Step: 594, Loss: 0.11162763833999634, Lr:0.0001\n",
      "Epoch 8, Step: 595, Loss: 0.19538649916648865, Lr:0.0001\n",
      "Epoch 8, Step: 596, Loss: 0.16568554937839508, Lr:0.0001\n",
      "Epoch 8, Step: 597, Loss: 0.22534511983394623, Lr:0.0001\n",
      "Epoch 8, Step: 598, Loss: 0.16065359115600586, Lr:0.0001\n",
      "Epoch 8, Step: 599, Loss: 0.19997307658195496, Lr:0.0001\n",
      "Epoch 8, Step: 600, Loss: 0.06666749715805054, Lr:0.0001\n",
      "Epoch 8, Step: 601, Loss: 0.09165600687265396, Lr:0.0001\n",
      "Epoch 8, Step: 602, Loss: 0.31266066431999207, Lr:0.0001\n",
      "Epoch 8, Step: 603, Loss: 0.07422957569360733, Lr:0.0001\n",
      "Epoch 8, Step: 604, Loss: 0.08405017107725143, Lr:0.0001\n",
      "Epoch 8, Step: 605, Loss: 0.18554668128490448, Lr:0.0001\n",
      "Epoch 8, Step: 606, Loss: 0.12841345369815826, Lr:0.0001\n",
      "Epoch 8, Step: 607, Loss: 0.22499266266822815, Lr:0.0001\n",
      "Epoch 8, Step: 608, Loss: 0.439452588558197, Lr:0.0001\n",
      "Epoch 8, Step: 609, Loss: 0.08955344557762146, Lr:0.0001\n",
      "Epoch 8, Step: 610, Loss: 0.07945475727319717, Lr:0.0001\n",
      "Epoch 8, Step: 611, Loss: 0.30063965916633606, Lr:0.0001\n",
      "Epoch 8, Step: 612, Loss: 0.09288494288921356, Lr:0.0001\n",
      "Epoch 8, Step: 613, Loss: 0.03823407366871834, Lr:0.0001\n",
      "Epoch 8, Step: 614, Loss: 0.2639327943325043, Lr:0.0001\n",
      "Epoch 8, Step: 615, Loss: 0.3009491264820099, Lr:0.0001\n",
      "Epoch 8, Step: 616, Loss: 0.06933324038982391, Lr:0.0001\n",
      "Epoch 8, Step: 617, Loss: 0.10256140679121017, Lr:0.0001\n",
      "Epoch 8, Step: 618, Loss: 0.24009647965431213, Lr:0.0001\n",
      "Epoch 8, Step: 619, Loss: 0.07474744319915771, Lr:0.0001\n",
      "Epoch 8, Step: 620, Loss: 0.18025389313697815, Lr:0.0001\n",
      "Epoch 8, Step: 621, Loss: 0.04693252593278885, Lr:0.0001\n",
      "Epoch 8, Step: 622, Loss: 0.13964684307575226, Lr:0.0001\n",
      "Epoch 8, Step: 623, Loss: 0.17392165958881378, Lr:0.0001\n",
      "Epoch 8, Step: 624, Loss: 0.2266579121351242, Lr:0.0001\n",
      "Epoch 8, Step: 625, Loss: 0.39355194568634033, Lr:0.0001\n",
      "Epoch 8, Step: 626, Loss: 0.029192529618740082, Lr:0.0001\n",
      "Epoch 8, Step: 627, Loss: 0.0380731038749218, Lr:0.0001\n",
      "Epoch 8, Step: 628, Loss: 0.08707477152347565, Lr:0.0001\n",
      "Epoch 8, Step: 629, Loss: 0.04369444027543068, Lr:0.0001\n",
      "Epoch 8, Step: 630, Loss: 0.061134256422519684, Lr:0.0001\n",
      "Epoch 8, Step: 631, Loss: 0.15447768568992615, Lr:0.0001\n",
      "Epoch 8, Step: 632, Loss: 0.19010473787784576, Lr:0.0001\n",
      "Epoch 8, Step: 633, Loss: 0.09132128953933716, Lr:0.0001\n",
      "Epoch 8, Step: 634, Loss: 0.08334462344646454, Lr:0.0001\n",
      "Epoch 8, Step: 635, Loss: 0.01613328419625759, Lr:0.0001\n",
      "Epoch 8, Step: 636, Loss: 0.12372072786092758, Lr:0.0001\n",
      "Epoch 8, Step: 637, Loss: 0.12737400829792023, Lr:0.0001\n",
      "Epoch 8, Step: 638, Loss: 0.14987878501415253, Lr:0.0001\n",
      "Epoch 8, Step: 639, Loss: 0.27042585611343384, Lr:0.0001\n",
      "Epoch 8, Step: 640, Loss: 0.018657129257917404, Lr:0.0001\n",
      "Epoch 8, Step: 641, Loss: 0.34991687536239624, Lr:0.0001\n",
      "Epoch 8, Step: 642, Loss: 0.1706204116344452, Lr:0.0001\n",
      "Epoch 8, Step: 643, Loss: 0.04756178706884384, Lr:0.0001\n",
      "Epoch 8, Step: 644, Loss: 0.2065851092338562, Lr:0.0001\n",
      "Epoch 8, Step: 645, Loss: 0.14312413334846497, Lr:0.0001\n",
      "Epoch 8, Step: 646, Loss: 0.07774969190359116, Lr:0.0001\n",
      "Epoch 8, Step: 647, Loss: 0.09576589614152908, Lr:0.0001\n",
      "Epoch 8, Step: 648, Loss: 0.15044505894184113, Lr:0.0001\n",
      "Epoch 8, Step: 649, Loss: 0.006257189903408289, Lr:0.0001\n",
      "Epoch 8, Step: 650, Loss: 0.09008821845054626, Lr:0.0001\n",
      "Epoch 8, Step: 651, Loss: 0.2818565368652344, Lr:0.0001\n",
      "Epoch 8, Step: 652, Loss: 0.10774045437574387, Lr:0.0001\n",
      "Epoch 8, Step: 653, Loss: 0.21746797859668732, Lr:0.0001\n",
      "Epoch 8, Step: 654, Loss: 0.023447832092642784, Lr:0.0001\n",
      "Epoch 8, Step: 655, Loss: 0.30829542875289917, Lr:0.0001\n",
      "Epoch 8, Step: 656, Loss: 0.15167143940925598, Lr:0.0001\n",
      "Epoch 8, Step: 657, Loss: 0.11108262091875076, Lr:0.0001\n",
      "Epoch 8, Step: 658, Loss: 0.2722293734550476, Lr:0.0001\n",
      "Epoch 8, Step: 659, Loss: 0.2494046986103058, Lr:0.0001\n",
      "Epoch 8, Step: 660, Loss: 0.16149669885635376, Lr:0.0001\n",
      "Epoch 8, Step: 661, Loss: 0.10241430997848511, Lr:0.0001\n",
      "Epoch 8, Step: 662, Loss: 0.16514495015144348, Lr:0.0001\n",
      "Epoch 8, Step: 663, Loss: 0.18971815705299377, Lr:0.0001\n",
      "Epoch 8, Step: 664, Loss: 0.12742628157138824, Lr:0.0001\n",
      "Epoch 8, Step: 665, Loss: 0.16235986351966858, Lr:0.0001\n",
      "Epoch 8, Step: 666, Loss: 0.21554484963417053, Lr:0.0001\n",
      "Epoch 8, Step: 667, Loss: 0.11446790397167206, Lr:0.0001\n",
      "Epoch 8, Step: 668, Loss: 0.20593030750751495, Lr:0.0001\n",
      "Epoch 8, Step: 669, Loss: 0.1391679048538208, Lr:0.0001\n",
      "Epoch 8, Step: 670, Loss: 0.3451063930988312, Lr:0.0001\n",
      "Epoch 8, Step: 671, Loss: 0.2743852138519287, Lr:0.0001\n",
      "Epoch 8, Step: 672, Loss: 0.05817113816738129, Lr:0.0001\n",
      "Epoch 8, Step: 673, Loss: 0.15762174129486084, Lr:0.0001\n",
      "Epoch 8, Step: 674, Loss: 0.15099450945854187, Lr:0.0001\n",
      "Epoch 8, Step: 675, Loss: 0.05057763308286667, Lr:0.0001\n",
      "Epoch 8, Step: 676, Loss: 0.20159634947776794, Lr:0.0001\n",
      "Epoch 8, Step: 677, Loss: 0.3269111216068268, Lr:0.0001\n",
      "Epoch 8, Step: 678, Loss: 0.376459538936615, Lr:0.0001\n",
      "Epoch 8, Step: 679, Loss: 0.3057834208011627, Lr:0.0001\n",
      "Epoch 8, Step: 680, Loss: 0.15846168994903564, Lr:0.0001\n",
      "Epoch 8, Step: 681, Loss: 0.39227378368377686, Lr:0.0001\n",
      "Epoch 8, Step: 682, Loss: 0.4748213589191437, Lr:0.0001\n",
      "Epoch 8, Step: 683, Loss: 0.025237392634153366, Lr:0.0001\n",
      "Epoch 8, Step: 684, Loss: 0.14522065222263336, Lr:0.0001\n",
      "Epoch 8, Step: 685, Loss: 0.16352665424346924, Lr:0.0001\n",
      "Epoch 8, Step: 686, Loss: 0.2233823984861374, Lr:0.0001\n",
      "Epoch 8, Step: 687, Loss: 0.09678560495376587, Lr:0.0001\n",
      "Epoch 8, Step: 688, Loss: 0.06840737909078598, Lr:0.0001\n",
      "Epoch 8, Step: 689, Loss: 0.06529945880174637, Lr:0.0001\n",
      "Epoch 8, Step: 690, Loss: 0.05667901039123535, Lr:0.0001\n",
      "Epoch 8, Step: 691, Loss: 0.007833986543118954, Lr:0.0001\n",
      "Epoch 8, Step: 692, Loss: 0.1909685730934143, Lr:0.0001\n",
      "Epoch 8, Step: 693, Loss: 0.08951351791620255, Lr:0.0001\n",
      "Epoch 8, Step: 694, Loss: 0.05201449990272522, Lr:0.0001\n",
      "Epoch 8, Step: 695, Loss: 0.1099177896976471, Lr:0.0001\n",
      "Epoch 8, Step: 696, Loss: 0.1921844333410263, Lr:0.0001\n",
      "Epoch 8, Step: 697, Loss: 0.358054518699646, Lr:0.0001\n",
      "Epoch 8, Step: 698, Loss: 0.22206836938858032, Lr:0.0001\n",
      "Epoch 8, Step: 699, Loss: 0.729323148727417, Lr:0.0001\n",
      "Epoch 8, Step: 700, Loss: 0.09557744860649109, Lr:0.0001\n",
      "Epoch 8, Step: 701, Loss: 0.047833167016506195, Lr:0.0001\n",
      "Epoch 8, Step: 702, Loss: 0.17759108543395996, Lr:0.0001\n",
      "Epoch 8, Step: 703, Loss: 0.0456312820315361, Lr:0.0001\n",
      "Epoch 8, Step: 704, Loss: 0.19864782691001892, Lr:0.0001\n",
      "Epoch 8, Step: 705, Loss: 0.6944798231124878, Lr:0.0001\n",
      "Epoch 8, Step: 706, Loss: 0.23765023052692413, Lr:0.0001\n",
      "Epoch 8, Step: 707, Loss: 0.1361771821975708, Lr:0.0001\n",
      "Epoch 8, Step: 708, Loss: 0.04643510654568672, Lr:0.0001\n",
      "Epoch 8, Step: 709, Loss: 0.09861242026090622, Lr:0.0001\n",
      "Epoch 8, Step: 710, Loss: 0.28308001160621643, Lr:0.0001\n",
      "Epoch 8, Step: 711, Loss: 0.4615634083747864, Lr:0.0001\n",
      "Epoch 8, Step: 712, Loss: 0.2322298288345337, Lr:0.0001\n",
      "Epoch 8, Step: 713, Loss: 0.3228078782558441, Lr:0.0001\n",
      "Epoch 8, Step: 714, Loss: 0.30419424176216125, Lr:0.0001\n",
      "Epoch 8, Step: 715, Loss: 0.1417165845632553, Lr:0.0001\n",
      "Epoch 8, Step: 716, Loss: 0.1566355973482132, Lr:0.0001\n",
      "Epoch 8, Step: 717, Loss: 0.17665129899978638, Lr:0.0001\n",
      "Epoch 8, Step: 718, Loss: 0.44085049629211426, Lr:0.0001\n",
      "Epoch 8, Step: 719, Loss: 0.2394859343767166, Lr:0.0001\n",
      "Epoch 8, Step: 720, Loss: 0.0611979216337204, Lr:0.0001\n",
      "Epoch 8, Step: 721, Loss: 0.0443028099834919, Lr:0.0001\n",
      "Epoch 8, Step: 722, Loss: 0.25495943427085876, Lr:0.0001\n",
      "Epoch 8, Step: 723, Loss: 0.33683717250823975, Lr:0.0001\n",
      "Epoch 8, Step: 724, Loss: 0.15189363062381744, Lr:0.0001\n",
      "Epoch 8, Step: 725, Loss: 0.0448717325925827, Lr:0.0001\n",
      "Epoch 8, Step: 726, Loss: 0.20340730249881744, Lr:0.0001\n",
      "Epoch 8, Step: 727, Loss: 0.12629196047782898, Lr:0.0001\n",
      "Epoch 8, Step: 728, Loss: 0.2887461185455322, Lr:0.0001\n",
      "Epoch 8, Step: 729, Loss: 0.07906317710876465, Lr:0.0001\n",
      "Epoch 8, Step: 730, Loss: 0.04733050987124443, Lr:0.0001\n",
      "Epoch 8, Step: 731, Loss: 0.14287042617797852, Lr:0.0001\n",
      "Epoch 8, Step: 732, Loss: 0.22351603209972382, Lr:0.0001\n",
      "Epoch 8, Step: 733, Loss: 0.04475114122033119, Lr:0.0001\n",
      "Epoch 8, Step: 734, Loss: 0.13384030759334564, Lr:0.0001\n",
      "Epoch 8, Step: 735, Loss: 0.40184009075164795, Lr:0.0001\n",
      "Epoch 8, Step: 736, Loss: 0.09955015033483505, Lr:0.0001\n",
      "Epoch 8, Step: 737, Loss: 0.0883093848824501, Lr:0.0001\n",
      "Epoch 8, Step: 738, Loss: 0.08733734488487244, Lr:0.0001\n",
      "Epoch 8, Step: 739, Loss: 0.04159383475780487, Lr:0.0001\n",
      "Epoch 8, Step: 740, Loss: 0.1720888912677765, Lr:0.0001\n",
      "Epoch 8, Step: 741, Loss: 0.05642927438020706, Lr:0.0001\n",
      "Epoch 8, Step: 742, Loss: 0.39306575059890747, Lr:0.0001\n",
      "Epoch 8, Step: 743, Loss: 0.3819948732852936, Lr:0.0001\n",
      "Epoch 8, Step: 744, Loss: 0.31261736154556274, Lr:0.0001\n",
      "Epoch 8, Step: 745, Loss: 0.037943195551633835, Lr:0.0001\n",
      "Epoch 8, Step: 746, Loss: 0.08336455374956131, Lr:0.0001\n",
      "Epoch 8, Step: 747, Loss: 0.38265642523765564, Lr:0.0001\n",
      "Epoch 8, Step: 748, Loss: 0.09432106465101242, Lr:0.0001\n",
      "Epoch 8, Step: 749, Loss: 0.22833660244941711, Lr:0.0001\n",
      "Epoch 8, Step: 750, Loss: 0.07059408724308014, Lr:0.0001\n",
      "Epoch 8, Step: 751, Loss: 0.01698203571140766, Lr:0.0001\n",
      "Epoch 8, Step: 752, Loss: 0.16767717897891998, Lr:0.0001\n",
      "Epoch 8, Step: 753, Loss: 0.2832055985927582, Lr:0.0001\n",
      "Epoch 8, Step: 754, Loss: 0.016480445861816406, Lr:0.0001\n",
      "Epoch 8, Step: 755, Loss: 0.09515698999166489, Lr:0.0001\n",
      "Epoch 8, Step: 756, Loss: 0.09582772850990295, Lr:0.0001\n",
      "Epoch 8, Step: 757, Loss: 0.13023395836353302, Lr:0.0001\n",
      "Epoch 8, Step: 758, Loss: 0.019251935184001923, Lr:0.0001\n",
      "Epoch 8, Step: 759, Loss: 0.033761754631996155, Lr:0.0001\n",
      "Epoch 8, Step: 760, Loss: 0.07802799344062805, Lr:0.0001\n",
      "Epoch 8, Step: 761, Loss: 0.20574066042900085, Lr:0.0001\n",
      "Epoch 8, Step: 762, Loss: 0.05639246478676796, Lr:0.0001\n",
      "Epoch 8, Step: 763, Loss: 0.03431249409914017, Lr:0.0001\n",
      "Epoch 8, Step: 764, Loss: 0.5663868188858032, Lr:0.0001\n",
      "Epoch 8, Step: 765, Loss: 0.011208347976207733, Lr:0.0001\n",
      "Epoch 8, Step: 766, Loss: 0.14608298242092133, Lr:0.0001\n",
      "Epoch 8, Step: 767, Loss: 0.04721856862306595, Lr:0.0001\n",
      "Epoch 8, Step: 768, Loss: 0.02913619391620159, Lr:0.0001\n",
      "Epoch 8, Step: 769, Loss: 0.16573980450630188, Lr:0.0001\n",
      "Epoch 8, Step: 770, Loss: 0.18871314823627472, Lr:0.0001\n",
      "Epoch 8, Step: 771, Loss: 0.27562254667282104, Lr:0.0001\n",
      "Epoch 8, Step: 772, Loss: 0.08530037850141525, Lr:0.0001\n",
      "Epoch 8, Step: 773, Loss: 0.012919512577354908, Lr:0.0001\n",
      "Epoch 8, Step: 774, Loss: 0.12476135790348053, Lr:0.0001\n",
      "Epoch 8, Step: 775, Loss: 0.04493049904704094, Lr:0.0001\n",
      "Epoch 8, Step: 776, Loss: 0.019694918766617775, Lr:0.0001\n",
      "Epoch 8, Step: 777, Loss: 0.11473598331212997, Lr:0.0001\n",
      "Epoch 8, Step: 778, Loss: 0.045716363936662674, Lr:0.0001\n",
      "Epoch 8, Step: 779, Loss: 0.05264349281787872, Lr:0.0001\n",
      "Epoch 8, Step: 780, Loss: 0.029741639271378517, Lr:0.0001\n",
      "Epoch 8, Step: 781, Loss: 0.03792621195316315, Lr:0.0001\n",
      "Epoch 8, Step: 782, Loss: 0.35046783089637756, Lr:0.0001\n",
      "Epoch 8, Step: 783, Loss: 0.1652892380952835, Lr:0.0001\n",
      "Epoch 8, Step: 784, Loss: 0.22733348608016968, Lr:0.0001\n",
      "Epoch 8, Step: 785, Loss: 0.10140486061573029, Lr:0.0001\n",
      "Epoch 8, Step: 786, Loss: 0.06040067598223686, Lr:0.0001\n",
      "Epoch 8, Step: 787, Loss: 0.05473248288035393, Lr:0.0001\n",
      "Epoch 8, Step: 788, Loss: 0.43782293796539307, Lr:0.0001\n",
      "Epoch 8, Step: 789, Loss: 0.1172361671924591, Lr:0.0001\n",
      "Epoch 8, Step: 790, Loss: 0.5270499587059021, Lr:0.0001\n",
      "Epoch 8, Step: 791, Loss: 0.07349253445863724, Lr:0.0001\n",
      "Epoch 8, Step: 792, Loss: 0.2253042459487915, Lr:0.0001\n",
      "Epoch 8, Step: 793, Loss: 0.009565605781972408, Lr:0.0001\n",
      "Epoch 8, Step: 794, Loss: 0.009904141537845135, Lr:0.0001\n",
      "Epoch 8, Step: 795, Loss: 0.04467867687344551, Lr:0.0001\n",
      "Epoch 8, Step: 796, Loss: 0.24681879580020905, Lr:0.0001\n",
      "Epoch 8, Step: 797, Loss: 0.12541839480400085, Lr:0.0001\n",
      "Epoch 8, Step: 798, Loss: 0.298019140958786, Lr:0.0001\n",
      "Epoch 8, Step: 799, Loss: 0.09962327033281326, Lr:0.0001\n",
      "Epoch 8, Step: 800, Loss: 0.13245889544487, Lr:0.0001\n",
      "Epoch 8, Step: 801, Loss: 0.15136587619781494, Lr:0.0001\n",
      "Epoch 8, Step: 802, Loss: 0.18498021364212036, Lr:0.0001\n",
      "Epoch 8, Step: 803, Loss: 0.2197011411190033, Lr:0.0001\n",
      "Epoch 8, Step: 804, Loss: 0.44218745827674866, Lr:0.0001\n",
      "Epoch 8, Step: 805, Loss: 0.2864552140235901, Lr:0.0001\n",
      "Epoch 8, Step: 806, Loss: 0.024957776069641113, Lr:0.0001\n",
      "Epoch 8, Step: 807, Loss: 0.3823188543319702, Lr:0.0001\n",
      "Epoch 8, Step: 808, Loss: 0.053015969693660736, Lr:0.0001\n",
      "Epoch 8, Step: 809, Loss: 0.06222780421376228, Lr:0.0001\n",
      "Epoch 8, Step: 810, Loss: 0.01437807735055685, Lr:0.0001\n",
      "Epoch 8, Step: 811, Loss: 0.07039283961057663, Lr:0.0001\n",
      "Epoch 8, Step: 812, Loss: 0.07582946866750717, Lr:0.0001\n",
      "Epoch 8, Step: 813, Loss: 0.053797610104084015, Lr:0.0001\n",
      "Epoch 8, Step: 814, Loss: 0.004715397953987122, Lr:0.0001\n",
      "Epoch 8, Step: 815, Loss: 0.10500499606132507, Lr:0.0001\n",
      "Epoch 8, Step: 816, Loss: 0.3182266652584076, Lr:0.0001\n",
      "Epoch 8, Step: 817, Loss: 0.11584534496068954, Lr:0.0001\n",
      "Epoch 8, Step: 818, Loss: 0.16849012672901154, Lr:0.0001\n",
      "Epoch 8, Step: 819, Loss: 0.28572627902030945, Lr:0.0001\n",
      "Epoch 8, Step: 820, Loss: 0.40187734365463257, Lr:0.0001\n",
      "Epoch 8, Step: 821, Loss: 0.35668137669563293, Lr:0.0001\n",
      "Epoch 8, Step: 822, Loss: 0.11111469566822052, Lr:0.0001\n",
      "Epoch 8, Step: 823, Loss: 0.2667135000228882, Lr:0.0001\n",
      "Epoch 8, Step: 824, Loss: 0.24654510617256165, Lr:0.0001\n",
      "Epoch 8, Step: 825, Loss: 0.11734014004468918, Lr:0.0001\n",
      "Epoch 8, Step: 826, Loss: 0.19664381444454193, Lr:0.0001\n",
      "Epoch 8, Step: 827, Loss: 0.17160582542419434, Lr:0.0001\n",
      "Epoch 8, Step: 828, Loss: 0.058569785207509995, Lr:0.0001\n",
      "Epoch 8, Step: 829, Loss: 0.1784849613904953, Lr:0.0001\n",
      "Epoch 8, Step: 830, Loss: 0.05977556109428406, Lr:0.0001\n",
      "Epoch 8, Step: 831, Loss: 0.1448761522769928, Lr:0.0001\n",
      "Epoch 8, Step: 832, Loss: 0.050703756511211395, Lr:0.0001\n",
      "Epoch 8, Step: 833, Loss: 0.11409412324428558, Lr:0.0001\n",
      "Epoch 8, Step: 834, Loss: 0.4750363528728485, Lr:0.0001\n",
      "Epoch 8, Step: 835, Loss: 0.2701299786567688, Lr:0.0001\n",
      "Epoch 8, Step: 836, Loss: 0.12873351573944092, Lr:0.0001\n",
      "Epoch 8, Step: 837, Loss: 0.1581316590309143, Lr:0.0001\n",
      "Epoch 8, Step: 838, Loss: 0.08412749320268631, Lr:0.0001\n",
      "Epoch 8, Step: 839, Loss: 0.04700804501771927, Lr:0.0001\n",
      "Epoch 8, Step: 840, Loss: 0.037274766713380814, Lr:0.0001\n",
      "Epoch 8, Step: 841, Loss: 0.27005839347839355, Lr:0.0001\n",
      "Epoch 8, Step: 842, Loss: 0.212721049785614, Lr:0.0001\n",
      "Epoch 8, Step: 843, Loss: 0.15923774242401123, Lr:0.0001\n",
      "Epoch 8, Step: 844, Loss: 0.08346205204725266, Lr:0.0001\n",
      "Epoch 8, Step: 845, Loss: 0.08720449358224869, Lr:0.0001\n",
      "Epoch 8, Step: 846, Loss: 0.1409885138273239, Lr:0.0001\n",
      "Epoch 8, Step: 847, Loss: 0.05603354051709175, Lr:0.0001\n",
      "Epoch 8, Step: 848, Loss: 0.1957603394985199, Lr:0.0001\n",
      "Epoch 8, Step: 849, Loss: 0.1413414031267166, Lr:0.0001\n",
      "Epoch 8, Step: 850, Loss: 0.04907335340976715, Lr:0.0001\n",
      "Epoch 8, Step: 851, Loss: 0.13183344900608063, Lr:0.0001\n",
      "Epoch 8, Step: 852, Loss: 0.09655610471963882, Lr:0.0001\n",
      "Epoch 8, Step: 853, Loss: 0.2485360950231552, Lr:0.0001\n",
      "Epoch 8, Step: 854, Loss: 0.06471483409404755, Lr:0.0001\n",
      "Epoch 8, Step: 855, Loss: 0.02911178208887577, Lr:0.0001\n",
      "Epoch 8, Step: 856, Loss: 0.05553660914301872, Lr:0.0001\n",
      "Epoch 8, Step: 857, Loss: 0.08575429767370224, Lr:0.0001\n",
      "Epoch 8, Step: 858, Loss: 0.181024968624115, Lr:0.0001\n",
      "Epoch 8, Step: 859, Loss: 0.23447734117507935, Lr:0.0001\n",
      "Epoch 8, Step: 860, Loss: 0.10514499247074127, Lr:0.0001\n",
      "Epoch 8, Step: 861, Loss: 0.11788986623287201, Lr:0.0001\n",
      "Epoch 8, Step: 862, Loss: 0.0312609001994133, Lr:0.0001\n",
      "Epoch 8, Step: 863, Loss: 0.24510377645492554, Lr:0.0001\n",
      "Epoch 8, Step: 864, Loss: 0.3342374265193939, Lr:0.0001\n",
      "Epoch 8, Step: 865, Loss: 0.21885037422180176, Lr:0.0001\n",
      "Epoch 8, Step: 866, Loss: 0.30484193563461304, Lr:0.0001\n",
      "Epoch 8, Step: 867, Loss: 0.17794610559940338, Lr:0.0001\n",
      "Epoch 8, Step: 868, Loss: 0.39352113008499146, Lr:0.0001\n",
      "Epoch 8, Step: 869, Loss: 0.18601253628730774, Lr:0.0001\n",
      "Epoch 8, Step: 870, Loss: 0.13952665030956268, Lr:0.0001\n",
      "Epoch 8, Step: 871, Loss: 0.03333894535899162, Lr:0.0001\n",
      "Epoch 8, Step: 872, Loss: 0.06127365306019783, Lr:0.0001\n",
      "Epoch 8, Step: 873, Loss: 0.11741843819618225, Lr:0.0001\n",
      "Epoch 8, Step: 874, Loss: 0.2018176019191742, Lr:0.0001\n",
      "Epoch 8, Step: 875, Loss: 0.09267784655094147, Lr:0.0001\n",
      "Epoch 8, Step: 876, Loss: 0.2640128433704376, Lr:0.0001\n",
      "Epoch 8, Step: 877, Loss: 0.11277373135089874, Lr:0.0001\n",
      "Epoch 8, Step: 878, Loss: 0.2716631293296814, Lr:0.0001\n",
      "Epoch 8, Step: 879, Loss: 0.1905190795660019, Lr:0.0001\n",
      "Epoch 8, Step: 880, Loss: 0.040959376841783524, Lr:0.0001\n",
      "Epoch 8, Step: 881, Loss: 0.27023711800575256, Lr:0.0001\n",
      "Epoch 8, Step: 882, Loss: 0.04258428141474724, Lr:0.0001\n",
      "Epoch 8, Step: 883, Loss: 0.14438143372535706, Lr:0.0001\n",
      "Epoch 8, Step: 884, Loss: 0.1991705298423767, Lr:0.0001\n",
      "Epoch 8, Step: 885, Loss: 0.28086578845977783, Lr:0.0001\n",
      "Epoch 8, Step: 886, Loss: 0.11735476553440094, Lr:0.0001\n",
      "Epoch 8, Step: 887, Loss: 0.17698903381824493, Lr:0.0001\n",
      "Epoch 8, Step: 888, Loss: 0.09361683577299118, Lr:0.0001\n",
      "Epoch 8, Step: 889, Loss: 0.3005237579345703, Lr:0.0001\n",
      "Epoch 8, Step: 890, Loss: 0.12677176296710968, Lr:0.0001\n",
      "Epoch 8, Step: 891, Loss: 0.12101951986551285, Lr:0.0001\n",
      "Epoch 8, Step: 892, Loss: 0.15444663166999817, Lr:0.0001\n",
      "Epoch 8, Step: 893, Loss: 0.040404852479696274, Lr:0.0001\n",
      "Epoch 8, Step: 894, Loss: 0.06965741515159607, Lr:0.0001\n",
      "Epoch 8, Step: 895, Loss: 0.2058289498090744, Lr:0.0001\n",
      "Epoch 8, Step: 896, Loss: 0.10268419981002808, Lr:0.0001\n",
      "Epoch 8, Step: 897, Loss: 0.13621574640274048, Lr:0.0001\n",
      "Epoch 8, Step: 898, Loss: 0.0927216112613678, Lr:0.0001\n",
      "Epoch 8, Step: 899, Loss: 0.08888762444257736, Lr:0.0001\n",
      "Epoch 8, Step: 900, Loss: 0.35222434997558594, Lr:0.0001\n",
      "Epoch 8, Step: 901, Loss: 0.07760021835565567, Lr:0.0001\n",
      "Epoch 8, Step: 902, Loss: 0.2597959041595459, Lr:0.0001\n",
      "Epoch 8, Step: 903, Loss: 0.5590687394142151, Lr:0.0001\n",
      "Epoch 8, Step: 904, Loss: 0.21168862283229828, Lr:0.0001\n",
      "Epoch 8, Step: 905, Loss: 0.44592276215553284, Lr:0.0001\n",
      "Epoch 8, Step: 906, Loss: 0.0560050904750824, Lr:0.0001\n",
      "Epoch 8, Step: 907, Loss: 0.2997664213180542, Lr:0.0001\n",
      "Epoch 8, Step: 908, Loss: 0.056445829570293427, Lr:0.0001\n",
      "Epoch 8, Step: 909, Loss: 0.10346328467130661, Lr:0.0001\n",
      "Epoch 8, Step: 910, Loss: 0.14647988975048065, Lr:0.0001\n",
      "Epoch 8, Step: 911, Loss: 0.3780931830406189, Lr:0.0001\n",
      "Epoch 8, Step: 912, Loss: 0.17344313859939575, Lr:0.0001\n",
      "Epoch 8, Step: 913, Loss: 0.07775748521089554, Lr:0.0001\n",
      "Epoch 8, Step: 914, Loss: 0.28910234570503235, Lr:0.0001\n",
      "Epoch 8, Step: 915, Loss: 0.1984531581401825, Lr:0.0001\n",
      "Epoch 8, Step: 916, Loss: 0.628718912601471, Lr:0.0001\n",
      "Epoch 8, Step: 917, Loss: 0.06322351098060608, Lr:0.0001\n",
      "Epoch 8, Step: 918, Loss: 0.26452770829200745, Lr:0.0001\n",
      "Epoch 8, Step: 919, Loss: 0.20618614554405212, Lr:0.0001\n",
      "Epoch 8, Step: 920, Loss: 0.05758381634950638, Lr:0.0001\n",
      "Epoch 8, Step: 921, Loss: 0.06971331685781479, Lr:0.0001\n",
      "Epoch 8, Step: 922, Loss: 0.2113746851682663, Lr:0.0001\n",
      "Epoch 8, Step: 923, Loss: 0.2928237318992615, Lr:0.0001\n",
      "Epoch 8, Step: 924, Loss: 0.29902783036231995, Lr:0.0001\n",
      "Epoch 8, Step: 925, Loss: 0.1312706172466278, Lr:0.0001\n",
      "Epoch 8, Step: 926, Loss: 0.06415735930204391, Lr:0.0001\n",
      "Epoch 8, Step: 927, Loss: 0.14435340464115143, Lr:0.0001\n",
      "Epoch 8, Step: 928, Loss: 0.05726113170385361, Lr:0.0001\n",
      "Epoch 8, Step: 929, Loss: 0.06936917454004288, Lr:0.0001\n",
      "Epoch 8, Step: 930, Loss: 0.3327549397945404, Lr:0.0001\n",
      "Epoch 8, Step: 931, Loss: 0.055323079228401184, Lr:0.0001\n",
      "Epoch 8, Step: 932, Loss: 0.02883322164416313, Lr:0.0001\n",
      "Epoch 8, Step: 933, Loss: 0.26426857709884644, Lr:0.0001\n",
      "Epoch 8, Step: 934, Loss: 0.2865799367427826, Lr:0.0001\n",
      "Epoch 8, Step: 935, Loss: 0.3550836443901062, Lr:0.0001\n",
      "Epoch 8, Step: 936, Loss: 0.1834455281496048, Lr:0.0001\n",
      "Epoch 8, Step: 937, Loss: 0.15821623802185059, Lr:0.0001\n",
      "Epoch 8, Step: 938, Loss: 0.1664774864912033, Lr:0.0001\n",
      "Epoch 8, Step: 939, Loss: 0.17408305406570435, Lr:0.0001\n",
      "Epoch 8, Step: 940, Loss: 0.1751943677663803, Lr:0.0001\n",
      "Epoch 8, Step: 941, Loss: 0.15442921221256256, Lr:0.0001\n",
      "Epoch 8, Step: 942, Loss: 0.11330334097146988, Lr:0.0001\n",
      "Epoch 8, Step: 943, Loss: 0.14706900715827942, Lr:0.0001\n",
      "Epoch 8, Step: 944, Loss: 0.13900429010391235, Lr:0.0001\n",
      "Epoch 8, Step: 945, Loss: 0.1217421218752861, Lr:0.0001\n",
      "Epoch 8, Step: 946, Loss: 0.3755057454109192, Lr:0.0001\n",
      "Epoch 8, Step: 947, Loss: 0.08928608894348145, Lr:0.0001\n",
      "Epoch 8, Step: 948, Loss: 0.42669677734375, Lr:0.0001\n",
      "Epoch 8, Step: 949, Loss: 0.6127973794937134, Lr:0.0001\n",
      "Epoch 8, Step: 950, Loss: 0.07034064829349518, Lr:0.0001\n",
      "Epoch 8, Step: 951, Loss: 0.07890693098306656, Lr:0.0001\n",
      "Epoch 8, Step: 952, Loss: 0.17632928490638733, Lr:0.0001\n",
      "Epoch 8, Step: 953, Loss: 0.2987954616546631, Lr:0.0001\n",
      "Epoch 8, Step: 954, Loss: 0.26242688298225403, Lr:0.0001\n",
      "Epoch 8, Step: 955, Loss: 0.17285658419132233, Lr:0.0001\n",
      "Epoch 8, Step: 956, Loss: 0.08659408241510391, Lr:0.0001\n",
      "Epoch 8, Step: 957, Loss: 0.07967232167720795, Lr:0.0001\n",
      "Epoch 8, Step: 958, Loss: 0.022190701216459274, Lr:0.0001\n",
      "Epoch 8, Step: 959, Loss: 0.12014929205179214, Lr:0.0001\n",
      "Epoch 8, Step: 960, Loss: 0.05176124721765518, Lr:0.0001\n",
      "Epoch 8, Step: 961, Loss: 0.05057946592569351, Lr:0.0001\n",
      "Epoch 8, Step: 962, Loss: 0.18306894600391388, Lr:0.0001\n",
      "Epoch 8, Step: 963, Loss: 0.29554715752601624, Lr:0.0001\n",
      "Epoch 8, Step: 964, Loss: 0.10066687315702438, Lr:0.0001\n",
      "Epoch 8, Step: 965, Loss: 0.07505585253238678, Lr:0.0001\n",
      "Epoch 8, Step: 966, Loss: 0.09197957068681717, Lr:0.0001\n",
      "Epoch 8, Step: 967, Loss: 0.09690452367067337, Lr:0.0001\n",
      "Epoch 8, Step: 968, Loss: 0.08498766273260117, Lr:0.0001\n",
      "Epoch 8, Step: 969, Loss: 0.11393870413303375, Lr:0.0001\n",
      "Epoch 8, Step: 970, Loss: 0.23191145062446594, Lr:0.0001\n",
      "Epoch 8, Step: 971, Loss: 0.0677923709154129, Lr:0.0001\n",
      "Epoch 8, Step: 972, Loss: 0.05313123017549515, Lr:0.0001\n",
      "Epoch 8, Step: 973, Loss: 0.11991383135318756, Lr:0.0001\n",
      "Epoch 8, Step: 974, Loss: 0.2286403477191925, Lr:0.0001\n",
      "Epoch 8, Step: 975, Loss: 0.48276305198669434, Lr:0.0001\n",
      "Epoch 8, Step: 976, Loss: 0.21375292539596558, Lr:0.0001\n",
      "Epoch 8, Step: 977, Loss: 0.4571354389190674, Lr:0.0001\n",
      "Epoch 8, Step: 978, Loss: 0.13830424845218658, Lr:0.0001\n",
      "Epoch 8, Step: 979, Loss: 0.3536166250705719, Lr:0.0001\n",
      "Epoch 8, Step: 980, Loss: 0.3440852761268616, Lr:0.0001\n",
      "Epoch 8, Step: 981, Loss: 0.043813593685626984, Lr:0.0001\n",
      "Epoch 8, Step: 982, Loss: 0.16515657305717468, Lr:0.0001\n",
      "Epoch 8, Step: 983, Loss: 0.2605631351470947, Lr:0.0001\n",
      "Epoch 8, Step: 984, Loss: 0.062468498945236206, Lr:0.0001\n",
      "Epoch 8, Step: 985, Loss: 0.18797774612903595, Lr:0.0001\n",
      "Epoch 8, Step: 986, Loss: 0.2474808394908905, Lr:0.0001\n",
      "Epoch 8, Step: 987, Loss: 0.5985499620437622, Lr:0.0001\n",
      "Epoch 8, Step: 988, Loss: 0.13509124517440796, Lr:0.0001\n",
      "Epoch 8, Step: 989, Loss: 0.1799830049276352, Lr:0.0001\n",
      "Epoch 8, Step: 990, Loss: 0.20117174088954926, Lr:0.0001\n",
      "Epoch 8, Step: 991, Loss: 0.3068796396255493, Lr:0.0001\n",
      "Epoch 8, Step: 992, Loss: 0.34033605456352234, Lr:0.0001\n",
      "Epoch 8, Step: 993, Loss: 0.15736861526966095, Lr:0.0001\n",
      "Epoch 8, Step: 994, Loss: 0.1773882508277893, Lr:0.0001\n",
      "Epoch 8, Step: 995, Loss: 0.5508910417556763, Lr:0.0001\n",
      "Epoch 8, Step: 996, Loss: 0.26017236709594727, Lr:0.0001\n",
      "Epoch 8, Step: 997, Loss: 0.13844333589076996, Lr:0.0001\n",
      "Epoch 8, Step: 998, Loss: 0.09266042709350586, Lr:0.0001\n",
      "Epoch 8, Step: 999, Loss: 0.11078649014234543, Lr:0.0001\n",
      "Epoch 8, Step: 1000, Loss: 0.19404250383377075, Lr:0.0001\n",
      "Epoch 8, Step: 1001, Loss: 0.19139590859413147, Lr:0.0001\n",
      "Epoch 8, Step: 1002, Loss: 0.06528286635875702, Lr:0.0001\n",
      "Epoch 8, Step: 1003, Loss: 0.0805225521326065, Lr:0.0001\n",
      "Epoch 8, Step: 1004, Loss: 0.03442394360899925, Lr:0.0001\n",
      "Epoch 8, Step: 1005, Loss: 0.5275012850761414, Lr:0.0001\n",
      "Epoch 8, Step: 1006, Loss: 0.07158076018095016, Lr:0.0001\n",
      "Epoch 8, Step: 1007, Loss: 0.9466288685798645, Lr:0.0001\n",
      "Epoch 8, Step: 1008, Loss: 0.05739489942789078, Lr:0.0001\n",
      "Epoch 8, Step: 1009, Loss: 0.13529165089130402, Lr:0.0001\n",
      "Epoch 8, Step: 1010, Loss: 0.11960403621196747, Lr:0.0001\n",
      "Epoch 8, Step: 1011, Loss: 0.2659403681755066, Lr:0.0001\n",
      "Epoch 8, Step: 1012, Loss: 0.08063362538814545, Lr:0.0001\n",
      "Epoch 8, Step: 1013, Loss: 0.2258501499891281, Lr:0.0001\n",
      "Epoch 8, Step: 1014, Loss: 0.30645838379859924, Lr:0.0001\n",
      "Epoch 8, Step: 1015, Loss: 0.2343079149723053, Lr:0.0001\n",
      "Epoch 8, Step: 1016, Loss: 0.3638521730899811, Lr:0.0001\n",
      "Epoch 8, Step: 1017, Loss: 0.5191580057144165, Lr:0.0001\n",
      "Epoch 8, Step: 1018, Loss: 0.12173156440258026, Lr:0.0001\n",
      "Epoch 8, Step: 1019, Loss: 0.12956783175468445, Lr:0.0001\n",
      "Epoch 8, Step: 1020, Loss: 0.08489291369915009, Lr:0.0001\n",
      "Epoch 8, Step: 1021, Loss: 0.6414045691490173, Lr:0.0001\n",
      "Epoch 8, Step: 1022, Loss: 0.16681407392024994, Lr:0.0001\n",
      "Epoch 8, Step: 1023, Loss: 0.2555840015411377, Lr:0.0001\n",
      "Epoch 8, Step: 1024, Loss: 0.11018995940685272, Lr:0.0001\n",
      "Epoch 8, Step: 1025, Loss: 0.10467216372489929, Lr:0.0001\n",
      "Epoch 8, Step: 1026, Loss: 0.10037205368280411, Lr:0.0001\n",
      "Epoch 8, Step: 1027, Loss: 0.21625399589538574, Lr:0.0001\n",
      "Epoch 8, Step: 1028, Loss: 0.16833126544952393, Lr:0.0001\n",
      "Epoch 8, Step: 1029, Loss: 0.18548060953617096, Lr:0.0001\n",
      "Epoch 8, Step: 1030, Loss: 0.10135006904602051, Lr:0.0001\n",
      "Epoch 8, Step: 1031, Loss: 0.2417934089899063, Lr:0.0001\n",
      "Epoch 8, Step: 1032, Loss: 0.39458027482032776, Lr:0.0001\n",
      "Epoch 8, Step: 1033, Loss: 0.13507454097270966, Lr:0.0001\n",
      "Epoch 8, Step: 1034, Loss: 0.0915757417678833, Lr:0.0001\n",
      "Epoch 8, Step: 1035, Loss: 0.3531721234321594, Lr:0.0001\n",
      "Epoch 8, Step: 1036, Loss: 0.30484649538993835, Lr:0.0001\n",
      "Epoch 8, Step: 1037, Loss: 0.1344805806875229, Lr:0.0001\n",
      "Epoch 8, Step: 1038, Loss: 0.18713396787643433, Lr:0.0001\n",
      "Epoch 8, Step: 1039, Loss: 0.1461106240749359, Lr:0.0001\n",
      "Epoch 8, Step: 1040, Loss: 0.3979718089103699, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 8\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:18 loss: 0.0332 (0.0332) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.3255 data: 0.1580 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:15 loss: 0.0030 (0.0304) acc1: 100.0000 (98.8636) acc5: 100.0000 (100.0000) time: 0.3330 data: 0.1590 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:12 loss: 0.0030 (0.0681) acc1: 100.0000 (98.5119) acc5: 100.0000 (100.0000) time: 0.3397 data: 0.1608 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:08 loss: 0.1553 (0.1966) acc1: 93.7500 (92.9435) acc5: 100.0000 (100.0000) time: 0.3534 data: 0.1673 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:05 loss: 0.2406 (0.1995) acc1: 87.5000 (92.6829) acc5: 100.0000 (100.0000) time: 0.3627 data: 0.1719 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:02 loss: 0.0617 (0.1790) acc1: 93.7500 (93.3824) acc5: 100.0000 (100.0000) time: 0.3609 data: 0.1701 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0617 (0.1759) acc1: 100.0000 (93.4166) acc5: 100.0000 (100.0000) time: 0.3495 data: 0.1630 max mem: 15137\n",
      "Test: Total time: 0:00:19 (0.3476 s / it)\n",
      "* Acc@1 93.417 Acc@5 100.000 loss 0.176\n",
      "Accuracy of the network on the 881 test image: 93.4%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 9, Step: 0, Loss: 0.07248508185148239, Lr:0.0001\n",
      "Epoch 9, Step: 1, Loss: 0.30410459637641907, Lr:0.0001\n",
      "Epoch 9, Step: 2, Loss: 0.0630083978176117, Lr:0.0001\n",
      "Epoch 9, Step: 3, Loss: 0.03630116954445839, Lr:0.0001\n",
      "Epoch 9, Step: 4, Loss: 0.38834381103515625, Lr:0.0001\n",
      "Epoch 9, Step: 5, Loss: 0.15646354854106903, Lr:0.0001\n",
      "Epoch 9, Step: 6, Loss: 0.14297790825366974, Lr:0.0001\n",
      "Epoch 9, Step: 7, Loss: 0.10090606659650803, Lr:0.0001\n",
      "Epoch 9, Step: 8, Loss: 0.26967522501945496, Lr:0.0001\n",
      "Epoch 9, Step: 9, Loss: 0.15549996495246887, Lr:0.0001\n",
      "Epoch 9, Step: 10, Loss: 0.18255124986171722, Lr:0.0001\n",
      "Epoch 9, Step: 11, Loss: 0.07602956146001816, Lr:0.0001\n",
      "Epoch 9, Step: 12, Loss: 0.21895849704742432, Lr:0.0001\n",
      "Epoch 9, Step: 13, Loss: 0.3801010251045227, Lr:0.0001\n",
      "Epoch 9, Step: 14, Loss: 0.14922265708446503, Lr:0.0001\n",
      "Epoch 9, Step: 15, Loss: 0.3059667646884918, Lr:0.0001\n",
      "Epoch 9, Step: 16, Loss: 0.5009849071502686, Lr:0.0001\n",
      "Epoch 9, Step: 17, Loss: 0.1620001196861267, Lr:0.0001\n",
      "Epoch 9, Step: 18, Loss: 0.23688125610351562, Lr:0.0001\n",
      "Epoch 9, Step: 19, Loss: 0.2578042447566986, Lr:0.0001\n",
      "Epoch 9, Step: 20, Loss: 0.3915556073188782, Lr:0.0001\n",
      "Epoch 9, Step: 21, Loss: 0.05739793926477432, Lr:0.0001\n",
      "Epoch 9, Step: 22, Loss: 0.05592551827430725, Lr:0.0001\n",
      "Epoch 9, Step: 23, Loss: 0.205414816737175, Lr:0.0001\n",
      "Epoch 9, Step: 24, Loss: 0.1521860957145691, Lr:0.0001\n",
      "Epoch 9, Step: 25, Loss: 0.10713740438222885, Lr:0.0001\n",
      "Epoch 9, Step: 26, Loss: 0.09120846539735794, Lr:0.0001\n",
      "Epoch 9, Step: 27, Loss: 0.028598597273230553, Lr:0.0001\n",
      "Epoch 9, Step: 28, Loss: 0.31648683547973633, Lr:0.0001\n",
      "Epoch 9, Step: 29, Loss: 0.19543039798736572, Lr:0.0001\n",
      "Epoch 9, Step: 30, Loss: 0.23060114681720734, Lr:0.0001\n",
      "Epoch 9, Step: 31, Loss: 0.31642937660217285, Lr:0.0001\n",
      "Epoch 9, Step: 32, Loss: 0.14868426322937012, Lr:0.0001\n",
      "Epoch 9, Step: 33, Loss: 0.42712071537971497, Lr:0.0001\n",
      "Epoch 9, Step: 34, Loss: 0.15252958238124847, Lr:0.0001\n",
      "Epoch 9, Step: 35, Loss: 0.23733031749725342, Lr:0.0001\n",
      "Epoch 9, Step: 36, Loss: 0.06677056103944778, Lr:0.0001\n",
      "Epoch 9, Step: 37, Loss: 0.06903965771198273, Lr:0.0001\n",
      "Epoch 9, Step: 38, Loss: 0.21525397896766663, Lr:0.0001\n",
      "Epoch 9, Step: 39, Loss: 0.36507368087768555, Lr:0.0001\n",
      "Epoch 9, Step: 40, Loss: 0.3051791191101074, Lr:0.0001\n",
      "Epoch 9, Step: 41, Loss: 0.07424931228160858, Lr:0.0001\n",
      "Epoch 9, Step: 42, Loss: 0.4897209107875824, Lr:0.0001\n",
      "Epoch 9, Step: 43, Loss: 0.21354079246520996, Lr:0.0001\n",
      "Epoch 9, Step: 44, Loss: 0.1707170605659485, Lr:0.0001\n",
      "Epoch 9, Step: 45, Loss: 0.1288968324661255, Lr:0.0001\n",
      "Epoch 9, Step: 46, Loss: 0.06288724392652512, Lr:0.0001\n",
      "Epoch 9, Step: 47, Loss: 0.15397432446479797, Lr:0.0001\n",
      "Epoch 9, Step: 48, Loss: 0.4717535376548767, Lr:0.0001\n",
      "Epoch 9, Step: 49, Loss: 0.1091705709695816, Lr:0.0001\n",
      "Epoch 9, Step: 50, Loss: 0.20232100784778595, Lr:0.0001\n",
      "Epoch 9, Step: 51, Loss: 0.2654794752597809, Lr:0.0001\n",
      "Epoch 9, Step: 52, Loss: 0.012895943596959114, Lr:0.0001\n",
      "Epoch 9, Step: 53, Loss: 0.06568275392055511, Lr:0.0001\n",
      "Epoch 9, Step: 54, Loss: 0.24793590605258942, Lr:0.0001\n",
      "Epoch 9, Step: 55, Loss: 0.29679471254348755, Lr:0.0001\n",
      "Epoch 9, Step: 56, Loss: 0.024124445393681526, Lr:0.0001\n",
      "Epoch 9, Step: 57, Loss: 0.3746092915534973, Lr:0.0001\n",
      "Epoch 9, Step: 58, Loss: 0.02566685527563095, Lr:0.0001\n",
      "Epoch 9, Step: 59, Loss: 0.14844317734241486, Lr:0.0001\n",
      "Epoch 9, Step: 60, Loss: 0.09832029789686203, Lr:0.0001\n",
      "Epoch 9, Step: 61, Loss: 0.08465201407670975, Lr:0.0001\n",
      "Epoch 9, Step: 62, Loss: 0.11824551224708557, Lr:0.0001\n",
      "Epoch 9, Step: 63, Loss: 0.03898150101304054, Lr:0.0001\n",
      "Epoch 9, Step: 64, Loss: 0.05712609365582466, Lr:0.0001\n",
      "Epoch 9, Step: 65, Loss: 0.23087838292121887, Lr:0.0001\n",
      "Epoch 9, Step: 66, Loss: 0.07677406072616577, Lr:0.0001\n",
      "Epoch 9, Step: 67, Loss: 0.30505192279815674, Lr:0.0001\n",
      "Epoch 9, Step: 68, Loss: 0.15737400949001312, Lr:0.0001\n",
      "Epoch 9, Step: 69, Loss: 0.057309284806251526, Lr:0.0001\n",
      "Epoch 9, Step: 70, Loss: 0.345002144575119, Lr:0.0001\n",
      "Epoch 9, Step: 71, Loss: 0.02111085318028927, Lr:0.0001\n",
      "Epoch 9, Step: 72, Loss: 0.04012834280729294, Lr:0.0001\n",
      "Epoch 9, Step: 73, Loss: 0.14434988796710968, Lr:0.0001\n",
      "Epoch 9, Step: 74, Loss: 0.11567939817905426, Lr:0.0001\n",
      "Epoch 9, Step: 75, Loss: 0.02834763005375862, Lr:0.0001\n",
      "Epoch 9, Step: 76, Loss: 0.06744255125522614, Lr:0.0001\n",
      "Epoch 9, Step: 77, Loss: 0.11974682658910751, Lr:0.0001\n",
      "Epoch 9, Step: 78, Loss: 0.2404542863368988, Lr:0.0001\n",
      "Epoch 9, Step: 79, Loss: 0.03643254563212395, Lr:0.0001\n",
      "Epoch 9, Step: 80, Loss: 0.10341233015060425, Lr:0.0001\n",
      "Epoch 9, Step: 81, Loss: 0.10564970225095749, Lr:0.0001\n",
      "Epoch 9, Step: 82, Loss: 0.18566280603408813, Lr:0.0001\n",
      "Epoch 9, Step: 83, Loss: 0.14066749811172485, Lr:0.0001\n",
      "Epoch 9, Step: 84, Loss: 0.015182795003056526, Lr:0.0001\n",
      "Epoch 9, Step: 85, Loss: 0.3229508697986603, Lr:0.0001\n",
      "Epoch 9, Step: 86, Loss: 0.06610281020402908, Lr:0.0001\n",
      "Epoch 9, Step: 87, Loss: 0.014698464423418045, Lr:0.0001\n",
      "Epoch 9, Step: 88, Loss: 0.2949489951133728, Lr:0.0001\n",
      "Epoch 9, Step: 89, Loss: 0.11948881298303604, Lr:0.0001\n",
      "Epoch 9, Step: 90, Loss: 0.027668815106153488, Lr:0.0001\n",
      "Epoch 9, Step: 91, Loss: 0.039902690798044205, Lr:0.0001\n",
      "Epoch 9, Step: 92, Loss: 0.023628579452633858, Lr:0.0001\n",
      "Epoch 9, Step: 93, Loss: 0.04553813114762306, Lr:0.0001\n",
      "Epoch 9, Step: 94, Loss: 0.054832641035318375, Lr:0.0001\n",
      "Epoch 9, Step: 95, Loss: 0.20433585345745087, Lr:0.0001\n",
      "Epoch 9, Step: 96, Loss: 0.24627165496349335, Lr:0.0001\n",
      "Epoch 9, Step: 97, Loss: 0.03937973827123642, Lr:0.0001\n",
      "Epoch 9, Step: 98, Loss: 0.12790070474147797, Lr:0.0001\n",
      "Epoch 9, Step: 99, Loss: 0.01601262204349041, Lr:0.0001\n",
      "Epoch 9, Step: 100, Loss: 0.1005859375, Lr:0.0001\n",
      "Epoch 9, Step: 101, Loss: 0.04129733890295029, Lr:0.0001\n",
      "Epoch 9, Step: 102, Loss: 0.003908107522875071, Lr:0.0001\n",
      "Epoch 9, Step: 103, Loss: 0.11498790979385376, Lr:0.0001\n",
      "Epoch 9, Step: 104, Loss: 0.12252526730298996, Lr:0.0001\n",
      "Epoch 9, Step: 105, Loss: 0.42333200573921204, Lr:0.0001\n",
      "Epoch 9, Step: 106, Loss: 0.7193442583084106, Lr:0.0001\n",
      "Epoch 9, Step: 107, Loss: 0.11549748480319977, Lr:0.0001\n",
      "Epoch 9, Step: 108, Loss: 0.37918439507484436, Lr:0.0001\n",
      "Epoch 9, Step: 109, Loss: 0.1346348226070404, Lr:0.0001\n",
      "Epoch 9, Step: 110, Loss: 0.17183387279510498, Lr:0.0001\n",
      "Epoch 9, Step: 111, Loss: 0.17148296535015106, Lr:0.0001\n",
      "Epoch 9, Step: 112, Loss: 0.02903369441628456, Lr:0.0001\n",
      "Epoch 9, Step: 113, Loss: 0.09088591486215591, Lr:0.0001\n",
      "Epoch 9, Step: 114, Loss: 0.08390232175588608, Lr:0.0001\n",
      "Epoch 9, Step: 115, Loss: 0.2634986937046051, Lr:0.0001\n",
      "Epoch 9, Step: 116, Loss: 0.06614971905946732, Lr:0.0001\n",
      "Epoch 9, Step: 117, Loss: 0.13184118270874023, Lr:0.0001\n",
      "Epoch 9, Step: 118, Loss: 0.19465363025665283, Lr:0.0001\n",
      "Epoch 9, Step: 119, Loss: 0.09115225076675415, Lr:0.0001\n",
      "Epoch 9, Step: 120, Loss: 0.035089343786239624, Lr:0.0001\n",
      "Epoch 9, Step: 121, Loss: 0.09887208044528961, Lr:0.0001\n",
      "Epoch 9, Step: 122, Loss: 0.017041528597474098, Lr:0.0001\n",
      "Epoch 9, Step: 123, Loss: 0.326956570148468, Lr:0.0001\n",
      "Epoch 9, Step: 124, Loss: 0.02288104221224785, Lr:0.0001\n",
      "Epoch 9, Step: 125, Loss: 0.09094251692295074, Lr:0.0001\n",
      "Epoch 9, Step: 126, Loss: 0.07340271770954132, Lr:0.0001\n",
      "Epoch 9, Step: 127, Loss: 0.022078856825828552, Lr:0.0001\n",
      "Epoch 9, Step: 128, Loss: 0.04225657880306244, Lr:0.0001\n",
      "Epoch 9, Step: 129, Loss: 0.20073966681957245, Lr:0.0001\n",
      "Epoch 9, Step: 130, Loss: 0.055291797965765, Lr:0.0001\n",
      "Epoch 9, Step: 131, Loss: 0.01655382663011551, Lr:0.0001\n",
      "Epoch 9, Step: 132, Loss: 0.1827399730682373, Lr:0.0001\n",
      "Epoch 9, Step: 133, Loss: 0.3630405366420746, Lr:0.0001\n",
      "Epoch 9, Step: 134, Loss: 0.250654935836792, Lr:0.0001\n",
      "Epoch 9, Step: 135, Loss: 0.3169998824596405, Lr:0.0001\n",
      "Epoch 9, Step: 136, Loss: 0.30720317363739014, Lr:0.0001\n",
      "Epoch 9, Step: 137, Loss: 0.37927699089050293, Lr:0.0001\n",
      "Epoch 9, Step: 138, Loss: 0.07676367461681366, Lr:0.0001\n",
      "Epoch 9, Step: 139, Loss: 0.0842413604259491, Lr:0.0001\n",
      "Epoch 9, Step: 140, Loss: 0.22151216864585876, Lr:0.0001\n",
      "Epoch 9, Step: 141, Loss: 0.08445865660905838, Lr:0.0001\n",
      "Epoch 9, Step: 142, Loss: 0.22852252423763275, Lr:0.0001\n",
      "Epoch 9, Step: 143, Loss: 0.18497952818870544, Lr:0.0001\n",
      "Epoch 9, Step: 144, Loss: 0.05572156235575676, Lr:0.0001\n",
      "Epoch 9, Step: 145, Loss: 0.03313126787543297, Lr:0.0001\n",
      "Epoch 9, Step: 146, Loss: 0.18849675357341766, Lr:0.0001\n",
      "Epoch 9, Step: 147, Loss: 0.3762200176715851, Lr:0.0001\n",
      "Epoch 9, Step: 148, Loss: 0.19218449294567108, Lr:0.0001\n",
      "Epoch 9, Step: 149, Loss: 0.253403902053833, Lr:0.0001\n",
      "Epoch 9, Step: 150, Loss: 0.04551086574792862, Lr:0.0001\n",
      "Epoch 9, Step: 151, Loss: 0.12578065693378448, Lr:0.0001\n",
      "Epoch 9, Step: 152, Loss: 0.029846588149666786, Lr:0.0001\n",
      "Epoch 9, Step: 153, Loss: 0.1793016493320465, Lr:0.0001\n",
      "Epoch 9, Step: 154, Loss: 0.06723066419363022, Lr:0.0001\n",
      "Epoch 9, Step: 155, Loss: 0.07112954556941986, Lr:0.0001\n",
      "Epoch 9, Step: 156, Loss: 0.19284124672412872, Lr:0.0001\n",
      "Epoch 9, Step: 157, Loss: 0.105802021920681, Lr:0.0001\n",
      "Epoch 9, Step: 158, Loss: 0.142005056142807, Lr:0.0001\n",
      "Epoch 9, Step: 159, Loss: 0.11262811720371246, Lr:0.0001\n",
      "Epoch 9, Step: 160, Loss: 0.21698187291622162, Lr:0.0001\n",
      "Epoch 9, Step: 161, Loss: 0.19792813062667847, Lr:0.0001\n",
      "Epoch 9, Step: 162, Loss: 0.15712282061576843, Lr:0.0001\n",
      "Epoch 9, Step: 163, Loss: 0.05109761655330658, Lr:0.0001\n",
      "Epoch 9, Step: 164, Loss: 0.012182440608739853, Lr:0.0001\n",
      "Epoch 9, Step: 165, Loss: 0.40588828921318054, Lr:0.0001\n",
      "Epoch 9, Step: 166, Loss: 0.11387937515974045, Lr:0.0001\n",
      "Epoch 9, Step: 167, Loss: 0.578034520149231, Lr:0.0001\n",
      "Epoch 9, Step: 168, Loss: 0.06458733230829239, Lr:0.0001\n",
      "Epoch 9, Step: 169, Loss: 0.08237683027982712, Lr:0.0001\n",
      "Epoch 9, Step: 170, Loss: 0.011912337504327297, Lr:0.0001\n",
      "Epoch 9, Step: 171, Loss: 0.1724102944135666, Lr:0.0001\n",
      "Epoch 9, Step: 172, Loss: 0.08392128348350525, Lr:0.0001\n",
      "Epoch 9, Step: 173, Loss: 0.34701451659202576, Lr:0.0001\n",
      "Epoch 9, Step: 174, Loss: 0.10808847099542618, Lr:0.0001\n",
      "Epoch 9, Step: 175, Loss: 0.1298261284828186, Lr:0.0001\n",
      "Epoch 9, Step: 176, Loss: 0.2320682257413864, Lr:0.0001\n",
      "Epoch 9, Step: 177, Loss: 0.11761841922998428, Lr:0.0001\n",
      "Epoch 9, Step: 178, Loss: 0.054255180060863495, Lr:0.0001\n",
      "Epoch 9, Step: 179, Loss: 0.12604011595249176, Lr:0.0001\n",
      "Epoch 9, Step: 180, Loss: 0.6372253894805908, Lr:0.0001\n",
      "Epoch 9, Step: 181, Loss: 0.10916876047849655, Lr:0.0001\n",
      "Epoch 9, Step: 182, Loss: 0.04748351499438286, Lr:0.0001\n",
      "Epoch 9, Step: 183, Loss: 0.2694031000137329, Lr:0.0001\n",
      "Epoch 9, Step: 184, Loss: 0.045493900775909424, Lr:0.0001\n",
      "Epoch 9, Step: 185, Loss: 0.16627809405326843, Lr:0.0001\n",
      "Epoch 9, Step: 186, Loss: 0.125486820936203, Lr:0.0001\n",
      "Epoch 9, Step: 187, Loss: 0.05927467346191406, Lr:0.0001\n",
      "Epoch 9, Step: 188, Loss: 0.06976856291294098, Lr:0.0001\n",
      "Epoch 9, Step: 189, Loss: 0.4969552755355835, Lr:0.0001\n",
      "Epoch 9, Step: 190, Loss: 0.5832546949386597, Lr:0.0001\n",
      "Epoch 9, Step: 191, Loss: 0.18387717008590698, Lr:0.0001\n",
      "Epoch 9, Step: 192, Loss: 0.3262796103954315, Lr:0.0001\n",
      "Epoch 9, Step: 193, Loss: 0.02524190954864025, Lr:0.0001\n",
      "Epoch 9, Step: 194, Loss: 0.2323712706565857, Lr:0.0001\n",
      "Epoch 9, Step: 195, Loss: 0.1463341861963272, Lr:0.0001\n",
      "Epoch 9, Step: 196, Loss: 0.15112441778182983, Lr:0.0001\n",
      "Epoch 9, Step: 197, Loss: 0.22418425977230072, Lr:0.0001\n",
      "Epoch 9, Step: 198, Loss: 0.05060135945677757, Lr:0.0001\n",
      "Epoch 9, Step: 199, Loss: 0.1380869746208191, Lr:0.0001\n",
      "Epoch 9, Step: 200, Loss: 0.10849346220493317, Lr:0.0001\n",
      "Epoch 9, Step: 201, Loss: 0.056203749030828476, Lr:0.0001\n",
      "Epoch 9, Step: 202, Loss: 0.09188300371170044, Lr:0.0001\n",
      "Epoch 9, Step: 203, Loss: 0.1226990669965744, Lr:0.0001\n",
      "Epoch 9, Step: 204, Loss: 0.0971420630812645, Lr:0.0001\n",
      "Epoch 9, Step: 205, Loss: 0.03874365985393524, Lr:0.0001\n",
      "Epoch 9, Step: 206, Loss: 0.4271749258041382, Lr:0.0001\n",
      "Epoch 9, Step: 207, Loss: 0.05788024514913559, Lr:0.0001\n",
      "Epoch 9, Step: 208, Loss: 0.021128244698047638, Lr:0.0001\n",
      "Epoch 9, Step: 209, Loss: 0.04963960498571396, Lr:0.0001\n",
      "Epoch 9, Step: 210, Loss: 0.45873352885246277, Lr:0.0001\n",
      "Epoch 9, Step: 211, Loss: 0.04596730321645737, Lr:0.0001\n",
      "Epoch 9, Step: 212, Loss: 0.07490983605384827, Lr:0.0001\n",
      "Epoch 9, Step: 213, Loss: 0.02863207831978798, Lr:0.0001\n",
      "Epoch 9, Step: 214, Loss: 0.091000497341156, Lr:0.0001\n",
      "Epoch 9, Step: 215, Loss: 0.11304633319377899, Lr:0.0001\n",
      "Epoch 9, Step: 216, Loss: 0.47581249475479126, Lr:0.0001\n",
      "Epoch 9, Step: 217, Loss: 0.045473285019397736, Lr:0.0001\n",
      "Epoch 9, Step: 218, Loss: 0.03491612896323204, Lr:0.0001\n",
      "Epoch 9, Step: 219, Loss: 0.22796013951301575, Lr:0.0001\n",
      "Epoch 9, Step: 220, Loss: 0.1062144860625267, Lr:0.0001\n",
      "Epoch 9, Step: 221, Loss: 0.0512767918407917, Lr:0.0001\n",
      "Epoch 9, Step: 222, Loss: 0.023562200367450714, Lr:0.0001\n",
      "Epoch 9, Step: 223, Loss: 0.05631551146507263, Lr:0.0001\n",
      "Epoch 9, Step: 224, Loss: 0.10608131438493729, Lr:0.0001\n",
      "Epoch 9, Step: 225, Loss: 0.3600160777568817, Lr:0.0001\n",
      "Epoch 9, Step: 226, Loss: 0.19592861831188202, Lr:0.0001\n",
      "Epoch 9, Step: 227, Loss: 0.017908776178956032, Lr:0.0001\n",
      "Epoch 9, Step: 228, Loss: 0.03407333791255951, Lr:0.0001\n",
      "Epoch 9, Step: 229, Loss: 0.08358877897262573, Lr:0.0001\n",
      "Epoch 9, Step: 230, Loss: 0.11067529022693634, Lr:0.0001\n",
      "Epoch 9, Step: 231, Loss: 0.029544297605752945, Lr:0.0001\n",
      "Epoch 9, Step: 232, Loss: 0.039107680320739746, Lr:0.0001\n",
      "Epoch 9, Step: 233, Loss: 0.04515562951564789, Lr:0.0001\n",
      "Epoch 9, Step: 234, Loss: 0.31537821888923645, Lr:0.0001\n",
      "Epoch 9, Step: 235, Loss: 0.03862491622567177, Lr:0.0001\n",
      "Epoch 9, Step: 236, Loss: 0.06975658237934113, Lr:0.0001\n",
      "Epoch 9, Step: 237, Loss: 0.06598049402236938, Lr:0.0001\n",
      "Epoch 9, Step: 238, Loss: 0.28631591796875, Lr:0.0001\n",
      "Epoch 9, Step: 239, Loss: 0.15190201997756958, Lr:0.0001\n",
      "Epoch 9, Step: 240, Loss: 0.24711757898330688, Lr:0.0001\n",
      "Epoch 9, Step: 241, Loss: 0.05821841210126877, Lr:0.0001\n",
      "Epoch 9, Step: 242, Loss: 0.13370037078857422, Lr:0.0001\n",
      "Epoch 9, Step: 243, Loss: 0.19610105454921722, Lr:0.0001\n",
      "Epoch 9, Step: 244, Loss: 0.050366152077913284, Lr:0.0001\n",
      "Epoch 9, Step: 245, Loss: 0.04135126248002052, Lr:0.0001\n",
      "Epoch 9, Step: 246, Loss: 0.014008698984980583, Lr:0.0001\n",
      "Epoch 9, Step: 247, Loss: 0.12675504386425018, Lr:0.0001\n",
      "Epoch 9, Step: 248, Loss: 0.22095076739788055, Lr:0.0001\n",
      "Epoch 9, Step: 249, Loss: 0.26977235078811646, Lr:0.0001\n",
      "Epoch 9, Step: 250, Loss: 0.012174117378890514, Lr:0.0001\n",
      "Epoch 9, Step: 251, Loss: 0.15455709397792816, Lr:0.0001\n",
      "Epoch 9, Step: 252, Loss: 0.04296797513961792, Lr:0.0001\n",
      "Epoch 9, Step: 253, Loss: 0.19786716997623444, Lr:0.0001\n",
      "Epoch 9, Step: 254, Loss: 0.1646227240562439, Lr:0.0001\n",
      "Epoch 9, Step: 255, Loss: 0.06616997718811035, Lr:0.0001\n",
      "Epoch 9, Step: 256, Loss: 0.07628968358039856, Lr:0.0001\n",
      "Epoch 9, Step: 257, Loss: 0.06187129765748978, Lr:0.0001\n",
      "Epoch 9, Step: 258, Loss: 0.11073601245880127, Lr:0.0001\n",
      "Epoch 9, Step: 259, Loss: 0.10587520152330399, Lr:0.0001\n",
      "Epoch 9, Step: 260, Loss: 0.05767112597823143, Lr:0.0001\n",
      "Epoch 9, Step: 261, Loss: 0.19527781009674072, Lr:0.0001\n",
      "Epoch 9, Step: 262, Loss: 0.07184577733278275, Lr:0.0001\n",
      "Epoch 9, Step: 263, Loss: 0.18655911087989807, Lr:0.0001\n",
      "Epoch 9, Step: 264, Loss: 0.03179952874779701, Lr:0.0001\n",
      "Epoch 9, Step: 265, Loss: 0.24506835639476776, Lr:0.0001\n",
      "Epoch 9, Step: 266, Loss: 0.31512004137039185, Lr:0.0001\n",
      "Epoch 9, Step: 267, Loss: 0.02346520870923996, Lr:0.0001\n",
      "Epoch 9, Step: 268, Loss: 0.23773540556430817, Lr:0.0001\n",
      "Epoch 9, Step: 269, Loss: 0.026249399408698082, Lr:0.0001\n",
      "Epoch 9, Step: 270, Loss: 0.130919948220253, Lr:0.0001\n",
      "Epoch 9, Step: 271, Loss: 0.13859543204307556, Lr:0.0001\n",
      "Epoch 9, Step: 272, Loss: 0.11344967037439346, Lr:0.0001\n",
      "Epoch 9, Step: 273, Loss: 0.046702709048986435, Lr:0.0001\n",
      "Epoch 9, Step: 274, Loss: 0.09733665734529495, Lr:0.0001\n",
      "Epoch 9, Step: 275, Loss: 0.048928167670965195, Lr:0.0001\n",
      "Epoch 9, Step: 276, Loss: 0.09040553867816925, Lr:0.0001\n",
      "Epoch 9, Step: 277, Loss: 0.014384808950126171, Lr:0.0001\n",
      "Epoch 9, Step: 278, Loss: 0.05990876257419586, Lr:0.0001\n",
      "Epoch 9, Step: 279, Loss: 0.0496530756354332, Lr:0.0001\n",
      "Epoch 9, Step: 280, Loss: 0.1002262756228447, Lr:0.0001\n",
      "Epoch 9, Step: 281, Loss: 0.15850424766540527, Lr:0.0001\n",
      "Epoch 9, Step: 282, Loss: 0.07974115759134293, Lr:0.0001\n",
      "Epoch 9, Step: 283, Loss: 0.23521161079406738, Lr:0.0001\n",
      "Epoch 9, Step: 284, Loss: 0.20989452302455902, Lr:0.0001\n",
      "Epoch 9, Step: 285, Loss: 0.42835885286331177, Lr:0.0001\n",
      "Epoch 9, Step: 286, Loss: 0.07580110430717468, Lr:0.0001\n",
      "Epoch 9, Step: 287, Loss: 0.1228729709982872, Lr:0.0001\n",
      "Epoch 9, Step: 288, Loss: 0.3246889114379883, Lr:0.0001\n",
      "Epoch 9, Step: 289, Loss: 0.058136630803346634, Lr:0.0001\n",
      "Epoch 9, Step: 290, Loss: 0.16019392013549805, Lr:0.0001\n",
      "Epoch 9, Step: 291, Loss: 0.06785369664430618, Lr:0.0001\n",
      "Epoch 9, Step: 292, Loss: 0.21702982485294342, Lr:0.0001\n",
      "Epoch 9, Step: 293, Loss: 0.2275971919298172, Lr:0.0001\n",
      "Epoch 9, Step: 294, Loss: 0.2685917615890503, Lr:0.0001\n",
      "Epoch 9, Step: 295, Loss: 0.19798417389392853, Lr:0.0001\n",
      "Epoch 9, Step: 296, Loss: 0.16168050467967987, Lr:0.0001\n",
      "Epoch 9, Step: 297, Loss: 0.10951220989227295, Lr:0.0001\n",
      "Epoch 9, Step: 298, Loss: 0.43802720308303833, Lr:0.0001\n",
      "Epoch 9, Step: 299, Loss: 0.5613365769386292, Lr:0.0001\n",
      "Epoch 9, Step: 300, Loss: 0.1743782013654709, Lr:0.0001\n",
      "Epoch 9, Step: 301, Loss: 0.16294284164905548, Lr:0.0001\n",
      "Epoch 9, Step: 302, Loss: 0.23128393292427063, Lr:0.0001\n",
      "Epoch 9, Step: 303, Loss: 0.06644944101572037, Lr:0.0001\n",
      "Epoch 9, Step: 304, Loss: 0.2919280529022217, Lr:0.0001\n",
      "Epoch 9, Step: 305, Loss: 0.23867350816726685, Lr:0.0001\n",
      "Epoch 9, Step: 306, Loss: 0.39962372183799744, Lr:0.0001\n",
      "Epoch 9, Step: 307, Loss: 0.1637267768383026, Lr:0.0001\n",
      "Epoch 9, Step: 308, Loss: 0.3389759361743927, Lr:0.0001\n",
      "Epoch 9, Step: 309, Loss: 0.19638365507125854, Lr:0.0001\n",
      "Epoch 9, Step: 310, Loss: 0.16318896412849426, Lr:0.0001\n",
      "Epoch 9, Step: 311, Loss: 0.06203184276819229, Lr:0.0001\n",
      "Epoch 9, Step: 312, Loss: 0.42316240072250366, Lr:0.0001\n",
      "Epoch 9, Step: 313, Loss: 0.110834501683712, Lr:0.0001\n",
      "Epoch 9, Step: 314, Loss: 0.24573524296283722, Lr:0.0001\n",
      "Epoch 9, Step: 315, Loss: 0.19626423716545105, Lr:0.0001\n",
      "Epoch 9, Step: 316, Loss: 0.22681650519371033, Lr:0.0001\n",
      "Epoch 9, Step: 317, Loss: 0.06771320104598999, Lr:0.0001\n",
      "Epoch 9, Step: 318, Loss: 0.16302841901779175, Lr:0.0001\n",
      "Epoch 9, Step: 319, Loss: 0.23365060985088348, Lr:0.0001\n",
      "Epoch 9, Step: 320, Loss: 0.14691393077373505, Lr:0.0001\n",
      "Epoch 9, Step: 321, Loss: 0.014842042699456215, Lr:0.0001\n",
      "Epoch 9, Step: 322, Loss: 0.04754021763801575, Lr:0.0001\n",
      "Epoch 9, Step: 323, Loss: 0.22015130519866943, Lr:0.0001\n",
      "Epoch 9, Step: 324, Loss: 0.012325120158493519, Lr:0.0001\n",
      "Epoch 9, Step: 325, Loss: 0.43941107392311096, Lr:0.0001\n",
      "Epoch 9, Step: 326, Loss: 0.04679546132683754, Lr:0.0001\n",
      "Epoch 9, Step: 327, Loss: 0.1612366884946823, Lr:0.0001\n",
      "Epoch 9, Step: 328, Loss: 0.14182192087173462, Lr:0.0001\n",
      "Epoch 9, Step: 329, Loss: 0.5052540302276611, Lr:0.0001\n",
      "Epoch 9, Step: 330, Loss: 0.15549913048744202, Lr:0.0001\n",
      "Epoch 9, Step: 331, Loss: 0.21404649317264557, Lr:0.0001\n",
      "Epoch 9, Step: 332, Loss: 0.3084295988082886, Lr:0.0001\n",
      "Epoch 9, Step: 333, Loss: 0.14354318380355835, Lr:0.0001\n",
      "Epoch 9, Step: 334, Loss: 0.06446520239114761, Lr:0.0001\n",
      "Epoch 9, Step: 335, Loss: 0.05867736041545868, Lr:0.0001\n",
      "Epoch 9, Step: 336, Loss: 0.23075880110263824, Lr:0.0001\n",
      "Epoch 9, Step: 337, Loss: 0.047230206429958344, Lr:0.0001\n",
      "Epoch 9, Step: 338, Loss: 0.17919428646564484, Lr:0.0001\n",
      "Epoch 9, Step: 339, Loss: 0.06424053758382797, Lr:0.0001\n",
      "Epoch 9, Step: 340, Loss: 0.2864437401294708, Lr:0.0001\n",
      "Epoch 9, Step: 341, Loss: 0.06413160264492035, Lr:0.0001\n",
      "Epoch 9, Step: 342, Loss: 0.16645002365112305, Lr:0.0001\n",
      "Epoch 9, Step: 343, Loss: 0.18373502790927887, Lr:0.0001\n",
      "Epoch 9, Step: 344, Loss: 0.05990120396018028, Lr:0.0001\n",
      "Epoch 9, Step: 345, Loss: 0.1631535142660141, Lr:0.0001\n",
      "Epoch 9, Step: 346, Loss: 0.2452782690525055, Lr:0.0001\n",
      "Epoch 9, Step: 347, Loss: 0.05945136398077011, Lr:0.0001\n",
      "Epoch 9, Step: 348, Loss: 0.13707324862480164, Lr:0.0001\n",
      "Epoch 9, Step: 349, Loss: 0.12737491726875305, Lr:0.0001\n",
      "Epoch 9, Step: 350, Loss: 0.24541351199150085, Lr:0.0001\n",
      "Epoch 9, Step: 351, Loss: 0.03344470262527466, Lr:0.0001\n",
      "Epoch 9, Step: 352, Loss: 0.07884235680103302, Lr:0.0001\n",
      "Epoch 9, Step: 353, Loss: 0.17128239572048187, Lr:0.0001\n",
      "Epoch 9, Step: 354, Loss: 0.1691133975982666, Lr:0.0001\n",
      "Epoch 9, Step: 355, Loss: 0.28175121545791626, Lr:0.0001\n",
      "Epoch 9, Step: 356, Loss: 0.05846115201711655, Lr:0.0001\n",
      "Epoch 9, Step: 357, Loss: 0.3124546706676483, Lr:0.0001\n",
      "Epoch 9, Step: 358, Loss: 0.18969830870628357, Lr:0.0001\n",
      "Epoch 9, Step: 359, Loss: 0.14692749083042145, Lr:0.0001\n",
      "Epoch 9, Step: 360, Loss: 0.020105930045247078, Lr:0.0001\n",
      "Epoch 9, Step: 361, Loss: 0.2955431342124939, Lr:0.0001\n",
      "Epoch 9, Step: 362, Loss: 0.05699436366558075, Lr:0.0001\n",
      "Epoch 9, Step: 363, Loss: 0.40662887692451477, Lr:0.0001\n",
      "Epoch 9, Step: 364, Loss: 0.08628712594509125, Lr:0.0001\n",
      "Epoch 9, Step: 365, Loss: 0.25531286001205444, Lr:0.0001\n",
      "Epoch 9, Step: 366, Loss: 0.07874047756195068, Lr:0.0001\n",
      "Epoch 9, Step: 367, Loss: 0.3451661765575409, Lr:0.0001\n",
      "Epoch 9, Step: 368, Loss: 0.34994184970855713, Lr:0.0001\n",
      "Epoch 9, Step: 369, Loss: 0.1615424007177353, Lr:0.0001\n",
      "Epoch 9, Step: 370, Loss: 0.11131265014410019, Lr:0.0001\n",
      "Epoch 9, Step: 371, Loss: 0.20507626235485077, Lr:0.0001\n",
      "Epoch 9, Step: 372, Loss: 0.14861488342285156, Lr:0.0001\n",
      "Epoch 9, Step: 373, Loss: 0.23175188899040222, Lr:0.0001\n",
      "Epoch 9, Step: 374, Loss: 0.05343356356024742, Lr:0.0001\n",
      "Epoch 9, Step: 375, Loss: 0.5552895665168762, Lr:0.0001\n",
      "Epoch 9, Step: 376, Loss: 0.10789521783590317, Lr:0.0001\n",
      "Epoch 9, Step: 377, Loss: 0.2352309376001358, Lr:0.0001\n",
      "Epoch 9, Step: 378, Loss: 0.18834473192691803, Lr:0.0001\n",
      "Epoch 9, Step: 379, Loss: 0.12909948825836182, Lr:0.0001\n",
      "Epoch 9, Step: 380, Loss: 0.11690379679203033, Lr:0.0001\n",
      "Epoch 9, Step: 381, Loss: 0.2223091423511505, Lr:0.0001\n",
      "Epoch 9, Step: 382, Loss: 0.360597163438797, Lr:0.0001\n",
      "Epoch 9, Step: 383, Loss: 0.027317384257912636, Lr:0.0001\n",
      "Epoch 9, Step: 384, Loss: 0.08360433578491211, Lr:0.0001\n",
      "Epoch 9, Step: 385, Loss: 0.13808944821357727, Lr:0.0001\n",
      "Epoch 9, Step: 386, Loss: 0.15846288204193115, Lr:0.0001\n",
      "Epoch 9, Step: 387, Loss: 0.19724564254283905, Lr:0.0001\n",
      "Epoch 9, Step: 388, Loss: 0.09595277160406113, Lr:0.0001\n",
      "Epoch 9, Step: 389, Loss: 0.08016856759786606, Lr:0.0001\n",
      "Epoch 9, Step: 390, Loss: 0.06484802067279816, Lr:0.0001\n",
      "Epoch 9, Step: 391, Loss: 0.26429712772369385, Lr:0.0001\n",
      "Epoch 9, Step: 392, Loss: 0.12188117206096649, Lr:0.0001\n",
      "Epoch 9, Step: 393, Loss: 0.08839929103851318, Lr:0.0001\n",
      "Epoch 9, Step: 394, Loss: 0.14391396939754486, Lr:0.0001\n",
      "Epoch 9, Step: 395, Loss: 0.21247170865535736, Lr:0.0001\n",
      "Epoch 9, Step: 396, Loss: 0.10706838220357895, Lr:0.0001\n",
      "Epoch 9, Step: 397, Loss: 0.2540724277496338, Lr:0.0001\n",
      "Epoch 9, Step: 398, Loss: 0.008619713596999645, Lr:0.0001\n",
      "Epoch 9, Step: 399, Loss: 0.029920488595962524, Lr:0.0001\n",
      "Epoch 9, Step: 400, Loss: 0.25244414806365967, Lr:0.0001\n",
      "Epoch 9, Step: 401, Loss: 0.08911977708339691, Lr:0.0001\n",
      "Epoch 9, Step: 402, Loss: 0.14786502718925476, Lr:0.0001\n",
      "Epoch 9, Step: 403, Loss: 0.07869928330183029, Lr:0.0001\n",
      "Epoch 9, Step: 404, Loss: 0.15153758227825165, Lr:0.0001\n",
      "Epoch 9, Step: 405, Loss: 0.0964994728565216, Lr:0.0001\n",
      "Epoch 9, Step: 406, Loss: 0.11071119457483292, Lr:0.0001\n",
      "Epoch 9, Step: 407, Loss: 0.2596287429332733, Lr:0.0001\n",
      "Epoch 9, Step: 408, Loss: 0.037098005414009094, Lr:0.0001\n",
      "Epoch 9, Step: 409, Loss: 0.050283681601285934, Lr:0.0001\n",
      "Epoch 9, Step: 410, Loss: 0.44702062010765076, Lr:0.0001\n",
      "Epoch 9, Step: 411, Loss: 0.13396918773651123, Lr:0.0001\n",
      "Epoch 9, Step: 412, Loss: 0.13132520020008087, Lr:0.0001\n",
      "Epoch 9, Step: 413, Loss: 0.07895424962043762, Lr:0.0001\n",
      "Epoch 9, Step: 414, Loss: 0.2576599717140198, Lr:0.0001\n",
      "Epoch 9, Step: 415, Loss: 0.14183156192302704, Lr:0.0001\n",
      "Epoch 9, Step: 416, Loss: 0.053888481110334396, Lr:0.0001\n",
      "Epoch 9, Step: 417, Loss: 0.1039080023765564, Lr:0.0001\n",
      "Epoch 9, Step: 418, Loss: 0.12244483083486557, Lr:0.0001\n",
      "Epoch 9, Step: 419, Loss: 0.08354920893907547, Lr:0.0001\n",
      "Epoch 9, Step: 420, Loss: 0.036044809967279434, Lr:0.0001\n",
      "Epoch 9, Step: 421, Loss: 0.12397339940071106, Lr:0.0001\n",
      "Epoch 9, Step: 422, Loss: 0.07920075953006744, Lr:0.0001\n",
      "Epoch 9, Step: 423, Loss: 0.289104163646698, Lr:0.0001\n",
      "Epoch 9, Step: 424, Loss: 0.36435797810554504, Lr:0.0001\n",
      "Epoch 9, Step: 425, Loss: 0.22607339918613434, Lr:0.0001\n",
      "Epoch 9, Step: 426, Loss: 0.02817540057003498, Lr:0.0001\n",
      "Epoch 9, Step: 427, Loss: 0.14459753036499023, Lr:0.0001\n",
      "Epoch 9, Step: 428, Loss: 0.1604534387588501, Lr:0.0001\n",
      "Epoch 9, Step: 429, Loss: 0.09011638164520264, Lr:0.0001\n",
      "Epoch 9, Step: 430, Loss: 0.2006670981645584, Lr:0.0001\n",
      "Epoch 9, Step: 431, Loss: 0.573610246181488, Lr:0.0001\n",
      "Epoch 9, Step: 432, Loss: 0.11856900900602341, Lr:0.0001\n",
      "Epoch 9, Step: 433, Loss: 0.15517009794712067, Lr:0.0001\n",
      "Epoch 9, Step: 434, Loss: 0.050336506217718124, Lr:0.0001\n",
      "Epoch 9, Step: 435, Loss: 0.0679829865694046, Lr:0.0001\n",
      "Epoch 9, Step: 436, Loss: 0.42693787813186646, Lr:0.0001\n",
      "Epoch 9, Step: 437, Loss: 0.3436056673526764, Lr:0.0001\n",
      "Epoch 9, Step: 438, Loss: 0.13866619765758514, Lr:0.0001\n",
      "Epoch 9, Step: 439, Loss: 0.13889826834201813, Lr:0.0001\n",
      "Epoch 9, Step: 440, Loss: 0.15023164451122284, Lr:0.0001\n",
      "Epoch 9, Step: 441, Loss: 0.029117660596966743, Lr:0.0001\n",
      "Epoch 9, Step: 442, Loss: 0.45567432045936584, Lr:0.0001\n",
      "Epoch 9, Step: 443, Loss: 0.2188369333744049, Lr:0.0001\n",
      "Epoch 9, Step: 444, Loss: 0.05480421334505081, Lr:0.0001\n",
      "Epoch 9, Step: 445, Loss: 0.09464412182569504, Lr:0.0001\n",
      "Epoch 9, Step: 446, Loss: 0.3547670841217041, Lr:0.0001\n",
      "Epoch 9, Step: 447, Loss: 0.1797281950712204, Lr:0.0001\n",
      "Epoch 9, Step: 448, Loss: 0.10637512803077698, Lr:0.0001\n",
      "Epoch 9, Step: 449, Loss: 0.01749366521835327, Lr:0.0001\n",
      "Epoch 9, Step: 450, Loss: 0.12184492498636246, Lr:0.0001\n",
      "Epoch 9, Step: 451, Loss: 0.1314961314201355, Lr:0.0001\n",
      "Epoch 9, Step: 452, Loss: 0.3146213889122009, Lr:0.0001\n",
      "Epoch 9, Step: 453, Loss: 0.29187747836112976, Lr:0.0001\n",
      "Epoch 9, Step: 454, Loss: 0.11552155762910843, Lr:0.0001\n",
      "Epoch 9, Step: 455, Loss: 0.3326861560344696, Lr:0.0001\n",
      "Epoch 9, Step: 456, Loss: 0.4309196472167969, Lr:0.0001\n",
      "Epoch 9, Step: 457, Loss: 0.106118343770504, Lr:0.0001\n",
      "Epoch 9, Step: 458, Loss: 0.5815836787223816, Lr:0.0001\n",
      "Epoch 9, Step: 459, Loss: 0.0924951583147049, Lr:0.0001\n",
      "Epoch 9, Step: 460, Loss: 0.2085723727941513, Lr:0.0001\n",
      "Epoch 9, Step: 461, Loss: 0.16797375679016113, Lr:0.0001\n",
      "Epoch 9, Step: 462, Loss: 0.08889571577310562, Lr:0.0001\n",
      "Epoch 9, Step: 463, Loss: 0.04850867763161659, Lr:0.0001\n",
      "Epoch 9, Step: 464, Loss: 0.30561041831970215, Lr:0.0001\n",
      "Epoch 9, Step: 465, Loss: 0.47929906845092773, Lr:0.0001\n",
      "Epoch 9, Step: 466, Loss: 0.06223492696881294, Lr:0.0001\n",
      "Epoch 9, Step: 467, Loss: 0.10795819759368896, Lr:0.0001\n",
      "Epoch 9, Step: 468, Loss: 0.44213807582855225, Lr:0.0001\n",
      "Epoch 9, Step: 469, Loss: 0.5617898106575012, Lr:0.0001\n",
      "Epoch 9, Step: 470, Loss: 0.11470473557710648, Lr:0.0001\n",
      "Epoch 9, Step: 471, Loss: 0.24523678421974182, Lr:0.0001\n",
      "Epoch 9, Step: 472, Loss: 0.27496758103370667, Lr:0.0001\n",
      "Epoch 9, Step: 473, Loss: 0.211086243391037, Lr:0.0001\n",
      "Epoch 9, Step: 474, Loss: 0.15943145751953125, Lr:0.0001\n",
      "Epoch 9, Step: 475, Loss: 0.06027843430638313, Lr:0.0001\n",
      "Epoch 9, Step: 476, Loss: 0.23087893426418304, Lr:0.0001\n",
      "Epoch 9, Step: 477, Loss: 0.07368425279855728, Lr:0.0001\n",
      "Epoch 9, Step: 478, Loss: 0.036455925554037094, Lr:0.0001\n",
      "Epoch 9, Step: 479, Loss: 0.1784399151802063, Lr:0.0001\n",
      "Epoch 9, Step: 480, Loss: 0.06493909657001495, Lr:0.0001\n",
      "Epoch 9, Step: 481, Loss: 0.1693381518125534, Lr:0.0001\n",
      "Epoch 9, Step: 482, Loss: 0.28365105390548706, Lr:0.0001\n",
      "Epoch 9, Step: 483, Loss: 0.1395137906074524, Lr:0.0001\n",
      "Epoch 9, Step: 484, Loss: 0.41153091192245483, Lr:0.0001\n",
      "Epoch 9, Step: 485, Loss: 0.14339733123779297, Lr:0.0001\n",
      "Epoch 9, Step: 486, Loss: 0.03435713052749634, Lr:0.0001\n",
      "Epoch 9, Step: 487, Loss: 0.09073999524116516, Lr:0.0001\n",
      "Epoch 9, Step: 488, Loss: 0.046328164637088776, Lr:0.0001\n",
      "Epoch 9, Step: 489, Loss: 0.04358061030507088, Lr:0.0001\n",
      "Epoch 9, Step: 490, Loss: 0.20628194510936737, Lr:0.0001\n",
      "Epoch 9, Step: 491, Loss: 0.19009634852409363, Lr:0.0001\n",
      "Epoch 9, Step: 492, Loss: 0.09273924678564072, Lr:0.0001\n",
      "Epoch 9, Step: 493, Loss: 0.0894462913274765, Lr:0.0001\n",
      "Epoch 9, Step: 494, Loss: 0.25550103187561035, Lr:0.0001\n",
      "Epoch 9, Step: 495, Loss: 0.663439929485321, Lr:0.0001\n",
      "Epoch 9, Step: 496, Loss: 0.032256390899419785, Lr:0.0001\n",
      "Epoch 9, Step: 497, Loss: 0.23668909072875977, Lr:0.0001\n",
      "Epoch 9, Step: 498, Loss: 0.07707038521766663, Lr:0.0001\n",
      "Epoch 9, Step: 499, Loss: 0.19126738607883453, Lr:0.0001\n",
      "Epoch 9, Step: 500, Loss: 0.10513654351234436, Lr:0.0001\n",
      "Epoch 9, Step: 501, Loss: 0.020070165395736694, Lr:0.0001\n",
      "Epoch 9, Step: 502, Loss: 0.2954501211643219, Lr:0.0001\n",
      "Epoch 9, Step: 503, Loss: 0.07335440814495087, Lr:0.0001\n",
      "Epoch 9, Step: 504, Loss: 0.08107607066631317, Lr:0.0001\n",
      "Epoch 9, Step: 505, Loss: 0.2035915106534958, Lr:0.0001\n",
      "Epoch 9, Step: 506, Loss: 0.11730381846427917, Lr:0.0001\n",
      "Epoch 9, Step: 507, Loss: 0.14110352098941803, Lr:0.0001\n",
      "Epoch 9, Step: 508, Loss: 0.19593578577041626, Lr:0.0001\n",
      "Epoch 9, Step: 509, Loss: 0.039570100605487823, Lr:0.0001\n",
      "Epoch 9, Step: 510, Loss: 0.06985485553741455, Lr:0.0001\n",
      "Epoch 9, Step: 511, Loss: 0.12599948048591614, Lr:0.0001\n",
      "Epoch 9, Step: 512, Loss: 0.22342723608016968, Lr:0.0001\n",
      "Epoch 9, Step: 513, Loss: 0.06942740827798843, Lr:0.0001\n",
      "Epoch 9, Step: 514, Loss: 0.09757781028747559, Lr:0.0001\n",
      "Epoch 9, Step: 515, Loss: 0.32540738582611084, Lr:0.0001\n",
      "Epoch 9, Step: 516, Loss: 0.13503530621528625, Lr:0.0001\n",
      "Epoch 9, Step: 517, Loss: 0.36343100666999817, Lr:0.0001\n",
      "Epoch 9, Step: 518, Loss: 0.14255425333976746, Lr:0.0001\n",
      "Epoch 9, Step: 519, Loss: 0.10853934288024902, Lr:0.0001\n",
      "Epoch 9, Step: 520, Loss: 0.49825677275657654, Lr:0.0001\n",
      "Epoch 9, Step: 521, Loss: 0.12202875316143036, Lr:0.0001\n",
      "Epoch 9, Step: 522, Loss: 0.1038876473903656, Lr:0.0001\n",
      "Epoch 9, Step: 523, Loss: 0.20439879596233368, Lr:0.0001\n",
      "Epoch 9, Step: 524, Loss: 0.12272921949625015, Lr:0.0001\n",
      "Epoch 9, Step: 525, Loss: 0.07463770359754562, Lr:0.0001\n",
      "Epoch 9, Step: 526, Loss: 0.18307295441627502, Lr:0.0001\n",
      "Epoch 9, Step: 527, Loss: 0.049284499138593674, Lr:0.0001\n",
      "Epoch 9, Step: 528, Loss: 0.2275465428829193, Lr:0.0001\n",
      "Epoch 9, Step: 529, Loss: 0.12139496207237244, Lr:0.0001\n",
      "Epoch 9, Step: 530, Loss: 0.00685735372826457, Lr:0.0001\n",
      "Epoch 9, Step: 531, Loss: 0.398948073387146, Lr:0.0001\n",
      "Epoch 9, Step: 532, Loss: 0.06558376550674438, Lr:0.0001\n",
      "Epoch 9, Step: 533, Loss: 0.41792163252830505, Lr:0.0001\n",
      "Epoch 9, Step: 534, Loss: 0.10079959034919739, Lr:0.0001\n",
      "Epoch 9, Step: 535, Loss: 0.17477260529994965, Lr:0.0001\n",
      "Epoch 9, Step: 536, Loss: 0.11589950323104858, Lr:0.0001\n",
      "Epoch 9, Step: 537, Loss: 0.16110333800315857, Lr:0.0001\n",
      "Epoch 9, Step: 538, Loss: 0.046553973108530045, Lr:0.0001\n",
      "Epoch 9, Step: 539, Loss: 0.03198755905032158, Lr:0.0001\n",
      "Epoch 9, Step: 540, Loss: 0.08129432797431946, Lr:0.0001\n",
      "Epoch 9, Step: 541, Loss: 0.21221737563610077, Lr:0.0001\n",
      "Epoch 9, Step: 542, Loss: 0.17556090652942657, Lr:0.0001\n",
      "Epoch 9, Step: 543, Loss: 0.1528950035572052, Lr:0.0001\n",
      "Epoch 9, Step: 544, Loss: 0.16405145823955536, Lr:0.0001\n",
      "Epoch 9, Step: 545, Loss: 0.08665232360363007, Lr:0.0001\n",
      "Epoch 9, Step: 546, Loss: 0.3562006652355194, Lr:0.0001\n",
      "Epoch 9, Step: 547, Loss: 0.33899781107902527, Lr:0.0001\n",
      "Epoch 9, Step: 548, Loss: 0.19726169109344482, Lr:0.0001\n",
      "Epoch 9, Step: 549, Loss: 0.13578906655311584, Lr:0.0001\n",
      "Epoch 9, Step: 550, Loss: 0.07517851144075394, Lr:0.0001\n",
      "Epoch 9, Step: 551, Loss: 0.0506303608417511, Lr:0.0001\n",
      "Epoch 9, Step: 552, Loss: 0.32923293113708496, Lr:0.0001\n",
      "Epoch 9, Step: 553, Loss: 0.04360870271921158, Lr:0.0001\n",
      "Epoch 9, Step: 554, Loss: 0.31511005759239197, Lr:0.0001\n",
      "Epoch 9, Step: 555, Loss: 0.07509510964155197, Lr:0.0001\n",
      "Epoch 9, Step: 556, Loss: 0.04400215297937393, Lr:0.0001\n",
      "Epoch 9, Step: 557, Loss: 0.09486351907253265, Lr:0.0001\n",
      "Epoch 9, Step: 558, Loss: 0.11441811919212341, Lr:0.0001\n",
      "Epoch 9, Step: 559, Loss: 0.23094460368156433, Lr:0.0001\n",
      "Epoch 9, Step: 560, Loss: 0.046633005142211914, Lr:0.0001\n",
      "Epoch 9, Step: 561, Loss: 0.2516331076622009, Lr:0.0001\n",
      "Epoch 9, Step: 562, Loss: 0.1627209633588791, Lr:0.0001\n",
      "Epoch 9, Step: 563, Loss: 0.20336200296878815, Lr:0.0001\n",
      "Epoch 9, Step: 564, Loss: 0.026955358684062958, Lr:0.0001\n",
      "Epoch 9, Step: 565, Loss: 0.18419651687145233, Lr:0.0001\n",
      "Epoch 9, Step: 566, Loss: 0.01228415872901678, Lr:0.0001\n",
      "Epoch 9, Step: 567, Loss: 0.08886773884296417, Lr:0.0001\n",
      "Epoch 9, Step: 568, Loss: 0.1581050008535385, Lr:0.0001\n",
      "Epoch 9, Step: 569, Loss: 0.03093043714761734, Lr:0.0001\n",
      "Epoch 9, Step: 570, Loss: 0.06361208111047745, Lr:0.0001\n",
      "Epoch 9, Step: 571, Loss: 0.37353813648223877, Lr:0.0001\n",
      "Epoch 9, Step: 572, Loss: 0.09034919738769531, Lr:0.0001\n",
      "Epoch 9, Step: 573, Loss: 0.3510044813156128, Lr:0.0001\n",
      "Epoch 9, Step: 574, Loss: 0.0624392032623291, Lr:0.0001\n",
      "Epoch 9, Step: 575, Loss: 0.10844162851572037, Lr:0.0001\n",
      "Epoch 9, Step: 576, Loss: 0.8725161552429199, Lr:0.0001\n",
      "Epoch 9, Step: 577, Loss: 0.03225186467170715, Lr:0.0001\n",
      "Epoch 9, Step: 578, Loss: 0.13671287894248962, Lr:0.0001\n",
      "Epoch 9, Step: 579, Loss: 0.17334988713264465, Lr:0.0001\n",
      "Epoch 9, Step: 580, Loss: 0.1157541424036026, Lr:0.0001\n",
      "Epoch 9, Step: 581, Loss: 0.26560187339782715, Lr:0.0001\n",
      "Epoch 9, Step: 582, Loss: 0.08442994207143784, Lr:0.0001\n",
      "Epoch 9, Step: 583, Loss: 0.09833941608667374, Lr:0.0001\n",
      "Epoch 9, Step: 584, Loss: 0.10758169740438461, Lr:0.0001\n",
      "Epoch 9, Step: 585, Loss: 0.34853437542915344, Lr:0.0001\n",
      "Epoch 9, Step: 586, Loss: 0.07328974455595016, Lr:0.0001\n",
      "Epoch 9, Step: 587, Loss: 0.05654442310333252, Lr:0.0001\n",
      "Epoch 9, Step: 588, Loss: 0.17519508302211761, Lr:0.0001\n",
      "Epoch 9, Step: 589, Loss: 0.06749489903450012, Lr:0.0001\n",
      "Epoch 9, Step: 590, Loss: 0.31003448367118835, Lr:0.0001\n",
      "Epoch 9, Step: 591, Loss: 0.06040237098932266, Lr:0.0001\n",
      "Epoch 9, Step: 592, Loss: 0.22103644907474518, Lr:0.0001\n",
      "Epoch 9, Step: 593, Loss: 0.12140719592571259, Lr:0.0001\n",
      "Epoch 9, Step: 594, Loss: 0.12432911247015, Lr:0.0001\n",
      "Epoch 9, Step: 595, Loss: 0.30865034461021423, Lr:0.0001\n",
      "Epoch 9, Step: 596, Loss: 0.21323144435882568, Lr:0.0001\n",
      "Epoch 9, Step: 597, Loss: 0.023762399330735207, Lr:0.0001\n",
      "Epoch 9, Step: 598, Loss: 0.4153520166873932, Lr:0.0001\n",
      "Epoch 9, Step: 599, Loss: 0.22452053427696228, Lr:0.0001\n",
      "Epoch 9, Step: 600, Loss: 0.1603325456380844, Lr:0.0001\n",
      "Epoch 9, Step: 601, Loss: 0.3194321095943451, Lr:0.0001\n",
      "Epoch 9, Step: 602, Loss: 0.3149452209472656, Lr:0.0001\n",
      "Epoch 9, Step: 603, Loss: 0.25298893451690674, Lr:0.0001\n",
      "Epoch 9, Step: 604, Loss: 0.019806794822216034, Lr:0.0001\n",
      "Epoch 9, Step: 605, Loss: 0.14162665605545044, Lr:0.0001\n",
      "Epoch 9, Step: 606, Loss: 0.2522731423377991, Lr:0.0001\n",
      "Epoch 9, Step: 607, Loss: 0.03950674831867218, Lr:0.0001\n",
      "Epoch 9, Step: 608, Loss: 0.24807065725326538, Lr:0.0001\n",
      "Epoch 9, Step: 609, Loss: 0.11333364993333817, Lr:0.0001\n",
      "Epoch 9, Step: 610, Loss: 0.2646317481994629, Lr:0.0001\n",
      "Epoch 9, Step: 611, Loss: 0.05044486001133919, Lr:0.0001\n",
      "Epoch 9, Step: 612, Loss: 0.1348547786474228, Lr:0.0001\n",
      "Epoch 9, Step: 613, Loss: 0.14220339059829712, Lr:0.0001\n",
      "Epoch 9, Step: 614, Loss: 0.2551199197769165, Lr:0.0001\n",
      "Epoch 9, Step: 615, Loss: 0.06274014711380005, Lr:0.0001\n",
      "Epoch 9, Step: 616, Loss: 0.17669498920440674, Lr:0.0001\n",
      "Epoch 9, Step: 617, Loss: 0.3682301640510559, Lr:0.0001\n",
      "Epoch 9, Step: 618, Loss: 0.21733888983726501, Lr:0.0001\n",
      "Epoch 9, Step: 619, Loss: 0.41621801257133484, Lr:0.0001\n",
      "Epoch 9, Step: 620, Loss: 0.2598697543144226, Lr:0.0001\n",
      "Epoch 9, Step: 621, Loss: 0.20961782336235046, Lr:0.0001\n",
      "Epoch 9, Step: 622, Loss: 0.17798824608325958, Lr:0.0001\n",
      "Epoch 9, Step: 623, Loss: 0.4232403337955475, Lr:0.0001\n",
      "Epoch 9, Step: 624, Loss: 0.1530764400959015, Lr:0.0001\n",
      "Epoch 9, Step: 625, Loss: 0.2397957444190979, Lr:0.0001\n",
      "Epoch 9, Step: 626, Loss: 0.2718680799007416, Lr:0.0001\n",
      "Epoch 9, Step: 627, Loss: 0.17957016825675964, Lr:0.0001\n",
      "Epoch 9, Step: 628, Loss: 0.2666209936141968, Lr:0.0001\n",
      "Epoch 9, Step: 629, Loss: 0.07179903984069824, Lr:0.0001\n",
      "Epoch 9, Step: 630, Loss: 0.11941839009523392, Lr:0.0001\n",
      "Epoch 9, Step: 631, Loss: 0.09419766068458557, Lr:0.0001\n",
      "Epoch 9, Step: 632, Loss: 0.16581661999225616, Lr:0.0001\n",
      "Epoch 9, Step: 633, Loss: 0.1307496577501297, Lr:0.0001\n",
      "Epoch 9, Step: 634, Loss: 0.23936805129051208, Lr:0.0001\n",
      "Epoch 9, Step: 635, Loss: 0.06606393307447433, Lr:0.0001\n",
      "Epoch 9, Step: 636, Loss: 0.07722114026546478, Lr:0.0001\n",
      "Epoch 9, Step: 637, Loss: 0.21502353250980377, Lr:0.0001\n",
      "Epoch 9, Step: 638, Loss: 0.16015954315662384, Lr:0.0001\n",
      "Epoch 9, Step: 639, Loss: 0.22257328033447266, Lr:0.0001\n",
      "Epoch 9, Step: 640, Loss: 0.2803017497062683, Lr:0.0001\n",
      "Epoch 9, Step: 641, Loss: 0.13062146306037903, Lr:0.0001\n",
      "Epoch 9, Step: 642, Loss: 0.12743891775608063, Lr:0.0001\n",
      "Epoch 9, Step: 643, Loss: 0.09212838858366013, Lr:0.0001\n",
      "Epoch 9, Step: 644, Loss: 0.08895887434482574, Lr:0.0001\n",
      "Epoch 9, Step: 645, Loss: 0.19090862572193146, Lr:0.0001\n",
      "Epoch 9, Step: 646, Loss: 0.1179291158914566, Lr:0.0001\n",
      "Epoch 9, Step: 647, Loss: 0.2369890809059143, Lr:0.0001\n",
      "Epoch 9, Step: 648, Loss: 0.14716865122318268, Lr:0.0001\n",
      "Epoch 9, Step: 649, Loss: 0.0074663786217570305, Lr:0.0001\n",
      "Epoch 9, Step: 650, Loss: 0.3121117651462555, Lr:0.0001\n",
      "Epoch 9, Step: 651, Loss: 0.4792708456516266, Lr:0.0001\n",
      "Epoch 9, Step: 652, Loss: 0.10755179822444916, Lr:0.0001\n",
      "Epoch 9, Step: 653, Loss: 0.22658468782901764, Lr:0.0001\n",
      "Epoch 9, Step: 654, Loss: 0.15197357535362244, Lr:0.0001\n",
      "Epoch 9, Step: 655, Loss: 0.13647983968257904, Lr:0.0001\n",
      "Epoch 9, Step: 656, Loss: 0.10437887161970139, Lr:0.0001\n",
      "Epoch 9, Step: 657, Loss: 0.0221866425126791, Lr:0.0001\n",
      "Epoch 9, Step: 658, Loss: 0.039457086473703384, Lr:0.0001\n",
      "Epoch 9, Step: 659, Loss: 0.18735474348068237, Lr:0.0001\n",
      "Epoch 9, Step: 660, Loss: 0.1851349174976349, Lr:0.0001\n",
      "Epoch 9, Step: 661, Loss: 0.11139346659183502, Lr:0.0001\n",
      "Epoch 9, Step: 662, Loss: 0.1733301281929016, Lr:0.0001\n",
      "Epoch 9, Step: 663, Loss: 0.0450269877910614, Lr:0.0001\n",
      "Epoch 9, Step: 664, Loss: 0.14677821099758148, Lr:0.0001\n",
      "Epoch 9, Step: 665, Loss: 0.16680559515953064, Lr:0.0001\n",
      "Epoch 9, Step: 666, Loss: 0.035902541130781174, Lr:0.0001\n",
      "Epoch 9, Step: 667, Loss: 0.14691196382045746, Lr:0.0001\n",
      "Epoch 9, Step: 668, Loss: 0.2187720239162445, Lr:0.0001\n",
      "Epoch 9, Step: 669, Loss: 0.10188227891921997, Lr:0.0001\n",
      "Epoch 9, Step: 670, Loss: 0.020094556733965874, Lr:0.0001\n",
      "Epoch 9, Step: 671, Loss: 0.05471911281347275, Lr:0.0001\n",
      "Epoch 9, Step: 672, Loss: 0.03842584043741226, Lr:0.0001\n",
      "Epoch 9, Step: 673, Loss: 0.1087198480963707, Lr:0.0001\n",
      "Epoch 9, Step: 674, Loss: 0.48943471908569336, Lr:0.0001\n",
      "Epoch 9, Step: 675, Loss: 0.12130890041589737, Lr:0.0001\n",
      "Epoch 9, Step: 676, Loss: 0.2411259412765503, Lr:0.0001\n",
      "Epoch 9, Step: 677, Loss: 0.1581975519657135, Lr:0.0001\n",
      "Epoch 9, Step: 678, Loss: 0.2645496428012848, Lr:0.0001\n",
      "Epoch 9, Step: 679, Loss: 0.1242479532957077, Lr:0.0001\n",
      "Epoch 9, Step: 680, Loss: 0.07332450151443481, Lr:0.0001\n",
      "Epoch 9, Step: 681, Loss: 0.16746461391448975, Lr:0.0001\n",
      "Epoch 9, Step: 682, Loss: 0.10637451708316803, Lr:0.0001\n",
      "Epoch 9, Step: 683, Loss: 0.19907110929489136, Lr:0.0001\n",
      "Epoch 9, Step: 684, Loss: 0.03279977664351463, Lr:0.0001\n",
      "Epoch 9, Step: 685, Loss: 0.09746371954679489, Lr:0.0001\n",
      "Epoch 9, Step: 686, Loss: 0.1033262386918068, Lr:0.0001\n",
      "Epoch 9, Step: 687, Loss: 0.20762446522712708, Lr:0.0001\n",
      "Epoch 9, Step: 688, Loss: 0.37066787481307983, Lr:0.0001\n",
      "Epoch 9, Step: 689, Loss: 0.09042931348085403, Lr:0.0001\n",
      "Epoch 9, Step: 690, Loss: 0.020311998203396797, Lr:0.0001\n",
      "Epoch 9, Step: 691, Loss: 0.0826592743396759, Lr:0.0001\n",
      "Epoch 9, Step: 692, Loss: 0.05367681384086609, Lr:0.0001\n",
      "Epoch 9, Step: 693, Loss: 0.14605563879013062, Lr:0.0001\n",
      "Epoch 9, Step: 694, Loss: 0.0995485708117485, Lr:0.0001\n",
      "Epoch 9, Step: 695, Loss: 0.21552439033985138, Lr:0.0001\n",
      "Epoch 9, Step: 696, Loss: 0.09717749804258347, Lr:0.0001\n",
      "Epoch 9, Step: 697, Loss: 0.16944143176078796, Lr:0.0001\n",
      "Epoch 9, Step: 698, Loss: 0.29370376467704773, Lr:0.0001\n",
      "Epoch 9, Step: 699, Loss: 0.06914901733398438, Lr:0.0001\n",
      "Epoch 9, Step: 700, Loss: 0.16061529517173767, Lr:0.0001\n",
      "Epoch 9, Step: 701, Loss: 0.30243587493896484, Lr:0.0001\n",
      "Epoch 9, Step: 702, Loss: 0.20985306799411774, Lr:0.0001\n",
      "Epoch 9, Step: 703, Loss: 0.19969548285007477, Lr:0.0001\n",
      "Epoch 9, Step: 704, Loss: 0.13611997663974762, Lr:0.0001\n",
      "Epoch 9, Step: 705, Loss: 0.24028944969177246, Lr:0.0001\n",
      "Epoch 9, Step: 706, Loss: 0.060819294303655624, Lr:0.0001\n",
      "Epoch 9, Step: 707, Loss: 0.35556745529174805, Lr:0.0001\n",
      "Epoch 9, Step: 708, Loss: 0.3735964596271515, Lr:0.0001\n",
      "Epoch 9, Step: 709, Loss: 0.0844031348824501, Lr:0.0001\n",
      "Epoch 9, Step: 710, Loss: 0.10281254351139069, Lr:0.0001\n",
      "Epoch 9, Step: 711, Loss: 0.007269445341080427, Lr:0.0001\n",
      "Epoch 9, Step: 712, Loss: 0.048471782356500626, Lr:0.0001\n",
      "Epoch 9, Step: 713, Loss: 0.23883511126041412, Lr:0.0001\n",
      "Epoch 9, Step: 714, Loss: 0.09483548998832703, Lr:0.0001\n",
      "Epoch 9, Step: 715, Loss: 0.12270578742027283, Lr:0.0001\n",
      "Epoch 9, Step: 716, Loss: 0.10142836719751358, Lr:0.0001\n",
      "Epoch 9, Step: 717, Loss: 0.11144307255744934, Lr:0.0001\n",
      "Epoch 9, Step: 718, Loss: 0.12400563061237335, Lr:0.0001\n",
      "Epoch 9, Step: 719, Loss: 0.164853036403656, Lr:0.0001\n",
      "Epoch 9, Step: 720, Loss: 0.11439263075590134, Lr:0.0001\n",
      "Epoch 9, Step: 721, Loss: 0.21523186564445496, Lr:0.0001\n",
      "Epoch 9, Step: 722, Loss: 0.40298330783843994, Lr:0.0001\n",
      "Epoch 9, Step: 723, Loss: 0.12330146878957748, Lr:0.0001\n",
      "Epoch 9, Step: 724, Loss: 0.16385185718536377, Lr:0.0001\n",
      "Epoch 9, Step: 725, Loss: 0.22431817650794983, Lr:0.0001\n",
      "Epoch 9, Step: 726, Loss: 0.1435733139514923, Lr:0.0001\n",
      "Epoch 9, Step: 727, Loss: 0.19228583574295044, Lr:0.0001\n",
      "Epoch 9, Step: 728, Loss: 0.08067367970943451, Lr:0.0001\n",
      "Epoch 9, Step: 729, Loss: 0.1464693248271942, Lr:0.0001\n",
      "Epoch 9, Step: 730, Loss: 0.20247918367385864, Lr:0.0001\n",
      "Epoch 9, Step: 731, Loss: 0.04674867168068886, Lr:0.0001\n",
      "Epoch 9, Step: 732, Loss: 0.0860508531332016, Lr:0.0001\n",
      "Epoch 9, Step: 733, Loss: 0.015439667738974094, Lr:0.0001\n",
      "Epoch 9, Step: 734, Loss: 0.10784473270177841, Lr:0.0001\n",
      "Epoch 9, Step: 735, Loss: 0.059155505150556564, Lr:0.0001\n",
      "Epoch 9, Step: 736, Loss: 0.5401532649993896, Lr:0.0001\n",
      "Epoch 9, Step: 737, Loss: 0.08895280957221985, Lr:0.0001\n",
      "Epoch 9, Step: 738, Loss: 0.0708664208650589, Lr:0.0001\n",
      "Epoch 9, Step: 739, Loss: 0.12431042641401291, Lr:0.0001\n",
      "Epoch 9, Step: 740, Loss: 0.11015436053276062, Lr:0.0001\n",
      "Epoch 9, Step: 741, Loss: 0.13198012113571167, Lr:0.0001\n",
      "Epoch 9, Step: 742, Loss: 0.13999563455581665, Lr:0.0001\n",
      "Epoch 9, Step: 743, Loss: 0.029666829854249954, Lr:0.0001\n",
      "Epoch 9, Step: 744, Loss: 0.07939590513706207, Lr:0.0001\n",
      "Epoch 9, Step: 745, Loss: 0.12102466821670532, Lr:0.0001\n",
      "Epoch 9, Step: 746, Loss: 0.11432267725467682, Lr:0.0001\n",
      "Epoch 9, Step: 747, Loss: 0.03316384181380272, Lr:0.0001\n",
      "Epoch 9, Step: 748, Loss: 0.2800968587398529, Lr:0.0001\n",
      "Epoch 9, Step: 749, Loss: 0.3457567095756531, Lr:0.0001\n",
      "Epoch 9, Step: 750, Loss: 0.06587721407413483, Lr:0.0001\n",
      "Epoch 9, Step: 751, Loss: 0.26012590527534485, Lr:0.0001\n",
      "Epoch 9, Step: 752, Loss: 0.06425569951534271, Lr:0.0001\n",
      "Epoch 9, Step: 753, Loss: 0.14596673846244812, Lr:0.0001\n",
      "Epoch 9, Step: 754, Loss: 0.29301440715789795, Lr:0.0001\n",
      "Epoch 9, Step: 755, Loss: 0.04441031068563461, Lr:0.0001\n",
      "Epoch 9, Step: 756, Loss: 0.05824493616819382, Lr:0.0001\n",
      "Epoch 9, Step: 757, Loss: 0.15032325685024261, Lr:0.0001\n",
      "Epoch 9, Step: 758, Loss: 0.28746774792671204, Lr:0.0001\n",
      "Epoch 9, Step: 759, Loss: 0.12596750259399414, Lr:0.0001\n",
      "Epoch 9, Step: 760, Loss: 0.13713832199573517, Lr:0.0001\n",
      "Epoch 9, Step: 761, Loss: 0.30066338181495667, Lr:0.0001\n",
      "Epoch 9, Step: 762, Loss: 0.4315890967845917, Lr:0.0001\n",
      "Epoch 9, Step: 763, Loss: 0.2724067270755768, Lr:0.0001\n",
      "Epoch 9, Step: 764, Loss: 0.0958651453256607, Lr:0.0001\n",
      "Epoch 9, Step: 765, Loss: 0.16887031495571136, Lr:0.0001\n",
      "Epoch 9, Step: 766, Loss: 0.26349180936813354, Lr:0.0001\n",
      "Epoch 9, Step: 767, Loss: 0.10811746120452881, Lr:0.0001\n",
      "Epoch 9, Step: 768, Loss: 0.009949734434485435, Lr:0.0001\n",
      "Epoch 9, Step: 769, Loss: 0.24465788900852203, Lr:0.0001\n",
      "Epoch 9, Step: 770, Loss: 0.6586241722106934, Lr:0.0001\n",
      "Epoch 9, Step: 771, Loss: 0.243830144405365, Lr:0.0001\n",
      "Epoch 9, Step: 772, Loss: 0.060171205550432205, Lr:0.0001\n",
      "Epoch 9, Step: 773, Loss: 0.18779264390468597, Lr:0.0001\n",
      "Epoch 9, Step: 774, Loss: 0.07803758233785629, Lr:0.0001\n",
      "Epoch 9, Step: 775, Loss: 0.3873469829559326, Lr:0.0001\n",
      "Epoch 9, Step: 776, Loss: 0.025386648252606392, Lr:0.0001\n",
      "Epoch 9, Step: 777, Loss: 0.15797904133796692, Lr:0.0001\n",
      "Epoch 9, Step: 778, Loss: 0.20019760727882385, Lr:0.0001\n",
      "Epoch 9, Step: 779, Loss: 0.17495015263557434, Lr:0.0001\n",
      "Epoch 9, Step: 780, Loss: 0.20322631299495697, Lr:0.0001\n",
      "Epoch 9, Step: 781, Loss: 0.04549960047006607, Lr:0.0001\n",
      "Epoch 9, Step: 782, Loss: 0.14027740061283112, Lr:0.0001\n",
      "Epoch 9, Step: 783, Loss: 0.06885149329900742, Lr:0.0001\n",
      "Epoch 9, Step: 784, Loss: 0.38728535175323486, Lr:0.0001\n",
      "Epoch 9, Step: 785, Loss: 0.055590201169252396, Lr:0.0001\n",
      "Epoch 9, Step: 786, Loss: 0.2684202790260315, Lr:0.0001\n",
      "Epoch 9, Step: 787, Loss: 0.20151975750923157, Lr:0.0001\n",
      "Epoch 9, Step: 788, Loss: 0.19981953501701355, Lr:0.0001\n",
      "Epoch 9, Step: 789, Loss: 0.08200700581073761, Lr:0.0001\n",
      "Epoch 9, Step: 790, Loss: 0.14260946214199066, Lr:0.0001\n",
      "Epoch 9, Step: 791, Loss: 0.06319781392812729, Lr:0.0001\n",
      "Epoch 9, Step: 792, Loss: 0.01650017872452736, Lr:0.0001\n",
      "Epoch 9, Step: 793, Loss: 0.19308409094810486, Lr:0.0001\n",
      "Epoch 9, Step: 794, Loss: 0.10317479074001312, Lr:0.0001\n",
      "Epoch 9, Step: 795, Loss: 0.08336697518825531, Lr:0.0001\n",
      "Epoch 9, Step: 796, Loss: 0.08400435000658035, Lr:0.0001\n",
      "Epoch 9, Step: 797, Loss: 0.08296538144350052, Lr:0.0001\n",
      "Epoch 9, Step: 798, Loss: 0.4400583803653717, Lr:0.0001\n",
      "Epoch 9, Step: 799, Loss: 0.16859106719493866, Lr:0.0001\n",
      "Epoch 9, Step: 800, Loss: 0.1354724019765854, Lr:0.0001\n",
      "Epoch 9, Step: 801, Loss: 0.02793923020362854, Lr:0.0001\n",
      "Epoch 9, Step: 802, Loss: 0.07406166940927505, Lr:0.0001\n",
      "Epoch 9, Step: 803, Loss: 0.1782042384147644, Lr:0.0001\n",
      "Epoch 9, Step: 804, Loss: 0.12316726893186569, Lr:0.0001\n",
      "Epoch 9, Step: 805, Loss: 0.14981317520141602, Lr:0.0001\n",
      "Epoch 9, Step: 806, Loss: 0.09211824089288712, Lr:0.0001\n",
      "Epoch 9, Step: 807, Loss: 0.2201160192489624, Lr:0.0001\n",
      "Epoch 9, Step: 808, Loss: 0.16706012189388275, Lr:0.0001\n",
      "Epoch 9, Step: 809, Loss: 0.1576317399740219, Lr:0.0001\n",
      "Epoch 9, Step: 810, Loss: 0.032975245267152786, Lr:0.0001\n",
      "Epoch 9, Step: 811, Loss: 0.5799611806869507, Lr:0.0001\n",
      "Epoch 9, Step: 812, Loss: 0.20609647035598755, Lr:0.0001\n",
      "Epoch 9, Step: 813, Loss: 0.08599863201379776, Lr:0.0001\n",
      "Epoch 9, Step: 814, Loss: 0.07505115866661072, Lr:0.0001\n",
      "Epoch 9, Step: 815, Loss: 0.04631970450282097, Lr:0.0001\n",
      "Epoch 9, Step: 816, Loss: 0.12261533737182617, Lr:0.0001\n",
      "Epoch 9, Step: 817, Loss: 0.03913582116365433, Lr:0.0001\n",
      "Epoch 9, Step: 818, Loss: 0.1541011780500412, Lr:0.0001\n",
      "Epoch 9, Step: 819, Loss: 0.04949969798326492, Lr:0.0001\n",
      "Epoch 9, Step: 820, Loss: 0.025571314617991447, Lr:0.0001\n",
      "Epoch 9, Step: 821, Loss: 0.059264518320560455, Lr:0.0001\n",
      "Epoch 9, Step: 822, Loss: 0.04602084308862686, Lr:0.0001\n",
      "Epoch 9, Step: 823, Loss: 0.024913592264056206, Lr:0.0001\n",
      "Epoch 9, Step: 824, Loss: 0.4195397198200226, Lr:0.0001\n",
      "Epoch 9, Step: 825, Loss: 0.356330007314682, Lr:0.0001\n",
      "Epoch 9, Step: 826, Loss: 0.2600097358226776, Lr:0.0001\n",
      "Epoch 9, Step: 827, Loss: 0.09500148892402649, Lr:0.0001\n",
      "Epoch 9, Step: 828, Loss: 0.31923115253448486, Lr:0.0001\n",
      "Epoch 9, Step: 829, Loss: 0.14009375870227814, Lr:0.0001\n",
      "Epoch 9, Step: 830, Loss: 0.0933610051870346, Lr:0.0001\n",
      "Epoch 9, Step: 831, Loss: 0.06706131994724274, Lr:0.0001\n",
      "Epoch 9, Step: 832, Loss: 0.03287162259221077, Lr:0.0001\n",
      "Epoch 9, Step: 833, Loss: 0.1479496955871582, Lr:0.0001\n",
      "Epoch 9, Step: 834, Loss: 0.20980679988861084, Lr:0.0001\n",
      "Epoch 9, Step: 835, Loss: 0.21359281241893768, Lr:0.0001\n",
      "Epoch 9, Step: 836, Loss: 0.12808716297149658, Lr:0.0001\n",
      "Epoch 9, Step: 837, Loss: 0.07183178514242172, Lr:0.0001\n",
      "Epoch 9, Step: 838, Loss: 0.1333521604537964, Lr:0.0001\n",
      "Epoch 9, Step: 839, Loss: 0.08263419568538666, Lr:0.0001\n",
      "Epoch 9, Step: 840, Loss: 0.5444957613945007, Lr:0.0001\n",
      "Epoch 9, Step: 841, Loss: 0.08945832401514053, Lr:0.0001\n",
      "Epoch 9, Step: 842, Loss: 0.39313453435897827, Lr:0.0001\n",
      "Epoch 9, Step: 843, Loss: 0.11118535697460175, Lr:0.0001\n",
      "Epoch 9, Step: 844, Loss: 0.1256871372461319, Lr:0.0001\n",
      "Epoch 9, Step: 845, Loss: 0.2579330801963806, Lr:0.0001\n",
      "Epoch 9, Step: 846, Loss: 0.3103746473789215, Lr:0.0001\n",
      "Epoch 9, Step: 847, Loss: 0.06190775707364082, Lr:0.0001\n",
      "Epoch 9, Step: 848, Loss: 0.24170972406864166, Lr:0.0001\n",
      "Epoch 9, Step: 849, Loss: 0.20353488624095917, Lr:0.0001\n",
      "Epoch 9, Step: 850, Loss: 0.11837932467460632, Lr:0.0001\n",
      "Epoch 9, Step: 851, Loss: 0.15597563982009888, Lr:0.0001\n",
      "Epoch 9, Step: 852, Loss: 0.23599593341350555, Lr:0.0001\n",
      "Epoch 9, Step: 853, Loss: 0.20109032094478607, Lr:0.0001\n",
      "Epoch 9, Step: 854, Loss: 0.025905832648277283, Lr:0.0001\n",
      "Epoch 9, Step: 855, Loss: 0.2284778505563736, Lr:0.0001\n",
      "Epoch 9, Step: 856, Loss: 0.3559243083000183, Lr:0.0001\n",
      "Epoch 9, Step: 857, Loss: 0.5381631851196289, Lr:0.0001\n",
      "Epoch 9, Step: 858, Loss: 0.14079806208610535, Lr:0.0001\n",
      "Epoch 9, Step: 859, Loss: 0.31350386142730713, Lr:0.0001\n",
      "Epoch 9, Step: 860, Loss: 0.17376677691936493, Lr:0.0001\n",
      "Epoch 9, Step: 861, Loss: 0.15626926720142365, Lr:0.0001\n",
      "Epoch 9, Step: 862, Loss: 0.06752616912126541, Lr:0.0001\n",
      "Epoch 9, Step: 863, Loss: 0.10112819075584412, Lr:0.0001\n",
      "Epoch 9, Step: 864, Loss: 0.17060692608356476, Lr:0.0001\n",
      "Epoch 9, Step: 865, Loss: 0.06379425525665283, Lr:0.0001\n",
      "Epoch 9, Step: 866, Loss: 0.07428054511547089, Lr:0.0001\n",
      "Epoch 9, Step: 867, Loss: 0.3571285605430603, Lr:0.0001\n",
      "Epoch 9, Step: 868, Loss: 0.19376270473003387, Lr:0.0001\n",
      "Epoch 9, Step: 869, Loss: 0.07828780263662338, Lr:0.0001\n",
      "Epoch 9, Step: 870, Loss: 0.27994200587272644, Lr:0.0001\n",
      "Epoch 9, Step: 871, Loss: 0.10120119899511337, Lr:0.0001\n",
      "Epoch 9, Step: 872, Loss: 0.0968751534819603, Lr:0.0001\n",
      "Epoch 9, Step: 873, Loss: 0.2575867176055908, Lr:0.0001\n",
      "Epoch 9, Step: 874, Loss: 0.1856643110513687, Lr:0.0001\n",
      "Epoch 9, Step: 875, Loss: 0.22792649269104004, Lr:0.0001\n",
      "Epoch 9, Step: 876, Loss: 0.023496253415942192, Lr:0.0001\n",
      "Epoch 9, Step: 877, Loss: 0.3568357527256012, Lr:0.0001\n",
      "Epoch 9, Step: 878, Loss: 0.23169609904289246, Lr:0.0001\n",
      "Epoch 9, Step: 879, Loss: 0.19634997844696045, Lr:0.0001\n",
      "Epoch 9, Step: 880, Loss: 0.08811867982149124, Lr:0.0001\n",
      "Epoch 9, Step: 881, Loss: 0.15265266597270966, Lr:0.0001\n",
      "Epoch 9, Step: 882, Loss: 0.1144350990653038, Lr:0.0001\n",
      "Epoch 9, Step: 883, Loss: 0.15017038583755493, Lr:0.0001\n",
      "Epoch 9, Step: 884, Loss: 0.2930307388305664, Lr:0.0001\n",
      "Epoch 9, Step: 885, Loss: 0.1591440886259079, Lr:0.0001\n",
      "Epoch 9, Step: 886, Loss: 0.2264307141304016, Lr:0.0001\n",
      "Epoch 9, Step: 887, Loss: 0.04950552061200142, Lr:0.0001\n",
      "Epoch 9, Step: 888, Loss: 0.16518282890319824, Lr:0.0001\n",
      "Epoch 9, Step: 889, Loss: 0.17967680096626282, Lr:0.0001\n",
      "Epoch 9, Step: 890, Loss: 0.15934200584888458, Lr:0.0001\n",
      "Epoch 9, Step: 891, Loss: 0.15654605627059937, Lr:0.0001\n",
      "Epoch 9, Step: 892, Loss: 0.43324118852615356, Lr:0.0001\n",
      "Epoch 9, Step: 893, Loss: 0.292609304189682, Lr:0.0001\n",
      "Epoch 9, Step: 894, Loss: 0.3799695074558258, Lr:0.0001\n",
      "Epoch 9, Step: 895, Loss: 0.1430218517780304, Lr:0.0001\n",
      "Epoch 9, Step: 896, Loss: 0.20891864597797394, Lr:0.0001\n",
      "Epoch 9, Step: 897, Loss: 0.08737341314554214, Lr:0.0001\n",
      "Epoch 9, Step: 898, Loss: 0.08986832946538925, Lr:0.0001\n",
      "Epoch 9, Step: 899, Loss: 0.16867578029632568, Lr:0.0001\n",
      "Epoch 9, Step: 900, Loss: 0.10582216829061508, Lr:0.0001\n",
      "Epoch 9, Step: 901, Loss: 0.11766558885574341, Lr:0.0001\n",
      "Epoch 9, Step: 902, Loss: 0.04837455227971077, Lr:0.0001\n",
      "Epoch 9, Step: 903, Loss: 0.0975441187620163, Lr:0.0001\n",
      "Epoch 9, Step: 904, Loss: 0.2796141505241394, Lr:0.0001\n",
      "Epoch 9, Step: 905, Loss: 0.26350894570350647, Lr:0.0001\n",
      "Epoch 9, Step: 906, Loss: 0.14132018387317657, Lr:0.0001\n",
      "Epoch 9, Step: 907, Loss: 0.11332184076309204, Lr:0.0001\n",
      "Epoch 9, Step: 908, Loss: 0.2195454239845276, Lr:0.0001\n",
      "Epoch 9, Step: 909, Loss: 0.23243747651576996, Lr:0.0001\n",
      "Epoch 9, Step: 910, Loss: 0.030756762251257896, Lr:0.0001\n",
      "Epoch 9, Step: 911, Loss: 0.18464826047420502, Lr:0.0001\n",
      "Epoch 9, Step: 912, Loss: 0.1474829614162445, Lr:0.0001\n",
      "Epoch 9, Step: 913, Loss: 0.04511771723628044, Lr:0.0001\n",
      "Epoch 9, Step: 914, Loss: 0.1719180792570114, Lr:0.0001\n",
      "Epoch 9, Step: 915, Loss: 0.03350566700100899, Lr:0.0001\n",
      "Epoch 9, Step: 916, Loss: 0.1450747400522232, Lr:0.0001\n",
      "Epoch 9, Step: 917, Loss: 0.108759805560112, Lr:0.0001\n",
      "Epoch 9, Step: 918, Loss: 0.17786242067813873, Lr:0.0001\n",
      "Epoch 9, Step: 919, Loss: 0.2646722197532654, Lr:0.0001\n",
      "Epoch 9, Step: 920, Loss: 0.043937794864177704, Lr:0.0001\n",
      "Epoch 9, Step: 921, Loss: 0.15766046941280365, Lr:0.0001\n",
      "Epoch 9, Step: 922, Loss: 0.16823014616966248, Lr:0.0001\n",
      "Epoch 9, Step: 923, Loss: 0.1868426650762558, Lr:0.0001\n",
      "Epoch 9, Step: 924, Loss: 0.047545645385980606, Lr:0.0001\n",
      "Epoch 9, Step: 925, Loss: 0.010233787819743156, Lr:0.0001\n",
      "Epoch 9, Step: 926, Loss: 0.2824554145336151, Lr:0.0001\n",
      "Epoch 9, Step: 927, Loss: 0.07559361308813095, Lr:0.0001\n",
      "Epoch 9, Step: 928, Loss: 0.4517858028411865, Lr:0.0001\n",
      "Epoch 9, Step: 929, Loss: 0.12040186673402786, Lr:0.0001\n",
      "Epoch 9, Step: 930, Loss: 0.12638400495052338, Lr:0.0001\n",
      "Epoch 9, Step: 931, Loss: 0.04615627974271774, Lr:0.0001\n",
      "Epoch 9, Step: 932, Loss: 0.1822643280029297, Lr:0.0001\n",
      "Epoch 9, Step: 933, Loss: 0.1483636051416397, Lr:0.0001\n",
      "Epoch 9, Step: 934, Loss: 0.2260817289352417, Lr:0.0001\n",
      "Epoch 9, Step: 935, Loss: 0.21969279646873474, Lr:0.0001\n",
      "Epoch 9, Step: 936, Loss: 0.2610411047935486, Lr:0.0001\n",
      "Epoch 9, Step: 937, Loss: 0.28697699308395386, Lr:0.0001\n",
      "Epoch 9, Step: 938, Loss: 0.10047689825296402, Lr:0.0001\n",
      "Epoch 9, Step: 939, Loss: 0.12139999866485596, Lr:0.0001\n",
      "Epoch 9, Step: 940, Loss: 0.10189512372016907, Lr:0.0001\n",
      "Epoch 9, Step: 941, Loss: 0.10172045975923538, Lr:0.0001\n",
      "Epoch 9, Step: 942, Loss: 0.024304447695612907, Lr:0.0001\n",
      "Epoch 9, Step: 943, Loss: 0.16642999649047852, Lr:0.0001\n",
      "Epoch 9, Step: 944, Loss: 0.13029518723487854, Lr:0.0001\n",
      "Epoch 9, Step: 945, Loss: 0.1656302511692047, Lr:0.0001\n",
      "Epoch 9, Step: 946, Loss: 0.022631924599409103, Lr:0.0001\n",
      "Epoch 9, Step: 947, Loss: 0.3950260877609253, Lr:0.0001\n",
      "Epoch 9, Step: 948, Loss: 0.21760624647140503, Lr:0.0001\n",
      "Epoch 9, Step: 949, Loss: 0.19991126656532288, Lr:0.0001\n",
      "Epoch 9, Step: 950, Loss: 0.12155836075544357, Lr:0.0001\n",
      "Epoch 9, Step: 951, Loss: 0.022742779925465584, Lr:0.0001\n",
      "Epoch 9, Step: 952, Loss: 0.0940018743276596, Lr:0.0001\n",
      "Epoch 9, Step: 953, Loss: 0.1352585256099701, Lr:0.0001\n",
      "Epoch 9, Step: 954, Loss: 0.11316601186990738, Lr:0.0001\n",
      "Epoch 9, Step: 955, Loss: 0.05605125427246094, Lr:0.0001\n",
      "Epoch 9, Step: 956, Loss: 0.03406026214361191, Lr:0.0001\n",
      "Epoch 9, Step: 957, Loss: 0.14504337310791016, Lr:0.0001\n",
      "Epoch 9, Step: 958, Loss: 0.019014736637473106, Lr:0.0001\n",
      "Epoch 9, Step: 959, Loss: 0.509207010269165, Lr:0.0001\n",
      "Epoch 9, Step: 960, Loss: 0.2034343034029007, Lr:0.0001\n",
      "Epoch 9, Step: 961, Loss: 0.15251488983631134, Lr:0.0001\n",
      "Epoch 9, Step: 962, Loss: 0.04833047091960907, Lr:0.0001\n",
      "Epoch 9, Step: 963, Loss: 0.0548262745141983, Lr:0.0001\n",
      "Epoch 9, Step: 964, Loss: 0.06866007298231125, Lr:0.0001\n",
      "Epoch 9, Step: 965, Loss: 0.22644221782684326, Lr:0.0001\n",
      "Epoch 9, Step: 966, Loss: 0.06861699372529984, Lr:0.0001\n",
      "Epoch 9, Step: 967, Loss: 0.07751811295747757, Lr:0.0001\n",
      "Epoch 9, Step: 968, Loss: 0.20846976339817047, Lr:0.0001\n",
      "Epoch 9, Step: 969, Loss: 0.19199839234352112, Lr:0.0001\n",
      "Epoch 9, Step: 970, Loss: 0.16512610018253326, Lr:0.0001\n",
      "Epoch 9, Step: 971, Loss: 0.08292145282030106, Lr:0.0001\n",
      "Epoch 9, Step: 972, Loss: 0.13738688826560974, Lr:0.0001\n",
      "Epoch 9, Step: 973, Loss: 0.06316127628087997, Lr:0.0001\n",
      "Epoch 9, Step: 974, Loss: 0.01584109105169773, Lr:0.0001\n",
      "Epoch 9, Step: 975, Loss: 0.32204827666282654, Lr:0.0001\n",
      "Epoch 9, Step: 976, Loss: 0.23625440895557404, Lr:0.0001\n",
      "Epoch 9, Step: 977, Loss: 0.13897749781608582, Lr:0.0001\n",
      "Epoch 9, Step: 978, Loss: 0.03950185328722, Lr:0.0001\n",
      "Epoch 9, Step: 979, Loss: 0.1971684694290161, Lr:0.0001\n",
      "Epoch 9, Step: 980, Loss: 0.10368101298809052, Lr:0.0001\n",
      "Epoch 9, Step: 981, Loss: 0.18461601436138153, Lr:0.0001\n",
      "Epoch 9, Step: 982, Loss: 0.11345648765563965, Lr:0.0001\n",
      "Epoch 9, Step: 983, Loss: 0.093229278922081, Lr:0.0001\n",
      "Epoch 9, Step: 984, Loss: 0.4204963147640228, Lr:0.0001\n",
      "Epoch 9, Step: 985, Loss: 0.5399662852287292, Lr:0.0001\n",
      "Epoch 9, Step: 986, Loss: 0.3399602770805359, Lr:0.0001\n",
      "Epoch 9, Step: 987, Loss: 0.03954939916729927, Lr:0.0001\n",
      "Epoch 9, Step: 988, Loss: 0.21436341106891632, Lr:0.0001\n",
      "Epoch 9, Step: 989, Loss: 0.3153858780860901, Lr:0.0001\n",
      "Epoch 9, Step: 990, Loss: 0.18014571070671082, Lr:0.0001\n",
      "Epoch 9, Step: 991, Loss: 0.20765778422355652, Lr:0.0001\n",
      "Epoch 9, Step: 992, Loss: 0.10197507590055466, Lr:0.0001\n",
      "Epoch 9, Step: 993, Loss: 0.34111663699150085, Lr:0.0001\n",
      "Epoch 9, Step: 994, Loss: 0.06648454070091248, Lr:0.0001\n",
      "Epoch 9, Step: 995, Loss: 0.3082430362701416, Lr:0.0001\n",
      "Epoch 9, Step: 996, Loss: 0.20286843180656433, Lr:0.0001\n",
      "Epoch 9, Step: 997, Loss: 0.5288997888565063, Lr:0.0001\n",
      "Epoch 9, Step: 998, Loss: 0.09373641014099121, Lr:0.0001\n",
      "Epoch 9, Step: 999, Loss: 0.10464239865541458, Lr:0.0001\n",
      "Epoch 9, Step: 1000, Loss: 0.10398583859205246, Lr:0.0001\n",
      "Epoch 9, Step: 1001, Loss: 0.15637673437595367, Lr:0.0001\n",
      "Epoch 9, Step: 1002, Loss: 0.08107631653547287, Lr:0.0001\n",
      "Epoch 9, Step: 1003, Loss: 0.2947651147842407, Lr:0.0001\n",
      "Epoch 9, Step: 1004, Loss: 0.08641165494918823, Lr:0.0001\n",
      "Epoch 9, Step: 1005, Loss: 0.1689867228269577, Lr:0.0001\n",
      "Epoch 9, Step: 1006, Loss: 0.05272994190454483, Lr:0.0001\n",
      "Epoch 9, Step: 1007, Loss: 0.1733895093202591, Lr:0.0001\n",
      "Epoch 9, Step: 1008, Loss: 0.05982542783021927, Lr:0.0001\n",
      "Epoch 9, Step: 1009, Loss: 0.2837153375148773, Lr:0.0001\n",
      "Epoch 9, Step: 1010, Loss: 0.11278355121612549, Lr:0.0001\n",
      "Epoch 9, Step: 1011, Loss: 0.22543206810951233, Lr:0.0001\n",
      "Epoch 9, Step: 1012, Loss: 0.1446092426776886, Lr:0.0001\n",
      "Epoch 9, Step: 1013, Loss: 0.4790966510772705, Lr:0.0001\n",
      "Epoch 9, Step: 1014, Loss: 0.320437490940094, Lr:0.0001\n",
      "Epoch 9, Step: 1015, Loss: 0.3353002965450287, Lr:0.0001\n",
      "Epoch 9, Step: 1016, Loss: 0.03261062130331993, Lr:0.0001\n",
      "Epoch 9, Step: 1017, Loss: 0.08909905701875687, Lr:0.0001\n",
      "Epoch 9, Step: 1018, Loss: 0.12929494678974152, Lr:0.0001\n",
      "Epoch 9, Step: 1019, Loss: 0.18863725662231445, Lr:0.0001\n",
      "Epoch 9, Step: 1020, Loss: 0.10149277001619339, Lr:0.0001\n",
      "Epoch 9, Step: 1021, Loss: 0.06612186878919601, Lr:0.0001\n",
      "Epoch 9, Step: 1022, Loss: 0.16913414001464844, Lr:0.0001\n",
      "Epoch 9, Step: 1023, Loss: 0.12366079539060593, Lr:0.0001\n",
      "Epoch 9, Step: 1024, Loss: 0.5621439218521118, Lr:0.0001\n",
      "Epoch 9, Step: 1025, Loss: 0.0449443981051445, Lr:0.0001\n",
      "Epoch 9, Step: 1026, Loss: 0.019494760781526566, Lr:0.0001\n",
      "Epoch 9, Step: 1027, Loss: 0.1124492883682251, Lr:0.0001\n",
      "Epoch 9, Step: 1028, Loss: 0.0541849359869957, Lr:0.0001\n",
      "Epoch 9, Step: 1029, Loss: 0.26264840364456177, Lr:0.0001\n",
      "Epoch 9, Step: 1030, Loss: 0.11903832107782364, Lr:0.0001\n",
      "Epoch 9, Step: 1031, Loss: 0.06868372112512589, Lr:0.0001\n",
      "Epoch 9, Step: 1032, Loss: 0.17076635360717773, Lr:0.0001\n",
      "Epoch 9, Step: 1033, Loss: 0.18851794302463531, Lr:0.0001\n",
      "Epoch 9, Step: 1034, Loss: 0.46619677543640137, Lr:0.0001\n",
      "Epoch 9, Step: 1035, Loss: 0.0899096205830574, Lr:0.0001\n",
      "Epoch 9, Step: 1036, Loss: 0.04192200303077698, Lr:0.0001\n",
      "Epoch 9, Step: 1037, Loss: 0.20179904997348785, Lr:0.0001\n",
      "Epoch 9, Step: 1038, Loss: 0.21437877416610718, Lr:0.0001\n",
      "Epoch 9, Step: 1039, Loss: 0.03249045088887215, Lr:0.0001\n",
      "Epoch 9, Step: 1040, Loss: 0.060363881289958954, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 9\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:16 loss: 1.1555 (1.1555) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.2965 data: 0.1289 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.3860 (0.4863) acc1: 81.2500 (81.8182) acc5: 100.0000 (100.0000) time: 0.2933 data: 0.1136 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.3372 (0.5208) acc1: 87.5000 (82.4405) acc5: 100.0000 (100.0000) time: 0.2955 data: 0.1110 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.3930 (0.5445) acc1: 81.2500 (81.2500) acc5: 100.0000 (100.0000) time: 0.2931 data: 0.1112 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.2904 (0.4572) acc1: 81.2500 (83.6890) acc5: 100.0000 (100.0000) time: 0.2936 data: 0.1152 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0247 (0.3728) acc1: 100.0000 (86.8873) acc5: 100.0000 (100.0000) time: 0.2959 data: 0.1165 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0195 (0.3465) acc1: 100.0000 (87.8547) acc5: 100.0000 (100.0000) time: 0.2849 data: 0.1110 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.2909 s / it)\n",
      "* Acc@1 87.855 Acc@5 100.000 loss 0.346\n",
      "Accuracy of the network on the 881 test image: 87.9%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 10, Step: 0, Loss: 0.12542471289634705, Lr:0.0001\n",
      "Epoch 10, Step: 1, Loss: 0.15577496588230133, Lr:0.0001\n",
      "Epoch 10, Step: 2, Loss: 0.3184327483177185, Lr:0.0001\n",
      "Epoch 10, Step: 3, Loss: 0.17763245105743408, Lr:0.0001\n",
      "Epoch 10, Step: 4, Loss: 0.40514102578163147, Lr:0.0001\n",
      "Epoch 10, Step: 5, Loss: 0.2028394192457199, Lr:0.0001\n",
      "Epoch 10, Step: 6, Loss: 0.19010771811008453, Lr:0.0001\n",
      "Epoch 10, Step: 7, Loss: 0.04566702991724014, Lr:0.0001\n",
      "Epoch 10, Step: 8, Loss: 0.07354046404361725, Lr:0.0001\n",
      "Epoch 10, Step: 9, Loss: 0.07772546261548996, Lr:0.0001\n",
      "Epoch 10, Step: 10, Loss: 0.13563776016235352, Lr:0.0001\n",
      "Epoch 10, Step: 11, Loss: 0.11440741270780563, Lr:0.0001\n",
      "Epoch 10, Step: 12, Loss: 0.1264747679233551, Lr:0.0001\n",
      "Epoch 10, Step: 13, Loss: 0.1009606346487999, Lr:0.0001\n",
      "Epoch 10, Step: 14, Loss: 0.1047956719994545, Lr:0.0001\n",
      "Epoch 10, Step: 15, Loss: 0.13866698741912842, Lr:0.0001\n",
      "Epoch 10, Step: 16, Loss: 0.1130228340625763, Lr:0.0001\n",
      "Epoch 10, Step: 17, Loss: 0.1180935874581337, Lr:0.0001\n",
      "Epoch 10, Step: 18, Loss: 0.03315084055066109, Lr:0.0001\n",
      "Epoch 10, Step: 19, Loss: 0.06691853702068329, Lr:0.0001\n",
      "Epoch 10, Step: 20, Loss: 0.04469040781259537, Lr:0.0001\n",
      "Epoch 10, Step: 21, Loss: 0.29494497179985046, Lr:0.0001\n",
      "Epoch 10, Step: 22, Loss: 0.11988598853349686, Lr:0.0001\n",
      "Epoch 10, Step: 23, Loss: 0.08900708705186844, Lr:0.0001\n",
      "Epoch 10, Step: 24, Loss: 0.3424122631549835, Lr:0.0001\n",
      "Epoch 10, Step: 25, Loss: 0.05875980854034424, Lr:0.0001\n",
      "Epoch 10, Step: 26, Loss: 0.26898622512817383, Lr:0.0001\n",
      "Epoch 10, Step: 27, Loss: 0.09109138697385788, Lr:0.0001\n",
      "Epoch 10, Step: 28, Loss: 0.01401771605014801, Lr:0.0001\n",
      "Epoch 10, Step: 29, Loss: 0.16608791053295135, Lr:0.0001\n",
      "Epoch 10, Step: 30, Loss: 0.22182780504226685, Lr:0.0001\n",
      "Epoch 10, Step: 31, Loss: 0.44301465153694153, Lr:0.0001\n",
      "Epoch 10, Step: 32, Loss: 0.2816700041294098, Lr:0.0001\n",
      "Epoch 10, Step: 33, Loss: 0.07262002676725388, Lr:0.0001\n",
      "Epoch 10, Step: 34, Loss: 0.023684607818722725, Lr:0.0001\n",
      "Epoch 10, Step: 35, Loss: 0.16464540362358093, Lr:0.0001\n",
      "Epoch 10, Step: 36, Loss: 0.04211465269327164, Lr:0.0001\n",
      "Epoch 10, Step: 37, Loss: 0.1214984878897667, Lr:0.0001\n",
      "Epoch 10, Step: 38, Loss: 0.16706588864326477, Lr:0.0001\n",
      "Epoch 10, Step: 39, Loss: 0.07349381595849991, Lr:0.0001\n",
      "Epoch 10, Step: 40, Loss: 0.09160295128822327, Lr:0.0001\n",
      "Epoch 10, Step: 41, Loss: 0.1979893296957016, Lr:0.0001\n",
      "Epoch 10, Step: 42, Loss: 0.42453664541244507, Lr:0.0001\n",
      "Epoch 10, Step: 43, Loss: 0.10031704604625702, Lr:0.0001\n",
      "Epoch 10, Step: 44, Loss: 0.17793849110603333, Lr:0.0001\n",
      "Epoch 10, Step: 45, Loss: 0.09924660623073578, Lr:0.0001\n",
      "Epoch 10, Step: 46, Loss: 0.020052321255207062, Lr:0.0001\n",
      "Epoch 10, Step: 47, Loss: 0.3825819492340088, Lr:0.0001\n",
      "Epoch 10, Step: 48, Loss: 0.04855604097247124, Lr:0.0001\n",
      "Epoch 10, Step: 49, Loss: 0.10780464112758636, Lr:0.0001\n",
      "Epoch 10, Step: 50, Loss: 0.10007229447364807, Lr:0.0001\n",
      "Epoch 10, Step: 51, Loss: 0.1142120435833931, Lr:0.0001\n",
      "Epoch 10, Step: 52, Loss: 0.07725225389003754, Lr:0.0001\n",
      "Epoch 10, Step: 53, Loss: 0.061555299907922745, Lr:0.0001\n",
      "Epoch 10, Step: 54, Loss: 0.1518111377954483, Lr:0.0001\n",
      "Epoch 10, Step: 55, Loss: 0.3584824204444885, Lr:0.0001\n",
      "Epoch 10, Step: 56, Loss: 0.16934186220169067, Lr:0.0001\n",
      "Epoch 10, Step: 57, Loss: 0.14275513589382172, Lr:0.0001\n",
      "Epoch 10, Step: 58, Loss: 0.023100629448890686, Lr:0.0001\n",
      "Epoch 10, Step: 59, Loss: 0.10137884318828583, Lr:0.0001\n",
      "Epoch 10, Step: 60, Loss: 0.08784391731023788, Lr:0.0001\n",
      "Epoch 10, Step: 61, Loss: 0.06026241555809975, Lr:0.0001\n",
      "Epoch 10, Step: 62, Loss: 0.1014096811413765, Lr:0.0001\n",
      "Epoch 10, Step: 63, Loss: 0.03951162472367287, Lr:0.0001\n",
      "Epoch 10, Step: 64, Loss: 0.22268742322921753, Lr:0.0001\n",
      "Epoch 10, Step: 65, Loss: 0.09810996800661087, Lr:0.0001\n",
      "Epoch 10, Step: 66, Loss: 0.17410960793495178, Lr:0.0001\n",
      "Epoch 10, Step: 67, Loss: 0.024893777444958687, Lr:0.0001\n",
      "Epoch 10, Step: 68, Loss: 0.08971153199672699, Lr:0.0001\n",
      "Epoch 10, Step: 69, Loss: 0.22536897659301758, Lr:0.0001\n",
      "Epoch 10, Step: 70, Loss: 0.03773726895451546, Lr:0.0001\n",
      "Epoch 10, Step: 71, Loss: 0.22434841096401215, Lr:0.0001\n",
      "Epoch 10, Step: 72, Loss: 0.16548191010951996, Lr:0.0001\n",
      "Epoch 10, Step: 73, Loss: 0.01704818569123745, Lr:0.0001\n",
      "Epoch 10, Step: 74, Loss: 0.00767922680824995, Lr:0.0001\n",
      "Epoch 10, Step: 75, Loss: 0.15507160127162933, Lr:0.0001\n",
      "Epoch 10, Step: 76, Loss: 0.5657461881637573, Lr:0.0001\n",
      "Epoch 10, Step: 77, Loss: 0.25472506880760193, Lr:0.0001\n",
      "Epoch 10, Step: 78, Loss: 0.10073509812355042, Lr:0.0001\n",
      "Epoch 10, Step: 79, Loss: 0.11550945788621902, Lr:0.0001\n",
      "Epoch 10, Step: 80, Loss: 0.046266987919807434, Lr:0.0001\n",
      "Epoch 10, Step: 81, Loss: 0.08930832892656326, Lr:0.0001\n",
      "Epoch 10, Step: 82, Loss: 0.1235671192407608, Lr:0.0001\n",
      "Epoch 10, Step: 83, Loss: 0.18884985148906708, Lr:0.0001\n",
      "Epoch 10, Step: 84, Loss: 0.0902809128165245, Lr:0.0001\n",
      "Epoch 10, Step: 85, Loss: 0.11586539447307587, Lr:0.0001\n",
      "Epoch 10, Step: 86, Loss: 0.10815621167421341, Lr:0.0001\n",
      "Epoch 10, Step: 87, Loss: 0.14095671474933624, Lr:0.0001\n",
      "Epoch 10, Step: 88, Loss: 0.4368334412574768, Lr:0.0001\n",
      "Epoch 10, Step: 89, Loss: 0.020390385761857033, Lr:0.0001\n",
      "Epoch 10, Step: 90, Loss: 0.3281761705875397, Lr:0.0001\n",
      "Epoch 10, Step: 91, Loss: 0.06359251588582993, Lr:0.0001\n",
      "Epoch 10, Step: 92, Loss: 0.11010045558214188, Lr:0.0001\n",
      "Epoch 10, Step: 93, Loss: 0.1282261461019516, Lr:0.0001\n",
      "Epoch 10, Step: 94, Loss: 0.06652247905731201, Lr:0.0001\n",
      "Epoch 10, Step: 95, Loss: 0.13913653790950775, Lr:0.0001\n",
      "Epoch 10, Step: 96, Loss: 0.18406537175178528, Lr:0.0001\n",
      "Epoch 10, Step: 97, Loss: 0.10492415726184845, Lr:0.0001\n",
      "Epoch 10, Step: 98, Loss: 0.04555473476648331, Lr:0.0001\n",
      "Epoch 10, Step: 99, Loss: 0.23870430886745453, Lr:0.0001\n",
      "Epoch 10, Step: 100, Loss: 0.08587193489074707, Lr:0.0001\n",
      "Epoch 10, Step: 101, Loss: 0.13698941469192505, Lr:0.0001\n",
      "Epoch 10, Step: 102, Loss: 0.16607174277305603, Lr:0.0001\n",
      "Epoch 10, Step: 103, Loss: 0.03634831681847572, Lr:0.0001\n",
      "Epoch 10, Step: 104, Loss: 0.05697391927242279, Lr:0.0001\n",
      "Epoch 10, Step: 105, Loss: 0.2242225855588913, Lr:0.0001\n",
      "Epoch 10, Step: 106, Loss: 0.06831219792366028, Lr:0.0001\n",
      "Epoch 10, Step: 107, Loss: 0.08107861131429672, Lr:0.0001\n",
      "Epoch 10, Step: 108, Loss: 0.5048298835754395, Lr:0.0001\n",
      "Epoch 10, Step: 109, Loss: 0.04266037791967392, Lr:0.0001\n",
      "Epoch 10, Step: 110, Loss: 0.024887466803193092, Lr:0.0001\n",
      "Epoch 10, Step: 111, Loss: 0.18591687083244324, Lr:0.0001\n",
      "Epoch 10, Step: 112, Loss: 0.17539408802986145, Lr:0.0001\n",
      "Epoch 10, Step: 113, Loss: 0.1757565140724182, Lr:0.0001\n",
      "Epoch 10, Step: 114, Loss: 0.033841460943222046, Lr:0.0001\n",
      "Epoch 10, Step: 115, Loss: 0.10526292026042938, Lr:0.0001\n",
      "Epoch 10, Step: 116, Loss: 0.3186391592025757, Lr:0.0001\n",
      "Epoch 10, Step: 117, Loss: 0.22675642371177673, Lr:0.0001\n",
      "Epoch 10, Step: 118, Loss: 0.3512911796569824, Lr:0.0001\n",
      "Epoch 10, Step: 119, Loss: 0.1330564171075821, Lr:0.0001\n",
      "Epoch 10, Step: 120, Loss: 0.12530551850795746, Lr:0.0001\n",
      "Epoch 10, Step: 121, Loss: 0.030203675851225853, Lr:0.0001\n",
      "Epoch 10, Step: 122, Loss: 0.28851696848869324, Lr:0.0001\n",
      "Epoch 10, Step: 123, Loss: 0.053823649883270264, Lr:0.0001\n",
      "Epoch 10, Step: 124, Loss: 0.8947058916091919, Lr:0.0001\n",
      "Epoch 10, Step: 125, Loss: 0.44780680537223816, Lr:0.0001\n",
      "Epoch 10, Step: 126, Loss: 0.054563894867897034, Lr:0.0001\n",
      "Epoch 10, Step: 127, Loss: 0.09906378388404846, Lr:0.0001\n",
      "Epoch 10, Step: 128, Loss: 0.1405380219221115, Lr:0.0001\n",
      "Epoch 10, Step: 129, Loss: 0.24965545535087585, Lr:0.0001\n",
      "Epoch 10, Step: 130, Loss: 0.07559575885534286, Lr:0.0001\n",
      "Epoch 10, Step: 131, Loss: 0.03448759764432907, Lr:0.0001\n",
      "Epoch 10, Step: 132, Loss: 0.22051987051963806, Lr:0.0001\n",
      "Epoch 10, Step: 133, Loss: 0.1475016325712204, Lr:0.0001\n",
      "Epoch 10, Step: 134, Loss: 0.1568603217601776, Lr:0.0001\n",
      "Epoch 10, Step: 135, Loss: 0.5143463015556335, Lr:0.0001\n",
      "Epoch 10, Step: 136, Loss: 0.1710520088672638, Lr:0.0001\n",
      "Epoch 10, Step: 137, Loss: 0.16895075142383575, Lr:0.0001\n",
      "Epoch 10, Step: 138, Loss: 0.16082455217838287, Lr:0.0001\n",
      "Epoch 10, Step: 139, Loss: 0.016299210488796234, Lr:0.0001\n",
      "Epoch 10, Step: 140, Loss: 0.044610802084207535, Lr:0.0001\n",
      "Epoch 10, Step: 141, Loss: 0.12182653695344925, Lr:0.0001\n",
      "Epoch 10, Step: 142, Loss: 0.17877113819122314, Lr:0.0001\n",
      "Epoch 10, Step: 143, Loss: 0.07690447568893433, Lr:0.0001\n",
      "Epoch 10, Step: 144, Loss: 0.012032299302518368, Lr:0.0001\n",
      "Epoch 10, Step: 145, Loss: 0.35814836621284485, Lr:0.0001\n",
      "Epoch 10, Step: 146, Loss: 0.18995285034179688, Lr:0.0001\n",
      "Epoch 10, Step: 147, Loss: 0.11817318946123123, Lr:0.0001\n",
      "Epoch 10, Step: 148, Loss: 0.2576959729194641, Lr:0.0001\n",
      "Epoch 10, Step: 149, Loss: 0.04150763154029846, Lr:0.0001\n",
      "Epoch 10, Step: 150, Loss: 0.030565399676561356, Lr:0.0001\n",
      "Epoch 10, Step: 151, Loss: 0.13766805827617645, Lr:0.0001\n",
      "Epoch 10, Step: 152, Loss: 0.22238218784332275, Lr:0.0001\n",
      "Epoch 10, Step: 153, Loss: 0.1108025312423706, Lr:0.0001\n",
      "Epoch 10, Step: 154, Loss: 0.07841569930315018, Lr:0.0001\n",
      "Epoch 10, Step: 155, Loss: 0.05170322582125664, Lr:0.0001\n",
      "Epoch 10, Step: 156, Loss: 0.054610222578048706, Lr:0.0001\n",
      "Epoch 10, Step: 157, Loss: 0.11925199627876282, Lr:0.0001\n",
      "Epoch 10, Step: 158, Loss: 0.0701463371515274, Lr:0.0001\n",
      "Epoch 10, Step: 159, Loss: 0.24597705900669098, Lr:0.0001\n",
      "Epoch 10, Step: 160, Loss: 0.028217190876603127, Lr:0.0001\n",
      "Epoch 10, Step: 161, Loss: 0.08085557818412781, Lr:0.0001\n",
      "Epoch 10, Step: 162, Loss: 0.26148802042007446, Lr:0.0001\n",
      "Epoch 10, Step: 163, Loss: 0.5260367393493652, Lr:0.0001\n",
      "Epoch 10, Step: 164, Loss: 0.10460010915994644, Lr:0.0001\n",
      "Epoch 10, Step: 165, Loss: 0.08414468169212341, Lr:0.0001\n",
      "Epoch 10, Step: 166, Loss: 0.15670931339263916, Lr:0.0001\n",
      "Epoch 10, Step: 167, Loss: 0.07655321806669235, Lr:0.0001\n",
      "Epoch 10, Step: 168, Loss: 0.05041501298546791, Lr:0.0001\n",
      "Epoch 10, Step: 169, Loss: 0.23712651431560516, Lr:0.0001\n",
      "Epoch 10, Step: 170, Loss: 0.09491002559661865, Lr:0.0001\n",
      "Epoch 10, Step: 171, Loss: 0.14265446364879608, Lr:0.0001\n",
      "Epoch 10, Step: 172, Loss: 0.07660166174173355, Lr:0.0001\n",
      "Epoch 10, Step: 173, Loss: 0.10461508482694626, Lr:0.0001\n",
      "Epoch 10, Step: 174, Loss: 0.26066213846206665, Lr:0.0001\n",
      "Epoch 10, Step: 175, Loss: 0.14233285188674927, Lr:0.0001\n",
      "Epoch 10, Step: 176, Loss: 0.3386288285255432, Lr:0.0001\n",
      "Epoch 10, Step: 177, Loss: 0.4785197079181671, Lr:0.0001\n",
      "Epoch 10, Step: 178, Loss: 0.1008143201470375, Lr:0.0001\n",
      "Epoch 10, Step: 179, Loss: 0.04762507230043411, Lr:0.0001\n",
      "Epoch 10, Step: 180, Loss: 0.1271984875202179, Lr:0.0001\n",
      "Epoch 10, Step: 181, Loss: 0.02902228757739067, Lr:0.0001\n",
      "Epoch 10, Step: 182, Loss: 0.08860180526971817, Lr:0.0001\n",
      "Epoch 10, Step: 183, Loss: 0.13205468654632568, Lr:0.0001\n",
      "Epoch 10, Step: 184, Loss: 0.1954251527786255, Lr:0.0001\n",
      "Epoch 10, Step: 185, Loss: 0.1179063618183136, Lr:0.0001\n",
      "Epoch 10, Step: 186, Loss: 0.109676294028759, Lr:0.0001\n",
      "Epoch 10, Step: 187, Loss: 0.18271517753601074, Lr:0.0001\n",
      "Epoch 10, Step: 188, Loss: 0.11075134575366974, Lr:0.0001\n",
      "Epoch 10, Step: 189, Loss: 0.10555344820022583, Lr:0.0001\n",
      "Epoch 10, Step: 190, Loss: 0.2758934199810028, Lr:0.0001\n",
      "Epoch 10, Step: 191, Loss: 0.1254514753818512, Lr:0.0001\n",
      "Epoch 10, Step: 192, Loss: 0.07430102676153183, Lr:0.0001\n",
      "Epoch 10, Step: 193, Loss: 0.006472918204963207, Lr:0.0001\n",
      "Epoch 10, Step: 194, Loss: 0.15709441900253296, Lr:0.0001\n",
      "Epoch 10, Step: 195, Loss: 0.5690516829490662, Lr:0.0001\n",
      "Epoch 10, Step: 196, Loss: 0.0395660400390625, Lr:0.0001\n",
      "Epoch 10, Step: 197, Loss: 0.1217423751950264, Lr:0.0001\n",
      "Epoch 10, Step: 198, Loss: 0.07536585628986359, Lr:0.0001\n",
      "Epoch 10, Step: 199, Loss: 0.45541155338287354, Lr:0.0001\n",
      "Epoch 10, Step: 200, Loss: 0.028285551816225052, Lr:0.0001\n",
      "Epoch 10, Step: 201, Loss: 0.12959936261177063, Lr:0.0001\n",
      "Epoch 10, Step: 202, Loss: 0.2629072368144989, Lr:0.0001\n",
      "Epoch 10, Step: 203, Loss: 0.1307428926229477, Lr:0.0001\n",
      "Epoch 10, Step: 204, Loss: 0.05816635861992836, Lr:0.0001\n",
      "Epoch 10, Step: 205, Loss: 0.060748495161533356, Lr:0.0001\n",
      "Epoch 10, Step: 206, Loss: 0.13083496689796448, Lr:0.0001\n",
      "Epoch 10, Step: 207, Loss: 0.17661795020103455, Lr:0.0001\n",
      "Epoch 10, Step: 208, Loss: 0.17879046499729156, Lr:0.0001\n",
      "Epoch 10, Step: 209, Loss: 0.19586893916130066, Lr:0.0001\n",
      "Epoch 10, Step: 210, Loss: 0.05264444649219513, Lr:0.0001\n",
      "Epoch 10, Step: 211, Loss: 0.13047650456428528, Lr:0.0001\n",
      "Epoch 10, Step: 212, Loss: 0.24740943312644958, Lr:0.0001\n",
      "Epoch 10, Step: 213, Loss: 0.190693661570549, Lr:0.0001\n",
      "Epoch 10, Step: 214, Loss: 0.12089533358812332, Lr:0.0001\n",
      "Epoch 10, Step: 215, Loss: 0.08336956799030304, Lr:0.0001\n",
      "Epoch 10, Step: 216, Loss: 0.06987779587507248, Lr:0.0001\n",
      "Epoch 10, Step: 217, Loss: 0.07657509297132492, Lr:0.0001\n",
      "Epoch 10, Step: 218, Loss: 0.1410546898841858, Lr:0.0001\n",
      "Epoch 10, Step: 219, Loss: 0.04955556243658066, Lr:0.0001\n",
      "Epoch 10, Step: 220, Loss: 0.04224031791090965, Lr:0.0001\n",
      "Epoch 10, Step: 221, Loss: 0.09184932708740234, Lr:0.0001\n",
      "Epoch 10, Step: 222, Loss: 0.048256777226924896, Lr:0.0001\n",
      "Epoch 10, Step: 223, Loss: 0.13417865335941315, Lr:0.0001\n",
      "Epoch 10, Step: 224, Loss: 0.34049445390701294, Lr:0.0001\n",
      "Epoch 10, Step: 225, Loss: 0.1244673952460289, Lr:0.0001\n",
      "Epoch 10, Step: 226, Loss: 0.23066523671150208, Lr:0.0001\n",
      "Epoch 10, Step: 227, Loss: 0.16154806315898895, Lr:0.0001\n",
      "Epoch 10, Step: 228, Loss: 0.2211679369211197, Lr:0.0001\n",
      "Epoch 10, Step: 229, Loss: 0.4548262655735016, Lr:0.0001\n",
      "Epoch 10, Step: 230, Loss: 0.13342002034187317, Lr:0.0001\n",
      "Epoch 10, Step: 231, Loss: 0.15454868972301483, Lr:0.0001\n",
      "Epoch 10, Step: 232, Loss: 0.03748702630400658, Lr:0.0001\n",
      "Epoch 10, Step: 233, Loss: 0.012309812940657139, Lr:0.0001\n",
      "Epoch 10, Step: 234, Loss: 0.2631864845752716, Lr:0.0001\n",
      "Epoch 10, Step: 235, Loss: 0.06561174243688583, Lr:0.0001\n",
      "Epoch 10, Step: 236, Loss: 0.17632907629013062, Lr:0.0001\n",
      "Epoch 10, Step: 237, Loss: 0.012225291691720486, Lr:0.0001\n",
      "Epoch 10, Step: 238, Loss: 0.31369730830192566, Lr:0.0001\n",
      "Epoch 10, Step: 239, Loss: 0.1976812332868576, Lr:0.0001\n",
      "Epoch 10, Step: 240, Loss: 0.2379882037639618, Lr:0.0001\n",
      "Epoch 10, Step: 241, Loss: 0.08468732237815857, Lr:0.0001\n",
      "Epoch 10, Step: 242, Loss: 0.06370915472507477, Lr:0.0001\n",
      "Epoch 10, Step: 243, Loss: 0.07011853903532028, Lr:0.0001\n",
      "Epoch 10, Step: 244, Loss: 0.2984989285469055, Lr:0.0001\n",
      "Epoch 10, Step: 245, Loss: 0.03499830886721611, Lr:0.0001\n",
      "Epoch 10, Step: 246, Loss: 0.1803411841392517, Lr:0.0001\n",
      "Epoch 10, Step: 247, Loss: 0.01603538915514946, Lr:0.0001\n",
      "Epoch 10, Step: 248, Loss: 0.04966326057910919, Lr:0.0001\n",
      "Epoch 10, Step: 249, Loss: 0.06905580312013626, Lr:0.0001\n",
      "Epoch 10, Step: 250, Loss: 0.17511442303657532, Lr:0.0001\n",
      "Epoch 10, Step: 251, Loss: 0.11770478636026382, Lr:0.0001\n",
      "Epoch 10, Step: 252, Loss: 0.2751234471797943, Lr:0.0001\n",
      "Epoch 10, Step: 253, Loss: 0.5500733852386475, Lr:0.0001\n",
      "Epoch 10, Step: 254, Loss: 0.33336201310157776, Lr:0.0001\n",
      "Epoch 10, Step: 255, Loss: 0.07364451885223389, Lr:0.0001\n",
      "Epoch 10, Step: 256, Loss: 0.04140404239296913, Lr:0.0001\n",
      "Epoch 10, Step: 257, Loss: 0.02654845640063286, Lr:0.0001\n",
      "Epoch 10, Step: 258, Loss: 0.027987590059638023, Lr:0.0001\n",
      "Epoch 10, Step: 259, Loss: 0.13916130363941193, Lr:0.0001\n",
      "Epoch 10, Step: 260, Loss: 0.02146495133638382, Lr:0.0001\n",
      "Epoch 10, Step: 261, Loss: 0.24607284367084503, Lr:0.0001\n",
      "Epoch 10, Step: 262, Loss: 0.05628475174307823, Lr:0.0001\n",
      "Epoch 10, Step: 263, Loss: 0.06228011101484299, Lr:0.0001\n",
      "Epoch 10, Step: 264, Loss: 0.26020967960357666, Lr:0.0001\n",
      "Epoch 10, Step: 265, Loss: 0.07370132207870483, Lr:0.0001\n",
      "Epoch 10, Step: 266, Loss: 0.042376723140478134, Lr:0.0001\n",
      "Epoch 10, Step: 267, Loss: 0.14535608887672424, Lr:0.0001\n",
      "Epoch 10, Step: 268, Loss: 0.03328149393200874, Lr:0.0001\n",
      "Epoch 10, Step: 269, Loss: 0.2322666496038437, Lr:0.0001\n",
      "Epoch 10, Step: 270, Loss: 0.019688542932271957, Lr:0.0001\n",
      "Epoch 10, Step: 271, Loss: 0.2065676599740982, Lr:0.0001\n",
      "Epoch 10, Step: 272, Loss: 0.04534447565674782, Lr:0.0001\n",
      "Epoch 10, Step: 273, Loss: 0.12505415081977844, Lr:0.0001\n",
      "Epoch 10, Step: 274, Loss: 0.01547821331769228, Lr:0.0001\n",
      "Epoch 10, Step: 275, Loss: 0.03520822525024414, Lr:0.0001\n",
      "Epoch 10, Step: 276, Loss: 0.36874040961265564, Lr:0.0001\n",
      "Epoch 10, Step: 277, Loss: 0.3066346049308777, Lr:0.0001\n",
      "Epoch 10, Step: 278, Loss: 0.07766880840063095, Lr:0.0001\n",
      "Epoch 10, Step: 279, Loss: 0.01863796077668667, Lr:0.0001\n",
      "Epoch 10, Step: 280, Loss: 0.17256884276866913, Lr:0.0001\n",
      "Epoch 10, Step: 281, Loss: 0.4954345226287842, Lr:0.0001\n",
      "Epoch 10, Step: 282, Loss: 0.04027973487973213, Lr:0.0001\n",
      "Epoch 10, Step: 283, Loss: 0.20157860219478607, Lr:0.0001\n",
      "Epoch 10, Step: 284, Loss: 0.5043227076530457, Lr:0.0001\n",
      "Epoch 10, Step: 285, Loss: 0.6659137010574341, Lr:0.0001\n",
      "Epoch 10, Step: 286, Loss: 0.22254906594753265, Lr:0.0001\n",
      "Epoch 10, Step: 287, Loss: 0.042821306735277176, Lr:0.0001\n",
      "Epoch 10, Step: 288, Loss: 0.02981422282755375, Lr:0.0001\n",
      "Epoch 10, Step: 289, Loss: 0.15054236352443695, Lr:0.0001\n",
      "Epoch 10, Step: 290, Loss: 0.19379568099975586, Lr:0.0001\n",
      "Epoch 10, Step: 291, Loss: 0.07401641458272934, Lr:0.0001\n",
      "Epoch 10, Step: 292, Loss: 0.12637147307395935, Lr:0.0001\n",
      "Epoch 10, Step: 293, Loss: 0.26491498947143555, Lr:0.0001\n",
      "Epoch 10, Step: 294, Loss: 0.1931597888469696, Lr:0.0001\n",
      "Epoch 10, Step: 295, Loss: 0.1023595780134201, Lr:0.0001\n",
      "Epoch 10, Step: 296, Loss: 0.24003760516643524, Lr:0.0001\n",
      "Epoch 10, Step: 297, Loss: 0.03423319756984711, Lr:0.0001\n",
      "Epoch 10, Step: 298, Loss: 0.22496993839740753, Lr:0.0001\n",
      "Epoch 10, Step: 299, Loss: 0.22075693309307098, Lr:0.0001\n",
      "Epoch 10, Step: 300, Loss: 0.03691491857171059, Lr:0.0001\n",
      "Epoch 10, Step: 301, Loss: 0.0749519020318985, Lr:0.0001\n",
      "Epoch 10, Step: 302, Loss: 0.07927331328392029, Lr:0.0001\n",
      "Epoch 10, Step: 303, Loss: 0.21827682852745056, Lr:0.0001\n",
      "Epoch 10, Step: 304, Loss: 0.2575616240501404, Lr:0.0001\n",
      "Epoch 10, Step: 305, Loss: 0.21535725891590118, Lr:0.0001\n",
      "Epoch 10, Step: 306, Loss: 0.09655150026082993, Lr:0.0001\n",
      "Epoch 10, Step: 307, Loss: 0.10348527133464813, Lr:0.0001\n",
      "Epoch 10, Step: 308, Loss: 0.10030203312635422, Lr:0.0001\n",
      "Epoch 10, Step: 309, Loss: 0.19716481864452362, Lr:0.0001\n",
      "Epoch 10, Step: 310, Loss: 0.25106191635131836, Lr:0.0001\n",
      "Epoch 10, Step: 311, Loss: 0.0759335309267044, Lr:0.0001\n",
      "Epoch 10, Step: 312, Loss: 0.11238331347703934, Lr:0.0001\n",
      "Epoch 10, Step: 313, Loss: 0.05757439509034157, Lr:0.0001\n",
      "Epoch 10, Step: 314, Loss: 0.04031837359070778, Lr:0.0001\n",
      "Epoch 10, Step: 315, Loss: 0.18368321657180786, Lr:0.0001\n",
      "Epoch 10, Step: 316, Loss: 0.29232296347618103, Lr:0.0001\n",
      "Epoch 10, Step: 317, Loss: 0.004205894656479359, Lr:0.0001\n",
      "Epoch 10, Step: 318, Loss: 0.1352195292711258, Lr:0.0001\n",
      "Epoch 10, Step: 319, Loss: 0.06317473948001862, Lr:0.0001\n",
      "Epoch 10, Step: 320, Loss: 0.15291407704353333, Lr:0.0001\n",
      "Epoch 10, Step: 321, Loss: 0.2454906702041626, Lr:0.0001\n",
      "Epoch 10, Step: 322, Loss: 0.14977173507213593, Lr:0.0001\n",
      "Epoch 10, Step: 323, Loss: 0.07526573538780212, Lr:0.0001\n",
      "Epoch 10, Step: 324, Loss: 0.09135200828313828, Lr:0.0001\n",
      "Epoch 10, Step: 325, Loss: 0.17654433846473694, Lr:0.0001\n",
      "Epoch 10, Step: 326, Loss: 0.04130774363875389, Lr:0.0001\n",
      "Epoch 10, Step: 327, Loss: 0.12368272244930267, Lr:0.0001\n",
      "Epoch 10, Step: 328, Loss: 0.055114347487688065, Lr:0.0001\n",
      "Epoch 10, Step: 329, Loss: 0.2965295910835266, Lr:0.0001\n",
      "Epoch 10, Step: 330, Loss: 0.4815264940261841, Lr:0.0001\n",
      "Epoch 10, Step: 331, Loss: 0.03085973672568798, Lr:0.0001\n",
      "Epoch 10, Step: 332, Loss: 0.07321379333734512, Lr:0.0001\n",
      "Epoch 10, Step: 333, Loss: 0.17092689871788025, Lr:0.0001\n",
      "Epoch 10, Step: 334, Loss: 0.0672709122300148, Lr:0.0001\n",
      "Epoch 10, Step: 335, Loss: 0.03625408187508583, Lr:0.0001\n",
      "Epoch 10, Step: 336, Loss: 0.07976709306240082, Lr:0.0001\n",
      "Epoch 10, Step: 337, Loss: 0.1088264137506485, Lr:0.0001\n",
      "Epoch 10, Step: 338, Loss: 0.03198142722249031, Lr:0.0001\n",
      "Epoch 10, Step: 339, Loss: 0.24587659537792206, Lr:0.0001\n",
      "Epoch 10, Step: 340, Loss: 0.013919845223426819, Lr:0.0001\n",
      "Epoch 10, Step: 341, Loss: 0.12291313707828522, Lr:0.0001\n",
      "Epoch 10, Step: 342, Loss: 0.09743759781122208, Lr:0.0001\n",
      "Epoch 10, Step: 343, Loss: 0.08215086907148361, Lr:0.0001\n",
      "Epoch 10, Step: 344, Loss: 0.07594489306211472, Lr:0.0001\n",
      "Epoch 10, Step: 345, Loss: 0.022145861759781837, Lr:0.0001\n",
      "Epoch 10, Step: 346, Loss: 0.22567492723464966, Lr:0.0001\n",
      "Epoch 10, Step: 347, Loss: 0.07829749584197998, Lr:0.0001\n",
      "Epoch 10, Step: 348, Loss: 0.1443726122379303, Lr:0.0001\n",
      "Epoch 10, Step: 349, Loss: 0.2420477271080017, Lr:0.0001\n",
      "Epoch 10, Step: 350, Loss: 0.03175685182213783, Lr:0.0001\n",
      "Epoch 10, Step: 351, Loss: 0.06302978843450546, Lr:0.0001\n",
      "Epoch 10, Step: 352, Loss: 0.18558692932128906, Lr:0.0001\n",
      "Epoch 10, Step: 353, Loss: 0.4372512400150299, Lr:0.0001\n",
      "Epoch 10, Step: 354, Loss: 0.13342368602752686, Lr:0.0001\n",
      "Epoch 10, Step: 355, Loss: 0.09755285084247589, Lr:0.0001\n",
      "Epoch 10, Step: 356, Loss: 0.0592513382434845, Lr:0.0001\n",
      "Epoch 10, Step: 357, Loss: 0.33360955119132996, Lr:0.0001\n",
      "Epoch 10, Step: 358, Loss: 0.09927918016910553, Lr:0.0001\n",
      "Epoch 10, Step: 359, Loss: 0.09159774333238602, Lr:0.0001\n",
      "Epoch 10, Step: 360, Loss: 0.11914922297000885, Lr:0.0001\n",
      "Epoch 10, Step: 361, Loss: 0.3078162968158722, Lr:0.0001\n",
      "Epoch 10, Step: 362, Loss: 0.05188145115971565, Lr:0.0001\n",
      "Epoch 10, Step: 363, Loss: 0.010561486706137657, Lr:0.0001\n",
      "Epoch 10, Step: 364, Loss: 0.11033337563276291, Lr:0.0001\n",
      "Epoch 10, Step: 365, Loss: 0.23951676487922668, Lr:0.0001\n",
      "Epoch 10, Step: 366, Loss: 0.08599770069122314, Lr:0.0001\n",
      "Epoch 10, Step: 367, Loss: 0.007934345863759518, Lr:0.0001\n",
      "Epoch 10, Step: 368, Loss: 0.23889055848121643, Lr:0.0001\n",
      "Epoch 10, Step: 369, Loss: 0.13053016364574432, Lr:0.0001\n",
      "Epoch 10, Step: 370, Loss: 0.023180337622761726, Lr:0.0001\n",
      "Epoch 10, Step: 371, Loss: 0.3012464940547943, Lr:0.0001\n",
      "Epoch 10, Step: 372, Loss: 0.13816599547863007, Lr:0.0001\n",
      "Epoch 10, Step: 373, Loss: 0.030426183715462685, Lr:0.0001\n",
      "Epoch 10, Step: 374, Loss: 0.0628328025341034, Lr:0.0001\n",
      "Epoch 10, Step: 375, Loss: 0.023723162710666656, Lr:0.0001\n",
      "Epoch 10, Step: 376, Loss: 0.05486047640442848, Lr:0.0001\n",
      "Epoch 10, Step: 377, Loss: 0.04304943233728409, Lr:0.0001\n",
      "Epoch 10, Step: 378, Loss: 0.13127529621124268, Lr:0.0001\n",
      "Epoch 10, Step: 379, Loss: 0.16748572885990143, Lr:0.0001\n",
      "Epoch 10, Step: 380, Loss: 0.13048610091209412, Lr:0.0001\n",
      "Epoch 10, Step: 381, Loss: 0.12844492495059967, Lr:0.0001\n",
      "Epoch 10, Step: 382, Loss: 0.05311466380953789, Lr:0.0001\n",
      "Epoch 10, Step: 383, Loss: 0.023922594264149666, Lr:0.0001\n",
      "Epoch 10, Step: 384, Loss: 0.0604262501001358, Lr:0.0001\n",
      "Epoch 10, Step: 385, Loss: 0.05514795705676079, Lr:0.0001\n",
      "Epoch 10, Step: 386, Loss: 0.13466231524944305, Lr:0.0001\n",
      "Epoch 10, Step: 387, Loss: 0.1525295376777649, Lr:0.0001\n",
      "Epoch 10, Step: 388, Loss: 0.34545668959617615, Lr:0.0001\n",
      "Epoch 10, Step: 389, Loss: 0.06142609566450119, Lr:0.0001\n",
      "Epoch 10, Step: 390, Loss: 0.17458529770374298, Lr:0.0001\n",
      "Epoch 10, Step: 391, Loss: 0.07510491460561752, Lr:0.0001\n",
      "Epoch 10, Step: 392, Loss: 0.009830798953771591, Lr:0.0001\n",
      "Epoch 10, Step: 393, Loss: 0.10072920471429825, Lr:0.0001\n",
      "Epoch 10, Step: 394, Loss: 0.22617417573928833, Lr:0.0001\n",
      "Epoch 10, Step: 395, Loss: 0.1713997721672058, Lr:0.0001\n",
      "Epoch 10, Step: 396, Loss: 0.05574677139520645, Lr:0.0001\n",
      "Epoch 10, Step: 397, Loss: 0.1025964766740799, Lr:0.0001\n",
      "Epoch 10, Step: 398, Loss: 0.16495874524116516, Lr:0.0001\n",
      "Epoch 10, Step: 399, Loss: 0.10847213119268417, Lr:0.0001\n",
      "Epoch 10, Step: 400, Loss: 0.046067267656326294, Lr:0.0001\n",
      "Epoch 10, Step: 401, Loss: 0.03037542849779129, Lr:0.0001\n",
      "Epoch 10, Step: 402, Loss: 0.12553814053535461, Lr:0.0001\n",
      "Epoch 10, Step: 403, Loss: 0.029396988451480865, Lr:0.0001\n",
      "Epoch 10, Step: 404, Loss: 0.05235181003808975, Lr:0.0001\n",
      "Epoch 10, Step: 405, Loss: 0.07795050740242004, Lr:0.0001\n",
      "Epoch 10, Step: 406, Loss: 0.14919151365756989, Lr:0.0001\n",
      "Epoch 10, Step: 407, Loss: 0.013212624937295914, Lr:0.0001\n",
      "Epoch 10, Step: 408, Loss: 0.15950994193553925, Lr:0.0001\n",
      "Epoch 10, Step: 409, Loss: 0.12643715739250183, Lr:0.0001\n",
      "Epoch 10, Step: 410, Loss: 0.11564873903989792, Lr:0.0001\n",
      "Epoch 10, Step: 411, Loss: 0.04178408905863762, Lr:0.0001\n",
      "Epoch 10, Step: 412, Loss: 0.13861729204654694, Lr:0.0001\n",
      "Epoch 10, Step: 413, Loss: 0.11493375897407532, Lr:0.0001\n",
      "Epoch 10, Step: 414, Loss: 0.07666145265102386, Lr:0.0001\n",
      "Epoch 10, Step: 415, Loss: 0.09195922315120697, Lr:0.0001\n",
      "Epoch 10, Step: 416, Loss: 0.006497628521174192, Lr:0.0001\n",
      "Epoch 10, Step: 417, Loss: 0.279335081577301, Lr:0.0001\n",
      "Epoch 10, Step: 418, Loss: 0.2304341346025467, Lr:0.0001\n",
      "Epoch 10, Step: 419, Loss: 0.10823987424373627, Lr:0.0001\n",
      "Epoch 10, Step: 420, Loss: 0.2576603293418884, Lr:0.0001\n",
      "Epoch 10, Step: 421, Loss: 0.19268983602523804, Lr:0.0001\n",
      "Epoch 10, Step: 422, Loss: 0.019582871347665787, Lr:0.0001\n",
      "Epoch 10, Step: 423, Loss: 0.019938750192523003, Lr:0.0001\n",
      "Epoch 10, Step: 424, Loss: 0.02135419473052025, Lr:0.0001\n",
      "Epoch 10, Step: 425, Loss: 0.20624984800815582, Lr:0.0001\n",
      "Epoch 10, Step: 426, Loss: 0.04980385676026344, Lr:0.0001\n",
      "Epoch 10, Step: 427, Loss: 0.19107218086719513, Lr:0.0001\n",
      "Epoch 10, Step: 428, Loss: 0.14797137677669525, Lr:0.0001\n",
      "Epoch 10, Step: 429, Loss: 0.05917016416788101, Lr:0.0001\n",
      "Epoch 10, Step: 430, Loss: 0.04928675293922424, Lr:0.0001\n",
      "Epoch 10, Step: 431, Loss: 0.05185150355100632, Lr:0.0001\n",
      "Epoch 10, Step: 432, Loss: 0.07937533408403397, Lr:0.0001\n",
      "Epoch 10, Step: 433, Loss: 0.0780915766954422, Lr:0.0001\n",
      "Epoch 10, Step: 434, Loss: 0.023075345903635025, Lr:0.0001\n",
      "Epoch 10, Step: 435, Loss: 0.14665627479553223, Lr:0.0001\n",
      "Epoch 10, Step: 436, Loss: 0.06398896127939224, Lr:0.0001\n",
      "Epoch 10, Step: 437, Loss: 0.1271965056657791, Lr:0.0001\n",
      "Epoch 10, Step: 438, Loss: 0.018748538568615913, Lr:0.0001\n",
      "Epoch 10, Step: 439, Loss: 0.15240037441253662, Lr:0.0001\n",
      "Epoch 10, Step: 440, Loss: 0.1925087869167328, Lr:0.0001\n",
      "Epoch 10, Step: 441, Loss: 0.12950162589550018, Lr:0.0001\n",
      "Epoch 10, Step: 442, Loss: 0.1373133510351181, Lr:0.0001\n",
      "Epoch 10, Step: 443, Loss: 0.13549061119556427, Lr:0.0001\n",
      "Epoch 10, Step: 444, Loss: 0.057856302708387375, Lr:0.0001\n",
      "Epoch 10, Step: 445, Loss: 0.11379135400056839, Lr:0.0001\n",
      "Epoch 10, Step: 446, Loss: 0.12988460063934326, Lr:0.0001\n",
      "Epoch 10, Step: 447, Loss: 0.026500260457396507, Lr:0.0001\n",
      "Epoch 10, Step: 448, Loss: 0.006613587960600853, Lr:0.0001\n",
      "Epoch 10, Step: 449, Loss: 0.19376137852668762, Lr:0.0001\n",
      "Epoch 10, Step: 450, Loss: 0.03613719716668129, Lr:0.0001\n",
      "Epoch 10, Step: 451, Loss: 0.2541767358779907, Lr:0.0001\n",
      "Epoch 10, Step: 452, Loss: 0.03897812217473984, Lr:0.0001\n",
      "Epoch 10, Step: 453, Loss: 0.4599396586418152, Lr:0.0001\n",
      "Epoch 10, Step: 454, Loss: 0.11155364662408829, Lr:0.0001\n",
      "Epoch 10, Step: 455, Loss: 0.05298304930329323, Lr:0.0001\n",
      "Epoch 10, Step: 456, Loss: 0.010473313741385937, Lr:0.0001\n",
      "Epoch 10, Step: 457, Loss: 0.13718344271183014, Lr:0.0001\n",
      "Epoch 10, Step: 458, Loss: 0.4033758044242859, Lr:0.0001\n",
      "Epoch 10, Step: 459, Loss: 0.017038952559232712, Lr:0.0001\n",
      "Epoch 10, Step: 460, Loss: 0.045587822794914246, Lr:0.0001\n",
      "Epoch 10, Step: 461, Loss: 0.270151823759079, Lr:0.0001\n",
      "Epoch 10, Step: 462, Loss: 0.05224965885281563, Lr:0.0001\n",
      "Epoch 10, Step: 463, Loss: 0.11400169879198074, Lr:0.0001\n",
      "Epoch 10, Step: 464, Loss: 0.036104075610637665, Lr:0.0001\n",
      "Epoch 10, Step: 465, Loss: 0.017871079966425896, Lr:0.0001\n",
      "Epoch 10, Step: 466, Loss: 0.21110209822654724, Lr:0.0001\n",
      "Epoch 10, Step: 467, Loss: 0.12143231928348541, Lr:0.0001\n",
      "Epoch 10, Step: 468, Loss: 0.05267148092389107, Lr:0.0001\n",
      "Epoch 10, Step: 469, Loss: 0.15756624937057495, Lr:0.0001\n",
      "Epoch 10, Step: 470, Loss: 0.1394127756357193, Lr:0.0001\n",
      "Epoch 10, Step: 471, Loss: 0.10581697523593903, Lr:0.0001\n",
      "Epoch 10, Step: 472, Loss: 0.021000949665904045, Lr:0.0001\n",
      "Epoch 10, Step: 473, Loss: 0.39672937989234924, Lr:0.0001\n",
      "Epoch 10, Step: 474, Loss: 0.06426563858985901, Lr:0.0001\n",
      "Epoch 10, Step: 475, Loss: 0.15285225212574005, Lr:0.0001\n",
      "Epoch 10, Step: 476, Loss: 0.20433002710342407, Lr:0.0001\n",
      "Epoch 10, Step: 477, Loss: 0.09013121575117111, Lr:0.0001\n",
      "Epoch 10, Step: 478, Loss: 0.30102449655532837, Lr:0.0001\n",
      "Epoch 10, Step: 479, Loss: 0.05602347478270531, Lr:0.0001\n",
      "Epoch 10, Step: 480, Loss: 0.21598346531391144, Lr:0.0001\n",
      "Epoch 10, Step: 481, Loss: 0.45193204283714294, Lr:0.0001\n",
      "Epoch 10, Step: 482, Loss: 0.0815916359424591, Lr:0.0001\n",
      "Epoch 10, Step: 483, Loss: 0.27215391397476196, Lr:0.0001\n",
      "Epoch 10, Step: 484, Loss: 0.12726958096027374, Lr:0.0001\n",
      "Epoch 10, Step: 485, Loss: 0.039027731865644455, Lr:0.0001\n",
      "Epoch 10, Step: 486, Loss: 0.07840988039970398, Lr:0.0001\n",
      "Epoch 10, Step: 487, Loss: 0.25093838572502136, Lr:0.0001\n",
      "Epoch 10, Step: 488, Loss: 0.0740409642457962, Lr:0.0001\n",
      "Epoch 10, Step: 489, Loss: 0.20851141214370728, Lr:0.0001\n",
      "Epoch 10, Step: 490, Loss: 0.02875066176056862, Lr:0.0001\n",
      "Epoch 10, Step: 491, Loss: 0.29846686124801636, Lr:0.0001\n",
      "Epoch 10, Step: 492, Loss: 0.12738440930843353, Lr:0.0001\n",
      "Epoch 10, Step: 493, Loss: 0.07168815284967422, Lr:0.0001\n",
      "Epoch 10, Step: 494, Loss: 0.39715567231178284, Lr:0.0001\n",
      "Epoch 10, Step: 495, Loss: 0.2588486671447754, Lr:0.0001\n",
      "Epoch 10, Step: 496, Loss: 0.043007779866456985, Lr:0.0001\n",
      "Epoch 10, Step: 497, Loss: 0.37112969160079956, Lr:0.0001\n",
      "Epoch 10, Step: 498, Loss: 0.14582417905330658, Lr:0.0001\n",
      "Epoch 10, Step: 499, Loss: 0.12087416648864746, Lr:0.0001\n",
      "Epoch 10, Step: 500, Loss: 0.07808408886194229, Lr:0.0001\n",
      "Epoch 10, Step: 501, Loss: 0.07067176699638367, Lr:0.0001\n",
      "Epoch 10, Step: 502, Loss: 0.10354524850845337, Lr:0.0001\n",
      "Epoch 10, Step: 503, Loss: 0.05141794681549072, Lr:0.0001\n",
      "Epoch 10, Step: 504, Loss: 0.32126477360725403, Lr:0.0001\n",
      "Epoch 10, Step: 505, Loss: 0.16984416544437408, Lr:0.0001\n",
      "Epoch 10, Step: 506, Loss: 0.4207547605037689, Lr:0.0001\n",
      "Epoch 10, Step: 507, Loss: 0.3871772587299347, Lr:0.0001\n",
      "Epoch 10, Step: 508, Loss: 0.20571215450763702, Lr:0.0001\n",
      "Epoch 10, Step: 509, Loss: 0.3941973149776459, Lr:0.0001\n",
      "Epoch 10, Step: 510, Loss: 0.26841726899147034, Lr:0.0001\n",
      "Epoch 10, Step: 511, Loss: 0.04898626357316971, Lr:0.0001\n",
      "Epoch 10, Step: 512, Loss: 0.12746664881706238, Lr:0.0001\n",
      "Epoch 10, Step: 513, Loss: 0.25074827671051025, Lr:0.0001\n",
      "Epoch 10, Step: 514, Loss: 0.01987162046134472, Lr:0.0001\n",
      "Epoch 10, Step: 515, Loss: 0.11214904487133026, Lr:0.0001\n",
      "Epoch 10, Step: 516, Loss: 0.18988122045993805, Lr:0.0001\n",
      "Epoch 10, Step: 517, Loss: 0.21163837611675262, Lr:0.0001\n",
      "Epoch 10, Step: 518, Loss: 0.010719675570726395, Lr:0.0001\n",
      "Epoch 10, Step: 519, Loss: 0.267814576625824, Lr:0.0001\n",
      "Epoch 10, Step: 520, Loss: 0.13795232772827148, Lr:0.0001\n",
      "Epoch 10, Step: 521, Loss: 0.11574745923280716, Lr:0.0001\n",
      "Epoch 10, Step: 522, Loss: 0.36419495940208435, Lr:0.0001\n",
      "Epoch 10, Step: 523, Loss: 0.48918139934539795, Lr:0.0001\n",
      "Epoch 10, Step: 524, Loss: 0.26215070486068726, Lr:0.0001\n",
      "Epoch 10, Step: 525, Loss: 0.08824647963047028, Lr:0.0001\n",
      "Epoch 10, Step: 526, Loss: 0.27525952458381653, Lr:0.0001\n",
      "Epoch 10, Step: 527, Loss: 0.3208245635032654, Lr:0.0001\n",
      "Epoch 10, Step: 528, Loss: 0.06268512457609177, Lr:0.0001\n",
      "Epoch 10, Step: 529, Loss: 0.12501317262649536, Lr:0.0001\n",
      "Epoch 10, Step: 530, Loss: 0.1559632122516632, Lr:0.0001\n",
      "Epoch 10, Step: 531, Loss: 0.049332112073898315, Lr:0.0001\n",
      "Epoch 10, Step: 532, Loss: 0.19683398306369781, Lr:0.0001\n",
      "Epoch 10, Step: 533, Loss: 0.04198943078517914, Lr:0.0001\n",
      "Epoch 10, Step: 534, Loss: 0.06452706456184387, Lr:0.0001\n",
      "Epoch 10, Step: 535, Loss: 0.19216802716255188, Lr:0.0001\n",
      "Epoch 10, Step: 536, Loss: 0.09505429118871689, Lr:0.0001\n",
      "Epoch 10, Step: 537, Loss: 0.3456416428089142, Lr:0.0001\n",
      "Epoch 10, Step: 538, Loss: 0.08836567401885986, Lr:0.0001\n",
      "Epoch 10, Step: 539, Loss: 0.23224177956581116, Lr:0.0001\n",
      "Epoch 10, Step: 540, Loss: 0.288457453250885, Lr:0.0001\n",
      "Epoch 10, Step: 541, Loss: 0.058351993560791016, Lr:0.0001\n",
      "Epoch 10, Step: 542, Loss: 0.08463003486394882, Lr:0.0001\n",
      "Epoch 10, Step: 543, Loss: 0.1716887652873993, Lr:0.0001\n",
      "Epoch 10, Step: 544, Loss: 0.17722263932228088, Lr:0.0001\n",
      "Epoch 10, Step: 545, Loss: 0.3558201193809509, Lr:0.0001\n",
      "Epoch 10, Step: 546, Loss: 0.05418378487229347, Lr:0.0001\n",
      "Epoch 10, Step: 547, Loss: 0.03421436622738838, Lr:0.0001\n",
      "Epoch 10, Step: 548, Loss: 0.1262991577386856, Lr:0.0001\n",
      "Epoch 10, Step: 549, Loss: 0.1222432479262352, Lr:0.0001\n",
      "Epoch 10, Step: 550, Loss: 0.2190694659948349, Lr:0.0001\n",
      "Epoch 10, Step: 551, Loss: 0.11147154867649078, Lr:0.0001\n",
      "Epoch 10, Step: 552, Loss: 0.1841956526041031, Lr:0.0001\n",
      "Epoch 10, Step: 553, Loss: 0.12721799314022064, Lr:0.0001\n",
      "Epoch 10, Step: 554, Loss: 0.05725621059536934, Lr:0.0001\n",
      "Epoch 10, Step: 555, Loss: 0.22663220763206482, Lr:0.0001\n",
      "Epoch 10, Step: 556, Loss: 0.09071213752031326, Lr:0.0001\n",
      "Epoch 10, Step: 557, Loss: 0.13465623557567596, Lr:0.0001\n",
      "Epoch 10, Step: 558, Loss: 0.04899531602859497, Lr:0.0001\n",
      "Epoch 10, Step: 559, Loss: 0.04510880634188652, Lr:0.0001\n",
      "Epoch 10, Step: 560, Loss: 0.2350960075855255, Lr:0.0001\n",
      "Epoch 10, Step: 561, Loss: 0.18360111117362976, Lr:0.0001\n",
      "Epoch 10, Step: 562, Loss: 0.1421591192483902, Lr:0.0001\n",
      "Epoch 10, Step: 563, Loss: 0.11517561227083206, Lr:0.0001\n",
      "Epoch 10, Step: 564, Loss: 0.3083750307559967, Lr:0.0001\n",
      "Epoch 10, Step: 565, Loss: 0.2792218029499054, Lr:0.0001\n",
      "Epoch 10, Step: 566, Loss: 0.26994702219963074, Lr:0.0001\n",
      "Epoch 10, Step: 567, Loss: 0.303101509809494, Lr:0.0001\n",
      "Epoch 10, Step: 568, Loss: 0.28572651743888855, Lr:0.0001\n",
      "Epoch 10, Step: 569, Loss: 0.07557299733161926, Lr:0.0001\n",
      "Epoch 10, Step: 570, Loss: 0.03626500815153122, Lr:0.0001\n",
      "Epoch 10, Step: 571, Loss: 0.19481009244918823, Lr:0.0001\n",
      "Epoch 10, Step: 572, Loss: 0.03795003518462181, Lr:0.0001\n",
      "Epoch 10, Step: 573, Loss: 0.31005823612213135, Lr:0.0001\n",
      "Epoch 10, Step: 574, Loss: 0.048290885984897614, Lr:0.0001\n",
      "Epoch 10, Step: 575, Loss: 0.027872713282704353, Lr:0.0001\n",
      "Epoch 10, Step: 576, Loss: 0.058118369430303574, Lr:0.0001\n",
      "Epoch 10, Step: 577, Loss: 0.11373905837535858, Lr:0.0001\n",
      "Epoch 10, Step: 578, Loss: 0.09290256351232529, Lr:0.0001\n",
      "Epoch 10, Step: 579, Loss: 0.07823742181062698, Lr:0.0001\n",
      "Epoch 10, Step: 580, Loss: 0.41255849599838257, Lr:0.0001\n",
      "Epoch 10, Step: 581, Loss: 0.09999841451644897, Lr:0.0001\n",
      "Epoch 10, Step: 582, Loss: 0.1395011991262436, Lr:0.0001\n",
      "Epoch 10, Step: 583, Loss: 0.5451686382293701, Lr:0.0001\n",
      "Epoch 10, Step: 584, Loss: 0.13896605372428894, Lr:0.0001\n",
      "Epoch 10, Step: 585, Loss: 0.05443555489182472, Lr:0.0001\n",
      "Epoch 10, Step: 586, Loss: 0.028673067688941956, Lr:0.0001\n",
      "Epoch 10, Step: 587, Loss: 0.1784331500530243, Lr:0.0001\n",
      "Epoch 10, Step: 588, Loss: 0.1023760437965393, Lr:0.0001\n",
      "Epoch 10, Step: 589, Loss: 0.19886203110218048, Lr:0.0001\n",
      "Epoch 10, Step: 590, Loss: 0.058851663023233414, Lr:0.0001\n",
      "Epoch 10, Step: 591, Loss: 0.07950036227703094, Lr:0.0001\n",
      "Epoch 10, Step: 592, Loss: 0.1967291682958603, Lr:0.0001\n",
      "Epoch 10, Step: 593, Loss: 0.06712237000465393, Lr:0.0001\n",
      "Epoch 10, Step: 594, Loss: 0.1622212827205658, Lr:0.0001\n",
      "Epoch 10, Step: 595, Loss: 0.22641505300998688, Lr:0.0001\n",
      "Epoch 10, Step: 596, Loss: 0.0258953794836998, Lr:0.0001\n",
      "Epoch 10, Step: 597, Loss: 0.17050524055957794, Lr:0.0001\n",
      "Epoch 10, Step: 598, Loss: 0.16606655716896057, Lr:0.0001\n",
      "Epoch 10, Step: 599, Loss: 0.013557386584579945, Lr:0.0001\n",
      "Epoch 10, Step: 600, Loss: 0.22001774609088898, Lr:0.0001\n",
      "Epoch 10, Step: 601, Loss: 0.0689612552523613, Lr:0.0001\n",
      "Epoch 10, Step: 602, Loss: 0.14832313358783722, Lr:0.0001\n",
      "Epoch 10, Step: 603, Loss: 0.03317319601774216, Lr:0.0001\n",
      "Epoch 10, Step: 604, Loss: 0.14129391312599182, Lr:0.0001\n",
      "Epoch 10, Step: 605, Loss: 0.24057383835315704, Lr:0.0001\n",
      "Epoch 10, Step: 606, Loss: 0.2872631549835205, Lr:0.0001\n",
      "Epoch 10, Step: 607, Loss: 0.3079686760902405, Lr:0.0001\n",
      "Epoch 10, Step: 608, Loss: 0.016104241833090782, Lr:0.0001\n",
      "Epoch 10, Step: 609, Loss: 0.030654141679406166, Lr:0.0001\n",
      "Epoch 10, Step: 610, Loss: 0.15164440870285034, Lr:0.0001\n",
      "Epoch 10, Step: 611, Loss: 0.20389240980148315, Lr:0.0001\n",
      "Epoch 10, Step: 612, Loss: 0.18027129769325256, Lr:0.0001\n",
      "Epoch 10, Step: 613, Loss: 0.05799134075641632, Lr:0.0001\n",
      "Epoch 10, Step: 614, Loss: 0.215448796749115, Lr:0.0001\n",
      "Epoch 10, Step: 615, Loss: 0.08674726635217667, Lr:0.0001\n",
      "Epoch 10, Step: 616, Loss: 0.04921106994152069, Lr:0.0001\n",
      "Epoch 10, Step: 617, Loss: 0.07740776240825653, Lr:0.0001\n",
      "Epoch 10, Step: 618, Loss: 0.011944719590246677, Lr:0.0001\n",
      "Epoch 10, Step: 619, Loss: 0.03655845671892166, Lr:0.0001\n",
      "Epoch 10, Step: 620, Loss: 0.19579437375068665, Lr:0.0001\n",
      "Epoch 10, Step: 621, Loss: 0.11003760993480682, Lr:0.0001\n",
      "Epoch 10, Step: 622, Loss: 0.38510197401046753, Lr:0.0001\n",
      "Epoch 10, Step: 623, Loss: 0.1455492377281189, Lr:0.0001\n",
      "Epoch 10, Step: 624, Loss: 0.17962245643138885, Lr:0.0001\n",
      "Epoch 10, Step: 625, Loss: 0.06690987199544907, Lr:0.0001\n",
      "Epoch 10, Step: 626, Loss: 0.054832205176353455, Lr:0.0001\n",
      "Epoch 10, Step: 627, Loss: 0.018225297331809998, Lr:0.0001\n",
      "Epoch 10, Step: 628, Loss: 0.06536097079515457, Lr:0.0001\n",
      "Epoch 10, Step: 629, Loss: 0.2728895843029022, Lr:0.0001\n",
      "Epoch 10, Step: 630, Loss: 0.08125008642673492, Lr:0.0001\n",
      "Epoch 10, Step: 631, Loss: 0.10912971943616867, Lr:0.0001\n",
      "Epoch 10, Step: 632, Loss: 0.038179874420166016, Lr:0.0001\n",
      "Epoch 10, Step: 633, Loss: 0.11500167846679688, Lr:0.0001\n",
      "Epoch 10, Step: 634, Loss: 0.22717919945716858, Lr:0.0001\n",
      "Epoch 10, Step: 635, Loss: 0.12109348177909851, Lr:0.0001\n",
      "Epoch 10, Step: 636, Loss: 0.22695299983024597, Lr:0.0001\n",
      "Epoch 10, Step: 637, Loss: 0.01968289352953434, Lr:0.0001\n",
      "Epoch 10, Step: 638, Loss: 0.3921210467815399, Lr:0.0001\n",
      "Epoch 10, Step: 639, Loss: 0.08596932888031006, Lr:0.0001\n",
      "Epoch 10, Step: 640, Loss: 0.028457554057240486, Lr:0.0001\n",
      "Epoch 10, Step: 641, Loss: 0.06917647272348404, Lr:0.0001\n",
      "Epoch 10, Step: 642, Loss: 0.3540268540382385, Lr:0.0001\n",
      "Epoch 10, Step: 643, Loss: 0.09412575513124466, Lr:0.0001\n",
      "Epoch 10, Step: 644, Loss: 0.018671482801437378, Lr:0.0001\n",
      "Epoch 10, Step: 645, Loss: 0.18797361850738525, Lr:0.0001\n",
      "Epoch 10, Step: 646, Loss: 0.019338585436344147, Lr:0.0001\n",
      "Epoch 10, Step: 647, Loss: 0.3715631067752838, Lr:0.0001\n",
      "Epoch 10, Step: 648, Loss: 0.03525044769048691, Lr:0.0001\n",
      "Epoch 10, Step: 649, Loss: 0.21541254222393036, Lr:0.0001\n",
      "Epoch 10, Step: 650, Loss: 0.19343556463718414, Lr:0.0001\n",
      "Epoch 10, Step: 651, Loss: 0.22293426096439362, Lr:0.0001\n",
      "Epoch 10, Step: 652, Loss: 0.25206252932548523, Lr:0.0001\n",
      "Epoch 10, Step: 653, Loss: 2.287752151489258, Lr:0.0001\n",
      "Epoch 10, Step: 654, Loss: 0.2200668752193451, Lr:0.0001\n",
      "Epoch 10, Step: 655, Loss: 0.0735006332397461, Lr:0.0001\n",
      "Epoch 10, Step: 656, Loss: 0.31560075283050537, Lr:0.0001\n",
      "Epoch 10, Step: 657, Loss: 0.061915308237075806, Lr:0.0001\n",
      "Epoch 10, Step: 658, Loss: 0.06767021864652634, Lr:0.0001\n",
      "Epoch 10, Step: 659, Loss: 0.07216372340917587, Lr:0.0001\n",
      "Epoch 10, Step: 660, Loss: 0.5703713297843933, Lr:0.0001\n",
      "Epoch 10, Step: 661, Loss: 0.20521068572998047, Lr:0.0001\n",
      "Epoch 10, Step: 662, Loss: 0.16823779046535492, Lr:0.0001\n",
      "Epoch 10, Step: 663, Loss: 0.21967464685440063, Lr:0.0001\n",
      "Epoch 10, Step: 664, Loss: 0.11418290436267853, Lr:0.0001\n",
      "Epoch 10, Step: 665, Loss: 0.21423998475074768, Lr:0.0001\n",
      "Epoch 10, Step: 666, Loss: 0.15416082739830017, Lr:0.0001\n",
      "Epoch 10, Step: 667, Loss: 0.24668766558170319, Lr:0.0001\n",
      "Epoch 10, Step: 668, Loss: 0.1778142899274826, Lr:0.0001\n",
      "Epoch 10, Step: 669, Loss: 0.10315489768981934, Lr:0.0001\n",
      "Epoch 10, Step: 670, Loss: 0.02446494996547699, Lr:0.0001\n",
      "Epoch 10, Step: 671, Loss: 0.17158818244934082, Lr:0.0001\n",
      "Epoch 10, Step: 672, Loss: 0.16255967319011688, Lr:0.0001\n",
      "Epoch 10, Step: 673, Loss: 0.2899545431137085, Lr:0.0001\n",
      "Epoch 10, Step: 674, Loss: 0.16156384348869324, Lr:0.0001\n",
      "Epoch 10, Step: 675, Loss: 0.23640283942222595, Lr:0.0001\n",
      "Epoch 10, Step: 676, Loss: 0.05031207576394081, Lr:0.0001\n",
      "Epoch 10, Step: 677, Loss: 0.37386488914489746, Lr:0.0001\n",
      "Epoch 10, Step: 678, Loss: 0.02182336337864399, Lr:0.0001\n",
      "Epoch 10, Step: 679, Loss: 0.08672983944416046, Lr:0.0001\n",
      "Epoch 10, Step: 680, Loss: 0.031467851251363754, Lr:0.0001\n",
      "Epoch 10, Step: 681, Loss: 0.05649866536259651, Lr:0.0001\n",
      "Epoch 10, Step: 682, Loss: 0.23351454734802246, Lr:0.0001\n",
      "Epoch 10, Step: 683, Loss: 0.130999356508255, Lr:0.0001\n",
      "Epoch 10, Step: 684, Loss: 0.37960538268089294, Lr:0.0001\n",
      "Epoch 10, Step: 685, Loss: 0.07020404189825058, Lr:0.0001\n",
      "Epoch 10, Step: 686, Loss: 0.04840918257832527, Lr:0.0001\n",
      "Epoch 10, Step: 687, Loss: 0.0663280040025711, Lr:0.0001\n",
      "Epoch 10, Step: 688, Loss: 0.40031901001930237, Lr:0.0001\n",
      "Epoch 10, Step: 689, Loss: 0.14521870017051697, Lr:0.0001\n",
      "Epoch 10, Step: 690, Loss: 0.16370061039924622, Lr:0.0001\n",
      "Epoch 10, Step: 691, Loss: 0.23459315299987793, Lr:0.0001\n",
      "Epoch 10, Step: 692, Loss: 0.13912519812583923, Lr:0.0001\n",
      "Epoch 10, Step: 693, Loss: 0.08428215235471725, Lr:0.0001\n",
      "Epoch 10, Step: 694, Loss: 0.1618429273366928, Lr:0.0001\n",
      "Epoch 10, Step: 695, Loss: 0.10064482688903809, Lr:0.0001\n",
      "Epoch 10, Step: 696, Loss: 0.15016181766986847, Lr:0.0001\n",
      "Epoch 10, Step: 697, Loss: 0.05844145268201828, Lr:0.0001\n",
      "Epoch 10, Step: 698, Loss: 0.05390772968530655, Lr:0.0001\n",
      "Epoch 10, Step: 699, Loss: 0.2113397866487503, Lr:0.0001\n",
      "Epoch 10, Step: 700, Loss: 0.011292428709566593, Lr:0.0001\n",
      "Epoch 10, Step: 701, Loss: 0.6814007759094238, Lr:0.0001\n",
      "Epoch 10, Step: 702, Loss: 0.026509679853916168, Lr:0.0001\n",
      "Epoch 10, Step: 703, Loss: 0.5395357012748718, Lr:0.0001\n",
      "Epoch 10, Step: 704, Loss: 0.11233904212713242, Lr:0.0001\n",
      "Epoch 10, Step: 705, Loss: 0.052879851311445236, Lr:0.0001\n",
      "Epoch 10, Step: 706, Loss: 0.019796816632151604, Lr:0.0001\n",
      "Epoch 10, Step: 707, Loss: 0.03739771619439125, Lr:0.0001\n",
      "Epoch 10, Step: 708, Loss: 0.10465709120035172, Lr:0.0001\n",
      "Epoch 10, Step: 709, Loss: 0.12809625267982483, Lr:0.0001\n",
      "Epoch 10, Step: 710, Loss: 0.07564523816108704, Lr:0.0001\n",
      "Epoch 10, Step: 711, Loss: 0.12192283570766449, Lr:0.0001\n",
      "Epoch 10, Step: 712, Loss: 0.14853425323963165, Lr:0.0001\n",
      "Epoch 10, Step: 713, Loss: 0.001995365833863616, Lr:0.0001\n",
      "Epoch 10, Step: 714, Loss: 0.048874348402023315, Lr:0.0001\n",
      "Epoch 10, Step: 715, Loss: 0.19298657774925232, Lr:0.0001\n",
      "Epoch 10, Step: 716, Loss: 0.042110588401556015, Lr:0.0001\n",
      "Epoch 10, Step: 717, Loss: 0.04798904061317444, Lr:0.0001\n",
      "Epoch 10, Step: 718, Loss: 0.20823761820793152, Lr:0.0001\n",
      "Epoch 10, Step: 719, Loss: 0.18877355754375458, Lr:0.0001\n",
      "Epoch 10, Step: 720, Loss: 0.11337687820196152, Lr:0.0001\n",
      "Epoch 10, Step: 721, Loss: 0.19461685419082642, Lr:0.0001\n",
      "Epoch 10, Step: 722, Loss: 0.5626713633537292, Lr:0.0001\n",
      "Epoch 10, Step: 723, Loss: 0.044166695326566696, Lr:0.0001\n",
      "Epoch 10, Step: 724, Loss: 0.2372160255908966, Lr:0.0001\n",
      "Epoch 10, Step: 725, Loss: 0.10506860911846161, Lr:0.0001\n",
      "Epoch 10, Step: 726, Loss: 0.09687677025794983, Lr:0.0001\n",
      "Epoch 10, Step: 727, Loss: 0.2492508441209793, Lr:0.0001\n",
      "Epoch 10, Step: 728, Loss: 0.04228748008608818, Lr:0.0001\n",
      "Epoch 10, Step: 729, Loss: 0.14371447265148163, Lr:0.0001\n",
      "Epoch 10, Step: 730, Loss: 0.0867830440402031, Lr:0.0001\n",
      "Epoch 10, Step: 731, Loss: 0.23428726196289062, Lr:0.0001\n",
      "Epoch 10, Step: 732, Loss: 0.043377526104450226, Lr:0.0001\n",
      "Epoch 10, Step: 733, Loss: 0.2063174694776535, Lr:0.0001\n",
      "Epoch 10, Step: 734, Loss: 0.29833778738975525, Lr:0.0001\n",
      "Epoch 10, Step: 735, Loss: 0.2667240500450134, Lr:0.0001\n",
      "Epoch 10, Step: 736, Loss: 0.0067099896259605885, Lr:0.0001\n",
      "Epoch 10, Step: 737, Loss: 0.4824395775794983, Lr:0.0001\n",
      "Epoch 10, Step: 738, Loss: 0.31874680519104004, Lr:0.0001\n",
      "Epoch 10, Step: 739, Loss: 0.19681547582149506, Lr:0.0001\n",
      "Epoch 10, Step: 740, Loss: 0.10674483329057693, Lr:0.0001\n",
      "Epoch 10, Step: 741, Loss: 0.18164783716201782, Lr:0.0001\n",
      "Epoch 10, Step: 742, Loss: 0.3184203803539276, Lr:0.0001\n",
      "Epoch 10, Step: 743, Loss: 0.1364302784204483, Lr:0.0001\n",
      "Epoch 10, Step: 744, Loss: 0.1878896802663803, Lr:0.0001\n",
      "Epoch 10, Step: 745, Loss: 0.10202698409557343, Lr:0.0001\n",
      "Epoch 10, Step: 746, Loss: 0.07733909040689468, Lr:0.0001\n",
      "Epoch 10, Step: 747, Loss: 0.09696422517299652, Lr:0.0001\n",
      "Epoch 10, Step: 748, Loss: 0.04670897498726845, Lr:0.0001\n",
      "Epoch 10, Step: 749, Loss: 0.09691700339317322, Lr:0.0001\n",
      "Epoch 10, Step: 750, Loss: 0.16681057214736938, Lr:0.0001\n",
      "Epoch 10, Step: 751, Loss: 0.12676595151424408, Lr:0.0001\n",
      "Epoch 10, Step: 752, Loss: 0.07156836241483688, Lr:0.0001\n",
      "Epoch 10, Step: 753, Loss: 0.047563422471284866, Lr:0.0001\n",
      "Epoch 10, Step: 754, Loss: 0.1371850073337555, Lr:0.0001\n",
      "Epoch 10, Step: 755, Loss: 0.16302043199539185, Lr:0.0001\n",
      "Epoch 10, Step: 756, Loss: 0.2015276700258255, Lr:0.0001\n",
      "Epoch 10, Step: 757, Loss: 0.06844969093799591, Lr:0.0001\n",
      "Epoch 10, Step: 758, Loss: 0.021575238555669785, Lr:0.0001\n",
      "Epoch 10, Step: 759, Loss: 0.26539355516433716, Lr:0.0001\n",
      "Epoch 10, Step: 760, Loss: 0.5023949146270752, Lr:0.0001\n",
      "Epoch 10, Step: 761, Loss: 0.12595544755458832, Lr:0.0001\n",
      "Epoch 10, Step: 762, Loss: 0.15308469533920288, Lr:0.0001\n",
      "Epoch 10, Step: 763, Loss: 0.09497631341218948, Lr:0.0001\n",
      "Epoch 10, Step: 764, Loss: 0.21437394618988037, Lr:0.0001\n",
      "Epoch 10, Step: 765, Loss: 0.1561918705701828, Lr:0.0001\n",
      "Epoch 10, Step: 766, Loss: 0.12217725068330765, Lr:0.0001\n",
      "Epoch 10, Step: 767, Loss: 0.14536960422992706, Lr:0.0001\n",
      "Epoch 10, Step: 768, Loss: 0.17682158946990967, Lr:0.0001\n",
      "Epoch 10, Step: 769, Loss: 0.13367576897144318, Lr:0.0001\n",
      "Epoch 10, Step: 770, Loss: 0.15639890730381012, Lr:0.0001\n",
      "Epoch 10, Step: 771, Loss: 0.09756322205066681, Lr:0.0001\n",
      "Epoch 10, Step: 772, Loss: 0.15186133980751038, Lr:0.0001\n",
      "Epoch 10, Step: 773, Loss: 0.11363808065652847, Lr:0.0001\n",
      "Epoch 10, Step: 774, Loss: 0.11347544193267822, Lr:0.0001\n",
      "Epoch 10, Step: 775, Loss: 0.031851626932621, Lr:0.0001\n",
      "Epoch 10, Step: 776, Loss: 0.046485237777233124, Lr:0.0001\n",
      "Epoch 10, Step: 777, Loss: 0.2894980013370514, Lr:0.0001\n",
      "Epoch 10, Step: 778, Loss: 0.6144785284996033, Lr:0.0001\n",
      "Epoch 10, Step: 779, Loss: 0.08742836117744446, Lr:0.0001\n",
      "Epoch 10, Step: 780, Loss: 0.052284762263298035, Lr:0.0001\n",
      "Epoch 10, Step: 781, Loss: 0.4789126515388489, Lr:0.0001\n",
      "Epoch 10, Step: 782, Loss: 0.3286212384700775, Lr:0.0001\n",
      "Epoch 10, Step: 783, Loss: 0.24532277882099152, Lr:0.0001\n",
      "Epoch 10, Step: 784, Loss: 0.22784337401390076, Lr:0.0001\n",
      "Epoch 10, Step: 785, Loss: 0.05011289194226265, Lr:0.0001\n",
      "Epoch 10, Step: 786, Loss: 0.05714663863182068, Lr:0.0001\n",
      "Epoch 10, Step: 787, Loss: 0.1522606760263443, Lr:0.0001\n",
      "Epoch 10, Step: 788, Loss: 0.075300432741642, Lr:0.0001\n",
      "Epoch 10, Step: 789, Loss: 0.12043668329715729, Lr:0.0001\n",
      "Epoch 10, Step: 790, Loss: 0.056936442852020264, Lr:0.0001\n",
      "Epoch 10, Step: 791, Loss: 0.22080127894878387, Lr:0.0001\n",
      "Epoch 10, Step: 792, Loss: 0.1615525335073471, Lr:0.0001\n",
      "Epoch 10, Step: 793, Loss: 0.2288966327905655, Lr:0.0001\n",
      "Epoch 10, Step: 794, Loss: 0.07004611194133759, Lr:0.0001\n",
      "Epoch 10, Step: 795, Loss: 0.08296476304531097, Lr:0.0001\n",
      "Epoch 10, Step: 796, Loss: 0.06270372867584229, Lr:0.0001\n",
      "Epoch 10, Step: 797, Loss: 0.27052053809165955, Lr:0.0001\n",
      "Epoch 10, Step: 798, Loss: 0.3640865385532379, Lr:0.0001\n",
      "Epoch 10, Step: 799, Loss: 0.16282522678375244, Lr:0.0001\n",
      "Epoch 10, Step: 800, Loss: 0.2902945876121521, Lr:0.0001\n",
      "Epoch 10, Step: 801, Loss: 0.15081945061683655, Lr:0.0001\n",
      "Epoch 10, Step: 802, Loss: 0.05184992402791977, Lr:0.0001\n",
      "Epoch 10, Step: 803, Loss: 0.11556542664766312, Lr:0.0001\n",
      "Epoch 10, Step: 804, Loss: 0.2601678669452667, Lr:0.0001\n",
      "Epoch 10, Step: 805, Loss: 0.25154709815979004, Lr:0.0001\n",
      "Epoch 10, Step: 806, Loss: 0.03251137584447861, Lr:0.0001\n",
      "Epoch 10, Step: 807, Loss: 0.10260897874832153, Lr:0.0001\n",
      "Epoch 10, Step: 808, Loss: 0.2339262068271637, Lr:0.0001\n",
      "Epoch 10, Step: 809, Loss: 0.03739422559738159, Lr:0.0001\n",
      "Epoch 10, Step: 810, Loss: 0.15244846045970917, Lr:0.0001\n",
      "Epoch 10, Step: 811, Loss: 0.14073188602924347, Lr:0.0001\n",
      "Epoch 10, Step: 812, Loss: 0.039737019687891006, Lr:0.0001\n",
      "Epoch 10, Step: 813, Loss: 0.07395701855421066, Lr:0.0001\n",
      "Epoch 10, Step: 814, Loss: 0.008542923256754875, Lr:0.0001\n",
      "Epoch 10, Step: 815, Loss: 0.3151073455810547, Lr:0.0001\n",
      "Epoch 10, Step: 816, Loss: 0.03743782639503479, Lr:0.0001\n",
      "Epoch 10, Step: 817, Loss: 0.10293210297822952, Lr:0.0001\n",
      "Epoch 10, Step: 818, Loss: 0.04515404254198074, Lr:0.0001\n",
      "Epoch 10, Step: 819, Loss: 0.052032165229320526, Lr:0.0001\n",
      "Epoch 10, Step: 820, Loss: 0.26345768570899963, Lr:0.0001\n",
      "Epoch 10, Step: 821, Loss: 0.47198545932769775, Lr:0.0001\n",
      "Epoch 10, Step: 822, Loss: 0.1698301136493683, Lr:0.0001\n",
      "Epoch 10, Step: 823, Loss: 0.22478941082954407, Lr:0.0001\n",
      "Epoch 10, Step: 824, Loss: 0.11702094227075577, Lr:0.0001\n",
      "Epoch 10, Step: 825, Loss: 0.03337527811527252, Lr:0.0001\n",
      "Epoch 10, Step: 826, Loss: 0.04409663751721382, Lr:0.0001\n",
      "Epoch 10, Step: 827, Loss: 0.18984484672546387, Lr:0.0001\n",
      "Epoch 10, Step: 828, Loss: 0.05365521088242531, Lr:0.0001\n",
      "Epoch 10, Step: 829, Loss: 0.4489189088344574, Lr:0.0001\n",
      "Epoch 10, Step: 830, Loss: 0.0992828905582428, Lr:0.0001\n",
      "Epoch 10, Step: 831, Loss: 0.3453035056591034, Lr:0.0001\n",
      "Epoch 10, Step: 832, Loss: 0.12323083728551865, Lr:0.0001\n",
      "Epoch 10, Step: 833, Loss: 0.20112596452236176, Lr:0.0001\n",
      "Epoch 10, Step: 834, Loss: 0.06022261828184128, Lr:0.0001\n",
      "Epoch 10, Step: 835, Loss: 0.28415822982788086, Lr:0.0001\n",
      "Epoch 10, Step: 836, Loss: 0.03556501492857933, Lr:0.0001\n",
      "Epoch 10, Step: 837, Loss: 0.07981622964143753, Lr:0.0001\n",
      "Epoch 10, Step: 838, Loss: 0.28350377082824707, Lr:0.0001\n",
      "Epoch 10, Step: 839, Loss: 0.23227503895759583, Lr:0.0001\n",
      "Epoch 10, Step: 840, Loss: 0.4224265515804291, Lr:0.0001\n",
      "Epoch 10, Step: 841, Loss: 0.09811405092477798, Lr:0.0001\n",
      "Epoch 10, Step: 842, Loss: 0.02504923939704895, Lr:0.0001\n",
      "Epoch 10, Step: 843, Loss: 0.27603185176849365, Lr:0.0001\n",
      "Epoch 10, Step: 844, Loss: 0.06430728733539581, Lr:0.0001\n",
      "Epoch 10, Step: 845, Loss: 0.023853326216340065, Lr:0.0001\n",
      "Epoch 10, Step: 846, Loss: 0.1778411865234375, Lr:0.0001\n",
      "Epoch 10, Step: 847, Loss: 0.014760387130081654, Lr:0.0001\n",
      "Epoch 10, Step: 848, Loss: 0.013312765397131443, Lr:0.0001\n",
      "Epoch 10, Step: 849, Loss: 0.22308608889579773, Lr:0.0001\n",
      "Epoch 10, Step: 850, Loss: 0.22720025479793549, Lr:0.0001\n",
      "Epoch 10, Step: 851, Loss: 0.06639661639928818, Lr:0.0001\n",
      "Epoch 10, Step: 852, Loss: 0.20967237651348114, Lr:0.0001\n",
      "Epoch 10, Step: 853, Loss: 0.23582686483860016, Lr:0.0001\n",
      "Epoch 10, Step: 854, Loss: 0.03255621716380119, Lr:0.0001\n",
      "Epoch 10, Step: 855, Loss: 0.2443910837173462, Lr:0.0001\n",
      "Epoch 10, Step: 856, Loss: 0.5356065630912781, Lr:0.0001\n",
      "Epoch 10, Step: 857, Loss: 0.12712052464485168, Lr:0.0001\n",
      "Epoch 10, Step: 858, Loss: 0.2985089421272278, Lr:0.0001\n",
      "Epoch 10, Step: 859, Loss: 0.1363089382648468, Lr:0.0001\n",
      "Epoch 10, Step: 860, Loss: 0.22655564546585083, Lr:0.0001\n",
      "Epoch 10, Step: 861, Loss: 0.17959730327129364, Lr:0.0001\n",
      "Epoch 10, Step: 862, Loss: 0.2122117131948471, Lr:0.0001\n",
      "Epoch 10, Step: 863, Loss: 0.09990070015192032, Lr:0.0001\n",
      "Epoch 10, Step: 864, Loss: 0.0763220265507698, Lr:0.0001\n",
      "Epoch 10, Step: 865, Loss: 0.04996313899755478, Lr:0.0001\n",
      "Epoch 10, Step: 866, Loss: 0.2252170592546463, Lr:0.0001\n",
      "Epoch 10, Step: 867, Loss: 0.2598976194858551, Lr:0.0001\n",
      "Epoch 10, Step: 868, Loss: 0.27725985646247864, Lr:0.0001\n",
      "Epoch 10, Step: 869, Loss: 0.058415692299604416, Lr:0.0001\n",
      "Epoch 10, Step: 870, Loss: 0.19899100065231323, Lr:0.0001\n",
      "Epoch 10, Step: 871, Loss: 0.15969736874103546, Lr:0.0001\n",
      "Epoch 10, Step: 872, Loss: 0.05522332713007927, Lr:0.0001\n",
      "Epoch 10, Step: 873, Loss: 0.37694522738456726, Lr:0.0001\n",
      "Epoch 10, Step: 874, Loss: 0.18320363759994507, Lr:0.0001\n",
      "Epoch 10, Step: 875, Loss: 0.27518776059150696, Lr:0.0001\n",
      "Epoch 10, Step: 876, Loss: 0.1140674501657486, Lr:0.0001\n",
      "Epoch 10, Step: 877, Loss: 0.21497571468353271, Lr:0.0001\n",
      "Epoch 10, Step: 878, Loss: 0.30308040976524353, Lr:0.0001\n",
      "Epoch 10, Step: 879, Loss: 0.3236449360847473, Lr:0.0001\n",
      "Epoch 10, Step: 880, Loss: 0.2546505928039551, Lr:0.0001\n",
      "Epoch 10, Step: 881, Loss: 0.24399149417877197, Lr:0.0001\n",
      "Epoch 10, Step: 882, Loss: 0.026460815221071243, Lr:0.0001\n",
      "Epoch 10, Step: 883, Loss: 0.42165398597717285, Lr:0.0001\n",
      "Epoch 10, Step: 884, Loss: 0.2239869236946106, Lr:0.0001\n",
      "Epoch 10, Step: 885, Loss: 0.21045732498168945, Lr:0.0001\n",
      "Epoch 10, Step: 886, Loss: 0.08425813168287277, Lr:0.0001\n",
      "Epoch 10, Step: 887, Loss: 0.18607407808303833, Lr:0.0001\n",
      "Epoch 10, Step: 888, Loss: 0.13187488913536072, Lr:0.0001\n",
      "Epoch 10, Step: 889, Loss: 0.34530165791511536, Lr:0.0001\n",
      "Epoch 10, Step: 890, Loss: 0.037444137036800385, Lr:0.0001\n",
      "Epoch 10, Step: 891, Loss: 0.10813078284263611, Lr:0.0001\n",
      "Epoch 10, Step: 892, Loss: 0.06905867904424667, Lr:0.0001\n",
      "Epoch 10, Step: 893, Loss: 0.06712164729833603, Lr:0.0001\n",
      "Epoch 10, Step: 894, Loss: 0.12159319221973419, Lr:0.0001\n",
      "Epoch 10, Step: 895, Loss: 0.015353795140981674, Lr:0.0001\n",
      "Epoch 10, Step: 896, Loss: 0.15048834681510925, Lr:0.0001\n",
      "Epoch 10, Step: 897, Loss: 0.06502319872379303, Lr:0.0001\n",
      "Epoch 10, Step: 898, Loss: 0.07440990209579468, Lr:0.0001\n",
      "Epoch 10, Step: 899, Loss: 0.08420929312705994, Lr:0.0001\n",
      "Epoch 10, Step: 900, Loss: 0.1501883864402771, Lr:0.0001\n",
      "Epoch 10, Step: 901, Loss: 0.11649403721094131, Lr:0.0001\n",
      "Epoch 10, Step: 902, Loss: 0.3623380959033966, Lr:0.0001\n",
      "Epoch 10, Step: 903, Loss: 0.21219098567962646, Lr:0.0001\n",
      "Epoch 10, Step: 904, Loss: 0.218979611992836, Lr:0.0001\n",
      "Epoch 10, Step: 905, Loss: 0.15813100337982178, Lr:0.0001\n",
      "Epoch 10, Step: 906, Loss: 0.04767569899559021, Lr:0.0001\n",
      "Epoch 10, Step: 907, Loss: 0.02535645104944706, Lr:0.0001\n",
      "Epoch 10, Step: 908, Loss: 0.19130459427833557, Lr:0.0001\n",
      "Epoch 10, Step: 909, Loss: 0.5043436288833618, Lr:0.0001\n",
      "Epoch 10, Step: 910, Loss: 0.1290271282196045, Lr:0.0001\n",
      "Epoch 10, Step: 911, Loss: 0.1636836975812912, Lr:0.0001\n",
      "Epoch 10, Step: 912, Loss: 0.3711645007133484, Lr:0.0001\n",
      "Epoch 10, Step: 913, Loss: 0.24154354631900787, Lr:0.0001\n",
      "Epoch 10, Step: 914, Loss: 0.04238348826766014, Lr:0.0001\n",
      "Epoch 10, Step: 915, Loss: 0.004731034394353628, Lr:0.0001\n",
      "Epoch 10, Step: 916, Loss: 0.16480883955955505, Lr:0.0001\n",
      "Epoch 10, Step: 917, Loss: 0.09910773485898972, Lr:0.0001\n",
      "Epoch 10, Step: 918, Loss: 0.05872643366456032, Lr:0.0001\n",
      "Epoch 10, Step: 919, Loss: 0.3792942762374878, Lr:0.0001\n",
      "Epoch 10, Step: 920, Loss: 0.12627734243869781, Lr:0.0001\n",
      "Epoch 10, Step: 921, Loss: 0.035686295479536057, Lr:0.0001\n",
      "Epoch 10, Step: 922, Loss: 0.049232762306928635, Lr:0.0001\n",
      "Epoch 10, Step: 923, Loss: 0.29357022047042847, Lr:0.0001\n",
      "Epoch 10, Step: 924, Loss: 0.1161758229136467, Lr:0.0001\n",
      "Epoch 10, Step: 925, Loss: 0.2159285843372345, Lr:0.0001\n",
      "Epoch 10, Step: 926, Loss: 0.0366625040769577, Lr:0.0001\n",
      "Epoch 10, Step: 927, Loss: 0.53329998254776, Lr:0.0001\n",
      "Epoch 10, Step: 928, Loss: 0.07111192494630814, Lr:0.0001\n",
      "Epoch 10, Step: 929, Loss: 0.2851375937461853, Lr:0.0001\n",
      "Epoch 10, Step: 930, Loss: 0.1399441510438919, Lr:0.0001\n",
      "Epoch 10, Step: 931, Loss: 0.07080373167991638, Lr:0.0001\n",
      "Epoch 10, Step: 932, Loss: 0.027236122637987137, Lr:0.0001\n",
      "Epoch 10, Step: 933, Loss: 0.09292004257440567, Lr:0.0001\n",
      "Epoch 10, Step: 934, Loss: 0.17283082008361816, Lr:0.0001\n",
      "Epoch 10, Step: 935, Loss: 0.1301913857460022, Lr:0.0001\n",
      "Epoch 10, Step: 936, Loss: 0.14238803088665009, Lr:0.0001\n",
      "Epoch 10, Step: 937, Loss: 0.2553764283657074, Lr:0.0001\n",
      "Epoch 10, Step: 938, Loss: 0.14297690987586975, Lr:0.0001\n",
      "Epoch 10, Step: 939, Loss: 0.14747191965579987, Lr:0.0001\n",
      "Epoch 10, Step: 940, Loss: 0.13849951326847076, Lr:0.0001\n",
      "Epoch 10, Step: 941, Loss: 0.15149305760860443, Lr:0.0001\n",
      "Epoch 10, Step: 942, Loss: 0.10941237211227417, Lr:0.0001\n",
      "Epoch 10, Step: 943, Loss: 0.23572306334972382, Lr:0.0001\n",
      "Epoch 10, Step: 944, Loss: 0.18282872438430786, Lr:0.0001\n",
      "Epoch 10, Step: 945, Loss: 0.1356169581413269, Lr:0.0001\n",
      "Epoch 10, Step: 946, Loss: 0.04443172737956047, Lr:0.0001\n",
      "Epoch 10, Step: 947, Loss: 0.08166725188493729, Lr:0.0001\n",
      "Epoch 10, Step: 948, Loss: 0.18072964251041412, Lr:0.0001\n",
      "Epoch 10, Step: 949, Loss: 0.16385944187641144, Lr:0.0001\n",
      "Epoch 10, Step: 950, Loss: 0.13757933676242828, Lr:0.0001\n",
      "Epoch 10, Step: 951, Loss: 0.09220435470342636, Lr:0.0001\n",
      "Epoch 10, Step: 952, Loss: 0.08819279819726944, Lr:0.0001\n",
      "Epoch 10, Step: 953, Loss: 0.26285624504089355, Lr:0.0001\n",
      "Epoch 10, Step: 954, Loss: 0.04688195139169693, Lr:0.0001\n",
      "Epoch 10, Step: 955, Loss: 0.12551134824752808, Lr:0.0001\n",
      "Epoch 10, Step: 956, Loss: 0.3314445912837982, Lr:0.0001\n",
      "Epoch 10, Step: 957, Loss: 0.03968275710940361, Lr:0.0001\n",
      "Epoch 10, Step: 958, Loss: 0.17642436921596527, Lr:0.0001\n",
      "Epoch 10, Step: 959, Loss: 0.0033970207441598177, Lr:0.0001\n",
      "Epoch 10, Step: 960, Loss: 0.2730746269226074, Lr:0.0001\n",
      "Epoch 10, Step: 961, Loss: 0.02023717574775219, Lr:0.0001\n",
      "Epoch 10, Step: 962, Loss: 0.14945495128631592, Lr:0.0001\n",
      "Epoch 10, Step: 963, Loss: 0.274947851896286, Lr:0.0001\n",
      "Epoch 10, Step: 964, Loss: 0.32735583186149597, Lr:0.0001\n",
      "Epoch 10, Step: 965, Loss: 0.09468912333250046, Lr:0.0001\n",
      "Epoch 10, Step: 966, Loss: 0.11338214576244354, Lr:0.0001\n",
      "Epoch 10, Step: 967, Loss: 0.1410282850265503, Lr:0.0001\n",
      "Epoch 10, Step: 968, Loss: 0.1526268720626831, Lr:0.0001\n",
      "Epoch 10, Step: 969, Loss: 0.2543192505836487, Lr:0.0001\n",
      "Epoch 10, Step: 970, Loss: 0.27189862728118896, Lr:0.0001\n",
      "Epoch 10, Step: 971, Loss: 0.1369086354970932, Lr:0.0001\n",
      "Epoch 10, Step: 972, Loss: 0.09781916439533234, Lr:0.0001\n",
      "Epoch 10, Step: 973, Loss: 0.024967331439256668, Lr:0.0001\n",
      "Epoch 10, Step: 974, Loss: 0.056784600019454956, Lr:0.0001\n",
      "Epoch 10, Step: 975, Loss: 0.11180086433887482, Lr:0.0001\n",
      "Epoch 10, Step: 976, Loss: 0.027692699804902077, Lr:0.0001\n",
      "Epoch 10, Step: 977, Loss: 0.022022338584065437, Lr:0.0001\n",
      "Epoch 10, Step: 978, Loss: 0.2967858612537384, Lr:0.0001\n",
      "Epoch 10, Step: 979, Loss: 0.25120705366134644, Lr:0.0001\n",
      "Epoch 10, Step: 980, Loss: 0.21055801212787628, Lr:0.0001\n",
      "Epoch 10, Step: 981, Loss: 0.08426878601312637, Lr:0.0001\n",
      "Epoch 10, Step: 982, Loss: 0.33049046993255615, Lr:0.0001\n",
      "Epoch 10, Step: 983, Loss: 0.11040510982275009, Lr:0.0001\n",
      "Epoch 10, Step: 984, Loss: 0.14268672466278076, Lr:0.0001\n",
      "Epoch 10, Step: 985, Loss: 0.1753598004579544, Lr:0.0001\n",
      "Epoch 10, Step: 986, Loss: 0.1459892988204956, Lr:0.0001\n",
      "Epoch 10, Step: 987, Loss: 0.10047699511051178, Lr:0.0001\n",
      "Epoch 10, Step: 988, Loss: 0.08055810630321503, Lr:0.0001\n",
      "Epoch 10, Step: 989, Loss: 0.12729902565479279, Lr:0.0001\n",
      "Epoch 10, Step: 990, Loss: 0.05230122432112694, Lr:0.0001\n",
      "Epoch 10, Step: 991, Loss: 0.03511852025985718, Lr:0.0001\n",
      "Epoch 10, Step: 992, Loss: 0.17763444781303406, Lr:0.0001\n",
      "Epoch 10, Step: 993, Loss: 0.11792560666799545, Lr:0.0001\n",
      "Epoch 10, Step: 994, Loss: 0.2200252264738083, Lr:0.0001\n",
      "Epoch 10, Step: 995, Loss: 0.09121158719062805, Lr:0.0001\n",
      "Epoch 10, Step: 996, Loss: 0.0636037290096283, Lr:0.0001\n",
      "Epoch 10, Step: 997, Loss: 0.07333995401859283, Lr:0.0001\n",
      "Epoch 10, Step: 998, Loss: 0.11959129571914673, Lr:0.0001\n",
      "Epoch 10, Step: 999, Loss: 0.1789710819721222, Lr:0.0001\n",
      "Epoch 10, Step: 1000, Loss: 0.22780582308769226, Lr:0.0001\n",
      "Epoch 10, Step: 1001, Loss: 0.23474082350730896, Lr:0.0001\n",
      "Epoch 10, Step: 1002, Loss: 0.3336125314235687, Lr:0.0001\n",
      "Epoch 10, Step: 1003, Loss: 0.48539698123931885, Lr:0.0001\n",
      "Epoch 10, Step: 1004, Loss: 0.16818025708198547, Lr:0.0001\n",
      "Epoch 10, Step: 1005, Loss: 0.07930371165275574, Lr:0.0001\n",
      "Epoch 10, Step: 1006, Loss: 0.10186679661273956, Lr:0.0001\n",
      "Epoch 10, Step: 1007, Loss: 0.16107980906963348, Lr:0.0001\n",
      "Epoch 10, Step: 1008, Loss: 0.03391643613576889, Lr:0.0001\n",
      "Epoch 10, Step: 1009, Loss: 0.2604503333568573, Lr:0.0001\n",
      "Epoch 10, Step: 1010, Loss: 0.10556177794933319, Lr:0.0001\n",
      "Epoch 10, Step: 1011, Loss: 0.02104421705007553, Lr:0.0001\n",
      "Epoch 10, Step: 1012, Loss: 0.42719757556915283, Lr:0.0001\n",
      "Epoch 10, Step: 1013, Loss: 0.024642707780003548, Lr:0.0001\n",
      "Epoch 10, Step: 1014, Loss: 0.0732993334531784, Lr:0.0001\n",
      "Epoch 10, Step: 1015, Loss: 0.3027108311653137, Lr:0.0001\n",
      "Epoch 10, Step: 1016, Loss: 0.25231024622917175, Lr:0.0001\n",
      "Epoch 10, Step: 1017, Loss: 0.06638994812965393, Lr:0.0001\n",
      "Epoch 10, Step: 1018, Loss: 0.024680713191628456, Lr:0.0001\n",
      "Epoch 10, Step: 1019, Loss: 0.11121106892824173, Lr:0.0001\n",
      "Epoch 10, Step: 1020, Loss: 0.15322169661521912, Lr:0.0001\n",
      "Epoch 10, Step: 1021, Loss: 0.05650133267045021, Lr:0.0001\n",
      "Epoch 10, Step: 1022, Loss: 0.050240613520145416, Lr:0.0001\n",
      "Epoch 10, Step: 1023, Loss: 0.14360599219799042, Lr:0.0001\n",
      "Epoch 10, Step: 1024, Loss: 0.05941865220665932, Lr:0.0001\n",
      "Epoch 10, Step: 1025, Loss: 0.09480588883161545, Lr:0.0001\n",
      "Epoch 10, Step: 1026, Loss: 0.09107567369937897, Lr:0.0001\n",
      "Epoch 10, Step: 1027, Loss: 0.10438071936368942, Lr:0.0001\n",
      "Epoch 10, Step: 1028, Loss: 0.0260043665766716, Lr:0.0001\n",
      "Epoch 10, Step: 1029, Loss: 0.08504267036914825, Lr:0.0001\n",
      "Epoch 10, Step: 1030, Loss: 0.10062974691390991, Lr:0.0001\n",
      "Epoch 10, Step: 1031, Loss: 0.039507120847702026, Lr:0.0001\n",
      "Epoch 10, Step: 1032, Loss: 0.18429872393608093, Lr:0.0001\n",
      "Epoch 10, Step: 1033, Loss: 0.0443723089993, Lr:0.0001\n",
      "Epoch 10, Step: 1034, Loss: 0.08800025284290314, Lr:0.0001\n",
      "Epoch 10, Step: 1035, Loss: 0.12037920206785202, Lr:0.0001\n",
      "Epoch 10, Step: 1036, Loss: 0.09783776104450226, Lr:0.0001\n",
      "Epoch 10, Step: 1037, Loss: 0.09894656389951706, Lr:0.0001\n",
      "Epoch 10, Step: 1038, Loss: 0.4929649829864502, Lr:0.0001\n",
      "Epoch 10, Step: 1039, Loss: 0.4102478325366974, Lr:0.0001\n",
      "Epoch 10, Step: 1040, Loss: 0.18908245861530304, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 10\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:15 loss: 0.0199 (0.0199) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.2795 data: 0.1130 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:12 loss: 0.0002 (0.0021) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.2796 data: 0.1078 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0002 (0.0492) acc1: 100.0000 (98.8095) acc5: 100.0000 (100.0000) time: 0.2842 data: 0.1095 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.0356 (0.1492) acc1: 93.7500 (94.5565) acc5: 100.0000 (100.0000) time: 0.2883 data: 0.1117 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.2512 (0.1593) acc1: 87.5000 (93.7500) acc5: 100.0000 (100.0000) time: 0.2875 data: 0.1120 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0292 (0.1448) acc1: 100.0000 (94.3627) acc5: 100.0000 (100.0000) time: 0.2865 data: 0.1118 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0193 (0.1456) acc1: 100.0000 (94.5516) acc5: 100.0000 (100.0000) time: 0.2734 data: 0.1061 max mem: 15137\n",
      "Test: Total time: 0:00:15 (0.2808 s / it)\n",
      "* Acc@1 94.552 Acc@5 100.000 loss 0.146\n",
      "Accuracy of the network on the 881 test image: 94.6%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 11, Step: 0, Loss: 0.05752059444785118, Lr:0.0001\n",
      "Epoch 11, Step: 1, Loss: 0.20279644429683685, Lr:0.0001\n",
      "Epoch 11, Step: 2, Loss: 0.23129941523075104, Lr:0.0001\n",
      "Epoch 11, Step: 3, Loss: 0.1024947464466095, Lr:0.0001\n",
      "Epoch 11, Step: 4, Loss: 0.08617117255926132, Lr:0.0001\n",
      "Epoch 11, Step: 5, Loss: 0.01628667302429676, Lr:0.0001\n",
      "Epoch 11, Step: 6, Loss: 0.15059402585029602, Lr:0.0001\n",
      "Epoch 11, Step: 7, Loss: 0.22370107471942902, Lr:0.0001\n",
      "Epoch 11, Step: 8, Loss: 0.07444370537996292, Lr:0.0001\n",
      "Epoch 11, Step: 9, Loss: 0.01935495063662529, Lr:0.0001\n",
      "Epoch 11, Step: 10, Loss: 0.07676807045936584, Lr:0.0001\n",
      "Epoch 11, Step: 11, Loss: 0.02661542035639286, Lr:0.0001\n",
      "Epoch 11, Step: 12, Loss: 0.06627237051725388, Lr:0.0001\n",
      "Epoch 11, Step: 13, Loss: 0.280592143535614, Lr:0.0001\n",
      "Epoch 11, Step: 14, Loss: 0.07275360077619553, Lr:0.0001\n",
      "Epoch 11, Step: 15, Loss: 0.06913930922746658, Lr:0.0001\n",
      "Epoch 11, Step: 16, Loss: 0.0782477930188179, Lr:0.0001\n",
      "Epoch 11, Step: 17, Loss: 0.1281985491514206, Lr:0.0001\n",
      "Epoch 11, Step: 18, Loss: 0.364602267742157, Lr:0.0001\n",
      "Epoch 11, Step: 19, Loss: 0.10524424910545349, Lr:0.0001\n",
      "Epoch 11, Step: 20, Loss: 0.15883785486221313, Lr:0.0001\n",
      "Epoch 11, Step: 21, Loss: 0.2025785893201828, Lr:0.0001\n",
      "Epoch 11, Step: 22, Loss: 0.19717536866664886, Lr:0.0001\n",
      "Epoch 11, Step: 23, Loss: 0.017010755836963654, Lr:0.0001\n",
      "Epoch 11, Step: 24, Loss: 0.07616646587848663, Lr:0.0001\n",
      "Epoch 11, Step: 25, Loss: 0.024633852764964104, Lr:0.0001\n",
      "Epoch 11, Step: 26, Loss: 0.14086437225341797, Lr:0.0001\n",
      "Epoch 11, Step: 27, Loss: 0.1384425312280655, Lr:0.0001\n",
      "Epoch 11, Step: 28, Loss: 0.16978706419467926, Lr:0.0001\n",
      "Epoch 11, Step: 29, Loss: 0.13884340226650238, Lr:0.0001\n",
      "Epoch 11, Step: 30, Loss: 0.019787654280662537, Lr:0.0001\n",
      "Epoch 11, Step: 31, Loss: 0.03648867458105087, Lr:0.0001\n",
      "Epoch 11, Step: 32, Loss: 0.14884665608406067, Lr:0.0001\n",
      "Epoch 11, Step: 33, Loss: 0.173002228140831, Lr:0.0001\n",
      "Epoch 11, Step: 34, Loss: 0.14178095757961273, Lr:0.0001\n",
      "Epoch 11, Step: 35, Loss: 0.0183964092284441, Lr:0.0001\n",
      "Epoch 11, Step: 36, Loss: 0.08171544969081879, Lr:0.0001\n",
      "Epoch 11, Step: 37, Loss: 0.015677878633141518, Lr:0.0001\n",
      "Epoch 11, Step: 38, Loss: 0.06756135821342468, Lr:0.0001\n",
      "Epoch 11, Step: 39, Loss: 0.18532177805900574, Lr:0.0001\n",
      "Epoch 11, Step: 40, Loss: 0.10938292741775513, Lr:0.0001\n",
      "Epoch 11, Step: 41, Loss: 0.17306481301784515, Lr:0.0001\n",
      "Epoch 11, Step: 42, Loss: 0.15876661241054535, Lr:0.0001\n",
      "Epoch 11, Step: 43, Loss: 0.10773912072181702, Lr:0.0001\n",
      "Epoch 11, Step: 44, Loss: 0.338768869638443, Lr:0.0001\n",
      "Epoch 11, Step: 45, Loss: 0.03661671280860901, Lr:0.0001\n",
      "Epoch 11, Step: 46, Loss: 0.04616517573595047, Lr:0.0001\n",
      "Epoch 11, Step: 47, Loss: 0.06261605769395828, Lr:0.0001\n",
      "Epoch 11, Step: 48, Loss: 0.17841175198554993, Lr:0.0001\n",
      "Epoch 11, Step: 49, Loss: 0.2064134031534195, Lr:0.0001\n",
      "Epoch 11, Step: 50, Loss: 0.20842555165290833, Lr:0.0001\n",
      "Epoch 11, Step: 51, Loss: 0.021706076338887215, Lr:0.0001\n",
      "Epoch 11, Step: 52, Loss: 0.1172032505273819, Lr:0.0001\n",
      "Epoch 11, Step: 53, Loss: 0.07671595364809036, Lr:0.0001\n",
      "Epoch 11, Step: 54, Loss: 0.048638083040714264, Lr:0.0001\n",
      "Epoch 11, Step: 55, Loss: 0.02855999395251274, Lr:0.0001\n",
      "Epoch 11, Step: 56, Loss: 0.08190496265888214, Lr:0.0001\n",
      "Epoch 11, Step: 57, Loss: 0.05004052817821503, Lr:0.0001\n",
      "Epoch 11, Step: 58, Loss: 0.5632933378219604, Lr:0.0001\n",
      "Epoch 11, Step: 59, Loss: 0.06842009723186493, Lr:0.0001\n",
      "Epoch 11, Step: 60, Loss: 0.15347830951213837, Lr:0.0001\n",
      "Epoch 11, Step: 61, Loss: 0.2275141179561615, Lr:0.0001\n",
      "Epoch 11, Step: 62, Loss: 0.029706906527280807, Lr:0.0001\n",
      "Epoch 11, Step: 63, Loss: 0.23213249444961548, Lr:0.0001\n",
      "Epoch 11, Step: 64, Loss: 0.04448807239532471, Lr:0.0001\n",
      "Epoch 11, Step: 65, Loss: 0.1279710829257965, Lr:0.0001\n",
      "Epoch 11, Step: 66, Loss: 0.3110816180706024, Lr:0.0001\n",
      "Epoch 11, Step: 67, Loss: 0.3305596113204956, Lr:0.0001\n",
      "Epoch 11, Step: 68, Loss: 0.0911819264292717, Lr:0.0001\n",
      "Epoch 11, Step: 69, Loss: 0.027870632708072662, Lr:0.0001\n",
      "Epoch 11, Step: 70, Loss: 0.07929713279008865, Lr:0.0001\n",
      "Epoch 11, Step: 71, Loss: 0.08807655423879623, Lr:0.0001\n",
      "Epoch 11, Step: 72, Loss: 0.0866362452507019, Lr:0.0001\n",
      "Epoch 11, Step: 73, Loss: 0.16297507286071777, Lr:0.0001\n",
      "Epoch 11, Step: 74, Loss: 0.06135053187608719, Lr:0.0001\n",
      "Epoch 11, Step: 75, Loss: 0.25327667593955994, Lr:0.0001\n",
      "Epoch 11, Step: 76, Loss: 0.25009170174598694, Lr:0.0001\n",
      "Epoch 11, Step: 77, Loss: 0.21718011796474457, Lr:0.0001\n",
      "Epoch 11, Step: 78, Loss: 0.0861659049987793, Lr:0.0001\n",
      "Epoch 11, Step: 79, Loss: 0.1785110980272293, Lr:0.0001\n",
      "Epoch 11, Step: 80, Loss: 0.26616114377975464, Lr:0.0001\n",
      "Epoch 11, Step: 81, Loss: 0.10873745381832123, Lr:0.0001\n",
      "Epoch 11, Step: 82, Loss: 0.046442411839962006, Lr:0.0001\n",
      "Epoch 11, Step: 83, Loss: 0.12694372236728668, Lr:0.0001\n",
      "Epoch 11, Step: 84, Loss: 0.12950406968593597, Lr:0.0001\n",
      "Epoch 11, Step: 85, Loss: 0.2121213972568512, Lr:0.0001\n",
      "Epoch 11, Step: 86, Loss: 0.1159413754940033, Lr:0.0001\n",
      "Epoch 11, Step: 87, Loss: 0.03346369415521622, Lr:0.0001\n",
      "Epoch 11, Step: 88, Loss: 0.08619475364685059, Lr:0.0001\n",
      "Epoch 11, Step: 89, Loss: 0.25486573576927185, Lr:0.0001\n",
      "Epoch 11, Step: 90, Loss: 0.10316529870033264, Lr:0.0001\n",
      "Epoch 11, Step: 91, Loss: 0.0059145716950297356, Lr:0.0001\n",
      "Epoch 11, Step: 92, Loss: 0.009504356421530247, Lr:0.0001\n",
      "Epoch 11, Step: 93, Loss: 0.036145467311143875, Lr:0.0001\n",
      "Epoch 11, Step: 94, Loss: 0.3889753520488739, Lr:0.0001\n",
      "Epoch 11, Step: 95, Loss: 0.004693875089287758, Lr:0.0001\n",
      "Epoch 11, Step: 96, Loss: 0.06048938259482384, Lr:0.0001\n",
      "Epoch 11, Step: 97, Loss: 0.10745396465063095, Lr:0.0001\n",
      "Epoch 11, Step: 98, Loss: 0.03722954913973808, Lr:0.0001\n",
      "Epoch 11, Step: 99, Loss: 0.18974924087524414, Lr:0.0001\n",
      "Epoch 11, Step: 100, Loss: 0.0370207317173481, Lr:0.0001\n",
      "Epoch 11, Step: 101, Loss: 0.13279613852500916, Lr:0.0001\n",
      "Epoch 11, Step: 102, Loss: 0.09401004016399384, Lr:0.0001\n",
      "Epoch 11, Step: 103, Loss: 0.07654976844787598, Lr:0.0001\n",
      "Epoch 11, Step: 104, Loss: 0.016352225095033646, Lr:0.0001\n",
      "Epoch 11, Step: 105, Loss: 0.13744176924228668, Lr:0.0001\n",
      "Epoch 11, Step: 106, Loss: 0.19487591087818146, Lr:0.0001\n",
      "Epoch 11, Step: 107, Loss: 0.49425607919692993, Lr:0.0001\n",
      "Epoch 11, Step: 108, Loss: 0.25331151485443115, Lr:0.0001\n",
      "Epoch 11, Step: 109, Loss: 0.22656992077827454, Lr:0.0001\n",
      "Epoch 11, Step: 110, Loss: 0.08709795027971268, Lr:0.0001\n",
      "Epoch 11, Step: 111, Loss: 0.0601816289126873, Lr:0.0001\n",
      "Epoch 11, Step: 112, Loss: 0.08394745737314224, Lr:0.0001\n",
      "Epoch 11, Step: 113, Loss: 0.4307362735271454, Lr:0.0001\n",
      "Epoch 11, Step: 114, Loss: 0.29695412516593933, Lr:0.0001\n",
      "Epoch 11, Step: 115, Loss: 0.32394808530807495, Lr:0.0001\n",
      "Epoch 11, Step: 116, Loss: 0.19235412776470184, Lr:0.0001\n",
      "Epoch 11, Step: 117, Loss: 0.038354381918907166, Lr:0.0001\n",
      "Epoch 11, Step: 118, Loss: 0.18370120227336884, Lr:0.0001\n",
      "Epoch 11, Step: 119, Loss: 0.036230333149433136, Lr:0.0001\n",
      "Epoch 11, Step: 120, Loss: 0.0748835951089859, Lr:0.0001\n",
      "Epoch 11, Step: 121, Loss: 0.04730460047721863, Lr:0.0001\n",
      "Epoch 11, Step: 122, Loss: 0.02648761309683323, Lr:0.0001\n",
      "Epoch 11, Step: 123, Loss: 0.004320099018514156, Lr:0.0001\n",
      "Epoch 11, Step: 124, Loss: 0.47666284441947937, Lr:0.0001\n",
      "Epoch 11, Step: 125, Loss: 0.13744990527629852, Lr:0.0001\n",
      "Epoch 11, Step: 126, Loss: 0.04331624507904053, Lr:0.0001\n",
      "Epoch 11, Step: 127, Loss: 0.17262575030326843, Lr:0.0001\n",
      "Epoch 11, Step: 128, Loss: 0.18843930959701538, Lr:0.0001\n",
      "Epoch 11, Step: 129, Loss: 0.13986648619174957, Lr:0.0001\n",
      "Epoch 11, Step: 130, Loss: 0.05386628955602646, Lr:0.0001\n",
      "Epoch 11, Step: 131, Loss: 0.3924543857574463, Lr:0.0001\n",
      "Epoch 11, Step: 132, Loss: 0.05330495536327362, Lr:0.0001\n",
      "Epoch 11, Step: 133, Loss: 0.18519000709056854, Lr:0.0001\n",
      "Epoch 11, Step: 134, Loss: 0.14295390248298645, Lr:0.0001\n",
      "Epoch 11, Step: 135, Loss: 0.09503251314163208, Lr:0.0001\n",
      "Epoch 11, Step: 136, Loss: 0.03688816726207733, Lr:0.0001\n",
      "Epoch 11, Step: 137, Loss: 0.03677754104137421, Lr:0.0001\n",
      "Epoch 11, Step: 138, Loss: 0.09243354201316833, Lr:0.0001\n",
      "Epoch 11, Step: 139, Loss: 0.09737672656774521, Lr:0.0001\n",
      "Epoch 11, Step: 140, Loss: 0.033615730702877045, Lr:0.0001\n",
      "Epoch 11, Step: 141, Loss: 0.04200361296534538, Lr:0.0001\n",
      "Epoch 11, Step: 142, Loss: 0.053962815552949905, Lr:0.0001\n",
      "Epoch 11, Step: 143, Loss: 0.4446958601474762, Lr:0.0001\n",
      "Epoch 11, Step: 144, Loss: 0.019451754167675972, Lr:0.0001\n",
      "Epoch 11, Step: 145, Loss: 0.21128946542739868, Lr:0.0001\n",
      "Epoch 11, Step: 146, Loss: 0.060715191066265106, Lr:0.0001\n",
      "Epoch 11, Step: 147, Loss: 0.19226093590259552, Lr:0.0001\n",
      "Epoch 11, Step: 148, Loss: 0.15978413820266724, Lr:0.0001\n",
      "Epoch 11, Step: 149, Loss: 0.16051895916461945, Lr:0.0001\n",
      "Epoch 11, Step: 150, Loss: 0.1452420949935913, Lr:0.0001\n",
      "Epoch 11, Step: 151, Loss: 0.29851871728897095, Lr:0.0001\n",
      "Epoch 11, Step: 152, Loss: 0.10389202833175659, Lr:0.0001\n",
      "Epoch 11, Step: 153, Loss: 0.06361998617649078, Lr:0.0001\n",
      "Epoch 11, Step: 154, Loss: 0.0756164938211441, Lr:0.0001\n",
      "Epoch 11, Step: 155, Loss: 0.041254881769418716, Lr:0.0001\n",
      "Epoch 11, Step: 156, Loss: 0.017817111685872078, Lr:0.0001\n",
      "Epoch 11, Step: 157, Loss: 0.47666314244270325, Lr:0.0001\n",
      "Epoch 11, Step: 158, Loss: 0.03755713626742363, Lr:0.0001\n",
      "Epoch 11, Step: 159, Loss: 0.13577911257743835, Lr:0.0001\n",
      "Epoch 11, Step: 160, Loss: 0.13249319791793823, Lr:0.0001\n",
      "Epoch 11, Step: 161, Loss: 0.36337631940841675, Lr:0.0001\n",
      "Epoch 11, Step: 162, Loss: 0.1401912420988083, Lr:0.0001\n",
      "Epoch 11, Step: 163, Loss: 0.088946133852005, Lr:0.0001\n",
      "Epoch 11, Step: 164, Loss: 0.10020118951797485, Lr:0.0001\n",
      "Epoch 11, Step: 165, Loss: 0.11855092644691467, Lr:0.0001\n",
      "Epoch 11, Step: 166, Loss: 0.16234135627746582, Lr:0.0001\n",
      "Epoch 11, Step: 167, Loss: 0.20169095695018768, Lr:0.0001\n",
      "Epoch 11, Step: 168, Loss: 0.14411109685897827, Lr:0.0001\n",
      "Epoch 11, Step: 169, Loss: 0.08265369385480881, Lr:0.0001\n",
      "Epoch 11, Step: 170, Loss: 0.03595709055662155, Lr:0.0001\n",
      "Epoch 11, Step: 171, Loss: 0.17921391129493713, Lr:0.0001\n",
      "Epoch 11, Step: 172, Loss: 0.03126990795135498, Lr:0.0001\n",
      "Epoch 11, Step: 173, Loss: 0.06979356706142426, Lr:0.0001\n",
      "Epoch 11, Step: 174, Loss: 0.156904399394989, Lr:0.0001\n",
      "Epoch 11, Step: 175, Loss: 0.13692891597747803, Lr:0.0001\n",
      "Epoch 11, Step: 176, Loss: 0.3649711012840271, Lr:0.0001\n",
      "Epoch 11, Step: 177, Loss: 0.030438465997576714, Lr:0.0001\n",
      "Epoch 11, Step: 178, Loss: 0.07085883617401123, Lr:0.0001\n",
      "Epoch 11, Step: 179, Loss: 0.14092044532299042, Lr:0.0001\n",
      "Epoch 11, Step: 180, Loss: 0.12441328167915344, Lr:0.0001\n",
      "Epoch 11, Step: 181, Loss: 0.12321676313877106, Lr:0.0001\n",
      "Epoch 11, Step: 182, Loss: 0.3120753765106201, Lr:0.0001\n",
      "Epoch 11, Step: 183, Loss: 0.047003500163555145, Lr:0.0001\n",
      "Epoch 11, Step: 184, Loss: 0.10094934701919556, Lr:0.0001\n",
      "Epoch 11, Step: 185, Loss: 0.21591967344284058, Lr:0.0001\n",
      "Epoch 11, Step: 186, Loss: 0.05414740741252899, Lr:0.0001\n",
      "Epoch 11, Step: 187, Loss: 0.1019878163933754, Lr:0.0001\n",
      "Epoch 11, Step: 188, Loss: 0.043897274881601334, Lr:0.0001\n",
      "Epoch 11, Step: 189, Loss: 0.113186314702034, Lr:0.0001\n",
      "Epoch 11, Step: 190, Loss: 0.09808430075645447, Lr:0.0001\n",
      "Epoch 11, Step: 191, Loss: 0.25403663516044617, Lr:0.0001\n",
      "Epoch 11, Step: 192, Loss: 0.3435302674770355, Lr:0.0001\n",
      "Epoch 11, Step: 193, Loss: 0.22820943593978882, Lr:0.0001\n",
      "Epoch 11, Step: 194, Loss: 0.07889685779809952, Lr:0.0001\n",
      "Epoch 11, Step: 195, Loss: 0.09547560662031174, Lr:0.0001\n",
      "Epoch 11, Step: 196, Loss: 0.10452644526958466, Lr:0.0001\n",
      "Epoch 11, Step: 197, Loss: 0.03684921935200691, Lr:0.0001\n",
      "Epoch 11, Step: 198, Loss: 0.014246933162212372, Lr:0.0001\n",
      "Epoch 11, Step: 199, Loss: 0.16549408435821533, Lr:0.0001\n",
      "Epoch 11, Step: 200, Loss: 0.09690297394990921, Lr:0.0001\n",
      "Epoch 11, Step: 201, Loss: 0.3200514614582062, Lr:0.0001\n",
      "Epoch 11, Step: 202, Loss: 0.16974321007728577, Lr:0.0001\n",
      "Epoch 11, Step: 203, Loss: 0.13292387127876282, Lr:0.0001\n",
      "Epoch 11, Step: 204, Loss: 0.04602811858057976, Lr:0.0001\n",
      "Epoch 11, Step: 205, Loss: 0.050087373703718185, Lr:0.0001\n",
      "Epoch 11, Step: 206, Loss: 0.06253375113010406, Lr:0.0001\n",
      "Epoch 11, Step: 207, Loss: 0.06413491070270538, Lr:0.0001\n",
      "Epoch 11, Step: 208, Loss: 0.015085883438587189, Lr:0.0001\n",
      "Epoch 11, Step: 209, Loss: 0.050507642328739166, Lr:0.0001\n",
      "Epoch 11, Step: 210, Loss: 0.23098471760749817, Lr:0.0001\n",
      "Epoch 11, Step: 211, Loss: 0.03236960247159004, Lr:0.0001\n",
      "Epoch 11, Step: 212, Loss: 0.19671200215816498, Lr:0.0001\n",
      "Epoch 11, Step: 213, Loss: 0.06247621029615402, Lr:0.0001\n",
      "Epoch 11, Step: 214, Loss: 0.15005487203598022, Lr:0.0001\n",
      "Epoch 11, Step: 215, Loss: 0.08302857726812363, Lr:0.0001\n",
      "Epoch 11, Step: 216, Loss: 0.09266043454408646, Lr:0.0001\n",
      "Epoch 11, Step: 217, Loss: 0.03494288772344589, Lr:0.0001\n",
      "Epoch 11, Step: 218, Loss: 0.20865385234355927, Lr:0.0001\n",
      "Epoch 11, Step: 219, Loss: 0.6734671592712402, Lr:0.0001\n",
      "Epoch 11, Step: 220, Loss: 0.20927876234054565, Lr:0.0001\n",
      "Epoch 11, Step: 221, Loss: 0.1155337244272232, Lr:0.0001\n",
      "Epoch 11, Step: 222, Loss: 0.28581857681274414, Lr:0.0001\n",
      "Epoch 11, Step: 223, Loss: 0.17113097012043, Lr:0.0001\n",
      "Epoch 11, Step: 224, Loss: 0.03765249252319336, Lr:0.0001\n",
      "Epoch 11, Step: 225, Loss: 0.025568928569555283, Lr:0.0001\n",
      "Epoch 11, Step: 226, Loss: 0.022683793678879738, Lr:0.0001\n",
      "Epoch 11, Step: 227, Loss: 0.04038291797041893, Lr:0.0001\n",
      "Epoch 11, Step: 228, Loss: 0.03683957830071449, Lr:0.0001\n",
      "Epoch 11, Step: 229, Loss: 0.052324019372463226, Lr:0.0001\n",
      "Epoch 11, Step: 230, Loss: 0.09241502732038498, Lr:0.0001\n",
      "Epoch 11, Step: 231, Loss: 0.28972673416137695, Lr:0.0001\n",
      "Epoch 11, Step: 232, Loss: 0.03911586478352547, Lr:0.0001\n",
      "Epoch 11, Step: 233, Loss: 0.15426704287528992, Lr:0.0001\n",
      "Epoch 11, Step: 234, Loss: 0.0464911162853241, Lr:0.0001\n",
      "Epoch 11, Step: 235, Loss: 0.23975695669651031, Lr:0.0001\n",
      "Epoch 11, Step: 236, Loss: 0.04782984405755997, Lr:0.0001\n",
      "Epoch 11, Step: 237, Loss: 0.09320434182882309, Lr:0.0001\n",
      "Epoch 11, Step: 238, Loss: 0.12056980282068253, Lr:0.0001\n",
      "Epoch 11, Step: 239, Loss: 0.457462877035141, Lr:0.0001\n",
      "Epoch 11, Step: 240, Loss: 0.06826078146696091, Lr:0.0001\n",
      "Epoch 11, Step: 241, Loss: 0.03809593617916107, Lr:0.0001\n",
      "Epoch 11, Step: 242, Loss: 0.22153431177139282, Lr:0.0001\n",
      "Epoch 11, Step: 243, Loss: 0.1507035195827484, Lr:0.0001\n",
      "Epoch 11, Step: 244, Loss: 0.2731631100177765, Lr:0.0001\n",
      "Epoch 11, Step: 245, Loss: 0.08777876198291779, Lr:0.0001\n",
      "Epoch 11, Step: 246, Loss: 0.48762181401252747, Lr:0.0001\n",
      "Epoch 11, Step: 247, Loss: 0.025946861132979393, Lr:0.0001\n",
      "Epoch 11, Step: 248, Loss: 0.04094384238123894, Lr:0.0001\n",
      "Epoch 11, Step: 249, Loss: 0.15373516082763672, Lr:0.0001\n",
      "Epoch 11, Step: 250, Loss: 0.4001401364803314, Lr:0.0001\n",
      "Epoch 11, Step: 251, Loss: 0.13847392797470093, Lr:0.0001\n",
      "Epoch 11, Step: 252, Loss: 0.15459522604942322, Lr:0.0001\n",
      "Epoch 11, Step: 253, Loss: 0.027398543432354927, Lr:0.0001\n",
      "Epoch 11, Step: 254, Loss: 0.13945461809635162, Lr:0.0001\n",
      "Epoch 11, Step: 255, Loss: 0.030794639140367508, Lr:0.0001\n",
      "Epoch 11, Step: 256, Loss: 0.015178644098341465, Lr:0.0001\n",
      "Epoch 11, Step: 257, Loss: 0.22604665160179138, Lr:0.0001\n",
      "Epoch 11, Step: 258, Loss: 0.09791233390569687, Lr:0.0001\n",
      "Epoch 11, Step: 259, Loss: 0.2571926414966583, Lr:0.0001\n",
      "Epoch 11, Step: 260, Loss: 0.21979886293411255, Lr:0.0001\n",
      "Epoch 11, Step: 261, Loss: 0.03829959034919739, Lr:0.0001\n",
      "Epoch 11, Step: 262, Loss: 0.08202510327100754, Lr:0.0001\n",
      "Epoch 11, Step: 263, Loss: 0.14696697890758514, Lr:0.0001\n",
      "Epoch 11, Step: 264, Loss: 0.017235910519957542, Lr:0.0001\n",
      "Epoch 11, Step: 265, Loss: 0.15563209354877472, Lr:0.0001\n",
      "Epoch 11, Step: 266, Loss: 0.0956098809838295, Lr:0.0001\n",
      "Epoch 11, Step: 267, Loss: 0.2652129828929901, Lr:0.0001\n",
      "Epoch 11, Step: 268, Loss: 0.049770377576351166, Lr:0.0001\n",
      "Epoch 11, Step: 269, Loss: 0.02926807850599289, Lr:0.0001\n",
      "Epoch 11, Step: 270, Loss: 0.13768954575061798, Lr:0.0001\n",
      "Epoch 11, Step: 271, Loss: 0.09323086589574814, Lr:0.0001\n",
      "Epoch 11, Step: 272, Loss: 0.08605758845806122, Lr:0.0001\n",
      "Epoch 11, Step: 273, Loss: 0.42040765285491943, Lr:0.0001\n",
      "Epoch 11, Step: 274, Loss: 0.3457586467266083, Lr:0.0001\n",
      "Epoch 11, Step: 275, Loss: 0.1239209994673729, Lr:0.0001\n",
      "Epoch 11, Step: 276, Loss: 0.11317635327577591, Lr:0.0001\n",
      "Epoch 11, Step: 277, Loss: 0.022740546613931656, Lr:0.0001\n",
      "Epoch 11, Step: 278, Loss: 0.41379716992378235, Lr:0.0001\n",
      "Epoch 11, Step: 279, Loss: 0.3757862448692322, Lr:0.0001\n",
      "Epoch 11, Step: 280, Loss: 0.15881066024303436, Lr:0.0001\n",
      "Epoch 11, Step: 281, Loss: 0.07151978462934494, Lr:0.0001\n",
      "Epoch 11, Step: 282, Loss: 0.38793855905532837, Lr:0.0001\n",
      "Epoch 11, Step: 283, Loss: 0.4404759109020233, Lr:0.0001\n",
      "Epoch 11, Step: 284, Loss: 0.27266091108322144, Lr:0.0001\n",
      "Epoch 11, Step: 285, Loss: 0.04344554245471954, Lr:0.0001\n",
      "Epoch 11, Step: 286, Loss: 0.14428210258483887, Lr:0.0001\n",
      "Epoch 11, Step: 287, Loss: 0.025154270231723785, Lr:0.0001\n",
      "Epoch 11, Step: 288, Loss: 0.099143385887146, Lr:0.0001\n",
      "Epoch 11, Step: 289, Loss: 0.1498860865831375, Lr:0.0001\n",
      "Epoch 11, Step: 290, Loss: 0.0833347961306572, Lr:0.0001\n",
      "Epoch 11, Step: 291, Loss: 0.47654369473457336, Lr:0.0001\n",
      "Epoch 11, Step: 292, Loss: 0.21082496643066406, Lr:0.0001\n",
      "Epoch 11, Step: 293, Loss: 0.2972070574760437, Lr:0.0001\n",
      "Epoch 11, Step: 294, Loss: 0.3086589276790619, Lr:0.0001\n",
      "Epoch 11, Step: 295, Loss: 0.1942366361618042, Lr:0.0001\n",
      "Epoch 11, Step: 296, Loss: 0.05480501055717468, Lr:0.0001\n",
      "Epoch 11, Step: 297, Loss: 0.29726502299308777, Lr:0.0001\n",
      "Epoch 11, Step: 298, Loss: 0.09383000433444977, Lr:0.0001\n",
      "Epoch 11, Step: 299, Loss: 0.20027762651443481, Lr:0.0001\n",
      "Epoch 11, Step: 300, Loss: 0.28257906436920166, Lr:0.0001\n",
      "Epoch 11, Step: 301, Loss: 0.02405942603945732, Lr:0.0001\n",
      "Epoch 11, Step: 302, Loss: 0.03397166356444359, Lr:0.0001\n",
      "Epoch 11, Step: 303, Loss: 0.15517938137054443, Lr:0.0001\n",
      "Epoch 11, Step: 304, Loss: 0.2297017127275467, Lr:0.0001\n",
      "Epoch 11, Step: 305, Loss: 0.07555674761533737, Lr:0.0001\n",
      "Epoch 11, Step: 306, Loss: 0.05947251617908478, Lr:0.0001\n",
      "Epoch 11, Step: 307, Loss: 0.19656574726104736, Lr:0.0001\n",
      "Epoch 11, Step: 308, Loss: 0.04096997529268265, Lr:0.0001\n",
      "Epoch 11, Step: 309, Loss: 0.1734331250190735, Lr:0.0001\n",
      "Epoch 11, Step: 310, Loss: 0.24650442600250244, Lr:0.0001\n",
      "Epoch 11, Step: 311, Loss: 0.08481130003929138, Lr:0.0001\n",
      "Epoch 11, Step: 312, Loss: 0.18124085664749146, Lr:0.0001\n",
      "Epoch 11, Step: 313, Loss: 0.13061557710170746, Lr:0.0001\n",
      "Epoch 11, Step: 314, Loss: 0.029157977551221848, Lr:0.0001\n",
      "Epoch 11, Step: 315, Loss: 0.10116974264383316, Lr:0.0001\n",
      "Epoch 11, Step: 316, Loss: 0.08744937181472778, Lr:0.0001\n",
      "Epoch 11, Step: 317, Loss: 0.11439404636621475, Lr:0.0001\n",
      "Epoch 11, Step: 318, Loss: 0.18773773312568665, Lr:0.0001\n",
      "Epoch 11, Step: 319, Loss: 0.04672187194228172, Lr:0.0001\n",
      "Epoch 11, Step: 320, Loss: 0.1387876719236374, Lr:0.0001\n",
      "Epoch 11, Step: 321, Loss: 0.3801981210708618, Lr:0.0001\n",
      "Epoch 11, Step: 322, Loss: 0.06767598539590836, Lr:0.0001\n",
      "Epoch 11, Step: 323, Loss: 0.08467203378677368, Lr:0.0001\n",
      "Epoch 11, Step: 324, Loss: 0.14818182587623596, Lr:0.0001\n",
      "Epoch 11, Step: 325, Loss: 0.08570217341184616, Lr:0.0001\n",
      "Epoch 11, Step: 326, Loss: 0.31201446056365967, Lr:0.0001\n",
      "Epoch 11, Step: 327, Loss: 0.16498926281929016, Lr:0.0001\n",
      "Epoch 11, Step: 328, Loss: 0.11148784309625626, Lr:0.0001\n",
      "Epoch 11, Step: 329, Loss: 0.14657056331634521, Lr:0.0001\n",
      "Epoch 11, Step: 330, Loss: 0.24014027416706085, Lr:0.0001\n",
      "Epoch 11, Step: 331, Loss: 0.24136961996555328, Lr:0.0001\n",
      "Epoch 11, Step: 332, Loss: 0.11564016342163086, Lr:0.0001\n",
      "Epoch 11, Step: 333, Loss: 0.2626199722290039, Lr:0.0001\n",
      "Epoch 11, Step: 334, Loss: 0.3270398676395416, Lr:0.0001\n",
      "Epoch 11, Step: 335, Loss: 0.07432177662849426, Lr:0.0001\n",
      "Epoch 11, Step: 336, Loss: 0.1713322252035141, Lr:0.0001\n",
      "Epoch 11, Step: 337, Loss: 0.3338717818260193, Lr:0.0001\n",
      "Epoch 11, Step: 338, Loss: 0.10653667151927948, Lr:0.0001\n",
      "Epoch 11, Step: 339, Loss: 0.007629739586263895, Lr:0.0001\n",
      "Epoch 11, Step: 340, Loss: 0.02225646749138832, Lr:0.0001\n",
      "Epoch 11, Step: 341, Loss: 0.0634661391377449, Lr:0.0001\n",
      "Epoch 11, Step: 342, Loss: 0.08591657876968384, Lr:0.0001\n",
      "Epoch 11, Step: 343, Loss: 0.13264994323253632, Lr:0.0001\n",
      "Epoch 11, Step: 344, Loss: 0.2528834640979767, Lr:0.0001\n",
      "Epoch 11, Step: 345, Loss: 0.12154831737279892, Lr:0.0001\n",
      "Epoch 11, Step: 346, Loss: 0.05800222232937813, Lr:0.0001\n",
      "Epoch 11, Step: 347, Loss: 0.0601508654654026, Lr:0.0001\n",
      "Epoch 11, Step: 348, Loss: 0.17916958034038544, Lr:0.0001\n",
      "Epoch 11, Step: 349, Loss: 0.2899130880832672, Lr:0.0001\n",
      "Epoch 11, Step: 350, Loss: 0.1262321025133133, Lr:0.0001\n",
      "Epoch 11, Step: 351, Loss: 0.2317417860031128, Lr:0.0001\n",
      "Epoch 11, Step: 352, Loss: 0.3222901225090027, Lr:0.0001\n",
      "Epoch 11, Step: 353, Loss: 0.08391225337982178, Lr:0.0001\n",
      "Epoch 11, Step: 354, Loss: 0.15704090893268585, Lr:0.0001\n",
      "Epoch 11, Step: 355, Loss: 0.2903497517108917, Lr:0.0001\n",
      "Epoch 11, Step: 356, Loss: 0.13283398747444153, Lr:0.0001\n",
      "Epoch 11, Step: 357, Loss: 0.06880147010087967, Lr:0.0001\n",
      "Epoch 11, Step: 358, Loss: 0.051296085119247437, Lr:0.0001\n",
      "Epoch 11, Step: 359, Loss: 0.03506050258874893, Lr:0.0001\n",
      "Epoch 11, Step: 360, Loss: 0.06870539486408234, Lr:0.0001\n",
      "Epoch 11, Step: 361, Loss: 0.05955708026885986, Lr:0.0001\n",
      "Epoch 11, Step: 362, Loss: 0.262324720621109, Lr:0.0001\n",
      "Epoch 11, Step: 363, Loss: 0.17794083058834076, Lr:0.0001\n",
      "Epoch 11, Step: 364, Loss: 0.13932549953460693, Lr:0.0001\n",
      "Epoch 11, Step: 365, Loss: 0.2995416224002838, Lr:0.0001\n",
      "Epoch 11, Step: 366, Loss: 0.15338574349880219, Lr:0.0001\n",
      "Epoch 11, Step: 367, Loss: 0.3683466911315918, Lr:0.0001\n",
      "Epoch 11, Step: 368, Loss: 0.04451519250869751, Lr:0.0001\n",
      "Epoch 11, Step: 369, Loss: 0.06586379557847977, Lr:0.0001\n",
      "Epoch 11, Step: 370, Loss: 0.11397552490234375, Lr:0.0001\n",
      "Epoch 11, Step: 371, Loss: 0.026996539905667305, Lr:0.0001\n",
      "Epoch 11, Step: 372, Loss: 0.11895695328712463, Lr:0.0001\n",
      "Epoch 11, Step: 373, Loss: 0.08343534171581268, Lr:0.0001\n",
      "Epoch 11, Step: 374, Loss: 0.27184680104255676, Lr:0.0001\n",
      "Epoch 11, Step: 375, Loss: 0.11881790310144424, Lr:0.0001\n",
      "Epoch 11, Step: 376, Loss: 0.02212626114487648, Lr:0.0001\n",
      "Epoch 11, Step: 377, Loss: 0.0971309170126915, Lr:0.0001\n",
      "Epoch 11, Step: 378, Loss: 0.15519341826438904, Lr:0.0001\n",
      "Epoch 11, Step: 379, Loss: 0.041045937687158585, Lr:0.0001\n",
      "Epoch 11, Step: 380, Loss: 0.02097051590681076, Lr:0.0001\n",
      "Epoch 11, Step: 381, Loss: 0.20098422467708588, Lr:0.0001\n",
      "Epoch 11, Step: 382, Loss: 0.14492356777191162, Lr:0.0001\n",
      "Epoch 11, Step: 383, Loss: 0.08186370879411697, Lr:0.0001\n",
      "Epoch 11, Step: 384, Loss: 0.22123108804225922, Lr:0.0001\n",
      "Epoch 11, Step: 385, Loss: 0.14258261024951935, Lr:0.0001\n",
      "Epoch 11, Step: 386, Loss: 0.164458230137825, Lr:0.0001\n",
      "Epoch 11, Step: 387, Loss: 0.15818427503108978, Lr:0.0001\n",
      "Epoch 11, Step: 388, Loss: 0.3713552951812744, Lr:0.0001\n",
      "Epoch 11, Step: 389, Loss: 0.11578407883644104, Lr:0.0001\n",
      "Epoch 11, Step: 390, Loss: 0.0955277606844902, Lr:0.0001\n",
      "Epoch 11, Step: 391, Loss: 0.22464780509471893, Lr:0.0001\n",
      "Epoch 11, Step: 392, Loss: 0.052887532860040665, Lr:0.0001\n",
      "Epoch 11, Step: 393, Loss: 0.003765643807128072, Lr:0.0001\n",
      "Epoch 11, Step: 394, Loss: 0.057336024940013885, Lr:0.0001\n",
      "Epoch 11, Step: 395, Loss: 0.09437864273786545, Lr:0.0001\n",
      "Epoch 11, Step: 396, Loss: 0.05198522284626961, Lr:0.0001\n",
      "Epoch 11, Step: 397, Loss: 0.010581562295556068, Lr:0.0001\n",
      "Epoch 11, Step: 398, Loss: 0.11785655468702316, Lr:0.0001\n",
      "Epoch 11, Step: 399, Loss: 0.16015687584877014, Lr:0.0001\n",
      "Epoch 11, Step: 400, Loss: 0.4419492483139038, Lr:0.0001\n",
      "Epoch 11, Step: 401, Loss: 0.25048819184303284, Lr:0.0001\n",
      "Epoch 11, Step: 402, Loss: 0.28145235776901245, Lr:0.0001\n",
      "Epoch 11, Step: 403, Loss: 0.0302896685898304, Lr:0.0001\n",
      "Epoch 11, Step: 404, Loss: 0.11191663146018982, Lr:0.0001\n",
      "Epoch 11, Step: 405, Loss: 0.10254515707492828, Lr:0.0001\n",
      "Epoch 11, Step: 406, Loss: 0.014705679379403591, Lr:0.0001\n",
      "Epoch 11, Step: 407, Loss: 0.21150434017181396, Lr:0.0001\n",
      "Epoch 11, Step: 408, Loss: 0.15191178023815155, Lr:0.0001\n",
      "Epoch 11, Step: 409, Loss: 0.24130681157112122, Lr:0.0001\n",
      "Epoch 11, Step: 410, Loss: 0.3140783905982971, Lr:0.0001\n",
      "Epoch 11, Step: 411, Loss: 0.10610303282737732, Lr:0.0001\n",
      "Epoch 11, Step: 412, Loss: 0.048738062381744385, Lr:0.0001\n",
      "Epoch 11, Step: 413, Loss: 0.0237810667604208, Lr:0.0001\n",
      "Epoch 11, Step: 414, Loss: 0.006472297012805939, Lr:0.0001\n",
      "Epoch 11, Step: 415, Loss: 0.33470630645751953, Lr:0.0001\n",
      "Epoch 11, Step: 416, Loss: 0.04290558025240898, Lr:0.0001\n",
      "Epoch 11, Step: 417, Loss: 0.22176341712474823, Lr:0.0001\n",
      "Epoch 11, Step: 418, Loss: 0.1943598836660385, Lr:0.0001\n",
      "Epoch 11, Step: 419, Loss: 0.29094398021698, Lr:0.0001\n",
      "Epoch 11, Step: 420, Loss: 0.05673925578594208, Lr:0.0001\n",
      "Epoch 11, Step: 421, Loss: 0.21529845893383026, Lr:0.0001\n",
      "Epoch 11, Step: 422, Loss: 0.25111883878707886, Lr:0.0001\n",
      "Epoch 11, Step: 423, Loss: 0.200273796916008, Lr:0.0001\n",
      "Epoch 11, Step: 424, Loss: 0.0782971903681755, Lr:0.0001\n",
      "Epoch 11, Step: 425, Loss: 0.04464397579431534, Lr:0.0001\n",
      "Epoch 11, Step: 426, Loss: 0.0513155497610569, Lr:0.0001\n",
      "Epoch 11, Step: 427, Loss: 0.15470144152641296, Lr:0.0001\n",
      "Epoch 11, Step: 428, Loss: 0.1183457151055336, Lr:0.0001\n",
      "Epoch 11, Step: 429, Loss: 0.037041276693344116, Lr:0.0001\n",
      "Epoch 11, Step: 430, Loss: 0.10893808305263519, Lr:0.0001\n",
      "Epoch 11, Step: 431, Loss: 0.22102515399456024, Lr:0.0001\n",
      "Epoch 11, Step: 432, Loss: 0.09056425839662552, Lr:0.0001\n",
      "Epoch 11, Step: 433, Loss: 0.6877564787864685, Lr:0.0001\n",
      "Epoch 11, Step: 434, Loss: 0.13381844758987427, Lr:0.0001\n",
      "Epoch 11, Step: 435, Loss: 0.039655108004808426, Lr:0.0001\n",
      "Epoch 11, Step: 436, Loss: 0.22641249001026154, Lr:0.0001\n",
      "Epoch 11, Step: 437, Loss: 0.08391985297203064, Lr:0.0001\n",
      "Epoch 11, Step: 438, Loss: 0.32824385166168213, Lr:0.0001\n",
      "Epoch 11, Step: 439, Loss: 0.09229938685894012, Lr:0.0001\n",
      "Epoch 11, Step: 440, Loss: 0.23270560801029205, Lr:0.0001\n",
      "Epoch 11, Step: 441, Loss: 0.17914721369743347, Lr:0.0001\n",
      "Epoch 11, Step: 442, Loss: 0.08376839756965637, Lr:0.0001\n",
      "Epoch 11, Step: 443, Loss: 0.22631047666072845, Lr:0.0001\n",
      "Epoch 11, Step: 444, Loss: 0.015312974341213703, Lr:0.0001\n",
      "Epoch 11, Step: 445, Loss: 0.04838760197162628, Lr:0.0001\n",
      "Epoch 11, Step: 446, Loss: 0.13643582165241241, Lr:0.0001\n",
      "Epoch 11, Step: 447, Loss: 0.006856469437479973, Lr:0.0001\n",
      "Epoch 11, Step: 448, Loss: 0.07446180284023285, Lr:0.0001\n",
      "Epoch 11, Step: 449, Loss: 0.12040650844573975, Lr:0.0001\n",
      "Epoch 11, Step: 450, Loss: 0.2085786908864975, Lr:0.0001\n",
      "Epoch 11, Step: 451, Loss: 0.10486775636672974, Lr:0.0001\n",
      "Epoch 11, Step: 452, Loss: 0.17304366827011108, Lr:0.0001\n",
      "Epoch 11, Step: 453, Loss: 0.20842014253139496, Lr:0.0001\n",
      "Epoch 11, Step: 454, Loss: 0.2739604711532593, Lr:0.0001\n",
      "Epoch 11, Step: 455, Loss: 0.15947525203227997, Lr:0.0001\n",
      "Epoch 11, Step: 456, Loss: 0.043101001530885696, Lr:0.0001\n",
      "Epoch 11, Step: 457, Loss: 0.05084042623639107, Lr:0.0001\n",
      "Epoch 11, Step: 458, Loss: 0.20927350223064423, Lr:0.0001\n",
      "Epoch 11, Step: 459, Loss: 0.21957935392856598, Lr:0.0001\n",
      "Epoch 11, Step: 460, Loss: 0.11657455563545227, Lr:0.0001\n",
      "Epoch 11, Step: 461, Loss: 0.044900160282850266, Lr:0.0001\n",
      "Epoch 11, Step: 462, Loss: 0.2072739601135254, Lr:0.0001\n",
      "Epoch 11, Step: 463, Loss: 0.06105775013566017, Lr:0.0001\n",
      "Epoch 11, Step: 464, Loss: 0.5144429802894592, Lr:0.0001\n",
      "Epoch 11, Step: 465, Loss: 0.0534278005361557, Lr:0.0001\n",
      "Epoch 11, Step: 466, Loss: 0.13826656341552734, Lr:0.0001\n",
      "Epoch 11, Step: 467, Loss: 0.07173158973455429, Lr:0.0001\n",
      "Epoch 11, Step: 468, Loss: 0.024393483996391296, Lr:0.0001\n",
      "Epoch 11, Step: 469, Loss: 0.08338681608438492, Lr:0.0001\n",
      "Epoch 11, Step: 470, Loss: 0.021778637543320656, Lr:0.0001\n",
      "Epoch 11, Step: 471, Loss: 0.04444988816976547, Lr:0.0001\n",
      "Epoch 11, Step: 472, Loss: 0.09497138857841492, Lr:0.0001\n",
      "Epoch 11, Step: 473, Loss: 0.04878866672515869, Lr:0.0001\n",
      "Epoch 11, Step: 474, Loss: 0.22156395018100739, Lr:0.0001\n",
      "Epoch 11, Step: 475, Loss: 0.12327265739440918, Lr:0.0001\n",
      "Epoch 11, Step: 476, Loss: 0.36059480905532837, Lr:0.0001\n",
      "Epoch 11, Step: 477, Loss: 0.20093010365962982, Lr:0.0001\n",
      "Epoch 11, Step: 478, Loss: 0.27374085783958435, Lr:0.0001\n",
      "Epoch 11, Step: 479, Loss: 0.036481019109487534, Lr:0.0001\n",
      "Epoch 11, Step: 480, Loss: 0.14500674605369568, Lr:0.0001\n",
      "Epoch 11, Step: 481, Loss: 0.094172902405262, Lr:0.0001\n",
      "Epoch 11, Step: 482, Loss: 0.1397199183702469, Lr:0.0001\n",
      "Epoch 11, Step: 483, Loss: 0.2520284652709961, Lr:0.0001\n",
      "Epoch 11, Step: 484, Loss: 0.38611090183258057, Lr:0.0001\n",
      "Epoch 11, Step: 485, Loss: 0.22899797558784485, Lr:0.0001\n",
      "Epoch 11, Step: 486, Loss: 0.15680143237113953, Lr:0.0001\n",
      "Epoch 11, Step: 487, Loss: 0.2510080933570862, Lr:0.0001\n",
      "Epoch 11, Step: 488, Loss: 0.12143179029226303, Lr:0.0001\n",
      "Epoch 11, Step: 489, Loss: 0.27229613065719604, Lr:0.0001\n",
      "Epoch 11, Step: 490, Loss: 0.0579075813293457, Lr:0.0001\n",
      "Epoch 11, Step: 491, Loss: 0.19935187697410583, Lr:0.0001\n",
      "Epoch 11, Step: 492, Loss: 0.151164710521698, Lr:0.0001\n",
      "Epoch 11, Step: 493, Loss: 0.0960407555103302, Lr:0.0001\n",
      "Epoch 11, Step: 494, Loss: 0.08089372515678406, Lr:0.0001\n",
      "Epoch 11, Step: 495, Loss: 0.011761246249079704, Lr:0.0001\n",
      "Epoch 11, Step: 496, Loss: 0.03505399823188782, Lr:0.0001\n",
      "Epoch 11, Step: 497, Loss: 0.054087087512016296, Lr:0.0001\n",
      "Epoch 11, Step: 498, Loss: 0.1313147246837616, Lr:0.0001\n",
      "Epoch 11, Step: 499, Loss: 0.07916004955768585, Lr:0.0001\n",
      "Epoch 11, Step: 500, Loss: 0.14104166626930237, Lr:0.0001\n",
      "Epoch 11, Step: 501, Loss: 0.0896725058555603, Lr:0.0001\n",
      "Epoch 11, Step: 502, Loss: 0.12131292372941971, Lr:0.0001\n",
      "Epoch 11, Step: 503, Loss: 0.02629731222987175, Lr:0.0001\n",
      "Epoch 11, Step: 504, Loss: 0.06619975715875626, Lr:0.0001\n",
      "Epoch 11, Step: 505, Loss: 0.06586316972970963, Lr:0.0001\n",
      "Epoch 11, Step: 506, Loss: 0.061348266899585724, Lr:0.0001\n",
      "Epoch 11, Step: 507, Loss: 0.03656511753797531, Lr:0.0001\n",
      "Epoch 11, Step: 508, Loss: 0.044665269553661346, Lr:0.0001\n",
      "Epoch 11, Step: 509, Loss: 0.24110032618045807, Lr:0.0001\n",
      "Epoch 11, Step: 510, Loss: 0.0564180351793766, Lr:0.0001\n",
      "Epoch 11, Step: 511, Loss: 0.03562227264046669, Lr:0.0001\n",
      "Epoch 11, Step: 512, Loss: 0.023808462545275688, Lr:0.0001\n",
      "Epoch 11, Step: 513, Loss: 0.1615043580532074, Lr:0.0001\n",
      "Epoch 11, Step: 514, Loss: 0.0721340924501419, Lr:0.0001\n",
      "Epoch 11, Step: 515, Loss: 0.21771323680877686, Lr:0.0001\n",
      "Epoch 11, Step: 516, Loss: 0.6219995021820068, Lr:0.0001\n",
      "Epoch 11, Step: 517, Loss: 0.08284284174442291, Lr:0.0001\n",
      "Epoch 11, Step: 518, Loss: 0.01780587062239647, Lr:0.0001\n",
      "Epoch 11, Step: 519, Loss: 0.1709727942943573, Lr:0.0001\n",
      "Epoch 11, Step: 520, Loss: 0.017746785655617714, Lr:0.0001\n",
      "Epoch 11, Step: 521, Loss: 0.05657845735549927, Lr:0.0001\n",
      "Epoch 11, Step: 522, Loss: 0.11360662430524826, Lr:0.0001\n",
      "Epoch 11, Step: 523, Loss: 0.2019835263490677, Lr:0.0001\n",
      "Epoch 11, Step: 524, Loss: 0.1175752803683281, Lr:0.0001\n",
      "Epoch 11, Step: 525, Loss: 0.21161913871765137, Lr:0.0001\n",
      "Epoch 11, Step: 526, Loss: 0.11741021275520325, Lr:0.0001\n",
      "Epoch 11, Step: 527, Loss: 0.351376473903656, Lr:0.0001\n",
      "Epoch 11, Step: 528, Loss: 0.11205410212278366, Lr:0.0001\n",
      "Epoch 11, Step: 529, Loss: 0.030252138152718544, Lr:0.0001\n",
      "Epoch 11, Step: 530, Loss: 0.13539335131645203, Lr:0.0001\n",
      "Epoch 11, Step: 531, Loss: 0.2751658260822296, Lr:0.0001\n",
      "Epoch 11, Step: 532, Loss: 0.13374212384223938, Lr:0.0001\n",
      "Epoch 11, Step: 533, Loss: 0.03813239187002182, Lr:0.0001\n",
      "Epoch 11, Step: 534, Loss: 0.06456227600574493, Lr:0.0001\n",
      "Epoch 11, Step: 535, Loss: 0.35855817794799805, Lr:0.0001\n",
      "Epoch 11, Step: 536, Loss: 0.35335561633110046, Lr:0.0001\n",
      "Epoch 11, Step: 537, Loss: 0.059290554374456406, Lr:0.0001\n",
      "Epoch 11, Step: 538, Loss: 0.040266603231430054, Lr:0.0001\n",
      "Epoch 11, Step: 539, Loss: 0.028008416295051575, Lr:0.0001\n",
      "Epoch 11, Step: 540, Loss: 0.18779215216636658, Lr:0.0001\n",
      "Epoch 11, Step: 541, Loss: 0.12469585239887238, Lr:0.0001\n",
      "Epoch 11, Step: 542, Loss: 0.35269036889076233, Lr:0.0001\n",
      "Epoch 11, Step: 543, Loss: 0.02824469469487667, Lr:0.0001\n",
      "Epoch 11, Step: 544, Loss: 0.17332856357097626, Lr:0.0001\n",
      "Epoch 11, Step: 545, Loss: 0.05133061856031418, Lr:0.0001\n",
      "Epoch 11, Step: 546, Loss: 0.021039586514234543, Lr:0.0001\n",
      "Epoch 11, Step: 547, Loss: 0.04171618074178696, Lr:0.0001\n",
      "Epoch 11, Step: 548, Loss: 0.26272663474082947, Lr:0.0001\n",
      "Epoch 11, Step: 549, Loss: 0.2172442525625229, Lr:0.0001\n",
      "Epoch 11, Step: 550, Loss: 0.06422316282987595, Lr:0.0001\n",
      "Epoch 11, Step: 551, Loss: 0.20407961308956146, Lr:0.0001\n",
      "Epoch 11, Step: 552, Loss: 0.0720236673951149, Lr:0.0001\n",
      "Epoch 11, Step: 553, Loss: 0.11967436969280243, Lr:0.0001\n",
      "Epoch 11, Step: 554, Loss: 0.06321239471435547, Lr:0.0001\n",
      "Epoch 11, Step: 555, Loss: 0.07319585978984833, Lr:0.0001\n",
      "Epoch 11, Step: 556, Loss: 0.08569672703742981, Lr:0.0001\n",
      "Epoch 11, Step: 557, Loss: 0.09181234985589981, Lr:0.0001\n",
      "Epoch 11, Step: 558, Loss: 0.11464565247297287, Lr:0.0001\n",
      "Epoch 11, Step: 559, Loss: 0.046937718987464905, Lr:0.0001\n",
      "Epoch 11, Step: 560, Loss: 0.15892288088798523, Lr:0.0001\n",
      "Epoch 11, Step: 561, Loss: 0.07126349210739136, Lr:0.0001\n",
      "Epoch 11, Step: 562, Loss: 0.28910836577415466, Lr:0.0001\n",
      "Epoch 11, Step: 563, Loss: 0.03840688243508339, Lr:0.0001\n",
      "Epoch 11, Step: 564, Loss: 0.09441836178302765, Lr:0.0001\n",
      "Epoch 11, Step: 565, Loss: 0.22297286987304688, Lr:0.0001\n",
      "Epoch 11, Step: 566, Loss: 0.047838326543569565, Lr:0.0001\n",
      "Epoch 11, Step: 567, Loss: 0.03075934574007988, Lr:0.0001\n",
      "Epoch 11, Step: 568, Loss: 0.1150733232498169, Lr:0.0001\n",
      "Epoch 11, Step: 569, Loss: 0.011340870521962643, Lr:0.0001\n",
      "Epoch 11, Step: 570, Loss: 0.021243762224912643, Lr:0.0001\n",
      "Epoch 11, Step: 571, Loss: 0.0507470928132534, Lr:0.0001\n",
      "Epoch 11, Step: 572, Loss: 0.023021580651402473, Lr:0.0001\n",
      "Epoch 11, Step: 573, Loss: 0.3151146471500397, Lr:0.0001\n",
      "Epoch 11, Step: 574, Loss: 0.07416309416294098, Lr:0.0001\n",
      "Epoch 11, Step: 575, Loss: 0.5869154930114746, Lr:0.0001\n",
      "Epoch 11, Step: 576, Loss: 0.1087903156876564, Lr:0.0001\n",
      "Epoch 11, Step: 577, Loss: 0.09715284407138824, Lr:0.0001\n",
      "Epoch 11, Step: 578, Loss: 0.1100606918334961, Lr:0.0001\n",
      "Epoch 11, Step: 579, Loss: 0.058254387229681015, Lr:0.0001\n",
      "Epoch 11, Step: 580, Loss: 0.07900695502758026, Lr:0.0001\n",
      "Epoch 11, Step: 581, Loss: 0.05842753127217293, Lr:0.0001\n",
      "Epoch 11, Step: 582, Loss: 0.06729848682880402, Lr:0.0001\n",
      "Epoch 11, Step: 583, Loss: 0.1620725393295288, Lr:0.0001\n",
      "Epoch 11, Step: 584, Loss: 0.08669186383485794, Lr:0.0001\n",
      "Epoch 11, Step: 585, Loss: 0.09659534692764282, Lr:0.0001\n",
      "Epoch 11, Step: 586, Loss: 0.13352909684181213, Lr:0.0001\n",
      "Epoch 11, Step: 587, Loss: 0.0925055742263794, Lr:0.0001\n",
      "Epoch 11, Step: 588, Loss: 0.06807179749011993, Lr:0.0001\n",
      "Epoch 11, Step: 589, Loss: 0.06661590188741684, Lr:0.0001\n",
      "Epoch 11, Step: 590, Loss: 0.11708943545818329, Lr:0.0001\n",
      "Epoch 11, Step: 591, Loss: 0.11745321750640869, Lr:0.0001\n",
      "Epoch 11, Step: 592, Loss: 0.2607680559158325, Lr:0.0001\n",
      "Epoch 11, Step: 593, Loss: 0.03123435005545616, Lr:0.0001\n",
      "Epoch 11, Step: 594, Loss: 0.011833562515676022, Lr:0.0001\n",
      "Epoch 11, Step: 595, Loss: 0.10667765140533447, Lr:0.0001\n",
      "Epoch 11, Step: 596, Loss: 0.26567724347114563, Lr:0.0001\n",
      "Epoch 11, Step: 597, Loss: 0.2296573668718338, Lr:0.0001\n",
      "Epoch 11, Step: 598, Loss: 0.08664096891880035, Lr:0.0001\n",
      "Epoch 11, Step: 599, Loss: 0.21075370907783508, Lr:0.0001\n",
      "Epoch 11, Step: 600, Loss: 0.25566625595092773, Lr:0.0001\n",
      "Epoch 11, Step: 601, Loss: 0.0842999592423439, Lr:0.0001\n",
      "Epoch 11, Step: 602, Loss: 0.11576022952795029, Lr:0.0001\n",
      "Epoch 11, Step: 603, Loss: 0.08991321176290512, Lr:0.0001\n",
      "Epoch 11, Step: 604, Loss: 0.1412988305091858, Lr:0.0001\n",
      "Epoch 11, Step: 605, Loss: 0.1131012812256813, Lr:0.0001\n",
      "Epoch 11, Step: 606, Loss: 0.031214825809001923, Lr:0.0001\n",
      "Epoch 11, Step: 607, Loss: 0.10595520585775375, Lr:0.0001\n",
      "Epoch 11, Step: 608, Loss: 0.09819673746824265, Lr:0.0001\n",
      "Epoch 11, Step: 609, Loss: 0.08718301355838776, Lr:0.0001\n",
      "Epoch 11, Step: 610, Loss: 0.10879053920507431, Lr:0.0001\n",
      "Epoch 11, Step: 611, Loss: 0.21283186972141266, Lr:0.0001\n",
      "Epoch 11, Step: 612, Loss: 0.28591543436050415, Lr:0.0001\n",
      "Epoch 11, Step: 613, Loss: 0.026973288506269455, Lr:0.0001\n",
      "Epoch 11, Step: 614, Loss: 0.29822707176208496, Lr:0.0001\n",
      "Epoch 11, Step: 615, Loss: 0.01148143783211708, Lr:0.0001\n",
      "Epoch 11, Step: 616, Loss: 0.30074745416641235, Lr:0.0001\n",
      "Epoch 11, Step: 617, Loss: 0.23843957483768463, Lr:0.0001\n",
      "Epoch 11, Step: 618, Loss: 0.062320392578840256, Lr:0.0001\n",
      "Epoch 11, Step: 619, Loss: 0.11802417784929276, Lr:0.0001\n",
      "Epoch 11, Step: 620, Loss: 0.011457557789981365, Lr:0.0001\n",
      "Epoch 11, Step: 621, Loss: 0.044048599898815155, Lr:0.0001\n",
      "Epoch 11, Step: 622, Loss: 0.1178237721323967, Lr:0.0001\n",
      "Epoch 11, Step: 623, Loss: 0.0571046844124794, Lr:0.0001\n",
      "Epoch 11, Step: 624, Loss: 0.0950923040509224, Lr:0.0001\n",
      "Epoch 11, Step: 625, Loss: 0.15188589692115784, Lr:0.0001\n",
      "Epoch 11, Step: 626, Loss: 0.02350657433271408, Lr:0.0001\n",
      "Epoch 11, Step: 627, Loss: 0.05086638033390045, Lr:0.0001\n",
      "Epoch 11, Step: 628, Loss: 0.020690103992819786, Lr:0.0001\n",
      "Epoch 11, Step: 629, Loss: 0.24695445597171783, Lr:0.0001\n",
      "Epoch 11, Step: 630, Loss: 0.027171188965439796, Lr:0.0001\n",
      "Epoch 11, Step: 631, Loss: 0.06985224038362503, Lr:0.0001\n",
      "Epoch 11, Step: 632, Loss: 0.09272489696741104, Lr:0.0001\n",
      "Epoch 11, Step: 633, Loss: 0.09877152740955353, Lr:0.0001\n",
      "Epoch 11, Step: 634, Loss: 0.06344965100288391, Lr:0.0001\n",
      "Epoch 11, Step: 635, Loss: 0.040506575256586075, Lr:0.0001\n",
      "Epoch 11, Step: 636, Loss: 0.09971943497657776, Lr:0.0001\n",
      "Epoch 11, Step: 637, Loss: 0.05438758432865143, Lr:0.0001\n",
      "Epoch 11, Step: 638, Loss: 0.09763402491807938, Lr:0.0001\n",
      "Epoch 11, Step: 639, Loss: 0.42633846402168274, Lr:0.0001\n",
      "Epoch 11, Step: 640, Loss: 0.022949595004320145, Lr:0.0001\n",
      "Epoch 11, Step: 641, Loss: 0.02066856436431408, Lr:0.0001\n",
      "Epoch 11, Step: 642, Loss: 0.07041139155626297, Lr:0.0001\n",
      "Epoch 11, Step: 643, Loss: 0.1547081172466278, Lr:0.0001\n",
      "Epoch 11, Step: 644, Loss: 0.06429630517959595, Lr:0.0001\n",
      "Epoch 11, Step: 645, Loss: 0.030818838626146317, Lr:0.0001\n",
      "Epoch 11, Step: 646, Loss: 0.034809987992048264, Lr:0.0001\n",
      "Epoch 11, Step: 647, Loss: 0.01639390178024769, Lr:0.0001\n",
      "Epoch 11, Step: 648, Loss: 0.34551385045051575, Lr:0.0001\n",
      "Epoch 11, Step: 649, Loss: 0.06530744582414627, Lr:0.0001\n",
      "Epoch 11, Step: 650, Loss: 0.04230703413486481, Lr:0.0001\n",
      "Epoch 11, Step: 651, Loss: 0.018401017412543297, Lr:0.0001\n",
      "Epoch 11, Step: 652, Loss: 0.13368844985961914, Lr:0.0001\n",
      "Epoch 11, Step: 653, Loss: 0.02770305797457695, Lr:0.0001\n",
      "Epoch 11, Step: 654, Loss: 0.014769316650927067, Lr:0.0001\n",
      "Epoch 11, Step: 655, Loss: 0.17762993276119232, Lr:0.0001\n",
      "Epoch 11, Step: 656, Loss: 0.015028825961053371, Lr:0.0001\n",
      "Epoch 11, Step: 657, Loss: 0.13298793137073517, Lr:0.0001\n",
      "Epoch 11, Step: 658, Loss: 0.07819270342588425, Lr:0.0001\n",
      "Epoch 11, Step: 659, Loss: 0.02714509889483452, Lr:0.0001\n",
      "Epoch 11, Step: 660, Loss: 0.0303560271859169, Lr:0.0001\n",
      "Epoch 11, Step: 661, Loss: 0.04263070970773697, Lr:0.0001\n",
      "Epoch 11, Step: 662, Loss: 0.11828070878982544, Lr:0.0001\n",
      "Epoch 11, Step: 663, Loss: 0.03547077998518944, Lr:0.0001\n",
      "Epoch 11, Step: 664, Loss: 0.033255793154239655, Lr:0.0001\n",
      "Epoch 11, Step: 665, Loss: 0.032986052334308624, Lr:0.0001\n",
      "Epoch 11, Step: 666, Loss: 0.06781566143035889, Lr:0.0001\n",
      "Epoch 11, Step: 667, Loss: 0.032922688871622086, Lr:0.0001\n",
      "Epoch 11, Step: 668, Loss: 0.10501816868782043, Lr:0.0001\n",
      "Epoch 11, Step: 669, Loss: 0.05485040321946144, Lr:0.0001\n",
      "Epoch 11, Step: 670, Loss: 0.018106698989868164, Lr:0.0001\n",
      "Epoch 11, Step: 671, Loss: 0.014356818050146103, Lr:0.0001\n",
      "Epoch 11, Step: 672, Loss: 0.0781119242310524, Lr:0.0001\n",
      "Epoch 11, Step: 673, Loss: 0.11938115209341049, Lr:0.0001\n",
      "Epoch 11, Step: 674, Loss: 0.10729721188545227, Lr:0.0001\n",
      "Epoch 11, Step: 675, Loss: 0.07135242223739624, Lr:0.0001\n",
      "Epoch 11, Step: 676, Loss: 0.2005469799041748, Lr:0.0001\n",
      "Epoch 11, Step: 677, Loss: 0.005904984660446644, Lr:0.0001\n",
      "Epoch 11, Step: 678, Loss: 0.05305321887135506, Lr:0.0001\n",
      "Epoch 11, Step: 679, Loss: 0.16134652495384216, Lr:0.0001\n",
      "Epoch 11, Step: 680, Loss: 0.10663961619138718, Lr:0.0001\n",
      "Epoch 11, Step: 681, Loss: 0.08986958861351013, Lr:0.0001\n",
      "Epoch 11, Step: 682, Loss: 0.10320927202701569, Lr:0.0001\n",
      "Epoch 11, Step: 683, Loss: 0.10144113004207611, Lr:0.0001\n",
      "Epoch 11, Step: 684, Loss: 0.4186476469039917, Lr:0.0001\n",
      "Epoch 11, Step: 685, Loss: 0.12185598164796829, Lr:0.0001\n",
      "Epoch 11, Step: 686, Loss: 0.20474496483802795, Lr:0.0001\n",
      "Epoch 11, Step: 687, Loss: 0.010101399384438992, Lr:0.0001\n",
      "Epoch 11, Step: 688, Loss: 0.2039809376001358, Lr:0.0001\n",
      "Epoch 11, Step: 689, Loss: 0.022512385621666908, Lr:0.0001\n",
      "Epoch 11, Step: 690, Loss: 0.07726482301950455, Lr:0.0001\n",
      "Epoch 11, Step: 691, Loss: 0.13196250796318054, Lr:0.0001\n",
      "Epoch 11, Step: 692, Loss: 0.04625549167394638, Lr:0.0001\n",
      "Epoch 11, Step: 693, Loss: 0.043806739151477814, Lr:0.0001\n",
      "Epoch 11, Step: 694, Loss: 0.10342619568109512, Lr:0.0001\n",
      "Epoch 11, Step: 695, Loss: 0.1104712039232254, Lr:0.0001\n",
      "Epoch 11, Step: 696, Loss: 0.030049454420804977, Lr:0.0001\n",
      "Epoch 11, Step: 697, Loss: 0.013738618232309818, Lr:0.0001\n",
      "Epoch 11, Step: 698, Loss: 0.25075486302375793, Lr:0.0001\n",
      "Epoch 11, Step: 699, Loss: 0.11665638536214828, Lr:0.0001\n",
      "Epoch 11, Step: 700, Loss: 0.02915940247476101, Lr:0.0001\n",
      "Epoch 11, Step: 701, Loss: 0.15363731980323792, Lr:0.0001\n",
      "Epoch 11, Step: 702, Loss: 0.08936821669340134, Lr:0.0001\n",
      "Epoch 11, Step: 703, Loss: 0.06260266900062561, Lr:0.0001\n",
      "Epoch 11, Step: 704, Loss: 0.2737473249435425, Lr:0.0001\n",
      "Epoch 11, Step: 705, Loss: 0.03805207461118698, Lr:0.0001\n",
      "Epoch 11, Step: 706, Loss: 0.24949146807193756, Lr:0.0001\n",
      "Epoch 11, Step: 707, Loss: 0.17519687116146088, Lr:0.0001\n",
      "Epoch 11, Step: 708, Loss: 0.2512168884277344, Lr:0.0001\n",
      "Epoch 11, Step: 709, Loss: 0.3470999300479889, Lr:0.0001\n",
      "Epoch 11, Step: 710, Loss: 0.24989169836044312, Lr:0.0001\n",
      "Epoch 11, Step: 711, Loss: 0.17398840188980103, Lr:0.0001\n",
      "Epoch 11, Step: 712, Loss: 0.04975491017103195, Lr:0.0001\n",
      "Epoch 11, Step: 713, Loss: 0.4986710250377655, Lr:0.0001\n",
      "Epoch 11, Step: 714, Loss: 0.10217790305614471, Lr:0.0001\n",
      "Epoch 11, Step: 715, Loss: 0.013499138876795769, Lr:0.0001\n",
      "Epoch 11, Step: 716, Loss: 0.010386606678366661, Lr:0.0001\n",
      "Epoch 11, Step: 717, Loss: 0.11434156447649002, Lr:0.0001\n",
      "Epoch 11, Step: 718, Loss: 0.382282018661499, Lr:0.0001\n",
      "Epoch 11, Step: 719, Loss: 0.04278111085295677, Lr:0.0001\n",
      "Epoch 11, Step: 720, Loss: 0.13072672486305237, Lr:0.0001\n",
      "Epoch 11, Step: 721, Loss: 0.15256237983703613, Lr:0.0001\n",
      "Epoch 11, Step: 722, Loss: 0.09442071616649628, Lr:0.0001\n",
      "Epoch 11, Step: 723, Loss: 0.0249655582010746, Lr:0.0001\n",
      "Epoch 11, Step: 724, Loss: 0.1467631757259369, Lr:0.0001\n",
      "Epoch 11, Step: 725, Loss: 0.11093617975711823, Lr:0.0001\n",
      "Epoch 11, Step: 726, Loss: 0.0052729505114257336, Lr:0.0001\n",
      "Epoch 11, Step: 727, Loss: 0.04770570248365402, Lr:0.0001\n",
      "Epoch 11, Step: 728, Loss: 0.01701432093977928, Lr:0.0001\n",
      "Epoch 11, Step: 729, Loss: 0.05908061936497688, Lr:0.0001\n",
      "Epoch 11, Step: 730, Loss: 0.34861788153648376, Lr:0.0001\n",
      "Epoch 11, Step: 731, Loss: 0.19371363520622253, Lr:0.0001\n",
      "Epoch 11, Step: 732, Loss: 0.17628256976604462, Lr:0.0001\n",
      "Epoch 11, Step: 733, Loss: 0.5180612206459045, Lr:0.0001\n",
      "Epoch 11, Step: 734, Loss: 0.17726290225982666, Lr:0.0001\n",
      "Epoch 11, Step: 735, Loss: 0.033775050193071365, Lr:0.0001\n",
      "Epoch 11, Step: 736, Loss: 0.08161124587059021, Lr:0.0001\n",
      "Epoch 11, Step: 737, Loss: 0.057321492582559586, Lr:0.0001\n",
      "Epoch 11, Step: 738, Loss: 0.07630433142185211, Lr:0.0001\n",
      "Epoch 11, Step: 739, Loss: 0.04471699520945549, Lr:0.0001\n",
      "Epoch 11, Step: 740, Loss: 0.055639419704675674, Lr:0.0001\n",
      "Epoch 11, Step: 741, Loss: 0.08936581015586853, Lr:0.0001\n",
      "Epoch 11, Step: 742, Loss: 0.16724728047847748, Lr:0.0001\n",
      "Epoch 11, Step: 743, Loss: 0.1545862853527069, Lr:0.0001\n",
      "Epoch 11, Step: 744, Loss: 0.3044983446598053, Lr:0.0001\n",
      "Epoch 11, Step: 745, Loss: 0.033651918172836304, Lr:0.0001\n",
      "Epoch 11, Step: 746, Loss: 0.02901548519730568, Lr:0.0001\n",
      "Epoch 11, Step: 747, Loss: 0.0504109188914299, Lr:0.0001\n",
      "Epoch 11, Step: 748, Loss: 0.10856235772371292, Lr:0.0001\n",
      "Epoch 11, Step: 749, Loss: 0.1003737524151802, Lr:0.0001\n",
      "Epoch 11, Step: 750, Loss: 0.1461380273103714, Lr:0.0001\n",
      "Epoch 11, Step: 751, Loss: 0.014368866570293903, Lr:0.0001\n",
      "Epoch 11, Step: 752, Loss: 0.2008279263973236, Lr:0.0001\n",
      "Epoch 11, Step: 753, Loss: 0.2908521592617035, Lr:0.0001\n",
      "Epoch 11, Step: 754, Loss: 0.035166218876838684, Lr:0.0001\n",
      "Epoch 11, Step: 755, Loss: 0.06011804938316345, Lr:0.0001\n",
      "Epoch 11, Step: 756, Loss: 0.07059328258037567, Lr:0.0001\n",
      "Epoch 11, Step: 757, Loss: 0.03542321175336838, Lr:0.0001\n",
      "Epoch 11, Step: 758, Loss: 0.045153725892305374, Lr:0.0001\n",
      "Epoch 11, Step: 759, Loss: 0.14112797379493713, Lr:0.0001\n",
      "Epoch 11, Step: 760, Loss: 0.04635069519281387, Lr:0.0001\n",
      "Epoch 11, Step: 761, Loss: 0.11941087990999222, Lr:0.0001\n",
      "Epoch 11, Step: 762, Loss: 0.04181665554642677, Lr:0.0001\n",
      "Epoch 11, Step: 763, Loss: 0.07554870843887329, Lr:0.0001\n",
      "Epoch 11, Step: 764, Loss: 0.08954497426748276, Lr:0.0001\n",
      "Epoch 11, Step: 765, Loss: 0.16755329072475433, Lr:0.0001\n",
      "Epoch 11, Step: 766, Loss: 0.10793834924697876, Lr:0.0001\n",
      "Epoch 11, Step: 767, Loss: 0.12611353397369385, Lr:0.0001\n",
      "Epoch 11, Step: 768, Loss: 0.06911297142505646, Lr:0.0001\n",
      "Epoch 11, Step: 769, Loss: 0.20614011585712433, Lr:0.0001\n",
      "Epoch 11, Step: 770, Loss: 0.010622664354741573, Lr:0.0001\n",
      "Epoch 11, Step: 771, Loss: 0.060420215129852295, Lr:0.0001\n",
      "Epoch 11, Step: 772, Loss: 0.019051101058721542, Lr:0.0001\n",
      "Epoch 11, Step: 773, Loss: 0.43077415227890015, Lr:0.0001\n",
      "Epoch 11, Step: 774, Loss: 0.2802697420120239, Lr:0.0001\n",
      "Epoch 11, Step: 775, Loss: 0.19201672077178955, Lr:0.0001\n",
      "Epoch 11, Step: 776, Loss: 0.10612853616476059, Lr:0.0001\n",
      "Epoch 11, Step: 777, Loss: 0.10573598742485046, Lr:0.0001\n",
      "Epoch 11, Step: 778, Loss: 0.18548907339572906, Lr:0.0001\n",
      "Epoch 11, Step: 779, Loss: 0.14125074446201324, Lr:0.0001\n",
      "Epoch 11, Step: 780, Loss: 0.0541856624186039, Lr:0.0001\n",
      "Epoch 11, Step: 781, Loss: 0.08463158458471298, Lr:0.0001\n",
      "Epoch 11, Step: 782, Loss: 0.2733788788318634, Lr:0.0001\n",
      "Epoch 11, Step: 783, Loss: 0.06142806261777878, Lr:0.0001\n",
      "Epoch 11, Step: 784, Loss: 0.042588334530591965, Lr:0.0001\n",
      "Epoch 11, Step: 785, Loss: 0.2515808343887329, Lr:0.0001\n",
      "Epoch 11, Step: 786, Loss: 0.12176680564880371, Lr:0.0001\n",
      "Epoch 11, Step: 787, Loss: 0.12049258500337601, Lr:0.0001\n",
      "Epoch 11, Step: 788, Loss: 0.21063779294490814, Lr:0.0001\n",
      "Epoch 11, Step: 789, Loss: 0.17768068611621857, Lr:0.0001\n",
      "Epoch 11, Step: 790, Loss: 0.12226369976997375, Lr:0.0001\n",
      "Epoch 11, Step: 791, Loss: 0.16970835626125336, Lr:0.0001\n",
      "Epoch 11, Step: 792, Loss: 0.015279954299330711, Lr:0.0001\n",
      "Epoch 11, Step: 793, Loss: 0.037675049155950546, Lr:0.0001\n",
      "Epoch 11, Step: 794, Loss: 0.20601454377174377, Lr:0.0001\n",
      "Epoch 11, Step: 795, Loss: 0.013964910991489887, Lr:0.0001\n",
      "Epoch 11, Step: 796, Loss: 0.08538118004798889, Lr:0.0001\n",
      "Epoch 11, Step: 797, Loss: 0.03660782799124718, Lr:0.0001\n",
      "Epoch 11, Step: 798, Loss: 0.08056004345417023, Lr:0.0001\n",
      "Epoch 11, Step: 799, Loss: 0.17343120276927948, Lr:0.0001\n",
      "Epoch 11, Step: 800, Loss: 0.169841006398201, Lr:0.0001\n",
      "Epoch 11, Step: 801, Loss: 0.26882779598236084, Lr:0.0001\n",
      "Epoch 11, Step: 802, Loss: 0.052490655332803726, Lr:0.0001\n",
      "Epoch 11, Step: 803, Loss: 0.10885819047689438, Lr:0.0001\n",
      "Epoch 11, Step: 804, Loss: 0.20243336260318756, Lr:0.0001\n",
      "Epoch 11, Step: 805, Loss: 0.31223195791244507, Lr:0.0001\n",
      "Epoch 11, Step: 806, Loss: 0.012269081547856331, Lr:0.0001\n",
      "Epoch 11, Step: 807, Loss: 0.2334025651216507, Lr:0.0001\n",
      "Epoch 11, Step: 808, Loss: 0.030379462987184525, Lr:0.0001\n",
      "Epoch 11, Step: 809, Loss: 0.4635632336139679, Lr:0.0001\n",
      "Epoch 11, Step: 810, Loss: 0.3265013098716736, Lr:0.0001\n",
      "Epoch 11, Step: 811, Loss: 0.09719022363424301, Lr:0.0001\n",
      "Epoch 11, Step: 812, Loss: 0.311397910118103, Lr:0.0001\n",
      "Epoch 11, Step: 813, Loss: 0.09741086512804031, Lr:0.0001\n",
      "Epoch 11, Step: 814, Loss: 0.30850842595100403, Lr:0.0001\n",
      "Epoch 11, Step: 815, Loss: 0.029633447527885437, Lr:0.0001\n",
      "Epoch 11, Step: 816, Loss: 0.03835472837090492, Lr:0.0001\n",
      "Epoch 11, Step: 817, Loss: 0.0928436815738678, Lr:0.0001\n",
      "Epoch 11, Step: 818, Loss: 0.07735930383205414, Lr:0.0001\n",
      "Epoch 11, Step: 819, Loss: 0.07909060269594193, Lr:0.0001\n",
      "Epoch 11, Step: 820, Loss: 0.048234544694423676, Lr:0.0001\n",
      "Epoch 11, Step: 821, Loss: 0.03351984918117523, Lr:0.0001\n",
      "Epoch 11, Step: 822, Loss: 0.10225388407707214, Lr:0.0001\n",
      "Epoch 11, Step: 823, Loss: 0.04046085476875305, Lr:0.0001\n",
      "Epoch 11, Step: 824, Loss: 0.18542321026325226, Lr:0.0001\n",
      "Epoch 11, Step: 825, Loss: 0.12482655048370361, Lr:0.0001\n",
      "Epoch 11, Step: 826, Loss: 0.1396857500076294, Lr:0.0001\n",
      "Epoch 11, Step: 827, Loss: 0.30630940198898315, Lr:0.0001\n",
      "Epoch 11, Step: 828, Loss: 0.02506992779672146, Lr:0.0001\n",
      "Epoch 11, Step: 829, Loss: 0.27435699105262756, Lr:0.0001\n",
      "Epoch 11, Step: 830, Loss: 0.06362561136484146, Lr:0.0001\n",
      "Epoch 11, Step: 831, Loss: 0.3653595447540283, Lr:0.0001\n",
      "Epoch 11, Step: 832, Loss: 0.37539142370224, Lr:0.0001\n",
      "Epoch 11, Step: 833, Loss: 0.12154659628868103, Lr:0.0001\n",
      "Epoch 11, Step: 834, Loss: 0.2476695030927658, Lr:0.0001\n",
      "Epoch 11, Step: 835, Loss: 0.08619192242622375, Lr:0.0001\n",
      "Epoch 11, Step: 836, Loss: 0.11754202097654343, Lr:0.0001\n",
      "Epoch 11, Step: 837, Loss: 0.02403334528207779, Lr:0.0001\n",
      "Epoch 11, Step: 838, Loss: 0.11996246129274368, Lr:0.0001\n",
      "Epoch 11, Step: 839, Loss: 0.06310334801673889, Lr:0.0001\n",
      "Epoch 11, Step: 840, Loss: 0.1071966290473938, Lr:0.0001\n",
      "Epoch 11, Step: 841, Loss: 0.2538813352584839, Lr:0.0001\n",
      "Epoch 11, Step: 842, Loss: 0.21353445947170258, Lr:0.0001\n",
      "Epoch 11, Step: 843, Loss: 0.03506157174706459, Lr:0.0001\n",
      "Epoch 11, Step: 844, Loss: 0.08908729255199432, Lr:0.0001\n",
      "Epoch 11, Step: 845, Loss: 0.10695739090442657, Lr:0.0001\n",
      "Epoch 11, Step: 846, Loss: 0.08067113906145096, Lr:0.0001\n",
      "Epoch 11, Step: 847, Loss: 0.09634960442781448, Lr:0.0001\n",
      "Epoch 11, Step: 848, Loss: 0.04886540025472641, Lr:0.0001\n",
      "Epoch 11, Step: 849, Loss: 0.03234853968024254, Lr:0.0001\n",
      "Epoch 11, Step: 850, Loss: 0.2100435495376587, Lr:0.0001\n",
      "Epoch 11, Step: 851, Loss: 0.36404186487197876, Lr:0.0001\n",
      "Epoch 11, Step: 852, Loss: 0.664311408996582, Lr:0.0001\n",
      "Epoch 11, Step: 853, Loss: 0.07626648247241974, Lr:0.0001\n",
      "Epoch 11, Step: 854, Loss: 0.08954563736915588, Lr:0.0001\n",
      "Epoch 11, Step: 855, Loss: 0.05750787630677223, Lr:0.0001\n",
      "Epoch 11, Step: 856, Loss: 0.048381056636571884, Lr:0.0001\n",
      "Epoch 11, Step: 857, Loss: 0.1201566606760025, Lr:0.0001\n",
      "Epoch 11, Step: 858, Loss: 0.026669424027204514, Lr:0.0001\n",
      "Epoch 11, Step: 859, Loss: 0.23175615072250366, Lr:0.0001\n",
      "Epoch 11, Step: 860, Loss: 0.10603373497724533, Lr:0.0001\n",
      "Epoch 11, Step: 861, Loss: 0.0882267877459526, Lr:0.0001\n",
      "Epoch 11, Step: 862, Loss: 0.12834413349628448, Lr:0.0001\n",
      "Epoch 11, Step: 863, Loss: 0.05071687325835228, Lr:0.0001\n",
      "Epoch 11, Step: 864, Loss: 0.1251223385334015, Lr:0.0001\n",
      "Epoch 11, Step: 865, Loss: 0.19919809699058533, Lr:0.0001\n",
      "Epoch 11, Step: 866, Loss: 0.2724892497062683, Lr:0.0001\n",
      "Epoch 11, Step: 867, Loss: 0.16292020678520203, Lr:0.0001\n",
      "Epoch 11, Step: 868, Loss: 0.22304248809814453, Lr:0.0001\n",
      "Epoch 11, Step: 869, Loss: 0.005467473063617945, Lr:0.0001\n",
      "Epoch 11, Step: 870, Loss: 0.1409451961517334, Lr:0.0001\n",
      "Epoch 11, Step: 871, Loss: 0.03814616799354553, Lr:0.0001\n",
      "Epoch 11, Step: 872, Loss: 0.01732775941491127, Lr:0.0001\n",
      "Epoch 11, Step: 873, Loss: 0.07209300249814987, Lr:0.0001\n",
      "Epoch 11, Step: 874, Loss: 0.19710828363895416, Lr:0.0001\n",
      "Epoch 11, Step: 875, Loss: 0.5257824659347534, Lr:0.0001\n",
      "Epoch 11, Step: 876, Loss: 0.06203513592481613, Lr:0.0001\n",
      "Epoch 11, Step: 877, Loss: 0.02609051950275898, Lr:0.0001\n",
      "Epoch 11, Step: 878, Loss: 0.17560367286205292, Lr:0.0001\n",
      "Epoch 11, Step: 879, Loss: 0.06679820269346237, Lr:0.0001\n",
      "Epoch 11, Step: 880, Loss: 0.00935989897698164, Lr:0.0001\n",
      "Epoch 11, Step: 881, Loss: 0.03366461768746376, Lr:0.0001\n",
      "Epoch 11, Step: 882, Loss: 0.16821295022964478, Lr:0.0001\n",
      "Epoch 11, Step: 883, Loss: 0.46615761518478394, Lr:0.0001\n",
      "Epoch 11, Step: 884, Loss: 0.06335525214672089, Lr:0.0001\n",
      "Epoch 11, Step: 885, Loss: 0.030582400038838387, Lr:0.0001\n",
      "Epoch 11, Step: 886, Loss: 0.08714638650417328, Lr:0.0001\n",
      "Epoch 11, Step: 887, Loss: 0.28562361001968384, Lr:0.0001\n",
      "Epoch 11, Step: 888, Loss: 0.18438513576984406, Lr:0.0001\n",
      "Epoch 11, Step: 889, Loss: 0.03794890642166138, Lr:0.0001\n",
      "Epoch 11, Step: 890, Loss: 0.14599590003490448, Lr:0.0001\n",
      "Epoch 11, Step: 891, Loss: 0.15473708510398865, Lr:0.0001\n",
      "Epoch 11, Step: 892, Loss: 0.14897805452346802, Lr:0.0001\n",
      "Epoch 11, Step: 893, Loss: 0.18432748317718506, Lr:0.0001\n",
      "Epoch 11, Step: 894, Loss: 0.10747426003217697, Lr:0.0001\n",
      "Epoch 11, Step: 895, Loss: 0.2698221504688263, Lr:0.0001\n",
      "Epoch 11, Step: 896, Loss: 0.03382056951522827, Lr:0.0001\n",
      "Epoch 11, Step: 897, Loss: 0.08076754212379456, Lr:0.0001\n",
      "Epoch 11, Step: 898, Loss: 0.2843429446220398, Lr:0.0001\n",
      "Epoch 11, Step: 899, Loss: 0.14656637609004974, Lr:0.0001\n",
      "Epoch 11, Step: 900, Loss: 0.23366212844848633, Lr:0.0001\n",
      "Epoch 11, Step: 901, Loss: 0.1807979941368103, Lr:0.0001\n",
      "Epoch 11, Step: 902, Loss: 0.17142926156520844, Lr:0.0001\n",
      "Epoch 11, Step: 903, Loss: 0.07065583020448685, Lr:0.0001\n",
      "Epoch 11, Step: 904, Loss: 0.0816066712141037, Lr:0.0001\n",
      "Epoch 11, Step: 905, Loss: 0.2775622010231018, Lr:0.0001\n",
      "Epoch 11, Step: 906, Loss: 0.015037667006254196, Lr:0.0001\n",
      "Epoch 11, Step: 907, Loss: 0.13567908108234406, Lr:0.0001\n",
      "Epoch 11, Step: 908, Loss: 0.05039701238274574, Lr:0.0001\n",
      "Epoch 11, Step: 909, Loss: 0.11618973314762115, Lr:0.0001\n",
      "Epoch 11, Step: 910, Loss: 0.2218162566423416, Lr:0.0001\n",
      "Epoch 11, Step: 911, Loss: 0.07529064267873764, Lr:0.0001\n",
      "Epoch 11, Step: 912, Loss: 0.06808572262525558, Lr:0.0001\n",
      "Epoch 11, Step: 913, Loss: 0.21520131826400757, Lr:0.0001\n",
      "Epoch 11, Step: 914, Loss: 0.11661773920059204, Lr:0.0001\n",
      "Epoch 11, Step: 915, Loss: 0.5411784052848816, Lr:0.0001\n",
      "Epoch 11, Step: 916, Loss: 0.3514932692050934, Lr:0.0001\n",
      "Epoch 11, Step: 917, Loss: 0.16513481736183167, Lr:0.0001\n",
      "Epoch 11, Step: 918, Loss: 0.14604289829730988, Lr:0.0001\n",
      "Epoch 11, Step: 919, Loss: 0.31225061416625977, Lr:0.0001\n",
      "Epoch 11, Step: 920, Loss: 0.05057714506983757, Lr:0.0001\n",
      "Epoch 11, Step: 921, Loss: 0.30735787749290466, Lr:0.0001\n",
      "Epoch 11, Step: 922, Loss: 0.3158939480781555, Lr:0.0001\n",
      "Epoch 11, Step: 923, Loss: 0.06225074082612991, Lr:0.0001\n",
      "Epoch 11, Step: 924, Loss: 0.28302001953125, Lr:0.0001\n",
      "Epoch 11, Step: 925, Loss: 0.32429033517837524, Lr:0.0001\n",
      "Epoch 11, Step: 926, Loss: 0.2811821401119232, Lr:0.0001\n",
      "Epoch 11, Step: 927, Loss: 0.11613690108060837, Lr:0.0001\n",
      "Epoch 11, Step: 928, Loss: 0.06084982678294182, Lr:0.0001\n",
      "Epoch 11, Step: 929, Loss: 0.08309434354305267, Lr:0.0001\n",
      "Epoch 11, Step: 930, Loss: 0.05043082311749458, Lr:0.0001\n",
      "Epoch 11, Step: 931, Loss: 0.19115301966667175, Lr:0.0001\n",
      "Epoch 11, Step: 932, Loss: 0.1656094640493393, Lr:0.0001\n",
      "Epoch 11, Step: 933, Loss: 0.1662532240152359, Lr:0.0001\n",
      "Epoch 11, Step: 934, Loss: 0.13099780678749084, Lr:0.0001\n",
      "Epoch 11, Step: 935, Loss: 0.05672116577625275, Lr:0.0001\n",
      "Epoch 11, Step: 936, Loss: 0.15565140545368195, Lr:0.0001\n",
      "Epoch 11, Step: 937, Loss: 0.024954456835985184, Lr:0.0001\n",
      "Epoch 11, Step: 938, Loss: 0.14914831519126892, Lr:0.0001\n",
      "Epoch 11, Step: 939, Loss: 0.4608911871910095, Lr:0.0001\n",
      "Epoch 11, Step: 940, Loss: 0.3298710882663727, Lr:0.0001\n",
      "Epoch 11, Step: 941, Loss: 0.03901101276278496, Lr:0.0001\n",
      "Epoch 11, Step: 942, Loss: 0.05572137609124184, Lr:0.0001\n",
      "Epoch 11, Step: 943, Loss: 0.12459752708673477, Lr:0.0001\n",
      "Epoch 11, Step: 944, Loss: 0.12468650192022324, Lr:0.0001\n",
      "Epoch 11, Step: 945, Loss: 0.2840460240840912, Lr:0.0001\n",
      "Epoch 11, Step: 946, Loss: 0.08591382950544357, Lr:0.0001\n",
      "Epoch 11, Step: 947, Loss: 0.35419949889183044, Lr:0.0001\n",
      "Epoch 11, Step: 948, Loss: 0.02730286680161953, Lr:0.0001\n",
      "Epoch 11, Step: 949, Loss: 0.32969915866851807, Lr:0.0001\n",
      "Epoch 11, Step: 950, Loss: 0.3164254426956177, Lr:0.0001\n",
      "Epoch 11, Step: 951, Loss: 0.05477578565478325, Lr:0.0001\n",
      "Epoch 11, Step: 952, Loss: 0.3854856491088867, Lr:0.0001\n",
      "Epoch 11, Step: 953, Loss: 0.006345752626657486, Lr:0.0001\n",
      "Epoch 11, Step: 954, Loss: 0.022474629804491997, Lr:0.0001\n",
      "Epoch 11, Step: 955, Loss: 0.08787355571985245, Lr:0.0001\n",
      "Epoch 11, Step: 956, Loss: 0.09266020357608795, Lr:0.0001\n",
      "Epoch 11, Step: 957, Loss: 0.2592751383781433, Lr:0.0001\n",
      "Epoch 11, Step: 958, Loss: 0.184055894613266, Lr:0.0001\n",
      "Epoch 11, Step: 959, Loss: 0.17632527649402618, Lr:0.0001\n",
      "Epoch 11, Step: 960, Loss: 0.0506315603852272, Lr:0.0001\n",
      "Epoch 11, Step: 961, Loss: 0.07217422872781754, Lr:0.0001\n",
      "Epoch 11, Step: 962, Loss: 0.02812102623283863, Lr:0.0001\n",
      "Epoch 11, Step: 963, Loss: 0.08260185271501541, Lr:0.0001\n",
      "Epoch 11, Step: 964, Loss: 0.30713632702827454, Lr:0.0001\n",
      "Epoch 11, Step: 965, Loss: 0.013234476558864117, Lr:0.0001\n",
      "Epoch 11, Step: 966, Loss: 0.22177033126354218, Lr:0.0001\n",
      "Epoch 11, Step: 967, Loss: 0.027060523629188538, Lr:0.0001\n",
      "Epoch 11, Step: 968, Loss: 0.07069259881973267, Lr:0.0001\n",
      "Epoch 11, Step: 969, Loss: 0.14972829818725586, Lr:0.0001\n",
      "Epoch 11, Step: 970, Loss: 0.033963605761528015, Lr:0.0001\n",
      "Epoch 11, Step: 971, Loss: 0.05597662180662155, Lr:0.0001\n",
      "Epoch 11, Step: 972, Loss: 0.016620805487036705, Lr:0.0001\n",
      "Epoch 11, Step: 973, Loss: 0.048452671617269516, Lr:0.0001\n",
      "Epoch 11, Step: 974, Loss: 0.17505766451358795, Lr:0.0001\n",
      "Epoch 11, Step: 975, Loss: 0.03097100369632244, Lr:0.0001\n",
      "Epoch 11, Step: 976, Loss: 0.09453567862510681, Lr:0.0001\n",
      "Epoch 11, Step: 977, Loss: 0.034748002886772156, Lr:0.0001\n",
      "Epoch 11, Step: 978, Loss: 0.24494794011116028, Lr:0.0001\n",
      "Epoch 11, Step: 979, Loss: 0.30037859082221985, Lr:0.0001\n",
      "Epoch 11, Step: 980, Loss: 0.2543671429157257, Lr:0.0001\n",
      "Epoch 11, Step: 981, Loss: 0.026726122945547104, Lr:0.0001\n",
      "Epoch 11, Step: 982, Loss: 0.2381202131509781, Lr:0.0001\n",
      "Epoch 11, Step: 983, Loss: 0.060764312744140625, Lr:0.0001\n",
      "Epoch 11, Step: 984, Loss: 0.09430717676877975, Lr:0.0001\n",
      "Epoch 11, Step: 985, Loss: 0.0626179501414299, Lr:0.0001\n",
      "Epoch 11, Step: 986, Loss: 0.03399120643734932, Lr:0.0001\n",
      "Epoch 11, Step: 987, Loss: 0.15421463549137115, Lr:0.0001\n",
      "Epoch 11, Step: 988, Loss: 0.26160871982574463, Lr:0.0001\n",
      "Epoch 11, Step: 989, Loss: 0.3577532470226288, Lr:0.0001\n",
      "Epoch 11, Step: 990, Loss: 0.1359790712594986, Lr:0.0001\n",
      "Epoch 11, Step: 991, Loss: 0.029716189950704575, Lr:0.0001\n",
      "Epoch 11, Step: 992, Loss: 0.03667942062020302, Lr:0.0001\n",
      "Epoch 11, Step: 993, Loss: 0.07928851246833801, Lr:0.0001\n",
      "Epoch 11, Step: 994, Loss: 0.11342372745275497, Lr:0.0001\n",
      "Epoch 11, Step: 995, Loss: 0.17543673515319824, Lr:0.0001\n",
      "Epoch 11, Step: 996, Loss: 0.23454514145851135, Lr:0.0001\n",
      "Epoch 11, Step: 997, Loss: 0.22828148305416107, Lr:0.0001\n",
      "Epoch 11, Step: 998, Loss: 0.10405739396810532, Lr:0.0001\n",
      "Epoch 11, Step: 999, Loss: 0.3172919452190399, Lr:0.0001\n",
      "Epoch 11, Step: 1000, Loss: 0.08936142176389694, Lr:0.0001\n",
      "Epoch 11, Step: 1001, Loss: 0.292982816696167, Lr:0.0001\n",
      "Epoch 11, Step: 1002, Loss: 0.20369665324687958, Lr:0.0001\n",
      "Epoch 11, Step: 1003, Loss: 0.06646095216274261, Lr:0.0001\n",
      "Epoch 11, Step: 1004, Loss: 0.09078869223594666, Lr:0.0001\n",
      "Epoch 11, Step: 1005, Loss: 0.1706385612487793, Lr:0.0001\n",
      "Epoch 11, Step: 1006, Loss: 0.14013919234275818, Lr:0.0001\n",
      "Epoch 11, Step: 1007, Loss: 0.03986409679055214, Lr:0.0001\n",
      "Epoch 11, Step: 1008, Loss: 0.20776964724063873, Lr:0.0001\n",
      "Epoch 11, Step: 1009, Loss: 0.3940710723400116, Lr:0.0001\n",
      "Epoch 11, Step: 1010, Loss: 0.10330898314714432, Lr:0.0001\n",
      "Epoch 11, Step: 1011, Loss: 0.24516639113426208, Lr:0.0001\n",
      "Epoch 11, Step: 1012, Loss: 0.16876481473445892, Lr:0.0001\n",
      "Epoch 11, Step: 1013, Loss: 0.468997597694397, Lr:0.0001\n",
      "Epoch 11, Step: 1014, Loss: 0.16626131534576416, Lr:0.0001\n",
      "Epoch 11, Step: 1015, Loss: 0.3298647999763489, Lr:0.0001\n",
      "Epoch 11, Step: 1016, Loss: 0.1912594884634018, Lr:0.0001\n",
      "Epoch 11, Step: 1017, Loss: 0.02859516441822052, Lr:0.0001\n",
      "Epoch 11, Step: 1018, Loss: 0.15005594491958618, Lr:0.0001\n",
      "Epoch 11, Step: 1019, Loss: 0.31017640233039856, Lr:0.0001\n",
      "Epoch 11, Step: 1020, Loss: 0.02296018972992897, Lr:0.0001\n",
      "Epoch 11, Step: 1021, Loss: 0.03314977511763573, Lr:0.0001\n",
      "Epoch 11, Step: 1022, Loss: 0.17195239663124084, Lr:0.0001\n",
      "Epoch 11, Step: 1023, Loss: 0.1743389368057251, Lr:0.0001\n",
      "Epoch 11, Step: 1024, Loss: 0.15689587593078613, Lr:0.0001\n",
      "Epoch 11, Step: 1025, Loss: 0.2322860211133957, Lr:0.0001\n",
      "Epoch 11, Step: 1026, Loss: 0.14054939150810242, Lr:0.0001\n",
      "Epoch 11, Step: 1027, Loss: 0.6887111067771912, Lr:0.0001\n",
      "Epoch 11, Step: 1028, Loss: 0.024409616366028786, Lr:0.0001\n",
      "Epoch 11, Step: 1029, Loss: 0.25742945075035095, Lr:0.0001\n",
      "Epoch 11, Step: 1030, Loss: 0.0744108036160469, Lr:0.0001\n",
      "Epoch 11, Step: 1031, Loss: 0.24848276376724243, Lr:0.0001\n",
      "Epoch 11, Step: 1032, Loss: 0.034357648342847824, Lr:0.0001\n",
      "Epoch 11, Step: 1033, Loss: 0.06794105470180511, Lr:0.0001\n",
      "Epoch 11, Step: 1034, Loss: 0.09067203104496002, Lr:0.0001\n",
      "Epoch 11, Step: 1035, Loss: 0.21291658282279968, Lr:0.0001\n",
      "Epoch 11, Step: 1036, Loss: 0.06412214040756226, Lr:0.0001\n",
      "Epoch 11, Step: 1037, Loss: 0.026497868821024895, Lr:0.0001\n",
      "Epoch 11, Step: 1038, Loss: 0.06021518632769585, Lr:0.0001\n",
      "Epoch 11, Step: 1039, Loss: 0.08796163648366928, Lr:0.0001\n",
      "Epoch 11, Step: 1040, Loss: 0.03427751362323761, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 11\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:16 loss: 0.1911 (0.1911) acc1: 93.7500 (93.7500) acc5: 100.0000 (100.0000) time: 0.2925 data: 0.1235 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.0004 (0.0850) acc1: 100.0000 (97.7273) acc5: 100.0000 (100.0000) time: 0.2832 data: 0.1089 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0013 (0.0996) acc1: 100.0000 (97.9167) acc5: 100.0000 (100.0000) time: 0.2817 data: 0.1069 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.0183 (0.2179) acc1: 100.0000 (95.1613) acc5: 100.0000 (100.0000) time: 0.2824 data: 0.1068 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.2790 (0.2553) acc1: 87.5000 (93.2927) acc5: 100.0000 (100.0000) time: 0.2851 data: 0.1097 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.4606 (0.2987) acc1: 81.2500 (91.6667) acc5: 100.0000 (100.0000) time: 0.2877 data: 0.1124 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.1335 (0.3058) acc1: 87.5000 (91.4869) acc5: 100.0000 (100.0000) time: 0.2756 data: 0.1071 max mem: 15137\n",
      "Test: Total time: 0:00:15 (0.2805 s / it)\n",
      "* Acc@1 91.487 Acc@5 100.000 loss 0.306\n",
      "Accuracy of the network on the 881 test image: 91.5%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 12, Step: 0, Loss: 0.026074262335896492, Lr:0.0001\n",
      "Epoch 12, Step: 1, Loss: 0.23493823409080505, Lr:0.0001\n",
      "Epoch 12, Step: 2, Loss: 0.17238372564315796, Lr:0.0001\n",
      "Epoch 12, Step: 3, Loss: 0.2979782223701477, Lr:0.0001\n",
      "Epoch 12, Step: 4, Loss: 0.0732436403632164, Lr:0.0001\n",
      "Epoch 12, Step: 5, Loss: 0.1978325992822647, Lr:0.0001\n",
      "Epoch 12, Step: 6, Loss: 0.18504765629768372, Lr:0.0001\n",
      "Epoch 12, Step: 7, Loss: 0.15384531021118164, Lr:0.0001\n",
      "Epoch 12, Step: 8, Loss: 0.18249885737895966, Lr:0.0001\n",
      "Epoch 12, Step: 9, Loss: 0.38387683033943176, Lr:0.0001\n",
      "Epoch 12, Step: 10, Loss: 0.042803723365068436, Lr:0.0001\n",
      "Epoch 12, Step: 11, Loss: 0.15483862161636353, Lr:0.0001\n",
      "Epoch 12, Step: 12, Loss: 0.025566715747117996, Lr:0.0001\n",
      "Epoch 12, Step: 13, Loss: 0.06929018348455429, Lr:0.0001\n",
      "Epoch 12, Step: 14, Loss: 0.011153139173984528, Lr:0.0001\n",
      "Epoch 12, Step: 15, Loss: 0.035092491656541824, Lr:0.0001\n",
      "Epoch 12, Step: 16, Loss: 0.06884798407554626, Lr:0.0001\n",
      "Epoch 12, Step: 17, Loss: 0.051739707589149475, Lr:0.0001\n",
      "Epoch 12, Step: 18, Loss: 0.07300208508968353, Lr:0.0001\n",
      "Epoch 12, Step: 19, Loss: 0.042955100536346436, Lr:0.0001\n",
      "Epoch 12, Step: 20, Loss: 0.10632603615522385, Lr:0.0001\n",
      "Epoch 12, Step: 21, Loss: 0.017333824187517166, Lr:0.0001\n",
      "Epoch 12, Step: 22, Loss: 0.02258550375699997, Lr:0.0001\n",
      "Epoch 12, Step: 23, Loss: 0.07351616770029068, Lr:0.0001\n",
      "Epoch 12, Step: 24, Loss: 0.23657017946243286, Lr:0.0001\n",
      "Epoch 12, Step: 25, Loss: 0.12242698669433594, Lr:0.0001\n",
      "Epoch 12, Step: 26, Loss: 0.22746989130973816, Lr:0.0001\n",
      "Epoch 12, Step: 27, Loss: 0.04582059755921364, Lr:0.0001\n",
      "Epoch 12, Step: 28, Loss: 0.16630974411964417, Lr:0.0001\n",
      "Epoch 12, Step: 29, Loss: 0.10143659263849258, Lr:0.0001\n",
      "Epoch 12, Step: 30, Loss: 0.07313167303800583, Lr:0.0001\n",
      "Epoch 12, Step: 31, Loss: 0.054288361221551895, Lr:0.0001\n",
      "Epoch 12, Step: 32, Loss: 0.11895483732223511, Lr:0.0001\n",
      "Epoch 12, Step: 33, Loss: 0.19339503347873688, Lr:0.0001\n",
      "Epoch 12, Step: 34, Loss: 0.09053821116685867, Lr:0.0001\n",
      "Epoch 12, Step: 35, Loss: 0.010652385652065277, Lr:0.0001\n",
      "Epoch 12, Step: 36, Loss: 0.15739977359771729, Lr:0.0001\n",
      "Epoch 12, Step: 37, Loss: 0.21714241802692413, Lr:0.0001\n",
      "Epoch 12, Step: 38, Loss: 0.0295613631606102, Lr:0.0001\n",
      "Epoch 12, Step: 39, Loss: 0.0458809919655323, Lr:0.0001\n",
      "Epoch 12, Step: 40, Loss: 0.06359048932790756, Lr:0.0001\n",
      "Epoch 12, Step: 41, Loss: 0.06662552058696747, Lr:0.0001\n",
      "Epoch 12, Step: 42, Loss: 0.13876499235630035, Lr:0.0001\n",
      "Epoch 12, Step: 43, Loss: 0.12362732738256454, Lr:0.0001\n",
      "Epoch 12, Step: 44, Loss: 0.18617531657218933, Lr:0.0001\n",
      "Epoch 12, Step: 45, Loss: 0.12789574265480042, Lr:0.0001\n",
      "Epoch 12, Step: 46, Loss: 0.007085628341883421, Lr:0.0001\n",
      "Epoch 12, Step: 47, Loss: 0.06102876737713814, Lr:0.0001\n",
      "Epoch 12, Step: 48, Loss: 0.12152112275362015, Lr:0.0001\n",
      "Epoch 12, Step: 49, Loss: 0.13802216947078705, Lr:0.0001\n",
      "Epoch 12, Step: 50, Loss: 0.13015718758106232, Lr:0.0001\n",
      "Epoch 12, Step: 51, Loss: 0.07736596465110779, Lr:0.0001\n",
      "Epoch 12, Step: 52, Loss: 0.049671534448862076, Lr:0.0001\n",
      "Epoch 12, Step: 53, Loss: 0.028311802074313164, Lr:0.0001\n",
      "Epoch 12, Step: 54, Loss: 0.017594050616025925, Lr:0.0001\n",
      "Epoch 12, Step: 55, Loss: 0.10826853662729263, Lr:0.0001\n",
      "Epoch 12, Step: 56, Loss: 0.18100357055664062, Lr:0.0001\n",
      "Epoch 12, Step: 57, Loss: 0.04830161854624748, Lr:0.0001\n",
      "Epoch 12, Step: 58, Loss: 0.06290852278470993, Lr:0.0001\n",
      "Epoch 12, Step: 59, Loss: 0.01696477271616459, Lr:0.0001\n",
      "Epoch 12, Step: 60, Loss: 0.0645429790019989, Lr:0.0001\n",
      "Epoch 12, Step: 61, Loss: 0.11326249688863754, Lr:0.0001\n",
      "Epoch 12, Step: 62, Loss: 0.0532008521258831, Lr:0.0001\n",
      "Epoch 12, Step: 63, Loss: 0.04361306503415108, Lr:0.0001\n",
      "Epoch 12, Step: 64, Loss: 0.020950431004166603, Lr:0.0001\n",
      "Epoch 12, Step: 65, Loss: 0.08327387273311615, Lr:0.0001\n",
      "Epoch 12, Step: 66, Loss: 0.052479732781648636, Lr:0.0001\n",
      "Epoch 12, Step: 67, Loss: 0.10013313591480255, Lr:0.0001\n",
      "Epoch 12, Step: 68, Loss: 0.12141460180282593, Lr:0.0001\n",
      "Epoch 12, Step: 69, Loss: 0.028711890801787376, Lr:0.0001\n",
      "Epoch 12, Step: 70, Loss: 0.05082065239548683, Lr:0.0001\n",
      "Epoch 12, Step: 71, Loss: 0.0878336951136589, Lr:0.0001\n",
      "Epoch 12, Step: 72, Loss: 0.07706845551729202, Lr:0.0001\n",
      "Epoch 12, Step: 73, Loss: 0.1159038171172142, Lr:0.0001\n",
      "Epoch 12, Step: 74, Loss: 0.5069738030433655, Lr:0.0001\n",
      "Epoch 12, Step: 75, Loss: 0.5715855956077576, Lr:0.0001\n",
      "Epoch 12, Step: 76, Loss: 0.11674655973911285, Lr:0.0001\n",
      "Epoch 12, Step: 77, Loss: 0.05790714919567108, Lr:0.0001\n",
      "Epoch 12, Step: 78, Loss: 0.027331937104463577, Lr:0.0001\n",
      "Epoch 12, Step: 79, Loss: 0.3347697854042053, Lr:0.0001\n",
      "Epoch 12, Step: 80, Loss: 0.2999112010002136, Lr:0.0001\n",
      "Epoch 12, Step: 81, Loss: 0.07649966329336166, Lr:0.0001\n",
      "Epoch 12, Step: 82, Loss: 0.12283932417631149, Lr:0.0001\n",
      "Epoch 12, Step: 83, Loss: 0.20994935929775238, Lr:0.0001\n",
      "Epoch 12, Step: 84, Loss: 0.1891380250453949, Lr:0.0001\n",
      "Epoch 12, Step: 85, Loss: 0.19949685037136078, Lr:0.0001\n",
      "Epoch 12, Step: 86, Loss: 0.07420901209115982, Lr:0.0001\n",
      "Epoch 12, Step: 87, Loss: 0.07181315869092941, Lr:0.0001\n",
      "Epoch 12, Step: 88, Loss: 0.05330171436071396, Lr:0.0001\n",
      "Epoch 12, Step: 89, Loss: 0.24506588280200958, Lr:0.0001\n",
      "Epoch 12, Step: 90, Loss: 0.13307422399520874, Lr:0.0001\n",
      "Epoch 12, Step: 91, Loss: 0.023201609030365944, Lr:0.0001\n",
      "Epoch 12, Step: 92, Loss: 0.10992598533630371, Lr:0.0001\n",
      "Epoch 12, Step: 93, Loss: 0.017444733530282974, Lr:0.0001\n",
      "Epoch 12, Step: 94, Loss: 0.4404698312282562, Lr:0.0001\n",
      "Epoch 12, Step: 95, Loss: 0.23365527391433716, Lr:0.0001\n",
      "Epoch 12, Step: 96, Loss: 0.0445823147892952, Lr:0.0001\n",
      "Epoch 12, Step: 97, Loss: 0.16593649983406067, Lr:0.0001\n",
      "Epoch 12, Step: 98, Loss: 0.16005954146385193, Lr:0.0001\n",
      "Epoch 12, Step: 99, Loss: 0.1948745995759964, Lr:0.0001\n",
      "Epoch 12, Step: 100, Loss: 0.1377907693386078, Lr:0.0001\n",
      "Epoch 12, Step: 101, Loss: 0.02348531037569046, Lr:0.0001\n",
      "Epoch 12, Step: 102, Loss: 0.019685925915837288, Lr:0.0001\n",
      "Epoch 12, Step: 103, Loss: 0.13805562257766724, Lr:0.0001\n",
      "Epoch 12, Step: 104, Loss: 0.07747481018304825, Lr:0.0001\n",
      "Epoch 12, Step: 105, Loss: 0.12860740721225739, Lr:0.0001\n",
      "Epoch 12, Step: 106, Loss: 0.026882462203502655, Lr:0.0001\n",
      "Epoch 12, Step: 107, Loss: 0.063484787940979, Lr:0.0001\n",
      "Epoch 12, Step: 108, Loss: 0.16839514672756195, Lr:0.0001\n",
      "Epoch 12, Step: 109, Loss: 0.07455441355705261, Lr:0.0001\n",
      "Epoch 12, Step: 110, Loss: 0.29134488105773926, Lr:0.0001\n",
      "Epoch 12, Step: 111, Loss: 0.07571491599082947, Lr:0.0001\n",
      "Epoch 12, Step: 112, Loss: 0.07568082213401794, Lr:0.0001\n",
      "Epoch 12, Step: 113, Loss: 0.2857678234577179, Lr:0.0001\n",
      "Epoch 12, Step: 114, Loss: 0.18580490350723267, Lr:0.0001\n",
      "Epoch 12, Step: 115, Loss: 0.425229549407959, Lr:0.0001\n",
      "Epoch 12, Step: 116, Loss: 0.09754560887813568, Lr:0.0001\n",
      "Epoch 12, Step: 117, Loss: 0.007701487746089697, Lr:0.0001\n",
      "Epoch 12, Step: 118, Loss: 0.34199491143226624, Lr:0.0001\n",
      "Epoch 12, Step: 119, Loss: 0.2580496370792389, Lr:0.0001\n",
      "Epoch 12, Step: 120, Loss: 0.32589638233184814, Lr:0.0001\n",
      "Epoch 12, Step: 121, Loss: 0.029982399195432663, Lr:0.0001\n",
      "Epoch 12, Step: 122, Loss: 0.09843224287033081, Lr:0.0001\n",
      "Epoch 12, Step: 123, Loss: 0.06912805885076523, Lr:0.0001\n",
      "Epoch 12, Step: 124, Loss: 0.13275420665740967, Lr:0.0001\n",
      "Epoch 12, Step: 125, Loss: 0.10806559771299362, Lr:0.0001\n",
      "Epoch 12, Step: 126, Loss: 0.20228181779384613, Lr:0.0001\n",
      "Epoch 12, Step: 127, Loss: 0.10405804961919785, Lr:0.0001\n",
      "Epoch 12, Step: 128, Loss: 0.21584199368953705, Lr:0.0001\n",
      "Epoch 12, Step: 129, Loss: 0.13056796789169312, Lr:0.0001\n",
      "Epoch 12, Step: 130, Loss: 0.07505925744771957, Lr:0.0001\n",
      "Epoch 12, Step: 131, Loss: 0.12725397944450378, Lr:0.0001\n",
      "Epoch 12, Step: 132, Loss: 0.004650340881198645, Lr:0.0001\n",
      "Epoch 12, Step: 133, Loss: 0.09683839976787567, Lr:0.0001\n",
      "Epoch 12, Step: 134, Loss: 0.055225927382707596, Lr:0.0001\n",
      "Epoch 12, Step: 135, Loss: 0.18447189033031464, Lr:0.0001\n",
      "Epoch 12, Step: 136, Loss: 0.08745395392179489, Lr:0.0001\n",
      "Epoch 12, Step: 137, Loss: 0.025497382506728172, Lr:0.0001\n",
      "Epoch 12, Step: 138, Loss: 0.2805671989917755, Lr:0.0001\n",
      "Epoch 12, Step: 139, Loss: 0.04034188762307167, Lr:0.0001\n",
      "Epoch 12, Step: 140, Loss: 0.0529957078397274, Lr:0.0001\n",
      "Epoch 12, Step: 141, Loss: 0.10629283636808395, Lr:0.0001\n",
      "Epoch 12, Step: 142, Loss: 0.0755390003323555, Lr:0.0001\n",
      "Epoch 12, Step: 143, Loss: 0.07096594572067261, Lr:0.0001\n",
      "Epoch 12, Step: 144, Loss: 0.42048320174217224, Lr:0.0001\n",
      "Epoch 12, Step: 145, Loss: 0.062162142246961594, Lr:0.0001\n",
      "Epoch 12, Step: 146, Loss: 0.47063010931015015, Lr:0.0001\n",
      "Epoch 12, Step: 147, Loss: 0.44662347435951233, Lr:0.0001\n",
      "Epoch 12, Step: 148, Loss: 0.38523173332214355, Lr:0.0001\n",
      "Epoch 12, Step: 149, Loss: 0.11550963670015335, Lr:0.0001\n",
      "Epoch 12, Step: 150, Loss: 0.11300486326217651, Lr:0.0001\n",
      "Epoch 12, Step: 151, Loss: 0.19265960156917572, Lr:0.0001\n",
      "Epoch 12, Step: 152, Loss: 0.06339284777641296, Lr:0.0001\n",
      "Epoch 12, Step: 153, Loss: 0.06722096353769302, Lr:0.0001\n",
      "Epoch 12, Step: 154, Loss: 0.04625922441482544, Lr:0.0001\n",
      "Epoch 12, Step: 155, Loss: 0.14396819472312927, Lr:0.0001\n",
      "Epoch 12, Step: 156, Loss: 0.026510749012231827, Lr:0.0001\n",
      "Epoch 12, Step: 157, Loss: 0.05155675858259201, Lr:0.0001\n",
      "Epoch 12, Step: 158, Loss: 0.039800893515348434, Lr:0.0001\n",
      "Epoch 12, Step: 159, Loss: 0.15763303637504578, Lr:0.0001\n",
      "Epoch 12, Step: 160, Loss: 0.04817405343055725, Lr:0.0001\n",
      "Epoch 12, Step: 161, Loss: 0.07678045332431793, Lr:0.0001\n",
      "Epoch 12, Step: 162, Loss: 0.2024320662021637, Lr:0.0001\n",
      "Epoch 12, Step: 163, Loss: 0.11174944788217545, Lr:0.0001\n",
      "Epoch 12, Step: 164, Loss: 0.1991419792175293, Lr:0.0001\n",
      "Epoch 12, Step: 165, Loss: 0.36978772282600403, Lr:0.0001\n",
      "Epoch 12, Step: 166, Loss: 0.1632654070854187, Lr:0.0001\n",
      "Epoch 12, Step: 167, Loss: 0.24217137694358826, Lr:0.0001\n",
      "Epoch 12, Step: 168, Loss: 0.13182179629802704, Lr:0.0001\n",
      "Epoch 12, Step: 169, Loss: 0.019697729498147964, Lr:0.0001\n",
      "Epoch 12, Step: 170, Loss: 0.0027296002954244614, Lr:0.0001\n",
      "Epoch 12, Step: 171, Loss: 0.050898969173431396, Lr:0.0001\n",
      "Epoch 12, Step: 172, Loss: 0.22814461588859558, Lr:0.0001\n",
      "Epoch 12, Step: 173, Loss: 0.19436657428741455, Lr:0.0001\n",
      "Epoch 12, Step: 174, Loss: 0.20277012884616852, Lr:0.0001\n",
      "Epoch 12, Step: 175, Loss: 0.12414004653692245, Lr:0.0001\n",
      "Epoch 12, Step: 176, Loss: 0.14398936927318573, Lr:0.0001\n",
      "Epoch 12, Step: 177, Loss: 0.03083438239991665, Lr:0.0001\n",
      "Epoch 12, Step: 178, Loss: 0.26526370644569397, Lr:0.0001\n",
      "Epoch 12, Step: 179, Loss: 0.2551576495170593, Lr:0.0001\n",
      "Epoch 12, Step: 180, Loss: 0.02285795286297798, Lr:0.0001\n",
      "Epoch 12, Step: 181, Loss: 0.10036259889602661, Lr:0.0001\n",
      "Epoch 12, Step: 182, Loss: 0.0838032066822052, Lr:0.0001\n",
      "Epoch 12, Step: 183, Loss: 0.16036050021648407, Lr:0.0001\n",
      "Epoch 12, Step: 184, Loss: 0.12958361208438873, Lr:0.0001\n",
      "Epoch 12, Step: 185, Loss: 0.08614863455295563, Lr:0.0001\n",
      "Epoch 12, Step: 186, Loss: 0.009224982000887394, Lr:0.0001\n",
      "Epoch 12, Step: 187, Loss: 0.12025313824415207, Lr:0.0001\n",
      "Epoch 12, Step: 188, Loss: 0.26849448680877686, Lr:0.0001\n",
      "Epoch 12, Step: 189, Loss: 0.1961706429719925, Lr:0.0001\n",
      "Epoch 12, Step: 190, Loss: 0.12603017687797546, Lr:0.0001\n",
      "Epoch 12, Step: 191, Loss: 0.05131953954696655, Lr:0.0001\n",
      "Epoch 12, Step: 192, Loss: 0.15882772207260132, Lr:0.0001\n",
      "Epoch 12, Step: 193, Loss: 0.03536280244588852, Lr:0.0001\n",
      "Epoch 12, Step: 194, Loss: 0.1337764412164688, Lr:0.0001\n",
      "Epoch 12, Step: 195, Loss: 0.23087801039218903, Lr:0.0001\n",
      "Epoch 12, Step: 196, Loss: 0.13143958151340485, Lr:0.0001\n",
      "Epoch 12, Step: 197, Loss: 0.11817649751901627, Lr:0.0001\n",
      "Epoch 12, Step: 198, Loss: 0.036164138466119766, Lr:0.0001\n",
      "Epoch 12, Step: 199, Loss: 0.14938004314899445, Lr:0.0001\n",
      "Epoch 12, Step: 200, Loss: 0.12691226601600647, Lr:0.0001\n",
      "Epoch 12, Step: 201, Loss: 0.23009076714515686, Lr:0.0001\n",
      "Epoch 12, Step: 202, Loss: 0.14074300229549408, Lr:0.0001\n",
      "Epoch 12, Step: 203, Loss: 0.03943425416946411, Lr:0.0001\n",
      "Epoch 12, Step: 204, Loss: 0.028249887749552727, Lr:0.0001\n",
      "Epoch 12, Step: 205, Loss: 0.11188707500696182, Lr:0.0001\n",
      "Epoch 12, Step: 206, Loss: 0.19749918580055237, Lr:0.0001\n",
      "Epoch 12, Step: 207, Loss: 0.08452285826206207, Lr:0.0001\n",
      "Epoch 12, Step: 208, Loss: 0.21619035303592682, Lr:0.0001\n",
      "Epoch 12, Step: 209, Loss: 0.17582792043685913, Lr:0.0001\n",
      "Epoch 12, Step: 210, Loss: 0.17910119891166687, Lr:0.0001\n",
      "Epoch 12, Step: 211, Loss: 0.1694791615009308, Lr:0.0001\n",
      "Epoch 12, Step: 212, Loss: 0.04897648096084595, Lr:0.0001\n",
      "Epoch 12, Step: 213, Loss: 0.12230198085308075, Lr:0.0001\n",
      "Epoch 12, Step: 214, Loss: 0.22657695412635803, Lr:0.0001\n",
      "Epoch 12, Step: 215, Loss: 0.1177927628159523, Lr:0.0001\n",
      "Epoch 12, Step: 216, Loss: 0.011076655238866806, Lr:0.0001\n",
      "Epoch 12, Step: 217, Loss: 0.003913740161806345, Lr:0.0001\n",
      "Epoch 12, Step: 218, Loss: 0.03993494063615799, Lr:0.0001\n",
      "Epoch 12, Step: 219, Loss: 0.39080727100372314, Lr:0.0001\n",
      "Epoch 12, Step: 220, Loss: 0.20396845042705536, Lr:0.0001\n",
      "Epoch 12, Step: 221, Loss: 0.03747684136033058, Lr:0.0001\n",
      "Epoch 12, Step: 222, Loss: 0.05776135250926018, Lr:0.0001\n",
      "Epoch 12, Step: 223, Loss: 0.04732261970639229, Lr:0.0001\n",
      "Epoch 12, Step: 224, Loss: 0.1911274939775467, Lr:0.0001\n",
      "Epoch 12, Step: 225, Loss: 0.21181757748126984, Lr:0.0001\n",
      "Epoch 12, Step: 226, Loss: 0.14497549831867218, Lr:0.0001\n",
      "Epoch 12, Step: 227, Loss: 0.19357889890670776, Lr:0.0001\n",
      "Epoch 12, Step: 228, Loss: 0.06190866976976395, Lr:0.0001\n",
      "Epoch 12, Step: 229, Loss: 0.07043831795454025, Lr:0.0001\n",
      "Epoch 12, Step: 230, Loss: 0.2515096962451935, Lr:0.0001\n",
      "Epoch 12, Step: 231, Loss: 0.14157618582248688, Lr:0.0001\n",
      "Epoch 12, Step: 232, Loss: 0.02230471558868885, Lr:0.0001\n",
      "Epoch 12, Step: 233, Loss: 0.08272445946931839, Lr:0.0001\n",
      "Epoch 12, Step: 234, Loss: 0.12141717970371246, Lr:0.0001\n",
      "Epoch 12, Step: 235, Loss: 0.03908023610711098, Lr:0.0001\n",
      "Epoch 12, Step: 236, Loss: 0.145961731672287, Lr:0.0001\n",
      "Epoch 12, Step: 237, Loss: 0.053544022142887115, Lr:0.0001\n",
      "Epoch 12, Step: 238, Loss: 0.011897662654519081, Lr:0.0001\n",
      "Epoch 12, Step: 239, Loss: 0.13404624164104462, Lr:0.0001\n",
      "Epoch 12, Step: 240, Loss: 0.05800040438771248, Lr:0.0001\n",
      "Epoch 12, Step: 241, Loss: 0.02892843820154667, Lr:0.0001\n",
      "Epoch 12, Step: 242, Loss: 0.10009733587503433, Lr:0.0001\n",
      "Epoch 12, Step: 243, Loss: 0.26068115234375, Lr:0.0001\n",
      "Epoch 12, Step: 244, Loss: 0.07086597383022308, Lr:0.0001\n",
      "Epoch 12, Step: 245, Loss: 0.04513266682624817, Lr:0.0001\n",
      "Epoch 12, Step: 246, Loss: 0.11906350404024124, Lr:0.0001\n",
      "Epoch 12, Step: 247, Loss: 0.06193463131785393, Lr:0.0001\n",
      "Epoch 12, Step: 248, Loss: 0.07790090143680573, Lr:0.0001\n",
      "Epoch 12, Step: 249, Loss: 0.05117994174361229, Lr:0.0001\n",
      "Epoch 12, Step: 250, Loss: 0.11645790189504623, Lr:0.0001\n",
      "Epoch 12, Step: 251, Loss: 0.15053433179855347, Lr:0.0001\n",
      "Epoch 12, Step: 252, Loss: 0.05910564586520195, Lr:0.0001\n",
      "Epoch 12, Step: 253, Loss: 0.3287425637245178, Lr:0.0001\n",
      "Epoch 12, Step: 254, Loss: 0.08446664363145828, Lr:0.0001\n",
      "Epoch 12, Step: 255, Loss: 0.018714169040322304, Lr:0.0001\n",
      "Epoch 12, Step: 256, Loss: 0.04274260997772217, Lr:0.0001\n",
      "Epoch 12, Step: 257, Loss: 0.04166189581155777, Lr:0.0001\n",
      "Epoch 12, Step: 258, Loss: 0.09062130004167557, Lr:0.0001\n",
      "Epoch 12, Step: 259, Loss: 0.0830850750207901, Lr:0.0001\n",
      "Epoch 12, Step: 260, Loss: 0.05895185470581055, Lr:0.0001\n",
      "Epoch 12, Step: 261, Loss: 0.041667211800813675, Lr:0.0001\n",
      "Epoch 12, Step: 262, Loss: 0.2734113037586212, Lr:0.0001\n",
      "Epoch 12, Step: 263, Loss: 0.04914962127804756, Lr:0.0001\n",
      "Epoch 12, Step: 264, Loss: 0.1794700175523758, Lr:0.0001\n",
      "Epoch 12, Step: 265, Loss: 0.06930407136678696, Lr:0.0001\n",
      "Epoch 12, Step: 266, Loss: 0.14593984186649323, Lr:0.0001\n",
      "Epoch 12, Step: 267, Loss: 0.02591022662818432, Lr:0.0001\n",
      "Epoch 12, Step: 268, Loss: 0.0841478630900383, Lr:0.0001\n",
      "Epoch 12, Step: 269, Loss: 0.15497440099716187, Lr:0.0001\n",
      "Epoch 12, Step: 270, Loss: 0.023427875712513924, Lr:0.0001\n",
      "Epoch 12, Step: 271, Loss: 0.04504917562007904, Lr:0.0001\n",
      "Epoch 12, Step: 272, Loss: 0.14313936233520508, Lr:0.0001\n",
      "Epoch 12, Step: 273, Loss: 0.07000545412302017, Lr:0.0001\n",
      "Epoch 12, Step: 274, Loss: 0.06765531748533249, Lr:0.0001\n",
      "Epoch 12, Step: 275, Loss: 0.10071082413196564, Lr:0.0001\n",
      "Epoch 12, Step: 276, Loss: 0.10716840624809265, Lr:0.0001\n",
      "Epoch 12, Step: 277, Loss: 0.12787464261054993, Lr:0.0001\n",
      "Epoch 12, Step: 278, Loss: 0.17712704837322235, Lr:0.0001\n",
      "Epoch 12, Step: 279, Loss: 0.24876970052719116, Lr:0.0001\n",
      "Epoch 12, Step: 280, Loss: 0.053422633558511734, Lr:0.0001\n",
      "Epoch 12, Step: 281, Loss: 0.39145714044570923, Lr:0.0001\n",
      "Epoch 12, Step: 282, Loss: 0.036879632622003555, Lr:0.0001\n",
      "Epoch 12, Step: 283, Loss: 0.2060627043247223, Lr:0.0001\n",
      "Epoch 12, Step: 284, Loss: 0.027846036478877068, Lr:0.0001\n",
      "Epoch 12, Step: 285, Loss: 0.08688127994537354, Lr:0.0001\n",
      "Epoch 12, Step: 286, Loss: 0.11496594548225403, Lr:0.0001\n",
      "Epoch 12, Step: 287, Loss: 0.037687525153160095, Lr:0.0001\n",
      "Epoch 12, Step: 288, Loss: 0.05739989131689072, Lr:0.0001\n",
      "Epoch 12, Step: 289, Loss: 0.12797532975673676, Lr:0.0001\n",
      "Epoch 12, Step: 290, Loss: 0.048360176384449005, Lr:0.0001\n",
      "Epoch 12, Step: 291, Loss: 0.026014646515250206, Lr:0.0001\n",
      "Epoch 12, Step: 292, Loss: 0.04293617978692055, Lr:0.0001\n",
      "Epoch 12, Step: 293, Loss: 0.017647914588451385, Lr:0.0001\n",
      "Epoch 12, Step: 294, Loss: 0.03840859606862068, Lr:0.0001\n",
      "Epoch 12, Step: 295, Loss: 0.1449625939130783, Lr:0.0001\n",
      "Epoch 12, Step: 296, Loss: 0.07531306892633438, Lr:0.0001\n",
      "Epoch 12, Step: 297, Loss: 0.2989456355571747, Lr:0.0001\n",
      "Epoch 12, Step: 298, Loss: 0.23686227202415466, Lr:0.0001\n",
      "Epoch 12, Step: 299, Loss: 0.019794311374425888, Lr:0.0001\n",
      "Epoch 12, Step: 300, Loss: 0.11259358376264572, Lr:0.0001\n",
      "Epoch 12, Step: 301, Loss: 0.07701361924409866, Lr:0.0001\n",
      "Epoch 12, Step: 302, Loss: 0.06765533238649368, Lr:0.0001\n",
      "Epoch 12, Step: 303, Loss: 0.017666129395365715, Lr:0.0001\n",
      "Epoch 12, Step: 304, Loss: 0.1329890787601471, Lr:0.0001\n",
      "Epoch 12, Step: 305, Loss: 0.21180860698223114, Lr:0.0001\n",
      "Epoch 12, Step: 306, Loss: 0.041319310665130615, Lr:0.0001\n",
      "Epoch 12, Step: 307, Loss: 0.03389602154493332, Lr:0.0001\n",
      "Epoch 12, Step: 308, Loss: 0.01895422488451004, Lr:0.0001\n",
      "Epoch 12, Step: 309, Loss: 0.3837360441684723, Lr:0.0001\n",
      "Epoch 12, Step: 310, Loss: 0.17137499153614044, Lr:0.0001\n",
      "Epoch 12, Step: 311, Loss: 0.031432706862688065, Lr:0.0001\n",
      "Epoch 12, Step: 312, Loss: 0.1493939459323883, Lr:0.0001\n",
      "Epoch 12, Step: 313, Loss: 0.08610842376947403, Lr:0.0001\n",
      "Epoch 12, Step: 314, Loss: 0.263372540473938, Lr:0.0001\n",
      "Epoch 12, Step: 315, Loss: 0.14215321838855743, Lr:0.0001\n",
      "Epoch 12, Step: 316, Loss: 0.1261305958032608, Lr:0.0001\n",
      "Epoch 12, Step: 317, Loss: 0.162092924118042, Lr:0.0001\n",
      "Epoch 12, Step: 318, Loss: 0.06120931729674339, Lr:0.0001\n",
      "Epoch 12, Step: 319, Loss: 0.03817339614033699, Lr:0.0001\n",
      "Epoch 12, Step: 320, Loss: 0.03533404320478439, Lr:0.0001\n",
      "Epoch 12, Step: 321, Loss: 0.07097981125116348, Lr:0.0001\n",
      "Epoch 12, Step: 322, Loss: 0.008745395578444004, Lr:0.0001\n",
      "Epoch 12, Step: 323, Loss: 0.007897285744547844, Lr:0.0001\n",
      "Epoch 12, Step: 324, Loss: 0.09209294617176056, Lr:0.0001\n",
      "Epoch 12, Step: 325, Loss: 0.10285327583551407, Lr:0.0001\n",
      "Epoch 12, Step: 326, Loss: 0.13495151698589325, Lr:0.0001\n",
      "Epoch 12, Step: 327, Loss: 0.07483990490436554, Lr:0.0001\n",
      "Epoch 12, Step: 328, Loss: 0.27889561653137207, Lr:0.0001\n",
      "Epoch 12, Step: 329, Loss: 0.37173813581466675, Lr:0.0001\n",
      "Epoch 12, Step: 330, Loss: 0.17376886308193207, Lr:0.0001\n",
      "Epoch 12, Step: 331, Loss: 0.15629979968070984, Lr:0.0001\n",
      "Epoch 12, Step: 332, Loss: 0.12699507176876068, Lr:0.0001\n",
      "Epoch 12, Step: 333, Loss: 0.10263744741678238, Lr:0.0001\n",
      "Epoch 12, Step: 334, Loss: 0.046727050095796585, Lr:0.0001\n",
      "Epoch 12, Step: 335, Loss: 0.03677360713481903, Lr:0.0001\n",
      "Epoch 12, Step: 336, Loss: 0.09679410606622696, Lr:0.0001\n",
      "Epoch 12, Step: 337, Loss: 0.04573427140712738, Lr:0.0001\n",
      "Epoch 12, Step: 338, Loss: 0.07211699336767197, Lr:0.0001\n",
      "Epoch 12, Step: 339, Loss: 0.10905764251947403, Lr:0.0001\n",
      "Epoch 12, Step: 340, Loss: 0.5185277462005615, Lr:0.0001\n",
      "Epoch 12, Step: 341, Loss: 0.09468714147806168, Lr:0.0001\n",
      "Epoch 12, Step: 342, Loss: 0.06589192152023315, Lr:0.0001\n",
      "Epoch 12, Step: 343, Loss: 0.04529156908392906, Lr:0.0001\n",
      "Epoch 12, Step: 344, Loss: 0.193137988448143, Lr:0.0001\n",
      "Epoch 12, Step: 345, Loss: 0.1262112557888031, Lr:0.0001\n",
      "Epoch 12, Step: 346, Loss: 0.0061678760685026646, Lr:0.0001\n",
      "Epoch 12, Step: 347, Loss: 0.039735712110996246, Lr:0.0001\n",
      "Epoch 12, Step: 348, Loss: 0.17249858379364014, Lr:0.0001\n",
      "Epoch 12, Step: 349, Loss: 0.018457839265465736, Lr:0.0001\n",
      "Epoch 12, Step: 350, Loss: 0.03099646605551243, Lr:0.0001\n",
      "Epoch 12, Step: 351, Loss: 0.07165324687957764, Lr:0.0001\n",
      "Epoch 12, Step: 352, Loss: 0.04157460853457451, Lr:0.0001\n",
      "Epoch 12, Step: 353, Loss: 0.8715237379074097, Lr:0.0001\n",
      "Epoch 12, Step: 354, Loss: 0.19851170480251312, Lr:0.0001\n",
      "Epoch 12, Step: 355, Loss: 0.07058408856391907, Lr:0.0001\n",
      "Epoch 12, Step: 356, Loss: 0.1690419316291809, Lr:0.0001\n",
      "Epoch 12, Step: 357, Loss: 0.09891632199287415, Lr:0.0001\n",
      "Epoch 12, Step: 358, Loss: 0.27885881066322327, Lr:0.0001\n",
      "Epoch 12, Step: 359, Loss: 0.21146294474601746, Lr:0.0001\n",
      "Epoch 12, Step: 360, Loss: 0.010142462328076363, Lr:0.0001\n",
      "Epoch 12, Step: 361, Loss: 0.20786981284618378, Lr:0.0001\n",
      "Epoch 12, Step: 362, Loss: 0.25697457790374756, Lr:0.0001\n",
      "Epoch 12, Step: 363, Loss: 0.12794320285320282, Lr:0.0001\n",
      "Epoch 12, Step: 364, Loss: 0.4801676869392395, Lr:0.0001\n",
      "Epoch 12, Step: 365, Loss: 0.009357207454741001, Lr:0.0001\n",
      "Epoch 12, Step: 366, Loss: 0.4126673638820648, Lr:0.0001\n",
      "Epoch 12, Step: 367, Loss: 0.1284855455160141, Lr:0.0001\n",
      "Epoch 12, Step: 368, Loss: 0.16507478058338165, Lr:0.0001\n",
      "Epoch 12, Step: 369, Loss: 0.13157546520233154, Lr:0.0001\n",
      "Epoch 12, Step: 370, Loss: 0.13101045787334442, Lr:0.0001\n",
      "Epoch 12, Step: 371, Loss: 0.44387170672416687, Lr:0.0001\n",
      "Epoch 12, Step: 372, Loss: 0.13712364435195923, Lr:0.0001\n",
      "Epoch 12, Step: 373, Loss: 0.23252640664577484, Lr:0.0001\n",
      "Epoch 12, Step: 374, Loss: 0.07411237806081772, Lr:0.0001\n",
      "Epoch 12, Step: 375, Loss: 0.25508835911750793, Lr:0.0001\n",
      "Epoch 12, Step: 376, Loss: 0.1906939297914505, Lr:0.0001\n",
      "Epoch 12, Step: 377, Loss: 0.09521527588367462, Lr:0.0001\n",
      "Epoch 12, Step: 378, Loss: 0.2380613535642624, Lr:0.0001\n",
      "Epoch 12, Step: 379, Loss: 0.1698971390724182, Lr:0.0001\n",
      "Epoch 12, Step: 380, Loss: 0.08803114295005798, Lr:0.0001\n",
      "Epoch 12, Step: 381, Loss: 0.02046121656894684, Lr:0.0001\n",
      "Epoch 12, Step: 382, Loss: 0.1940835416316986, Lr:0.0001\n",
      "Epoch 12, Step: 383, Loss: 0.1254318505525589, Lr:0.0001\n",
      "Epoch 12, Step: 384, Loss: 0.322459876537323, Lr:0.0001\n",
      "Epoch 12, Step: 385, Loss: 0.3135785162448883, Lr:0.0001\n",
      "Epoch 12, Step: 386, Loss: 0.10308397561311722, Lr:0.0001\n",
      "Epoch 12, Step: 387, Loss: 0.18943147361278534, Lr:0.0001\n",
      "Epoch 12, Step: 388, Loss: 0.06174198538064957, Lr:0.0001\n",
      "Epoch 12, Step: 389, Loss: 0.23793841898441315, Lr:0.0001\n",
      "Epoch 12, Step: 390, Loss: 0.009638532996177673, Lr:0.0001\n",
      "Epoch 12, Step: 391, Loss: 0.11054357141256332, Lr:0.0001\n",
      "Epoch 12, Step: 392, Loss: 0.030368968844413757, Lr:0.0001\n",
      "Epoch 12, Step: 393, Loss: 0.1763780266046524, Lr:0.0001\n",
      "Epoch 12, Step: 394, Loss: 0.18178591132164001, Lr:0.0001\n",
      "Epoch 12, Step: 395, Loss: 0.06714467704296112, Lr:0.0001\n",
      "Epoch 12, Step: 396, Loss: 0.2920015752315521, Lr:0.0001\n",
      "Epoch 12, Step: 397, Loss: 0.3223128020763397, Lr:0.0001\n",
      "Epoch 12, Step: 398, Loss: 0.16114844381809235, Lr:0.0001\n",
      "Epoch 12, Step: 399, Loss: 0.03695790097117424, Lr:0.0001\n",
      "Epoch 12, Step: 400, Loss: 0.18584337830543518, Lr:0.0001\n",
      "Epoch 12, Step: 401, Loss: 0.022039853036403656, Lr:0.0001\n",
      "Epoch 12, Step: 402, Loss: 0.2587677240371704, Lr:0.0001\n",
      "Epoch 12, Step: 403, Loss: 0.11612170934677124, Lr:0.0001\n",
      "Epoch 12, Step: 404, Loss: 0.09725906699895859, Lr:0.0001\n",
      "Epoch 12, Step: 405, Loss: 0.11349156498908997, Lr:0.0001\n",
      "Epoch 12, Step: 406, Loss: 0.2356216311454773, Lr:0.0001\n",
      "Epoch 12, Step: 407, Loss: 0.05034219101071358, Lr:0.0001\n",
      "Epoch 12, Step: 408, Loss: 0.4862448275089264, Lr:0.0001\n",
      "Epoch 12, Step: 409, Loss: 0.13233226537704468, Lr:0.0001\n",
      "Epoch 12, Step: 410, Loss: 0.18038871884346008, Lr:0.0001\n",
      "Epoch 12, Step: 411, Loss: 0.024286292493343353, Lr:0.0001\n",
      "Epoch 12, Step: 412, Loss: 0.22726064920425415, Lr:0.0001\n",
      "Epoch 12, Step: 413, Loss: 0.13847218453884125, Lr:0.0001\n",
      "Epoch 12, Step: 414, Loss: 0.05255868285894394, Lr:0.0001\n",
      "Epoch 12, Step: 415, Loss: 0.2281264215707779, Lr:0.0001\n",
      "Epoch 12, Step: 416, Loss: 0.2129681557416916, Lr:0.0001\n",
      "Epoch 12, Step: 417, Loss: 0.03816203027963638, Lr:0.0001\n",
      "Epoch 12, Step: 418, Loss: 0.2853643298149109, Lr:0.0001\n",
      "Epoch 12, Step: 419, Loss: 0.01876230537891388, Lr:0.0001\n",
      "Epoch 12, Step: 420, Loss: 0.07674047350883484, Lr:0.0001\n",
      "Epoch 12, Step: 421, Loss: 0.28951576352119446, Lr:0.0001\n",
      "Epoch 12, Step: 422, Loss: 0.019586613401770592, Lr:0.0001\n",
      "Epoch 12, Step: 423, Loss: 0.25299733877182007, Lr:0.0001\n",
      "Epoch 12, Step: 424, Loss: 0.259255975484848, Lr:0.0001\n",
      "Epoch 12, Step: 425, Loss: 0.05842192471027374, Lr:0.0001\n",
      "Epoch 12, Step: 426, Loss: 0.08154600858688354, Lr:0.0001\n",
      "Epoch 12, Step: 427, Loss: 0.13411188125610352, Lr:0.0001\n",
      "Epoch 12, Step: 428, Loss: 0.022184692323207855, Lr:0.0001\n",
      "Epoch 12, Step: 429, Loss: 0.14088517427444458, Lr:0.0001\n",
      "Epoch 12, Step: 430, Loss: 0.1435428261756897, Lr:0.0001\n",
      "Epoch 12, Step: 431, Loss: 0.19586613774299622, Lr:0.0001\n",
      "Epoch 12, Step: 432, Loss: 0.07577474415302277, Lr:0.0001\n",
      "Epoch 12, Step: 433, Loss: 0.18833103775978088, Lr:0.0001\n",
      "Epoch 12, Step: 434, Loss: 0.008627508766949177, Lr:0.0001\n",
      "Epoch 12, Step: 435, Loss: 0.09104221314191818, Lr:0.0001\n",
      "Epoch 12, Step: 436, Loss: 0.2663523256778717, Lr:0.0001\n",
      "Epoch 12, Step: 437, Loss: 0.07330751419067383, Lr:0.0001\n",
      "Epoch 12, Step: 438, Loss: 0.28946685791015625, Lr:0.0001\n",
      "Epoch 12, Step: 439, Loss: 0.2646176218986511, Lr:0.0001\n",
      "Epoch 12, Step: 440, Loss: 0.08431091159582138, Lr:0.0001\n",
      "Epoch 12, Step: 441, Loss: 0.033850692212581635, Lr:0.0001\n",
      "Epoch 12, Step: 442, Loss: 0.21391995251178741, Lr:0.0001\n",
      "Epoch 12, Step: 443, Loss: 0.06203477829694748, Lr:0.0001\n",
      "Epoch 12, Step: 444, Loss: 0.09297304600477219, Lr:0.0001\n",
      "Epoch 12, Step: 445, Loss: 0.12072865664958954, Lr:0.0001\n",
      "Epoch 12, Step: 446, Loss: 0.014016052708029747, Lr:0.0001\n",
      "Epoch 12, Step: 447, Loss: 0.012996937148272991, Lr:0.0001\n",
      "Epoch 12, Step: 448, Loss: 0.09946243464946747, Lr:0.0001\n",
      "Epoch 12, Step: 449, Loss: 0.07163418084383011, Lr:0.0001\n",
      "Epoch 12, Step: 450, Loss: 0.19178852438926697, Lr:0.0001\n",
      "Epoch 12, Step: 451, Loss: 0.01947612687945366, Lr:0.0001\n",
      "Epoch 12, Step: 452, Loss: 0.14278243482112885, Lr:0.0001\n",
      "Epoch 12, Step: 453, Loss: 0.04202836751937866, Lr:0.0001\n",
      "Epoch 12, Step: 454, Loss: 0.28689736127853394, Lr:0.0001\n",
      "Epoch 12, Step: 455, Loss: 0.12335167080163956, Lr:0.0001\n",
      "Epoch 12, Step: 456, Loss: 0.12052548676729202, Lr:0.0001\n",
      "Epoch 12, Step: 457, Loss: 0.03102380782365799, Lr:0.0001\n",
      "Epoch 12, Step: 458, Loss: 0.022155271843075752, Lr:0.0001\n",
      "Epoch 12, Step: 459, Loss: 0.015987545251846313, Lr:0.0001\n",
      "Epoch 12, Step: 460, Loss: 0.042631376534700394, Lr:0.0001\n",
      "Epoch 12, Step: 461, Loss: 0.00691968435421586, Lr:0.0001\n",
      "Epoch 12, Step: 462, Loss: 0.010261207818984985, Lr:0.0001\n",
      "Epoch 12, Step: 463, Loss: 0.13118360936641693, Lr:0.0001\n",
      "Epoch 12, Step: 464, Loss: 0.12659674882888794, Lr:0.0001\n",
      "Epoch 12, Step: 465, Loss: 0.3079122006893158, Lr:0.0001\n",
      "Epoch 12, Step: 466, Loss: 0.07967664301395416, Lr:0.0001\n",
      "Epoch 12, Step: 467, Loss: 0.0866171345114708, Lr:0.0001\n",
      "Epoch 12, Step: 468, Loss: 0.27359116077423096, Lr:0.0001\n",
      "Epoch 12, Step: 469, Loss: 0.15607798099517822, Lr:0.0001\n",
      "Epoch 12, Step: 470, Loss: 0.09088801592588425, Lr:0.0001\n",
      "Epoch 12, Step: 471, Loss: 0.07150179147720337, Lr:0.0001\n",
      "Epoch 12, Step: 472, Loss: 0.11620165407657623, Lr:0.0001\n",
      "Epoch 12, Step: 473, Loss: 0.08491288870573044, Lr:0.0001\n",
      "Epoch 12, Step: 474, Loss: 0.07662448287010193, Lr:0.0001\n",
      "Epoch 12, Step: 475, Loss: 0.10192573815584183, Lr:0.0001\n",
      "Epoch 12, Step: 476, Loss: 0.24244830012321472, Lr:0.0001\n",
      "Epoch 12, Step: 477, Loss: 0.1549098938703537, Lr:0.0001\n",
      "Epoch 12, Step: 478, Loss: 0.0658934935927391, Lr:0.0001\n",
      "Epoch 12, Step: 479, Loss: 0.2120172530412674, Lr:0.0001\n",
      "Epoch 12, Step: 480, Loss: 0.08275429159402847, Lr:0.0001\n",
      "Epoch 12, Step: 481, Loss: 0.03993707522749901, Lr:0.0001\n",
      "Epoch 12, Step: 482, Loss: 0.3269791007041931, Lr:0.0001\n",
      "Epoch 12, Step: 483, Loss: 0.32825255393981934, Lr:0.0001\n",
      "Epoch 12, Step: 484, Loss: 0.1913367658853531, Lr:0.0001\n",
      "Epoch 12, Step: 485, Loss: 0.016354219987988472, Lr:0.0001\n",
      "Epoch 12, Step: 486, Loss: 0.02213134802877903, Lr:0.0001\n",
      "Epoch 12, Step: 487, Loss: 0.012530871666967869, Lr:0.0001\n",
      "Epoch 12, Step: 488, Loss: 0.04046429321169853, Lr:0.0001\n",
      "Epoch 12, Step: 489, Loss: 0.164536714553833, Lr:0.0001\n",
      "Epoch 12, Step: 490, Loss: 0.17830564081668854, Lr:0.0001\n",
      "Epoch 12, Step: 491, Loss: 0.08610865473747253, Lr:0.0001\n",
      "Epoch 12, Step: 492, Loss: 0.06315582245588303, Lr:0.0001\n",
      "Epoch 12, Step: 493, Loss: 0.08441922813653946, Lr:0.0001\n",
      "Epoch 12, Step: 494, Loss: 0.05114204064011574, Lr:0.0001\n",
      "Epoch 12, Step: 495, Loss: 0.26312169432640076, Lr:0.0001\n",
      "Epoch 12, Step: 496, Loss: 0.2694161832332611, Lr:0.0001\n",
      "Epoch 12, Step: 497, Loss: 0.12261882424354553, Lr:0.0001\n",
      "Epoch 12, Step: 498, Loss: 0.0853780135512352, Lr:0.0001\n",
      "Epoch 12, Step: 499, Loss: 0.04198506474494934, Lr:0.0001\n",
      "Epoch 12, Step: 500, Loss: 0.06473322212696075, Lr:0.0001\n",
      "Epoch 12, Step: 501, Loss: 0.08181558549404144, Lr:0.0001\n",
      "Epoch 12, Step: 502, Loss: 0.11279270797967911, Lr:0.0001\n",
      "Epoch 12, Step: 503, Loss: 0.03763265162706375, Lr:0.0001\n",
      "Epoch 12, Step: 504, Loss: 0.0029653790406882763, Lr:0.0001\n",
      "Epoch 12, Step: 505, Loss: 0.15238042175769806, Lr:0.0001\n",
      "Epoch 12, Step: 506, Loss: 0.10756169259548187, Lr:0.0001\n",
      "Epoch 12, Step: 507, Loss: 0.20206496119499207, Lr:0.0001\n",
      "Epoch 12, Step: 508, Loss: 0.006798595655709505, Lr:0.0001\n",
      "Epoch 12, Step: 509, Loss: 0.0326126292347908, Lr:0.0001\n",
      "Epoch 12, Step: 510, Loss: 0.010671140626072884, Lr:0.0001\n",
      "Epoch 12, Step: 511, Loss: 0.11156218498945236, Lr:0.0001\n",
      "Epoch 12, Step: 512, Loss: 0.16205944120883942, Lr:0.0001\n",
      "Epoch 12, Step: 513, Loss: 0.04095149412751198, Lr:0.0001\n",
      "Epoch 12, Step: 514, Loss: 0.02651890739798546, Lr:0.0001\n",
      "Epoch 12, Step: 515, Loss: 0.08222103118896484, Lr:0.0001\n",
      "Epoch 12, Step: 516, Loss: 0.16226546466350555, Lr:0.0001\n",
      "Epoch 12, Step: 517, Loss: 0.07499929517507553, Lr:0.0001\n",
      "Epoch 12, Step: 518, Loss: 0.13578474521636963, Lr:0.0001\n",
      "Epoch 12, Step: 519, Loss: 0.11820435523986816, Lr:0.0001\n",
      "Epoch 12, Step: 520, Loss: 0.04274262487888336, Lr:0.0001\n",
      "Epoch 12, Step: 521, Loss: 0.10692142695188522, Lr:0.0001\n",
      "Epoch 12, Step: 522, Loss: 0.06526868045330048, Lr:0.0001\n",
      "Epoch 12, Step: 523, Loss: 0.1775703877210617, Lr:0.0001\n",
      "Epoch 12, Step: 524, Loss: 0.3015964925289154, Lr:0.0001\n",
      "Epoch 12, Step: 525, Loss: 0.4379124939441681, Lr:0.0001\n",
      "Epoch 12, Step: 526, Loss: 0.017331019043922424, Lr:0.0001\n",
      "Epoch 12, Step: 527, Loss: 0.10031550377607346, Lr:0.0001\n",
      "Epoch 12, Step: 528, Loss: 0.45574355125427246, Lr:0.0001\n",
      "Epoch 12, Step: 529, Loss: 0.20299382507801056, Lr:0.0001\n",
      "Epoch 12, Step: 530, Loss: 0.05421719327569008, Lr:0.0001\n",
      "Epoch 12, Step: 531, Loss: 0.0556708499789238, Lr:0.0001\n",
      "Epoch 12, Step: 532, Loss: 0.06158475950360298, Lr:0.0001\n",
      "Epoch 12, Step: 533, Loss: 0.11131409555673599, Lr:0.0001\n",
      "Epoch 12, Step: 534, Loss: 0.10923241823911667, Lr:0.0001\n",
      "Epoch 12, Step: 535, Loss: 0.04740772768855095, Lr:0.0001\n",
      "Epoch 12, Step: 536, Loss: 0.005132426042109728, Lr:0.0001\n",
      "Epoch 12, Step: 537, Loss: 0.04956628009676933, Lr:0.0001\n",
      "Epoch 12, Step: 538, Loss: 0.1579708606004715, Lr:0.0001\n",
      "Epoch 12, Step: 539, Loss: 0.08704313635826111, Lr:0.0001\n",
      "Epoch 12, Step: 540, Loss: 0.01707305572926998, Lr:0.0001\n",
      "Epoch 12, Step: 541, Loss: 0.10706755518913269, Lr:0.0001\n",
      "Epoch 12, Step: 542, Loss: 0.12116200476884842, Lr:0.0001\n",
      "Epoch 12, Step: 543, Loss: 0.18723025918006897, Lr:0.0001\n",
      "Epoch 12, Step: 544, Loss: 0.1895221769809723, Lr:0.0001\n",
      "Epoch 12, Step: 545, Loss: 0.38312971591949463, Lr:0.0001\n",
      "Epoch 12, Step: 546, Loss: 0.16143204271793365, Lr:0.0001\n",
      "Epoch 12, Step: 547, Loss: 0.12636278569698334, Lr:0.0001\n",
      "Epoch 12, Step: 548, Loss: 0.013503127731382847, Lr:0.0001\n",
      "Epoch 12, Step: 549, Loss: 0.1794085055589676, Lr:0.0001\n",
      "Epoch 12, Step: 550, Loss: 0.012519026175141335, Lr:0.0001\n",
      "Epoch 12, Step: 551, Loss: 0.01586746983230114, Lr:0.0001\n",
      "Epoch 12, Step: 552, Loss: 0.014698409475386143, Lr:0.0001\n",
      "Epoch 12, Step: 553, Loss: 0.023028096184134483, Lr:0.0001\n",
      "Epoch 12, Step: 554, Loss: 0.011679372750222683, Lr:0.0001\n",
      "Epoch 12, Step: 555, Loss: 0.04861687868833542, Lr:0.0001\n",
      "Epoch 12, Step: 556, Loss: 0.17884404957294464, Lr:0.0001\n",
      "Epoch 12, Step: 557, Loss: 0.2160072773694992, Lr:0.0001\n",
      "Epoch 12, Step: 558, Loss: 0.24870538711547852, Lr:0.0001\n",
      "Epoch 12, Step: 559, Loss: 0.0560002326965332, Lr:0.0001\n",
      "Epoch 12, Step: 560, Loss: 0.258331298828125, Lr:0.0001\n",
      "Epoch 12, Step: 561, Loss: 0.13650210201740265, Lr:0.0001\n",
      "Epoch 12, Step: 562, Loss: 0.25321152806282043, Lr:0.0001\n",
      "Epoch 12, Step: 563, Loss: 0.11571346968412399, Lr:0.0001\n",
      "Epoch 12, Step: 564, Loss: 0.07635924965143204, Lr:0.0001\n",
      "Epoch 12, Step: 565, Loss: 0.18262141942977905, Lr:0.0001\n",
      "Epoch 12, Step: 566, Loss: 0.06599658727645874, Lr:0.0001\n",
      "Epoch 12, Step: 567, Loss: 0.0436599999666214, Lr:0.0001\n",
      "Epoch 12, Step: 568, Loss: 0.1351448893547058, Lr:0.0001\n",
      "Epoch 12, Step: 569, Loss: 0.1849786341190338, Lr:0.0001\n",
      "Epoch 12, Step: 570, Loss: 0.07024940848350525, Lr:0.0001\n",
      "Epoch 12, Step: 571, Loss: 0.043239377439022064, Lr:0.0001\n",
      "Epoch 12, Step: 572, Loss: 0.17561779916286469, Lr:0.0001\n",
      "Epoch 12, Step: 573, Loss: 0.034579094499349594, Lr:0.0001\n",
      "Epoch 12, Step: 574, Loss: 0.1115318089723587, Lr:0.0001\n",
      "Epoch 12, Step: 575, Loss: 0.12248408794403076, Lr:0.0001\n",
      "Epoch 12, Step: 576, Loss: 0.08365087956190109, Lr:0.0001\n",
      "Epoch 12, Step: 577, Loss: 0.0461314432322979, Lr:0.0001\n",
      "Epoch 12, Step: 578, Loss: 0.0723724216222763, Lr:0.0001\n",
      "Epoch 12, Step: 579, Loss: 0.09318274259567261, Lr:0.0001\n",
      "Epoch 12, Step: 580, Loss: 0.03714286535978317, Lr:0.0001\n",
      "Epoch 12, Step: 581, Loss: 0.017788788303732872, Lr:0.0001\n",
      "Epoch 12, Step: 582, Loss: 0.11518757045269012, Lr:0.0001\n",
      "Epoch 12, Step: 583, Loss: 0.03175133466720581, Lr:0.0001\n",
      "Epoch 12, Step: 584, Loss: 0.0812387689948082, Lr:0.0001\n",
      "Epoch 12, Step: 585, Loss: 0.253061980009079, Lr:0.0001\n",
      "Epoch 12, Step: 586, Loss: 0.24338960647583008, Lr:0.0001\n",
      "Epoch 12, Step: 587, Loss: 0.26905515789985657, Lr:0.0001\n",
      "Epoch 12, Step: 588, Loss: 0.10879071801900864, Lr:0.0001\n",
      "Epoch 12, Step: 589, Loss: 0.08125238120555878, Lr:0.0001\n",
      "Epoch 12, Step: 590, Loss: 0.12118355929851532, Lr:0.0001\n",
      "Epoch 12, Step: 591, Loss: 0.2031812220811844, Lr:0.0001\n",
      "Epoch 12, Step: 592, Loss: 0.058477409183979034, Lr:0.0001\n",
      "Epoch 12, Step: 593, Loss: 0.10556963086128235, Lr:0.0001\n",
      "Epoch 12, Step: 594, Loss: 0.10222722589969635, Lr:0.0001\n",
      "Epoch 12, Step: 595, Loss: 0.009297898039221764, Lr:0.0001\n",
      "Epoch 12, Step: 596, Loss: 0.08696099370718002, Lr:0.0001\n",
      "Epoch 12, Step: 597, Loss: 0.007709154859185219, Lr:0.0001\n",
      "Epoch 12, Step: 598, Loss: 0.08123984187841415, Lr:0.0001\n",
      "Epoch 12, Step: 599, Loss: 0.26519638299942017, Lr:0.0001\n",
      "Epoch 12, Step: 600, Loss: 0.2273768037557602, Lr:0.0001\n",
      "Epoch 12, Step: 601, Loss: 0.028801124542951584, Lr:0.0001\n",
      "Epoch 12, Step: 602, Loss: 0.6922577023506165, Lr:0.0001\n",
      "Epoch 12, Step: 603, Loss: 0.08704245090484619, Lr:0.0001\n",
      "Epoch 12, Step: 604, Loss: 0.1808088719844818, Lr:0.0001\n",
      "Epoch 12, Step: 605, Loss: 0.12179049104452133, Lr:0.0001\n",
      "Epoch 12, Step: 606, Loss: 0.019222307950258255, Lr:0.0001\n",
      "Epoch 12, Step: 607, Loss: 0.06268694996833801, Lr:0.0001\n",
      "Epoch 12, Step: 608, Loss: 0.2646337151527405, Lr:0.0001\n",
      "Epoch 12, Step: 609, Loss: 0.10039582848548889, Lr:0.0001\n",
      "Epoch 12, Step: 610, Loss: 0.10342299938201904, Lr:0.0001\n",
      "Epoch 12, Step: 611, Loss: 0.07539694756269455, Lr:0.0001\n",
      "Epoch 12, Step: 612, Loss: 0.07846856117248535, Lr:0.0001\n",
      "Epoch 12, Step: 613, Loss: 0.07781398296356201, Lr:0.0001\n",
      "Epoch 12, Step: 614, Loss: 0.12655194103717804, Lr:0.0001\n",
      "Epoch 12, Step: 615, Loss: 0.013158586807549, Lr:0.0001\n",
      "Epoch 12, Step: 616, Loss: 0.011651141569018364, Lr:0.0001\n",
      "Epoch 12, Step: 617, Loss: 0.021014820784330368, Lr:0.0001\n",
      "Epoch 12, Step: 618, Loss: 0.12814009189605713, Lr:0.0001\n",
      "Epoch 12, Step: 619, Loss: 0.14495018124580383, Lr:0.0001\n",
      "Epoch 12, Step: 620, Loss: 0.12282951921224594, Lr:0.0001\n",
      "Epoch 12, Step: 621, Loss: 0.5014081597328186, Lr:0.0001\n",
      "Epoch 12, Step: 622, Loss: 0.05413766950368881, Lr:0.0001\n",
      "Epoch 12, Step: 623, Loss: 0.09949244558811188, Lr:0.0001\n",
      "Epoch 12, Step: 624, Loss: 0.07272277772426605, Lr:0.0001\n",
      "Epoch 12, Step: 625, Loss: 0.02064051851630211, Lr:0.0001\n",
      "Epoch 12, Step: 626, Loss: 0.06641854345798492, Lr:0.0001\n",
      "Epoch 12, Step: 627, Loss: 0.11755003780126572, Lr:0.0001\n",
      "Epoch 12, Step: 628, Loss: 0.11520932614803314, Lr:0.0001\n",
      "Epoch 12, Step: 629, Loss: 0.1574808806180954, Lr:0.0001\n",
      "Epoch 12, Step: 630, Loss: 0.20069029927253723, Lr:0.0001\n",
      "Epoch 12, Step: 631, Loss: 0.0287654846906662, Lr:0.0001\n",
      "Epoch 12, Step: 632, Loss: 0.04128248989582062, Lr:0.0001\n",
      "Epoch 12, Step: 633, Loss: 0.05045781284570694, Lr:0.0001\n",
      "Epoch 12, Step: 634, Loss: 0.14754903316497803, Lr:0.0001\n",
      "Epoch 12, Step: 635, Loss: 0.025822166353464127, Lr:0.0001\n",
      "Epoch 12, Step: 636, Loss: 0.18379811942577362, Lr:0.0001\n",
      "Epoch 12, Step: 637, Loss: 0.01896035298705101, Lr:0.0001\n",
      "Epoch 12, Step: 638, Loss: 0.013356931507587433, Lr:0.0001\n",
      "Epoch 12, Step: 639, Loss: 0.05730943754315376, Lr:0.0001\n",
      "Epoch 12, Step: 640, Loss: 0.022180892527103424, Lr:0.0001\n",
      "Epoch 12, Step: 641, Loss: 0.3869163691997528, Lr:0.0001\n",
      "Epoch 12, Step: 642, Loss: 0.12053681910037994, Lr:0.0001\n",
      "Epoch 12, Step: 643, Loss: 0.15467888116836548, Lr:0.0001\n",
      "Epoch 12, Step: 644, Loss: 0.05615996941924095, Lr:0.0001\n",
      "Epoch 12, Step: 645, Loss: 0.05534875765442848, Lr:0.0001\n",
      "Epoch 12, Step: 646, Loss: 0.27271780371665955, Lr:0.0001\n",
      "Epoch 12, Step: 647, Loss: 0.05229419842362404, Lr:0.0001\n",
      "Epoch 12, Step: 648, Loss: 0.113375723361969, Lr:0.0001\n",
      "Epoch 12, Step: 649, Loss: 0.09832417964935303, Lr:0.0001\n",
      "Epoch 12, Step: 650, Loss: 0.018417082726955414, Lr:0.0001\n",
      "Epoch 12, Step: 651, Loss: 0.012143060564994812, Lr:0.0001\n",
      "Epoch 12, Step: 652, Loss: 0.22723796963691711, Lr:0.0001\n",
      "Epoch 12, Step: 653, Loss: 0.034705255180597305, Lr:0.0001\n",
      "Epoch 12, Step: 654, Loss: 0.41062596440315247, Lr:0.0001\n",
      "Epoch 12, Step: 655, Loss: 0.06917186081409454, Lr:0.0001\n",
      "Epoch 12, Step: 656, Loss: 0.05539010465145111, Lr:0.0001\n",
      "Epoch 12, Step: 657, Loss: 0.1263919621706009, Lr:0.0001\n",
      "Epoch 12, Step: 658, Loss: 0.08662844449281693, Lr:0.0001\n",
      "Epoch 12, Step: 659, Loss: 0.035643018782138824, Lr:0.0001\n",
      "Epoch 12, Step: 660, Loss: 0.2340400069952011, Lr:0.0001\n",
      "Epoch 12, Step: 661, Loss: 0.06692144274711609, Lr:0.0001\n",
      "Epoch 12, Step: 662, Loss: 0.3083398640155792, Lr:0.0001\n",
      "Epoch 12, Step: 663, Loss: 0.2686064839363098, Lr:0.0001\n",
      "Epoch 12, Step: 664, Loss: 0.08851045370101929, Lr:0.0001\n",
      "Epoch 12, Step: 665, Loss: 0.12355391681194305, Lr:0.0001\n",
      "Epoch 12, Step: 666, Loss: 0.3658193051815033, Lr:0.0001\n",
      "Epoch 12, Step: 667, Loss: 0.06338167190551758, Lr:0.0001\n",
      "Epoch 12, Step: 668, Loss: 0.025366492569446564, Lr:0.0001\n",
      "Epoch 12, Step: 669, Loss: 0.08979678899049759, Lr:0.0001\n",
      "Epoch 12, Step: 670, Loss: 0.18029405176639557, Lr:0.0001\n",
      "Epoch 12, Step: 671, Loss: 0.0408799909055233, Lr:0.0001\n",
      "Epoch 12, Step: 672, Loss: 0.09736063331365585, Lr:0.0001\n",
      "Epoch 12, Step: 673, Loss: 0.11668268591165543, Lr:0.0001\n",
      "Epoch 12, Step: 674, Loss: 0.2442559450864792, Lr:0.0001\n",
      "Epoch 12, Step: 675, Loss: 0.016572723165154457, Lr:0.0001\n",
      "Epoch 12, Step: 676, Loss: 0.08294020593166351, Lr:0.0001\n",
      "Epoch 12, Step: 677, Loss: 0.11137142032384872, Lr:0.0001\n",
      "Epoch 12, Step: 678, Loss: 0.047801900655031204, Lr:0.0001\n",
      "Epoch 12, Step: 679, Loss: 0.08038121461868286, Lr:0.0001\n",
      "Epoch 12, Step: 680, Loss: 0.30531370639801025, Lr:0.0001\n",
      "Epoch 12, Step: 681, Loss: 0.05228688195347786, Lr:0.0001\n",
      "Epoch 12, Step: 682, Loss: 0.08731787651777267, Lr:0.0001\n",
      "Epoch 12, Step: 683, Loss: 0.09706611931324005, Lr:0.0001\n",
      "Epoch 12, Step: 684, Loss: 0.1279963105916977, Lr:0.0001\n",
      "Epoch 12, Step: 685, Loss: 0.00631287507712841, Lr:0.0001\n",
      "Epoch 12, Step: 686, Loss: 0.37635838985443115, Lr:0.0001\n",
      "Epoch 12, Step: 687, Loss: 0.06957075744867325, Lr:0.0001\n",
      "Epoch 12, Step: 688, Loss: 0.09865871071815491, Lr:0.0001\n",
      "Epoch 12, Step: 689, Loss: 0.6411373615264893, Lr:0.0001\n",
      "Epoch 12, Step: 690, Loss: 0.13100062310695648, Lr:0.0001\n",
      "Epoch 12, Step: 691, Loss: 0.11018186807632446, Lr:0.0001\n",
      "Epoch 12, Step: 692, Loss: 0.12906630337238312, Lr:0.0001\n",
      "Epoch 12, Step: 693, Loss: 0.012252873741090298, Lr:0.0001\n",
      "Epoch 12, Step: 694, Loss: 0.17858675122261047, Lr:0.0001\n",
      "Epoch 12, Step: 695, Loss: 0.21385708451271057, Lr:0.0001\n",
      "Epoch 12, Step: 696, Loss: 0.09126825630664825, Lr:0.0001\n",
      "Epoch 12, Step: 697, Loss: 0.2608775198459625, Lr:0.0001\n",
      "Epoch 12, Step: 698, Loss: 0.40923207998275757, Lr:0.0001\n",
      "Epoch 12, Step: 699, Loss: 0.008396361023187637, Lr:0.0001\n",
      "Epoch 12, Step: 700, Loss: 0.03035202994942665, Lr:0.0001\n",
      "Epoch 12, Step: 701, Loss: 0.19986295700073242, Lr:0.0001\n",
      "Epoch 12, Step: 702, Loss: 0.15579628944396973, Lr:0.0001\n",
      "Epoch 12, Step: 703, Loss: 0.361104279756546, Lr:0.0001\n",
      "Epoch 12, Step: 704, Loss: 0.21756309270858765, Lr:0.0001\n",
      "Epoch 12, Step: 705, Loss: 0.17784789204597473, Lr:0.0001\n",
      "Epoch 12, Step: 706, Loss: 0.23506127297878265, Lr:0.0001\n",
      "Epoch 12, Step: 707, Loss: 0.017813587561249733, Lr:0.0001\n",
      "Epoch 12, Step: 708, Loss: 0.2100861668586731, Lr:0.0001\n",
      "Epoch 12, Step: 709, Loss: 0.022761885076761246, Lr:0.0001\n",
      "Epoch 12, Step: 710, Loss: 0.11187153309583664, Lr:0.0001\n",
      "Epoch 12, Step: 711, Loss: 0.08155975490808487, Lr:0.0001\n",
      "Epoch 12, Step: 712, Loss: 0.037685126066207886, Lr:0.0001\n",
      "Epoch 12, Step: 713, Loss: 0.08443797379732132, Lr:0.0001\n",
      "Epoch 12, Step: 714, Loss: 0.1476975679397583, Lr:0.0001\n",
      "Epoch 12, Step: 715, Loss: 0.14018607139587402, Lr:0.0001\n",
      "Epoch 12, Step: 716, Loss: 0.14443153142929077, Lr:0.0001\n",
      "Epoch 12, Step: 717, Loss: 0.07867331057786942, Lr:0.0001\n",
      "Epoch 12, Step: 718, Loss: 0.02148735709488392, Lr:0.0001\n",
      "Epoch 12, Step: 719, Loss: 0.18103550374507904, Lr:0.0001\n",
      "Epoch 12, Step: 720, Loss: 0.5989094972610474, Lr:0.0001\n",
      "Epoch 12, Step: 721, Loss: 0.05181706324219704, Lr:0.0001\n",
      "Epoch 12, Step: 722, Loss: 0.07969354093074799, Lr:0.0001\n",
      "Epoch 12, Step: 723, Loss: 0.15907511115074158, Lr:0.0001\n",
      "Epoch 12, Step: 724, Loss: 0.4704340398311615, Lr:0.0001\n",
      "Epoch 12, Step: 725, Loss: 0.19446469843387604, Lr:0.0001\n",
      "Epoch 12, Step: 726, Loss: 0.04393364489078522, Lr:0.0001\n",
      "Epoch 12, Step: 727, Loss: 0.2198462337255478, Lr:0.0001\n",
      "Epoch 12, Step: 728, Loss: 0.03437299653887749, Lr:0.0001\n",
      "Epoch 12, Step: 729, Loss: 0.03962084278464317, Lr:0.0001\n",
      "Epoch 12, Step: 730, Loss: 0.12573489546775818, Lr:0.0001\n",
      "Epoch 12, Step: 731, Loss: 0.34508273005485535, Lr:0.0001\n",
      "Epoch 12, Step: 732, Loss: 0.05602496862411499, Lr:0.0001\n",
      "Epoch 12, Step: 733, Loss: 0.05908140167593956, Lr:0.0001\n",
      "Epoch 12, Step: 734, Loss: 0.15881772339344025, Lr:0.0001\n",
      "Epoch 12, Step: 735, Loss: 0.11298476159572601, Lr:0.0001\n",
      "Epoch 12, Step: 736, Loss: 0.060982853174209595, Lr:0.0001\n",
      "Epoch 12, Step: 737, Loss: 0.027776213362812996, Lr:0.0001\n",
      "Epoch 12, Step: 738, Loss: 0.1973608434200287, Lr:0.0001\n",
      "Epoch 12, Step: 739, Loss: 0.12459222227334976, Lr:0.0001\n",
      "Epoch 12, Step: 740, Loss: 0.06266216933727264, Lr:0.0001\n",
      "Epoch 12, Step: 741, Loss: 0.3113006055355072, Lr:0.0001\n",
      "Epoch 12, Step: 742, Loss: 0.020368052646517754, Lr:0.0001\n",
      "Epoch 12, Step: 743, Loss: 0.05555422231554985, Lr:0.0001\n",
      "Epoch 12, Step: 744, Loss: 0.12794186174869537, Lr:0.0001\n",
      "Epoch 12, Step: 745, Loss: 0.15176071226596832, Lr:0.0001\n",
      "Epoch 12, Step: 746, Loss: 0.11529147624969482, Lr:0.0001\n",
      "Epoch 12, Step: 747, Loss: 0.03055177628993988, Lr:0.0001\n",
      "Epoch 12, Step: 748, Loss: 0.11160539090633392, Lr:0.0001\n",
      "Epoch 12, Step: 749, Loss: 0.017059046775102615, Lr:0.0001\n",
      "Epoch 12, Step: 750, Loss: 0.01966867782175541, Lr:0.0001\n",
      "Epoch 12, Step: 751, Loss: 0.29177793860435486, Lr:0.0001\n",
      "Epoch 12, Step: 752, Loss: 0.18210846185684204, Lr:0.0001\n",
      "Epoch 12, Step: 753, Loss: 0.09845829010009766, Lr:0.0001\n",
      "Epoch 12, Step: 754, Loss: 0.04364955052733421, Lr:0.0001\n",
      "Epoch 12, Step: 755, Loss: 0.07051464170217514, Lr:0.0001\n",
      "Epoch 12, Step: 756, Loss: 0.07102500647306442, Lr:0.0001\n",
      "Epoch 12, Step: 757, Loss: 0.02655789628624916, Lr:0.0001\n",
      "Epoch 12, Step: 758, Loss: 0.1123824492096901, Lr:0.0001\n",
      "Epoch 12, Step: 759, Loss: 0.026743140071630478, Lr:0.0001\n",
      "Epoch 12, Step: 760, Loss: 0.12164893746376038, Lr:0.0001\n",
      "Epoch 12, Step: 761, Loss: 0.14765189588069916, Lr:0.0001\n",
      "Epoch 12, Step: 762, Loss: 0.5141364932060242, Lr:0.0001\n",
      "Epoch 12, Step: 763, Loss: 0.19732294976711273, Lr:0.0001\n",
      "Epoch 12, Step: 764, Loss: 0.022623294964432716, Lr:0.0001\n",
      "Epoch 12, Step: 765, Loss: 0.07672948390245438, Lr:0.0001\n",
      "Epoch 12, Step: 766, Loss: 0.3409300744533539, Lr:0.0001\n",
      "Epoch 12, Step: 767, Loss: 0.2394302487373352, Lr:0.0001\n",
      "Epoch 12, Step: 768, Loss: 0.19369962811470032, Lr:0.0001\n",
      "Epoch 12, Step: 769, Loss: 0.05891237407922745, Lr:0.0001\n",
      "Epoch 12, Step: 770, Loss: 0.35250282287597656, Lr:0.0001\n",
      "Epoch 12, Step: 771, Loss: 0.0952528640627861, Lr:0.0001\n",
      "Epoch 12, Step: 772, Loss: 0.0952688530087471, Lr:0.0001\n",
      "Epoch 12, Step: 773, Loss: 0.054165538400411606, Lr:0.0001\n",
      "Epoch 12, Step: 774, Loss: 0.07447893172502518, Lr:0.0001\n",
      "Epoch 12, Step: 775, Loss: 0.2871348261833191, Lr:0.0001\n",
      "Epoch 12, Step: 776, Loss: 0.18862289190292358, Lr:0.0001\n",
      "Epoch 12, Step: 777, Loss: 0.08866690844297409, Lr:0.0001\n",
      "Epoch 12, Step: 778, Loss: 0.03851456567645073, Lr:0.0001\n",
      "Epoch 12, Step: 779, Loss: 0.4027934670448303, Lr:0.0001\n",
      "Epoch 12, Step: 780, Loss: 0.2750316262245178, Lr:0.0001\n",
      "Epoch 12, Step: 781, Loss: 0.1991947889328003, Lr:0.0001\n",
      "Epoch 12, Step: 782, Loss: 0.012412035837769508, Lr:0.0001\n",
      "Epoch 12, Step: 783, Loss: 0.08832960575819016, Lr:0.0001\n",
      "Epoch 12, Step: 784, Loss: 0.06549569219350815, Lr:0.0001\n",
      "Epoch 12, Step: 785, Loss: 0.018093308433890343, Lr:0.0001\n",
      "Epoch 12, Step: 786, Loss: 0.05156014859676361, Lr:0.0001\n",
      "Epoch 12, Step: 787, Loss: 0.0321730375289917, Lr:0.0001\n",
      "Epoch 12, Step: 788, Loss: 0.11005157977342606, Lr:0.0001\n",
      "Epoch 12, Step: 789, Loss: 0.138961523771286, Lr:0.0001\n",
      "Epoch 12, Step: 790, Loss: 0.12273683398962021, Lr:0.0001\n",
      "Epoch 12, Step: 791, Loss: 0.2551253139972687, Lr:0.0001\n",
      "Epoch 12, Step: 792, Loss: 0.10047446936368942, Lr:0.0001\n",
      "Epoch 12, Step: 793, Loss: 0.08417696505784988, Lr:0.0001\n",
      "Epoch 12, Step: 794, Loss: 0.04497262090444565, Lr:0.0001\n",
      "Epoch 12, Step: 795, Loss: 0.011902578175067902, Lr:0.0001\n",
      "Epoch 12, Step: 796, Loss: 0.044134270399808884, Lr:0.0001\n",
      "Epoch 12, Step: 797, Loss: 0.04700404778122902, Lr:0.0001\n",
      "Epoch 12, Step: 798, Loss: 0.18834558129310608, Lr:0.0001\n",
      "Epoch 12, Step: 799, Loss: 0.11281262338161469, Lr:0.0001\n",
      "Epoch 12, Step: 800, Loss: 0.059044260531663895, Lr:0.0001\n",
      "Epoch 12, Step: 801, Loss: 0.05782020092010498, Lr:0.0001\n",
      "Epoch 12, Step: 802, Loss: 0.12499552965164185, Lr:0.0001\n",
      "Epoch 12, Step: 803, Loss: 0.07799321413040161, Lr:0.0001\n",
      "Epoch 12, Step: 804, Loss: 0.0034382259473204613, Lr:0.0001\n",
      "Epoch 12, Step: 805, Loss: 0.06110983341932297, Lr:0.0001\n",
      "Epoch 12, Step: 806, Loss: 0.21777686476707458, Lr:0.0001\n",
      "Epoch 12, Step: 807, Loss: 0.17247967422008514, Lr:0.0001\n",
      "Epoch 12, Step: 808, Loss: 0.09169360250234604, Lr:0.0001\n",
      "Epoch 12, Step: 809, Loss: 0.11052533239126205, Lr:0.0001\n",
      "Epoch 12, Step: 810, Loss: 0.17977328598499298, Lr:0.0001\n",
      "Epoch 12, Step: 811, Loss: 0.012941909022629261, Lr:0.0001\n",
      "Epoch 12, Step: 812, Loss: 0.15194550156593323, Lr:0.0001\n",
      "Epoch 12, Step: 813, Loss: 0.10630493611097336, Lr:0.0001\n",
      "Epoch 12, Step: 814, Loss: 0.17163193225860596, Lr:0.0001\n",
      "Epoch 12, Step: 815, Loss: 0.31021490693092346, Lr:0.0001\n",
      "Epoch 12, Step: 816, Loss: 0.19837266206741333, Lr:0.0001\n",
      "Epoch 12, Step: 817, Loss: 0.1966574341058731, Lr:0.0001\n",
      "Epoch 12, Step: 818, Loss: 0.1703033149242401, Lr:0.0001\n",
      "Epoch 12, Step: 819, Loss: 0.017964620143175125, Lr:0.0001\n",
      "Epoch 12, Step: 820, Loss: 0.0598004125058651, Lr:0.0001\n",
      "Epoch 12, Step: 821, Loss: 0.10951288044452667, Lr:0.0001\n",
      "Epoch 12, Step: 822, Loss: 0.042683474719524384, Lr:0.0001\n",
      "Epoch 12, Step: 823, Loss: 0.08700612187385559, Lr:0.0001\n",
      "Epoch 12, Step: 824, Loss: 0.16062873601913452, Lr:0.0001\n",
      "Epoch 12, Step: 825, Loss: 0.016653697937726974, Lr:0.0001\n",
      "Epoch 12, Step: 826, Loss: 0.13751420378684998, Lr:0.0001\n",
      "Epoch 12, Step: 827, Loss: 0.6984969973564148, Lr:0.0001\n",
      "Epoch 12, Step: 828, Loss: 0.08817437291145325, Lr:0.0001\n",
      "Epoch 12, Step: 829, Loss: 0.32301202416419983, Lr:0.0001\n",
      "Epoch 12, Step: 830, Loss: 0.17485930025577545, Lr:0.0001\n",
      "Epoch 12, Step: 831, Loss: 0.021526634693145752, Lr:0.0001\n",
      "Epoch 12, Step: 832, Loss: 0.12412839382886887, Lr:0.0001\n",
      "Epoch 12, Step: 833, Loss: 0.22292251884937286, Lr:0.0001\n",
      "Epoch 12, Step: 834, Loss: 0.1458049863576889, Lr:0.0001\n",
      "Epoch 12, Step: 835, Loss: 0.2025885432958603, Lr:0.0001\n",
      "Epoch 12, Step: 836, Loss: 0.15251164138317108, Lr:0.0001\n",
      "Epoch 12, Step: 837, Loss: 0.21835601329803467, Lr:0.0001\n",
      "Epoch 12, Step: 838, Loss: 0.02080223336815834, Lr:0.0001\n",
      "Epoch 12, Step: 839, Loss: 0.31546714901924133, Lr:0.0001\n",
      "Epoch 12, Step: 840, Loss: 0.08549009263515472, Lr:0.0001\n",
      "Epoch 12, Step: 841, Loss: 0.007327510509639978, Lr:0.0001\n",
      "Epoch 12, Step: 842, Loss: 0.07861896604299545, Lr:0.0001\n",
      "Epoch 12, Step: 843, Loss: 0.10556674003601074, Lr:0.0001\n",
      "Epoch 12, Step: 844, Loss: 0.09631945937871933, Lr:0.0001\n",
      "Epoch 12, Step: 845, Loss: 0.13394464552402496, Lr:0.0001\n",
      "Epoch 12, Step: 846, Loss: 0.05527199059724808, Lr:0.0001\n",
      "Epoch 12, Step: 847, Loss: 0.3917963206768036, Lr:0.0001\n",
      "Epoch 12, Step: 848, Loss: 0.14558535814285278, Lr:0.0001\n",
      "Epoch 12, Step: 849, Loss: 0.28077638149261475, Lr:0.0001\n",
      "Epoch 12, Step: 850, Loss: 0.06646303832530975, Lr:0.0001\n",
      "Epoch 12, Step: 851, Loss: 0.005852380767464638, Lr:0.0001\n",
      "Epoch 12, Step: 852, Loss: 0.21561148762702942, Lr:0.0001\n",
      "Epoch 12, Step: 853, Loss: 0.08522608131170273, Lr:0.0001\n",
      "Epoch 12, Step: 854, Loss: 0.3453671932220459, Lr:0.0001\n",
      "Epoch 12, Step: 855, Loss: 0.13825321197509766, Lr:0.0001\n",
      "Epoch 12, Step: 856, Loss: 0.2082386016845703, Lr:0.0001\n",
      "Epoch 12, Step: 857, Loss: 0.10204128175973892, Lr:0.0001\n",
      "Epoch 12, Step: 858, Loss: 0.020145611837506294, Lr:0.0001\n",
      "Epoch 12, Step: 859, Loss: 0.03177821636199951, Lr:0.0001\n",
      "Epoch 12, Step: 860, Loss: 0.3477473258972168, Lr:0.0001\n",
      "Epoch 12, Step: 861, Loss: 0.021464886143803596, Lr:0.0001\n",
      "Epoch 12, Step: 862, Loss: 0.1311383843421936, Lr:0.0001\n",
      "Epoch 12, Step: 863, Loss: 0.10028631240129471, Lr:0.0001\n",
      "Epoch 12, Step: 864, Loss: 0.11815346777439117, Lr:0.0001\n",
      "Epoch 12, Step: 865, Loss: 0.06935957074165344, Lr:0.0001\n",
      "Epoch 12, Step: 866, Loss: 0.24544882774353027, Lr:0.0001\n",
      "Epoch 12, Step: 867, Loss: 0.14336980879306793, Lr:0.0001\n",
      "Epoch 12, Step: 868, Loss: 0.018859075382351875, Lr:0.0001\n",
      "Epoch 12, Step: 869, Loss: 0.31691810488700867, Lr:0.0001\n",
      "Epoch 12, Step: 870, Loss: 0.055650778114795685, Lr:0.0001\n",
      "Epoch 12, Step: 871, Loss: 0.3098107576370239, Lr:0.0001\n",
      "Epoch 12, Step: 872, Loss: 0.11295347660779953, Lr:0.0001\n",
      "Epoch 12, Step: 873, Loss: 0.0563572533428669, Lr:0.0001\n",
      "Epoch 12, Step: 874, Loss: 0.0912519320845604, Lr:0.0001\n",
      "Epoch 12, Step: 875, Loss: 0.1072327122092247, Lr:0.0001\n",
      "Epoch 12, Step: 876, Loss: 0.10527107864618301, Lr:0.0001\n",
      "Epoch 12, Step: 877, Loss: 0.05801798775792122, Lr:0.0001\n",
      "Epoch 12, Step: 878, Loss: 0.07501403242349625, Lr:0.0001\n",
      "Epoch 12, Step: 879, Loss: 0.5824447870254517, Lr:0.0001\n",
      "Epoch 12, Step: 880, Loss: 0.09984638541936874, Lr:0.0001\n",
      "Epoch 12, Step: 881, Loss: 0.07703164964914322, Lr:0.0001\n",
      "Epoch 12, Step: 882, Loss: 0.08144046366214752, Lr:0.0001\n",
      "Epoch 12, Step: 883, Loss: 0.01950956881046295, Lr:0.0001\n",
      "Epoch 12, Step: 884, Loss: 0.005080780014395714, Lr:0.0001\n",
      "Epoch 12, Step: 885, Loss: 0.5076991319656372, Lr:0.0001\n",
      "Epoch 12, Step: 886, Loss: 0.11110737174749374, Lr:0.0001\n",
      "Epoch 12, Step: 887, Loss: 0.05193686857819557, Lr:0.0001\n",
      "Epoch 12, Step: 888, Loss: 0.0930507630109787, Lr:0.0001\n",
      "Epoch 12, Step: 889, Loss: 0.09998700022697449, Lr:0.0001\n",
      "Epoch 12, Step: 890, Loss: 0.17126142978668213, Lr:0.0001\n",
      "Epoch 12, Step: 891, Loss: 0.2656189501285553, Lr:0.0001\n",
      "Epoch 12, Step: 892, Loss: 0.16656529903411865, Lr:0.0001\n",
      "Epoch 12, Step: 893, Loss: 0.09014563262462616, Lr:0.0001\n",
      "Epoch 12, Step: 894, Loss: 0.044615428894758224, Lr:0.0001\n",
      "Epoch 12, Step: 895, Loss: 0.10182410478591919, Lr:0.0001\n",
      "Epoch 12, Step: 896, Loss: 0.21764683723449707, Lr:0.0001\n",
      "Epoch 12, Step: 897, Loss: 0.06974753737449646, Lr:0.0001\n",
      "Epoch 12, Step: 898, Loss: 0.032928988337516785, Lr:0.0001\n",
      "Epoch 12, Step: 899, Loss: 0.08315823972225189, Lr:0.0001\n",
      "Epoch 12, Step: 900, Loss: 0.08258376270532608, Lr:0.0001\n",
      "Epoch 12, Step: 901, Loss: 0.12776066362857819, Lr:0.0001\n",
      "Epoch 12, Step: 902, Loss: 0.11119581013917923, Lr:0.0001\n",
      "Epoch 12, Step: 903, Loss: 0.018177079036831856, Lr:0.0001\n",
      "Epoch 12, Step: 904, Loss: 0.033340949565172195, Lr:0.0001\n",
      "Epoch 12, Step: 905, Loss: 0.1988922506570816, Lr:0.0001\n",
      "Epoch 12, Step: 906, Loss: 0.10886246711015701, Lr:0.0001\n",
      "Epoch 12, Step: 907, Loss: 0.17138881981372833, Lr:0.0001\n",
      "Epoch 12, Step: 908, Loss: 0.019843144342303276, Lr:0.0001\n",
      "Epoch 12, Step: 909, Loss: 0.04215481877326965, Lr:0.0001\n",
      "Epoch 12, Step: 910, Loss: 0.01718132197856903, Lr:0.0001\n",
      "Epoch 12, Step: 911, Loss: 0.045880332589149475, Lr:0.0001\n",
      "Epoch 12, Step: 912, Loss: 0.21369025111198425, Lr:0.0001\n",
      "Epoch 12, Step: 913, Loss: 0.046348463743925095, Lr:0.0001\n",
      "Epoch 12, Step: 914, Loss: 0.04500158131122589, Lr:0.0001\n",
      "Epoch 12, Step: 915, Loss: 0.05959462746977806, Lr:0.0001\n",
      "Epoch 12, Step: 916, Loss: 0.037461310625076294, Lr:0.0001\n",
      "Epoch 12, Step: 917, Loss: 0.06070176884531975, Lr:0.0001\n",
      "Epoch 12, Step: 918, Loss: 0.31049248576164246, Lr:0.0001\n",
      "Epoch 12, Step: 919, Loss: 0.07207734137773514, Lr:0.0001\n",
      "Epoch 12, Step: 920, Loss: 0.35235297679901123, Lr:0.0001\n",
      "Epoch 12, Step: 921, Loss: 0.08097510039806366, Lr:0.0001\n",
      "Epoch 12, Step: 922, Loss: 0.08616382628679276, Lr:0.0001\n",
      "Epoch 12, Step: 923, Loss: 0.06921197474002838, Lr:0.0001\n",
      "Epoch 12, Step: 924, Loss: 0.05893956869840622, Lr:0.0001\n",
      "Epoch 12, Step: 925, Loss: 0.022168075665831566, Lr:0.0001\n",
      "Epoch 12, Step: 926, Loss: 0.12005062401294708, Lr:0.0001\n",
      "Epoch 12, Step: 927, Loss: 0.035506416112184525, Lr:0.0001\n",
      "Epoch 12, Step: 928, Loss: 0.14770741760730743, Lr:0.0001\n",
      "Epoch 12, Step: 929, Loss: 0.007806702982634306, Lr:0.0001\n",
      "Epoch 12, Step: 930, Loss: 0.14336435496807098, Lr:0.0001\n",
      "Epoch 12, Step: 931, Loss: 0.20223785936832428, Lr:0.0001\n",
      "Epoch 12, Step: 932, Loss: 0.11731644719839096, Lr:0.0001\n",
      "Epoch 12, Step: 933, Loss: 0.06716195493936539, Lr:0.0001\n",
      "Epoch 12, Step: 934, Loss: 0.09045112878084183, Lr:0.0001\n",
      "Epoch 12, Step: 935, Loss: 0.021928248926997185, Lr:0.0001\n",
      "Epoch 12, Step: 936, Loss: 0.22352752089500427, Lr:0.0001\n",
      "Epoch 12, Step: 937, Loss: 0.07038585841655731, Lr:0.0001\n",
      "Epoch 12, Step: 938, Loss: 0.053001828491687775, Lr:0.0001\n",
      "Epoch 12, Step: 939, Loss: 0.1965983510017395, Lr:0.0001\n",
      "Epoch 12, Step: 940, Loss: 0.011859435588121414, Lr:0.0001\n",
      "Epoch 12, Step: 941, Loss: 0.037142958492040634, Lr:0.0001\n",
      "Epoch 12, Step: 942, Loss: 0.017100363969802856, Lr:0.0001\n",
      "Epoch 12, Step: 943, Loss: 0.1428813487291336, Lr:0.0001\n",
      "Epoch 12, Step: 944, Loss: 0.08677639812231064, Lr:0.0001\n",
      "Epoch 12, Step: 945, Loss: 0.05564248189330101, Lr:0.0001\n",
      "Epoch 12, Step: 946, Loss: 0.06757035106420517, Lr:0.0001\n",
      "Epoch 12, Step: 947, Loss: 0.24697205424308777, Lr:0.0001\n",
      "Epoch 12, Step: 948, Loss: 0.019559985026717186, Lr:0.0001\n",
      "Epoch 12, Step: 949, Loss: 0.04976445063948631, Lr:0.0001\n",
      "Epoch 12, Step: 950, Loss: 0.21321891248226166, Lr:0.0001\n",
      "Epoch 12, Step: 951, Loss: 0.3155403435230255, Lr:0.0001\n",
      "Epoch 12, Step: 952, Loss: 0.25264060497283936, Lr:0.0001\n",
      "Epoch 12, Step: 953, Loss: 0.1685337871313095, Lr:0.0001\n",
      "Epoch 12, Step: 954, Loss: 0.1536303460597992, Lr:0.0001\n",
      "Epoch 12, Step: 955, Loss: 0.18473023176193237, Lr:0.0001\n",
      "Epoch 12, Step: 956, Loss: 0.0269513800740242, Lr:0.0001\n",
      "Epoch 12, Step: 957, Loss: 0.06563842296600342, Lr:0.0001\n",
      "Epoch 12, Step: 958, Loss: 0.13854597508907318, Lr:0.0001\n",
      "Epoch 12, Step: 959, Loss: 0.2552437484264374, Lr:0.0001\n",
      "Epoch 12, Step: 960, Loss: 0.3026714324951172, Lr:0.0001\n",
      "Epoch 12, Step: 961, Loss: 0.05439494550228119, Lr:0.0001\n",
      "Epoch 12, Step: 962, Loss: 0.15351451933383942, Lr:0.0001\n",
      "Epoch 12, Step: 963, Loss: 0.1362348347902298, Lr:0.0001\n",
      "Epoch 12, Step: 964, Loss: 0.064040906727314, Lr:0.0001\n",
      "Epoch 12, Step: 965, Loss: 0.08487524837255478, Lr:0.0001\n",
      "Epoch 12, Step: 966, Loss: 0.2124205231666565, Lr:0.0001\n",
      "Epoch 12, Step: 967, Loss: 0.2366950958967209, Lr:0.0001\n",
      "Epoch 12, Step: 968, Loss: 0.12418033927679062, Lr:0.0001\n",
      "Epoch 12, Step: 969, Loss: 0.0511607863008976, Lr:0.0001\n",
      "Epoch 12, Step: 970, Loss: 0.14981576800346375, Lr:0.0001\n",
      "Epoch 12, Step: 971, Loss: 0.20137929916381836, Lr:0.0001\n",
      "Epoch 12, Step: 972, Loss: 0.08760582655668259, Lr:0.0001\n",
      "Epoch 12, Step: 973, Loss: 0.14640523493289948, Lr:0.0001\n",
      "Epoch 12, Step: 974, Loss: 0.028593380004167557, Lr:0.0001\n",
      "Epoch 12, Step: 975, Loss: 0.0741475522518158, Lr:0.0001\n",
      "Epoch 12, Step: 976, Loss: 0.24257226288318634, Lr:0.0001\n",
      "Epoch 12, Step: 977, Loss: 0.3144553601741791, Lr:0.0001\n",
      "Epoch 12, Step: 978, Loss: 0.04952948912978172, Lr:0.0001\n",
      "Epoch 12, Step: 979, Loss: 0.08751726150512695, Lr:0.0001\n",
      "Epoch 12, Step: 980, Loss: 0.3653533160686493, Lr:0.0001\n",
      "Epoch 12, Step: 981, Loss: 0.22174440324306488, Lr:0.0001\n",
      "Epoch 12, Step: 982, Loss: 0.029238255694508553, Lr:0.0001\n",
      "Epoch 12, Step: 983, Loss: 0.04920241981744766, Lr:0.0001\n",
      "Epoch 12, Step: 984, Loss: 0.054166149348020554, Lr:0.0001\n",
      "Epoch 12, Step: 985, Loss: 0.16870643198490143, Lr:0.0001\n",
      "Epoch 12, Step: 986, Loss: 0.01403539814054966, Lr:0.0001\n",
      "Epoch 12, Step: 987, Loss: 0.1029532253742218, Lr:0.0001\n",
      "Epoch 12, Step: 988, Loss: 0.072903111577034, Lr:0.0001\n",
      "Epoch 12, Step: 989, Loss: 0.034182511270046234, Lr:0.0001\n",
      "Epoch 12, Step: 990, Loss: 0.12962159514427185, Lr:0.0001\n",
      "Epoch 12, Step: 991, Loss: 0.10661152005195618, Lr:0.0001\n",
      "Epoch 12, Step: 992, Loss: 0.04027717560529709, Lr:0.0001\n",
      "Epoch 12, Step: 993, Loss: 0.15257331728935242, Lr:0.0001\n",
      "Epoch 12, Step: 994, Loss: 0.06169256195425987, Lr:0.0001\n",
      "Epoch 12, Step: 995, Loss: 0.6009398102760315, Lr:0.0001\n",
      "Epoch 12, Step: 996, Loss: 0.00974738597869873, Lr:0.0001\n",
      "Epoch 12, Step: 997, Loss: 0.053427115082740784, Lr:0.0001\n",
      "Epoch 12, Step: 998, Loss: 0.1825169324874878, Lr:0.0001\n",
      "Epoch 12, Step: 999, Loss: 0.16445589065551758, Lr:0.0001\n",
      "Epoch 12, Step: 1000, Loss: 0.1321166753768921, Lr:0.0001\n",
      "Epoch 12, Step: 1001, Loss: 0.12574128806591034, Lr:0.0001\n",
      "Epoch 12, Step: 1002, Loss: 0.08055023849010468, Lr:0.0001\n",
      "Epoch 12, Step: 1003, Loss: 0.04741195961833, Lr:0.0001\n",
      "Epoch 12, Step: 1004, Loss: 0.16670289635658264, Lr:0.0001\n",
      "Epoch 12, Step: 1005, Loss: 0.011506331153213978, Lr:0.0001\n",
      "Epoch 12, Step: 1006, Loss: 0.15373601019382477, Lr:0.0001\n",
      "Epoch 12, Step: 1007, Loss: 0.11035779118537903, Lr:0.0001\n",
      "Epoch 12, Step: 1008, Loss: 0.13023963570594788, Lr:0.0001\n",
      "Epoch 12, Step: 1009, Loss: 0.04698092117905617, Lr:0.0001\n",
      "Epoch 12, Step: 1010, Loss: 0.018098238855600357, Lr:0.0001\n",
      "Epoch 12, Step: 1011, Loss: 0.23004725575447083, Lr:0.0001\n",
      "Epoch 12, Step: 1012, Loss: 0.09078175574541092, Lr:0.0001\n",
      "Epoch 12, Step: 1013, Loss: 0.03953000158071518, Lr:0.0001\n",
      "Epoch 12, Step: 1014, Loss: 0.065720334649086, Lr:0.0001\n",
      "Epoch 12, Step: 1015, Loss: 0.5569964647293091, Lr:0.0001\n",
      "Epoch 12, Step: 1016, Loss: 0.2522422969341278, Lr:0.0001\n",
      "Epoch 12, Step: 1017, Loss: 0.23026850819587708, Lr:0.0001\n",
      "Epoch 12, Step: 1018, Loss: 0.06356242299079895, Lr:0.0001\n",
      "Epoch 12, Step: 1019, Loss: 0.19804970920085907, Lr:0.0001\n",
      "Epoch 12, Step: 1020, Loss: 0.04693451523780823, Lr:0.0001\n",
      "Epoch 12, Step: 1021, Loss: 0.03802520036697388, Lr:0.0001\n",
      "Epoch 12, Step: 1022, Loss: 0.09167910367250443, Lr:0.0001\n",
      "Epoch 12, Step: 1023, Loss: 0.015257321298122406, Lr:0.0001\n",
      "Epoch 12, Step: 1024, Loss: 0.01624877192080021, Lr:0.0001\n",
      "Epoch 12, Step: 1025, Loss: 0.05014494061470032, Lr:0.0001\n",
      "Epoch 12, Step: 1026, Loss: 0.1623169481754303, Lr:0.0001\n",
      "Epoch 12, Step: 1027, Loss: 0.0698561817407608, Lr:0.0001\n",
      "Epoch 12, Step: 1028, Loss: 0.22709199786186218, Lr:0.0001\n",
      "Epoch 12, Step: 1029, Loss: 0.2578093111515045, Lr:0.0001\n",
      "Epoch 12, Step: 1030, Loss: 0.23471282422542572, Lr:0.0001\n",
      "Epoch 12, Step: 1031, Loss: 0.013643707148730755, Lr:0.0001\n",
      "Epoch 12, Step: 1032, Loss: 0.33527883887290955, Lr:0.0001\n",
      "Epoch 12, Step: 1033, Loss: 0.13697488605976105, Lr:0.0001\n",
      "Epoch 12, Step: 1034, Loss: 0.21020637452602386, Lr:0.0001\n",
      "Epoch 12, Step: 1035, Loss: 0.09760169684886932, Lr:0.0001\n",
      "Epoch 12, Step: 1036, Loss: 0.007827648892998695, Lr:0.0001\n",
      "Epoch 12, Step: 1037, Loss: 0.10221315175294876, Lr:0.0001\n",
      "Epoch 12, Step: 1038, Loss: 0.036370810121297836, Lr:0.0001\n",
      "Epoch 12, Step: 1039, Loss: 0.12470730394124985, Lr:0.0001\n",
      "Epoch 12, Step: 1040, Loss: 0.39237767457962036, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 12\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:16 loss: 0.4308 (0.4308) acc1: 81.2500 (81.2500) acc5: 100.0000 (100.0000) time: 0.2920 data: 0.1200 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:12 loss: 0.1033 (0.1411) acc1: 93.7500 (94.3182) acc5: 100.0000 (100.0000) time: 0.2810 data: 0.1087 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0994 (0.1774) acc1: 93.7500 (93.7500) acc5: 100.0000 (100.0000) time: 0.2809 data: 0.1069 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.2225 (0.2632) acc1: 93.7500 (91.1290) acc5: 100.0000 (100.0000) time: 0.2828 data: 0.1081 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.2308 (0.2792) acc1: 87.5000 (90.7012) acc5: 100.0000 (100.0000) time: 0.2862 data: 0.1110 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.1339 (0.2696) acc1: 93.7500 (91.5441) acc5: 100.0000 (100.0000) time: 0.2857 data: 0.1119 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0251 (0.2581) acc1: 100.0000 (91.8275) acc5: 100.0000 (100.0000) time: 0.2732 data: 0.1067 max mem: 15137\n",
      "Test: Total time: 0:00:15 (0.2796 s / it)\n",
      "* Acc@1 91.827 Acc@5 100.000 loss 0.258\n",
      "Accuracy of the network on the 881 test image: 91.8%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 13, Step: 0, Loss: 0.0449729785323143, Lr:0.0001\n",
      "Epoch 13, Step: 1, Loss: 0.038022466003894806, Lr:0.0001\n",
      "Epoch 13, Step: 2, Loss: 0.01832885667681694, Lr:0.0001\n",
      "Epoch 13, Step: 3, Loss: 0.5413050651550293, Lr:0.0001\n",
      "Epoch 13, Step: 4, Loss: 0.06498096138238907, Lr:0.0001\n",
      "Epoch 13, Step: 5, Loss: 0.1621173918247223, Lr:0.0001\n",
      "Epoch 13, Step: 6, Loss: 0.026073042303323746, Lr:0.0001\n",
      "Epoch 13, Step: 7, Loss: 0.017915140837430954, Lr:0.0001\n",
      "Epoch 13, Step: 8, Loss: 0.08390149474143982, Lr:0.0001\n",
      "Epoch 13, Step: 9, Loss: 0.1589810848236084, Lr:0.0001\n",
      "Epoch 13, Step: 10, Loss: 0.0795099213719368, Lr:0.0001\n",
      "Epoch 13, Step: 11, Loss: 0.21834337711334229, Lr:0.0001\n",
      "Epoch 13, Step: 12, Loss: 0.0859820619225502, Lr:0.0001\n",
      "Epoch 13, Step: 13, Loss: 0.11468296498060226, Lr:0.0001\n",
      "Epoch 13, Step: 14, Loss: 0.06599880009889603, Lr:0.0001\n",
      "Epoch 13, Step: 15, Loss: 0.08620068430900574, Lr:0.0001\n",
      "Epoch 13, Step: 16, Loss: 0.48588183522224426, Lr:0.0001\n",
      "Epoch 13, Step: 17, Loss: 0.07879316806793213, Lr:0.0001\n",
      "Epoch 13, Step: 18, Loss: 0.0496465340256691, Lr:0.0001\n",
      "Epoch 13, Step: 19, Loss: 0.09464195370674133, Lr:0.0001\n",
      "Epoch 13, Step: 20, Loss: 0.01822887361049652, Lr:0.0001\n",
      "Epoch 13, Step: 21, Loss: 0.12832537293434143, Lr:0.0001\n",
      "Epoch 13, Step: 22, Loss: 0.029417024925351143, Lr:0.0001\n",
      "Epoch 13, Step: 23, Loss: 0.206790030002594, Lr:0.0001\n",
      "Epoch 13, Step: 24, Loss: 0.08295971900224686, Lr:0.0001\n",
      "Epoch 13, Step: 25, Loss: 0.09098415076732635, Lr:0.0001\n",
      "Epoch 13, Step: 26, Loss: 0.028063258156180382, Lr:0.0001\n",
      "Epoch 13, Step: 27, Loss: 0.062980517745018, Lr:0.0001\n",
      "Epoch 13, Step: 28, Loss: 0.022661050781607628, Lr:0.0001\n",
      "Epoch 13, Step: 29, Loss: 0.23172126710414886, Lr:0.0001\n",
      "Epoch 13, Step: 30, Loss: 0.06621298938989639, Lr:0.0001\n",
      "Epoch 13, Step: 31, Loss: 0.05648759752511978, Lr:0.0001\n",
      "Epoch 13, Step: 32, Loss: 0.11523845046758652, Lr:0.0001\n",
      "Epoch 13, Step: 33, Loss: 0.3485344350337982, Lr:0.0001\n",
      "Epoch 13, Step: 34, Loss: 0.16528840363025665, Lr:0.0001\n",
      "Epoch 13, Step: 35, Loss: 0.013124513439834118, Lr:0.0001\n",
      "Epoch 13, Step: 36, Loss: 0.08004272729158401, Lr:0.0001\n",
      "Epoch 13, Step: 37, Loss: 0.23957660794258118, Lr:0.0001\n",
      "Epoch 13, Step: 38, Loss: 0.08759775757789612, Lr:0.0001\n",
      "Epoch 13, Step: 39, Loss: 0.03622407838702202, Lr:0.0001\n",
      "Epoch 13, Step: 40, Loss: 0.1867552101612091, Lr:0.0001\n",
      "Epoch 13, Step: 41, Loss: 0.017381073907017708, Lr:0.0001\n",
      "Epoch 13, Step: 42, Loss: 0.025455165654420853, Lr:0.0001\n",
      "Epoch 13, Step: 43, Loss: 0.26939523220062256, Lr:0.0001\n",
      "Epoch 13, Step: 44, Loss: 0.03188179060816765, Lr:0.0001\n",
      "Epoch 13, Step: 45, Loss: 0.05750422552227974, Lr:0.0001\n",
      "Epoch 13, Step: 46, Loss: 0.013850429095327854, Lr:0.0001\n",
      "Epoch 13, Step: 47, Loss: 0.02529837004840374, Lr:0.0001\n",
      "Epoch 13, Step: 48, Loss: 0.11083388328552246, Lr:0.0001\n",
      "Epoch 13, Step: 49, Loss: 0.013281416147947311, Lr:0.0001\n",
      "Epoch 13, Step: 50, Loss: 0.2984863519668579, Lr:0.0001\n",
      "Epoch 13, Step: 51, Loss: 0.24580909311771393, Lr:0.0001\n",
      "Epoch 13, Step: 52, Loss: 0.0086913350969553, Lr:0.0001\n",
      "Epoch 13, Step: 53, Loss: 0.17264136672019958, Lr:0.0001\n",
      "Epoch 13, Step: 54, Loss: 0.2642822563648224, Lr:0.0001\n",
      "Epoch 13, Step: 55, Loss: 0.05296219885349274, Lr:0.0001\n",
      "Epoch 13, Step: 56, Loss: 0.3414607048034668, Lr:0.0001\n",
      "Epoch 13, Step: 57, Loss: 0.2698480188846588, Lr:0.0001\n",
      "Epoch 13, Step: 58, Loss: 0.10248809307813644, Lr:0.0001\n",
      "Epoch 13, Step: 59, Loss: 0.1972128301858902, Lr:0.0001\n",
      "Epoch 13, Step: 60, Loss: 0.19250033795833588, Lr:0.0001\n",
      "Epoch 13, Step: 61, Loss: 0.09975973516702652, Lr:0.0001\n",
      "Epoch 13, Step: 62, Loss: 0.0536593534052372, Lr:0.0001\n",
      "Epoch 13, Step: 63, Loss: 0.02816111035645008, Lr:0.0001\n",
      "Epoch 13, Step: 64, Loss: 0.10155623406171799, Lr:0.0001\n",
      "Epoch 13, Step: 65, Loss: 0.023055508732795715, Lr:0.0001\n",
      "Epoch 13, Step: 66, Loss: 0.027184385806322098, Lr:0.0001\n",
      "Epoch 13, Step: 67, Loss: 0.25760361552238464, Lr:0.0001\n",
      "Epoch 13, Step: 68, Loss: 0.18292206525802612, Lr:0.0001\n",
      "Epoch 13, Step: 69, Loss: 0.32475772500038147, Lr:0.0001\n",
      "Epoch 13, Step: 70, Loss: 0.11269599944353104, Lr:0.0001\n",
      "Epoch 13, Step: 71, Loss: 0.3275526165962219, Lr:0.0001\n",
      "Epoch 13, Step: 72, Loss: 0.09509668499231339, Lr:0.0001\n",
      "Epoch 13, Step: 73, Loss: 0.025396812707185745, Lr:0.0001\n",
      "Epoch 13, Step: 74, Loss: 0.2094157487154007, Lr:0.0001\n",
      "Epoch 13, Step: 75, Loss: 0.013812142424285412, Lr:0.0001\n",
      "Epoch 13, Step: 76, Loss: 0.013421722687780857, Lr:0.0001\n",
      "Epoch 13, Step: 77, Loss: 0.04728678613901138, Lr:0.0001\n",
      "Epoch 13, Step: 78, Loss: 0.015004363842308521, Lr:0.0001\n",
      "Epoch 13, Step: 79, Loss: 0.06403068453073502, Lr:0.0001\n",
      "Epoch 13, Step: 80, Loss: 0.23149406909942627, Lr:0.0001\n",
      "Epoch 13, Step: 81, Loss: 0.1215699315071106, Lr:0.0001\n",
      "Epoch 13, Step: 82, Loss: 0.2043643593788147, Lr:0.0001\n",
      "Epoch 13, Step: 83, Loss: 0.022661032155156136, Lr:0.0001\n",
      "Epoch 13, Step: 84, Loss: 0.07871975004673004, Lr:0.0001\n",
      "Epoch 13, Step: 85, Loss: 0.0033173912670463324, Lr:0.0001\n",
      "Epoch 13, Step: 86, Loss: 0.046095483005046844, Lr:0.0001\n",
      "Epoch 13, Step: 87, Loss: 0.0025952383875846863, Lr:0.0001\n",
      "Epoch 13, Step: 88, Loss: 0.09408845752477646, Lr:0.0001\n",
      "Epoch 13, Step: 89, Loss: 0.09776359051465988, Lr:0.0001\n",
      "Epoch 13, Step: 90, Loss: 0.0339699387550354, Lr:0.0001\n",
      "Epoch 13, Step: 91, Loss: 0.061982862651348114, Lr:0.0001\n",
      "Epoch 13, Step: 92, Loss: 0.011973337270319462, Lr:0.0001\n",
      "Epoch 13, Step: 93, Loss: 0.17690443992614746, Lr:0.0001\n",
      "Epoch 13, Step: 94, Loss: 0.023710696026682854, Lr:0.0001\n",
      "Epoch 13, Step: 95, Loss: 0.07922624796628952, Lr:0.0001\n",
      "Epoch 13, Step: 96, Loss: 0.11422526091337204, Lr:0.0001\n",
      "Epoch 13, Step: 97, Loss: 0.04196358844637871, Lr:0.0001\n",
      "Epoch 13, Step: 98, Loss: 0.14381955564022064, Lr:0.0001\n",
      "Epoch 13, Step: 99, Loss: 0.042834989726543427, Lr:0.0001\n",
      "Epoch 13, Step: 100, Loss: 0.011359264142811298, Lr:0.0001\n",
      "Epoch 13, Step: 101, Loss: 0.017908889800310135, Lr:0.0001\n",
      "Epoch 13, Step: 102, Loss: 0.053189054131507874, Lr:0.0001\n",
      "Epoch 13, Step: 103, Loss: 0.07972630858421326, Lr:0.0001\n",
      "Epoch 13, Step: 104, Loss: 0.3209369480609894, Lr:0.0001\n",
      "Epoch 13, Step: 105, Loss: 0.09726650267839432, Lr:0.0001\n",
      "Epoch 13, Step: 106, Loss: 0.04740980640053749, Lr:0.0001\n",
      "Epoch 13, Step: 107, Loss: 0.014402016997337341, Lr:0.0001\n",
      "Epoch 13, Step: 108, Loss: 0.15947070717811584, Lr:0.0001\n",
      "Epoch 13, Step: 109, Loss: 0.37051236629486084, Lr:0.0001\n",
      "Epoch 13, Step: 110, Loss: 0.0710914134979248, Lr:0.0001\n",
      "Epoch 13, Step: 111, Loss: 0.28337743878364563, Lr:0.0001\n",
      "Epoch 13, Step: 112, Loss: 0.15212604403495789, Lr:0.0001\n",
      "Epoch 13, Step: 113, Loss: 0.1320687234401703, Lr:0.0001\n",
      "Epoch 13, Step: 114, Loss: 0.05961902439594269, Lr:0.0001\n",
      "Epoch 13, Step: 115, Loss: 0.3236614465713501, Lr:0.0001\n",
      "Epoch 13, Step: 116, Loss: 0.310043603181839, Lr:0.0001\n",
      "Epoch 13, Step: 117, Loss: 0.1150612011551857, Lr:0.0001\n",
      "Epoch 13, Step: 118, Loss: 0.22286641597747803, Lr:0.0001\n",
      "Epoch 13, Step: 119, Loss: 0.1463211625814438, Lr:0.0001\n",
      "Epoch 13, Step: 120, Loss: 0.03129902482032776, Lr:0.0001\n",
      "Epoch 13, Step: 121, Loss: 0.026754869148135185, Lr:0.0001\n",
      "Epoch 13, Step: 122, Loss: 0.12857531011104584, Lr:0.0001\n",
      "Epoch 13, Step: 123, Loss: 0.06495707482099533, Lr:0.0001\n",
      "Epoch 13, Step: 124, Loss: 0.17476344108581543, Lr:0.0001\n",
      "Epoch 13, Step: 125, Loss: 0.06909666210412979, Lr:0.0001\n",
      "Epoch 13, Step: 126, Loss: 0.12054236233234406, Lr:0.0001\n",
      "Epoch 13, Step: 127, Loss: 0.03692164272069931, Lr:0.0001\n",
      "Epoch 13, Step: 128, Loss: 0.2861274778842926, Lr:0.0001\n",
      "Epoch 13, Step: 129, Loss: 0.2574925720691681, Lr:0.0001\n",
      "Epoch 13, Step: 130, Loss: 0.47062721848487854, Lr:0.0001\n",
      "Epoch 13, Step: 131, Loss: 0.10398884862661362, Lr:0.0001\n",
      "Epoch 13, Step: 132, Loss: 0.09744174033403397, Lr:0.0001\n",
      "Epoch 13, Step: 133, Loss: 0.13021819293498993, Lr:0.0001\n",
      "Epoch 13, Step: 134, Loss: 0.8267260789871216, Lr:0.0001\n",
      "Epoch 13, Step: 135, Loss: 0.055975932627916336, Lr:0.0001\n",
      "Epoch 13, Step: 136, Loss: 0.2121032178401947, Lr:0.0001\n",
      "Epoch 13, Step: 137, Loss: 0.02842227928340435, Lr:0.0001\n",
      "Epoch 13, Step: 138, Loss: 0.038746803998947144, Lr:0.0001\n",
      "Epoch 13, Step: 139, Loss: 0.1715838611125946, Lr:0.0001\n",
      "Epoch 13, Step: 140, Loss: 0.16464613378047943, Lr:0.0001\n",
      "Epoch 13, Step: 141, Loss: 0.2044048011302948, Lr:0.0001\n",
      "Epoch 13, Step: 142, Loss: 0.26646888256073, Lr:0.0001\n",
      "Epoch 13, Step: 143, Loss: 0.0109608955681324, Lr:0.0001\n",
      "Epoch 13, Step: 144, Loss: 0.19479621946811676, Lr:0.0001\n",
      "Epoch 13, Step: 145, Loss: 0.13746115565299988, Lr:0.0001\n",
      "Epoch 13, Step: 146, Loss: 0.2429468333721161, Lr:0.0001\n",
      "Epoch 13, Step: 147, Loss: 0.052302319556474686, Lr:0.0001\n",
      "Epoch 13, Step: 148, Loss: 0.07470634579658508, Lr:0.0001\n",
      "Epoch 13, Step: 149, Loss: 0.022689808160066605, Lr:0.0001\n",
      "Epoch 13, Step: 150, Loss: 0.20914070308208466, Lr:0.0001\n",
      "Epoch 13, Step: 151, Loss: 0.024532077834010124, Lr:0.0001\n",
      "Epoch 13, Step: 152, Loss: 0.1100766509771347, Lr:0.0001\n",
      "Epoch 13, Step: 153, Loss: 0.173976331949234, Lr:0.0001\n",
      "Epoch 13, Step: 154, Loss: 0.24198345839977264, Lr:0.0001\n",
      "Epoch 13, Step: 155, Loss: 0.22125783562660217, Lr:0.0001\n",
      "Epoch 13, Step: 156, Loss: 0.27150487899780273, Lr:0.0001\n",
      "Epoch 13, Step: 157, Loss: 0.32453128695487976, Lr:0.0001\n",
      "Epoch 13, Step: 158, Loss: 0.014957713894546032, Lr:0.0001\n",
      "Epoch 13, Step: 159, Loss: 0.13040989637374878, Lr:0.0001\n",
      "Epoch 13, Step: 160, Loss: 0.026540542021393776, Lr:0.0001\n",
      "Epoch 13, Step: 161, Loss: 0.04504130780696869, Lr:0.0001\n",
      "Epoch 13, Step: 162, Loss: 0.12203530967235565, Lr:0.0001\n",
      "Epoch 13, Step: 163, Loss: 0.1306809037923813, Lr:0.0001\n",
      "Epoch 13, Step: 164, Loss: 0.0034217345528304577, Lr:0.0001\n",
      "Epoch 13, Step: 165, Loss: 0.21588361263275146, Lr:0.0001\n",
      "Epoch 13, Step: 166, Loss: 0.06729661673307419, Lr:0.0001\n",
      "Epoch 13, Step: 167, Loss: 0.09246363490819931, Lr:0.0001\n",
      "Epoch 13, Step: 168, Loss: 0.09827376902103424, Lr:0.0001\n",
      "Epoch 13, Step: 169, Loss: 0.1510782688856125, Lr:0.0001\n",
      "Epoch 13, Step: 170, Loss: 0.10487515479326248, Lr:0.0001\n",
      "Epoch 13, Step: 171, Loss: 0.014641981571912766, Lr:0.0001\n",
      "Epoch 13, Step: 172, Loss: 0.05001339688897133, Lr:0.0001\n",
      "Epoch 13, Step: 173, Loss: 0.11555416136980057, Lr:0.0001\n",
      "Epoch 13, Step: 174, Loss: 0.03485637530684471, Lr:0.0001\n",
      "Epoch 13, Step: 175, Loss: 0.03562703728675842, Lr:0.0001\n",
      "Epoch 13, Step: 176, Loss: 0.029516929760575294, Lr:0.0001\n",
      "Epoch 13, Step: 177, Loss: 0.19040949642658234, Lr:0.0001\n",
      "Epoch 13, Step: 178, Loss: 0.25088411569595337, Lr:0.0001\n",
      "Epoch 13, Step: 179, Loss: 0.1524091362953186, Lr:0.0001\n",
      "Epoch 13, Step: 180, Loss: 0.16128595173358917, Lr:0.0001\n",
      "Epoch 13, Step: 181, Loss: 0.19466331601142883, Lr:0.0001\n",
      "Epoch 13, Step: 182, Loss: 0.09794683754444122, Lr:0.0001\n",
      "Epoch 13, Step: 183, Loss: 0.09380057454109192, Lr:0.0001\n",
      "Epoch 13, Step: 184, Loss: 0.026044199243187904, Lr:0.0001\n",
      "Epoch 13, Step: 185, Loss: 0.16746589541435242, Lr:0.0001\n",
      "Epoch 13, Step: 186, Loss: 0.021572893485426903, Lr:0.0001\n",
      "Epoch 13, Step: 187, Loss: 0.050379205495119095, Lr:0.0001\n",
      "Epoch 13, Step: 188, Loss: 0.04863325506448746, Lr:0.0001\n",
      "Epoch 13, Step: 189, Loss: 0.6279275417327881, Lr:0.0001\n",
      "Epoch 13, Step: 190, Loss: 0.25866228342056274, Lr:0.0001\n",
      "Epoch 13, Step: 191, Loss: 0.1630963236093521, Lr:0.0001\n",
      "Epoch 13, Step: 192, Loss: 0.19978934526443481, Lr:0.0001\n",
      "Epoch 13, Step: 193, Loss: 0.03692026436328888, Lr:0.0001\n",
      "Epoch 13, Step: 194, Loss: 0.05886240303516388, Lr:0.0001\n",
      "Epoch 13, Step: 195, Loss: 0.21537679433822632, Lr:0.0001\n",
      "Epoch 13, Step: 196, Loss: 0.0681486427783966, Lr:0.0001\n",
      "Epoch 13, Step: 197, Loss: 0.11017560958862305, Lr:0.0001\n",
      "Epoch 13, Step: 198, Loss: 0.35245153307914734, Lr:0.0001\n",
      "Epoch 13, Step: 199, Loss: 0.0966915413737297, Lr:0.0001\n",
      "Epoch 13, Step: 200, Loss: 0.007871577516198158, Lr:0.0001\n",
      "Epoch 13, Step: 201, Loss: 0.3001102805137634, Lr:0.0001\n",
      "Epoch 13, Step: 202, Loss: 0.01293292548507452, Lr:0.0001\n",
      "Epoch 13, Step: 203, Loss: 0.11212244629859924, Lr:0.0001\n",
      "Epoch 13, Step: 204, Loss: 0.02215150184929371, Lr:0.0001\n",
      "Epoch 13, Step: 205, Loss: 0.3130321800708771, Lr:0.0001\n",
      "Epoch 13, Step: 206, Loss: 0.0874820277094841, Lr:0.0001\n",
      "Epoch 13, Step: 207, Loss: 0.060370899736881256, Lr:0.0001\n",
      "Epoch 13, Step: 208, Loss: 0.07724706828594208, Lr:0.0001\n",
      "Epoch 13, Step: 209, Loss: 0.12464417517185211, Lr:0.0001\n",
      "Epoch 13, Step: 210, Loss: 0.09422510862350464, Lr:0.0001\n",
      "Epoch 13, Step: 211, Loss: 0.1835559457540512, Lr:0.0001\n",
      "Epoch 13, Step: 212, Loss: 0.045985884964466095, Lr:0.0001\n",
      "Epoch 13, Step: 213, Loss: 0.15579286217689514, Lr:0.0001\n",
      "Epoch 13, Step: 214, Loss: 0.14823904633522034, Lr:0.0001\n",
      "Epoch 13, Step: 215, Loss: 0.11530807614326477, Lr:0.0001\n",
      "Epoch 13, Step: 216, Loss: 0.16305412352085114, Lr:0.0001\n",
      "Epoch 13, Step: 217, Loss: 0.10042767226696014, Lr:0.0001\n",
      "Epoch 13, Step: 218, Loss: 0.22792093455791473, Lr:0.0001\n",
      "Epoch 13, Step: 219, Loss: 0.3307236433029175, Lr:0.0001\n",
      "Epoch 13, Step: 220, Loss: 0.06369321048259735, Lr:0.0001\n",
      "Epoch 13, Step: 221, Loss: 0.06423947960138321, Lr:0.0001\n",
      "Epoch 13, Step: 222, Loss: 0.14198017120361328, Lr:0.0001\n",
      "Epoch 13, Step: 223, Loss: 0.12378037720918655, Lr:0.0001\n",
      "Epoch 13, Step: 224, Loss: 0.11568836867809296, Lr:0.0001\n",
      "Epoch 13, Step: 225, Loss: 0.13682350516319275, Lr:0.0001\n",
      "Epoch 13, Step: 226, Loss: 0.0710604339838028, Lr:0.0001\n",
      "Epoch 13, Step: 227, Loss: 0.08515273779630661, Lr:0.0001\n",
      "Epoch 13, Step: 228, Loss: 0.018464114516973495, Lr:0.0001\n",
      "Epoch 13, Step: 229, Loss: 0.0379251129925251, Lr:0.0001\n",
      "Epoch 13, Step: 230, Loss: 0.4182398021221161, Lr:0.0001\n",
      "Epoch 13, Step: 231, Loss: 0.1418599933385849, Lr:0.0001\n",
      "Epoch 13, Step: 232, Loss: 0.08258211612701416, Lr:0.0001\n",
      "Epoch 13, Step: 233, Loss: 0.04358943551778793, Lr:0.0001\n",
      "Epoch 13, Step: 234, Loss: 0.13301914930343628, Lr:0.0001\n",
      "Epoch 13, Step: 235, Loss: 0.2555150091648102, Lr:0.0001\n",
      "Epoch 13, Step: 236, Loss: 0.05238357558846474, Lr:0.0001\n",
      "Epoch 13, Step: 237, Loss: 0.004619796760380268, Lr:0.0001\n",
      "Epoch 13, Step: 238, Loss: 0.051924340426921844, Lr:0.0001\n",
      "Epoch 13, Step: 239, Loss: 0.19242823123931885, Lr:0.0001\n",
      "Epoch 13, Step: 240, Loss: 0.07222705334424973, Lr:0.0001\n",
      "Epoch 13, Step: 241, Loss: 0.1936470866203308, Lr:0.0001\n",
      "Epoch 13, Step: 242, Loss: 0.08866281807422638, Lr:0.0001\n",
      "Epoch 13, Step: 243, Loss: 0.3400540053844452, Lr:0.0001\n",
      "Epoch 13, Step: 244, Loss: 0.10436897724866867, Lr:0.0001\n",
      "Epoch 13, Step: 245, Loss: 0.15269558131694794, Lr:0.0001\n",
      "Epoch 13, Step: 246, Loss: 0.08573293685913086, Lr:0.0001\n",
      "Epoch 13, Step: 247, Loss: 0.03456715866923332, Lr:0.0001\n",
      "Epoch 13, Step: 248, Loss: 0.3342916667461395, Lr:0.0001\n",
      "Epoch 13, Step: 249, Loss: 0.16598501801490784, Lr:0.0001\n",
      "Epoch 13, Step: 250, Loss: 0.020619716495275497, Lr:0.0001\n",
      "Epoch 13, Step: 251, Loss: 0.19988277554512024, Lr:0.0001\n",
      "Epoch 13, Step: 252, Loss: 0.0519685223698616, Lr:0.0001\n",
      "Epoch 13, Step: 253, Loss: 0.2808871865272522, Lr:0.0001\n",
      "Epoch 13, Step: 254, Loss: 0.0359899178147316, Lr:0.0001\n",
      "Epoch 13, Step: 255, Loss: 0.008934763260185719, Lr:0.0001\n",
      "Epoch 13, Step: 256, Loss: 0.3173648715019226, Lr:0.0001\n",
      "Epoch 13, Step: 257, Loss: 0.048757899552583694, Lr:0.0001\n",
      "Epoch 13, Step: 258, Loss: 0.013247747905552387, Lr:0.0001\n",
      "Epoch 13, Step: 259, Loss: 0.07479418814182281, Lr:0.0001\n",
      "Epoch 13, Step: 260, Loss: 0.1429210752248764, Lr:0.0001\n",
      "Epoch 13, Step: 261, Loss: 0.054945603013038635, Lr:0.0001\n",
      "Epoch 13, Step: 262, Loss: 0.04361476004123688, Lr:0.0001\n",
      "Epoch 13, Step: 263, Loss: 0.1714661568403244, Lr:0.0001\n",
      "Epoch 13, Step: 264, Loss: 0.369454026222229, Lr:0.0001\n",
      "Epoch 13, Step: 265, Loss: 0.08230855315923691, Lr:0.0001\n",
      "Epoch 13, Step: 266, Loss: 0.012613903731107712, Lr:0.0001\n",
      "Epoch 13, Step: 267, Loss: 0.02315695956349373, Lr:0.0001\n",
      "Epoch 13, Step: 268, Loss: 0.11473797261714935, Lr:0.0001\n",
      "Epoch 13, Step: 269, Loss: 0.09112845361232758, Lr:0.0001\n",
      "Epoch 13, Step: 270, Loss: 0.13160346448421478, Lr:0.0001\n",
      "Epoch 13, Step: 271, Loss: 0.028553003445267677, Lr:0.0001\n",
      "Epoch 13, Step: 272, Loss: 0.3108974099159241, Lr:0.0001\n",
      "Epoch 13, Step: 273, Loss: 0.0966365709900856, Lr:0.0001\n",
      "Epoch 13, Step: 274, Loss: 0.26672977209091187, Lr:0.0001\n",
      "Epoch 13, Step: 275, Loss: 0.1709149032831192, Lr:0.0001\n",
      "Epoch 13, Step: 276, Loss: 0.06619445234537125, Lr:0.0001\n",
      "Epoch 13, Step: 277, Loss: 0.13464367389678955, Lr:0.0001\n",
      "Epoch 13, Step: 278, Loss: 0.0845784917473793, Lr:0.0001\n",
      "Epoch 13, Step: 279, Loss: 0.004836572799831629, Lr:0.0001\n",
      "Epoch 13, Step: 280, Loss: 0.04980393126606941, Lr:0.0001\n",
      "Epoch 13, Step: 281, Loss: 0.29809948801994324, Lr:0.0001\n",
      "Epoch 13, Step: 282, Loss: 0.146444171667099, Lr:0.0001\n",
      "Epoch 13, Step: 283, Loss: 0.4072519838809967, Lr:0.0001\n",
      "Epoch 13, Step: 284, Loss: 0.025465024635195732, Lr:0.0001\n",
      "Epoch 13, Step: 285, Loss: 0.10469789803028107, Lr:0.0001\n",
      "Epoch 13, Step: 286, Loss: 0.03747652471065521, Lr:0.0001\n",
      "Epoch 13, Step: 287, Loss: 0.2074073851108551, Lr:0.0001\n",
      "Epoch 13, Step: 288, Loss: 0.0751580148935318, Lr:0.0001\n",
      "Epoch 13, Step: 289, Loss: 0.02918349765241146, Lr:0.0001\n",
      "Epoch 13, Step: 290, Loss: 0.034277625381946564, Lr:0.0001\n",
      "Epoch 13, Step: 291, Loss: 0.08461372554302216, Lr:0.0001\n",
      "Epoch 13, Step: 292, Loss: 0.04598420858383179, Lr:0.0001\n",
      "Epoch 13, Step: 293, Loss: 0.10631008446216583, Lr:0.0001\n",
      "Epoch 13, Step: 294, Loss: 0.2875542938709259, Lr:0.0001\n",
      "Epoch 13, Step: 295, Loss: 0.0866822749376297, Lr:0.0001\n",
      "Epoch 13, Step: 296, Loss: 0.13574983179569244, Lr:0.0001\n",
      "Epoch 13, Step: 297, Loss: 0.23332561552524567, Lr:0.0001\n",
      "Epoch 13, Step: 298, Loss: 0.059018366038799286, Lr:0.0001\n",
      "Epoch 13, Step: 299, Loss: 0.1073724776506424, Lr:0.0001\n",
      "Epoch 13, Step: 300, Loss: 0.08052071183919907, Lr:0.0001\n",
      "Epoch 13, Step: 301, Loss: 0.030447281897068024, Lr:0.0001\n",
      "Epoch 13, Step: 302, Loss: 0.05630534142255783, Lr:0.0001\n",
      "Epoch 13, Step: 303, Loss: 0.12101054191589355, Lr:0.0001\n",
      "Epoch 13, Step: 304, Loss: 0.046267300844192505, Lr:0.0001\n",
      "Epoch 13, Step: 305, Loss: 0.027214257046580315, Lr:0.0001\n",
      "Epoch 13, Step: 306, Loss: 0.04379518702626228, Lr:0.0001\n",
      "Epoch 13, Step: 307, Loss: 0.007541970815509558, Lr:0.0001\n",
      "Epoch 13, Step: 308, Loss: 0.04123814404010773, Lr:0.0001\n",
      "Epoch 13, Step: 309, Loss: 0.10465580224990845, Lr:0.0001\n",
      "Epoch 13, Step: 310, Loss: 0.2689787745475769, Lr:0.0001\n",
      "Epoch 13, Step: 311, Loss: 0.16436360776424408, Lr:0.0001\n",
      "Epoch 13, Step: 312, Loss: 0.2030656337738037, Lr:0.0001\n",
      "Epoch 13, Step: 313, Loss: 0.0016315814573317766, Lr:0.0001\n",
      "Epoch 13, Step: 314, Loss: 0.16138121485710144, Lr:0.0001\n",
      "Epoch 13, Step: 315, Loss: 0.004977656994014978, Lr:0.0001\n",
      "Epoch 13, Step: 316, Loss: 0.18544992804527283, Lr:0.0001\n",
      "Epoch 13, Step: 317, Loss: 0.12799395620822906, Lr:0.0001\n",
      "Epoch 13, Step: 318, Loss: 0.30950477719306946, Lr:0.0001\n",
      "Epoch 13, Step: 319, Loss: 0.010173902846872807, Lr:0.0001\n",
      "Epoch 13, Step: 320, Loss: 0.1737448275089264, Lr:0.0001\n",
      "Epoch 13, Step: 321, Loss: 0.23041854798793793, Lr:0.0001\n",
      "Epoch 13, Step: 322, Loss: 0.047976668924093246, Lr:0.0001\n",
      "Epoch 13, Step: 323, Loss: 0.2039252072572708, Lr:0.0001\n",
      "Epoch 13, Step: 324, Loss: 0.060668669641017914, Lr:0.0001\n",
      "Epoch 13, Step: 325, Loss: 0.007516025099903345, Lr:0.0001\n",
      "Epoch 13, Step: 326, Loss: 0.11842666566371918, Lr:0.0001\n",
      "Epoch 13, Step: 327, Loss: 0.09143280982971191, Lr:0.0001\n",
      "Epoch 13, Step: 328, Loss: 0.1951223611831665, Lr:0.0001\n",
      "Epoch 13, Step: 329, Loss: 0.053704071789979935, Lr:0.0001\n",
      "Epoch 13, Step: 330, Loss: 0.041784677654504776, Lr:0.0001\n",
      "Epoch 13, Step: 331, Loss: 0.054357483983039856, Lr:0.0001\n",
      "Epoch 13, Step: 332, Loss: 0.2128380537033081, Lr:0.0001\n",
      "Epoch 13, Step: 333, Loss: 0.005000172648578882, Lr:0.0001\n",
      "Epoch 13, Step: 334, Loss: 0.41486477851867676, Lr:0.0001\n",
      "Epoch 13, Step: 335, Loss: 0.1923072189092636, Lr:0.0001\n",
      "Epoch 13, Step: 336, Loss: 0.16013965010643005, Lr:0.0001\n",
      "Epoch 13, Step: 337, Loss: 0.11299903690814972, Lr:0.0001\n",
      "Epoch 13, Step: 338, Loss: 0.008297540247440338, Lr:0.0001\n",
      "Epoch 13, Step: 339, Loss: 0.005807763431221247, Lr:0.0001\n",
      "Epoch 13, Step: 340, Loss: 0.1152549609541893, Lr:0.0001\n",
      "Epoch 13, Step: 341, Loss: 0.013545175082981586, Lr:0.0001\n",
      "Epoch 13, Step: 342, Loss: 0.36001548171043396, Lr:0.0001\n",
      "Epoch 13, Step: 343, Loss: 0.1008337065577507, Lr:0.0001\n",
      "Epoch 13, Step: 344, Loss: 0.0462685227394104, Lr:0.0001\n",
      "Epoch 13, Step: 345, Loss: 0.057774268090724945, Lr:0.0001\n",
      "Epoch 13, Step: 346, Loss: 0.24504229426383972, Lr:0.0001\n",
      "Epoch 13, Step: 347, Loss: 0.07696140557527542, Lr:0.0001\n",
      "Epoch 13, Step: 348, Loss: 0.010659377090632915, Lr:0.0001\n",
      "Epoch 13, Step: 349, Loss: 0.030281199142336845, Lr:0.0001\n",
      "Epoch 13, Step: 350, Loss: 0.1420016586780548, Lr:0.0001\n",
      "Epoch 13, Step: 351, Loss: 0.13723711669445038, Lr:0.0001\n",
      "Epoch 13, Step: 352, Loss: 0.04524330794811249, Lr:0.0001\n",
      "Epoch 13, Step: 353, Loss: 0.02176734432578087, Lr:0.0001\n",
      "Epoch 13, Step: 354, Loss: 0.07592791318893433, Lr:0.0001\n",
      "Epoch 13, Step: 355, Loss: 0.028696581721305847, Lr:0.0001\n",
      "Epoch 13, Step: 356, Loss: 0.40441423654556274, Lr:0.0001\n",
      "Epoch 13, Step: 357, Loss: 0.0672140121459961, Lr:0.0001\n",
      "Epoch 13, Step: 358, Loss: 0.030998004600405693, Lr:0.0001\n",
      "Epoch 13, Step: 359, Loss: 0.041416361927986145, Lr:0.0001\n",
      "Epoch 13, Step: 360, Loss: 0.2799454629421234, Lr:0.0001\n",
      "Epoch 13, Step: 361, Loss: 0.013992724940180779, Lr:0.0001\n",
      "Epoch 13, Step: 362, Loss: 0.040122829377651215, Lr:0.0001\n",
      "Epoch 13, Step: 363, Loss: 0.011709083802998066, Lr:0.0001\n",
      "Epoch 13, Step: 364, Loss: 0.10604927688837051, Lr:0.0001\n",
      "Epoch 13, Step: 365, Loss: 0.09676740318536758, Lr:0.0001\n",
      "Epoch 13, Step: 366, Loss: 0.11050509661436081, Lr:0.0001\n",
      "Epoch 13, Step: 367, Loss: 0.018574247136712074, Lr:0.0001\n",
      "Epoch 13, Step: 368, Loss: 0.1594885289669037, Lr:0.0001\n",
      "Epoch 13, Step: 369, Loss: 0.13064756989479065, Lr:0.0001\n",
      "Epoch 13, Step: 370, Loss: 0.021821770817041397, Lr:0.0001\n",
      "Epoch 13, Step: 371, Loss: 0.1352894902229309, Lr:0.0001\n",
      "Epoch 13, Step: 372, Loss: 0.035685427486896515, Lr:0.0001\n",
      "Epoch 13, Step: 373, Loss: 0.08673647046089172, Lr:0.0001\n",
      "Epoch 13, Step: 374, Loss: 0.3235398828983307, Lr:0.0001\n",
      "Epoch 13, Step: 375, Loss: 0.08349228650331497, Lr:0.0001\n",
      "Epoch 13, Step: 376, Loss: 0.1617809683084488, Lr:0.0001\n",
      "Epoch 13, Step: 377, Loss: 0.02463514916598797, Lr:0.0001\n",
      "Epoch 13, Step: 378, Loss: 0.18976415693759918, Lr:0.0001\n",
      "Epoch 13, Step: 379, Loss: 0.15486206114292145, Lr:0.0001\n",
      "Epoch 13, Step: 380, Loss: 0.05013895407319069, Lr:0.0001\n",
      "Epoch 13, Step: 381, Loss: 0.08310745656490326, Lr:0.0001\n",
      "Epoch 13, Step: 382, Loss: 0.027644162997603416, Lr:0.0001\n",
      "Epoch 13, Step: 383, Loss: 0.03781586512923241, Lr:0.0001\n",
      "Epoch 13, Step: 384, Loss: 0.02833491563796997, Lr:0.0001\n",
      "Epoch 13, Step: 385, Loss: 0.02000132016837597, Lr:0.0001\n",
      "Epoch 13, Step: 386, Loss: 0.17633961141109467, Lr:0.0001\n",
      "Epoch 13, Step: 387, Loss: 0.2963833510875702, Lr:0.0001\n",
      "Epoch 13, Step: 388, Loss: 0.272652804851532, Lr:0.0001\n",
      "Epoch 13, Step: 389, Loss: 0.04587642848491669, Lr:0.0001\n",
      "Epoch 13, Step: 390, Loss: 0.25037163496017456, Lr:0.0001\n",
      "Epoch 13, Step: 391, Loss: 0.07115568220615387, Lr:0.0001\n",
      "Epoch 13, Step: 392, Loss: 0.3960108458995819, Lr:0.0001\n",
      "Epoch 13, Step: 393, Loss: 0.003775180783122778, Lr:0.0001\n",
      "Epoch 13, Step: 394, Loss: 0.08989456295967102, Lr:0.0001\n",
      "Epoch 13, Step: 395, Loss: 0.576660692691803, Lr:0.0001\n",
      "Epoch 13, Step: 396, Loss: 0.4508218765258789, Lr:0.0001\n",
      "Epoch 13, Step: 397, Loss: 0.06910543143749237, Lr:0.0001\n",
      "Epoch 13, Step: 398, Loss: 0.28392112255096436, Lr:0.0001\n",
      "Epoch 13, Step: 399, Loss: 0.4451085329055786, Lr:0.0001\n",
      "Epoch 13, Step: 400, Loss: 0.04537602886557579, Lr:0.0001\n",
      "Epoch 13, Step: 401, Loss: 0.1613209992647171, Lr:0.0001\n",
      "Epoch 13, Step: 402, Loss: 0.046291451901197433, Lr:0.0001\n",
      "Epoch 13, Step: 403, Loss: 0.09896399080753326, Lr:0.0001\n",
      "Epoch 13, Step: 404, Loss: 0.21875455975532532, Lr:0.0001\n",
      "Epoch 13, Step: 405, Loss: 0.24272342026233673, Lr:0.0001\n",
      "Epoch 13, Step: 406, Loss: 0.24977314472198486, Lr:0.0001\n",
      "Epoch 13, Step: 407, Loss: 0.0387021079659462, Lr:0.0001\n",
      "Epoch 13, Step: 408, Loss: 0.1910674124956131, Lr:0.0001\n",
      "Epoch 13, Step: 409, Loss: 0.47300684452056885, Lr:0.0001\n",
      "Epoch 13, Step: 410, Loss: 0.07508378475904465, Lr:0.0001\n",
      "Epoch 13, Step: 411, Loss: 0.1396780163049698, Lr:0.0001\n",
      "Epoch 13, Step: 412, Loss: 0.174488365650177, Lr:0.0001\n",
      "Epoch 13, Step: 413, Loss: 0.05868314951658249, Lr:0.0001\n",
      "Epoch 13, Step: 414, Loss: 0.056858427822589874, Lr:0.0001\n",
      "Epoch 13, Step: 415, Loss: 0.08727572858333588, Lr:0.0001\n",
      "Epoch 13, Step: 416, Loss: 0.05329112336039543, Lr:0.0001\n",
      "Epoch 13, Step: 417, Loss: 0.08768033236265182, Lr:0.0001\n",
      "Epoch 13, Step: 418, Loss: 0.183591827750206, Lr:0.0001\n",
      "Epoch 13, Step: 419, Loss: 0.13106603920459747, Lr:0.0001\n",
      "Epoch 13, Step: 420, Loss: 0.0824357196688652, Lr:0.0001\n",
      "Epoch 13, Step: 421, Loss: 0.2680855691432953, Lr:0.0001\n",
      "Epoch 13, Step: 422, Loss: 0.04216909781098366, Lr:0.0001\n",
      "Epoch 13, Step: 423, Loss: 0.11384572833776474, Lr:0.0001\n",
      "Epoch 13, Step: 424, Loss: 0.44948628544807434, Lr:0.0001\n",
      "Epoch 13, Step: 425, Loss: 0.20442727208137512, Lr:0.0001\n",
      "Epoch 13, Step: 426, Loss: 0.22439615428447723, Lr:0.0001\n",
      "Epoch 13, Step: 427, Loss: 0.08828683197498322, Lr:0.0001\n",
      "Epoch 13, Step: 428, Loss: 0.23134608566761017, Lr:0.0001\n",
      "Epoch 13, Step: 429, Loss: 0.1098383441567421, Lr:0.0001\n",
      "Epoch 13, Step: 430, Loss: 0.1901075392961502, Lr:0.0001\n",
      "Epoch 13, Step: 431, Loss: 0.15370520949363708, Lr:0.0001\n",
      "Epoch 13, Step: 432, Loss: 0.017910398542881012, Lr:0.0001\n",
      "Epoch 13, Step: 433, Loss: 0.10486648231744766, Lr:0.0001\n",
      "Epoch 13, Step: 434, Loss: 0.026400981470942497, Lr:0.0001\n",
      "Epoch 13, Step: 435, Loss: 0.09871075302362442, Lr:0.0001\n",
      "Epoch 13, Step: 436, Loss: 0.20923179388046265, Lr:0.0001\n",
      "Epoch 13, Step: 437, Loss: 0.34999600052833557, Lr:0.0001\n",
      "Epoch 13, Step: 438, Loss: 0.24517282843589783, Lr:0.0001\n",
      "Epoch 13, Step: 439, Loss: 0.2708491086959839, Lr:0.0001\n",
      "Epoch 13, Step: 440, Loss: 0.19359883666038513, Lr:0.0001\n",
      "Epoch 13, Step: 441, Loss: 0.12426724284887314, Lr:0.0001\n",
      "Epoch 13, Step: 442, Loss: 0.14550119638442993, Lr:0.0001\n",
      "Epoch 13, Step: 443, Loss: 0.01049363799393177, Lr:0.0001\n",
      "Epoch 13, Step: 444, Loss: 0.1265714466571808, Lr:0.0001\n",
      "Epoch 13, Step: 445, Loss: 0.03590394929051399, Lr:0.0001\n",
      "Epoch 13, Step: 446, Loss: 0.18862202763557434, Lr:0.0001\n",
      "Epoch 13, Step: 447, Loss: 0.012574272230267525, Lr:0.0001\n",
      "Epoch 13, Step: 448, Loss: 0.08875960111618042, Lr:0.0001\n",
      "Epoch 13, Step: 449, Loss: 0.26185277104377747, Lr:0.0001\n",
      "Epoch 13, Step: 450, Loss: 0.08762533217668533, Lr:0.0001\n",
      "Epoch 13, Step: 451, Loss: 0.09406781941652298, Lr:0.0001\n",
      "Epoch 13, Step: 452, Loss: 0.1673809438943863, Lr:0.0001\n",
      "Epoch 13, Step: 453, Loss: 0.1855638474225998, Lr:0.0001\n",
      "Epoch 13, Step: 454, Loss: 0.34020525217056274, Lr:0.0001\n",
      "Epoch 13, Step: 455, Loss: 0.08471551537513733, Lr:0.0001\n",
      "Epoch 13, Step: 456, Loss: 0.05121619626879692, Lr:0.0001\n",
      "Epoch 13, Step: 457, Loss: 0.14776621758937836, Lr:0.0001\n",
      "Epoch 13, Step: 458, Loss: 0.11919855326414108, Lr:0.0001\n",
      "Epoch 13, Step: 459, Loss: 0.25450369715690613, Lr:0.0001\n",
      "Epoch 13, Step: 460, Loss: 0.37023457884788513, Lr:0.0001\n",
      "Epoch 13, Step: 461, Loss: 0.14079537987709045, Lr:0.0001\n",
      "Epoch 13, Step: 462, Loss: 0.37066787481307983, Lr:0.0001\n",
      "Epoch 13, Step: 463, Loss: 0.12268199771642685, Lr:0.0001\n",
      "Epoch 13, Step: 464, Loss: 0.07787753641605377, Lr:0.0001\n",
      "Epoch 13, Step: 465, Loss: 0.04157644137740135, Lr:0.0001\n",
      "Epoch 13, Step: 466, Loss: 0.024106277152895927, Lr:0.0001\n",
      "Epoch 13, Step: 467, Loss: 0.09432565420866013, Lr:0.0001\n",
      "Epoch 13, Step: 468, Loss: 0.02215702272951603, Lr:0.0001\n",
      "Epoch 13, Step: 469, Loss: 0.04602974280714989, Lr:0.0001\n",
      "Epoch 13, Step: 470, Loss: 0.053672533482313156, Lr:0.0001\n",
      "Epoch 13, Step: 471, Loss: 0.25311627984046936, Lr:0.0001\n",
      "Epoch 13, Step: 472, Loss: 0.06553915143013, Lr:0.0001\n",
      "Epoch 13, Step: 473, Loss: 0.22157272696495056, Lr:0.0001\n",
      "Epoch 13, Step: 474, Loss: 0.14309614896774292, Lr:0.0001\n",
      "Epoch 13, Step: 475, Loss: 0.16935700178146362, Lr:0.0001\n",
      "Epoch 13, Step: 476, Loss: 0.2663641571998596, Lr:0.0001\n",
      "Epoch 13, Step: 477, Loss: 0.09780538082122803, Lr:0.0001\n",
      "Epoch 13, Step: 478, Loss: 0.034835245460271835, Lr:0.0001\n",
      "Epoch 13, Step: 479, Loss: 0.09699378162622452, Lr:0.0001\n",
      "Epoch 13, Step: 480, Loss: 0.09750311821699142, Lr:0.0001\n",
      "Epoch 13, Step: 481, Loss: 0.04865487664937973, Lr:0.0001\n",
      "Epoch 13, Step: 482, Loss: 0.32024767994880676, Lr:0.0001\n",
      "Epoch 13, Step: 483, Loss: 0.03823477402329445, Lr:0.0001\n",
      "Epoch 13, Step: 484, Loss: 0.083580382168293, Lr:0.0001\n",
      "Epoch 13, Step: 485, Loss: 0.16662196815013885, Lr:0.0001\n",
      "Epoch 13, Step: 486, Loss: 0.1610223650932312, Lr:0.0001\n",
      "Epoch 13, Step: 487, Loss: 0.06990016996860504, Lr:0.0001\n",
      "Epoch 13, Step: 488, Loss: 0.3753325343132019, Lr:0.0001\n",
      "Epoch 13, Step: 489, Loss: 0.024998974055051804, Lr:0.0001\n",
      "Epoch 13, Step: 490, Loss: 0.04635260999202728, Lr:0.0001\n",
      "Epoch 13, Step: 491, Loss: 0.10329725593328476, Lr:0.0001\n",
      "Epoch 13, Step: 492, Loss: 0.06695819646120071, Lr:0.0001\n",
      "Epoch 13, Step: 493, Loss: 0.0731196478009224, Lr:0.0001\n",
      "Epoch 13, Step: 494, Loss: 0.06764024496078491, Lr:0.0001\n",
      "Epoch 13, Step: 495, Loss: 0.49235448241233826, Lr:0.0001\n",
      "Epoch 13, Step: 496, Loss: 0.09907525032758713, Lr:0.0001\n",
      "Epoch 13, Step: 497, Loss: 0.11690042167901993, Lr:0.0001\n",
      "Epoch 13, Step: 498, Loss: 0.07162018120288849, Lr:0.0001\n",
      "Epoch 13, Step: 499, Loss: 0.1715705543756485, Lr:0.0001\n",
      "Epoch 13, Step: 500, Loss: 0.300192654132843, Lr:0.0001\n",
      "Epoch 13, Step: 501, Loss: 0.03587828949093819, Lr:0.0001\n",
      "Epoch 13, Step: 502, Loss: 0.02686516009271145, Lr:0.0001\n",
      "Epoch 13, Step: 503, Loss: 0.03882485255599022, Lr:0.0001\n",
      "Epoch 13, Step: 504, Loss: 0.0895698294043541, Lr:0.0001\n",
      "Epoch 13, Step: 505, Loss: 0.1968446969985962, Lr:0.0001\n",
      "Epoch 13, Step: 506, Loss: 0.16313062608242035, Lr:0.0001\n",
      "Epoch 13, Step: 507, Loss: 0.07332342118024826, Lr:0.0001\n",
      "Epoch 13, Step: 508, Loss: 0.03020063228905201, Lr:0.0001\n",
      "Epoch 13, Step: 509, Loss: 0.008874820545315742, Lr:0.0001\n",
      "Epoch 13, Step: 510, Loss: 0.12684932351112366, Lr:0.0001\n",
      "Epoch 13, Step: 511, Loss: 0.38049793243408203, Lr:0.0001\n",
      "Epoch 13, Step: 512, Loss: 0.1580807864665985, Lr:0.0001\n",
      "Epoch 13, Step: 513, Loss: 0.033550091087818146, Lr:0.0001\n",
      "Epoch 13, Step: 514, Loss: 0.06514487415552139, Lr:0.0001\n",
      "Epoch 13, Step: 515, Loss: 0.0433700792491436, Lr:0.0001\n",
      "Epoch 13, Step: 516, Loss: 0.30369332432746887, Lr:0.0001\n",
      "Epoch 13, Step: 517, Loss: 0.14785489439964294, Lr:0.0001\n",
      "Epoch 13, Step: 518, Loss: 0.14117127656936646, Lr:0.0001\n",
      "Epoch 13, Step: 519, Loss: 0.14540372788906097, Lr:0.0001\n",
      "Epoch 13, Step: 520, Loss: 0.0249472688883543, Lr:0.0001\n",
      "Epoch 13, Step: 521, Loss: 0.20925450325012207, Lr:0.0001\n",
      "Epoch 13, Step: 522, Loss: 0.33111757040023804, Lr:0.0001\n",
      "Epoch 13, Step: 523, Loss: 0.04234684631228447, Lr:0.0001\n",
      "Epoch 13, Step: 524, Loss: 0.9264665842056274, Lr:0.0001\n",
      "Epoch 13, Step: 525, Loss: 0.025575676932930946, Lr:0.0001\n",
      "Epoch 13, Step: 526, Loss: 0.009646707214415073, Lr:0.0001\n",
      "Epoch 13, Step: 527, Loss: 0.058912064880132675, Lr:0.0001\n",
      "Epoch 13, Step: 528, Loss: 0.2461511194705963, Lr:0.0001\n",
      "Epoch 13, Step: 529, Loss: 0.332344114780426, Lr:0.0001\n",
      "Epoch 13, Step: 530, Loss: 0.1301887035369873, Lr:0.0001\n",
      "Epoch 13, Step: 531, Loss: 0.20598618686199188, Lr:0.0001\n",
      "Epoch 13, Step: 532, Loss: 0.14018237590789795, Lr:0.0001\n",
      "Epoch 13, Step: 533, Loss: 0.1909942924976349, Lr:0.0001\n",
      "Epoch 13, Step: 534, Loss: 0.3001987338066101, Lr:0.0001\n",
      "Epoch 13, Step: 535, Loss: 0.19658686220645905, Lr:0.0001\n",
      "Epoch 13, Step: 536, Loss: 0.04782950133085251, Lr:0.0001\n",
      "Epoch 13, Step: 537, Loss: 0.11127417534589767, Lr:0.0001\n",
      "Epoch 13, Step: 538, Loss: 0.11010520160198212, Lr:0.0001\n",
      "Epoch 13, Step: 539, Loss: 0.10812751203775406, Lr:0.0001\n",
      "Epoch 13, Step: 540, Loss: 0.15010403096675873, Lr:0.0001\n",
      "Epoch 13, Step: 541, Loss: 0.09909696131944656, Lr:0.0001\n",
      "Epoch 13, Step: 542, Loss: 0.015366914682090282, Lr:0.0001\n",
      "Epoch 13, Step: 543, Loss: 0.09760675579309464, Lr:0.0001\n",
      "Epoch 13, Step: 544, Loss: 0.1146843284368515, Lr:0.0001\n",
      "Epoch 13, Step: 545, Loss: 0.07347371429204941, Lr:0.0001\n",
      "Epoch 13, Step: 546, Loss: 0.018610158935189247, Lr:0.0001\n",
      "Epoch 13, Step: 547, Loss: 0.09745365381240845, Lr:0.0001\n",
      "Epoch 13, Step: 548, Loss: 0.2572961449623108, Lr:0.0001\n",
      "Epoch 13, Step: 549, Loss: 0.11684310436248779, Lr:0.0001\n",
      "Epoch 13, Step: 550, Loss: 0.035971373319625854, Lr:0.0001\n",
      "Epoch 13, Step: 551, Loss: 0.12462571263313293, Lr:0.0001\n",
      "Epoch 13, Step: 552, Loss: 0.3245444595813751, Lr:0.0001\n",
      "Epoch 13, Step: 553, Loss: 0.035087186843156815, Lr:0.0001\n",
      "Epoch 13, Step: 554, Loss: 0.3185368478298187, Lr:0.0001\n",
      "Epoch 13, Step: 555, Loss: 0.045733433216810226, Lr:0.0001\n",
      "Epoch 13, Step: 556, Loss: 0.300497442483902, Lr:0.0001\n",
      "Epoch 13, Step: 557, Loss: 0.16710422933101654, Lr:0.0001\n",
      "Epoch 13, Step: 558, Loss: 0.09241164475679398, Lr:0.0001\n",
      "Epoch 13, Step: 559, Loss: 0.023920223116874695, Lr:0.0001\n",
      "Epoch 13, Step: 560, Loss: 0.08176790922880173, Lr:0.0001\n",
      "Epoch 13, Step: 561, Loss: 0.08147428929805756, Lr:0.0001\n",
      "Epoch 13, Step: 562, Loss: 0.2114991545677185, Lr:0.0001\n",
      "Epoch 13, Step: 563, Loss: 0.19036923348903656, Lr:0.0001\n",
      "Epoch 13, Step: 564, Loss: 0.32674092054367065, Lr:0.0001\n",
      "Epoch 13, Step: 565, Loss: 0.0413019172847271, Lr:0.0001\n",
      "Epoch 13, Step: 566, Loss: 0.07202993333339691, Lr:0.0001\n",
      "Epoch 13, Step: 567, Loss: 0.02790893241763115, Lr:0.0001\n",
      "Epoch 13, Step: 568, Loss: 0.03967535123229027, Lr:0.0001\n",
      "Epoch 13, Step: 569, Loss: 0.058458540588617325, Lr:0.0001\n",
      "Epoch 13, Step: 570, Loss: 0.0785544365644455, Lr:0.0001\n",
      "Epoch 13, Step: 571, Loss: 0.10901863127946854, Lr:0.0001\n",
      "Epoch 13, Step: 572, Loss: 0.13267260789871216, Lr:0.0001\n",
      "Epoch 13, Step: 573, Loss: 0.07336845248937607, Lr:0.0001\n",
      "Epoch 13, Step: 574, Loss: 0.11438903212547302, Lr:0.0001\n",
      "Epoch 13, Step: 575, Loss: 0.0031130430288612843, Lr:0.0001\n",
      "Epoch 13, Step: 576, Loss: 0.022932374849915504, Lr:0.0001\n",
      "Epoch 13, Step: 577, Loss: 0.09130095690488815, Lr:0.0001\n",
      "Epoch 13, Step: 578, Loss: 0.1046442836523056, Lr:0.0001\n",
      "Epoch 13, Step: 579, Loss: 0.0818130224943161, Lr:0.0001\n",
      "Epoch 13, Step: 580, Loss: 0.260814905166626, Lr:0.0001\n",
      "Epoch 13, Step: 581, Loss: 0.055184923112392426, Lr:0.0001\n",
      "Epoch 13, Step: 582, Loss: 0.09194058179855347, Lr:0.0001\n",
      "Epoch 13, Step: 583, Loss: 0.09861147403717041, Lr:0.0001\n",
      "Epoch 13, Step: 584, Loss: 0.25186705589294434, Lr:0.0001\n",
      "Epoch 13, Step: 585, Loss: 0.027301546186208725, Lr:0.0001\n",
      "Epoch 13, Step: 586, Loss: 0.36027729511260986, Lr:0.0001\n",
      "Epoch 13, Step: 587, Loss: 0.10507107526063919, Lr:0.0001\n",
      "Epoch 13, Step: 588, Loss: 0.03166555240750313, Lr:0.0001\n",
      "Epoch 13, Step: 589, Loss: 0.1151900440454483, Lr:0.0001\n",
      "Epoch 13, Step: 590, Loss: 0.5074113607406616, Lr:0.0001\n",
      "Epoch 13, Step: 591, Loss: 0.4048015773296356, Lr:0.0001\n",
      "Epoch 13, Step: 592, Loss: 0.018136391416192055, Lr:0.0001\n",
      "Epoch 13, Step: 593, Loss: 0.009724823758006096, Lr:0.0001\n",
      "Epoch 13, Step: 594, Loss: 0.12129590660333633, Lr:0.0001\n",
      "Epoch 13, Step: 595, Loss: 0.15159691870212555, Lr:0.0001\n",
      "Epoch 13, Step: 596, Loss: 0.09899044036865234, Lr:0.0001\n",
      "Epoch 13, Step: 597, Loss: 0.11893966794013977, Lr:0.0001\n",
      "Epoch 13, Step: 598, Loss: 0.3539779484272003, Lr:0.0001\n",
      "Epoch 13, Step: 599, Loss: 0.2998684346675873, Lr:0.0001\n",
      "Epoch 13, Step: 600, Loss: 0.09197351336479187, Lr:0.0001\n",
      "Epoch 13, Step: 601, Loss: 0.24030016362667084, Lr:0.0001\n",
      "Epoch 13, Step: 602, Loss: 0.28017088770866394, Lr:0.0001\n",
      "Epoch 13, Step: 603, Loss: 0.04602256417274475, Lr:0.0001\n",
      "Epoch 13, Step: 604, Loss: 0.055825404822826385, Lr:0.0001\n",
      "Epoch 13, Step: 605, Loss: 0.042692720890045166, Lr:0.0001\n",
      "Epoch 13, Step: 606, Loss: 0.17542624473571777, Lr:0.0001\n",
      "Epoch 13, Step: 607, Loss: 0.1528601050376892, Lr:0.0001\n",
      "Epoch 13, Step: 608, Loss: 0.011782706715166569, Lr:0.0001\n",
      "Epoch 13, Step: 609, Loss: 0.09847160428762436, Lr:0.0001\n",
      "Epoch 13, Step: 610, Loss: 0.24432696402072906, Lr:0.0001\n",
      "Epoch 13, Step: 611, Loss: 0.2835850715637207, Lr:0.0001\n",
      "Epoch 13, Step: 612, Loss: 0.11289847642183304, Lr:0.0001\n",
      "Epoch 13, Step: 613, Loss: 0.3024284243583679, Lr:0.0001\n",
      "Epoch 13, Step: 614, Loss: 0.041717205196619034, Lr:0.0001\n",
      "Epoch 13, Step: 615, Loss: 0.08104592561721802, Lr:0.0001\n",
      "Epoch 13, Step: 616, Loss: 0.35180848836898804, Lr:0.0001\n",
      "Epoch 13, Step: 617, Loss: 0.14008739590644836, Lr:0.0001\n",
      "Epoch 13, Step: 618, Loss: 0.2620234787464142, Lr:0.0001\n",
      "Epoch 13, Step: 619, Loss: 0.14592064917087555, Lr:0.0001\n",
      "Epoch 13, Step: 620, Loss: 0.28882208466529846, Lr:0.0001\n",
      "Epoch 13, Step: 621, Loss: 0.0754997730255127, Lr:0.0001\n",
      "Epoch 13, Step: 622, Loss: 0.20404747128486633, Lr:0.0001\n",
      "Epoch 13, Step: 623, Loss: 0.01753072813153267, Lr:0.0001\n",
      "Epoch 13, Step: 624, Loss: 0.2582574784755707, Lr:0.0001\n",
      "Epoch 13, Step: 625, Loss: 0.041352372616529465, Lr:0.0001\n",
      "Epoch 13, Step: 626, Loss: 0.02196360006928444, Lr:0.0001\n",
      "Epoch 13, Step: 627, Loss: 0.12570273876190186, Lr:0.0001\n",
      "Epoch 13, Step: 628, Loss: 0.028621330857276917, Lr:0.0001\n",
      "Epoch 13, Step: 629, Loss: 0.15949121117591858, Lr:0.0001\n",
      "Epoch 13, Step: 630, Loss: 0.028153419494628906, Lr:0.0001\n",
      "Epoch 13, Step: 631, Loss: 0.1935274600982666, Lr:0.0001\n",
      "Epoch 13, Step: 632, Loss: 0.3990773558616638, Lr:0.0001\n",
      "Epoch 13, Step: 633, Loss: 0.33150342106819153, Lr:0.0001\n",
      "Epoch 13, Step: 634, Loss: 0.12019528448581696, Lr:0.0001\n",
      "Epoch 13, Step: 635, Loss: 0.26683309674263, Lr:0.0001\n",
      "Epoch 13, Step: 636, Loss: 0.32798752188682556, Lr:0.0001\n",
      "Epoch 13, Step: 637, Loss: 0.05531127750873566, Lr:0.0001\n",
      "Epoch 13, Step: 638, Loss: 0.3712887763977051, Lr:0.0001\n",
      "Epoch 13, Step: 639, Loss: 0.03690562769770622, Lr:0.0001\n",
      "Epoch 13, Step: 640, Loss: 0.10123176127672195, Lr:0.0001\n",
      "Epoch 13, Step: 641, Loss: 0.08270437270402908, Lr:0.0001\n",
      "Epoch 13, Step: 642, Loss: 0.09764237701892853, Lr:0.0001\n",
      "Epoch 13, Step: 643, Loss: 0.07490465044975281, Lr:0.0001\n",
      "Epoch 13, Step: 644, Loss: 0.042824625968933105, Lr:0.0001\n",
      "Epoch 13, Step: 645, Loss: 0.032338473945856094, Lr:0.0001\n",
      "Epoch 13, Step: 646, Loss: 0.05653909966349602, Lr:0.0001\n",
      "Epoch 13, Step: 647, Loss: 0.15470749139785767, Lr:0.0001\n",
      "Epoch 13, Step: 648, Loss: 0.1717647761106491, Lr:0.0001\n",
      "Epoch 13, Step: 649, Loss: 0.39080846309661865, Lr:0.0001\n",
      "Epoch 13, Step: 650, Loss: 0.04939044639468193, Lr:0.0001\n",
      "Epoch 13, Step: 651, Loss: 0.017612509429454803, Lr:0.0001\n",
      "Epoch 13, Step: 652, Loss: 0.06637001782655716, Lr:0.0001\n",
      "Epoch 13, Step: 653, Loss: 0.20427680015563965, Lr:0.0001\n",
      "Epoch 13, Step: 654, Loss: 0.10945609956979752, Lr:0.0001\n",
      "Epoch 13, Step: 655, Loss: 0.03262130543589592, Lr:0.0001\n",
      "Epoch 13, Step: 656, Loss: 0.015649929642677307, Lr:0.0001\n",
      "Epoch 13, Step: 657, Loss: 0.08475828170776367, Lr:0.0001\n",
      "Epoch 13, Step: 658, Loss: 0.07106508314609528, Lr:0.0001\n",
      "Epoch 13, Step: 659, Loss: 0.11574088782072067, Lr:0.0001\n",
      "Epoch 13, Step: 660, Loss: 0.07912645488977432, Lr:0.0001\n",
      "Epoch 13, Step: 661, Loss: 0.260055273771286, Lr:0.0001\n",
      "Epoch 13, Step: 662, Loss: 0.1116938441991806, Lr:0.0001\n",
      "Epoch 13, Step: 663, Loss: 0.3039282262325287, Lr:0.0001\n",
      "Epoch 13, Step: 664, Loss: 0.3888169229030609, Lr:0.0001\n",
      "Epoch 13, Step: 665, Loss: 0.07924316078424454, Lr:0.0001\n",
      "Epoch 13, Step: 666, Loss: 0.06336237490177155, Lr:0.0001\n",
      "Epoch 13, Step: 667, Loss: 0.04688083752989769, Lr:0.0001\n",
      "Epoch 13, Step: 668, Loss: 0.25652655959129333, Lr:0.0001\n",
      "Epoch 13, Step: 669, Loss: 0.09907610714435577, Lr:0.0001\n",
      "Epoch 13, Step: 670, Loss: 0.09439244866371155, Lr:0.0001\n",
      "Epoch 13, Step: 671, Loss: 0.10217640548944473, Lr:0.0001\n",
      "Epoch 13, Step: 672, Loss: 0.049266211688518524, Lr:0.0001\n",
      "Epoch 13, Step: 673, Loss: 0.42669638991355896, Lr:0.0001\n",
      "Epoch 13, Step: 674, Loss: 0.04940817132592201, Lr:0.0001\n",
      "Epoch 13, Step: 675, Loss: 0.1282598227262497, Lr:0.0001\n",
      "Epoch 13, Step: 676, Loss: 0.18691498041152954, Lr:0.0001\n",
      "Epoch 13, Step: 677, Loss: 0.115258127450943, Lr:0.0001\n",
      "Epoch 13, Step: 678, Loss: 0.06334935128688812, Lr:0.0001\n",
      "Epoch 13, Step: 679, Loss: 0.8624492883682251, Lr:0.0001\n",
      "Epoch 13, Step: 680, Loss: 0.20428307354450226, Lr:0.0001\n",
      "Epoch 13, Step: 681, Loss: 0.04156043380498886, Lr:0.0001\n",
      "Epoch 13, Step: 682, Loss: 0.17645177245140076, Lr:0.0001\n",
      "Epoch 13, Step: 683, Loss: 0.05524580553174019, Lr:0.0001\n",
      "Epoch 13, Step: 684, Loss: 0.1838642656803131, Lr:0.0001\n",
      "Epoch 13, Step: 685, Loss: 0.1042480543255806, Lr:0.0001\n",
      "Epoch 13, Step: 686, Loss: 0.10666082799434662, Lr:0.0001\n",
      "Epoch 13, Step: 687, Loss: 0.14334087073802948, Lr:0.0001\n",
      "Epoch 13, Step: 688, Loss: 0.30622586607933044, Lr:0.0001\n",
      "Epoch 13, Step: 689, Loss: 0.19075541198253632, Lr:0.0001\n",
      "Epoch 13, Step: 690, Loss: 0.11183451116085052, Lr:0.0001\n",
      "Epoch 13, Step: 691, Loss: 0.033536311239004135, Lr:0.0001\n",
      "Epoch 13, Step: 692, Loss: 0.008934817276895046, Lr:0.0001\n",
      "Epoch 13, Step: 693, Loss: 0.21947269141674042, Lr:0.0001\n",
      "Epoch 13, Step: 694, Loss: 0.06559856981039047, Lr:0.0001\n",
      "Epoch 13, Step: 695, Loss: 0.3077429533004761, Lr:0.0001\n",
      "Epoch 13, Step: 696, Loss: 0.23726323246955872, Lr:0.0001\n",
      "Epoch 13, Step: 697, Loss: 0.11384247243404388, Lr:0.0001\n",
      "Epoch 13, Step: 698, Loss: 0.28719720244407654, Lr:0.0001\n",
      "Epoch 13, Step: 699, Loss: 0.11990656703710556, Lr:0.0001\n",
      "Epoch 13, Step: 700, Loss: 0.06499258428812027, Lr:0.0001\n",
      "Epoch 13, Step: 701, Loss: 0.19275200366973877, Lr:0.0001\n",
      "Epoch 13, Step: 702, Loss: 0.06501366943120956, Lr:0.0001\n",
      "Epoch 13, Step: 703, Loss: 0.141974538564682, Lr:0.0001\n",
      "Epoch 13, Step: 704, Loss: 0.02391580119729042, Lr:0.0001\n",
      "Epoch 13, Step: 705, Loss: 0.003053303575143218, Lr:0.0001\n",
      "Epoch 13, Step: 706, Loss: 0.027541644871234894, Lr:0.0001\n",
      "Epoch 13, Step: 707, Loss: 0.11186020076274872, Lr:0.0001\n",
      "Epoch 13, Step: 708, Loss: 0.013961374759674072, Lr:0.0001\n",
      "Epoch 13, Step: 709, Loss: 0.01638421043753624, Lr:0.0001\n",
      "Epoch 13, Step: 710, Loss: 0.06966140121221542, Lr:0.0001\n",
      "Epoch 13, Step: 711, Loss: 0.07048513740301132, Lr:0.0001\n",
      "Epoch 13, Step: 712, Loss: 0.03105991519987583, Lr:0.0001\n",
      "Epoch 13, Step: 713, Loss: 0.09047374129295349, Lr:0.0001\n",
      "Epoch 13, Step: 714, Loss: 0.19064722955226898, Lr:0.0001\n",
      "Epoch 13, Step: 715, Loss: 0.05920414254069328, Lr:0.0001\n",
      "Epoch 13, Step: 716, Loss: 0.01425192691385746, Lr:0.0001\n",
      "Epoch 13, Step: 717, Loss: 0.04977123439311981, Lr:0.0001\n",
      "Epoch 13, Step: 718, Loss: 0.230157271027565, Lr:0.0001\n",
      "Epoch 13, Step: 719, Loss: 0.0989425927400589, Lr:0.0001\n",
      "Epoch 13, Step: 720, Loss: 0.015087710693478584, Lr:0.0001\n",
      "Epoch 13, Step: 721, Loss: 0.03588235005736351, Lr:0.0001\n",
      "Epoch 13, Step: 722, Loss: 0.014249464496970177, Lr:0.0001\n",
      "Epoch 13, Step: 723, Loss: 0.09490521252155304, Lr:0.0001\n",
      "Epoch 13, Step: 724, Loss: 0.08474938571453094, Lr:0.0001\n",
      "Epoch 13, Step: 725, Loss: 0.07899309694766998, Lr:0.0001\n",
      "Epoch 13, Step: 726, Loss: 0.07336906343698502, Lr:0.0001\n",
      "Epoch 13, Step: 727, Loss: 0.08260736614465714, Lr:0.0001\n",
      "Epoch 13, Step: 728, Loss: 0.016876166686415672, Lr:0.0001\n",
      "Epoch 13, Step: 729, Loss: 0.027257973328232765, Lr:0.0001\n",
      "Epoch 13, Step: 730, Loss: 0.08858942985534668, Lr:0.0001\n",
      "Epoch 13, Step: 731, Loss: 0.0023340978659689426, Lr:0.0001\n",
      "Epoch 13, Step: 732, Loss: 0.22314554452896118, Lr:0.0001\n",
      "Epoch 13, Step: 733, Loss: 0.451669842004776, Lr:0.0001\n",
      "Epoch 13, Step: 734, Loss: 0.03747719153761864, Lr:0.0001\n",
      "Epoch 13, Step: 735, Loss: 0.012184755876660347, Lr:0.0001\n",
      "Epoch 13, Step: 736, Loss: 0.07740119099617004, Lr:0.0001\n",
      "Epoch 13, Step: 737, Loss: 0.08720904588699341, Lr:0.0001\n",
      "Epoch 13, Step: 738, Loss: 0.24970658123493195, Lr:0.0001\n",
      "Epoch 13, Step: 739, Loss: 0.1944049894809723, Lr:0.0001\n",
      "Epoch 13, Step: 740, Loss: 0.07740464806556702, Lr:0.0001\n",
      "Epoch 13, Step: 741, Loss: 0.48004430532455444, Lr:0.0001\n",
      "Epoch 13, Step: 742, Loss: 0.24078860878944397, Lr:0.0001\n",
      "Epoch 13, Step: 743, Loss: 0.09299175441265106, Lr:0.0001\n",
      "Epoch 13, Step: 744, Loss: 0.14370812475681305, Lr:0.0001\n",
      "Epoch 13, Step: 745, Loss: 0.15082795917987823, Lr:0.0001\n",
      "Epoch 13, Step: 746, Loss: 0.16656488180160522, Lr:0.0001\n",
      "Epoch 13, Step: 747, Loss: 0.16593022644519806, Lr:0.0001\n",
      "Epoch 13, Step: 748, Loss: 0.18124404549598694, Lr:0.0001\n",
      "Epoch 13, Step: 749, Loss: 0.18817660212516785, Lr:0.0001\n",
      "Epoch 13, Step: 750, Loss: 0.2501735985279083, Lr:0.0001\n",
      "Epoch 13, Step: 751, Loss: 0.03908688575029373, Lr:0.0001\n",
      "Epoch 13, Step: 752, Loss: 0.1926664113998413, Lr:0.0001\n",
      "Epoch 13, Step: 753, Loss: 0.07575604319572449, Lr:0.0001\n",
      "Epoch 13, Step: 754, Loss: 0.026660293340682983, Lr:0.0001\n",
      "Epoch 13, Step: 755, Loss: 0.1848638355731964, Lr:0.0001\n",
      "Epoch 13, Step: 756, Loss: 0.10036545991897583, Lr:0.0001\n",
      "Epoch 13, Step: 757, Loss: 0.018089478835463524, Lr:0.0001\n",
      "Epoch 13, Step: 758, Loss: 0.060457903891801834, Lr:0.0001\n",
      "Epoch 13, Step: 759, Loss: 0.14281414449214935, Lr:0.0001\n",
      "Epoch 13, Step: 760, Loss: 0.22627252340316772, Lr:0.0001\n",
      "Epoch 13, Step: 761, Loss: 0.10216370224952698, Lr:0.0001\n",
      "Epoch 13, Step: 762, Loss: 0.2841094732284546, Lr:0.0001\n",
      "Epoch 13, Step: 763, Loss: 0.012446120381355286, Lr:0.0001\n",
      "Epoch 13, Step: 764, Loss: 0.16337299346923828, Lr:0.0001\n",
      "Epoch 13, Step: 765, Loss: 0.043510857969522476, Lr:0.0001\n",
      "Epoch 13, Step: 766, Loss: 0.05023573711514473, Lr:0.0001\n",
      "Epoch 13, Step: 767, Loss: 0.005786640103906393, Lr:0.0001\n",
      "Epoch 13, Step: 768, Loss: 0.3126108646392822, Lr:0.0001\n",
      "Epoch 13, Step: 769, Loss: 0.10024730861186981, Lr:0.0001\n",
      "Epoch 13, Step: 770, Loss: 0.1461075246334076, Lr:0.0001\n",
      "Epoch 13, Step: 771, Loss: 0.05427895486354828, Lr:0.0001\n",
      "Epoch 13, Step: 772, Loss: 0.009107965044677258, Lr:0.0001\n",
      "Epoch 13, Step: 773, Loss: 0.0909186527132988, Lr:0.0001\n",
      "Epoch 13, Step: 774, Loss: 0.10111925005912781, Lr:0.0001\n",
      "Epoch 13, Step: 775, Loss: 0.0268507432192564, Lr:0.0001\n",
      "Epoch 13, Step: 776, Loss: 0.11263511329889297, Lr:0.0001\n",
      "Epoch 13, Step: 777, Loss: 0.18055684864521027, Lr:0.0001\n",
      "Epoch 13, Step: 778, Loss: 0.10644687712192535, Lr:0.0001\n",
      "Epoch 13, Step: 779, Loss: 0.01882464438676834, Lr:0.0001\n",
      "Epoch 13, Step: 780, Loss: 0.027805209159851074, Lr:0.0001\n",
      "Epoch 13, Step: 781, Loss: 0.2589479684829712, Lr:0.0001\n",
      "Epoch 13, Step: 782, Loss: 0.1033647432923317, Lr:0.0001\n",
      "Epoch 13, Step: 783, Loss: 0.06528341770172119, Lr:0.0001\n",
      "Epoch 13, Step: 784, Loss: 0.12501108646392822, Lr:0.0001\n",
      "Epoch 13, Step: 785, Loss: 0.03970036655664444, Lr:0.0001\n",
      "Epoch 13, Step: 786, Loss: 0.022065164521336555, Lr:0.0001\n",
      "Epoch 13, Step: 787, Loss: 0.034514397382736206, Lr:0.0001\n",
      "Epoch 13, Step: 788, Loss: 0.24743841588497162, Lr:0.0001\n",
      "Epoch 13, Step: 789, Loss: 0.09694656729698181, Lr:0.0001\n",
      "Epoch 13, Step: 790, Loss: 0.04132331907749176, Lr:0.0001\n",
      "Epoch 13, Step: 791, Loss: 0.1359885185956955, Lr:0.0001\n",
      "Epoch 13, Step: 792, Loss: 0.04981806501746178, Lr:0.0001\n",
      "Epoch 13, Step: 793, Loss: 0.14883948862552643, Lr:0.0001\n",
      "Epoch 13, Step: 794, Loss: 0.25397804379463196, Lr:0.0001\n",
      "Epoch 13, Step: 795, Loss: 0.09090718626976013, Lr:0.0001\n",
      "Epoch 13, Step: 796, Loss: 0.13387516140937805, Lr:0.0001\n",
      "Epoch 13, Step: 797, Loss: 0.09801542013883591, Lr:0.0001\n",
      "Epoch 13, Step: 798, Loss: 0.09889818727970123, Lr:0.0001\n",
      "Epoch 13, Step: 799, Loss: 0.016973460093140602, Lr:0.0001\n",
      "Epoch 13, Step: 800, Loss: 0.10921977460384369, Lr:0.0001\n",
      "Epoch 13, Step: 801, Loss: 0.006818750873208046, Lr:0.0001\n",
      "Epoch 13, Step: 802, Loss: 0.19260059297084808, Lr:0.0001\n",
      "Epoch 13, Step: 803, Loss: 0.008829871192574501, Lr:0.0001\n",
      "Epoch 13, Step: 804, Loss: 0.22749869525432587, Lr:0.0001\n",
      "Epoch 13, Step: 805, Loss: 0.11479660868644714, Lr:0.0001\n",
      "Epoch 13, Step: 806, Loss: 0.17390497028827667, Lr:0.0001\n",
      "Epoch 13, Step: 807, Loss: 0.013671569526195526, Lr:0.0001\n",
      "Epoch 13, Step: 808, Loss: 0.01559648010879755, Lr:0.0001\n",
      "Epoch 13, Step: 809, Loss: 0.1636418104171753, Lr:0.0001\n",
      "Epoch 13, Step: 810, Loss: 0.023186752572655678, Lr:0.0001\n",
      "Epoch 13, Step: 811, Loss: 0.02479059249162674, Lr:0.0001\n",
      "Epoch 13, Step: 812, Loss: 0.10553134977817535, Lr:0.0001\n",
      "Epoch 13, Step: 813, Loss: 0.015750465914607048, Lr:0.0001\n",
      "Epoch 13, Step: 814, Loss: 0.014119300059974194, Lr:0.0001\n",
      "Epoch 13, Step: 815, Loss: 0.15995687246322632, Lr:0.0001\n",
      "Epoch 13, Step: 816, Loss: 0.1023346334695816, Lr:0.0001\n",
      "Epoch 13, Step: 817, Loss: 0.04824104905128479, Lr:0.0001\n",
      "Epoch 13, Step: 818, Loss: 0.026434432715177536, Lr:0.0001\n",
      "Epoch 13, Step: 819, Loss: 0.05783671885728836, Lr:0.0001\n",
      "Epoch 13, Step: 820, Loss: 0.08527489751577377, Lr:0.0001\n",
      "Epoch 13, Step: 821, Loss: 0.03992311283946037, Lr:0.0001\n",
      "Epoch 13, Step: 822, Loss: 0.1461964249610901, Lr:0.0001\n",
      "Epoch 13, Step: 823, Loss: 0.0092054083943367, Lr:0.0001\n",
      "Epoch 13, Step: 824, Loss: 0.18482007086277008, Lr:0.0001\n",
      "Epoch 13, Step: 825, Loss: 0.0940094143152237, Lr:0.0001\n",
      "Epoch 13, Step: 826, Loss: 0.23917613923549652, Lr:0.0001\n",
      "Epoch 13, Step: 827, Loss: 0.08571755141019821, Lr:0.0001\n",
      "Epoch 13, Step: 828, Loss: 0.10385879874229431, Lr:0.0001\n",
      "Epoch 13, Step: 829, Loss: 0.019240593537688255, Lr:0.0001\n",
      "Epoch 13, Step: 830, Loss: 0.056416042149066925, Lr:0.0001\n",
      "Epoch 13, Step: 831, Loss: 0.02619076706469059, Lr:0.0001\n",
      "Epoch 13, Step: 832, Loss: 0.008926480077207088, Lr:0.0001\n",
      "Epoch 13, Step: 833, Loss: 0.03817642480134964, Lr:0.0001\n",
      "Epoch 13, Step: 834, Loss: 0.2504844665527344, Lr:0.0001\n",
      "Epoch 13, Step: 835, Loss: 0.031237756833434105, Lr:0.0001\n",
      "Epoch 13, Step: 836, Loss: 0.011946308426558971, Lr:0.0001\n",
      "Epoch 13, Step: 837, Loss: 0.07159227132797241, Lr:0.0001\n",
      "Epoch 13, Step: 838, Loss: 0.16584211587905884, Lr:0.0001\n",
      "Epoch 13, Step: 839, Loss: 0.03001156821846962, Lr:0.0001\n",
      "Epoch 13, Step: 840, Loss: 0.12564079463481903, Lr:0.0001\n",
      "Epoch 13, Step: 841, Loss: 0.06131476163864136, Lr:0.0001\n",
      "Epoch 13, Step: 842, Loss: 0.15030038356781006, Lr:0.0001\n",
      "Epoch 13, Step: 843, Loss: 0.06136828660964966, Lr:0.0001\n",
      "Epoch 13, Step: 844, Loss: 0.049073249101638794, Lr:0.0001\n",
      "Epoch 13, Step: 845, Loss: 0.045709844678640366, Lr:0.0001\n",
      "Epoch 13, Step: 846, Loss: 0.13829390704631805, Lr:0.0001\n",
      "Epoch 13, Step: 847, Loss: 0.0009863385930657387, Lr:0.0001\n",
      "Epoch 13, Step: 848, Loss: 0.12549541890621185, Lr:0.0001\n",
      "Epoch 13, Step: 849, Loss: 0.10682830214500427, Lr:0.0001\n",
      "Epoch 13, Step: 850, Loss: 0.09346811473369598, Lr:0.0001\n",
      "Epoch 13, Step: 851, Loss: 0.05350205674767494, Lr:0.0001\n",
      "Epoch 13, Step: 852, Loss: 0.11016257852315903, Lr:0.0001\n",
      "Epoch 13, Step: 853, Loss: 0.06812553852796555, Lr:0.0001\n",
      "Epoch 13, Step: 854, Loss: 0.028400583192706108, Lr:0.0001\n",
      "Epoch 13, Step: 855, Loss: 0.033287789672613144, Lr:0.0001\n",
      "Epoch 13, Step: 856, Loss: 0.1332881599664688, Lr:0.0001\n",
      "Epoch 13, Step: 857, Loss: 0.172102153301239, Lr:0.0001\n",
      "Epoch 13, Step: 858, Loss: 0.3269948661327362, Lr:0.0001\n",
      "Epoch 13, Step: 859, Loss: 0.22297903895378113, Lr:0.0001\n",
      "Epoch 13, Step: 860, Loss: 0.12019523978233337, Lr:0.0001\n",
      "Epoch 13, Step: 861, Loss: 0.06891576945781708, Lr:0.0001\n",
      "Epoch 13, Step: 862, Loss: 0.10585050284862518, Lr:0.0001\n",
      "Epoch 13, Step: 863, Loss: 0.024874471127986908, Lr:0.0001\n",
      "Epoch 13, Step: 864, Loss: 0.18341387808322906, Lr:0.0001\n",
      "Epoch 13, Step: 865, Loss: 0.13726341724395752, Lr:0.0001\n",
      "Epoch 13, Step: 866, Loss: 0.15092971920967102, Lr:0.0001\n",
      "Epoch 13, Step: 867, Loss: 0.29688146710395813, Lr:0.0001\n",
      "Epoch 13, Step: 868, Loss: 0.03273145109415054, Lr:0.0001\n",
      "Epoch 13, Step: 869, Loss: 0.01810264214873314, Lr:0.0001\n",
      "Epoch 13, Step: 870, Loss: 0.10678329318761826, Lr:0.0001\n",
      "Epoch 13, Step: 871, Loss: 0.027609938755631447, Lr:0.0001\n",
      "Epoch 13, Step: 872, Loss: 0.004691429436206818, Lr:0.0001\n",
      "Epoch 13, Step: 873, Loss: 0.33354195952415466, Lr:0.0001\n",
      "Epoch 13, Step: 874, Loss: 0.0582108274102211, Lr:0.0001\n",
      "Epoch 13, Step: 875, Loss: 0.05594736337661743, Lr:0.0001\n",
      "Epoch 13, Step: 876, Loss: 0.04447772353887558, Lr:0.0001\n",
      "Epoch 13, Step: 877, Loss: 0.011086778715252876, Lr:0.0001\n",
      "Epoch 13, Step: 878, Loss: 0.012921875342726707, Lr:0.0001\n",
      "Epoch 13, Step: 879, Loss: 0.45340341329574585, Lr:0.0001\n",
      "Epoch 13, Step: 880, Loss: 0.02254505828022957, Lr:0.0001\n",
      "Epoch 13, Step: 881, Loss: 0.0912892073392868, Lr:0.0001\n",
      "Epoch 13, Step: 882, Loss: 0.06417006999254227, Lr:0.0001\n",
      "Epoch 13, Step: 883, Loss: 0.22636854648590088, Lr:0.0001\n",
      "Epoch 13, Step: 884, Loss: 0.11106646806001663, Lr:0.0001\n",
      "Epoch 13, Step: 885, Loss: 0.030380578711628914, Lr:0.0001\n",
      "Epoch 13, Step: 886, Loss: 0.0984850525856018, Lr:0.0001\n",
      "Epoch 13, Step: 887, Loss: 0.04343375191092491, Lr:0.0001\n",
      "Epoch 13, Step: 888, Loss: 0.11374320834875107, Lr:0.0001\n",
      "Epoch 13, Step: 889, Loss: 0.08089295029640198, Lr:0.0001\n",
      "Epoch 13, Step: 890, Loss: 0.1132764145731926, Lr:0.0001\n",
      "Epoch 13, Step: 891, Loss: 0.14016103744506836, Lr:0.0001\n",
      "Epoch 13, Step: 892, Loss: 0.04709772393107414, Lr:0.0001\n",
      "Epoch 13, Step: 893, Loss: 0.18166911602020264, Lr:0.0001\n",
      "Epoch 13, Step: 894, Loss: 0.010064829140901566, Lr:0.0001\n",
      "Epoch 13, Step: 895, Loss: 0.010056485421955585, Lr:0.0001\n",
      "Epoch 13, Step: 896, Loss: 0.013925415463745594, Lr:0.0001\n",
      "Epoch 13, Step: 897, Loss: 0.054646801203489304, Lr:0.0001\n",
      "Epoch 13, Step: 898, Loss: 0.11046148091554642, Lr:0.0001\n",
      "Epoch 13, Step: 899, Loss: 0.10947547852993011, Lr:0.0001\n",
      "Epoch 13, Step: 900, Loss: 0.027766751125454903, Lr:0.0001\n",
      "Epoch 13, Step: 901, Loss: 0.09087217599153519, Lr:0.0001\n",
      "Epoch 13, Step: 902, Loss: 0.0324305035173893, Lr:0.0001\n",
      "Epoch 13, Step: 903, Loss: 0.02566635236144066, Lr:0.0001\n",
      "Epoch 13, Step: 904, Loss: 0.07512308657169342, Lr:0.0001\n",
      "Epoch 13, Step: 905, Loss: 0.023579290136694908, Lr:0.0001\n",
      "Epoch 13, Step: 906, Loss: 0.23595960438251495, Lr:0.0001\n",
      "Epoch 13, Step: 907, Loss: 0.01090523973107338, Lr:0.0001\n",
      "Epoch 13, Step: 908, Loss: 0.08866790682077408, Lr:0.0001\n",
      "Epoch 13, Step: 909, Loss: 0.22038429975509644, Lr:0.0001\n",
      "Epoch 13, Step: 910, Loss: 0.10469059646129608, Lr:0.0001\n",
      "Epoch 13, Step: 911, Loss: 0.18525685369968414, Lr:0.0001\n",
      "Epoch 13, Step: 912, Loss: 0.04280879721045494, Lr:0.0001\n",
      "Epoch 13, Step: 913, Loss: 0.029278641566634178, Lr:0.0001\n",
      "Epoch 13, Step: 914, Loss: 0.05552595108747482, Lr:0.0001\n",
      "Epoch 13, Step: 915, Loss: 0.03996226564049721, Lr:0.0001\n",
      "Epoch 13, Step: 916, Loss: 0.011269149370491505, Lr:0.0001\n",
      "Epoch 13, Step: 917, Loss: 0.06315521895885468, Lr:0.0001\n",
      "Epoch 13, Step: 918, Loss: 0.1943918913602829, Lr:0.0001\n",
      "Epoch 13, Step: 919, Loss: 0.17031458020210266, Lr:0.0001\n",
      "Epoch 13, Step: 920, Loss: 0.3427700400352478, Lr:0.0001\n",
      "Epoch 13, Step: 921, Loss: 0.16508537530899048, Lr:0.0001\n",
      "Epoch 13, Step: 922, Loss: 0.026185300201177597, Lr:0.0001\n",
      "Epoch 13, Step: 923, Loss: 0.010118664242327213, Lr:0.0001\n",
      "Epoch 13, Step: 924, Loss: 0.21647045016288757, Lr:0.0001\n",
      "Epoch 13, Step: 925, Loss: 0.06904635578393936, Lr:0.0001\n",
      "Epoch 13, Step: 926, Loss: 0.03961305320262909, Lr:0.0001\n",
      "Epoch 13, Step: 927, Loss: 0.15307393670082092, Lr:0.0001\n",
      "Epoch 13, Step: 928, Loss: 0.2144477665424347, Lr:0.0001\n",
      "Epoch 13, Step: 929, Loss: 0.03393149375915527, Lr:0.0001\n",
      "Epoch 13, Step: 930, Loss: 0.08423818647861481, Lr:0.0001\n",
      "Epoch 13, Step: 931, Loss: 0.01582248881459236, Lr:0.0001\n",
      "Epoch 13, Step: 932, Loss: 0.32379400730133057, Lr:0.0001\n",
      "Epoch 13, Step: 933, Loss: 0.08445834368467331, Lr:0.0001\n",
      "Epoch 13, Step: 934, Loss: 0.038705937564373016, Lr:0.0001\n",
      "Epoch 13, Step: 935, Loss: 0.07896997034549713, Lr:0.0001\n",
      "Epoch 13, Step: 936, Loss: 0.04429938644170761, Lr:0.0001\n",
      "Epoch 13, Step: 937, Loss: 0.11530802398920059, Lr:0.0001\n",
      "Epoch 13, Step: 938, Loss: 0.07025627791881561, Lr:0.0001\n",
      "Epoch 13, Step: 939, Loss: 0.03199481591582298, Lr:0.0001\n",
      "Epoch 13, Step: 940, Loss: 0.35451462864875793, Lr:0.0001\n",
      "Epoch 13, Step: 941, Loss: 0.14075365662574768, Lr:0.0001\n",
      "Epoch 13, Step: 942, Loss: 0.05430512875318527, Lr:0.0001\n",
      "Epoch 13, Step: 943, Loss: 0.017310185357928276, Lr:0.0001\n",
      "Epoch 13, Step: 944, Loss: 0.014413452707231045, Lr:0.0001\n",
      "Epoch 13, Step: 945, Loss: 0.1441279798746109, Lr:0.0001\n",
      "Epoch 13, Step: 946, Loss: 0.09754469990730286, Lr:0.0001\n",
      "Epoch 13, Step: 947, Loss: 0.01846275106072426, Lr:0.0001\n",
      "Epoch 13, Step: 948, Loss: 0.025698868557810783, Lr:0.0001\n",
      "Epoch 13, Step: 949, Loss: 0.05264197662472725, Lr:0.0001\n",
      "Epoch 13, Step: 950, Loss: 0.268498033285141, Lr:0.0001\n",
      "Epoch 13, Step: 951, Loss: 0.11691096425056458, Lr:0.0001\n",
      "Epoch 13, Step: 952, Loss: 0.0990908145904541, Lr:0.0001\n",
      "Epoch 13, Step: 953, Loss: 0.04579731076955795, Lr:0.0001\n",
      "Epoch 13, Step: 954, Loss: 0.11278689652681351, Lr:0.0001\n",
      "Epoch 13, Step: 955, Loss: 0.0637454241514206, Lr:0.0001\n",
      "Epoch 13, Step: 956, Loss: 0.13492663204669952, Lr:0.0001\n",
      "Epoch 13, Step: 957, Loss: 0.09969150274991989, Lr:0.0001\n",
      "Epoch 13, Step: 958, Loss: 0.153118297457695, Lr:0.0001\n",
      "Epoch 13, Step: 959, Loss: 0.03934810683131218, Lr:0.0001\n",
      "Epoch 13, Step: 960, Loss: 0.016198724508285522, Lr:0.0001\n",
      "Epoch 13, Step: 961, Loss: 0.07110778242349625, Lr:0.0001\n",
      "Epoch 13, Step: 962, Loss: 0.08882418274879456, Lr:0.0001\n",
      "Epoch 13, Step: 963, Loss: 0.0772404670715332, Lr:0.0001\n",
      "Epoch 13, Step: 964, Loss: 0.035349391400814056, Lr:0.0001\n",
      "Epoch 13, Step: 965, Loss: 0.46476155519485474, Lr:0.0001\n",
      "Epoch 13, Step: 966, Loss: 0.0206785649061203, Lr:0.0001\n",
      "Epoch 13, Step: 967, Loss: 0.08702246844768524, Lr:0.0001\n",
      "Epoch 13, Step: 968, Loss: 0.1592543125152588, Lr:0.0001\n",
      "Epoch 13, Step: 969, Loss: 0.11219616234302521, Lr:0.0001\n",
      "Epoch 13, Step: 970, Loss: 0.00969799142330885, Lr:0.0001\n",
      "Epoch 13, Step: 971, Loss: 0.0314052514731884, Lr:0.0001\n",
      "Epoch 13, Step: 972, Loss: 0.10163566470146179, Lr:0.0001\n",
      "Epoch 13, Step: 973, Loss: 0.2821348309516907, Lr:0.0001\n",
      "Epoch 13, Step: 974, Loss: 0.01632782258093357, Lr:0.0001\n",
      "Epoch 13, Step: 975, Loss: 0.01466476358473301, Lr:0.0001\n",
      "Epoch 13, Step: 976, Loss: 0.0912788063287735, Lr:0.0001\n",
      "Epoch 13, Step: 977, Loss: 0.07723525911569595, Lr:0.0001\n",
      "Epoch 13, Step: 978, Loss: 0.08609876781702042, Lr:0.0001\n",
      "Epoch 13, Step: 979, Loss: 0.10621770471334457, Lr:0.0001\n",
      "Epoch 13, Step: 980, Loss: 0.17621956765651703, Lr:0.0001\n",
      "Epoch 13, Step: 981, Loss: 0.20688042044639587, Lr:0.0001\n",
      "Epoch 13, Step: 982, Loss: 0.06516304612159729, Lr:0.0001\n",
      "Epoch 13, Step: 983, Loss: 0.183762788772583, Lr:0.0001\n",
      "Epoch 13, Step: 984, Loss: 0.08191879838705063, Lr:0.0001\n",
      "Epoch 13, Step: 985, Loss: 0.10825716704130173, Lr:0.0001\n",
      "Epoch 13, Step: 986, Loss: 0.16541144251823425, Lr:0.0001\n",
      "Epoch 13, Step: 987, Loss: 0.06345722079277039, Lr:0.0001\n",
      "Epoch 13, Step: 988, Loss: 0.03743951767683029, Lr:0.0001\n",
      "Epoch 13, Step: 989, Loss: 0.6454663276672363, Lr:0.0001\n",
      "Epoch 13, Step: 990, Loss: 0.04610959440469742, Lr:0.0001\n",
      "Epoch 13, Step: 991, Loss: 0.1902780383825302, Lr:0.0001\n",
      "Epoch 13, Step: 992, Loss: 0.0904681384563446, Lr:0.0001\n",
      "Epoch 13, Step: 993, Loss: 0.11872158944606781, Lr:0.0001\n",
      "Epoch 13, Step: 994, Loss: 0.14120393991470337, Lr:0.0001\n",
      "Epoch 13, Step: 995, Loss: 0.025755908340215683, Lr:0.0001\n",
      "Epoch 13, Step: 996, Loss: 0.12442634254693985, Lr:0.0001\n",
      "Epoch 13, Step: 997, Loss: 0.01671084202826023, Lr:0.0001\n",
      "Epoch 13, Step: 998, Loss: 0.08874054998159409, Lr:0.0001\n",
      "Epoch 13, Step: 999, Loss: 0.020180240273475647, Lr:0.0001\n",
      "Epoch 13, Step: 1000, Loss: 0.2336910218000412, Lr:0.0001\n",
      "Epoch 13, Step: 1001, Loss: 0.26992368698120117, Lr:0.0001\n",
      "Epoch 13, Step: 1002, Loss: 0.10860069841146469, Lr:0.0001\n",
      "Epoch 13, Step: 1003, Loss: 0.2789742648601532, Lr:0.0001\n",
      "Epoch 13, Step: 1004, Loss: 0.15160708129405975, Lr:0.0001\n",
      "Epoch 13, Step: 1005, Loss: 0.07803212106227875, Lr:0.0001\n",
      "Epoch 13, Step: 1006, Loss: 0.28222087025642395, Lr:0.0001\n",
      "Epoch 13, Step: 1007, Loss: 0.12005392462015152, Lr:0.0001\n",
      "Epoch 13, Step: 1008, Loss: 0.03491972014307976, Lr:0.0001\n",
      "Epoch 13, Step: 1009, Loss: 0.06134483963251114, Lr:0.0001\n",
      "Epoch 13, Step: 1010, Loss: 0.22927123308181763, Lr:0.0001\n",
      "Epoch 13, Step: 1011, Loss: 0.018608056008815765, Lr:0.0001\n",
      "Epoch 13, Step: 1012, Loss: 0.03405557945370674, Lr:0.0001\n",
      "Epoch 13, Step: 1013, Loss: 0.013616783544421196, Lr:0.0001\n",
      "Epoch 13, Step: 1014, Loss: 0.03626274690032005, Lr:0.0001\n",
      "Epoch 13, Step: 1015, Loss: 0.16953010857105255, Lr:0.0001\n",
      "Epoch 13, Step: 1016, Loss: 0.3524204194545746, Lr:0.0001\n",
      "Epoch 13, Step: 1017, Loss: 0.0875236988067627, Lr:0.0001\n",
      "Epoch 13, Step: 1018, Loss: 0.058731675148010254, Lr:0.0001\n",
      "Epoch 13, Step: 1019, Loss: 0.09777401387691498, Lr:0.0001\n",
      "Epoch 13, Step: 1020, Loss: 0.16353167593479156, Lr:0.0001\n",
      "Epoch 13, Step: 1021, Loss: 0.13423436880111694, Lr:0.0001\n",
      "Epoch 13, Step: 1022, Loss: 0.1452597677707672, Lr:0.0001\n",
      "Epoch 13, Step: 1023, Loss: 0.06705138832330704, Lr:0.0001\n",
      "Epoch 13, Step: 1024, Loss: 0.09861700981855392, Lr:0.0001\n",
      "Epoch 13, Step: 1025, Loss: 0.06737815588712692, Lr:0.0001\n",
      "Epoch 13, Step: 1026, Loss: 0.06289567053318024, Lr:0.0001\n",
      "Epoch 13, Step: 1027, Loss: 0.0336989089846611, Lr:0.0001\n",
      "Epoch 13, Step: 1028, Loss: 0.021828128024935722, Lr:0.0001\n",
      "Epoch 13, Step: 1029, Loss: 0.016479648649692535, Lr:0.0001\n",
      "Epoch 13, Step: 1030, Loss: 0.07812095433473587, Lr:0.0001\n",
      "Epoch 13, Step: 1031, Loss: 0.04987282305955887, Lr:0.0001\n",
      "Epoch 13, Step: 1032, Loss: 0.020738329738378525, Lr:0.0001\n",
      "Epoch 13, Step: 1033, Loss: 0.10719643533229828, Lr:0.0001\n",
      "Epoch 13, Step: 1034, Loss: 0.05475920811295509, Lr:0.0001\n",
      "Epoch 13, Step: 1035, Loss: 0.015147719532251358, Lr:0.0001\n",
      "Epoch 13, Step: 1036, Loss: 0.16590265929698944, Lr:0.0001\n",
      "Epoch 13, Step: 1037, Loss: 0.018650900572538376, Lr:0.0001\n",
      "Epoch 13, Step: 1038, Loss: 0.11314301192760468, Lr:0.0001\n",
      "Epoch 13, Step: 1039, Loss: 0.019900500774383545, Lr:0.0001\n",
      "Epoch 13, Step: 1040, Loss: 0.01195408683270216, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 13\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:16 loss: 0.6648 (0.6648) acc1: 87.5000 (87.5000) acc5: 100.0000 (100.0000) time: 0.3000 data: 0.1260 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.0007 (0.0678) acc1: 100.0000 (98.8636) acc5: 100.0000 (100.0000) time: 0.2853 data: 0.1115 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0031 (0.0627) acc1: 100.0000 (98.8095) acc5: 100.0000 (100.0000) time: 0.2828 data: 0.1097 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.0604 (0.2488) acc1: 93.7500 (93.7500) acc5: 100.0000 (100.0000) time: 0.2855 data: 0.1111 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.1771 (0.2488) acc1: 93.7500 (93.7500) acc5: 100.0000 (100.0000) time: 0.2891 data: 0.1141 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0192 (0.2276) acc1: 93.7500 (94.1176) acc5: 100.0000 (100.0000) time: 0.2905 data: 0.1149 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0064 (0.2137) acc1: 100.0000 (94.3246) acc5: 100.0000 (100.0000) time: 0.2778 data: 0.1086 max mem: 15137\n",
      "Test: Total time: 0:00:15 (0.2832 s / it)\n",
      "* Acc@1 94.325 Acc@5 100.000 loss 0.214\n",
      "Accuracy of the network on the 881 test image: 94.3%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 14, Step: 0, Loss: 0.40301498770713806, Lr:0.0001\n",
      "Epoch 14, Step: 1, Loss: 0.012593830935657024, Lr:0.0001\n",
      "Epoch 14, Step: 2, Loss: 0.2737963795661926, Lr:0.0001\n",
      "Epoch 14, Step: 3, Loss: 0.2046021819114685, Lr:0.0001\n",
      "Epoch 14, Step: 4, Loss: 0.054705433547496796, Lr:0.0001\n",
      "Epoch 14, Step: 5, Loss: 0.043271254748106, Lr:0.0001\n",
      "Epoch 14, Step: 6, Loss: 0.01905781775712967, Lr:0.0001\n",
      "Epoch 14, Step: 7, Loss: 0.0582413375377655, Lr:0.0001\n",
      "Epoch 14, Step: 8, Loss: 0.012182928621768951, Lr:0.0001\n",
      "Epoch 14, Step: 9, Loss: 0.24346521496772766, Lr:0.0001\n",
      "Epoch 14, Step: 10, Loss: 0.07096191495656967, Lr:0.0001\n",
      "Epoch 14, Step: 11, Loss: 0.020191457122564316, Lr:0.0001\n",
      "Epoch 14, Step: 12, Loss: 0.06505581736564636, Lr:0.0001\n",
      "Epoch 14, Step: 13, Loss: 0.792985200881958, Lr:0.0001\n",
      "Epoch 14, Step: 14, Loss: 0.20828332006931305, Lr:0.0001\n",
      "Epoch 14, Step: 15, Loss: 0.01312917098402977, Lr:0.0001\n",
      "Epoch 14, Step: 16, Loss: 0.034683793783187866, Lr:0.0001\n",
      "Epoch 14, Step: 17, Loss: 0.08675863593816757, Lr:0.0001\n",
      "Epoch 14, Step: 18, Loss: 0.23005777597427368, Lr:0.0001\n",
      "Epoch 14, Step: 19, Loss: 0.012067519128322601, Lr:0.0001\n",
      "Epoch 14, Step: 20, Loss: 0.10421793907880783, Lr:0.0001\n",
      "Epoch 14, Step: 21, Loss: 0.010637291707098484, Lr:0.0001\n",
      "Epoch 14, Step: 22, Loss: 0.07422254234552383, Lr:0.0001\n",
      "Epoch 14, Step: 23, Loss: 0.08114158362150192, Lr:0.0001\n",
      "Epoch 14, Step: 24, Loss: 0.04826978221535683, Lr:0.0001\n",
      "Epoch 14, Step: 25, Loss: 0.023446880280971527, Lr:0.0001\n",
      "Epoch 14, Step: 26, Loss: 0.03992048650979996, Lr:0.0001\n",
      "Epoch 14, Step: 27, Loss: 0.14529462158679962, Lr:0.0001\n",
      "Epoch 14, Step: 28, Loss: 0.1757713407278061, Lr:0.0001\n",
      "Epoch 14, Step: 29, Loss: 0.10592824965715408, Lr:0.0001\n",
      "Epoch 14, Step: 30, Loss: 0.017291437834501266, Lr:0.0001\n",
      "Epoch 14, Step: 31, Loss: 0.08624068647623062, Lr:0.0001\n",
      "Epoch 14, Step: 32, Loss: 0.4139542877674103, Lr:0.0001\n",
      "Epoch 14, Step: 33, Loss: 0.03339933231472969, Lr:0.0001\n",
      "Epoch 14, Step: 34, Loss: 0.04417328163981438, Lr:0.0001\n",
      "Epoch 14, Step: 35, Loss: 0.542881190776825, Lr:0.0001\n",
      "Epoch 14, Step: 36, Loss: 0.2148376703262329, Lr:0.0001\n",
      "Epoch 14, Step: 37, Loss: 0.12691223621368408, Lr:0.0001\n",
      "Epoch 14, Step: 38, Loss: 0.07010110467672348, Lr:0.0001\n",
      "Epoch 14, Step: 39, Loss: 0.28144797682762146, Lr:0.0001\n",
      "Epoch 14, Step: 40, Loss: 0.04458288848400116, Lr:0.0001\n",
      "Epoch 14, Step: 41, Loss: 0.2783929705619812, Lr:0.0001\n",
      "Epoch 14, Step: 42, Loss: 0.022260937839746475, Lr:0.0001\n",
      "Epoch 14, Step: 43, Loss: 0.011477150022983551, Lr:0.0001\n",
      "Epoch 14, Step: 44, Loss: 0.07322653383016586, Lr:0.0001\n",
      "Epoch 14, Step: 45, Loss: 0.20974525809288025, Lr:0.0001\n",
      "Epoch 14, Step: 46, Loss: 0.027743114158511162, Lr:0.0001\n",
      "Epoch 14, Step: 47, Loss: 0.2573714256286621, Lr:0.0001\n",
      "Epoch 14, Step: 48, Loss: 0.055613309144973755, Lr:0.0001\n",
      "Epoch 14, Step: 49, Loss: 0.045954398810863495, Lr:0.0001\n",
      "Epoch 14, Step: 50, Loss: 0.050101909786462784, Lr:0.0001\n",
      "Epoch 14, Step: 51, Loss: 0.057160504162311554, Lr:0.0001\n",
      "Epoch 14, Step: 52, Loss: 0.008884044364094734, Lr:0.0001\n",
      "Epoch 14, Step: 53, Loss: 0.16523386538028717, Lr:0.0001\n",
      "Epoch 14, Step: 54, Loss: 0.09589258581399918, Lr:0.0001\n",
      "Epoch 14, Step: 55, Loss: 0.006655471865087748, Lr:0.0001\n",
      "Epoch 14, Step: 56, Loss: 0.21227067708969116, Lr:0.0001\n",
      "Epoch 14, Step: 57, Loss: 0.0704711303114891, Lr:0.0001\n",
      "Epoch 14, Step: 58, Loss: 0.007469212636351585, Lr:0.0001\n",
      "Epoch 14, Step: 59, Loss: 0.1237988993525505, Lr:0.0001\n",
      "Epoch 14, Step: 60, Loss: 0.2100575715303421, Lr:0.0001\n",
      "Epoch 14, Step: 61, Loss: 0.09872300177812576, Lr:0.0001\n",
      "Epoch 14, Step: 62, Loss: 0.007056610193103552, Lr:0.0001\n",
      "Epoch 14, Step: 63, Loss: 0.0842769667506218, Lr:0.0001\n",
      "Epoch 14, Step: 64, Loss: 0.3037804961204529, Lr:0.0001\n",
      "Epoch 14, Step: 65, Loss: 0.07853922247886658, Lr:0.0001\n",
      "Epoch 14, Step: 66, Loss: 0.025215597823262215, Lr:0.0001\n",
      "Epoch 14, Step: 67, Loss: 0.043691348284482956, Lr:0.0001\n",
      "Epoch 14, Step: 68, Loss: 0.09968391060829163, Lr:0.0001\n",
      "Epoch 14, Step: 69, Loss: 0.036056894809007645, Lr:0.0001\n",
      "Epoch 14, Step: 70, Loss: 0.08603888005018234, Lr:0.0001\n",
      "Epoch 14, Step: 71, Loss: 0.1171920970082283, Lr:0.0001\n",
      "Epoch 14, Step: 72, Loss: 0.12079570442438126, Lr:0.0001\n",
      "Epoch 14, Step: 73, Loss: 0.06403898447751999, Lr:0.0001\n",
      "Epoch 14, Step: 74, Loss: 0.1072707325220108, Lr:0.0001\n",
      "Epoch 14, Step: 75, Loss: 0.20644277334213257, Lr:0.0001\n",
      "Epoch 14, Step: 76, Loss: 0.013535473495721817, Lr:0.0001\n",
      "Epoch 14, Step: 77, Loss: 0.37738892436027527, Lr:0.0001\n",
      "Epoch 14, Step: 78, Loss: 0.051671598106622696, Lr:0.0001\n",
      "Epoch 14, Step: 79, Loss: 0.031331371515989304, Lr:0.0001\n",
      "Epoch 14, Step: 80, Loss: 0.042093537747859955, Lr:0.0001\n",
      "Epoch 14, Step: 81, Loss: 0.13676832616329193, Lr:0.0001\n",
      "Epoch 14, Step: 82, Loss: 0.049313224852085114, Lr:0.0001\n",
      "Epoch 14, Step: 83, Loss: 0.07420939207077026, Lr:0.0001\n",
      "Epoch 14, Step: 84, Loss: 0.05773364380002022, Lr:0.0001\n",
      "Epoch 14, Step: 85, Loss: 0.017599282786250114, Lr:0.0001\n",
      "Epoch 14, Step: 86, Loss: 0.017780045047402382, Lr:0.0001\n",
      "Epoch 14, Step: 87, Loss: 0.0014560841955244541, Lr:0.0001\n",
      "Epoch 14, Step: 88, Loss: 0.1596754640340805, Lr:0.0001\n",
      "Epoch 14, Step: 89, Loss: 0.2281958907842636, Lr:0.0001\n",
      "Epoch 14, Step: 90, Loss: 0.02903713472187519, Lr:0.0001\n",
      "Epoch 14, Step: 91, Loss: 0.13240040838718414, Lr:0.0001\n",
      "Epoch 14, Step: 92, Loss: 0.1256888061761856, Lr:0.0001\n",
      "Epoch 14, Step: 93, Loss: 0.13815969228744507, Lr:0.0001\n",
      "Epoch 14, Step: 94, Loss: 0.3455452620983124, Lr:0.0001\n",
      "Epoch 14, Step: 95, Loss: 0.29245030879974365, Lr:0.0001\n",
      "Epoch 14, Step: 96, Loss: 0.01984778605401516, Lr:0.0001\n",
      "Epoch 14, Step: 97, Loss: 0.02613440901041031, Lr:0.0001\n",
      "Epoch 14, Step: 98, Loss: 0.08681560307741165, Lr:0.0001\n",
      "Epoch 14, Step: 99, Loss: 0.19175076484680176, Lr:0.0001\n",
      "Epoch 14, Step: 100, Loss: 0.37395724654197693, Lr:0.0001\n",
      "Epoch 14, Step: 101, Loss: 0.038000743836164474, Lr:0.0001\n",
      "Epoch 14, Step: 102, Loss: 0.05877671763300896, Lr:0.0001\n",
      "Epoch 14, Step: 103, Loss: 0.0408473014831543, Lr:0.0001\n",
      "Epoch 14, Step: 104, Loss: 0.24631564319133759, Lr:0.0001\n",
      "Epoch 14, Step: 105, Loss: 0.03157627582550049, Lr:0.0001\n",
      "Epoch 14, Step: 106, Loss: 0.19136419892311096, Lr:0.0001\n",
      "Epoch 14, Step: 107, Loss: 0.2898079454898834, Lr:0.0001\n",
      "Epoch 14, Step: 108, Loss: 0.08055774867534637, Lr:0.0001\n",
      "Epoch 14, Step: 109, Loss: 0.026976168155670166, Lr:0.0001\n",
      "Epoch 14, Step: 110, Loss: 0.13003873825073242, Lr:0.0001\n",
      "Epoch 14, Step: 111, Loss: 0.12116989493370056, Lr:0.0001\n",
      "Epoch 14, Step: 112, Loss: 0.09071182459592819, Lr:0.0001\n",
      "Epoch 14, Step: 113, Loss: 0.11837150901556015, Lr:0.0001\n",
      "Epoch 14, Step: 114, Loss: 0.27720609307289124, Lr:0.0001\n",
      "Epoch 14, Step: 115, Loss: 0.08610903471708298, Lr:0.0001\n",
      "Epoch 14, Step: 116, Loss: 0.010688490234315395, Lr:0.0001\n",
      "Epoch 14, Step: 117, Loss: 0.19266091287136078, Lr:0.0001\n",
      "Epoch 14, Step: 118, Loss: 0.06691954284906387, Lr:0.0001\n",
      "Epoch 14, Step: 119, Loss: 0.04351497069001198, Lr:0.0001\n",
      "Epoch 14, Step: 120, Loss: 0.18138684332370758, Lr:0.0001\n",
      "Epoch 14, Step: 121, Loss: 0.010034612379968166, Lr:0.0001\n",
      "Epoch 14, Step: 122, Loss: 0.04275891184806824, Lr:0.0001\n",
      "Epoch 14, Step: 123, Loss: 0.29414820671081543, Lr:0.0001\n",
      "Epoch 14, Step: 124, Loss: 0.0485718660056591, Lr:0.0001\n",
      "Epoch 14, Step: 125, Loss: 0.20545409619808197, Lr:0.0001\n",
      "Epoch 14, Step: 126, Loss: 0.10187562555074692, Lr:0.0001\n",
      "Epoch 14, Step: 127, Loss: 0.33696234226226807, Lr:0.0001\n",
      "Epoch 14, Step: 128, Loss: 0.017136961221694946, Lr:0.0001\n",
      "Epoch 14, Step: 129, Loss: 0.03191816806793213, Lr:0.0001\n",
      "Epoch 14, Step: 130, Loss: 0.06408751755952835, Lr:0.0001\n",
      "Epoch 14, Step: 131, Loss: 0.4053049087524414, Lr:0.0001\n",
      "Epoch 14, Step: 132, Loss: 0.20865096151828766, Lr:0.0001\n",
      "Epoch 14, Step: 133, Loss: 0.11620703339576721, Lr:0.0001\n",
      "Epoch 14, Step: 134, Loss: 0.07469942420721054, Lr:0.0001\n",
      "Epoch 14, Step: 135, Loss: 0.3785306513309479, Lr:0.0001\n",
      "Epoch 14, Step: 136, Loss: 0.09816722571849823, Lr:0.0001\n",
      "Epoch 14, Step: 137, Loss: 0.037722501903772354, Lr:0.0001\n",
      "Epoch 14, Step: 138, Loss: 0.08211922645568848, Lr:0.0001\n",
      "Epoch 14, Step: 139, Loss: 0.02560063824057579, Lr:0.0001\n",
      "Epoch 14, Step: 140, Loss: 0.06237867847084999, Lr:0.0001\n",
      "Epoch 14, Step: 141, Loss: 0.20600824058055878, Lr:0.0001\n",
      "Epoch 14, Step: 142, Loss: 0.13287921249866486, Lr:0.0001\n",
      "Epoch 14, Step: 143, Loss: 0.031230542808771133, Lr:0.0001\n",
      "Epoch 14, Step: 144, Loss: 0.21669873595237732, Lr:0.0001\n",
      "Epoch 14, Step: 145, Loss: 0.02580718882381916, Lr:0.0001\n",
      "Epoch 14, Step: 146, Loss: 0.07980754226446152, Lr:0.0001\n",
      "Epoch 14, Step: 147, Loss: 0.09955403953790665, Lr:0.0001\n",
      "Epoch 14, Step: 148, Loss: 0.026303045451641083, Lr:0.0001\n",
      "Epoch 14, Step: 149, Loss: 0.0217023566365242, Lr:0.0001\n",
      "Epoch 14, Step: 150, Loss: 0.06071443855762482, Lr:0.0001\n",
      "Epoch 14, Step: 151, Loss: 0.07651657611131668, Lr:0.0001\n",
      "Epoch 14, Step: 152, Loss: 0.162554532289505, Lr:0.0001\n",
      "Epoch 14, Step: 153, Loss: 0.07265935093164444, Lr:0.0001\n",
      "Epoch 14, Step: 154, Loss: 0.0772547498345375, Lr:0.0001\n",
      "Epoch 14, Step: 155, Loss: 0.12722912430763245, Lr:0.0001\n",
      "Epoch 14, Step: 156, Loss: 0.08822261542081833, Lr:0.0001\n",
      "Epoch 14, Step: 157, Loss: 0.26151877641677856, Lr:0.0001\n",
      "Epoch 14, Step: 158, Loss: 0.011042999103665352, Lr:0.0001\n",
      "Epoch 14, Step: 159, Loss: 0.40075749158859253, Lr:0.0001\n",
      "Epoch 14, Step: 160, Loss: 0.09339076280593872, Lr:0.0001\n",
      "Epoch 14, Step: 161, Loss: 0.04969872534275055, Lr:0.0001\n",
      "Epoch 14, Step: 162, Loss: 0.04790475219488144, Lr:0.0001\n",
      "Epoch 14, Step: 163, Loss: 0.0845235139131546, Lr:0.0001\n",
      "Epoch 14, Step: 164, Loss: 0.08153293281793594, Lr:0.0001\n",
      "Epoch 14, Step: 165, Loss: 0.08162680268287659, Lr:0.0001\n",
      "Epoch 14, Step: 166, Loss: 0.040604930371046066, Lr:0.0001\n",
      "Epoch 14, Step: 167, Loss: 0.008482284843921661, Lr:0.0001\n",
      "Epoch 14, Step: 168, Loss: 0.15833400189876556, Lr:0.0001\n",
      "Epoch 14, Step: 169, Loss: 0.3291394114494324, Lr:0.0001\n",
      "Epoch 14, Step: 170, Loss: 0.21697670221328735, Lr:0.0001\n",
      "Epoch 14, Step: 171, Loss: 0.007228224538266659, Lr:0.0001\n",
      "Epoch 14, Step: 172, Loss: 0.07672938704490662, Lr:0.0001\n",
      "Epoch 14, Step: 173, Loss: 0.04324762150645256, Lr:0.0001\n",
      "Epoch 14, Step: 174, Loss: 0.06759801506996155, Lr:0.0001\n",
      "Epoch 14, Step: 175, Loss: 0.08201532810926437, Lr:0.0001\n",
      "Epoch 14, Step: 176, Loss: 0.005774020683020353, Lr:0.0001\n",
      "Epoch 14, Step: 177, Loss: 0.21694590151309967, Lr:0.0001\n",
      "Epoch 14, Step: 178, Loss: 0.3694365918636322, Lr:0.0001\n",
      "Epoch 14, Step: 179, Loss: 0.0830741748213768, Lr:0.0001\n",
      "Epoch 14, Step: 180, Loss: 0.025188952684402466, Lr:0.0001\n",
      "Epoch 14, Step: 181, Loss: 0.08374934643507004, Lr:0.0001\n",
      "Epoch 14, Step: 182, Loss: 0.020516887307167053, Lr:0.0001\n",
      "Epoch 14, Step: 183, Loss: 0.0629906952381134, Lr:0.0001\n",
      "Epoch 14, Step: 184, Loss: 0.0687502771615982, Lr:0.0001\n",
      "Epoch 14, Step: 185, Loss: 0.1094113290309906, Lr:0.0001\n",
      "Epoch 14, Step: 186, Loss: 0.10804791003465652, Lr:0.0001\n",
      "Epoch 14, Step: 187, Loss: 0.07415920495986938, Lr:0.0001\n",
      "Epoch 14, Step: 188, Loss: 0.034876033663749695, Lr:0.0001\n",
      "Epoch 14, Step: 189, Loss: 0.007927271537482738, Lr:0.0001\n",
      "Epoch 14, Step: 190, Loss: 0.07523153722286224, Lr:0.0001\n",
      "Epoch 14, Step: 191, Loss: 0.011733630672097206, Lr:0.0001\n",
      "Epoch 14, Step: 192, Loss: 0.39338427782058716, Lr:0.0001\n",
      "Epoch 14, Step: 193, Loss: 0.10163265466690063, Lr:0.0001\n",
      "Epoch 14, Step: 194, Loss: 0.02185051515698433, Lr:0.0001\n",
      "Epoch 14, Step: 195, Loss: 0.3078863322734833, Lr:0.0001\n",
      "Epoch 14, Step: 196, Loss: 0.2344447821378708, Lr:0.0001\n",
      "Epoch 14, Step: 197, Loss: 0.012073852121829987, Lr:0.0001\n",
      "Epoch 14, Step: 198, Loss: 0.182447150349617, Lr:0.0001\n",
      "Epoch 14, Step: 199, Loss: 0.003638938767835498, Lr:0.0001\n",
      "Epoch 14, Step: 200, Loss: 0.23602017760276794, Lr:0.0001\n",
      "Epoch 14, Step: 201, Loss: 0.16144999861717224, Lr:0.0001\n",
      "Epoch 14, Step: 202, Loss: 0.0637301653623581, Lr:0.0001\n",
      "Epoch 14, Step: 203, Loss: 0.03268362209200859, Lr:0.0001\n",
      "Epoch 14, Step: 204, Loss: 0.0540451817214489, Lr:0.0001\n",
      "Epoch 14, Step: 205, Loss: 0.20374548435211182, Lr:0.0001\n",
      "Epoch 14, Step: 206, Loss: 0.14789827167987823, Lr:0.0001\n",
      "Epoch 14, Step: 207, Loss: 0.09951400011777878, Lr:0.0001\n",
      "Epoch 14, Step: 208, Loss: 0.3386853337287903, Lr:0.0001\n",
      "Epoch 14, Step: 209, Loss: 0.07919467985630035, Lr:0.0001\n",
      "Epoch 14, Step: 210, Loss: 0.5106157064437866, Lr:0.0001\n",
      "Epoch 14, Step: 211, Loss: 0.03771410509943962, Lr:0.0001\n",
      "Epoch 14, Step: 212, Loss: 0.07020308822393417, Lr:0.0001\n",
      "Epoch 14, Step: 213, Loss: 0.11607012897729874, Lr:0.0001\n",
      "Epoch 14, Step: 214, Loss: 0.11750546842813492, Lr:0.0001\n",
      "Epoch 14, Step: 215, Loss: 0.25021064281463623, Lr:0.0001\n",
      "Epoch 14, Step: 216, Loss: 0.12452336400747299, Lr:0.0001\n",
      "Epoch 14, Step: 217, Loss: 0.017165886238217354, Lr:0.0001\n",
      "Epoch 14, Step: 218, Loss: 0.013845653273165226, Lr:0.0001\n",
      "Epoch 14, Step: 219, Loss: 0.2027311772108078, Lr:0.0001\n",
      "Epoch 14, Step: 220, Loss: 0.1342230588197708, Lr:0.0001\n",
      "Epoch 14, Step: 221, Loss: 0.0444689504802227, Lr:0.0001\n",
      "Epoch 14, Step: 222, Loss: 0.15659689903259277, Lr:0.0001\n",
      "Epoch 14, Step: 223, Loss: 0.11133145540952682, Lr:0.0001\n",
      "Epoch 14, Step: 224, Loss: 0.09328307211399078, Lr:0.0001\n",
      "Epoch 14, Step: 225, Loss: 0.05383928120136261, Lr:0.0001\n",
      "Epoch 14, Step: 226, Loss: 0.12369510531425476, Lr:0.0001\n",
      "Epoch 14, Step: 227, Loss: 0.10469323396682739, Lr:0.0001\n",
      "Epoch 14, Step: 228, Loss: 0.05788839980959892, Lr:0.0001\n",
      "Epoch 14, Step: 229, Loss: 0.02449037879705429, Lr:0.0001\n",
      "Epoch 14, Step: 230, Loss: 0.03604787215590477, Lr:0.0001\n",
      "Epoch 14, Step: 231, Loss: 0.1417391449213028, Lr:0.0001\n",
      "Epoch 14, Step: 232, Loss: 0.04913293197751045, Lr:0.0001\n",
      "Epoch 14, Step: 233, Loss: 0.020602790638804436, Lr:0.0001\n",
      "Epoch 14, Step: 234, Loss: 0.16290220618247986, Lr:0.0001\n",
      "Epoch 14, Step: 235, Loss: 0.32518789172172546, Lr:0.0001\n",
      "Epoch 14, Step: 236, Loss: 0.014844435267150402, Lr:0.0001\n",
      "Epoch 14, Step: 237, Loss: 0.032720789313316345, Lr:0.0001\n",
      "Epoch 14, Step: 238, Loss: 0.06015932187438011, Lr:0.0001\n",
      "Epoch 14, Step: 239, Loss: 0.007503047119826078, Lr:0.0001\n",
      "Epoch 14, Step: 240, Loss: 0.06219632923603058, Lr:0.0001\n",
      "Epoch 14, Step: 241, Loss: 0.04371507465839386, Lr:0.0001\n",
      "Epoch 14, Step: 242, Loss: 0.04553249478340149, Lr:0.0001\n",
      "Epoch 14, Step: 243, Loss: 0.15829919278621674, Lr:0.0001\n",
      "Epoch 14, Step: 244, Loss: 0.06321950256824493, Lr:0.0001\n",
      "Epoch 14, Step: 245, Loss: 0.12051883339881897, Lr:0.0001\n",
      "Epoch 14, Step: 246, Loss: 0.06567759066820145, Lr:0.0001\n",
      "Epoch 14, Step: 247, Loss: 0.15655647218227386, Lr:0.0001\n",
      "Epoch 14, Step: 248, Loss: 0.06984163075685501, Lr:0.0001\n",
      "Epoch 14, Step: 249, Loss: 0.018697112798690796, Lr:0.0001\n",
      "Epoch 14, Step: 250, Loss: 0.03021218813955784, Lr:0.0001\n",
      "Epoch 14, Step: 251, Loss: 0.04123742878437042, Lr:0.0001\n",
      "Epoch 14, Step: 252, Loss: 0.02565426379442215, Lr:0.0001\n",
      "Epoch 14, Step: 253, Loss: 0.044784143567085266, Lr:0.0001\n",
      "Epoch 14, Step: 254, Loss: 0.23631267249584198, Lr:0.0001\n",
      "Epoch 14, Step: 255, Loss: 0.01425096858292818, Lr:0.0001\n",
      "Epoch 14, Step: 256, Loss: 0.25943148136138916, Lr:0.0001\n",
      "Epoch 14, Step: 257, Loss: 0.07934899628162384, Lr:0.0001\n",
      "Epoch 14, Step: 258, Loss: 0.07902348041534424, Lr:0.0001\n",
      "Epoch 14, Step: 259, Loss: 0.2338234931230545, Lr:0.0001\n",
      "Epoch 14, Step: 260, Loss: 0.20875057578086853, Lr:0.0001\n",
      "Epoch 14, Step: 261, Loss: 0.053532589226961136, Lr:0.0001\n",
      "Epoch 14, Step: 262, Loss: 0.14905156195163727, Lr:0.0001\n",
      "Epoch 14, Step: 263, Loss: 0.12242726236581802, Lr:0.0001\n",
      "Epoch 14, Step: 264, Loss: 0.0753202736377716, Lr:0.0001\n",
      "Epoch 14, Step: 265, Loss: 0.040519773960113525, Lr:0.0001\n",
      "Epoch 14, Step: 266, Loss: 0.04411284998059273, Lr:0.0001\n",
      "Epoch 14, Step: 267, Loss: 0.08123726397752762, Lr:0.0001\n",
      "Epoch 14, Step: 268, Loss: 0.027586160227656364, Lr:0.0001\n",
      "Epoch 14, Step: 269, Loss: 0.09571319073438644, Lr:0.0001\n",
      "Epoch 14, Step: 270, Loss: 0.15413996577262878, Lr:0.0001\n",
      "Epoch 14, Step: 271, Loss: 0.06560530513525009, Lr:0.0001\n",
      "Epoch 14, Step: 272, Loss: 0.015368224121630192, Lr:0.0001\n",
      "Epoch 14, Step: 273, Loss: 0.005344734527170658, Lr:0.0001\n",
      "Epoch 14, Step: 274, Loss: 0.04574853926897049, Lr:0.0001\n",
      "Epoch 14, Step: 275, Loss: 0.032559528946876526, Lr:0.0001\n",
      "Epoch 14, Step: 276, Loss: 0.22956770658493042, Lr:0.0001\n",
      "Epoch 14, Step: 277, Loss: 0.06089448183774948, Lr:0.0001\n",
      "Epoch 14, Step: 278, Loss: 0.018688932061195374, Lr:0.0001\n",
      "Epoch 14, Step: 279, Loss: 0.009474501945078373, Lr:0.0001\n",
      "Epoch 14, Step: 280, Loss: 0.02422173134982586, Lr:0.0001\n",
      "Epoch 14, Step: 281, Loss: 0.23118838667869568, Lr:0.0001\n",
      "Epoch 14, Step: 282, Loss: 0.03201230242848396, Lr:0.0001\n",
      "Epoch 14, Step: 283, Loss: 0.2912564277648926, Lr:0.0001\n",
      "Epoch 14, Step: 284, Loss: 0.039161793887615204, Lr:0.0001\n",
      "Epoch 14, Step: 285, Loss: 0.14040042459964752, Lr:0.0001\n",
      "Epoch 14, Step: 286, Loss: 0.07215750962495804, Lr:0.0001\n",
      "Epoch 14, Step: 287, Loss: 0.09690635651350021, Lr:0.0001\n",
      "Epoch 14, Step: 288, Loss: 0.023548375815153122, Lr:0.0001\n",
      "Epoch 14, Step: 289, Loss: 0.0527491420507431, Lr:0.0001\n",
      "Epoch 14, Step: 290, Loss: 0.03165125846862793, Lr:0.0001\n",
      "Epoch 14, Step: 291, Loss: 0.034395698457956314, Lr:0.0001\n",
      "Epoch 14, Step: 292, Loss: 0.08166848123073578, Lr:0.0001\n",
      "Epoch 14, Step: 293, Loss: 0.05391458794474602, Lr:0.0001\n",
      "Epoch 14, Step: 294, Loss: 0.2042645961046219, Lr:0.0001\n",
      "Epoch 14, Step: 295, Loss: 0.10861575603485107, Lr:0.0001\n",
      "Epoch 14, Step: 296, Loss: 0.17050082981586456, Lr:0.0001\n",
      "Epoch 14, Step: 297, Loss: 0.07361313700675964, Lr:0.0001\n",
      "Epoch 14, Step: 298, Loss: 0.0984104722738266, Lr:0.0001\n",
      "Epoch 14, Step: 299, Loss: 0.09894046187400818, Lr:0.0001\n",
      "Epoch 14, Step: 300, Loss: 0.10037897527217865, Lr:0.0001\n",
      "Epoch 14, Step: 301, Loss: 0.20150268077850342, Lr:0.0001\n",
      "Epoch 14, Step: 302, Loss: 0.11798759549856186, Lr:0.0001\n",
      "Epoch 14, Step: 303, Loss: 0.012148100882768631, Lr:0.0001\n",
      "Epoch 14, Step: 304, Loss: 0.13992789387702942, Lr:0.0001\n",
      "Epoch 14, Step: 305, Loss: 0.02009110152721405, Lr:0.0001\n",
      "Epoch 14, Step: 306, Loss: 0.10944904386997223, Lr:0.0001\n",
      "Epoch 14, Step: 307, Loss: 0.0708208903670311, Lr:0.0001\n",
      "Epoch 14, Step: 308, Loss: 0.020461872220039368, Lr:0.0001\n",
      "Epoch 14, Step: 309, Loss: 0.16835013031959534, Lr:0.0001\n",
      "Epoch 14, Step: 310, Loss: 0.17092420160770416, Lr:0.0001\n",
      "Epoch 14, Step: 311, Loss: 0.12234803289175034, Lr:0.0001\n",
      "Epoch 14, Step: 312, Loss: 0.08458233624696732, Lr:0.0001\n",
      "Epoch 14, Step: 313, Loss: 0.11255298554897308, Lr:0.0001\n",
      "Epoch 14, Step: 314, Loss: 0.022883037105202675, Lr:0.0001\n",
      "Epoch 14, Step: 315, Loss: 0.009902406483888626, Lr:0.0001\n",
      "Epoch 14, Step: 316, Loss: 0.01311890035867691, Lr:0.0001\n",
      "Epoch 14, Step: 317, Loss: 0.238987535238266, Lr:0.0001\n",
      "Epoch 14, Step: 318, Loss: 0.007111669518053532, Lr:0.0001\n",
      "Epoch 14, Step: 319, Loss: 0.05743841081857681, Lr:0.0001\n",
      "Epoch 14, Step: 320, Loss: 0.2842954695224762, Lr:0.0001\n",
      "Epoch 14, Step: 321, Loss: 0.06842925399541855, Lr:0.0001\n",
      "Epoch 14, Step: 322, Loss: 0.003869701409712434, Lr:0.0001\n",
      "Epoch 14, Step: 323, Loss: 0.008235707879066467, Lr:0.0001\n",
      "Epoch 14, Step: 324, Loss: 0.04627048969268799, Lr:0.0001\n",
      "Epoch 14, Step: 325, Loss: 0.3497143089771271, Lr:0.0001\n",
      "Epoch 14, Step: 326, Loss: 0.09687595069408417, Lr:0.0001\n",
      "Epoch 14, Step: 327, Loss: 0.1091742217540741, Lr:0.0001\n",
      "Epoch 14, Step: 328, Loss: 0.197984516620636, Lr:0.0001\n",
      "Epoch 14, Step: 329, Loss: 0.040188372135162354, Lr:0.0001\n",
      "Epoch 14, Step: 330, Loss: 0.1272522211074829, Lr:0.0001\n",
      "Epoch 14, Step: 331, Loss: 0.2769763171672821, Lr:0.0001\n",
      "Epoch 14, Step: 332, Loss: 0.1633968949317932, Lr:0.0001\n",
      "Epoch 14, Step: 333, Loss: 0.29818907380104065, Lr:0.0001\n",
      "Epoch 14, Step: 334, Loss: 0.06621497124433517, Lr:0.0001\n",
      "Epoch 14, Step: 335, Loss: 0.09279756247997284, Lr:0.0001\n",
      "Epoch 14, Step: 336, Loss: 0.022911371663212776, Lr:0.0001\n",
      "Epoch 14, Step: 337, Loss: 0.007430128287523985, Lr:0.0001\n",
      "Epoch 14, Step: 338, Loss: 0.03733266890048981, Lr:0.0001\n",
      "Epoch 14, Step: 339, Loss: 0.04422116279602051, Lr:0.0001\n",
      "Epoch 14, Step: 340, Loss: 0.10716361552476883, Lr:0.0001\n",
      "Epoch 14, Step: 341, Loss: 0.035086601972579956, Lr:0.0001\n",
      "Epoch 14, Step: 342, Loss: 0.023761479184031487, Lr:0.0001\n",
      "Epoch 14, Step: 343, Loss: 0.04001237824559212, Lr:0.0001\n",
      "Epoch 14, Step: 344, Loss: 0.08884795755147934, Lr:0.0001\n",
      "Epoch 14, Step: 345, Loss: 0.0742318406701088, Lr:0.0001\n",
      "Epoch 14, Step: 346, Loss: 0.18875668942928314, Lr:0.0001\n",
      "Epoch 14, Step: 347, Loss: 0.1186525821685791, Lr:0.0001\n",
      "Epoch 14, Step: 348, Loss: 0.28130805492401123, Lr:0.0001\n",
      "Epoch 14, Step: 349, Loss: 0.27677541971206665, Lr:0.0001\n",
      "Epoch 14, Step: 350, Loss: 0.2891625165939331, Lr:0.0001\n",
      "Epoch 14, Step: 351, Loss: 0.05747588723897934, Lr:0.0001\n",
      "Epoch 14, Step: 352, Loss: 0.023555995896458626, Lr:0.0001\n",
      "Epoch 14, Step: 353, Loss: 0.1400829255580902, Lr:0.0001\n",
      "Epoch 14, Step: 354, Loss: 0.12452375888824463, Lr:0.0001\n",
      "Epoch 14, Step: 355, Loss: 0.15701140463352203, Lr:0.0001\n",
      "Epoch 14, Step: 356, Loss: 0.12981681525707245, Lr:0.0001\n",
      "Epoch 14, Step: 357, Loss: 0.05354716256260872, Lr:0.0001\n",
      "Epoch 14, Step: 358, Loss: 0.023134782910346985, Lr:0.0001\n",
      "Epoch 14, Step: 359, Loss: 0.060391828417778015, Lr:0.0001\n",
      "Epoch 14, Step: 360, Loss: 0.14149299263954163, Lr:0.0001\n",
      "Epoch 14, Step: 361, Loss: 0.5492573976516724, Lr:0.0001\n",
      "Epoch 14, Step: 362, Loss: 0.014688458293676376, Lr:0.0001\n",
      "Epoch 14, Step: 363, Loss: 0.2454383224248886, Lr:0.0001\n",
      "Epoch 14, Step: 364, Loss: 0.0045461878180503845, Lr:0.0001\n",
      "Epoch 14, Step: 365, Loss: 0.03689880296587944, Lr:0.0001\n",
      "Epoch 14, Step: 366, Loss: 0.22341212630271912, Lr:0.0001\n",
      "Epoch 14, Step: 367, Loss: 0.014856700785458088, Lr:0.0001\n",
      "Epoch 14, Step: 368, Loss: 0.15451805293560028, Lr:0.0001\n",
      "Epoch 14, Step: 369, Loss: 0.0807371735572815, Lr:0.0001\n",
      "Epoch 14, Step: 370, Loss: 0.3516223430633545, Lr:0.0001\n",
      "Epoch 14, Step: 371, Loss: 0.19242772459983826, Lr:0.0001\n",
      "Epoch 14, Step: 372, Loss: 0.10820311307907104, Lr:0.0001\n",
      "Epoch 14, Step: 373, Loss: 0.0559958815574646, Lr:0.0001\n",
      "Epoch 14, Step: 374, Loss: 0.014726320281624794, Lr:0.0001\n",
      "Epoch 14, Step: 375, Loss: 0.038484156131744385, Lr:0.0001\n",
      "Epoch 14, Step: 376, Loss: 0.09755118936300278, Lr:0.0001\n",
      "Epoch 14, Step: 377, Loss: 0.04490898177027702, Lr:0.0001\n",
      "Epoch 14, Step: 378, Loss: 0.2402823120355606, Lr:0.0001\n",
      "Epoch 14, Step: 379, Loss: 0.022262651473283768, Lr:0.0001\n",
      "Epoch 14, Step: 380, Loss: 0.1721213310956955, Lr:0.0001\n",
      "Epoch 14, Step: 381, Loss: 0.07589602470397949, Lr:0.0001\n",
      "Epoch 14, Step: 382, Loss: 0.10223222523927689, Lr:0.0001\n",
      "Epoch 14, Step: 383, Loss: 0.5466257929801941, Lr:0.0001\n",
      "Epoch 14, Step: 384, Loss: 0.10237777233123779, Lr:0.0001\n",
      "Epoch 14, Step: 385, Loss: 0.3268055021762848, Lr:0.0001\n",
      "Epoch 14, Step: 386, Loss: 0.1716242879629135, Lr:0.0001\n",
      "Epoch 14, Step: 387, Loss: 0.05943791940808296, Lr:0.0001\n",
      "Epoch 14, Step: 388, Loss: 0.023525603115558624, Lr:0.0001\n",
      "Epoch 14, Step: 389, Loss: 0.0893913060426712, Lr:0.0001\n",
      "Epoch 14, Step: 390, Loss: 0.1389312595129013, Lr:0.0001\n",
      "Epoch 14, Step: 391, Loss: 0.07558819651603699, Lr:0.0001\n",
      "Epoch 14, Step: 392, Loss: 0.03044169582426548, Lr:0.0001\n",
      "Epoch 14, Step: 393, Loss: 0.034803904592990875, Lr:0.0001\n",
      "Epoch 14, Step: 394, Loss: 0.2354440689086914, Lr:0.0001\n",
      "Epoch 14, Step: 395, Loss: 0.031594861298799515, Lr:0.0001\n",
      "Epoch 14, Step: 396, Loss: 0.11039483547210693, Lr:0.0001\n",
      "Epoch 14, Step: 397, Loss: 0.016589727252721786, Lr:0.0001\n",
      "Epoch 14, Step: 398, Loss: 0.26187407970428467, Lr:0.0001\n",
      "Epoch 14, Step: 399, Loss: 0.02547018602490425, Lr:0.0001\n",
      "Epoch 14, Step: 400, Loss: 0.3586924076080322, Lr:0.0001\n",
      "Epoch 14, Step: 401, Loss: 0.14189684391021729, Lr:0.0001\n",
      "Epoch 14, Step: 402, Loss: 0.19303444027900696, Lr:0.0001\n",
      "Epoch 14, Step: 403, Loss: 0.07915038615465164, Lr:0.0001\n",
      "Epoch 14, Step: 404, Loss: 0.0293930321931839, Lr:0.0001\n",
      "Epoch 14, Step: 405, Loss: 0.15737439692020416, Lr:0.0001\n",
      "Epoch 14, Step: 406, Loss: 0.010196195915341377, Lr:0.0001\n",
      "Epoch 14, Step: 407, Loss: 0.08257235586643219, Lr:0.0001\n",
      "Epoch 14, Step: 408, Loss: 0.3038763701915741, Lr:0.0001\n",
      "Epoch 14, Step: 409, Loss: 0.3495117127895355, Lr:0.0001\n",
      "Epoch 14, Step: 410, Loss: 0.1619173288345337, Lr:0.0001\n",
      "Epoch 14, Step: 411, Loss: 0.22118806838989258, Lr:0.0001\n",
      "Epoch 14, Step: 412, Loss: 0.2784123420715332, Lr:0.0001\n",
      "Epoch 14, Step: 413, Loss: 0.06501885503530502, Lr:0.0001\n",
      "Epoch 14, Step: 414, Loss: 0.17586809396743774, Lr:0.0001\n",
      "Epoch 14, Step: 415, Loss: 0.12404021620750427, Lr:0.0001\n",
      "Epoch 14, Step: 416, Loss: 0.08853831887245178, Lr:0.0001\n",
      "Epoch 14, Step: 417, Loss: 0.03285769373178482, Lr:0.0001\n",
      "Epoch 14, Step: 418, Loss: 0.052287306636571884, Lr:0.0001\n",
      "Epoch 14, Step: 419, Loss: 0.0877201110124588, Lr:0.0001\n",
      "Epoch 14, Step: 420, Loss: 0.019041789695620537, Lr:0.0001\n",
      "Epoch 14, Step: 421, Loss: 0.03660174086689949, Lr:0.0001\n",
      "Epoch 14, Step: 422, Loss: 0.03664790466427803, Lr:0.0001\n",
      "Epoch 14, Step: 423, Loss: 0.39838388562202454, Lr:0.0001\n",
      "Epoch 14, Step: 424, Loss: 0.015651654452085495, Lr:0.0001\n",
      "Epoch 14, Step: 425, Loss: 0.17649677395820618, Lr:0.0001\n",
      "Epoch 14, Step: 426, Loss: 0.03077423758804798, Lr:0.0001\n",
      "Epoch 14, Step: 427, Loss: 0.00932339671999216, Lr:0.0001\n",
      "Epoch 14, Step: 428, Loss: 0.01373020838946104, Lr:0.0001\n",
      "Epoch 14, Step: 429, Loss: 0.08024965226650238, Lr:0.0001\n",
      "Epoch 14, Step: 430, Loss: 0.2715302109718323, Lr:0.0001\n",
      "Epoch 14, Step: 431, Loss: 0.23659825325012207, Lr:0.0001\n",
      "Epoch 14, Step: 432, Loss: 0.08228848874568939, Lr:0.0001\n",
      "Epoch 14, Step: 433, Loss: 0.0657632052898407, Lr:0.0001\n",
      "Epoch 14, Step: 434, Loss: 0.03336361050605774, Lr:0.0001\n",
      "Epoch 14, Step: 435, Loss: 0.1884843111038208, Lr:0.0001\n",
      "Epoch 14, Step: 436, Loss: 0.7459912896156311, Lr:0.0001\n",
      "Epoch 14, Step: 437, Loss: 0.18857599794864655, Lr:0.0001\n",
      "Epoch 14, Step: 438, Loss: 0.0698828175663948, Lr:0.0001\n",
      "Epoch 14, Step: 439, Loss: 0.16460956633090973, Lr:0.0001\n",
      "Epoch 14, Step: 440, Loss: 0.02629423327744007, Lr:0.0001\n",
      "Epoch 14, Step: 441, Loss: 0.24877622723579407, Lr:0.0001\n",
      "Epoch 14, Step: 442, Loss: 0.09392645955085754, Lr:0.0001\n",
      "Epoch 14, Step: 443, Loss: 0.03742457553744316, Lr:0.0001\n",
      "Epoch 14, Step: 444, Loss: 0.04767146334052086, Lr:0.0001\n",
      "Epoch 14, Step: 445, Loss: 0.042207688093185425, Lr:0.0001\n",
      "Epoch 14, Step: 446, Loss: 0.030358681455254555, Lr:0.0001\n",
      "Epoch 14, Step: 447, Loss: 0.059634532779455185, Lr:0.0001\n",
      "Epoch 14, Step: 448, Loss: 0.33216843008995056, Lr:0.0001\n",
      "Epoch 14, Step: 449, Loss: 0.022648092359304428, Lr:0.0001\n",
      "Epoch 14, Step: 450, Loss: 0.15317684412002563, Lr:0.0001\n",
      "Epoch 14, Step: 451, Loss: 0.015387178398668766, Lr:0.0001\n",
      "Epoch 14, Step: 452, Loss: 0.026802590116858482, Lr:0.0001\n",
      "Epoch 14, Step: 453, Loss: 0.12725159525871277, Lr:0.0001\n",
      "Epoch 14, Step: 454, Loss: 0.02199709601700306, Lr:0.0001\n",
      "Epoch 14, Step: 455, Loss: 0.0574282705783844, Lr:0.0001\n",
      "Epoch 14, Step: 456, Loss: 0.024924423545598984, Lr:0.0001\n",
      "Epoch 14, Step: 457, Loss: 0.1341884583234787, Lr:0.0001\n",
      "Epoch 14, Step: 458, Loss: 0.05064338445663452, Lr:0.0001\n",
      "Epoch 14, Step: 459, Loss: 0.2390081137418747, Lr:0.0001\n",
      "Epoch 14, Step: 460, Loss: 0.14088022708892822, Lr:0.0001\n",
      "Epoch 14, Step: 461, Loss: 0.1315019279718399, Lr:0.0001\n",
      "Epoch 14, Step: 462, Loss: 0.3573966324329376, Lr:0.0001\n",
      "Epoch 14, Step: 463, Loss: 0.029497286304831505, Lr:0.0001\n",
      "Epoch 14, Step: 464, Loss: 0.364376038312912, Lr:0.0001\n",
      "Epoch 14, Step: 465, Loss: 0.04188957065343857, Lr:0.0001\n",
      "Epoch 14, Step: 466, Loss: 0.1953752189874649, Lr:0.0001\n",
      "Epoch 14, Step: 467, Loss: 0.14400172233581543, Lr:0.0001\n",
      "Epoch 14, Step: 468, Loss: 0.04393814876675606, Lr:0.0001\n",
      "Epoch 14, Step: 469, Loss: 0.08187351375818253, Lr:0.0001\n",
      "Epoch 14, Step: 470, Loss: 0.05423516407608986, Lr:0.0001\n",
      "Epoch 14, Step: 471, Loss: 0.011031504720449448, Lr:0.0001\n",
      "Epoch 14, Step: 472, Loss: 0.19053827226161957, Lr:0.0001\n",
      "Epoch 14, Step: 473, Loss: 0.29168766736984253, Lr:0.0001\n",
      "Epoch 14, Step: 474, Loss: 0.0798637717962265, Lr:0.0001\n",
      "Epoch 14, Step: 475, Loss: 0.267539381980896, Lr:0.0001\n",
      "Epoch 14, Step: 476, Loss: 0.14964671432971954, Lr:0.0001\n",
      "Epoch 14, Step: 477, Loss: 0.01510636880993843, Lr:0.0001\n",
      "Epoch 14, Step: 478, Loss: 0.17847056686878204, Lr:0.0001\n",
      "Epoch 14, Step: 479, Loss: 0.25111475586891174, Lr:0.0001\n",
      "Epoch 14, Step: 480, Loss: 0.09216567873954773, Lr:0.0001\n",
      "Epoch 14, Step: 481, Loss: 0.0047968970611691475, Lr:0.0001\n",
      "Epoch 14, Step: 482, Loss: 0.029510658234357834, Lr:0.0001\n",
      "Epoch 14, Step: 483, Loss: 0.023459672927856445, Lr:0.0001\n",
      "Epoch 14, Step: 484, Loss: 0.013282508589327335, Lr:0.0001\n",
      "Epoch 14, Step: 485, Loss: 0.07754357159137726, Lr:0.0001\n",
      "Epoch 14, Step: 486, Loss: 0.2871440649032593, Lr:0.0001\n",
      "Epoch 14, Step: 487, Loss: 0.05592392012476921, Lr:0.0001\n",
      "Epoch 14, Step: 488, Loss: 0.23232628405094147, Lr:0.0001\n",
      "Epoch 14, Step: 489, Loss: 0.13066869974136353, Lr:0.0001\n",
      "Epoch 14, Step: 490, Loss: 0.14597460627555847, Lr:0.0001\n",
      "Epoch 14, Step: 491, Loss: 0.02083927020430565, Lr:0.0001\n",
      "Epoch 14, Step: 492, Loss: 0.01940479874610901, Lr:0.0001\n",
      "Epoch 14, Step: 493, Loss: 0.3867695927619934, Lr:0.0001\n",
      "Epoch 14, Step: 494, Loss: 0.1980520337820053, Lr:0.0001\n",
      "Epoch 14, Step: 495, Loss: 0.041151516139507294, Lr:0.0001\n",
      "Epoch 14, Step: 496, Loss: 0.18402007222175598, Lr:0.0001\n",
      "Epoch 14, Step: 497, Loss: 0.16018831729888916, Lr:0.0001\n",
      "Epoch 14, Step: 498, Loss: 0.11644313484430313, Lr:0.0001\n",
      "Epoch 14, Step: 499, Loss: 0.28063005208969116, Lr:0.0001\n",
      "Epoch 14, Step: 500, Loss: 0.12027937918901443, Lr:0.0001\n",
      "Epoch 14, Step: 501, Loss: 0.07566824555397034, Lr:0.0001\n",
      "Epoch 14, Step: 502, Loss: 0.041301123797893524, Lr:0.0001\n",
      "Epoch 14, Step: 503, Loss: 0.11319316923618317, Lr:0.0001\n",
      "Epoch 14, Step: 504, Loss: 0.06423656642436981, Lr:0.0001\n",
      "Epoch 14, Step: 505, Loss: 0.03562286123633385, Lr:0.0001\n",
      "Epoch 14, Step: 506, Loss: 0.12671346962451935, Lr:0.0001\n",
      "Epoch 14, Step: 507, Loss: 0.014836638234555721, Lr:0.0001\n",
      "Epoch 14, Step: 508, Loss: 0.04379009082913399, Lr:0.0001\n",
      "Epoch 14, Step: 509, Loss: 0.204088494181633, Lr:0.0001\n",
      "Epoch 14, Step: 510, Loss: 0.16965870559215546, Lr:0.0001\n",
      "Epoch 14, Step: 511, Loss: 0.0683852955698967, Lr:0.0001\n",
      "Epoch 14, Step: 512, Loss: 0.06194233521819115, Lr:0.0001\n",
      "Epoch 14, Step: 513, Loss: 0.009627721272408962, Lr:0.0001\n",
      "Epoch 14, Step: 514, Loss: 0.0035386939998716116, Lr:0.0001\n",
      "Epoch 14, Step: 515, Loss: 0.14988096058368683, Lr:0.0001\n",
      "Epoch 14, Step: 516, Loss: 0.34857210516929626, Lr:0.0001\n",
      "Epoch 14, Step: 517, Loss: 0.05119264870882034, Lr:0.0001\n",
      "Epoch 14, Step: 518, Loss: 0.05774799734354019, Lr:0.0001\n",
      "Epoch 14, Step: 519, Loss: 0.03149973973631859, Lr:0.0001\n",
      "Epoch 14, Step: 520, Loss: 0.041507262736558914, Lr:0.0001\n",
      "Epoch 14, Step: 521, Loss: 0.035104066133499146, Lr:0.0001\n",
      "Epoch 14, Step: 522, Loss: 0.07781005650758743, Lr:0.0001\n",
      "Epoch 14, Step: 523, Loss: 0.04270337149500847, Lr:0.0001\n",
      "Epoch 14, Step: 524, Loss: 0.07773640751838684, Lr:0.0001\n",
      "Epoch 14, Step: 525, Loss: 0.1875949501991272, Lr:0.0001\n",
      "Epoch 14, Step: 526, Loss: 0.11720902472734451, Lr:0.0001\n",
      "Epoch 14, Step: 527, Loss: 0.14435690641403198, Lr:0.0001\n",
      "Epoch 14, Step: 528, Loss: 0.0736033022403717, Lr:0.0001\n",
      "Epoch 14, Step: 529, Loss: 0.1481570303440094, Lr:0.0001\n",
      "Epoch 14, Step: 530, Loss: 0.07632457464933395, Lr:0.0001\n",
      "Epoch 14, Step: 531, Loss: 0.08663015067577362, Lr:0.0001\n",
      "Epoch 14, Step: 532, Loss: 0.11052612960338593, Lr:0.0001\n",
      "Epoch 14, Step: 533, Loss: 0.07145341485738754, Lr:0.0001\n",
      "Epoch 14, Step: 534, Loss: 0.020443091168999672, Lr:0.0001\n",
      "Epoch 14, Step: 535, Loss: 0.018552780151367188, Lr:0.0001\n",
      "Epoch 14, Step: 536, Loss: 0.22666692733764648, Lr:0.0001\n",
      "Epoch 14, Step: 537, Loss: 0.16237181425094604, Lr:0.0001\n",
      "Epoch 14, Step: 538, Loss: 0.13510452210903168, Lr:0.0001\n",
      "Epoch 14, Step: 539, Loss: 0.06419721245765686, Lr:0.0001\n",
      "Epoch 14, Step: 540, Loss: 0.15394647419452667, Lr:0.0001\n",
      "Epoch 14, Step: 541, Loss: 0.007052749395370483, Lr:0.0001\n",
      "Epoch 14, Step: 542, Loss: 0.14605936408042908, Lr:0.0001\n",
      "Epoch 14, Step: 543, Loss: 0.12375988066196442, Lr:0.0001\n",
      "Epoch 14, Step: 544, Loss: 0.05316559970378876, Lr:0.0001\n",
      "Epoch 14, Step: 545, Loss: 0.17387130856513977, Lr:0.0001\n",
      "Epoch 14, Step: 546, Loss: 0.09240246564149857, Lr:0.0001\n",
      "Epoch 14, Step: 547, Loss: 0.1815655380487442, Lr:0.0001\n",
      "Epoch 14, Step: 548, Loss: 0.04787345603108406, Lr:0.0001\n",
      "Epoch 14, Step: 549, Loss: 0.134642094373703, Lr:0.0001\n",
      "Epoch 14, Step: 550, Loss: 0.052633751183748245, Lr:0.0001\n",
      "Epoch 14, Step: 551, Loss: 0.03733540698885918, Lr:0.0001\n",
      "Epoch 14, Step: 552, Loss: 0.06862138956785202, Lr:0.0001\n",
      "Epoch 14, Step: 553, Loss: 0.02454410120844841, Lr:0.0001\n",
      "Epoch 14, Step: 554, Loss: 0.06719731539487839, Lr:0.0001\n",
      "Epoch 14, Step: 555, Loss: 0.021790890023112297, Lr:0.0001\n",
      "Epoch 14, Step: 556, Loss: 0.012300362810492516, Lr:0.0001\n",
      "Epoch 14, Step: 557, Loss: 0.027163514867424965, Lr:0.0001\n",
      "Epoch 14, Step: 558, Loss: 0.16269367933273315, Lr:0.0001\n",
      "Epoch 14, Step: 559, Loss: 0.1932172030210495, Lr:0.0001\n",
      "Epoch 14, Step: 560, Loss: 0.06952407211065292, Lr:0.0001\n",
      "Epoch 14, Step: 561, Loss: 0.04347386956214905, Lr:0.0001\n",
      "Epoch 14, Step: 562, Loss: 0.05393097549676895, Lr:0.0001\n",
      "Epoch 14, Step: 563, Loss: 0.17969423532485962, Lr:0.0001\n",
      "Epoch 14, Step: 564, Loss: 0.25810596346855164, Lr:0.0001\n",
      "Epoch 14, Step: 565, Loss: 0.010664455592632294, Lr:0.0001\n",
      "Epoch 14, Step: 566, Loss: 0.07194490730762482, Lr:0.0001\n",
      "Epoch 14, Step: 567, Loss: 0.130973219871521, Lr:0.0001\n",
      "Epoch 14, Step: 568, Loss: 0.027956655248999596, Lr:0.0001\n",
      "Epoch 14, Step: 569, Loss: 0.05196444317698479, Lr:0.0001\n",
      "Epoch 14, Step: 570, Loss: 0.09041957557201385, Lr:0.0001\n",
      "Epoch 14, Step: 571, Loss: 0.006567304488271475, Lr:0.0001\n",
      "Epoch 14, Step: 572, Loss: 0.04679238796234131, Lr:0.0001\n",
      "Epoch 14, Step: 573, Loss: 0.016734013333916664, Lr:0.0001\n",
      "Epoch 14, Step: 574, Loss: 0.004274735227227211, Lr:0.0001\n",
      "Epoch 14, Step: 575, Loss: 0.18132437765598297, Lr:0.0001\n",
      "Epoch 14, Step: 576, Loss: 0.007788741961121559, Lr:0.0001\n",
      "Epoch 14, Step: 577, Loss: 0.11692686378955841, Lr:0.0001\n",
      "Epoch 14, Step: 578, Loss: 0.17415964603424072, Lr:0.0001\n",
      "Epoch 14, Step: 579, Loss: 0.08806020021438599, Lr:0.0001\n",
      "Epoch 14, Step: 580, Loss: 0.003255294868722558, Lr:0.0001\n",
      "Epoch 14, Step: 581, Loss: 0.028147749602794647, Lr:0.0001\n",
      "Epoch 14, Step: 582, Loss: 0.04418525472283363, Lr:0.0001\n",
      "Epoch 14, Step: 583, Loss: 0.009065607562661171, Lr:0.0001\n",
      "Epoch 14, Step: 584, Loss: 0.021133456379175186, Lr:0.0001\n",
      "Epoch 14, Step: 585, Loss: 0.02092897891998291, Lr:0.0001\n",
      "Epoch 14, Step: 586, Loss: 0.03759763017296791, Lr:0.0001\n",
      "Epoch 14, Step: 587, Loss: 0.025508873164653778, Lr:0.0001\n",
      "Epoch 14, Step: 588, Loss: 0.0369412861764431, Lr:0.0001\n",
      "Epoch 14, Step: 589, Loss: 0.11866682767868042, Lr:0.0001\n",
      "Epoch 14, Step: 590, Loss: 0.03909197822213173, Lr:0.0001\n",
      "Epoch 14, Step: 591, Loss: 0.08323746174573898, Lr:0.0001\n",
      "Epoch 14, Step: 592, Loss: 0.07062344998121262, Lr:0.0001\n",
      "Epoch 14, Step: 593, Loss: 0.10777369141578674, Lr:0.0001\n",
      "Epoch 14, Step: 594, Loss: 0.11255102604627609, Lr:0.0001\n",
      "Epoch 14, Step: 595, Loss: 0.08824872970581055, Lr:0.0001\n",
      "Epoch 14, Step: 596, Loss: 0.08147361129522324, Lr:0.0001\n",
      "Epoch 14, Step: 597, Loss: 0.02252262830734253, Lr:0.0001\n",
      "Epoch 14, Step: 598, Loss: 0.09642056375741959, Lr:0.0001\n",
      "Epoch 14, Step: 599, Loss: 0.05962551385164261, Lr:0.0001\n",
      "Epoch 14, Step: 600, Loss: 0.04498697444796562, Lr:0.0001\n",
      "Epoch 14, Step: 601, Loss: 0.04567622393369675, Lr:0.0001\n",
      "Epoch 14, Step: 602, Loss: 0.10733790695667267, Lr:0.0001\n",
      "Epoch 14, Step: 603, Loss: 0.043157875537872314, Lr:0.0001\n",
      "Epoch 14, Step: 604, Loss: 0.02254607528448105, Lr:0.0001\n",
      "Epoch 14, Step: 605, Loss: 0.10884497314691544, Lr:0.0001\n",
      "Epoch 14, Step: 606, Loss: 0.0570964515209198, Lr:0.0001\n",
      "Epoch 14, Step: 607, Loss: 0.008869214914739132, Lr:0.0001\n",
      "Epoch 14, Step: 608, Loss: 0.11356482654809952, Lr:0.0001\n",
      "Epoch 14, Step: 609, Loss: 0.18670424818992615, Lr:0.0001\n",
      "Epoch 14, Step: 610, Loss: 0.06720472872257233, Lr:0.0001\n",
      "Epoch 14, Step: 611, Loss: 0.001067092176526785, Lr:0.0001\n",
      "Epoch 14, Step: 612, Loss: 0.2329990267753601, Lr:0.0001\n",
      "Epoch 14, Step: 613, Loss: 0.024020278826355934, Lr:0.0001\n",
      "Epoch 14, Step: 614, Loss: 0.09872812032699585, Lr:0.0001\n",
      "Epoch 14, Step: 615, Loss: 0.044195689260959625, Lr:0.0001\n",
      "Epoch 14, Step: 616, Loss: 0.12977994978427887, Lr:0.0001\n",
      "Epoch 14, Step: 617, Loss: 0.05666715279221535, Lr:0.0001\n",
      "Epoch 14, Step: 618, Loss: 0.024924173951148987, Lr:0.0001\n",
      "Epoch 14, Step: 619, Loss: 0.20239759981632233, Lr:0.0001\n",
      "Epoch 14, Step: 620, Loss: 0.011431850492954254, Lr:0.0001\n",
      "Epoch 14, Step: 621, Loss: 0.14660373330116272, Lr:0.0001\n",
      "Epoch 14, Step: 622, Loss: 0.35592544078826904, Lr:0.0001\n",
      "Epoch 14, Step: 623, Loss: 0.026829520240426064, Lr:0.0001\n",
      "Epoch 14, Step: 624, Loss: 0.032984454184770584, Lr:0.0001\n",
      "Epoch 14, Step: 625, Loss: 0.047222621738910675, Lr:0.0001\n",
      "Epoch 14, Step: 626, Loss: 0.08189710974693298, Lr:0.0001\n",
      "Epoch 14, Step: 627, Loss: 0.4794166684150696, Lr:0.0001\n",
      "Epoch 14, Step: 628, Loss: 0.014640029519796371, Lr:0.0001\n",
      "Epoch 14, Step: 629, Loss: 0.24580153822898865, Lr:0.0001\n",
      "Epoch 14, Step: 630, Loss: 0.11833847314119339, Lr:0.0001\n",
      "Epoch 14, Step: 631, Loss: 0.013617755845189095, Lr:0.0001\n",
      "Epoch 14, Step: 632, Loss: 0.23634271323680878, Lr:0.0001\n",
      "Epoch 14, Step: 633, Loss: 0.11795853823423386, Lr:0.0001\n",
      "Epoch 14, Step: 634, Loss: 0.10344969481229782, Lr:0.0001\n",
      "Epoch 14, Step: 635, Loss: 0.02408807910978794, Lr:0.0001\n",
      "Epoch 14, Step: 636, Loss: 0.06407291442155838, Lr:0.0001\n",
      "Epoch 14, Step: 637, Loss: 0.10863026976585388, Lr:0.0001\n",
      "Epoch 14, Step: 638, Loss: 0.06766670942306519, Lr:0.0001\n",
      "Epoch 14, Step: 639, Loss: 0.1798364669084549, Lr:0.0001\n",
      "Epoch 14, Step: 640, Loss: 0.18454304337501526, Lr:0.0001\n",
      "Epoch 14, Step: 641, Loss: 0.05492224916815758, Lr:0.0001\n",
      "Epoch 14, Step: 642, Loss: 0.08914290368556976, Lr:0.0001\n",
      "Epoch 14, Step: 643, Loss: 0.16726170480251312, Lr:0.0001\n",
      "Epoch 14, Step: 644, Loss: 0.05716169625520706, Lr:0.0001\n",
      "Epoch 14, Step: 645, Loss: 0.011719953268766403, Lr:0.0001\n",
      "Epoch 14, Step: 646, Loss: 0.06965282559394836, Lr:0.0001\n",
      "Epoch 14, Step: 647, Loss: 0.2652706503868103, Lr:0.0001\n",
      "Epoch 14, Step: 648, Loss: 0.038303643465042114, Lr:0.0001\n",
      "Epoch 14, Step: 649, Loss: 0.12613023817539215, Lr:0.0001\n",
      "Epoch 14, Step: 650, Loss: 0.2248283475637436, Lr:0.0001\n",
      "Epoch 14, Step: 651, Loss: 0.3015771210193634, Lr:0.0001\n",
      "Epoch 14, Step: 652, Loss: 0.1505076140165329, Lr:0.0001\n",
      "Epoch 14, Step: 653, Loss: 0.2500101923942566, Lr:0.0001\n",
      "Epoch 14, Step: 654, Loss: 0.0686405599117279, Lr:0.0001\n",
      "Epoch 14, Step: 655, Loss: 0.05303557589650154, Lr:0.0001\n",
      "Epoch 14, Step: 656, Loss: 0.0655779093503952, Lr:0.0001\n",
      "Epoch 14, Step: 657, Loss: 0.04520135000348091, Lr:0.0001\n",
      "Epoch 14, Step: 658, Loss: 0.04052439332008362, Lr:0.0001\n",
      "Epoch 14, Step: 659, Loss: 0.0994756668806076, Lr:0.0001\n",
      "Epoch 14, Step: 660, Loss: 0.022578643634915352, Lr:0.0001\n",
      "Epoch 14, Step: 661, Loss: 0.025781992822885513, Lr:0.0001\n",
      "Epoch 14, Step: 662, Loss: 0.0797710195183754, Lr:0.0001\n",
      "Epoch 14, Step: 663, Loss: 0.1511559933423996, Lr:0.0001\n",
      "Epoch 14, Step: 664, Loss: 0.0846165120601654, Lr:0.0001\n",
      "Epoch 14, Step: 665, Loss: 0.016078932210803032, Lr:0.0001\n",
      "Epoch 14, Step: 666, Loss: 0.0972701758146286, Lr:0.0001\n",
      "Epoch 14, Step: 667, Loss: 0.14804179966449738, Lr:0.0001\n",
      "Epoch 14, Step: 668, Loss: 0.1375458687543869, Lr:0.0001\n",
      "Epoch 14, Step: 669, Loss: 0.21815362572669983, Lr:0.0001\n",
      "Epoch 14, Step: 670, Loss: 0.051939308643341064, Lr:0.0001\n",
      "Epoch 14, Step: 671, Loss: 0.35865387320518494, Lr:0.0001\n",
      "Epoch 14, Step: 672, Loss: 0.02798127941787243, Lr:0.0001\n",
      "Epoch 14, Step: 673, Loss: 0.15389473736286163, Lr:0.0001\n",
      "Epoch 14, Step: 674, Loss: 0.0701354518532753, Lr:0.0001\n",
      "Epoch 14, Step: 675, Loss: 0.0755617767572403, Lr:0.0001\n",
      "Epoch 14, Step: 676, Loss: 0.018000587821006775, Lr:0.0001\n",
      "Epoch 14, Step: 677, Loss: 0.10480423271656036, Lr:0.0001\n",
      "Epoch 14, Step: 678, Loss: 0.028320861980319023, Lr:0.0001\n",
      "Epoch 14, Step: 679, Loss: 0.10174992680549622, Lr:0.0001\n",
      "Epoch 14, Step: 680, Loss: 0.042074523866176605, Lr:0.0001\n",
      "Epoch 14, Step: 681, Loss: 0.1298476904630661, Lr:0.0001\n",
      "Epoch 14, Step: 682, Loss: 0.2540832459926605, Lr:0.0001\n",
      "Epoch 14, Step: 683, Loss: 0.2670348286628723, Lr:0.0001\n",
      "Epoch 14, Step: 684, Loss: 0.15061885118484497, Lr:0.0001\n",
      "Epoch 14, Step: 685, Loss: 0.16636811196804047, Lr:0.0001\n",
      "Epoch 14, Step: 686, Loss: 0.12274735420942307, Lr:0.0001\n",
      "Epoch 14, Step: 687, Loss: 0.03461456671357155, Lr:0.0001\n",
      "Epoch 14, Step: 688, Loss: 0.13195884227752686, Lr:0.0001\n",
      "Epoch 14, Step: 689, Loss: 0.16022470593452454, Lr:0.0001\n",
      "Epoch 14, Step: 690, Loss: 0.24645432829856873, Lr:0.0001\n",
      "Epoch 14, Step: 691, Loss: 0.09232483804225922, Lr:0.0001\n",
      "Epoch 14, Step: 692, Loss: 0.11283218115568161, Lr:0.0001\n",
      "Epoch 14, Step: 693, Loss: 0.07506798952817917, Lr:0.0001\n",
      "Epoch 14, Step: 694, Loss: 0.023716799914836884, Lr:0.0001\n",
      "Epoch 14, Step: 695, Loss: 0.2013484537601471, Lr:0.0001\n",
      "Epoch 14, Step: 696, Loss: 0.04686415567994118, Lr:0.0001\n",
      "Epoch 14, Step: 697, Loss: 0.05710599571466446, Lr:0.0001\n",
      "Epoch 14, Step: 698, Loss: 0.1998053789138794, Lr:0.0001\n",
      "Epoch 14, Step: 699, Loss: 0.06177259609103203, Lr:0.0001\n",
      "Epoch 14, Step: 700, Loss: 0.10519465059041977, Lr:0.0001\n",
      "Epoch 14, Step: 701, Loss: 0.042638204991817474, Lr:0.0001\n",
      "Epoch 14, Step: 702, Loss: 0.14130711555480957, Lr:0.0001\n",
      "Epoch 14, Step: 703, Loss: 0.03772640973329544, Lr:0.0001\n",
      "Epoch 14, Step: 704, Loss: 0.03634091839194298, Lr:0.0001\n",
      "Epoch 14, Step: 705, Loss: 0.06424448639154434, Lr:0.0001\n",
      "Epoch 14, Step: 706, Loss: 0.047132037580013275, Lr:0.0001\n",
      "Epoch 14, Step: 707, Loss: 0.021353859454393387, Lr:0.0001\n",
      "Epoch 14, Step: 708, Loss: 0.03697372227907181, Lr:0.0001\n",
      "Epoch 14, Step: 709, Loss: 0.05049378052353859, Lr:0.0001\n",
      "Epoch 14, Step: 710, Loss: 0.021313752979040146, Lr:0.0001\n",
      "Epoch 14, Step: 711, Loss: 0.012095121666789055, Lr:0.0001\n",
      "Epoch 14, Step: 712, Loss: 0.11190993338823318, Lr:0.0001\n",
      "Epoch 14, Step: 713, Loss: 0.14043939113616943, Lr:0.0001\n",
      "Epoch 14, Step: 714, Loss: 0.016047805547714233, Lr:0.0001\n",
      "Epoch 14, Step: 715, Loss: 0.014733808115124702, Lr:0.0001\n",
      "Epoch 14, Step: 716, Loss: 0.14216788113117218, Lr:0.0001\n",
      "Epoch 14, Step: 717, Loss: 0.07478699833154678, Lr:0.0001\n",
      "Epoch 14, Step: 718, Loss: 0.13869145512580872, Lr:0.0001\n",
      "Epoch 14, Step: 719, Loss: 0.13023115694522858, Lr:0.0001\n",
      "Epoch 14, Step: 720, Loss: 0.06272716820240021, Lr:0.0001\n",
      "Epoch 14, Step: 721, Loss: 0.4325013756752014, Lr:0.0001\n",
      "Epoch 14, Step: 722, Loss: 0.4362794756889343, Lr:0.0001\n",
      "Epoch 14, Step: 723, Loss: 0.2731897532939911, Lr:0.0001\n",
      "Epoch 14, Step: 724, Loss: 0.029263459146022797, Lr:0.0001\n",
      "Epoch 14, Step: 725, Loss: 0.027653416618704796, Lr:0.0001\n",
      "Epoch 14, Step: 726, Loss: 0.12805543839931488, Lr:0.0001\n",
      "Epoch 14, Step: 727, Loss: 0.46565157175064087, Lr:0.0001\n",
      "Epoch 14, Step: 728, Loss: 0.06740845739841461, Lr:0.0001\n",
      "Epoch 14, Step: 729, Loss: 0.31736016273498535, Lr:0.0001\n",
      "Epoch 14, Step: 730, Loss: 0.03449743241071701, Lr:0.0001\n",
      "Epoch 14, Step: 731, Loss: 0.07820291817188263, Lr:0.0001\n",
      "Epoch 14, Step: 732, Loss: 0.07881534844636917, Lr:0.0001\n",
      "Epoch 14, Step: 733, Loss: 0.07702020555734634, Lr:0.0001\n",
      "Epoch 14, Step: 734, Loss: 0.15435124933719635, Lr:0.0001\n",
      "Epoch 14, Step: 735, Loss: 0.15928198397159576, Lr:0.0001\n",
      "Epoch 14, Step: 736, Loss: 0.6534398198127747, Lr:0.0001\n",
      "Epoch 14, Step: 737, Loss: 0.03363675996661186, Lr:0.0001\n",
      "Epoch 14, Step: 738, Loss: 0.1029825210571289, Lr:0.0001\n",
      "Epoch 14, Step: 739, Loss: 0.03608466684818268, Lr:0.0001\n",
      "Epoch 14, Step: 740, Loss: 0.00352375372312963, Lr:0.0001\n",
      "Epoch 14, Step: 741, Loss: 0.07979856431484222, Lr:0.0001\n",
      "Epoch 14, Step: 742, Loss: 0.16025638580322266, Lr:0.0001\n",
      "Epoch 14, Step: 743, Loss: 0.06552176177501678, Lr:0.0001\n",
      "Epoch 14, Step: 744, Loss: 0.12669049203395844, Lr:0.0001\n",
      "Epoch 14, Step: 745, Loss: 0.03029346652328968, Lr:0.0001\n",
      "Epoch 14, Step: 746, Loss: 0.2987399101257324, Lr:0.0001\n",
      "Epoch 14, Step: 747, Loss: 0.22260376811027527, Lr:0.0001\n",
      "Epoch 14, Step: 748, Loss: 0.8091122508049011, Lr:0.0001\n",
      "Epoch 14, Step: 749, Loss: 0.03489892929792404, Lr:0.0001\n",
      "Epoch 14, Step: 750, Loss: 0.4217243790626526, Lr:0.0001\n",
      "Epoch 14, Step: 751, Loss: 0.5631902813911438, Lr:0.0001\n",
      "Epoch 14, Step: 752, Loss: 0.14533551037311554, Lr:0.0001\n",
      "Epoch 14, Step: 753, Loss: 0.13779263198375702, Lr:0.0001\n",
      "Epoch 14, Step: 754, Loss: 0.26632827520370483, Lr:0.0001\n",
      "Epoch 14, Step: 755, Loss: 0.41619566082954407, Lr:0.0001\n",
      "Epoch 14, Step: 756, Loss: 0.07567307353019714, Lr:0.0001\n",
      "Epoch 14, Step: 757, Loss: 0.08091042935848236, Lr:0.0001\n",
      "Epoch 14, Step: 758, Loss: 0.06506569683551788, Lr:0.0001\n",
      "Epoch 14, Step: 759, Loss: 0.11829850822687149, Lr:0.0001\n",
      "Epoch 14, Step: 760, Loss: 0.12503722310066223, Lr:0.0001\n",
      "Epoch 14, Step: 761, Loss: 0.17893864214420319, Lr:0.0001\n",
      "Epoch 14, Step: 762, Loss: 0.08848948776721954, Lr:0.0001\n",
      "Epoch 14, Step: 763, Loss: 0.12788838148117065, Lr:0.0001\n",
      "Epoch 14, Step: 764, Loss: 0.09725429862737656, Lr:0.0001\n",
      "Epoch 14, Step: 765, Loss: 0.13785730302333832, Lr:0.0001\n",
      "Epoch 14, Step: 766, Loss: 0.06233071908354759, Lr:0.0001\n",
      "Epoch 14, Step: 767, Loss: 0.16284829378128052, Lr:0.0001\n",
      "Epoch 14, Step: 768, Loss: 0.10060286521911621, Lr:0.0001\n",
      "Epoch 14, Step: 769, Loss: 0.0626661479473114, Lr:0.0001\n",
      "Epoch 14, Step: 770, Loss: 0.015481531620025635, Lr:0.0001\n",
      "Epoch 14, Step: 771, Loss: 0.06003478169441223, Lr:0.0001\n",
      "Epoch 14, Step: 772, Loss: 0.11249272525310516, Lr:0.0001\n",
      "Epoch 14, Step: 773, Loss: 0.0803944319486618, Lr:0.0001\n",
      "Epoch 14, Step: 774, Loss: 0.1594744771718979, Lr:0.0001\n",
      "Epoch 14, Step: 775, Loss: 0.037829481065273285, Lr:0.0001\n",
      "Epoch 14, Step: 776, Loss: 0.5265263915061951, Lr:0.0001\n",
      "Epoch 14, Step: 777, Loss: 0.03762374073266983, Lr:0.0001\n",
      "Epoch 14, Step: 778, Loss: 0.04322171211242676, Lr:0.0001\n",
      "Epoch 14, Step: 779, Loss: 0.01853104867041111, Lr:0.0001\n",
      "Epoch 14, Step: 780, Loss: 0.1547134518623352, Lr:0.0001\n",
      "Epoch 14, Step: 781, Loss: 0.1352354884147644, Lr:0.0001\n",
      "Epoch 14, Step: 782, Loss: 0.03069302812218666, Lr:0.0001\n",
      "Epoch 14, Step: 783, Loss: 0.3209783732891083, Lr:0.0001\n",
      "Epoch 14, Step: 784, Loss: 0.03639139235019684, Lr:0.0001\n",
      "Epoch 14, Step: 785, Loss: 0.6338616609573364, Lr:0.0001\n",
      "Epoch 14, Step: 786, Loss: 0.2556048631668091, Lr:0.0001\n",
      "Epoch 14, Step: 787, Loss: 0.008617332205176353, Lr:0.0001\n",
      "Epoch 14, Step: 788, Loss: 0.18677999079227448, Lr:0.0001\n",
      "Epoch 14, Step: 789, Loss: 0.09381413459777832, Lr:0.0001\n",
      "Epoch 14, Step: 790, Loss: 0.03770501911640167, Lr:0.0001\n",
      "Epoch 14, Step: 791, Loss: 0.1350715011358261, Lr:0.0001\n",
      "Epoch 14, Step: 792, Loss: 0.17335964739322662, Lr:0.0001\n",
      "Epoch 14, Step: 793, Loss: 0.05327098071575165, Lr:0.0001\n",
      "Epoch 14, Step: 794, Loss: 0.02233074977993965, Lr:0.0001\n",
      "Epoch 14, Step: 795, Loss: 0.19202855229377747, Lr:0.0001\n",
      "Epoch 14, Step: 796, Loss: 0.13013556599617004, Lr:0.0001\n",
      "Epoch 14, Step: 797, Loss: 0.05688495188951492, Lr:0.0001\n",
      "Epoch 14, Step: 798, Loss: 0.05624593794345856, Lr:0.0001\n",
      "Epoch 14, Step: 799, Loss: 0.0377153716981411, Lr:0.0001\n",
      "Epoch 14, Step: 800, Loss: 0.17607276141643524, Lr:0.0001\n",
      "Epoch 14, Step: 801, Loss: 0.21805760264396667, Lr:0.0001\n",
      "Epoch 14, Step: 802, Loss: 0.01677357219159603, Lr:0.0001\n",
      "Epoch 14, Step: 803, Loss: 0.05762229114770889, Lr:0.0001\n",
      "Epoch 14, Step: 804, Loss: 0.2613662779331207, Lr:0.0001\n",
      "Epoch 14, Step: 805, Loss: 0.11411675065755844, Lr:0.0001\n",
      "Epoch 14, Step: 806, Loss: 0.03140927851200104, Lr:0.0001\n",
      "Epoch 14, Step: 807, Loss: 0.14023391902446747, Lr:0.0001\n",
      "Epoch 14, Step: 808, Loss: 0.2601325213909149, Lr:0.0001\n",
      "Epoch 14, Step: 809, Loss: 0.2408069670200348, Lr:0.0001\n",
      "Epoch 14, Step: 810, Loss: 0.11575712263584137, Lr:0.0001\n",
      "Epoch 14, Step: 811, Loss: 0.03532085195183754, Lr:0.0001\n",
      "Epoch 14, Step: 812, Loss: 0.2168104201555252, Lr:0.0001\n",
      "Epoch 14, Step: 813, Loss: 0.07229077070951462, Lr:0.0001\n",
      "Epoch 14, Step: 814, Loss: 0.10397440195083618, Lr:0.0001\n",
      "Epoch 14, Step: 815, Loss: 0.05268134921789169, Lr:0.0001\n",
      "Epoch 14, Step: 816, Loss: 0.30263978242874146, Lr:0.0001\n",
      "Epoch 14, Step: 817, Loss: 0.23219290375709534, Lr:0.0001\n",
      "Epoch 14, Step: 818, Loss: 0.08832968771457672, Lr:0.0001\n",
      "Epoch 14, Step: 819, Loss: 0.01824294775724411, Lr:0.0001\n",
      "Epoch 14, Step: 820, Loss: 0.021255990490317345, Lr:0.0001\n",
      "Epoch 14, Step: 821, Loss: 0.07317089289426804, Lr:0.0001\n",
      "Epoch 14, Step: 822, Loss: 0.21426302194595337, Lr:0.0001\n",
      "Epoch 14, Step: 823, Loss: 0.14062310755252838, Lr:0.0001\n",
      "Epoch 14, Step: 824, Loss: 0.3681068420410156, Lr:0.0001\n",
      "Epoch 14, Step: 825, Loss: 0.35493963956832886, Lr:0.0001\n",
      "Epoch 14, Step: 826, Loss: 0.04217752441763878, Lr:0.0001\n",
      "Epoch 14, Step: 827, Loss: 0.18020126223564148, Lr:0.0001\n",
      "Epoch 14, Step: 828, Loss: 0.2379295527935028, Lr:0.0001\n",
      "Epoch 14, Step: 829, Loss: 0.08279144763946533, Lr:0.0001\n",
      "Epoch 14, Step: 830, Loss: 0.137978196144104, Lr:0.0001\n",
      "Epoch 14, Step: 831, Loss: 0.16380871832370758, Lr:0.0001\n",
      "Epoch 14, Step: 832, Loss: 0.1889718919992447, Lr:0.0001\n",
      "Epoch 14, Step: 833, Loss: 0.0038898733910173178, Lr:0.0001\n",
      "Epoch 14, Step: 834, Loss: 0.04232720285654068, Lr:0.0001\n",
      "Epoch 14, Step: 835, Loss: 0.38323774933815, Lr:0.0001\n",
      "Epoch 14, Step: 836, Loss: 0.08374712616205215, Lr:0.0001\n",
      "Epoch 14, Step: 837, Loss: 0.18346315622329712, Lr:0.0001\n",
      "Epoch 14, Step: 838, Loss: 0.03401242569088936, Lr:0.0001\n",
      "Epoch 14, Step: 839, Loss: 0.3319591283798218, Lr:0.0001\n",
      "Epoch 14, Step: 840, Loss: 0.007779709994792938, Lr:0.0001\n",
      "Epoch 14, Step: 841, Loss: 0.0774763748049736, Lr:0.0001\n",
      "Epoch 14, Step: 842, Loss: 0.012710977345705032, Lr:0.0001\n",
      "Epoch 14, Step: 843, Loss: 0.16983583569526672, Lr:0.0001\n",
      "Epoch 14, Step: 844, Loss: 0.03734676539897919, Lr:0.0001\n",
      "Epoch 14, Step: 845, Loss: 0.01630030758678913, Lr:0.0001\n",
      "Epoch 14, Step: 846, Loss: 0.18286842107772827, Lr:0.0001\n",
      "Epoch 14, Step: 847, Loss: 0.052739281207323074, Lr:0.0001\n",
      "Epoch 14, Step: 848, Loss: 0.04833314195275307, Lr:0.0001\n",
      "Epoch 14, Step: 849, Loss: 0.16090431809425354, Lr:0.0001\n",
      "Epoch 14, Step: 850, Loss: 0.4071921706199646, Lr:0.0001\n",
      "Epoch 14, Step: 851, Loss: 0.07897978276014328, Lr:0.0001\n",
      "Epoch 14, Step: 852, Loss: 0.038745611906051636, Lr:0.0001\n",
      "Epoch 14, Step: 853, Loss: 0.05972004309296608, Lr:0.0001\n",
      "Epoch 14, Step: 854, Loss: 0.15891915559768677, Lr:0.0001\n",
      "Epoch 14, Step: 855, Loss: 0.6031333804130554, Lr:0.0001\n",
      "Epoch 14, Step: 856, Loss: 0.02600441314280033, Lr:0.0001\n",
      "Epoch 14, Step: 857, Loss: 0.06769920140504837, Lr:0.0001\n",
      "Epoch 14, Step: 858, Loss: 0.062490515410900116, Lr:0.0001\n",
      "Epoch 14, Step: 859, Loss: 0.12161584198474884, Lr:0.0001\n",
      "Epoch 14, Step: 860, Loss: 0.012814818881452084, Lr:0.0001\n",
      "Epoch 14, Step: 861, Loss: 0.017135923728346825, Lr:0.0001\n",
      "Epoch 14, Step: 862, Loss: 0.039706651121377945, Lr:0.0001\n",
      "Epoch 14, Step: 863, Loss: 0.03748651593923569, Lr:0.0001\n",
      "Epoch 14, Step: 864, Loss: 0.1064358502626419, Lr:0.0001\n",
      "Epoch 14, Step: 865, Loss: 0.08933047950267792, Lr:0.0001\n",
      "Epoch 14, Step: 866, Loss: 0.20785802602767944, Lr:0.0001\n",
      "Epoch 14, Step: 867, Loss: 0.34490856528282166, Lr:0.0001\n",
      "Epoch 14, Step: 868, Loss: 0.20288674533367157, Lr:0.0001\n",
      "Epoch 14, Step: 869, Loss: 0.18454013764858246, Lr:0.0001\n",
      "Epoch 14, Step: 870, Loss: 0.13306160271167755, Lr:0.0001\n",
      "Epoch 14, Step: 871, Loss: 0.15749134123325348, Lr:0.0001\n",
      "Epoch 14, Step: 872, Loss: 0.020326610654592514, Lr:0.0001\n",
      "Epoch 14, Step: 873, Loss: 0.013015915639698505, Lr:0.0001\n",
      "Epoch 14, Step: 874, Loss: 0.11749576032161713, Lr:0.0001\n",
      "Epoch 14, Step: 875, Loss: 0.0319482758641243, Lr:0.0001\n",
      "Epoch 14, Step: 876, Loss: 0.056649353355169296, Lr:0.0001\n",
      "Epoch 14, Step: 877, Loss: 0.013781270012259483, Lr:0.0001\n",
      "Epoch 14, Step: 878, Loss: 0.40959104895591736, Lr:0.0001\n",
      "Epoch 14, Step: 879, Loss: 0.17427290976047516, Lr:0.0001\n",
      "Epoch 14, Step: 880, Loss: 0.0061278692446649075, Lr:0.0001\n",
      "Epoch 14, Step: 881, Loss: 0.07527854293584824, Lr:0.0001\n",
      "Epoch 14, Step: 882, Loss: 0.03266756236553192, Lr:0.0001\n",
      "Epoch 14, Step: 883, Loss: 0.14729812741279602, Lr:0.0001\n",
      "Epoch 14, Step: 884, Loss: 0.1283697485923767, Lr:0.0001\n",
      "Epoch 14, Step: 885, Loss: 0.10220547765493393, Lr:0.0001\n",
      "Epoch 14, Step: 886, Loss: 0.13738957047462463, Lr:0.0001\n",
      "Epoch 14, Step: 887, Loss: 0.5674880146980286, Lr:0.0001\n",
      "Epoch 14, Step: 888, Loss: 0.20110087096691132, Lr:0.0001\n",
      "Epoch 14, Step: 889, Loss: 0.10544462502002716, Lr:0.0001\n",
      "Epoch 14, Step: 890, Loss: 0.11642686277627945, Lr:0.0001\n",
      "Epoch 14, Step: 891, Loss: 0.040989626199007034, Lr:0.0001\n",
      "Epoch 14, Step: 892, Loss: 0.008903355337679386, Lr:0.0001\n",
      "Epoch 14, Step: 893, Loss: 0.07276865839958191, Lr:0.0001\n",
      "Epoch 14, Step: 894, Loss: 0.2966718375682831, Lr:0.0001\n",
      "Epoch 14, Step: 895, Loss: 0.1434805542230606, Lr:0.0001\n",
      "Epoch 14, Step: 896, Loss: 0.10911241173744202, Lr:0.0001\n",
      "Epoch 14, Step: 897, Loss: 0.23395389318466187, Lr:0.0001\n",
      "Epoch 14, Step: 898, Loss: 0.10944735258817673, Lr:0.0001\n",
      "Epoch 14, Step: 899, Loss: 0.012204104103147984, Lr:0.0001\n",
      "Epoch 14, Step: 900, Loss: 0.08803649991750717, Lr:0.0001\n",
      "Epoch 14, Step: 901, Loss: 0.21073094010353088, Lr:0.0001\n",
      "Epoch 14, Step: 902, Loss: 0.11694692075252533, Lr:0.0001\n",
      "Epoch 14, Step: 903, Loss: 0.00933155044913292, Lr:0.0001\n",
      "Epoch 14, Step: 904, Loss: 0.08822507411241531, Lr:0.0001\n",
      "Epoch 14, Step: 905, Loss: 0.022097676992416382, Lr:0.0001\n",
      "Epoch 14, Step: 906, Loss: 0.02558922953903675, Lr:0.0001\n",
      "Epoch 14, Step: 907, Loss: 0.3311658501625061, Lr:0.0001\n",
      "Epoch 14, Step: 908, Loss: 0.049715593457221985, Lr:0.0001\n",
      "Epoch 14, Step: 909, Loss: 0.06563830375671387, Lr:0.0001\n",
      "Epoch 14, Step: 910, Loss: 0.0892367735505104, Lr:0.0001\n",
      "Epoch 14, Step: 911, Loss: 0.07561798393726349, Lr:0.0001\n",
      "Epoch 14, Step: 912, Loss: 0.07660448551177979, Lr:0.0001\n",
      "Epoch 14, Step: 913, Loss: 0.027134662494063377, Lr:0.0001\n",
      "Epoch 14, Step: 914, Loss: 0.18458351492881775, Lr:0.0001\n",
      "Epoch 14, Step: 915, Loss: 0.017730310559272766, Lr:0.0001\n",
      "Epoch 14, Step: 916, Loss: 0.016440587118268013, Lr:0.0001\n",
      "Epoch 14, Step: 917, Loss: 0.20481769740581512, Lr:0.0001\n",
      "Epoch 14, Step: 918, Loss: 0.05294618755578995, Lr:0.0001\n",
      "Epoch 14, Step: 919, Loss: 0.04069817438721657, Lr:0.0001\n",
      "Epoch 14, Step: 920, Loss: 0.07886730134487152, Lr:0.0001\n",
      "Epoch 14, Step: 921, Loss: 0.009618346579372883, Lr:0.0001\n",
      "Epoch 14, Step: 922, Loss: 0.06603807210922241, Lr:0.0001\n",
      "Epoch 14, Step: 923, Loss: 0.1492501199245453, Lr:0.0001\n",
      "Epoch 14, Step: 924, Loss: 0.0745433047413826, Lr:0.0001\n",
      "Epoch 14, Step: 925, Loss: 0.06266814470291138, Lr:0.0001\n",
      "Epoch 14, Step: 926, Loss: 0.047986168414354324, Lr:0.0001\n",
      "Epoch 14, Step: 927, Loss: 0.0912705585360527, Lr:0.0001\n",
      "Epoch 14, Step: 928, Loss: 0.07965211570262909, Lr:0.0001\n",
      "Epoch 14, Step: 929, Loss: 0.04944043979048729, Lr:0.0001\n",
      "Epoch 14, Step: 930, Loss: 0.011409645900130272, Lr:0.0001\n",
      "Epoch 14, Step: 931, Loss: 0.012061020359396935, Lr:0.0001\n",
      "Epoch 14, Step: 932, Loss: 0.1246112659573555, Lr:0.0001\n",
      "Epoch 14, Step: 933, Loss: 0.015879295766353607, Lr:0.0001\n",
      "Epoch 14, Step: 934, Loss: 0.2570294737815857, Lr:0.0001\n",
      "Epoch 14, Step: 935, Loss: 0.2054569274187088, Lr:0.0001\n",
      "Epoch 14, Step: 936, Loss: 0.10948342084884644, Lr:0.0001\n",
      "Epoch 14, Step: 937, Loss: 0.13432374596595764, Lr:0.0001\n",
      "Epoch 14, Step: 938, Loss: 0.02615082636475563, Lr:0.0001\n",
      "Epoch 14, Step: 939, Loss: 0.01893901824951172, Lr:0.0001\n",
      "Epoch 14, Step: 940, Loss: 0.0653841495513916, Lr:0.0001\n",
      "Epoch 14, Step: 941, Loss: 0.08050716668367386, Lr:0.0001\n",
      "Epoch 14, Step: 942, Loss: 0.06536468863487244, Lr:0.0001\n",
      "Epoch 14, Step: 943, Loss: 0.0966033786535263, Lr:0.0001\n",
      "Epoch 14, Step: 944, Loss: 0.07195810973644257, Lr:0.0001\n",
      "Epoch 14, Step: 945, Loss: 0.29659634828567505, Lr:0.0001\n",
      "Epoch 14, Step: 946, Loss: 0.14150674641132355, Lr:0.0001\n",
      "Epoch 14, Step: 947, Loss: 0.016259320080280304, Lr:0.0001\n",
      "Epoch 14, Step: 948, Loss: 0.070695661008358, Lr:0.0001\n",
      "Epoch 14, Step: 949, Loss: 0.03666923940181732, Lr:0.0001\n",
      "Epoch 14, Step: 950, Loss: 0.01878259889781475, Lr:0.0001\n",
      "Epoch 14, Step: 951, Loss: 0.08064653724431992, Lr:0.0001\n",
      "Epoch 14, Step: 952, Loss: 0.05900305509567261, Lr:0.0001\n",
      "Epoch 14, Step: 953, Loss: 0.07326732575893402, Lr:0.0001\n",
      "Epoch 14, Step: 954, Loss: 0.0726659893989563, Lr:0.0001\n",
      "Epoch 14, Step: 955, Loss: 0.08912937343120575, Lr:0.0001\n",
      "Epoch 14, Step: 956, Loss: 0.040162090212106705, Lr:0.0001\n",
      "Epoch 14, Step: 957, Loss: 0.23732313513755798, Lr:0.0001\n",
      "Epoch 14, Step: 958, Loss: 0.08789317309856415, Lr:0.0001\n",
      "Epoch 14, Step: 959, Loss: 0.005689989309757948, Lr:0.0001\n",
      "Epoch 14, Step: 960, Loss: 0.03954880312085152, Lr:0.0001\n",
      "Epoch 14, Step: 961, Loss: 0.0032106328289955854, Lr:0.0001\n",
      "Epoch 14, Step: 962, Loss: 0.27484431862831116, Lr:0.0001\n",
      "Epoch 14, Step: 963, Loss: 0.006012279074639082, Lr:0.0001\n",
      "Epoch 14, Step: 964, Loss: 0.04997783154249191, Lr:0.0001\n",
      "Epoch 14, Step: 965, Loss: 0.033673882484436035, Lr:0.0001\n",
      "Epoch 14, Step: 966, Loss: 0.1349371373653412, Lr:0.0001\n",
      "Epoch 14, Step: 967, Loss: 0.16939587891101837, Lr:0.0001\n",
      "Epoch 14, Step: 968, Loss: 0.3875366449356079, Lr:0.0001\n",
      "Epoch 14, Step: 969, Loss: 0.1786504089832306, Lr:0.0001\n",
      "Epoch 14, Step: 970, Loss: 0.08492454141378403, Lr:0.0001\n",
      "Epoch 14, Step: 971, Loss: 0.3041386902332306, Lr:0.0001\n",
      "Epoch 14, Step: 972, Loss: 0.147180438041687, Lr:0.0001\n",
      "Epoch 14, Step: 973, Loss: 0.19546948373317719, Lr:0.0001\n",
      "Epoch 14, Step: 974, Loss: 0.13360168039798737, Lr:0.0001\n",
      "Epoch 14, Step: 975, Loss: 0.08704571425914764, Lr:0.0001\n",
      "Epoch 14, Step: 976, Loss: 0.09599786251783371, Lr:0.0001\n",
      "Epoch 14, Step: 977, Loss: 0.05125027522444725, Lr:0.0001\n",
      "Epoch 14, Step: 978, Loss: 0.18873904645442963, Lr:0.0001\n",
      "Epoch 14, Step: 979, Loss: 0.26064956188201904, Lr:0.0001\n",
      "Epoch 14, Step: 980, Loss: 0.11006243526935577, Lr:0.0001\n",
      "Epoch 14, Step: 981, Loss: 0.009468025527894497, Lr:0.0001\n",
      "Epoch 14, Step: 982, Loss: 0.026180176064372063, Lr:0.0001\n",
      "Epoch 14, Step: 983, Loss: 0.010432771407067776, Lr:0.0001\n",
      "Epoch 14, Step: 984, Loss: 0.35933220386505127, Lr:0.0001\n",
      "Epoch 14, Step: 985, Loss: 0.023730657994747162, Lr:0.0001\n",
      "Epoch 14, Step: 986, Loss: 0.04847200959920883, Lr:0.0001\n",
      "Epoch 14, Step: 987, Loss: 0.3638264238834381, Lr:0.0001\n",
      "Epoch 14, Step: 988, Loss: 0.034113965928554535, Lr:0.0001\n",
      "Epoch 14, Step: 989, Loss: 0.028274044394493103, Lr:0.0001\n",
      "Epoch 14, Step: 990, Loss: 0.00947729591280222, Lr:0.0001\n",
      "Epoch 14, Step: 991, Loss: 0.38151678442955017, Lr:0.0001\n",
      "Epoch 14, Step: 992, Loss: 0.03447336331009865, Lr:0.0001\n",
      "Epoch 14, Step: 993, Loss: 0.031448256224393845, Lr:0.0001\n",
      "Epoch 14, Step: 994, Loss: 0.1513008028268814, Lr:0.0001\n",
      "Epoch 14, Step: 995, Loss: 0.009243362583220005, Lr:0.0001\n",
      "Epoch 14, Step: 996, Loss: 0.21118028461933136, Lr:0.0001\n",
      "Epoch 14, Step: 997, Loss: 0.03705909103155136, Lr:0.0001\n",
      "Epoch 14, Step: 998, Loss: 0.10774622112512589, Lr:0.0001\n",
      "Epoch 14, Step: 999, Loss: 0.09313113987445831, Lr:0.0001\n",
      "Epoch 14, Step: 1000, Loss: 0.2392391860485077, Lr:0.0001\n",
      "Epoch 14, Step: 1001, Loss: 0.22260749340057373, Lr:0.0001\n",
      "Epoch 14, Step: 1002, Loss: 0.013948898762464523, Lr:0.0001\n",
      "Epoch 14, Step: 1003, Loss: 0.039114948362112045, Lr:0.0001\n",
      "Epoch 14, Step: 1004, Loss: 0.04105806723237038, Lr:0.0001\n",
      "Epoch 14, Step: 1005, Loss: 0.1433524787425995, Lr:0.0001\n",
      "Epoch 14, Step: 1006, Loss: 0.007687663659453392, Lr:0.0001\n",
      "Epoch 14, Step: 1007, Loss: 0.024490583688020706, Lr:0.0001\n",
      "Epoch 14, Step: 1008, Loss: 0.18058784306049347, Lr:0.0001\n",
      "Epoch 14, Step: 1009, Loss: 0.8714705109596252, Lr:0.0001\n",
      "Epoch 14, Step: 1010, Loss: 0.21240635216236115, Lr:0.0001\n",
      "Epoch 14, Step: 1011, Loss: 0.1575034260749817, Lr:0.0001\n",
      "Epoch 14, Step: 1012, Loss: 0.2345098853111267, Lr:0.0001\n",
      "Epoch 14, Step: 1013, Loss: 0.11500416696071625, Lr:0.0001\n",
      "Epoch 14, Step: 1014, Loss: 0.024754304438829422, Lr:0.0001\n",
      "Epoch 14, Step: 1015, Loss: 0.06594540923833847, Lr:0.0001\n",
      "Epoch 14, Step: 1016, Loss: 0.05137299746274948, Lr:0.0001\n",
      "Epoch 14, Step: 1017, Loss: 0.2389504313468933, Lr:0.0001\n",
      "Epoch 14, Step: 1018, Loss: 0.08424458652734756, Lr:0.0001\n",
      "Epoch 14, Step: 1019, Loss: 0.04653997719287872, Lr:0.0001\n",
      "Epoch 14, Step: 1020, Loss: 0.1902329921722412, Lr:0.0001\n",
      "Epoch 14, Step: 1021, Loss: 0.19111105799674988, Lr:0.0001\n",
      "Epoch 14, Step: 1022, Loss: 0.12509970366954803, Lr:0.0001\n",
      "Epoch 14, Step: 1023, Loss: 0.12077343463897705, Lr:0.0001\n",
      "Epoch 14, Step: 1024, Loss: 0.3271665573120117, Lr:0.0001\n",
      "Epoch 14, Step: 1025, Loss: 0.1531490832567215, Lr:0.0001\n",
      "Epoch 14, Step: 1026, Loss: 0.01835394836962223, Lr:0.0001\n",
      "Epoch 14, Step: 1027, Loss: 0.11742953956127167, Lr:0.0001\n",
      "Epoch 14, Step: 1028, Loss: 0.06720030307769775, Lr:0.0001\n",
      "Epoch 14, Step: 1029, Loss: 0.21596868336200714, Lr:0.0001\n",
      "Epoch 14, Step: 1030, Loss: 0.08571420609951019, Lr:0.0001\n",
      "Epoch 14, Step: 1031, Loss: 0.3057294487953186, Lr:0.0001\n",
      "Epoch 14, Step: 1032, Loss: 0.14804834127426147, Lr:0.0001\n",
      "Epoch 14, Step: 1033, Loss: 0.04202602431178093, Lr:0.0001\n",
      "Epoch 14, Step: 1034, Loss: 0.26719027757644653, Lr:0.0001\n",
      "Epoch 14, Step: 1035, Loss: 0.01310566533356905, Lr:0.0001\n",
      "Epoch 14, Step: 1036, Loss: 0.28293052315711975, Lr:0.0001\n",
      "Epoch 14, Step: 1037, Loss: 0.22308996319770813, Lr:0.0001\n",
      "Epoch 14, Step: 1038, Loss: 0.15907420217990875, Lr:0.0001\n",
      "Epoch 14, Step: 1039, Loss: 0.1581403911113739, Lr:0.0001\n",
      "Epoch 14, Step: 1040, Loss: 0.12715467810630798, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 14\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:15 loss: 0.1796 (0.1796) acc1: 87.5000 (87.5000) acc5: 100.0000 (100.0000) time: 0.2736 data: 0.1056 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.0000 (0.0166) acc1: 100.0000 (98.8636) acc5: 100.0000 (100.0000) time: 0.2856 data: 0.1107 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0001 (0.0642) acc1: 100.0000 (97.9167) acc5: 100.0000 (100.0000) time: 0.2865 data: 0.1107 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.0384 (0.1777) acc1: 93.7500 (94.1532) acc5: 100.0000 (100.0000) time: 0.2915 data: 0.1145 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.1905 (0.1664) acc1: 93.7500 (94.2073) acc5: 100.0000 (100.0000) time: 0.3019 data: 0.1210 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.1064 (0.1733) acc1: 93.7500 (93.6275) acc5: 100.0000 (100.0000) time: 0.3018 data: 0.1203 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.1064 (0.1847) acc1: 93.7500 (93.3031) acc5: 100.0000 (100.0000) time: 0.2848 data: 0.1134 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.2898 s / it)\n",
      "* Acc@1 93.303 Acc@5 100.000 loss 0.185\n",
      "Accuracy of the network on the 881 test image: 93.3%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 15, Step: 0, Loss: 0.09300445765256882, Lr:0.0001\n",
      "Epoch 15, Step: 1, Loss: 0.23898570239543915, Lr:0.0001\n",
      "Epoch 15, Step: 2, Loss: 0.005598537623882294, Lr:0.0001\n",
      "Epoch 15, Step: 3, Loss: 0.030316343531012535, Lr:0.0001\n",
      "Epoch 15, Step: 4, Loss: 0.23816022276878357, Lr:0.0001\n",
      "Epoch 15, Step: 5, Loss: 0.05392196774482727, Lr:0.0001\n",
      "Epoch 15, Step: 6, Loss: 0.04197831079363823, Lr:0.0001\n",
      "Epoch 15, Step: 7, Loss: 0.1487581431865692, Lr:0.0001\n",
      "Epoch 15, Step: 8, Loss: 0.0438888855278492, Lr:0.0001\n",
      "Epoch 15, Step: 9, Loss: 0.050216201692819595, Lr:0.0001\n",
      "Epoch 15, Step: 10, Loss: 0.057977620512247086, Lr:0.0001\n",
      "Epoch 15, Step: 11, Loss: 0.06553109735250473, Lr:0.0001\n",
      "Epoch 15, Step: 12, Loss: 0.021178048104047775, Lr:0.0001\n",
      "Epoch 15, Step: 13, Loss: 0.14453360438346863, Lr:0.0001\n",
      "Epoch 15, Step: 14, Loss: 0.05059472471475601, Lr:0.0001\n",
      "Epoch 15, Step: 15, Loss: 0.11830979585647583, Lr:0.0001\n",
      "Epoch 15, Step: 16, Loss: 0.018742011860013008, Lr:0.0001\n",
      "Epoch 15, Step: 17, Loss: 0.10889636725187302, Lr:0.0001\n",
      "Epoch 15, Step: 18, Loss: 0.011813321150839329, Lr:0.0001\n",
      "Epoch 15, Step: 19, Loss: 0.11205845326185226, Lr:0.0001\n",
      "Epoch 15, Step: 20, Loss: 0.005725993309170008, Lr:0.0001\n",
      "Epoch 15, Step: 21, Loss: 0.03422188013792038, Lr:0.0001\n",
      "Epoch 15, Step: 22, Loss: 0.18500439822673798, Lr:0.0001\n",
      "Epoch 15, Step: 23, Loss: 0.24911260604858398, Lr:0.0001\n",
      "Epoch 15, Step: 24, Loss: 0.01893194578588009, Lr:0.0001\n",
      "Epoch 15, Step: 25, Loss: 0.05365524813532829, Lr:0.0001\n",
      "Epoch 15, Step: 26, Loss: 0.058613453060388565, Lr:0.0001\n",
      "Epoch 15, Step: 27, Loss: 0.08764335513114929, Lr:0.0001\n",
      "Epoch 15, Step: 28, Loss: 0.3762041926383972, Lr:0.0001\n",
      "Epoch 15, Step: 29, Loss: 0.09692448377609253, Lr:0.0001\n",
      "Epoch 15, Step: 30, Loss: 0.13921032845973969, Lr:0.0001\n",
      "Epoch 15, Step: 31, Loss: 0.08322051912546158, Lr:0.0001\n",
      "Epoch 15, Step: 32, Loss: 0.2794737219810486, Lr:0.0001\n",
      "Epoch 15, Step: 33, Loss: 0.05556487664580345, Lr:0.0001\n",
      "Epoch 15, Step: 34, Loss: 0.1252424120903015, Lr:0.0001\n",
      "Epoch 15, Step: 35, Loss: 0.015492451377213001, Lr:0.0001\n",
      "Epoch 15, Step: 36, Loss: 0.026731334626674652, Lr:0.0001\n",
      "Epoch 15, Step: 37, Loss: 0.018319567665457726, Lr:0.0001\n",
      "Epoch 15, Step: 38, Loss: 0.19347244501113892, Lr:0.0001\n",
      "Epoch 15, Step: 39, Loss: 0.06268596649169922, Lr:0.0001\n",
      "Epoch 15, Step: 40, Loss: 0.18599821627140045, Lr:0.0001\n",
      "Epoch 15, Step: 41, Loss: 0.14163565635681152, Lr:0.0001\n",
      "Epoch 15, Step: 42, Loss: 0.030754264444112778, Lr:0.0001\n",
      "Epoch 15, Step: 43, Loss: 0.09464611858129501, Lr:0.0001\n",
      "Epoch 15, Step: 44, Loss: 0.09865286201238632, Lr:0.0001\n",
      "Epoch 15, Step: 45, Loss: 0.024617958813905716, Lr:0.0001\n",
      "Epoch 15, Step: 46, Loss: 0.005808770190924406, Lr:0.0001\n",
      "Epoch 15, Step: 47, Loss: 0.12832851707935333, Lr:0.0001\n",
      "Epoch 15, Step: 48, Loss: 0.13227960467338562, Lr:0.0001\n",
      "Epoch 15, Step: 49, Loss: 0.08045525848865509, Lr:0.0001\n",
      "Epoch 15, Step: 50, Loss: 0.01727156527340412, Lr:0.0001\n",
      "Epoch 15, Step: 51, Loss: 0.09827752411365509, Lr:0.0001\n",
      "Epoch 15, Step: 52, Loss: 0.025451237335801125, Lr:0.0001\n",
      "Epoch 15, Step: 53, Loss: 0.16417823731899261, Lr:0.0001\n",
      "Epoch 15, Step: 54, Loss: 0.036195844411849976, Lr:0.0001\n",
      "Epoch 15, Step: 55, Loss: 0.1800953447818756, Lr:0.0001\n",
      "Epoch 15, Step: 56, Loss: 0.003450823714956641, Lr:0.0001\n",
      "Epoch 15, Step: 57, Loss: 0.029132191091775894, Lr:0.0001\n",
      "Epoch 15, Step: 58, Loss: 0.0004633205244317651, Lr:0.0001\n",
      "Epoch 15, Step: 59, Loss: 0.06837160885334015, Lr:0.0001\n",
      "Epoch 15, Step: 60, Loss: 0.20424385368824005, Lr:0.0001\n",
      "Epoch 15, Step: 61, Loss: 0.006423661019653082, Lr:0.0001\n",
      "Epoch 15, Step: 62, Loss: 0.01175776682794094, Lr:0.0001\n",
      "Epoch 15, Step: 63, Loss: 0.08768663555383682, Lr:0.0001\n",
      "Epoch 15, Step: 64, Loss: 0.3137361407279968, Lr:0.0001\n",
      "Epoch 15, Step: 65, Loss: 0.024798724800348282, Lr:0.0001\n",
      "Epoch 15, Step: 66, Loss: 0.05020990967750549, Lr:0.0001\n",
      "Epoch 15, Step: 67, Loss: 0.21692883968353271, Lr:0.0001\n",
      "Epoch 15, Step: 68, Loss: 0.04969889670610428, Lr:0.0001\n",
      "Epoch 15, Step: 69, Loss: 0.15787920355796814, Lr:0.0001\n",
      "Epoch 15, Step: 70, Loss: 0.0636754259467125, Lr:0.0001\n",
      "Epoch 15, Step: 71, Loss: 0.013264039531350136, Lr:0.0001\n",
      "Epoch 15, Step: 72, Loss: 0.037036433815956116, Lr:0.0001\n",
      "Epoch 15, Step: 73, Loss: 0.1598058044910431, Lr:0.0001\n",
      "Epoch 15, Step: 74, Loss: 0.16333742439746857, Lr:0.0001\n",
      "Epoch 15, Step: 75, Loss: 0.04687729850411415, Lr:0.0001\n",
      "Epoch 15, Step: 76, Loss: 0.01666337065398693, Lr:0.0001\n",
      "Epoch 15, Step: 77, Loss: 0.24442769587039948, Lr:0.0001\n",
      "Epoch 15, Step: 78, Loss: 0.05874069780111313, Lr:0.0001\n",
      "Epoch 15, Step: 79, Loss: 0.5140376687049866, Lr:0.0001\n",
      "Epoch 15, Step: 80, Loss: 0.10594035685062408, Lr:0.0001\n",
      "Epoch 15, Step: 81, Loss: 0.10743196308612823, Lr:0.0001\n",
      "Epoch 15, Step: 82, Loss: 0.11034844070672989, Lr:0.0001\n",
      "Epoch 15, Step: 83, Loss: 0.03769079968333244, Lr:0.0001\n",
      "Epoch 15, Step: 84, Loss: 0.050691232085227966, Lr:0.0001\n",
      "Epoch 15, Step: 85, Loss: 0.08228670805692673, Lr:0.0001\n",
      "Epoch 15, Step: 86, Loss: 0.054857250303030014, Lr:0.0001\n",
      "Epoch 15, Step: 87, Loss: 0.054859012365341187, Lr:0.0001\n",
      "Epoch 15, Step: 88, Loss: 0.060677364468574524, Lr:0.0001\n",
      "Epoch 15, Step: 89, Loss: 0.05377494543790817, Lr:0.0001\n",
      "Epoch 15, Step: 90, Loss: 0.015996787697076797, Lr:0.0001\n",
      "Epoch 15, Step: 91, Loss: 0.05856690555810928, Lr:0.0001\n",
      "Epoch 15, Step: 92, Loss: 0.4916476905345917, Lr:0.0001\n",
      "Epoch 15, Step: 93, Loss: 0.2443481832742691, Lr:0.0001\n",
      "Epoch 15, Step: 94, Loss: 0.11545106023550034, Lr:0.0001\n",
      "Epoch 15, Step: 95, Loss: 0.02223701775074005, Lr:0.0001\n",
      "Epoch 15, Step: 96, Loss: 0.1757897436618805, Lr:0.0001\n",
      "Epoch 15, Step: 97, Loss: 0.3538348972797394, Lr:0.0001\n",
      "Epoch 15, Step: 98, Loss: 0.3328944444656372, Lr:0.0001\n",
      "Epoch 15, Step: 99, Loss: 0.35238170623779297, Lr:0.0001\n",
      "Epoch 15, Step: 100, Loss: 0.17484289407730103, Lr:0.0001\n",
      "Epoch 15, Step: 101, Loss: 0.13270515203475952, Lr:0.0001\n",
      "Epoch 15, Step: 102, Loss: 0.08483678847551346, Lr:0.0001\n",
      "Epoch 15, Step: 103, Loss: 0.0657271072268486, Lr:0.0001\n",
      "Epoch 15, Step: 104, Loss: 0.6316695809364319, Lr:0.0001\n",
      "Epoch 15, Step: 105, Loss: 0.03915000706911087, Lr:0.0001\n",
      "Epoch 15, Step: 106, Loss: 0.011056178249418736, Lr:0.0001\n",
      "Epoch 15, Step: 107, Loss: 0.04636432230472565, Lr:0.0001\n",
      "Epoch 15, Step: 108, Loss: 0.1759253591299057, Lr:0.0001\n",
      "Epoch 15, Step: 109, Loss: 0.17098934948444366, Lr:0.0001\n",
      "Epoch 15, Step: 110, Loss: 0.24650555849075317, Lr:0.0001\n",
      "Epoch 15, Step: 111, Loss: 0.0215588491410017, Lr:0.0001\n",
      "Epoch 15, Step: 112, Loss: 0.16576647758483887, Lr:0.0001\n",
      "Epoch 15, Step: 113, Loss: 0.06433424353599548, Lr:0.0001\n",
      "Epoch 15, Step: 114, Loss: 0.1094764918088913, Lr:0.0001\n",
      "Epoch 15, Step: 115, Loss: 0.06125246733427048, Lr:0.0001\n",
      "Epoch 15, Step: 116, Loss: 0.2326326221227646, Lr:0.0001\n",
      "Epoch 15, Step: 117, Loss: 0.11674153804779053, Lr:0.0001\n",
      "Epoch 15, Step: 118, Loss: 0.33594396710395813, Lr:0.0001\n",
      "Epoch 15, Step: 119, Loss: 0.09724632650613785, Lr:0.0001\n",
      "Epoch 15, Step: 120, Loss: 0.18095915019512177, Lr:0.0001\n",
      "Epoch 15, Step: 121, Loss: 0.38791558146476746, Lr:0.0001\n",
      "Epoch 15, Step: 122, Loss: 0.17121650278568268, Lr:0.0001\n",
      "Epoch 15, Step: 123, Loss: 0.10835179686546326, Lr:0.0001\n",
      "Epoch 15, Step: 124, Loss: 0.04487483203411102, Lr:0.0001\n",
      "Epoch 15, Step: 125, Loss: 0.026341361925005913, Lr:0.0001\n",
      "Epoch 15, Step: 126, Loss: 0.18245385587215424, Lr:0.0001\n",
      "Epoch 15, Step: 127, Loss: 0.16839203238487244, Lr:0.0001\n",
      "Epoch 15, Step: 128, Loss: 0.06530112773180008, Lr:0.0001\n",
      "Epoch 15, Step: 129, Loss: 0.02097763679921627, Lr:0.0001\n",
      "Epoch 15, Step: 130, Loss: 0.18538619577884674, Lr:0.0001\n",
      "Epoch 15, Step: 131, Loss: 0.24277924001216888, Lr:0.0001\n",
      "Epoch 15, Step: 132, Loss: 0.08595707267522812, Lr:0.0001\n",
      "Epoch 15, Step: 133, Loss: 0.2234696000814438, Lr:0.0001\n",
      "Epoch 15, Step: 134, Loss: 0.03638148307800293, Lr:0.0001\n",
      "Epoch 15, Step: 135, Loss: 0.005523600149899721, Lr:0.0001\n",
      "Epoch 15, Step: 136, Loss: 0.02594057284295559, Lr:0.0001\n",
      "Epoch 15, Step: 137, Loss: 0.162149578332901, Lr:0.0001\n",
      "Epoch 15, Step: 138, Loss: 0.2170013189315796, Lr:0.0001\n",
      "Epoch 15, Step: 139, Loss: 0.04018674045801163, Lr:0.0001\n",
      "Epoch 15, Step: 140, Loss: 0.10476406663656235, Lr:0.0001\n",
      "Epoch 15, Step: 141, Loss: 0.09969741851091385, Lr:0.0001\n",
      "Epoch 15, Step: 142, Loss: 0.2741926908493042, Lr:0.0001\n",
      "Epoch 15, Step: 143, Loss: 0.005329254548996687, Lr:0.0001\n",
      "Epoch 15, Step: 144, Loss: 0.1569945216178894, Lr:0.0001\n",
      "Epoch 15, Step: 145, Loss: 0.06751454621553421, Lr:0.0001\n",
      "Epoch 15, Step: 146, Loss: 0.18515454232692719, Lr:0.0001\n",
      "Epoch 15, Step: 147, Loss: 0.12704874575138092, Lr:0.0001\n",
      "Epoch 15, Step: 148, Loss: 0.026806950569152832, Lr:0.0001\n",
      "Epoch 15, Step: 149, Loss: 0.3468714654445648, Lr:0.0001\n",
      "Epoch 15, Step: 150, Loss: 0.05527465045452118, Lr:0.0001\n",
      "Epoch 15, Step: 151, Loss: 0.08684009313583374, Lr:0.0001\n",
      "Epoch 15, Step: 152, Loss: 0.1599503755569458, Lr:0.0001\n",
      "Epoch 15, Step: 153, Loss: 0.060471341013908386, Lr:0.0001\n",
      "Epoch 15, Step: 154, Loss: 0.14722409844398499, Lr:0.0001\n",
      "Epoch 15, Step: 155, Loss: 0.032154832035303116, Lr:0.0001\n",
      "Epoch 15, Step: 156, Loss: 0.10448155552148819, Lr:0.0001\n",
      "Epoch 15, Step: 157, Loss: 0.041511908173561096, Lr:0.0001\n",
      "Epoch 15, Step: 158, Loss: 0.049634478986263275, Lr:0.0001\n",
      "Epoch 15, Step: 159, Loss: 0.0640835389494896, Lr:0.0001\n",
      "Epoch 15, Step: 160, Loss: 0.047067537903785706, Lr:0.0001\n",
      "Epoch 15, Step: 161, Loss: 0.1358797550201416, Lr:0.0001\n",
      "Epoch 15, Step: 162, Loss: 0.03490841016173363, Lr:0.0001\n",
      "Epoch 15, Step: 163, Loss: 0.04328536242246628, Lr:0.0001\n",
      "Epoch 15, Step: 164, Loss: 0.1880650520324707, Lr:0.0001\n",
      "Epoch 15, Step: 165, Loss: 0.14684760570526123, Lr:0.0001\n",
      "Epoch 15, Step: 166, Loss: 0.03394179418683052, Lr:0.0001\n",
      "Epoch 15, Step: 167, Loss: 0.12278826534748077, Lr:0.0001\n",
      "Epoch 15, Step: 168, Loss: 0.08347290754318237, Lr:0.0001\n",
      "Epoch 15, Step: 169, Loss: 0.1205974742770195, Lr:0.0001\n",
      "Epoch 15, Step: 170, Loss: 0.026517968624830246, Lr:0.0001\n",
      "Epoch 15, Step: 171, Loss: 0.11179794371128082, Lr:0.0001\n",
      "Epoch 15, Step: 172, Loss: 0.2284625768661499, Lr:0.0001\n",
      "Epoch 15, Step: 173, Loss: 0.01597650721669197, Lr:0.0001\n",
      "Epoch 15, Step: 174, Loss: 0.17846745252609253, Lr:0.0001\n",
      "Epoch 15, Step: 175, Loss: 0.1012711226940155, Lr:0.0001\n",
      "Epoch 15, Step: 176, Loss: 0.18629270792007446, Lr:0.0001\n",
      "Epoch 15, Step: 177, Loss: 0.022211825475096703, Lr:0.0001\n",
      "Epoch 15, Step: 178, Loss: 0.3013005256652832, Lr:0.0001\n",
      "Epoch 15, Step: 179, Loss: 0.05882752314209938, Lr:0.0001\n",
      "Epoch 15, Step: 180, Loss: 0.06642871350049973, Lr:0.0001\n",
      "Epoch 15, Step: 181, Loss: 0.017081914469599724, Lr:0.0001\n",
      "Epoch 15, Step: 182, Loss: 0.1334599107503891, Lr:0.0001\n",
      "Epoch 15, Step: 183, Loss: 0.11720112711191177, Lr:0.0001\n",
      "Epoch 15, Step: 184, Loss: 0.12063121050596237, Lr:0.0001\n",
      "Epoch 15, Step: 185, Loss: 0.10558798164129257, Lr:0.0001\n",
      "Epoch 15, Step: 186, Loss: 0.030025716871023178, Lr:0.0001\n",
      "Epoch 15, Step: 187, Loss: 0.021847926080226898, Lr:0.0001\n",
      "Epoch 15, Step: 188, Loss: 0.15005850791931152, Lr:0.0001\n",
      "Epoch 15, Step: 189, Loss: 0.02760501392185688, Lr:0.0001\n",
      "Epoch 15, Step: 190, Loss: 0.12976115942001343, Lr:0.0001\n",
      "Epoch 15, Step: 191, Loss: 0.2248096913099289, Lr:0.0001\n",
      "Epoch 15, Step: 192, Loss: 0.0043371012434363365, Lr:0.0001\n",
      "Epoch 15, Step: 193, Loss: 0.04930322989821434, Lr:0.0001\n",
      "Epoch 15, Step: 194, Loss: 0.028118712827563286, Lr:0.0001\n",
      "Epoch 15, Step: 195, Loss: 0.4023066461086273, Lr:0.0001\n",
      "Epoch 15, Step: 196, Loss: 0.019405024126172066, Lr:0.0001\n",
      "Epoch 15, Step: 197, Loss: 0.038705404847860336, Lr:0.0001\n",
      "Epoch 15, Step: 198, Loss: 0.043498069047927856, Lr:0.0001\n",
      "Epoch 15, Step: 199, Loss: 0.0834909975528717, Lr:0.0001\n",
      "Epoch 15, Step: 200, Loss: 0.05044335499405861, Lr:0.0001\n",
      "Epoch 15, Step: 201, Loss: 0.07985979318618774, Lr:0.0001\n",
      "Epoch 15, Step: 202, Loss: 0.14482992887496948, Lr:0.0001\n",
      "Epoch 15, Step: 203, Loss: 0.035433437675237656, Lr:0.0001\n",
      "Epoch 15, Step: 204, Loss: 0.2500412166118622, Lr:0.0001\n",
      "Epoch 15, Step: 205, Loss: 0.4056720733642578, Lr:0.0001\n",
      "Epoch 15, Step: 206, Loss: 0.02403969131410122, Lr:0.0001\n",
      "Epoch 15, Step: 207, Loss: 0.04361166059970856, Lr:0.0001\n",
      "Epoch 15, Step: 208, Loss: 0.04471801966428757, Lr:0.0001\n",
      "Epoch 15, Step: 209, Loss: 0.047354601323604584, Lr:0.0001\n",
      "Epoch 15, Step: 210, Loss: 0.0987326130270958, Lr:0.0001\n",
      "Epoch 15, Step: 211, Loss: 0.07487284392118454, Lr:0.0001\n",
      "Epoch 15, Step: 212, Loss: 0.015220418572425842, Lr:0.0001\n",
      "Epoch 15, Step: 213, Loss: 0.13339678943157196, Lr:0.0001\n",
      "Epoch 15, Step: 214, Loss: 0.07751387357711792, Lr:0.0001\n",
      "Epoch 15, Step: 215, Loss: 0.02293800376355648, Lr:0.0001\n",
      "Epoch 15, Step: 216, Loss: 0.09372447431087494, Lr:0.0001\n",
      "Epoch 15, Step: 217, Loss: 0.07177186012268066, Lr:0.0001\n",
      "Epoch 15, Step: 218, Loss: 0.07239554077386856, Lr:0.0001\n",
      "Epoch 15, Step: 219, Loss: 0.04724714905023575, Lr:0.0001\n",
      "Epoch 15, Step: 220, Loss: 0.20867878198623657, Lr:0.0001\n",
      "Epoch 15, Step: 221, Loss: 0.07011853903532028, Lr:0.0001\n",
      "Epoch 15, Step: 222, Loss: 0.1473071128129959, Lr:0.0001\n",
      "Epoch 15, Step: 223, Loss: 0.026756126433610916, Lr:0.0001\n",
      "Epoch 15, Step: 224, Loss: 0.10778285562992096, Lr:0.0001\n",
      "Epoch 15, Step: 225, Loss: 0.3485422432422638, Lr:0.0001\n",
      "Epoch 15, Step: 226, Loss: 0.060749053955078125, Lr:0.0001\n",
      "Epoch 15, Step: 227, Loss: 0.06748409569263458, Lr:0.0001\n",
      "Epoch 15, Step: 228, Loss: 0.09001024812459946, Lr:0.0001\n",
      "Epoch 15, Step: 229, Loss: 0.10005354136228561, Lr:0.0001\n",
      "Epoch 15, Step: 230, Loss: 0.08585021644830704, Lr:0.0001\n",
      "Epoch 15, Step: 231, Loss: 0.06657955050468445, Lr:0.0001\n",
      "Epoch 15, Step: 232, Loss: 0.10707221925258636, Lr:0.0001\n",
      "Epoch 15, Step: 233, Loss: 0.0030927546322345734, Lr:0.0001\n",
      "Epoch 15, Step: 234, Loss: 0.21967095136642456, Lr:0.0001\n",
      "Epoch 15, Step: 235, Loss: 0.35694193840026855, Lr:0.0001\n",
      "Epoch 15, Step: 236, Loss: 0.04571573808789253, Lr:0.0001\n",
      "Epoch 15, Step: 237, Loss: 0.11735635995864868, Lr:0.0001\n",
      "Epoch 15, Step: 238, Loss: 0.003970250952988863, Lr:0.0001\n",
      "Epoch 15, Step: 239, Loss: 0.1314023733139038, Lr:0.0001\n",
      "Epoch 15, Step: 240, Loss: 0.17123055458068848, Lr:0.0001\n",
      "Epoch 15, Step: 241, Loss: 0.2979471683502197, Lr:0.0001\n",
      "Epoch 15, Step: 242, Loss: 0.06261057406663895, Lr:0.0001\n",
      "Epoch 15, Step: 243, Loss: 0.06226160004734993, Lr:0.0001\n",
      "Epoch 15, Step: 244, Loss: 0.03801633417606354, Lr:0.0001\n",
      "Epoch 15, Step: 245, Loss: 0.1251251995563507, Lr:0.0001\n",
      "Epoch 15, Step: 246, Loss: 0.2667371332645416, Lr:0.0001\n",
      "Epoch 15, Step: 247, Loss: 0.12299198657274246, Lr:0.0001\n",
      "Epoch 15, Step: 248, Loss: 0.018998946994543076, Lr:0.0001\n",
      "Epoch 15, Step: 249, Loss: 0.040287379175424576, Lr:0.0001\n",
      "Epoch 15, Step: 250, Loss: 0.013948715291917324, Lr:0.0001\n",
      "Epoch 15, Step: 251, Loss: 0.03685533255338669, Lr:0.0001\n",
      "Epoch 15, Step: 252, Loss: 0.0285891555249691, Lr:0.0001\n",
      "Epoch 15, Step: 253, Loss: 0.06318461894989014, Lr:0.0001\n",
      "Epoch 15, Step: 254, Loss: 0.04342327639460564, Lr:0.0001\n",
      "Epoch 15, Step: 255, Loss: 0.031075160950422287, Lr:0.0001\n",
      "Epoch 15, Step: 256, Loss: 0.1541254073381424, Lr:0.0001\n",
      "Epoch 15, Step: 257, Loss: 0.08344323933124542, Lr:0.0001\n",
      "Epoch 15, Step: 258, Loss: 0.12285230308771133, Lr:0.0001\n",
      "Epoch 15, Step: 259, Loss: 0.19818493723869324, Lr:0.0001\n",
      "Epoch 15, Step: 260, Loss: 0.005113289691507816, Lr:0.0001\n",
      "Epoch 15, Step: 261, Loss: 0.12872759997844696, Lr:0.0001\n",
      "Epoch 15, Step: 262, Loss: 0.2730656862258911, Lr:0.0001\n",
      "Epoch 15, Step: 263, Loss: 0.0632614865899086, Lr:0.0001\n",
      "Epoch 15, Step: 264, Loss: 0.08708935976028442, Lr:0.0001\n",
      "Epoch 15, Step: 265, Loss: 0.03294515982270241, Lr:0.0001\n",
      "Epoch 15, Step: 266, Loss: 0.2933495044708252, Lr:0.0001\n",
      "Epoch 15, Step: 267, Loss: 0.22140096127986908, Lr:0.0001\n",
      "Epoch 15, Step: 268, Loss: 0.10578656196594238, Lr:0.0001\n",
      "Epoch 15, Step: 269, Loss: 0.14414893090724945, Lr:0.0001\n",
      "Epoch 15, Step: 270, Loss: 0.029889920726418495, Lr:0.0001\n",
      "Epoch 15, Step: 271, Loss: 0.12124672532081604, Lr:0.0001\n",
      "Epoch 15, Step: 272, Loss: 0.01648588851094246, Lr:0.0001\n",
      "Epoch 15, Step: 273, Loss: 0.009930959902703762, Lr:0.0001\n",
      "Epoch 15, Step: 274, Loss: 0.039971984922885895, Lr:0.0001\n",
      "Epoch 15, Step: 275, Loss: 0.16158945858478546, Lr:0.0001\n",
      "Epoch 15, Step: 276, Loss: 0.13598832488059998, Lr:0.0001\n",
      "Epoch 15, Step: 277, Loss: 0.140567809343338, Lr:0.0001\n",
      "Epoch 15, Step: 278, Loss: 0.3383199870586395, Lr:0.0001\n",
      "Epoch 15, Step: 279, Loss: 0.03223508223891258, Lr:0.0001\n",
      "Epoch 15, Step: 280, Loss: 0.26909351348876953, Lr:0.0001\n",
      "Epoch 15, Step: 281, Loss: 0.3077542185783386, Lr:0.0001\n",
      "Epoch 15, Step: 282, Loss: 0.04562201350927353, Lr:0.0001\n",
      "Epoch 15, Step: 283, Loss: 0.005091195926070213, Lr:0.0001\n",
      "Epoch 15, Step: 284, Loss: 0.15160559117794037, Lr:0.0001\n",
      "Epoch 15, Step: 285, Loss: 0.16520008444786072, Lr:0.0001\n",
      "Epoch 15, Step: 286, Loss: 0.05422999709844589, Lr:0.0001\n",
      "Epoch 15, Step: 287, Loss: 0.23815050721168518, Lr:0.0001\n",
      "Epoch 15, Step: 288, Loss: 0.16735981404781342, Lr:0.0001\n",
      "Epoch 15, Step: 289, Loss: 0.07232186198234558, Lr:0.0001\n",
      "Epoch 15, Step: 290, Loss: 0.0473933108150959, Lr:0.0001\n",
      "Epoch 15, Step: 291, Loss: 0.01186400093138218, Lr:0.0001\n",
      "Epoch 15, Step: 292, Loss: 0.10141725093126297, Lr:0.0001\n",
      "Epoch 15, Step: 293, Loss: 0.1647748500108719, Lr:0.0001\n",
      "Epoch 15, Step: 294, Loss: 0.07939240336418152, Lr:0.0001\n",
      "Epoch 15, Step: 295, Loss: 0.023491354659199715, Lr:0.0001\n",
      "Epoch 15, Step: 296, Loss: 0.03176366537809372, Lr:0.0001\n",
      "Epoch 15, Step: 297, Loss: 0.027757521718740463, Lr:0.0001\n",
      "Epoch 15, Step: 298, Loss: 0.052469391375780106, Lr:0.0001\n",
      "Epoch 15, Step: 299, Loss: 0.24557079374790192, Lr:0.0001\n",
      "Epoch 15, Step: 300, Loss: 0.13345454633235931, Lr:0.0001\n",
      "Epoch 15, Step: 301, Loss: 0.15996478497982025, Lr:0.0001\n",
      "Epoch 15, Step: 302, Loss: 0.1470320224761963, Lr:0.0001\n",
      "Epoch 15, Step: 303, Loss: 0.043550919741392136, Lr:0.0001\n",
      "Epoch 15, Step: 304, Loss: 0.11307075619697571, Lr:0.0001\n",
      "Epoch 15, Step: 305, Loss: 0.10465341806411743, Lr:0.0001\n",
      "Epoch 15, Step: 306, Loss: 0.204176664352417, Lr:0.0001\n",
      "Epoch 15, Step: 307, Loss: 0.030264347791671753, Lr:0.0001\n",
      "Epoch 15, Step: 308, Loss: 0.034276776015758514, Lr:0.0001\n",
      "Epoch 15, Step: 309, Loss: 0.05243387445807457, Lr:0.0001\n",
      "Epoch 15, Step: 310, Loss: 0.17949575185775757, Lr:0.0001\n",
      "Epoch 15, Step: 311, Loss: 0.067114919424057, Lr:0.0001\n",
      "Epoch 15, Step: 312, Loss: 0.046598341315984726, Lr:0.0001\n",
      "Epoch 15, Step: 313, Loss: 0.07130298763513565, Lr:0.0001\n",
      "Epoch 15, Step: 314, Loss: 0.030102701857686043, Lr:0.0001\n",
      "Epoch 15, Step: 315, Loss: 0.013190964236855507, Lr:0.0001\n",
      "Epoch 15, Step: 316, Loss: 0.2850620448589325, Lr:0.0001\n",
      "Epoch 15, Step: 317, Loss: 0.04281970113515854, Lr:0.0001\n",
      "Epoch 15, Step: 318, Loss: 0.031007597222924232, Lr:0.0001\n",
      "Epoch 15, Step: 319, Loss: 0.08243411034345627, Lr:0.0001\n",
      "Epoch 15, Step: 320, Loss: 0.2816617786884308, Lr:0.0001\n",
      "Epoch 15, Step: 321, Loss: 0.04322325065732002, Lr:0.0001\n",
      "Epoch 15, Step: 322, Loss: 0.17681045830249786, Lr:0.0001\n",
      "Epoch 15, Step: 323, Loss: 0.04352334514260292, Lr:0.0001\n",
      "Epoch 15, Step: 324, Loss: 0.09471174329519272, Lr:0.0001\n",
      "Epoch 15, Step: 325, Loss: 0.00696505606174469, Lr:0.0001\n",
      "Epoch 15, Step: 326, Loss: 0.03717091679573059, Lr:0.0001\n",
      "Epoch 15, Step: 327, Loss: 0.03771860897541046, Lr:0.0001\n",
      "Epoch 15, Step: 328, Loss: 0.142282634973526, Lr:0.0001\n",
      "Epoch 15, Step: 329, Loss: 0.061407674103975296, Lr:0.0001\n",
      "Epoch 15, Step: 330, Loss: 0.04976172745227814, Lr:0.0001\n",
      "Epoch 15, Step: 331, Loss: 0.06948322057723999, Lr:0.0001\n",
      "Epoch 15, Step: 332, Loss: 0.03902498260140419, Lr:0.0001\n",
      "Epoch 15, Step: 333, Loss: 0.03881947323679924, Lr:0.0001\n",
      "Epoch 15, Step: 334, Loss: 0.049450479447841644, Lr:0.0001\n",
      "Epoch 15, Step: 335, Loss: 0.019415583461523056, Lr:0.0001\n",
      "Epoch 15, Step: 336, Loss: 0.06484699249267578, Lr:0.0001\n",
      "Epoch 15, Step: 337, Loss: 0.034790411591529846, Lr:0.0001\n",
      "Epoch 15, Step: 338, Loss: 0.08510822802782059, Lr:0.0001\n",
      "Epoch 15, Step: 339, Loss: 0.07195824384689331, Lr:0.0001\n",
      "Epoch 15, Step: 340, Loss: 0.009049869142472744, Lr:0.0001\n",
      "Epoch 15, Step: 341, Loss: 0.1638508141040802, Lr:0.0001\n",
      "Epoch 15, Step: 342, Loss: 0.05595267936587334, Lr:0.0001\n",
      "Epoch 15, Step: 343, Loss: 0.02218043804168701, Lr:0.0001\n",
      "Epoch 15, Step: 344, Loss: 0.05632324516773224, Lr:0.0001\n",
      "Epoch 15, Step: 345, Loss: 0.04459771141409874, Lr:0.0001\n",
      "Epoch 15, Step: 346, Loss: 0.025723209604620934, Lr:0.0001\n",
      "Epoch 15, Step: 347, Loss: 0.20384027063846588, Lr:0.0001\n",
      "Epoch 15, Step: 348, Loss: 0.021548356860876083, Lr:0.0001\n",
      "Epoch 15, Step: 349, Loss: 0.021096058189868927, Lr:0.0001\n",
      "Epoch 15, Step: 350, Loss: 0.007545941509306431, Lr:0.0001\n",
      "Epoch 15, Step: 351, Loss: 0.007003086619079113, Lr:0.0001\n",
      "Epoch 15, Step: 352, Loss: 0.1623065173625946, Lr:0.0001\n",
      "Epoch 15, Step: 353, Loss: 0.1316722184419632, Lr:0.0001\n",
      "Epoch 15, Step: 354, Loss: 0.008491553366184235, Lr:0.0001\n",
      "Epoch 15, Step: 355, Loss: 0.08551345020532608, Lr:0.0001\n",
      "Epoch 15, Step: 356, Loss: 0.011835739016532898, Lr:0.0001\n",
      "Epoch 15, Step: 357, Loss: 0.01292192842811346, Lr:0.0001\n",
      "Epoch 15, Step: 358, Loss: 0.04852180555462837, Lr:0.0001\n",
      "Epoch 15, Step: 359, Loss: 0.03642089664936066, Lr:0.0001\n",
      "Epoch 15, Step: 360, Loss: 0.04346314072608948, Lr:0.0001\n",
      "Epoch 15, Step: 361, Loss: 0.056942570954561234, Lr:0.0001\n",
      "Epoch 15, Step: 362, Loss: 0.010886899195611477, Lr:0.0001\n",
      "Epoch 15, Step: 363, Loss: 0.03763703256845474, Lr:0.0001\n",
      "Epoch 15, Step: 364, Loss: 0.0065371571108698845, Lr:0.0001\n",
      "Epoch 15, Step: 365, Loss: 0.17854997515678406, Lr:0.0001\n",
      "Epoch 15, Step: 366, Loss: 0.20835570991039276, Lr:0.0001\n",
      "Epoch 15, Step: 367, Loss: 0.03229663521051407, Lr:0.0001\n",
      "Epoch 15, Step: 368, Loss: 0.013110547326505184, Lr:0.0001\n",
      "Epoch 15, Step: 369, Loss: 0.3142719268798828, Lr:0.0001\n",
      "Epoch 15, Step: 370, Loss: 0.0662689134478569, Lr:0.0001\n",
      "Epoch 15, Step: 371, Loss: 0.02751820906996727, Lr:0.0001\n",
      "Epoch 15, Step: 372, Loss: 0.006186426617205143, Lr:0.0001\n",
      "Epoch 15, Step: 373, Loss: 0.15398740768432617, Lr:0.0001\n",
      "Epoch 15, Step: 374, Loss: 0.07938966900110245, Lr:0.0001\n",
      "Epoch 15, Step: 375, Loss: 0.033951498568058014, Lr:0.0001\n",
      "Epoch 15, Step: 376, Loss: 0.04615657776594162, Lr:0.0001\n",
      "Epoch 15, Step: 377, Loss: 0.09356927871704102, Lr:0.0001\n",
      "Epoch 15, Step: 378, Loss: 0.12101531028747559, Lr:0.0001\n",
      "Epoch 15, Step: 379, Loss: 0.10520584881305695, Lr:0.0001\n",
      "Epoch 15, Step: 380, Loss: 0.03477766737341881, Lr:0.0001\n",
      "Epoch 15, Step: 381, Loss: 0.024993229657411575, Lr:0.0001\n",
      "Epoch 15, Step: 382, Loss: 0.26985058188438416, Lr:0.0001\n",
      "Epoch 15, Step: 383, Loss: 0.02728680893778801, Lr:0.0001\n",
      "Epoch 15, Step: 384, Loss: 0.03385564312338829, Lr:0.0001\n",
      "Epoch 15, Step: 385, Loss: 0.014349746517837048, Lr:0.0001\n",
      "Epoch 15, Step: 386, Loss: 0.0810457170009613, Lr:0.0001\n",
      "Epoch 15, Step: 387, Loss: 0.04511308670043945, Lr:0.0001\n",
      "Epoch 15, Step: 388, Loss: 0.16389408707618713, Lr:0.0001\n",
      "Epoch 15, Step: 389, Loss: 0.07343465089797974, Lr:0.0001\n",
      "Epoch 15, Step: 390, Loss: 0.14594343304634094, Lr:0.0001\n",
      "Epoch 15, Step: 391, Loss: 0.11232757568359375, Lr:0.0001\n",
      "Epoch 15, Step: 392, Loss: 0.0052735754288733006, Lr:0.0001\n",
      "Epoch 15, Step: 393, Loss: 0.010591245256364346, Lr:0.0001\n",
      "Epoch 15, Step: 394, Loss: 0.03905833512544632, Lr:0.0001\n",
      "Epoch 15, Step: 395, Loss: 0.016149718314409256, Lr:0.0001\n",
      "Epoch 15, Step: 396, Loss: 0.00977994129061699, Lr:0.0001\n",
      "Epoch 15, Step: 397, Loss: 0.0248330757021904, Lr:0.0001\n",
      "Epoch 15, Step: 398, Loss: 0.23457364737987518, Lr:0.0001\n",
      "Epoch 15, Step: 399, Loss: 0.018409796059131622, Lr:0.0001\n",
      "Epoch 15, Step: 400, Loss: 0.10217547416687012, Lr:0.0001\n",
      "Epoch 15, Step: 401, Loss: 0.24319401383399963, Lr:0.0001\n",
      "Epoch 15, Step: 402, Loss: 0.32056209444999695, Lr:0.0001\n",
      "Epoch 15, Step: 403, Loss: 0.1348572075366974, Lr:0.0001\n",
      "Epoch 15, Step: 404, Loss: 0.009360263124108315, Lr:0.0001\n",
      "Epoch 15, Step: 405, Loss: 0.1837710589170456, Lr:0.0001\n",
      "Epoch 15, Step: 406, Loss: 0.06822008639574051, Lr:0.0001\n",
      "Epoch 15, Step: 407, Loss: 0.09078346937894821, Lr:0.0001\n",
      "Epoch 15, Step: 408, Loss: 0.019878167659044266, Lr:0.0001\n",
      "Epoch 15, Step: 409, Loss: 0.040393564850091934, Lr:0.0001\n",
      "Epoch 15, Step: 410, Loss: 0.12663985788822174, Lr:0.0001\n",
      "Epoch 15, Step: 411, Loss: 0.25797760486602783, Lr:0.0001\n",
      "Epoch 15, Step: 412, Loss: 0.003082029055804014, Lr:0.0001\n",
      "Epoch 15, Step: 413, Loss: 0.14205330610275269, Lr:0.0001\n",
      "Epoch 15, Step: 414, Loss: 0.011426905170083046, Lr:0.0001\n",
      "Epoch 15, Step: 415, Loss: 0.005425245966762304, Lr:0.0001\n",
      "Epoch 15, Step: 416, Loss: 0.4256058633327484, Lr:0.0001\n",
      "Epoch 15, Step: 417, Loss: 0.025484293699264526, Lr:0.0001\n",
      "Epoch 15, Step: 418, Loss: 0.0917377695441246, Lr:0.0001\n",
      "Epoch 15, Step: 419, Loss: 0.02848687767982483, Lr:0.0001\n",
      "Epoch 15, Step: 420, Loss: 0.17780032753944397, Lr:0.0001\n",
      "Epoch 15, Step: 421, Loss: 0.2645513117313385, Lr:0.0001\n",
      "Epoch 15, Step: 422, Loss: 0.004335361532866955, Lr:0.0001\n",
      "Epoch 15, Step: 423, Loss: 0.28069156408309937, Lr:0.0001\n",
      "Epoch 15, Step: 424, Loss: 0.1412166953086853, Lr:0.0001\n",
      "Epoch 15, Step: 425, Loss: 0.031378112733364105, Lr:0.0001\n",
      "Epoch 15, Step: 426, Loss: 0.018383976072072983, Lr:0.0001\n",
      "Epoch 15, Step: 427, Loss: 0.04373987019062042, Lr:0.0001\n",
      "Epoch 15, Step: 428, Loss: 0.02556883729994297, Lr:0.0001\n",
      "Epoch 15, Step: 429, Loss: 0.12981016933918, Lr:0.0001\n",
      "Epoch 15, Step: 430, Loss: 0.24042662978172302, Lr:0.0001\n",
      "Epoch 15, Step: 431, Loss: 0.10726910829544067, Lr:0.0001\n",
      "Epoch 15, Step: 432, Loss: 0.23046891391277313, Lr:0.0001\n",
      "Epoch 15, Step: 433, Loss: 0.0445682592689991, Lr:0.0001\n",
      "Epoch 15, Step: 434, Loss: 0.27228203415870667, Lr:0.0001\n",
      "Epoch 15, Step: 435, Loss: 0.03881866857409477, Lr:0.0001\n",
      "Epoch 15, Step: 436, Loss: 0.1567491888999939, Lr:0.0001\n",
      "Epoch 15, Step: 437, Loss: 0.4390961527824402, Lr:0.0001\n",
      "Epoch 15, Step: 438, Loss: 0.1467207968235016, Lr:0.0001\n",
      "Epoch 15, Step: 439, Loss: 0.22424784302711487, Lr:0.0001\n",
      "Epoch 15, Step: 440, Loss: 0.022433796897530556, Lr:0.0001\n",
      "Epoch 15, Step: 441, Loss: 0.026738004758954048, Lr:0.0001\n",
      "Epoch 15, Step: 442, Loss: 0.058089520782232285, Lr:0.0001\n",
      "Epoch 15, Step: 443, Loss: 0.03859815374016762, Lr:0.0001\n",
      "Epoch 15, Step: 444, Loss: 0.08686348050832748, Lr:0.0001\n",
      "Epoch 15, Step: 445, Loss: 0.014000874012708664, Lr:0.0001\n",
      "Epoch 15, Step: 446, Loss: 0.17269782721996307, Lr:0.0001\n",
      "Epoch 15, Step: 447, Loss: 0.06406185030937195, Lr:0.0001\n",
      "Epoch 15, Step: 448, Loss: 0.005999616347253323, Lr:0.0001\n",
      "Epoch 15, Step: 449, Loss: 0.5579444169998169, Lr:0.0001\n",
      "Epoch 15, Step: 450, Loss: 0.019552865996956825, Lr:0.0001\n",
      "Epoch 15, Step: 451, Loss: 0.30751746892929077, Lr:0.0001\n",
      "Epoch 15, Step: 452, Loss: 0.4218236207962036, Lr:0.0001\n",
      "Epoch 15, Step: 453, Loss: 0.048271313309669495, Lr:0.0001\n",
      "Epoch 15, Step: 454, Loss: 0.05178461968898773, Lr:0.0001\n",
      "Epoch 15, Step: 455, Loss: 0.04732609912753105, Lr:0.0001\n",
      "Epoch 15, Step: 456, Loss: 0.05213545635342598, Lr:0.0001\n",
      "Epoch 15, Step: 457, Loss: 0.24209743738174438, Lr:0.0001\n",
      "Epoch 15, Step: 458, Loss: 0.18154899775981903, Lr:0.0001\n",
      "Epoch 15, Step: 459, Loss: 0.10033717006444931, Lr:0.0001\n",
      "Epoch 15, Step: 460, Loss: 0.11688240617513657, Lr:0.0001\n",
      "Epoch 15, Step: 461, Loss: 0.024727003648877144, Lr:0.0001\n",
      "Epoch 15, Step: 462, Loss: 0.2293235957622528, Lr:0.0001\n",
      "Epoch 15, Step: 463, Loss: 0.20021267235279083, Lr:0.0001\n",
      "Epoch 15, Step: 464, Loss: 0.0415436327457428, Lr:0.0001\n",
      "Epoch 15, Step: 465, Loss: 0.02186449058353901, Lr:0.0001\n",
      "Epoch 15, Step: 466, Loss: 0.04498470574617386, Lr:0.0001\n",
      "Epoch 15, Step: 467, Loss: 0.017646951600909233, Lr:0.0001\n",
      "Epoch 15, Step: 468, Loss: 0.23125064373016357, Lr:0.0001\n",
      "Epoch 15, Step: 469, Loss: 0.11702379584312439, Lr:0.0001\n",
      "Epoch 15, Step: 470, Loss: 0.03431800752878189, Lr:0.0001\n",
      "Epoch 15, Step: 471, Loss: 0.23866088688373566, Lr:0.0001\n",
      "Epoch 15, Step: 472, Loss: 0.0016401406610384583, Lr:0.0001\n",
      "Epoch 15, Step: 473, Loss: 0.2836187183856964, Lr:0.0001\n",
      "Epoch 15, Step: 474, Loss: 0.16201408207416534, Lr:0.0001\n",
      "Epoch 15, Step: 475, Loss: 0.17234936356544495, Lr:0.0001\n",
      "Epoch 15, Step: 476, Loss: 0.08796779811382294, Lr:0.0001\n",
      "Epoch 15, Step: 477, Loss: 0.4797208905220032, Lr:0.0001\n",
      "Epoch 15, Step: 478, Loss: 0.0367453433573246, Lr:0.0001\n",
      "Epoch 15, Step: 479, Loss: 0.03700018674135208, Lr:0.0001\n",
      "Epoch 15, Step: 480, Loss: 0.007103011477738619, Lr:0.0001\n",
      "Epoch 15, Step: 481, Loss: 0.04366712272167206, Lr:0.0001\n",
      "Epoch 15, Step: 482, Loss: 0.10722268372774124, Lr:0.0001\n",
      "Epoch 15, Step: 483, Loss: 0.05682867765426636, Lr:0.0001\n",
      "Epoch 15, Step: 484, Loss: 0.09482743591070175, Lr:0.0001\n",
      "Epoch 15, Step: 485, Loss: 0.049205243587493896, Lr:0.0001\n",
      "Epoch 15, Step: 486, Loss: 0.04619120806455612, Lr:0.0001\n",
      "Epoch 15, Step: 487, Loss: 0.07164135575294495, Lr:0.0001\n",
      "Epoch 15, Step: 488, Loss: 0.29590296745300293, Lr:0.0001\n",
      "Epoch 15, Step: 489, Loss: 0.15180590748786926, Lr:0.0001\n",
      "Epoch 15, Step: 490, Loss: 0.09324461966753006, Lr:0.0001\n",
      "Epoch 15, Step: 491, Loss: 0.0894211158156395, Lr:0.0001\n",
      "Epoch 15, Step: 492, Loss: 0.07266706228256226, Lr:0.0001\n",
      "Epoch 15, Step: 493, Loss: 0.03885960206389427, Lr:0.0001\n",
      "Epoch 15, Step: 494, Loss: 0.20904099941253662, Lr:0.0001\n",
      "Epoch 15, Step: 495, Loss: 0.03664802759885788, Lr:0.0001\n",
      "Epoch 15, Step: 496, Loss: 0.13912634551525116, Lr:0.0001\n",
      "Epoch 15, Step: 497, Loss: 0.21992018818855286, Lr:0.0001\n",
      "Epoch 15, Step: 498, Loss: 0.07664074748754501, Lr:0.0001\n",
      "Epoch 15, Step: 499, Loss: 0.12676694989204407, Lr:0.0001\n",
      "Epoch 15, Step: 500, Loss: 0.17017871141433716, Lr:0.0001\n",
      "Epoch 15, Step: 501, Loss: 0.009351606480777264, Lr:0.0001\n",
      "Epoch 15, Step: 502, Loss: 0.06595462560653687, Lr:0.0001\n",
      "Epoch 15, Step: 503, Loss: 0.0964571088552475, Lr:0.0001\n",
      "Epoch 15, Step: 504, Loss: 0.18194514513015747, Lr:0.0001\n",
      "Epoch 15, Step: 505, Loss: 0.12207724899053574, Lr:0.0001\n",
      "Epoch 15, Step: 506, Loss: 0.049437202513217926, Lr:0.0001\n",
      "Epoch 15, Step: 507, Loss: 0.05192079395055771, Lr:0.0001\n",
      "Epoch 15, Step: 508, Loss: 0.40389594435691833, Lr:0.0001\n",
      "Epoch 15, Step: 509, Loss: 0.12091528624296188, Lr:0.0001\n",
      "Epoch 15, Step: 510, Loss: 0.046793948858976364, Lr:0.0001\n",
      "Epoch 15, Step: 511, Loss: 0.1035211905837059, Lr:0.0001\n",
      "Epoch 15, Step: 512, Loss: 0.022836146876215935, Lr:0.0001\n",
      "Epoch 15, Step: 513, Loss: 0.049368277192115784, Lr:0.0001\n",
      "Epoch 15, Step: 514, Loss: 0.042805884033441544, Lr:0.0001\n",
      "Epoch 15, Step: 515, Loss: 0.0252379160374403, Lr:0.0001\n",
      "Epoch 15, Step: 516, Loss: 0.07569539546966553, Lr:0.0001\n",
      "Epoch 15, Step: 517, Loss: 0.03382296860218048, Lr:0.0001\n",
      "Epoch 15, Step: 518, Loss: 0.3218814432621002, Lr:0.0001\n",
      "Epoch 15, Step: 519, Loss: 0.057257939130067825, Lr:0.0001\n",
      "Epoch 15, Step: 520, Loss: 0.10100756585597992, Lr:0.0001\n",
      "Epoch 15, Step: 521, Loss: 0.2289491444826126, Lr:0.0001\n",
      "Epoch 15, Step: 522, Loss: 0.21480849385261536, Lr:0.0001\n",
      "Epoch 15, Step: 523, Loss: 0.03843444213271141, Lr:0.0001\n",
      "Epoch 15, Step: 524, Loss: 0.013689490966498852, Lr:0.0001\n",
      "Epoch 15, Step: 525, Loss: 0.0984109565615654, Lr:0.0001\n",
      "Epoch 15, Step: 526, Loss: 0.0736275166273117, Lr:0.0001\n",
      "Epoch 15, Step: 527, Loss: 0.01723870076239109, Lr:0.0001\n",
      "Epoch 15, Step: 528, Loss: 0.09963662922382355, Lr:0.0001\n",
      "Epoch 15, Step: 529, Loss: 0.1691439002752304, Lr:0.0001\n",
      "Epoch 15, Step: 530, Loss: 0.08172671496868134, Lr:0.0001\n",
      "Epoch 15, Step: 531, Loss: 0.35715433955192566, Lr:0.0001\n",
      "Epoch 15, Step: 532, Loss: 0.12449900805950165, Lr:0.0001\n",
      "Epoch 15, Step: 533, Loss: 0.04030527547001839, Lr:0.0001\n",
      "Epoch 15, Step: 534, Loss: 0.05177599936723709, Lr:0.0001\n",
      "Epoch 15, Step: 535, Loss: 0.06340603530406952, Lr:0.0001\n",
      "Epoch 15, Step: 536, Loss: 0.17935870587825775, Lr:0.0001\n",
      "Epoch 15, Step: 537, Loss: 0.03242287039756775, Lr:0.0001\n",
      "Epoch 15, Step: 538, Loss: 0.20908427238464355, Lr:0.0001\n",
      "Epoch 15, Step: 539, Loss: 0.008892925456166267, Lr:0.0001\n",
      "Epoch 15, Step: 540, Loss: 0.11852142214775085, Lr:0.0001\n",
      "Epoch 15, Step: 541, Loss: 0.07950131595134735, Lr:0.0001\n",
      "Epoch 15, Step: 542, Loss: 0.03399166092276573, Lr:0.0001\n",
      "Epoch 15, Step: 543, Loss: 0.07159381359815598, Lr:0.0001\n",
      "Epoch 15, Step: 544, Loss: 0.04376202076673508, Lr:0.0001\n",
      "Epoch 15, Step: 545, Loss: 0.07903419435024261, Lr:0.0001\n",
      "Epoch 15, Step: 546, Loss: 0.13116343319416046, Lr:0.0001\n",
      "Epoch 15, Step: 547, Loss: 0.12125326693058014, Lr:0.0001\n",
      "Epoch 15, Step: 548, Loss: 0.06600373983383179, Lr:0.0001\n",
      "Epoch 15, Step: 549, Loss: 0.34519389271736145, Lr:0.0001\n",
      "Epoch 15, Step: 550, Loss: 0.2449951469898224, Lr:0.0001\n",
      "Epoch 15, Step: 551, Loss: 0.04505199193954468, Lr:0.0001\n",
      "Epoch 15, Step: 552, Loss: 0.08359255641698837, Lr:0.0001\n",
      "Epoch 15, Step: 553, Loss: 0.16589215397834778, Lr:0.0001\n",
      "Epoch 15, Step: 554, Loss: 0.05282440409064293, Lr:0.0001\n",
      "Epoch 15, Step: 555, Loss: 0.00843743048608303, Lr:0.0001\n",
      "Epoch 15, Step: 556, Loss: 0.013721972703933716, Lr:0.0001\n",
      "Epoch 15, Step: 557, Loss: 0.017412692308425903, Lr:0.0001\n",
      "Epoch 15, Step: 558, Loss: 0.17570151388645172, Lr:0.0001\n",
      "Epoch 15, Step: 559, Loss: 0.060029037296772, Lr:0.0001\n",
      "Epoch 15, Step: 560, Loss: 0.18591412901878357, Lr:0.0001\n",
      "Epoch 15, Step: 561, Loss: 0.031573861837387085, Lr:0.0001\n",
      "Epoch 15, Step: 562, Loss: 0.022666214033961296, Lr:0.0001\n",
      "Epoch 15, Step: 563, Loss: 0.012084013782441616, Lr:0.0001\n",
      "Epoch 15, Step: 564, Loss: 0.2038753628730774, Lr:0.0001\n",
      "Epoch 15, Step: 565, Loss: 0.08019877225160599, Lr:0.0001\n",
      "Epoch 15, Step: 566, Loss: 0.017686305567622185, Lr:0.0001\n",
      "Epoch 15, Step: 567, Loss: 0.022731652483344078, Lr:0.0001\n",
      "Epoch 15, Step: 568, Loss: 0.09000839293003082, Lr:0.0001\n",
      "Epoch 15, Step: 569, Loss: 0.004887440707534552, Lr:0.0001\n",
      "Epoch 15, Step: 570, Loss: 0.19797709584236145, Lr:0.0001\n",
      "Epoch 15, Step: 571, Loss: 0.15098430216312408, Lr:0.0001\n",
      "Epoch 15, Step: 572, Loss: 0.021258417516946793, Lr:0.0001\n",
      "Epoch 15, Step: 573, Loss: 0.0808989554643631, Lr:0.0001\n",
      "Epoch 15, Step: 574, Loss: 0.051291074603796005, Lr:0.0001\n",
      "Epoch 15, Step: 575, Loss: 0.0827111005783081, Lr:0.0001\n",
      "Epoch 15, Step: 576, Loss: 0.17195308208465576, Lr:0.0001\n",
      "Epoch 15, Step: 577, Loss: 0.3621666729450226, Lr:0.0001\n",
      "Epoch 15, Step: 578, Loss: 0.038965340703725815, Lr:0.0001\n",
      "Epoch 15, Step: 579, Loss: 0.08834295719861984, Lr:0.0001\n",
      "Epoch 15, Step: 580, Loss: 0.19333991408348083, Lr:0.0001\n",
      "Epoch 15, Step: 581, Loss: 0.00838704127818346, Lr:0.0001\n",
      "Epoch 15, Step: 582, Loss: 0.11262732744216919, Lr:0.0001\n",
      "Epoch 15, Step: 583, Loss: 0.09223973006010056, Lr:0.0001\n",
      "Epoch 15, Step: 584, Loss: 0.20399996638298035, Lr:0.0001\n",
      "Epoch 15, Step: 585, Loss: 0.0620528981089592, Lr:0.0001\n",
      "Epoch 15, Step: 586, Loss: 0.039183586835861206, Lr:0.0001\n",
      "Epoch 15, Step: 587, Loss: 0.15756534039974213, Lr:0.0001\n",
      "Epoch 15, Step: 588, Loss: 0.17371037602424622, Lr:0.0001\n",
      "Epoch 15, Step: 589, Loss: 0.023987047374248505, Lr:0.0001\n",
      "Epoch 15, Step: 590, Loss: 0.14515332877635956, Lr:0.0001\n",
      "Epoch 15, Step: 591, Loss: 0.00650934549048543, Lr:0.0001\n",
      "Epoch 15, Step: 592, Loss: 0.18165862560272217, Lr:0.0001\n",
      "Epoch 15, Step: 593, Loss: 0.1579708456993103, Lr:0.0001\n",
      "Epoch 15, Step: 594, Loss: 0.06625527888536453, Lr:0.0001\n",
      "Epoch 15, Step: 595, Loss: 0.028238991275429726, Lr:0.0001\n",
      "Epoch 15, Step: 596, Loss: 0.0010381226893514395, Lr:0.0001\n",
      "Epoch 15, Step: 597, Loss: 0.05138358473777771, Lr:0.0001\n",
      "Epoch 15, Step: 598, Loss: 0.0539114847779274, Lr:0.0001\n",
      "Epoch 15, Step: 599, Loss: 0.02015949971973896, Lr:0.0001\n",
      "Epoch 15, Step: 600, Loss: 0.31921711564064026, Lr:0.0001\n",
      "Epoch 15, Step: 601, Loss: 0.010077818296849728, Lr:0.0001\n",
      "Epoch 15, Step: 602, Loss: 0.028373025357723236, Lr:0.0001\n",
      "Epoch 15, Step: 603, Loss: 0.13204403221607208, Lr:0.0001\n",
      "Epoch 15, Step: 604, Loss: 0.020297393202781677, Lr:0.0001\n",
      "Epoch 15, Step: 605, Loss: 0.026723090559244156, Lr:0.0001\n",
      "Epoch 15, Step: 606, Loss: 0.01424226351082325, Lr:0.0001\n",
      "Epoch 15, Step: 607, Loss: 0.06685000658035278, Lr:0.0001\n",
      "Epoch 15, Step: 608, Loss: 0.022923575714230537, Lr:0.0001\n",
      "Epoch 15, Step: 609, Loss: 0.05913996696472168, Lr:0.0001\n",
      "Epoch 15, Step: 610, Loss: 0.16206896305084229, Lr:0.0001\n",
      "Epoch 15, Step: 611, Loss: 0.10997118055820465, Lr:0.0001\n",
      "Epoch 15, Step: 612, Loss: 0.026622362434864044, Lr:0.0001\n",
      "Epoch 15, Step: 613, Loss: 0.016588322818279266, Lr:0.0001\n",
      "Epoch 15, Step: 614, Loss: 0.1657201200723648, Lr:0.0001\n",
      "Epoch 15, Step: 615, Loss: 0.007827294059097767, Lr:0.0001\n",
      "Epoch 15, Step: 616, Loss: 0.05675388500094414, Lr:0.0001\n",
      "Epoch 15, Step: 617, Loss: 0.021845929324626923, Lr:0.0001\n",
      "Epoch 15, Step: 618, Loss: 0.024712426587939262, Lr:0.0001\n",
      "Epoch 15, Step: 619, Loss: 0.08358854800462723, Lr:0.0001\n",
      "Epoch 15, Step: 620, Loss: 0.24651066958904266, Lr:0.0001\n",
      "Epoch 15, Step: 621, Loss: 0.15876013040542603, Lr:0.0001\n",
      "Epoch 15, Step: 622, Loss: 0.1507667899131775, Lr:0.0001\n",
      "Epoch 15, Step: 623, Loss: 0.09219465404748917, Lr:0.0001\n",
      "Epoch 15, Step: 624, Loss: 0.21679392457008362, Lr:0.0001\n",
      "Epoch 15, Step: 625, Loss: 0.27903661131858826, Lr:0.0001\n",
      "Epoch 15, Step: 626, Loss: 0.01981550268828869, Lr:0.0001\n",
      "Epoch 15, Step: 627, Loss: 0.19198153913021088, Lr:0.0001\n",
      "Epoch 15, Step: 628, Loss: 0.11011393368244171, Lr:0.0001\n",
      "Epoch 15, Step: 629, Loss: 0.11175859719514847, Lr:0.0001\n",
      "Epoch 15, Step: 630, Loss: 0.3344634771347046, Lr:0.0001\n",
      "Epoch 15, Step: 631, Loss: 0.1216016560792923, Lr:0.0001\n",
      "Epoch 15, Step: 632, Loss: 0.04343072697520256, Lr:0.0001\n",
      "Epoch 15, Step: 633, Loss: 0.15188246965408325, Lr:0.0001\n",
      "Epoch 15, Step: 634, Loss: 0.15721966326236725, Lr:0.0001\n",
      "Epoch 15, Step: 635, Loss: 0.028135739266872406, Lr:0.0001\n",
      "Epoch 15, Step: 636, Loss: 0.00835698563605547, Lr:0.0001\n",
      "Epoch 15, Step: 637, Loss: 0.08959291130304337, Lr:0.0001\n",
      "Epoch 15, Step: 638, Loss: 0.05018831789493561, Lr:0.0001\n",
      "Epoch 15, Step: 639, Loss: 0.037403397262096405, Lr:0.0001\n",
      "Epoch 15, Step: 640, Loss: 0.008075648918747902, Lr:0.0001\n",
      "Epoch 15, Step: 641, Loss: 0.19405488669872284, Lr:0.0001\n",
      "Epoch 15, Step: 642, Loss: 0.14740239083766937, Lr:0.0001\n",
      "Epoch 15, Step: 643, Loss: 0.02177213877439499, Lr:0.0001\n",
      "Epoch 15, Step: 644, Loss: 0.061502888798713684, Lr:0.0001\n",
      "Epoch 15, Step: 645, Loss: 0.3402590751647949, Lr:0.0001\n",
      "Epoch 15, Step: 646, Loss: 0.13552486896514893, Lr:0.0001\n",
      "Epoch 15, Step: 647, Loss: 0.1653418093919754, Lr:0.0001\n",
      "Epoch 15, Step: 648, Loss: 0.05438432842493057, Lr:0.0001\n",
      "Epoch 15, Step: 649, Loss: 0.013159009627997875, Lr:0.0001\n",
      "Epoch 15, Step: 650, Loss: 0.15740348398685455, Lr:0.0001\n",
      "Epoch 15, Step: 651, Loss: 0.010923774912953377, Lr:0.0001\n",
      "Epoch 15, Step: 652, Loss: 0.0295697171241045, Lr:0.0001\n",
      "Epoch 15, Step: 653, Loss: 0.30394071340560913, Lr:0.0001\n",
      "Epoch 15, Step: 654, Loss: 0.27780213952064514, Lr:0.0001\n",
      "Epoch 15, Step: 655, Loss: 0.040839407593011856, Lr:0.0001\n",
      "Epoch 15, Step: 656, Loss: 0.2676716148853302, Lr:0.0001\n",
      "Epoch 15, Step: 657, Loss: 0.03360526263713837, Lr:0.0001\n",
      "Epoch 15, Step: 658, Loss: 0.006514301057904959, Lr:0.0001\n",
      "Epoch 15, Step: 659, Loss: 0.06934429705142975, Lr:0.0001\n",
      "Epoch 15, Step: 660, Loss: 0.06473588943481445, Lr:0.0001\n",
      "Epoch 15, Step: 661, Loss: 0.23527835309505463, Lr:0.0001\n",
      "Epoch 15, Step: 662, Loss: 0.07831303030252457, Lr:0.0001\n",
      "Epoch 15, Step: 663, Loss: 0.04288658872246742, Lr:0.0001\n",
      "Epoch 15, Step: 664, Loss: 0.13475021719932556, Lr:0.0001\n",
      "Epoch 15, Step: 665, Loss: 0.07073169201612473, Lr:0.0001\n",
      "Epoch 15, Step: 666, Loss: 0.13661903142929077, Lr:0.0001\n",
      "Epoch 15, Step: 667, Loss: 0.06277790665626526, Lr:0.0001\n",
      "Epoch 15, Step: 668, Loss: 0.07542098313570023, Lr:0.0001\n",
      "Epoch 15, Step: 669, Loss: 0.08932682126760483, Lr:0.0001\n",
      "Epoch 15, Step: 670, Loss: 0.02524704486131668, Lr:0.0001\n",
      "Epoch 15, Step: 671, Loss: 0.011151758953928947, Lr:0.0001\n",
      "Epoch 15, Step: 672, Loss: 0.0925116240978241, Lr:0.0001\n",
      "Epoch 15, Step: 673, Loss: 0.022878069430589676, Lr:0.0001\n",
      "Epoch 15, Step: 674, Loss: 0.06863051652908325, Lr:0.0001\n",
      "Epoch 15, Step: 675, Loss: 0.07723934203386307, Lr:0.0001\n",
      "Epoch 15, Step: 676, Loss: 0.12721695005893707, Lr:0.0001\n",
      "Epoch 15, Step: 677, Loss: 0.10037121921777725, Lr:0.0001\n",
      "Epoch 15, Step: 678, Loss: 0.04892026260495186, Lr:0.0001\n",
      "Epoch 15, Step: 679, Loss: 0.009631222113966942, Lr:0.0001\n",
      "Epoch 15, Step: 680, Loss: 0.069194495677948, Lr:0.0001\n",
      "Epoch 15, Step: 681, Loss: 0.03115708753466606, Lr:0.0001\n",
      "Epoch 15, Step: 682, Loss: 0.006359148304909468, Lr:0.0001\n",
      "Epoch 15, Step: 683, Loss: 0.025331050157546997, Lr:0.0001\n",
      "Epoch 15, Step: 684, Loss: 0.015984298661351204, Lr:0.0001\n",
      "Epoch 15, Step: 685, Loss: 0.04592641443014145, Lr:0.0001\n",
      "Epoch 15, Step: 686, Loss: 0.0009305475978180766, Lr:0.0001\n",
      "Epoch 15, Step: 687, Loss: 0.22345088422298431, Lr:0.0001\n",
      "Epoch 15, Step: 688, Loss: 0.03652442991733551, Lr:0.0001\n",
      "Epoch 15, Step: 689, Loss: 0.001475518336519599, Lr:0.0001\n",
      "Epoch 15, Step: 690, Loss: 0.02521681785583496, Lr:0.0001\n",
      "Epoch 15, Step: 691, Loss: 0.017904922366142273, Lr:0.0001\n",
      "Epoch 15, Step: 692, Loss: 0.10246039927005768, Lr:0.0001\n",
      "Epoch 15, Step: 693, Loss: 0.02049749158322811, Lr:0.0001\n",
      "Epoch 15, Step: 694, Loss: 0.1586703509092331, Lr:0.0001\n",
      "Epoch 15, Step: 695, Loss: 0.06909677386283875, Lr:0.0001\n",
      "Epoch 15, Step: 696, Loss: 0.25084370374679565, Lr:0.0001\n",
      "Epoch 15, Step: 697, Loss: 0.06478063017129898, Lr:0.0001\n",
      "Epoch 15, Step: 698, Loss: 0.10112711787223816, Lr:0.0001\n",
      "Epoch 15, Step: 699, Loss: 0.016957096755504608, Lr:0.0001\n",
      "Epoch 15, Step: 700, Loss: 0.16720987856388092, Lr:0.0001\n",
      "Epoch 15, Step: 701, Loss: 0.051804590970277786, Lr:0.0001\n",
      "Epoch 15, Step: 702, Loss: 0.040966909378767014, Lr:0.0001\n",
      "Epoch 15, Step: 703, Loss: 0.010872607119381428, Lr:0.0001\n",
      "Epoch 15, Step: 704, Loss: 0.008815268985927105, Lr:0.0001\n",
      "Epoch 15, Step: 705, Loss: 0.04863610491156578, Lr:0.0001\n",
      "Epoch 15, Step: 706, Loss: 0.14573028683662415, Lr:0.0001\n",
      "Epoch 15, Step: 707, Loss: 0.004259908571839333, Lr:0.0001\n",
      "Epoch 15, Step: 708, Loss: 0.014823192730545998, Lr:0.0001\n",
      "Epoch 15, Step: 709, Loss: 0.05261318385601044, Lr:0.0001\n",
      "Epoch 15, Step: 710, Loss: 0.038472436368465424, Lr:0.0001\n",
      "Epoch 15, Step: 711, Loss: 0.07664736360311508, Lr:0.0001\n",
      "Epoch 15, Step: 712, Loss: 0.03873446211218834, Lr:0.0001\n",
      "Epoch 15, Step: 713, Loss: 0.22333811223506927, Lr:0.0001\n",
      "Epoch 15, Step: 714, Loss: 0.03767356276512146, Lr:0.0001\n",
      "Epoch 15, Step: 715, Loss: 0.27523547410964966, Lr:0.0001\n",
      "Epoch 15, Step: 716, Loss: 0.266810804605484, Lr:0.0001\n",
      "Epoch 15, Step: 717, Loss: 0.046488434076309204, Lr:0.0001\n",
      "Epoch 15, Step: 718, Loss: 0.02244364656507969, Lr:0.0001\n",
      "Epoch 15, Step: 719, Loss: 0.03451923280954361, Lr:0.0001\n",
      "Epoch 15, Step: 720, Loss: 0.021000565961003304, Lr:0.0001\n",
      "Epoch 15, Step: 721, Loss: 0.03246940299868584, Lr:0.0001\n",
      "Epoch 15, Step: 722, Loss: 0.01463820319622755, Lr:0.0001\n",
      "Epoch 15, Step: 723, Loss: 0.0408785417675972, Lr:0.0001\n",
      "Epoch 15, Step: 724, Loss: 0.324840784072876, Lr:0.0001\n",
      "Epoch 15, Step: 725, Loss: 0.0575135238468647, Lr:0.0001\n",
      "Epoch 15, Step: 726, Loss: 0.055957626551389694, Lr:0.0001\n",
      "Epoch 15, Step: 727, Loss: 0.05063513666391373, Lr:0.0001\n",
      "Epoch 15, Step: 728, Loss: 0.010918223299086094, Lr:0.0001\n",
      "Epoch 15, Step: 729, Loss: 0.16602599620819092, Lr:0.0001\n",
      "Epoch 15, Step: 730, Loss: 0.03326968103647232, Lr:0.0001\n",
      "Epoch 15, Step: 731, Loss: 0.1928895264863968, Lr:0.0001\n",
      "Epoch 15, Step: 732, Loss: 0.07028969377279282, Lr:0.0001\n",
      "Epoch 15, Step: 733, Loss: 0.08631940931081772, Lr:0.0001\n",
      "Epoch 15, Step: 734, Loss: 0.017402606084942818, Lr:0.0001\n",
      "Epoch 15, Step: 735, Loss: 0.04965224862098694, Lr:0.0001\n",
      "Epoch 15, Step: 736, Loss: 0.1097656711935997, Lr:0.0001\n",
      "Epoch 15, Step: 737, Loss: 0.05199979618191719, Lr:0.0001\n",
      "Epoch 15, Step: 738, Loss: 0.007642917800694704, Lr:0.0001\n",
      "Epoch 15, Step: 739, Loss: 0.017954356968402863, Lr:0.0001\n",
      "Epoch 15, Step: 740, Loss: 0.18232981860637665, Lr:0.0001\n",
      "Epoch 15, Step: 741, Loss: 0.1379433572292328, Lr:0.0001\n",
      "Epoch 15, Step: 742, Loss: 0.2209300696849823, Lr:0.0001\n",
      "Epoch 15, Step: 743, Loss: 0.03682974353432655, Lr:0.0001\n",
      "Epoch 15, Step: 744, Loss: 0.003079397138208151, Lr:0.0001\n",
      "Epoch 15, Step: 745, Loss: 0.031369324773550034, Lr:0.0001\n",
      "Epoch 15, Step: 746, Loss: 0.03948773071169853, Lr:0.0001\n",
      "Epoch 15, Step: 747, Loss: 0.004806363023817539, Lr:0.0001\n",
      "Epoch 15, Step: 748, Loss: 0.09306269884109497, Lr:0.0001\n",
      "Epoch 15, Step: 749, Loss: 0.20404009521007538, Lr:0.0001\n",
      "Epoch 15, Step: 750, Loss: 0.011539332568645477, Lr:0.0001\n",
      "Epoch 15, Step: 751, Loss: 0.11188296228647232, Lr:0.0001\n",
      "Epoch 15, Step: 752, Loss: 0.018368981778621674, Lr:0.0001\n",
      "Epoch 15, Step: 753, Loss: 0.03435169905424118, Lr:0.0001\n",
      "Epoch 15, Step: 754, Loss: 0.2075439840555191, Lr:0.0001\n",
      "Epoch 15, Step: 755, Loss: 0.018598642200231552, Lr:0.0001\n",
      "Epoch 15, Step: 756, Loss: 0.06569969654083252, Lr:0.0001\n",
      "Epoch 15, Step: 757, Loss: 0.18192385137081146, Lr:0.0001\n",
      "Epoch 15, Step: 758, Loss: 0.026256047189235687, Lr:0.0001\n",
      "Epoch 15, Step: 759, Loss: 0.011839082464575768, Lr:0.0001\n",
      "Epoch 15, Step: 760, Loss: 0.007794605102390051, Lr:0.0001\n",
      "Epoch 15, Step: 761, Loss: 0.07908245176076889, Lr:0.0001\n",
      "Epoch 15, Step: 762, Loss: 0.009150336496531963, Lr:0.0001\n",
      "Epoch 15, Step: 763, Loss: 0.2805461883544922, Lr:0.0001\n",
      "Epoch 15, Step: 764, Loss: 0.04238797724246979, Lr:0.0001\n",
      "Epoch 15, Step: 765, Loss: 0.09378225356340408, Lr:0.0001\n",
      "Epoch 15, Step: 766, Loss: 0.032382603734731674, Lr:0.0001\n",
      "Epoch 15, Step: 767, Loss: 0.029048465192317963, Lr:0.0001\n",
      "Epoch 15, Step: 768, Loss: 0.041789233684539795, Lr:0.0001\n",
      "Epoch 15, Step: 769, Loss: 0.01069354172796011, Lr:0.0001\n",
      "Epoch 15, Step: 770, Loss: 0.13416804373264313, Lr:0.0001\n",
      "Epoch 15, Step: 771, Loss: 0.07160615175962448, Lr:0.0001\n",
      "Epoch 15, Step: 772, Loss: 0.14309148490428925, Lr:0.0001\n",
      "Epoch 15, Step: 773, Loss: 0.01627171039581299, Lr:0.0001\n",
      "Epoch 15, Step: 774, Loss: 0.21206974983215332, Lr:0.0001\n",
      "Epoch 15, Step: 775, Loss: 0.07070741057395935, Lr:0.0001\n",
      "Epoch 15, Step: 776, Loss: 0.0627884492278099, Lr:0.0001\n",
      "Epoch 15, Step: 777, Loss: 0.06061363220214844, Lr:0.0001\n",
      "Epoch 15, Step: 778, Loss: 0.2273016721010208, Lr:0.0001\n",
      "Epoch 15, Step: 779, Loss: 0.07318144291639328, Lr:0.0001\n",
      "Epoch 15, Step: 780, Loss: 0.031020812690258026, Lr:0.0001\n",
      "Epoch 15, Step: 781, Loss: 0.03295448422431946, Lr:0.0001\n",
      "Epoch 15, Step: 782, Loss: 0.21338284015655518, Lr:0.0001\n",
      "Epoch 15, Step: 783, Loss: 0.009003889746963978, Lr:0.0001\n",
      "Epoch 15, Step: 784, Loss: 0.031085344031453133, Lr:0.0001\n",
      "Epoch 15, Step: 785, Loss: 0.046957120299339294, Lr:0.0001\n",
      "Epoch 15, Step: 786, Loss: 0.029662664979696274, Lr:0.0001\n",
      "Epoch 15, Step: 787, Loss: 0.012919584289193153, Lr:0.0001\n",
      "Epoch 15, Step: 788, Loss: 0.182858407497406, Lr:0.0001\n",
      "Epoch 15, Step: 789, Loss: 0.05877991393208504, Lr:0.0001\n",
      "Epoch 15, Step: 790, Loss: 0.07253622263669968, Lr:0.0001\n",
      "Epoch 15, Step: 791, Loss: 0.15834711492061615, Lr:0.0001\n",
      "Epoch 15, Step: 792, Loss: 0.16059377789497375, Lr:0.0001\n",
      "Epoch 15, Step: 793, Loss: 0.18511863052845, Lr:0.0001\n",
      "Epoch 15, Step: 794, Loss: 0.14185088872909546, Lr:0.0001\n",
      "Epoch 15, Step: 795, Loss: 0.26821932196617126, Lr:0.0001\n",
      "Epoch 15, Step: 796, Loss: 0.04403144493699074, Lr:0.0001\n",
      "Epoch 15, Step: 797, Loss: 0.03166677802801132, Lr:0.0001\n",
      "Epoch 15, Step: 798, Loss: 0.03213530778884888, Lr:0.0001\n",
      "Epoch 15, Step: 799, Loss: 0.14805400371551514, Lr:0.0001\n",
      "Epoch 15, Step: 800, Loss: 0.302586168050766, Lr:0.0001\n",
      "Epoch 15, Step: 801, Loss: 0.031002074480056763, Lr:0.0001\n",
      "Epoch 15, Step: 802, Loss: 0.2062157690525055, Lr:0.0001\n",
      "Epoch 15, Step: 803, Loss: 0.0664549171924591, Lr:0.0001\n",
      "Epoch 15, Step: 804, Loss: 0.009908733889460564, Lr:0.0001\n",
      "Epoch 15, Step: 805, Loss: 0.19337427616119385, Lr:0.0001\n",
      "Epoch 15, Step: 806, Loss: 0.004371963907033205, Lr:0.0001\n",
      "Epoch 15, Step: 807, Loss: 0.19181247055530548, Lr:0.0001\n",
      "Epoch 15, Step: 808, Loss: 0.06865351647138596, Lr:0.0001\n",
      "Epoch 15, Step: 809, Loss: 0.3220319151878357, Lr:0.0001\n",
      "Epoch 15, Step: 810, Loss: 0.02222505584359169, Lr:0.0001\n",
      "Epoch 15, Step: 811, Loss: 0.13055719435214996, Lr:0.0001\n",
      "Epoch 15, Step: 812, Loss: 0.08511372655630112, Lr:0.0001\n",
      "Epoch 15, Step: 813, Loss: 0.021140819415450096, Lr:0.0001\n",
      "Epoch 15, Step: 814, Loss: 0.09079577028751373, Lr:0.0001\n",
      "Epoch 15, Step: 815, Loss: 0.07095472514629364, Lr:0.0001\n",
      "Epoch 15, Step: 816, Loss: 0.08446690440177917, Lr:0.0001\n",
      "Epoch 15, Step: 817, Loss: 0.04036302492022514, Lr:0.0001\n",
      "Epoch 15, Step: 818, Loss: 0.019154299050569534, Lr:0.0001\n",
      "Epoch 15, Step: 819, Loss: 0.03621717542409897, Lr:0.0001\n",
      "Epoch 15, Step: 820, Loss: 0.13339173793792725, Lr:0.0001\n",
      "Epoch 15, Step: 821, Loss: 0.1592535376548767, Lr:0.0001\n",
      "Epoch 15, Step: 822, Loss: 0.05842527374625206, Lr:0.0001\n",
      "Epoch 15, Step: 823, Loss: 0.03585278242826462, Lr:0.0001\n",
      "Epoch 15, Step: 824, Loss: 0.23684674501419067, Lr:0.0001\n",
      "Epoch 15, Step: 825, Loss: 0.13376207649707794, Lr:0.0001\n",
      "Epoch 15, Step: 826, Loss: 0.09213180840015411, Lr:0.0001\n",
      "Epoch 15, Step: 827, Loss: 0.10063178092241287, Lr:0.0001\n",
      "Epoch 15, Step: 828, Loss: 0.09222672134637833, Lr:0.0001\n",
      "Epoch 15, Step: 829, Loss: 0.12994395196437836, Lr:0.0001\n",
      "Epoch 15, Step: 830, Loss: 0.054575707763433456, Lr:0.0001\n",
      "Epoch 15, Step: 831, Loss: 0.38864797353744507, Lr:0.0001\n",
      "Epoch 15, Step: 832, Loss: 0.2209312468767166, Lr:0.0001\n",
      "Epoch 15, Step: 833, Loss: 0.6273626685142517, Lr:0.0001\n",
      "Epoch 15, Step: 834, Loss: 0.07197324931621552, Lr:0.0001\n",
      "Epoch 15, Step: 835, Loss: 0.07926821708679199, Lr:0.0001\n",
      "Epoch 15, Step: 836, Loss: 0.04956156015396118, Lr:0.0001\n",
      "Epoch 15, Step: 837, Loss: 0.17029449343681335, Lr:0.0001\n",
      "Epoch 15, Step: 838, Loss: 0.0625099465250969, Lr:0.0001\n",
      "Epoch 15, Step: 839, Loss: 0.015472286380827427, Lr:0.0001\n",
      "Epoch 15, Step: 840, Loss: 0.06302482634782791, Lr:0.0001\n",
      "Epoch 15, Step: 841, Loss: 0.007954210974276066, Lr:0.0001\n",
      "Epoch 15, Step: 842, Loss: 0.04896727204322815, Lr:0.0001\n",
      "Epoch 15, Step: 843, Loss: 0.24837839603424072, Lr:0.0001\n",
      "Epoch 15, Step: 844, Loss: 0.16813626885414124, Lr:0.0001\n",
      "Epoch 15, Step: 845, Loss: 0.0209355391561985, Lr:0.0001\n",
      "Epoch 15, Step: 846, Loss: 0.0032518343068659306, Lr:0.0001\n",
      "Epoch 15, Step: 847, Loss: 0.1830456703901291, Lr:0.0001\n",
      "Epoch 15, Step: 848, Loss: 0.006733391433954239, Lr:0.0001\n",
      "Epoch 15, Step: 849, Loss: 0.0861096978187561, Lr:0.0001\n",
      "Epoch 15, Step: 850, Loss: 0.1533195972442627, Lr:0.0001\n",
      "Epoch 15, Step: 851, Loss: 0.1483389139175415, Lr:0.0001\n",
      "Epoch 15, Step: 852, Loss: 0.025534991174936295, Lr:0.0001\n",
      "Epoch 15, Step: 853, Loss: 0.14619189500808716, Lr:0.0001\n",
      "Epoch 15, Step: 854, Loss: 0.12229277938604355, Lr:0.0001\n",
      "Epoch 15, Step: 855, Loss: 0.031154271215200424, Lr:0.0001\n",
      "Epoch 15, Step: 856, Loss: 0.04627309739589691, Lr:0.0001\n",
      "Epoch 15, Step: 857, Loss: 0.05434155464172363, Lr:0.0001\n",
      "Epoch 15, Step: 858, Loss: 0.05005016177892685, Lr:0.0001\n",
      "Epoch 15, Step: 859, Loss: 0.028691980987787247, Lr:0.0001\n",
      "Epoch 15, Step: 860, Loss: 0.16983191668987274, Lr:0.0001\n",
      "Epoch 15, Step: 861, Loss: 0.03907991200685501, Lr:0.0001\n",
      "Epoch 15, Step: 862, Loss: 0.006416558753699064, Lr:0.0001\n",
      "Epoch 15, Step: 863, Loss: 0.09758757799863815, Lr:0.0001\n",
      "Epoch 15, Step: 864, Loss: 0.019649267196655273, Lr:0.0001\n",
      "Epoch 15, Step: 865, Loss: 0.1322953701019287, Lr:0.0001\n",
      "Epoch 15, Step: 866, Loss: 0.004895809106528759, Lr:0.0001\n",
      "Epoch 15, Step: 867, Loss: 0.14886964857578278, Lr:0.0001\n",
      "Epoch 15, Step: 868, Loss: 0.10784859955310822, Lr:0.0001\n",
      "Epoch 15, Step: 869, Loss: 0.09970499575138092, Lr:0.0001\n",
      "Epoch 15, Step: 870, Loss: 0.008225041441619396, Lr:0.0001\n",
      "Epoch 15, Step: 871, Loss: 0.06144656613469124, Lr:0.0001\n",
      "Epoch 15, Step: 872, Loss: 0.18936537206172943, Lr:0.0001\n",
      "Epoch 15, Step: 873, Loss: 0.10362663120031357, Lr:0.0001\n",
      "Epoch 15, Step: 874, Loss: 0.04717639833688736, Lr:0.0001\n",
      "Epoch 15, Step: 875, Loss: 0.01601596362888813, Lr:0.0001\n",
      "Epoch 15, Step: 876, Loss: 0.03167862072587013, Lr:0.0001\n",
      "Epoch 15, Step: 877, Loss: 0.15438710153102875, Lr:0.0001\n",
      "Epoch 15, Step: 878, Loss: 0.1687096357345581, Lr:0.0001\n",
      "Epoch 15, Step: 879, Loss: 0.051654547452926636, Lr:0.0001\n",
      "Epoch 15, Step: 880, Loss: 0.04305613413453102, Lr:0.0001\n",
      "Epoch 15, Step: 881, Loss: 0.20622773468494415, Lr:0.0001\n",
      "Epoch 15, Step: 882, Loss: 0.008619656786322594, Lr:0.0001\n",
      "Epoch 15, Step: 883, Loss: 0.029109222814440727, Lr:0.0001\n",
      "Epoch 15, Step: 884, Loss: 0.1379154622554779, Lr:0.0001\n",
      "Epoch 15, Step: 885, Loss: 0.2084638476371765, Lr:0.0001\n",
      "Epoch 15, Step: 886, Loss: 0.04501461237668991, Lr:0.0001\n",
      "Epoch 15, Step: 887, Loss: 0.029521174728870392, Lr:0.0001\n",
      "Epoch 15, Step: 888, Loss: 0.31935742497444153, Lr:0.0001\n",
      "Epoch 15, Step: 889, Loss: 0.5445760488510132, Lr:0.0001\n",
      "Epoch 15, Step: 890, Loss: 0.09741644561290741, Lr:0.0001\n",
      "Epoch 15, Step: 891, Loss: 0.022629283368587494, Lr:0.0001\n",
      "Epoch 15, Step: 892, Loss: 0.026949629187583923, Lr:0.0001\n",
      "Epoch 15, Step: 893, Loss: 0.044595908373594284, Lr:0.0001\n",
      "Epoch 15, Step: 894, Loss: 0.012838858179748058, Lr:0.0001\n",
      "Epoch 15, Step: 895, Loss: 0.11655660718679428, Lr:0.0001\n",
      "Epoch 15, Step: 896, Loss: 0.10261043161153793, Lr:0.0001\n",
      "Epoch 15, Step: 897, Loss: 0.24169205129146576, Lr:0.0001\n",
      "Epoch 15, Step: 898, Loss: 0.17412468791007996, Lr:0.0001\n",
      "Epoch 15, Step: 899, Loss: 0.0831942930817604, Lr:0.0001\n",
      "Epoch 15, Step: 900, Loss: 0.1355791687965393, Lr:0.0001\n",
      "Epoch 15, Step: 901, Loss: 0.02356688864529133, Lr:0.0001\n",
      "Epoch 15, Step: 902, Loss: 0.13329535722732544, Lr:0.0001\n",
      "Epoch 15, Step: 903, Loss: 0.05646009370684624, Lr:0.0001\n",
      "Epoch 15, Step: 904, Loss: 0.041532598435878754, Lr:0.0001\n",
      "Epoch 15, Step: 905, Loss: 0.03222722187638283, Lr:0.0001\n",
      "Epoch 15, Step: 906, Loss: 0.7178678512573242, Lr:0.0001\n",
      "Epoch 15, Step: 907, Loss: 0.010428490117192268, Lr:0.0001\n",
      "Epoch 15, Step: 908, Loss: 0.03113914467394352, Lr:0.0001\n",
      "Epoch 15, Step: 909, Loss: 0.2378028780221939, Lr:0.0001\n",
      "Epoch 15, Step: 910, Loss: 0.009744776412844658, Lr:0.0001\n",
      "Epoch 15, Step: 911, Loss: 0.05234071612358093, Lr:0.0001\n",
      "Epoch 15, Step: 912, Loss: 0.003000260330736637, Lr:0.0001\n",
      "Epoch 15, Step: 913, Loss: 0.12279237061738968, Lr:0.0001\n",
      "Epoch 15, Step: 914, Loss: 0.23046857118606567, Lr:0.0001\n",
      "Epoch 15, Step: 915, Loss: 0.05556602030992508, Lr:0.0001\n",
      "Epoch 15, Step: 916, Loss: 0.11787831783294678, Lr:0.0001\n",
      "Epoch 15, Step: 917, Loss: 0.24320490658283234, Lr:0.0001\n",
      "Epoch 15, Step: 918, Loss: 0.04595128446817398, Lr:0.0001\n",
      "Epoch 15, Step: 919, Loss: 0.5192072987556458, Lr:0.0001\n",
      "Epoch 15, Step: 920, Loss: 0.05680738016963005, Lr:0.0001\n",
      "Epoch 15, Step: 921, Loss: 0.020055165514349937, Lr:0.0001\n",
      "Epoch 15, Step: 922, Loss: 0.034487951546907425, Lr:0.0001\n",
      "Epoch 15, Step: 923, Loss: 0.10111533105373383, Lr:0.0001\n",
      "Epoch 15, Step: 924, Loss: 0.22446149587631226, Lr:0.0001\n",
      "Epoch 15, Step: 925, Loss: 0.2000984400510788, Lr:0.0001\n",
      "Epoch 15, Step: 926, Loss: 0.19382385909557343, Lr:0.0001\n",
      "Epoch 15, Step: 927, Loss: 0.0847155898809433, Lr:0.0001\n",
      "Epoch 15, Step: 928, Loss: 0.14222604036331177, Lr:0.0001\n",
      "Epoch 15, Step: 929, Loss: 0.19148048758506775, Lr:0.0001\n",
      "Epoch 15, Step: 930, Loss: 0.038829952478408813, Lr:0.0001\n",
      "Epoch 15, Step: 931, Loss: 0.048782430589199066, Lr:0.0001\n",
      "Epoch 15, Step: 932, Loss: 0.11589588969945908, Lr:0.0001\n",
      "Epoch 15, Step: 933, Loss: 0.15322495996952057, Lr:0.0001\n",
      "Epoch 15, Step: 934, Loss: 0.1664126217365265, Lr:0.0001\n",
      "Epoch 15, Step: 935, Loss: 0.36046919226646423, Lr:0.0001\n",
      "Epoch 15, Step: 936, Loss: 0.024419715628027916, Lr:0.0001\n",
      "Epoch 15, Step: 937, Loss: 0.06162117421627045, Lr:0.0001\n",
      "Epoch 15, Step: 938, Loss: 0.1885848045349121, Lr:0.0001\n",
      "Epoch 15, Step: 939, Loss: 0.005550773814320564, Lr:0.0001\n",
      "Epoch 15, Step: 940, Loss: 0.05476406589150429, Lr:0.0001\n",
      "Epoch 15, Step: 941, Loss: 0.0820750817656517, Lr:0.0001\n",
      "Epoch 15, Step: 942, Loss: 0.46455878019332886, Lr:0.0001\n",
      "Epoch 15, Step: 943, Loss: 0.08294644206762314, Lr:0.0001\n",
      "Epoch 15, Step: 944, Loss: 0.04112696647644043, Lr:0.0001\n",
      "Epoch 15, Step: 945, Loss: 0.11640182137489319, Lr:0.0001\n",
      "Epoch 15, Step: 946, Loss: 0.0582556426525116, Lr:0.0001\n",
      "Epoch 15, Step: 947, Loss: 0.017206141725182533, Lr:0.0001\n",
      "Epoch 15, Step: 948, Loss: 0.1560506373643875, Lr:0.0001\n",
      "Epoch 15, Step: 949, Loss: 0.07131413370370865, Lr:0.0001\n",
      "Epoch 15, Step: 950, Loss: 0.020500829443335533, Lr:0.0001\n",
      "Epoch 15, Step: 951, Loss: 0.07690688222646713, Lr:0.0001\n",
      "Epoch 15, Step: 952, Loss: 0.3147977292537689, Lr:0.0001\n",
      "Epoch 15, Step: 953, Loss: 0.13030214607715607, Lr:0.0001\n",
      "Epoch 15, Step: 954, Loss: 0.028910581022500992, Lr:0.0001\n",
      "Epoch 15, Step: 955, Loss: 0.1547153890132904, Lr:0.0001\n",
      "Epoch 15, Step: 956, Loss: 0.1906071901321411, Lr:0.0001\n",
      "Epoch 15, Step: 957, Loss: 0.1130901575088501, Lr:0.0001\n",
      "Epoch 15, Step: 958, Loss: 0.2272874414920807, Lr:0.0001\n",
      "Epoch 15, Step: 959, Loss: 0.08941543102264404, Lr:0.0001\n",
      "Epoch 15, Step: 960, Loss: 0.2719525694847107, Lr:0.0001\n",
      "Epoch 15, Step: 961, Loss: 0.08407724648714066, Lr:0.0001\n",
      "Epoch 15, Step: 962, Loss: 0.034252364188432693, Lr:0.0001\n",
      "Epoch 15, Step: 963, Loss: 0.7366348505020142, Lr:0.0001\n",
      "Epoch 15, Step: 964, Loss: 0.05598935857415199, Lr:0.0001\n",
      "Epoch 15, Step: 965, Loss: 0.0038595646619796753, Lr:0.0001\n",
      "Epoch 15, Step: 966, Loss: 0.07855825126171112, Lr:0.0001\n",
      "Epoch 15, Step: 967, Loss: 0.10053092241287231, Lr:0.0001\n",
      "Epoch 15, Step: 968, Loss: 0.19964584708213806, Lr:0.0001\n",
      "Epoch 15, Step: 969, Loss: 0.37404340505599976, Lr:0.0001\n",
      "Epoch 15, Step: 970, Loss: 0.03869061544537544, Lr:0.0001\n",
      "Epoch 15, Step: 971, Loss: 0.13247399032115936, Lr:0.0001\n",
      "Epoch 15, Step: 972, Loss: 0.022937647998332977, Lr:0.0001\n",
      "Epoch 15, Step: 973, Loss: 0.1850951462984085, Lr:0.0001\n",
      "Epoch 15, Step: 974, Loss: 0.04801299422979355, Lr:0.0001\n",
      "Epoch 15, Step: 975, Loss: 0.015265125781297684, Lr:0.0001\n",
      "Epoch 15, Step: 976, Loss: 0.4025722146034241, Lr:0.0001\n",
      "Epoch 15, Step: 977, Loss: 0.5269410610198975, Lr:0.0001\n",
      "Epoch 15, Step: 978, Loss: 0.10461520403623581, Lr:0.0001\n",
      "Epoch 15, Step: 979, Loss: 0.03097076527774334, Lr:0.0001\n",
      "Epoch 15, Step: 980, Loss: 0.34576311707496643, Lr:0.0001\n",
      "Epoch 15, Step: 981, Loss: 0.2549411654472351, Lr:0.0001\n",
      "Epoch 15, Step: 982, Loss: 0.07109378278255463, Lr:0.0001\n",
      "Epoch 15, Step: 983, Loss: 0.253204882144928, Lr:0.0001\n",
      "Epoch 15, Step: 984, Loss: 0.1778300702571869, Lr:0.0001\n",
      "Epoch 15, Step: 985, Loss: 0.08428384363651276, Lr:0.0001\n",
      "Epoch 15, Step: 986, Loss: 0.40192121267318726, Lr:0.0001\n",
      "Epoch 15, Step: 987, Loss: 0.007578880060464144, Lr:0.0001\n",
      "Epoch 15, Step: 988, Loss: 0.10020299255847931, Lr:0.0001\n",
      "Epoch 15, Step: 989, Loss: 0.10776771605014801, Lr:0.0001\n",
      "Epoch 15, Step: 990, Loss: 0.09451931715011597, Lr:0.0001\n",
      "Epoch 15, Step: 991, Loss: 0.03129918500781059, Lr:0.0001\n",
      "Epoch 15, Step: 992, Loss: 0.12021887302398682, Lr:0.0001\n",
      "Epoch 15, Step: 993, Loss: 0.03990069031715393, Lr:0.0001\n",
      "Epoch 15, Step: 994, Loss: 0.15292766690254211, Lr:0.0001\n",
      "Epoch 15, Step: 995, Loss: 0.01460913848131895, Lr:0.0001\n",
      "Epoch 15, Step: 996, Loss: 0.007463523186743259, Lr:0.0001\n",
      "Epoch 15, Step: 997, Loss: 0.17736677825450897, Lr:0.0001\n",
      "Epoch 15, Step: 998, Loss: 0.1726619452238083, Lr:0.0001\n",
      "Epoch 15, Step: 999, Loss: 0.06357382237911224, Lr:0.0001\n",
      "Epoch 15, Step: 1000, Loss: 0.06788008660078049, Lr:0.0001\n",
      "Epoch 15, Step: 1001, Loss: 0.06357000768184662, Lr:0.0001\n",
      "Epoch 15, Step: 1002, Loss: 0.03477580472826958, Lr:0.0001\n",
      "Epoch 15, Step: 1003, Loss: 0.11279874294996262, Lr:0.0001\n",
      "Epoch 15, Step: 1004, Loss: 0.06510750204324722, Lr:0.0001\n",
      "Epoch 15, Step: 1005, Loss: 0.1534498929977417, Lr:0.0001\n",
      "Epoch 15, Step: 1006, Loss: 0.017730461433529854, Lr:0.0001\n",
      "Epoch 15, Step: 1007, Loss: 0.07126870006322861, Lr:0.0001\n",
      "Epoch 15, Step: 1008, Loss: 0.05997878313064575, Lr:0.0001\n",
      "Epoch 15, Step: 1009, Loss: 0.14466489851474762, Lr:0.0001\n",
      "Epoch 15, Step: 1010, Loss: 0.3459596037864685, Lr:0.0001\n",
      "Epoch 15, Step: 1011, Loss: 0.03144071623682976, Lr:0.0001\n",
      "Epoch 15, Step: 1012, Loss: 0.046334922313690186, Lr:0.0001\n",
      "Epoch 15, Step: 1013, Loss: 0.02139083296060562, Lr:0.0001\n",
      "Epoch 15, Step: 1014, Loss: 0.022267771884799004, Lr:0.0001\n",
      "Epoch 15, Step: 1015, Loss: 0.0683317631483078, Lr:0.0001\n",
      "Epoch 15, Step: 1016, Loss: 0.41716498136520386, Lr:0.0001\n",
      "Epoch 15, Step: 1017, Loss: 0.01748567447066307, Lr:0.0001\n",
      "Epoch 15, Step: 1018, Loss: 0.12549906969070435, Lr:0.0001\n",
      "Epoch 15, Step: 1019, Loss: 0.043505001813173294, Lr:0.0001\n",
      "Epoch 15, Step: 1020, Loss: 0.014130517840385437, Lr:0.0001\n",
      "Epoch 15, Step: 1021, Loss: 0.003958630375564098, Lr:0.0001\n",
      "Epoch 15, Step: 1022, Loss: 0.24588419497013092, Lr:0.0001\n",
      "Epoch 15, Step: 1023, Loss: 0.004874885082244873, Lr:0.0001\n",
      "Epoch 15, Step: 1024, Loss: 0.02362978644669056, Lr:0.0001\n",
      "Epoch 15, Step: 1025, Loss: 0.05033431947231293, Lr:0.0001\n",
      "Epoch 15, Step: 1026, Loss: 0.19158518314361572, Lr:0.0001\n",
      "Epoch 15, Step: 1027, Loss: 0.14147347211837769, Lr:0.0001\n",
      "Epoch 15, Step: 1028, Loss: 0.06760228425264359, Lr:0.0001\n",
      "Epoch 15, Step: 1029, Loss: 0.08130072057247162, Lr:0.0001\n",
      "Epoch 15, Step: 1030, Loss: 0.17046043276786804, Lr:0.0001\n",
      "Epoch 15, Step: 1031, Loss: 0.26132550835609436, Lr:0.0001\n",
      "Epoch 15, Step: 1032, Loss: 0.0029745695646852255, Lr:0.0001\n",
      "Epoch 15, Step: 1033, Loss: 0.1627500057220459, Lr:0.0001\n",
      "Epoch 15, Step: 1034, Loss: 0.009203404188156128, Lr:0.0001\n",
      "Epoch 15, Step: 1035, Loss: 0.1455358862876892, Lr:0.0001\n",
      "Epoch 15, Step: 1036, Loss: 0.06997090578079224, Lr:0.0001\n",
      "Epoch 15, Step: 1037, Loss: 0.03314043581485748, Lr:0.0001\n",
      "Epoch 15, Step: 1038, Loss: 0.02601371891796589, Lr:0.0001\n",
      "Epoch 15, Step: 1039, Loss: 0.02770891971886158, Lr:0.0001\n",
      "Epoch 15, Step: 1040, Loss: 0.0508129820227623, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 15\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:16 loss: 1.2020 (1.2020) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.2970 data: 0.1160 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:14 loss: 0.1343 (0.2581) acc1: 87.5000 (91.4773) acc5: 100.0000 (100.0000) time: 0.3078 data: 0.1201 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:11 loss: 0.1343 (0.2261) acc1: 93.7500 (92.5595) acc5: 100.0000 (100.0000) time: 0.3226 data: 0.1226 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:08 loss: 0.1954 (0.2999) acc1: 93.7500 (88.7097) acc5: 100.0000 (100.0000) time: 0.3241 data: 0.1210 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:05 loss: 0.1559 (0.2716) acc1: 93.7500 (90.2439) acc5: 100.0000 (100.0000) time: 0.3167 data: 0.1236 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0386 (0.2365) acc1: 100.0000 (91.2990) acc5: 100.0000 (100.0000) time: 0.3135 data: 0.1285 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0474 (0.2248) acc1: 100.0000 (91.6005) acc5: 100.0000 (100.0000) time: 0.2993 data: 0.1230 max mem: 15137\n",
      "Test: Total time: 0:00:17 (0.3114 s / it)\n",
      "* Acc@1 91.600 Acc@5 100.000 loss 0.225\n",
      "Accuracy of the network on the 881 test image: 91.6%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 16, Step: 0, Loss: 0.04537726566195488, Lr:0.0001\n",
      "Epoch 16, Step: 1, Loss: 0.25734710693359375, Lr:0.0001\n",
      "Epoch 16, Step: 2, Loss: 0.09006525576114655, Lr:0.0001\n",
      "Epoch 16, Step: 3, Loss: 0.03373384475708008, Lr:0.0001\n",
      "Epoch 16, Step: 4, Loss: 0.09198907762765884, Lr:0.0001\n",
      "Epoch 16, Step: 5, Loss: 0.24350890517234802, Lr:0.0001\n",
      "Epoch 16, Step: 6, Loss: 0.10529825836420059, Lr:0.0001\n",
      "Epoch 16, Step: 7, Loss: 0.009665374644100666, Lr:0.0001\n",
      "Epoch 16, Step: 8, Loss: 0.15813130140304565, Lr:0.0001\n",
      "Epoch 16, Step: 9, Loss: 0.06020588427782059, Lr:0.0001\n",
      "Epoch 16, Step: 10, Loss: 0.029369574040174484, Lr:0.0001\n",
      "Epoch 16, Step: 11, Loss: 0.12076688557863235, Lr:0.0001\n",
      "Epoch 16, Step: 12, Loss: 0.011076572351157665, Lr:0.0001\n",
      "Epoch 16, Step: 13, Loss: 0.19555562734603882, Lr:0.0001\n",
      "Epoch 16, Step: 14, Loss: 0.21643640100955963, Lr:0.0001\n",
      "Epoch 16, Step: 15, Loss: 0.07789298892021179, Lr:0.0001\n",
      "Epoch 16, Step: 16, Loss: 0.025036077946424484, Lr:0.0001\n",
      "Epoch 16, Step: 17, Loss: 0.009020807221531868, Lr:0.0001\n",
      "Epoch 16, Step: 18, Loss: 0.11136051267385483, Lr:0.0001\n",
      "Epoch 16, Step: 19, Loss: 0.07183976471424103, Lr:0.0001\n",
      "Epoch 16, Step: 20, Loss: 0.21086151897907257, Lr:0.0001\n",
      "Epoch 16, Step: 21, Loss: 0.3565915524959564, Lr:0.0001\n",
      "Epoch 16, Step: 22, Loss: 0.19633978605270386, Lr:0.0001\n",
      "Epoch 16, Step: 23, Loss: 0.06532654911279678, Lr:0.0001\n",
      "Epoch 16, Step: 24, Loss: 0.12588506937026978, Lr:0.0001\n",
      "Epoch 16, Step: 25, Loss: 0.01812470331788063, Lr:0.0001\n",
      "Epoch 16, Step: 26, Loss: 0.12353801727294922, Lr:0.0001\n",
      "Epoch 16, Step: 27, Loss: 0.11362472176551819, Lr:0.0001\n",
      "Epoch 16, Step: 28, Loss: 0.03299405425786972, Lr:0.0001\n",
      "Epoch 16, Step: 29, Loss: 0.06284454464912415, Lr:0.0001\n",
      "Epoch 16, Step: 30, Loss: 0.10281187295913696, Lr:0.0001\n",
      "Epoch 16, Step: 31, Loss: 0.11439380049705505, Lr:0.0001\n",
      "Epoch 16, Step: 32, Loss: 0.16563066840171814, Lr:0.0001\n",
      "Epoch 16, Step: 33, Loss: 0.03918120265007019, Lr:0.0001\n",
      "Epoch 16, Step: 34, Loss: 0.054169852286577225, Lr:0.0001\n",
      "Epoch 16, Step: 35, Loss: 0.11835581809282303, Lr:0.0001\n",
      "Epoch 16, Step: 36, Loss: 0.08015546202659607, Lr:0.0001\n",
      "Epoch 16, Step: 37, Loss: 0.19844047725200653, Lr:0.0001\n",
      "Epoch 16, Step: 38, Loss: 0.03766718879342079, Lr:0.0001\n",
      "Epoch 16, Step: 39, Loss: 0.08935403823852539, Lr:0.0001\n",
      "Epoch 16, Step: 40, Loss: 0.28974029421806335, Lr:0.0001\n",
      "Epoch 16, Step: 41, Loss: 0.11766066402196884, Lr:0.0001\n",
      "Epoch 16, Step: 42, Loss: 0.07141733169555664, Lr:0.0001\n",
      "Epoch 16, Step: 43, Loss: 0.17020069062709808, Lr:0.0001\n",
      "Epoch 16, Step: 44, Loss: 0.0019108452834188938, Lr:0.0001\n",
      "Epoch 16, Step: 45, Loss: 0.04056491702795029, Lr:0.0001\n",
      "Epoch 16, Step: 46, Loss: 0.01451142504811287, Lr:0.0001\n",
      "Epoch 16, Step: 47, Loss: 0.02816106006503105, Lr:0.0001\n",
      "Epoch 16, Step: 48, Loss: 0.03136122226715088, Lr:0.0001\n",
      "Epoch 16, Step: 49, Loss: 0.002653187606483698, Lr:0.0001\n",
      "Epoch 16, Step: 50, Loss: 0.29772695899009705, Lr:0.0001\n",
      "Epoch 16, Step: 51, Loss: 0.21877047419548035, Lr:0.0001\n",
      "Epoch 16, Step: 52, Loss: 0.3240792453289032, Lr:0.0001\n",
      "Epoch 16, Step: 53, Loss: 0.0355486199259758, Lr:0.0001\n",
      "Epoch 16, Step: 54, Loss: 0.17329199612140656, Lr:0.0001\n",
      "Epoch 16, Step: 55, Loss: 0.01495413575321436, Lr:0.0001\n",
      "Epoch 16, Step: 56, Loss: 0.03757510706782341, Lr:0.0001\n",
      "Epoch 16, Step: 57, Loss: 0.349203884601593, Lr:0.0001\n",
      "Epoch 16, Step: 58, Loss: 0.16865691542625427, Lr:0.0001\n",
      "Epoch 16, Step: 59, Loss: 0.13226690888404846, Lr:0.0001\n",
      "Epoch 16, Step: 60, Loss: 0.047186478972435, Lr:0.0001\n",
      "Epoch 16, Step: 61, Loss: 0.032397087663412094, Lr:0.0001\n",
      "Epoch 16, Step: 62, Loss: 0.13401615619659424, Lr:0.0001\n",
      "Epoch 16, Step: 63, Loss: 0.03677620738744736, Lr:0.0001\n",
      "Epoch 16, Step: 64, Loss: 0.08505688607692719, Lr:0.0001\n",
      "Epoch 16, Step: 65, Loss: 0.0858435407280922, Lr:0.0001\n",
      "Epoch 16, Step: 66, Loss: 0.05676373839378357, Lr:0.0001\n",
      "Epoch 16, Step: 67, Loss: 0.05255582556128502, Lr:0.0001\n",
      "Epoch 16, Step: 68, Loss: 0.161636620759964, Lr:0.0001\n",
      "Epoch 16, Step: 69, Loss: 0.13732920587062836, Lr:0.0001\n",
      "Epoch 16, Step: 70, Loss: 0.02965879812836647, Lr:0.0001\n",
      "Epoch 16, Step: 71, Loss: 0.2623664140701294, Lr:0.0001\n",
      "Epoch 16, Step: 72, Loss: 0.0024601805489510298, Lr:0.0001\n",
      "Epoch 16, Step: 73, Loss: 0.0967450737953186, Lr:0.0001\n",
      "Epoch 16, Step: 74, Loss: 0.3651181161403656, Lr:0.0001\n",
      "Epoch 16, Step: 75, Loss: 0.050805218517780304, Lr:0.0001\n",
      "Epoch 16, Step: 76, Loss: 0.006942851468920708, Lr:0.0001\n",
      "Epoch 16, Step: 77, Loss: 0.07521901279687881, Lr:0.0001\n",
      "Epoch 16, Step: 78, Loss: 0.10637664049863815, Lr:0.0001\n",
      "Epoch 16, Step: 79, Loss: 0.04203211888670921, Lr:0.0001\n",
      "Epoch 16, Step: 80, Loss: 0.03510335087776184, Lr:0.0001\n",
      "Epoch 16, Step: 81, Loss: 0.24048157036304474, Lr:0.0001\n",
      "Epoch 16, Step: 82, Loss: 0.07524995505809784, Lr:0.0001\n",
      "Epoch 16, Step: 83, Loss: 0.23276931047439575, Lr:0.0001\n",
      "Epoch 16, Step: 84, Loss: 0.0341038815677166, Lr:0.0001\n",
      "Epoch 16, Step: 85, Loss: 0.03984634950757027, Lr:0.0001\n",
      "Epoch 16, Step: 86, Loss: 0.17229142785072327, Lr:0.0001\n",
      "Epoch 16, Step: 87, Loss: 0.04252998158335686, Lr:0.0001\n",
      "Epoch 16, Step: 88, Loss: 0.04407987743616104, Lr:0.0001\n",
      "Epoch 16, Step: 89, Loss: 0.07066664844751358, Lr:0.0001\n",
      "Epoch 16, Step: 90, Loss: 0.11380811780691147, Lr:0.0001\n",
      "Epoch 16, Step: 91, Loss: 0.1071993038058281, Lr:0.0001\n",
      "Epoch 16, Step: 92, Loss: 0.30572718381881714, Lr:0.0001\n",
      "Epoch 16, Step: 93, Loss: 0.03626452013850212, Lr:0.0001\n",
      "Epoch 16, Step: 94, Loss: 0.22772665321826935, Lr:0.0001\n",
      "Epoch 16, Step: 95, Loss: 0.0874512791633606, Lr:0.0001\n",
      "Epoch 16, Step: 96, Loss: 0.008418776094913483, Lr:0.0001\n",
      "Epoch 16, Step: 97, Loss: 0.16699112951755524, Lr:0.0001\n",
      "Epoch 16, Step: 98, Loss: 0.13443510234355927, Lr:0.0001\n",
      "Epoch 16, Step: 99, Loss: 0.00678928242996335, Lr:0.0001\n",
      "Epoch 16, Step: 100, Loss: 0.16807030141353607, Lr:0.0001\n",
      "Epoch 16, Step: 101, Loss: 0.22189001739025116, Lr:0.0001\n",
      "Epoch 16, Step: 102, Loss: 0.016423910856246948, Lr:0.0001\n",
      "Epoch 16, Step: 103, Loss: 0.015078062191605568, Lr:0.0001\n",
      "Epoch 16, Step: 104, Loss: 0.030136045068502426, Lr:0.0001\n",
      "Epoch 16, Step: 105, Loss: 0.04119916260242462, Lr:0.0001\n",
      "Epoch 16, Step: 106, Loss: 0.1163678988814354, Lr:0.0001\n",
      "Epoch 16, Step: 107, Loss: 0.2911565899848938, Lr:0.0001\n",
      "Epoch 16, Step: 108, Loss: 0.0583573654294014, Lr:0.0001\n",
      "Epoch 16, Step: 109, Loss: 0.1272158920764923, Lr:0.0001\n",
      "Epoch 16, Step: 110, Loss: 0.06643112748861313, Lr:0.0001\n",
      "Epoch 16, Step: 111, Loss: 0.17414425313472748, Lr:0.0001\n",
      "Epoch 16, Step: 112, Loss: 0.2764633595943451, Lr:0.0001\n",
      "Epoch 16, Step: 113, Loss: 0.09202298521995544, Lr:0.0001\n",
      "Epoch 16, Step: 114, Loss: 0.01852552779018879, Lr:0.0001\n",
      "Epoch 16, Step: 115, Loss: 0.0060380855575203896, Lr:0.0001\n",
      "Epoch 16, Step: 116, Loss: 0.16887882351875305, Lr:0.0001\n",
      "Epoch 16, Step: 117, Loss: 0.07429817318916321, Lr:0.0001\n",
      "Epoch 16, Step: 118, Loss: 0.2335546314716339, Lr:0.0001\n",
      "Epoch 16, Step: 119, Loss: 0.14343583583831787, Lr:0.0001\n",
      "Epoch 16, Step: 120, Loss: 0.03367515653371811, Lr:0.0001\n",
      "Epoch 16, Step: 121, Loss: 0.2343449592590332, Lr:0.0001\n",
      "Epoch 16, Step: 122, Loss: 0.025493908673524857, Lr:0.0001\n",
      "Epoch 16, Step: 123, Loss: 0.0951562449336052, Lr:0.0001\n",
      "Epoch 16, Step: 124, Loss: 0.18329904973506927, Lr:0.0001\n",
      "Epoch 16, Step: 125, Loss: 0.05597761645913124, Lr:0.0001\n",
      "Epoch 16, Step: 126, Loss: 0.06481015682220459, Lr:0.0001\n",
      "Epoch 16, Step: 127, Loss: 0.11416637897491455, Lr:0.0001\n",
      "Epoch 16, Step: 128, Loss: 0.16481007635593414, Lr:0.0001\n",
      "Epoch 16, Step: 129, Loss: 0.025507809594273567, Lr:0.0001\n",
      "Epoch 16, Step: 130, Loss: 0.49834322929382324, Lr:0.0001\n",
      "Epoch 16, Step: 131, Loss: 0.21960361301898956, Lr:0.0001\n",
      "Epoch 16, Step: 132, Loss: 0.1682889312505722, Lr:0.0001\n",
      "Epoch 16, Step: 133, Loss: 0.04608038067817688, Lr:0.0001\n",
      "Epoch 16, Step: 134, Loss: 0.11916136741638184, Lr:0.0001\n",
      "Epoch 16, Step: 135, Loss: 0.05467725172638893, Lr:0.0001\n",
      "Epoch 16, Step: 136, Loss: 0.03451966866850853, Lr:0.0001\n",
      "Epoch 16, Step: 137, Loss: 0.09477631747722626, Lr:0.0001\n",
      "Epoch 16, Step: 138, Loss: 0.17054231464862823, Lr:0.0001\n",
      "Epoch 16, Step: 139, Loss: 0.5247370004653931, Lr:0.0001\n",
      "Epoch 16, Step: 140, Loss: 0.06407323479652405, Lr:0.0001\n",
      "Epoch 16, Step: 141, Loss: 0.054161977022886276, Lr:0.0001\n",
      "Epoch 16, Step: 142, Loss: 0.1784268319606781, Lr:0.0001\n",
      "Epoch 16, Step: 143, Loss: 0.06819141656160355, Lr:0.0001\n",
      "Epoch 16, Step: 144, Loss: 0.20033857226371765, Lr:0.0001\n",
      "Epoch 16, Step: 145, Loss: 0.045863937586545944, Lr:0.0001\n",
      "Epoch 16, Step: 146, Loss: 0.22925719618797302, Lr:0.0001\n",
      "Epoch 16, Step: 147, Loss: 0.014051181264221668, Lr:0.0001\n",
      "Epoch 16, Step: 148, Loss: 0.07760724425315857, Lr:0.0001\n",
      "Epoch 16, Step: 149, Loss: 0.08354143798351288, Lr:0.0001\n",
      "Epoch 16, Step: 150, Loss: 0.16011761128902435, Lr:0.0001\n",
      "Epoch 16, Step: 151, Loss: 0.15373603999614716, Lr:0.0001\n",
      "Epoch 16, Step: 152, Loss: 0.03145703300833702, Lr:0.0001\n",
      "Epoch 16, Step: 153, Loss: 0.1396697759628296, Lr:0.0001\n",
      "Epoch 16, Step: 154, Loss: 0.06638477742671967, Lr:0.0001\n",
      "Epoch 16, Step: 155, Loss: 0.2147897332906723, Lr:0.0001\n",
      "Epoch 16, Step: 156, Loss: 0.09853215515613556, Lr:0.0001\n",
      "Epoch 16, Step: 157, Loss: 0.16194891929626465, Lr:0.0001\n",
      "Epoch 16, Step: 158, Loss: 0.0431554950773716, Lr:0.0001\n",
      "Epoch 16, Step: 159, Loss: 0.0233183354139328, Lr:0.0001\n",
      "Epoch 16, Step: 160, Loss: 0.1773035228252411, Lr:0.0001\n",
      "Epoch 16, Step: 161, Loss: 0.02185089886188507, Lr:0.0001\n",
      "Epoch 16, Step: 162, Loss: 0.01831727847456932, Lr:0.0001\n",
      "Epoch 16, Step: 163, Loss: 0.11568313837051392, Lr:0.0001\n",
      "Epoch 16, Step: 164, Loss: 0.08266850560903549, Lr:0.0001\n",
      "Epoch 16, Step: 165, Loss: 0.007270989008247852, Lr:0.0001\n",
      "Epoch 16, Step: 166, Loss: 0.09295761585235596, Lr:0.0001\n",
      "Epoch 16, Step: 167, Loss: 0.05547546595335007, Lr:0.0001\n",
      "Epoch 16, Step: 168, Loss: 0.0459379144012928, Lr:0.0001\n",
      "Epoch 16, Step: 169, Loss: 0.08174268156290054, Lr:0.0001\n",
      "Epoch 16, Step: 170, Loss: 0.1113273948431015, Lr:0.0001\n",
      "Epoch 16, Step: 171, Loss: 0.33535876870155334, Lr:0.0001\n",
      "Epoch 16, Step: 172, Loss: 0.10447153449058533, Lr:0.0001\n",
      "Epoch 16, Step: 173, Loss: 0.11919762194156647, Lr:0.0001\n",
      "Epoch 16, Step: 174, Loss: 0.01755102537572384, Lr:0.0001\n",
      "Epoch 16, Step: 175, Loss: 0.17184880375862122, Lr:0.0001\n",
      "Epoch 16, Step: 176, Loss: 0.1554040014743805, Lr:0.0001\n",
      "Epoch 16, Step: 177, Loss: 0.031833767890930176, Lr:0.0001\n",
      "Epoch 16, Step: 178, Loss: 0.11898782849311829, Lr:0.0001\n",
      "Epoch 16, Step: 179, Loss: 0.0511598065495491, Lr:0.0001\n",
      "Epoch 16, Step: 180, Loss: 0.2313499003648758, Lr:0.0001\n",
      "Epoch 16, Step: 181, Loss: 0.018673915416002274, Lr:0.0001\n",
      "Epoch 16, Step: 182, Loss: 0.012054874561727047, Lr:0.0001\n",
      "Epoch 16, Step: 183, Loss: 0.019255463033914566, Lr:0.0001\n",
      "Epoch 16, Step: 184, Loss: 0.038482990115880966, Lr:0.0001\n",
      "Epoch 16, Step: 185, Loss: 0.09102723747491837, Lr:0.0001\n",
      "Epoch 16, Step: 186, Loss: 0.018503796309232712, Lr:0.0001\n",
      "Epoch 16, Step: 187, Loss: 0.07280220836400986, Lr:0.0001\n",
      "Epoch 16, Step: 188, Loss: 0.008324244059622288, Lr:0.0001\n",
      "Epoch 16, Step: 189, Loss: 0.024377156049013138, Lr:0.0001\n",
      "Epoch 16, Step: 190, Loss: 0.08065486699342728, Lr:0.0001\n",
      "Epoch 16, Step: 191, Loss: 0.11206001043319702, Lr:0.0001\n",
      "Epoch 16, Step: 192, Loss: 0.0897463783621788, Lr:0.0001\n",
      "Epoch 16, Step: 193, Loss: 0.06013471260666847, Lr:0.0001\n",
      "Epoch 16, Step: 194, Loss: 0.028723260387778282, Lr:0.0001\n",
      "Epoch 16, Step: 195, Loss: 0.06305679678916931, Lr:0.0001\n",
      "Epoch 16, Step: 196, Loss: 0.09734383970499039, Lr:0.0001\n",
      "Epoch 16, Step: 197, Loss: 0.08730112016201019, Lr:0.0001\n",
      "Epoch 16, Step: 198, Loss: 0.1572577953338623, Lr:0.0001\n",
      "Epoch 16, Step: 199, Loss: 0.019012821838259697, Lr:0.0001\n",
      "Epoch 16, Step: 200, Loss: 0.2512345314025879, Lr:0.0001\n",
      "Epoch 16, Step: 201, Loss: 0.04980839043855667, Lr:0.0001\n",
      "Epoch 16, Step: 202, Loss: 0.008205654099583626, Lr:0.0001\n",
      "Epoch 16, Step: 203, Loss: 0.0028014988638460636, Lr:0.0001\n",
      "Epoch 16, Step: 204, Loss: 0.03521803021430969, Lr:0.0001\n",
      "Epoch 16, Step: 205, Loss: 0.07683248817920685, Lr:0.0001\n",
      "Epoch 16, Step: 206, Loss: 0.020428339019417763, Lr:0.0001\n",
      "Epoch 16, Step: 207, Loss: 0.11825967580080032, Lr:0.0001\n",
      "Epoch 16, Step: 208, Loss: 0.13655205070972443, Lr:0.0001\n",
      "Epoch 16, Step: 209, Loss: 0.02294725924730301, Lr:0.0001\n",
      "Epoch 16, Step: 210, Loss: 0.08185164630413055, Lr:0.0001\n",
      "Epoch 16, Step: 211, Loss: 0.03181905671954155, Lr:0.0001\n",
      "Epoch 16, Step: 212, Loss: 0.009639165364205837, Lr:0.0001\n",
      "Epoch 16, Step: 213, Loss: 0.027422796934843063, Lr:0.0001\n",
      "Epoch 16, Step: 214, Loss: 0.4169350564479828, Lr:0.0001\n",
      "Epoch 16, Step: 215, Loss: 0.4833959937095642, Lr:0.0001\n",
      "Epoch 16, Step: 216, Loss: 0.05064912140369415, Lr:0.0001\n",
      "Epoch 16, Step: 217, Loss: 0.014456732198596, Lr:0.0001\n",
      "Epoch 16, Step: 218, Loss: 0.18459147214889526, Lr:0.0001\n",
      "Epoch 16, Step: 219, Loss: 0.13219177722930908, Lr:0.0001\n",
      "Epoch 16, Step: 220, Loss: 0.048049986362457275, Lr:0.0001\n",
      "Epoch 16, Step: 221, Loss: 0.005774431861937046, Lr:0.0001\n",
      "Epoch 16, Step: 222, Loss: 0.054427117109298706, Lr:0.0001\n",
      "Epoch 16, Step: 223, Loss: 0.046223174780607224, Lr:0.0001\n",
      "Epoch 16, Step: 224, Loss: 0.054118432104587555, Lr:0.0001\n",
      "Epoch 16, Step: 225, Loss: 0.009620971977710724, Lr:0.0001\n",
      "Epoch 16, Step: 226, Loss: 0.08244328200817108, Lr:0.0001\n",
      "Epoch 16, Step: 227, Loss: 0.16175180673599243, Lr:0.0001\n",
      "Epoch 16, Step: 228, Loss: 0.500090479850769, Lr:0.0001\n",
      "Epoch 16, Step: 229, Loss: 0.08341769874095917, Lr:0.0001\n",
      "Epoch 16, Step: 230, Loss: 0.18369856476783752, Lr:0.0001\n",
      "Epoch 16, Step: 231, Loss: 0.144756019115448, Lr:0.0001\n",
      "Epoch 16, Step: 232, Loss: 0.016499441117048264, Lr:0.0001\n",
      "Epoch 16, Step: 233, Loss: 0.20368054509162903, Lr:0.0001\n",
      "Epoch 16, Step: 234, Loss: 0.0726408138871193, Lr:0.0001\n",
      "Epoch 16, Step: 235, Loss: 0.2803474962711334, Lr:0.0001\n",
      "Epoch 16, Step: 236, Loss: 0.04590243473649025, Lr:0.0001\n",
      "Epoch 16, Step: 237, Loss: 0.09402354061603546, Lr:0.0001\n",
      "Epoch 16, Step: 238, Loss: 0.1213400736451149, Lr:0.0001\n",
      "Epoch 16, Step: 239, Loss: 0.011357534676790237, Lr:0.0001\n",
      "Epoch 16, Step: 240, Loss: 0.2719440758228302, Lr:0.0001\n",
      "Epoch 16, Step: 241, Loss: 0.1994977742433548, Lr:0.0001\n",
      "Epoch 16, Step: 242, Loss: 0.020131757482886314, Lr:0.0001\n",
      "Epoch 16, Step: 243, Loss: 0.027957454323768616, Lr:0.0001\n",
      "Epoch 16, Step: 244, Loss: 0.07231886684894562, Lr:0.0001\n",
      "Epoch 16, Step: 245, Loss: 0.10108280926942825, Lr:0.0001\n",
      "Epoch 16, Step: 246, Loss: 0.12572047114372253, Lr:0.0001\n",
      "Epoch 16, Step: 247, Loss: 0.012933246791362762, Lr:0.0001\n",
      "Epoch 16, Step: 248, Loss: 0.10414174944162369, Lr:0.0001\n",
      "Epoch 16, Step: 249, Loss: 0.2852122187614441, Lr:0.0001\n",
      "Epoch 16, Step: 250, Loss: 0.03461211547255516, Lr:0.0001\n",
      "Epoch 16, Step: 251, Loss: 0.18278877437114716, Lr:0.0001\n",
      "Epoch 16, Step: 252, Loss: 0.16325001418590546, Lr:0.0001\n",
      "Epoch 16, Step: 253, Loss: 0.01577136106789112, Lr:0.0001\n",
      "Epoch 16, Step: 254, Loss: 0.17042939364910126, Lr:0.0001\n",
      "Epoch 16, Step: 255, Loss: 0.19269093871116638, Lr:0.0001\n",
      "Epoch 16, Step: 256, Loss: 0.004832932259887457, Lr:0.0001\n",
      "Epoch 16, Step: 257, Loss: 0.1011853888630867, Lr:0.0001\n",
      "Epoch 16, Step: 258, Loss: 0.12138381600379944, Lr:0.0001\n",
      "Epoch 16, Step: 259, Loss: 0.007120267488062382, Lr:0.0001\n",
      "Epoch 16, Step: 260, Loss: 0.4299590289592743, Lr:0.0001\n",
      "Epoch 16, Step: 261, Loss: 0.039523690938949585, Lr:0.0001\n",
      "Epoch 16, Step: 262, Loss: 0.07954338937997818, Lr:0.0001\n",
      "Epoch 16, Step: 263, Loss: 0.06885543465614319, Lr:0.0001\n",
      "Epoch 16, Step: 264, Loss: 0.0840374082326889, Lr:0.0001\n",
      "Epoch 16, Step: 265, Loss: 0.024903733283281326, Lr:0.0001\n",
      "Epoch 16, Step: 266, Loss: 0.27870652079582214, Lr:0.0001\n",
      "Epoch 16, Step: 267, Loss: 0.18388886749744415, Lr:0.0001\n",
      "Epoch 16, Step: 268, Loss: 0.05802929401397705, Lr:0.0001\n",
      "Epoch 16, Step: 269, Loss: 0.013369213789701462, Lr:0.0001\n",
      "Epoch 16, Step: 270, Loss: 0.020907647907733917, Lr:0.0001\n",
      "Epoch 16, Step: 271, Loss: 0.09588883817195892, Lr:0.0001\n",
      "Epoch 16, Step: 272, Loss: 0.010704531334340572, Lr:0.0001\n",
      "Epoch 16, Step: 273, Loss: 0.09574214369058609, Lr:0.0001\n",
      "Epoch 16, Step: 274, Loss: 0.0919128805398941, Lr:0.0001\n",
      "Epoch 16, Step: 275, Loss: 0.01050008088350296, Lr:0.0001\n",
      "Epoch 16, Step: 276, Loss: 0.22255510091781616, Lr:0.0001\n",
      "Epoch 16, Step: 277, Loss: 0.09037593752145767, Lr:0.0001\n",
      "Epoch 16, Step: 278, Loss: 0.13326753675937653, Lr:0.0001\n",
      "Epoch 16, Step: 279, Loss: 0.050731923431158066, Lr:0.0001\n",
      "Epoch 16, Step: 280, Loss: 0.1681888997554779, Lr:0.0001\n",
      "Epoch 16, Step: 281, Loss: 0.0025710677728056908, Lr:0.0001\n",
      "Epoch 16, Step: 282, Loss: 0.06929869204759598, Lr:0.0001\n",
      "Epoch 16, Step: 283, Loss: 0.10566511005163193, Lr:0.0001\n",
      "Epoch 16, Step: 284, Loss: 0.34319615364074707, Lr:0.0001\n",
      "Epoch 16, Step: 285, Loss: 0.34423911571502686, Lr:0.0001\n",
      "Epoch 16, Step: 286, Loss: 0.10480879992246628, Lr:0.0001\n",
      "Epoch 16, Step: 287, Loss: 0.014942790381610394, Lr:0.0001\n",
      "Epoch 16, Step: 288, Loss: 0.03519756719470024, Lr:0.0001\n",
      "Epoch 16, Step: 289, Loss: 0.08422797918319702, Lr:0.0001\n",
      "Epoch 16, Step: 290, Loss: 0.014158367179334164, Lr:0.0001\n",
      "Epoch 16, Step: 291, Loss: 0.03839653357863426, Lr:0.0001\n",
      "Epoch 16, Step: 292, Loss: 0.03571123257279396, Lr:0.0001\n",
      "Epoch 16, Step: 293, Loss: 0.03056032769382, Lr:0.0001\n",
      "Epoch 16, Step: 294, Loss: 0.06650256365537643, Lr:0.0001\n",
      "Epoch 16, Step: 295, Loss: 0.026778994128108025, Lr:0.0001\n",
      "Epoch 16, Step: 296, Loss: 0.05408982187509537, Lr:0.0001\n",
      "Epoch 16, Step: 297, Loss: 0.10357283055782318, Lr:0.0001\n",
      "Epoch 16, Step: 298, Loss: 0.12029171735048294, Lr:0.0001\n",
      "Epoch 16, Step: 299, Loss: 0.02252478152513504, Lr:0.0001\n",
      "Epoch 16, Step: 300, Loss: 0.09927774965763092, Lr:0.0001\n",
      "Epoch 16, Step: 301, Loss: 0.02159721404314041, Lr:0.0001\n",
      "Epoch 16, Step: 302, Loss: 0.07102075964212418, Lr:0.0001\n",
      "Epoch 16, Step: 303, Loss: 0.04358910396695137, Lr:0.0001\n",
      "Epoch 16, Step: 304, Loss: 0.0323963463306427, Lr:0.0001\n",
      "Epoch 16, Step: 305, Loss: 0.02333894371986389, Lr:0.0001\n",
      "Epoch 16, Step: 306, Loss: 0.03746044263243675, Lr:0.0001\n",
      "Epoch 16, Step: 307, Loss: 0.020932869985699654, Lr:0.0001\n",
      "Epoch 16, Step: 308, Loss: 0.17685963213443756, Lr:0.0001\n",
      "Epoch 16, Step: 309, Loss: 0.015520257875323296, Lr:0.0001\n",
      "Epoch 16, Step: 310, Loss: 0.006669563241302967, Lr:0.0001\n",
      "Epoch 16, Step: 311, Loss: 0.1327299326658249, Lr:0.0001\n",
      "Epoch 16, Step: 312, Loss: 0.1067141741514206, Lr:0.0001\n",
      "Epoch 16, Step: 313, Loss: 0.089738629758358, Lr:0.0001\n",
      "Epoch 16, Step: 314, Loss: 0.006494451779872179, Lr:0.0001\n",
      "Epoch 16, Step: 315, Loss: 0.4610913097858429, Lr:0.0001\n",
      "Epoch 16, Step: 316, Loss: 0.016544770449399948, Lr:0.0001\n",
      "Epoch 16, Step: 317, Loss: 0.02730870619416237, Lr:0.0001\n",
      "Epoch 16, Step: 318, Loss: 0.030377311632037163, Lr:0.0001\n",
      "Epoch 16, Step: 319, Loss: 0.08183062076568604, Lr:0.0001\n",
      "Epoch 16, Step: 320, Loss: 0.11559393256902695, Lr:0.0001\n",
      "Epoch 16, Step: 321, Loss: 0.014923580922186375, Lr:0.0001\n",
      "Epoch 16, Step: 322, Loss: 0.03727981820702553, Lr:0.0001\n",
      "Epoch 16, Step: 323, Loss: 0.05405295267701149, Lr:0.0001\n",
      "Epoch 16, Step: 324, Loss: 0.12528763711452484, Lr:0.0001\n",
      "Epoch 16, Step: 325, Loss: 0.08378095924854279, Lr:0.0001\n",
      "Epoch 16, Step: 326, Loss: 0.01375651452690363, Lr:0.0001\n",
      "Epoch 16, Step: 327, Loss: 0.6586371660232544, Lr:0.0001\n",
      "Epoch 16, Step: 328, Loss: 0.06825369596481323, Lr:0.0001\n",
      "Epoch 16, Step: 329, Loss: 0.24859008193016052, Lr:0.0001\n",
      "Epoch 16, Step: 330, Loss: 0.0865945965051651, Lr:0.0001\n",
      "Epoch 16, Step: 331, Loss: 0.015682479366660118, Lr:0.0001\n",
      "Epoch 16, Step: 332, Loss: 0.17273454368114471, Lr:0.0001\n",
      "Epoch 16, Step: 333, Loss: 0.05519630387425423, Lr:0.0001\n",
      "Epoch 16, Step: 334, Loss: 0.09958884119987488, Lr:0.0001\n",
      "Epoch 16, Step: 335, Loss: 0.0011465372517704964, Lr:0.0001\n",
      "Epoch 16, Step: 336, Loss: 0.1578950732946396, Lr:0.0001\n",
      "Epoch 16, Step: 337, Loss: 0.09161121398210526, Lr:0.0001\n",
      "Epoch 16, Step: 338, Loss: 0.18485337495803833, Lr:0.0001\n",
      "Epoch 16, Step: 339, Loss: 0.28544390201568604, Lr:0.0001\n",
      "Epoch 16, Step: 340, Loss: 0.007133331149816513, Lr:0.0001\n",
      "Epoch 16, Step: 341, Loss: 0.11646167188882828, Lr:0.0001\n",
      "Epoch 16, Step: 342, Loss: 0.07144249230623245, Lr:0.0001\n",
      "Epoch 16, Step: 343, Loss: 0.03044746443629265, Lr:0.0001\n",
      "Epoch 16, Step: 344, Loss: 0.07304148375988007, Lr:0.0001\n",
      "Epoch 16, Step: 345, Loss: 0.10242680460214615, Lr:0.0001\n",
      "Epoch 16, Step: 346, Loss: 0.3426801860332489, Lr:0.0001\n",
      "Epoch 16, Step: 347, Loss: 0.14795829355716705, Lr:0.0001\n",
      "Epoch 16, Step: 348, Loss: 0.08333224803209305, Lr:0.0001\n",
      "Epoch 16, Step: 349, Loss: 0.10562391579151154, Lr:0.0001\n",
      "Epoch 16, Step: 350, Loss: 0.15210004150867462, Lr:0.0001\n",
      "Epoch 16, Step: 351, Loss: 0.5467555522918701, Lr:0.0001\n",
      "Epoch 16, Step: 352, Loss: 0.565862238407135, Lr:0.0001\n",
      "Epoch 16, Step: 353, Loss: 0.05574096739292145, Lr:0.0001\n",
      "Epoch 16, Step: 354, Loss: 0.30405133962631226, Lr:0.0001\n",
      "Epoch 16, Step: 355, Loss: 0.0046854764223098755, Lr:0.0001\n",
      "Epoch 16, Step: 356, Loss: 0.0030388871673494577, Lr:0.0001\n",
      "Epoch 16, Step: 357, Loss: 0.04353003203868866, Lr:0.0001\n",
      "Epoch 16, Step: 358, Loss: 0.07912235707044601, Lr:0.0001\n",
      "Epoch 16, Step: 359, Loss: 0.0027560831513255835, Lr:0.0001\n",
      "Epoch 16, Step: 360, Loss: 0.2380172610282898, Lr:0.0001\n",
      "Epoch 16, Step: 361, Loss: 0.0969516709446907, Lr:0.0001\n",
      "Epoch 16, Step: 362, Loss: 0.1016484946012497, Lr:0.0001\n",
      "Epoch 16, Step: 363, Loss: 0.004800453782081604, Lr:0.0001\n",
      "Epoch 16, Step: 364, Loss: 0.02625851333141327, Lr:0.0001\n",
      "Epoch 16, Step: 365, Loss: 0.05723610520362854, Lr:0.0001\n",
      "Epoch 16, Step: 366, Loss: 0.06388635188341141, Lr:0.0001\n",
      "Epoch 16, Step: 367, Loss: 0.14321550726890564, Lr:0.0001\n",
      "Epoch 16, Step: 368, Loss: 0.2992197573184967, Lr:0.0001\n",
      "Epoch 16, Step: 369, Loss: 0.08706745505332947, Lr:0.0001\n",
      "Epoch 16, Step: 370, Loss: 0.2556258738040924, Lr:0.0001\n",
      "Epoch 16, Step: 371, Loss: 0.02747342176735401, Lr:0.0001\n",
      "Epoch 16, Step: 372, Loss: 0.011550333350896835, Lr:0.0001\n",
      "Epoch 16, Step: 373, Loss: 0.046283092349767685, Lr:0.0001\n",
      "Epoch 16, Step: 374, Loss: 0.14888449013233185, Lr:0.0001\n",
      "Epoch 16, Step: 375, Loss: 0.15288478136062622, Lr:0.0001\n",
      "Epoch 16, Step: 376, Loss: 0.1114846020936966, Lr:0.0001\n",
      "Epoch 16, Step: 377, Loss: 0.11253310739994049, Lr:0.0001\n",
      "Epoch 16, Step: 378, Loss: 0.05510445311665535, Lr:0.0001\n",
      "Epoch 16, Step: 379, Loss: 0.09182451665401459, Lr:0.0001\n",
      "Epoch 16, Step: 380, Loss: 0.02258928120136261, Lr:0.0001\n",
      "Epoch 16, Step: 381, Loss: 0.06738585978746414, Lr:0.0001\n",
      "Epoch 16, Step: 382, Loss: 0.10779239982366562, Lr:0.0001\n",
      "Epoch 16, Step: 383, Loss: 0.1527099311351776, Lr:0.0001\n",
      "Epoch 16, Step: 384, Loss: 0.05160171166062355, Lr:0.0001\n",
      "Epoch 16, Step: 385, Loss: 0.14821799099445343, Lr:0.0001\n",
      "Epoch 16, Step: 386, Loss: 0.15659867227077484, Lr:0.0001\n",
      "Epoch 16, Step: 387, Loss: 0.052860911935567856, Lr:0.0001\n",
      "Epoch 16, Step: 388, Loss: 0.14303182065486908, Lr:0.0001\n",
      "Epoch 16, Step: 389, Loss: 0.054172541946172714, Lr:0.0001\n",
      "Epoch 16, Step: 390, Loss: 0.09106721729040146, Lr:0.0001\n",
      "Epoch 16, Step: 391, Loss: 0.06535308808088303, Lr:0.0001\n",
      "Epoch 16, Step: 392, Loss: 0.026413166895508766, Lr:0.0001\n",
      "Epoch 16, Step: 393, Loss: 0.0652819573879242, Lr:0.0001\n",
      "Epoch 16, Step: 394, Loss: 0.06460604071617126, Lr:0.0001\n",
      "Epoch 16, Step: 395, Loss: 0.035741761326789856, Lr:0.0001\n",
      "Epoch 16, Step: 396, Loss: 0.032198548316955566, Lr:0.0001\n",
      "Epoch 16, Step: 397, Loss: 0.1709611564874649, Lr:0.0001\n",
      "Epoch 16, Step: 398, Loss: 0.06649710983037949, Lr:0.0001\n",
      "Epoch 16, Step: 399, Loss: 0.3938770592212677, Lr:0.0001\n",
      "Epoch 16, Step: 400, Loss: 0.08229102939367294, Lr:0.0001\n",
      "Epoch 16, Step: 401, Loss: 0.20214028656482697, Lr:0.0001\n",
      "Epoch 16, Step: 402, Loss: 0.08909359574317932, Lr:0.0001\n",
      "Epoch 16, Step: 403, Loss: 0.13422545790672302, Lr:0.0001\n",
      "Epoch 16, Step: 404, Loss: 0.39364737272262573, Lr:0.0001\n",
      "Epoch 16, Step: 405, Loss: 0.05490806698799133, Lr:0.0001\n",
      "Epoch 16, Step: 406, Loss: 0.18181753158569336, Lr:0.0001\n",
      "Epoch 16, Step: 407, Loss: 0.014911746606230736, Lr:0.0001\n",
      "Epoch 16, Step: 408, Loss: 0.05243001878261566, Lr:0.0001\n",
      "Epoch 16, Step: 409, Loss: 0.014663456939160824, Lr:0.0001\n",
      "Epoch 16, Step: 410, Loss: 0.12551961839199066, Lr:0.0001\n",
      "Epoch 16, Step: 411, Loss: 0.06433125585317612, Lr:0.0001\n",
      "Epoch 16, Step: 412, Loss: 0.08076079934835434, Lr:0.0001\n",
      "Epoch 16, Step: 413, Loss: 0.1260467916727066, Lr:0.0001\n",
      "Epoch 16, Step: 414, Loss: 0.4546782970428467, Lr:0.0001\n",
      "Epoch 16, Step: 415, Loss: 0.056916795670986176, Lr:0.0001\n",
      "Epoch 16, Step: 416, Loss: 0.022809719666838646, Lr:0.0001\n",
      "Epoch 16, Step: 417, Loss: 0.4308117926120758, Lr:0.0001\n",
      "Epoch 16, Step: 418, Loss: 0.10390609502792358, Lr:0.0001\n",
      "Epoch 16, Step: 419, Loss: 0.5711443424224854, Lr:0.0001\n",
      "Epoch 16, Step: 420, Loss: 0.08519390970468521, Lr:0.0001\n",
      "Epoch 16, Step: 421, Loss: 0.017970509827136993, Lr:0.0001\n",
      "Epoch 16, Step: 422, Loss: 0.050411298871040344, Lr:0.0001\n",
      "Epoch 16, Step: 423, Loss: 0.044409770518541336, Lr:0.0001\n",
      "Epoch 16, Step: 424, Loss: 0.06330147385597229, Lr:0.0001\n",
      "Epoch 16, Step: 425, Loss: 0.03434750810265541, Lr:0.0001\n",
      "Epoch 16, Step: 426, Loss: 0.25445884466171265, Lr:0.0001\n",
      "Epoch 16, Step: 427, Loss: 0.06453119218349457, Lr:0.0001\n",
      "Epoch 16, Step: 428, Loss: 0.00488843722268939, Lr:0.0001\n",
      "Epoch 16, Step: 429, Loss: 0.04511337727308273, Lr:0.0001\n",
      "Epoch 16, Step: 430, Loss: 0.13016366958618164, Lr:0.0001\n",
      "Epoch 16, Step: 431, Loss: 0.10118533670902252, Lr:0.0001\n",
      "Epoch 16, Step: 432, Loss: 0.25961625576019287, Lr:0.0001\n",
      "Epoch 16, Step: 433, Loss: 0.07999446243047714, Lr:0.0001\n",
      "Epoch 16, Step: 434, Loss: 0.14698249101638794, Lr:0.0001\n",
      "Epoch 16, Step: 435, Loss: 0.016371984034776688, Lr:0.0001\n",
      "Epoch 16, Step: 436, Loss: 0.04192538931965828, Lr:0.0001\n",
      "Epoch 16, Step: 437, Loss: 0.1255960315465927, Lr:0.0001\n",
      "Epoch 16, Step: 438, Loss: 0.37955242395401, Lr:0.0001\n",
      "Epoch 16, Step: 439, Loss: 0.06389972567558289, Lr:0.0001\n",
      "Epoch 16, Step: 440, Loss: 0.13476794958114624, Lr:0.0001\n",
      "Epoch 16, Step: 441, Loss: 0.038481295108795166, Lr:0.0001\n",
      "Epoch 16, Step: 442, Loss: 0.1196671724319458, Lr:0.0001\n",
      "Epoch 16, Step: 443, Loss: 0.005833189003169537, Lr:0.0001\n",
      "Epoch 16, Step: 444, Loss: 0.054937008768320084, Lr:0.0001\n",
      "Epoch 16, Step: 445, Loss: 0.043903324753046036, Lr:0.0001\n",
      "Epoch 16, Step: 446, Loss: 0.0370326042175293, Lr:0.0001\n",
      "Epoch 16, Step: 447, Loss: 0.0010285178432241082, Lr:0.0001\n",
      "Epoch 16, Step: 448, Loss: 0.1603519320487976, Lr:0.0001\n",
      "Epoch 16, Step: 449, Loss: 0.028558604419231415, Lr:0.0001\n",
      "Epoch 16, Step: 450, Loss: 0.025074202567338943, Lr:0.0001\n",
      "Epoch 16, Step: 451, Loss: 0.02878313884139061, Lr:0.0001\n",
      "Epoch 16, Step: 452, Loss: 0.018650829792022705, Lr:0.0001\n",
      "Epoch 16, Step: 453, Loss: 0.06607283651828766, Lr:0.0001\n",
      "Epoch 16, Step: 454, Loss: 0.05055674538016319, Lr:0.0001\n",
      "Epoch 16, Step: 455, Loss: 0.37026605010032654, Lr:0.0001\n",
      "Epoch 16, Step: 456, Loss: 0.01663702353835106, Lr:0.0001\n",
      "Epoch 16, Step: 457, Loss: 0.08023214340209961, Lr:0.0001\n",
      "Epoch 16, Step: 458, Loss: 0.06602006405591965, Lr:0.0001\n",
      "Epoch 16, Step: 459, Loss: 0.10818342119455338, Lr:0.0001\n",
      "Epoch 16, Step: 460, Loss: 0.08953996747732162, Lr:0.0001\n",
      "Epoch 16, Step: 461, Loss: 0.1313638836145401, Lr:0.0001\n",
      "Epoch 16, Step: 462, Loss: 0.04746311157941818, Lr:0.0001\n",
      "Epoch 16, Step: 463, Loss: 0.012326491065323353, Lr:0.0001\n",
      "Epoch 16, Step: 464, Loss: 0.020416365936398506, Lr:0.0001\n",
      "Epoch 16, Step: 465, Loss: 0.10372743755578995, Lr:0.0001\n",
      "Epoch 16, Step: 466, Loss: 0.003630849067121744, Lr:0.0001\n",
      "Epoch 16, Step: 467, Loss: 0.21799318492412567, Lr:0.0001\n",
      "Epoch 16, Step: 468, Loss: 0.04709392413496971, Lr:0.0001\n",
      "Epoch 16, Step: 469, Loss: 0.07880034297704697, Lr:0.0001\n",
      "Epoch 16, Step: 470, Loss: 0.031872257590293884, Lr:0.0001\n",
      "Epoch 16, Step: 471, Loss: 0.0017587582115083933, Lr:0.0001\n",
      "Epoch 16, Step: 472, Loss: 0.0982130840420723, Lr:0.0001\n",
      "Epoch 16, Step: 473, Loss: 0.014178525656461716, Lr:0.0001\n",
      "Epoch 16, Step: 474, Loss: 0.05952119454741478, Lr:0.0001\n",
      "Epoch 16, Step: 475, Loss: 0.038015641272068024, Lr:0.0001\n",
      "Epoch 16, Step: 476, Loss: 0.08740068972110748, Lr:0.0001\n",
      "Epoch 16, Step: 477, Loss: 0.013608494773507118, Lr:0.0001\n",
      "Epoch 16, Step: 478, Loss: 0.012884236872196198, Lr:0.0001\n",
      "Epoch 16, Step: 479, Loss: 0.050962671637535095, Lr:0.0001\n",
      "Epoch 16, Step: 480, Loss: 0.22007480263710022, Lr:0.0001\n",
      "Epoch 16, Step: 481, Loss: 0.09230005741119385, Lr:0.0001\n",
      "Epoch 16, Step: 482, Loss: 0.005798256024718285, Lr:0.0001\n",
      "Epoch 16, Step: 483, Loss: 0.04560364782810211, Lr:0.0001\n",
      "Epoch 16, Step: 484, Loss: 0.11174625158309937, Lr:0.0001\n",
      "Epoch 16, Step: 485, Loss: 0.06498738378286362, Lr:0.0001\n",
      "Epoch 16, Step: 486, Loss: 0.04767807573080063, Lr:0.0001\n",
      "Epoch 16, Step: 487, Loss: 0.021733202040195465, Lr:0.0001\n",
      "Epoch 16, Step: 488, Loss: 0.03718559816479683, Lr:0.0001\n",
      "Epoch 16, Step: 489, Loss: 0.04273706674575806, Lr:0.0001\n",
      "Epoch 16, Step: 490, Loss: 0.013512354344129562, Lr:0.0001\n",
      "Epoch 16, Step: 491, Loss: 0.026700256392359734, Lr:0.0001\n",
      "Epoch 16, Step: 492, Loss: 0.005652434658259153, Lr:0.0001\n",
      "Epoch 16, Step: 493, Loss: 0.01509096473455429, Lr:0.0001\n",
      "Epoch 16, Step: 494, Loss: 0.11997728794813156, Lr:0.0001\n",
      "Epoch 16, Step: 495, Loss: 0.378106951713562, Lr:0.0001\n",
      "Epoch 16, Step: 496, Loss: 0.02290915697813034, Lr:0.0001\n",
      "Epoch 16, Step: 497, Loss: 0.2612314224243164, Lr:0.0001\n",
      "Epoch 16, Step: 498, Loss: 0.0778331607580185, Lr:0.0001\n",
      "Epoch 16, Step: 499, Loss: 0.09336823225021362, Lr:0.0001\n",
      "Epoch 16, Step: 500, Loss: 0.019117996096611023, Lr:0.0001\n",
      "Epoch 16, Step: 501, Loss: 0.09158188849687576, Lr:0.0001\n",
      "Epoch 16, Step: 502, Loss: 0.1328040361404419, Lr:0.0001\n",
      "Epoch 16, Step: 503, Loss: 0.048177946358919144, Lr:0.0001\n",
      "Epoch 16, Step: 504, Loss: 0.0061879525892436504, Lr:0.0001\n",
      "Epoch 16, Step: 505, Loss: 0.020966587588191032, Lr:0.0001\n",
      "Epoch 16, Step: 506, Loss: 0.06480076164007187, Lr:0.0001\n",
      "Epoch 16, Step: 507, Loss: 0.09505967795848846, Lr:0.0001\n",
      "Epoch 16, Step: 508, Loss: 0.03497987613081932, Lr:0.0001\n",
      "Epoch 16, Step: 509, Loss: 0.025096314027905464, Lr:0.0001\n",
      "Epoch 16, Step: 510, Loss: 0.01822074130177498, Lr:0.0001\n",
      "Epoch 16, Step: 511, Loss: 0.3327098488807678, Lr:0.0001\n",
      "Epoch 16, Step: 512, Loss: 0.24289214611053467, Lr:0.0001\n",
      "Epoch 16, Step: 513, Loss: 0.1020621582865715, Lr:0.0001\n",
      "Epoch 16, Step: 514, Loss: 0.5131093263626099, Lr:0.0001\n",
      "Epoch 16, Step: 515, Loss: 0.019188309088349342, Lr:0.0001\n",
      "Epoch 16, Step: 516, Loss: 0.008482568897306919, Lr:0.0001\n",
      "Epoch 16, Step: 517, Loss: 0.04862741380929947, Lr:0.0001\n",
      "Epoch 16, Step: 518, Loss: 0.021461844444274902, Lr:0.0001\n",
      "Epoch 16, Step: 519, Loss: 0.009298366494476795, Lr:0.0001\n",
      "Epoch 16, Step: 520, Loss: 0.09947197884321213, Lr:0.0001\n",
      "Epoch 16, Step: 521, Loss: 0.09842344373464584, Lr:0.0001\n",
      "Epoch 16, Step: 522, Loss: 0.2379184514284134, Lr:0.0001\n",
      "Epoch 16, Step: 523, Loss: 0.3216187357902527, Lr:0.0001\n",
      "Epoch 16, Step: 524, Loss: 0.06162469461560249, Lr:0.0001\n",
      "Epoch 16, Step: 525, Loss: 0.09005188941955566, Lr:0.0001\n",
      "Epoch 16, Step: 526, Loss: 0.27403825521469116, Lr:0.0001\n",
      "Epoch 16, Step: 527, Loss: 0.08274177461862564, Lr:0.0001\n",
      "Epoch 16, Step: 528, Loss: 0.12712538242340088, Lr:0.0001\n",
      "Epoch 16, Step: 529, Loss: 0.06371081620454788, Lr:0.0001\n",
      "Epoch 16, Step: 530, Loss: 0.0724736899137497, Lr:0.0001\n",
      "Epoch 16, Step: 531, Loss: 0.022781705483794212, Lr:0.0001\n",
      "Epoch 16, Step: 532, Loss: 0.012052156031131744, Lr:0.0001\n",
      "Epoch 16, Step: 533, Loss: 0.007062362506985664, Lr:0.0001\n",
      "Epoch 16, Step: 534, Loss: 0.1993544101715088, Lr:0.0001\n",
      "Epoch 16, Step: 535, Loss: 0.012145588174462318, Lr:0.0001\n",
      "Epoch 16, Step: 536, Loss: 0.1625116467475891, Lr:0.0001\n",
      "Epoch 16, Step: 537, Loss: 0.07036440819501877, Lr:0.0001\n",
      "Epoch 16, Step: 538, Loss: 0.17972883582115173, Lr:0.0001\n",
      "Epoch 16, Step: 539, Loss: 0.12157624959945679, Lr:0.0001\n",
      "Epoch 16, Step: 540, Loss: 0.04854898899793625, Lr:0.0001\n",
      "Epoch 16, Step: 541, Loss: 0.21538054943084717, Lr:0.0001\n",
      "Epoch 16, Step: 542, Loss: 0.11976979672908783, Lr:0.0001\n",
      "Epoch 16, Step: 543, Loss: 0.043376389890909195, Lr:0.0001\n",
      "Epoch 16, Step: 544, Loss: 0.031061537563800812, Lr:0.0001\n",
      "Epoch 16, Step: 545, Loss: 0.05978507548570633, Lr:0.0001\n",
      "Epoch 16, Step: 546, Loss: 0.02204729989171028, Lr:0.0001\n",
      "Epoch 16, Step: 547, Loss: 0.05318375304341316, Lr:0.0001\n",
      "Epoch 16, Step: 548, Loss: 0.12257474660873413, Lr:0.0001\n",
      "Epoch 16, Step: 549, Loss: 0.2835802733898163, Lr:0.0001\n",
      "Epoch 16, Step: 550, Loss: 0.014366239309310913, Lr:0.0001\n",
      "Epoch 16, Step: 551, Loss: 0.1920875757932663, Lr:0.0001\n",
      "Epoch 16, Step: 552, Loss: 0.26325440406799316, Lr:0.0001\n",
      "Epoch 16, Step: 553, Loss: 0.08996715396642685, Lr:0.0001\n",
      "Epoch 16, Step: 554, Loss: 0.15142300724983215, Lr:0.0001\n",
      "Epoch 16, Step: 555, Loss: 0.18840374052524567, Lr:0.0001\n",
      "Epoch 16, Step: 556, Loss: 0.012781726196408272, Lr:0.0001\n",
      "Epoch 16, Step: 557, Loss: 0.011094193905591965, Lr:0.0001\n",
      "Epoch 16, Step: 558, Loss: 0.05889837443828583, Lr:0.0001\n",
      "Epoch 16, Step: 559, Loss: 0.25039735436439514, Lr:0.0001\n",
      "Epoch 16, Step: 560, Loss: 0.05368492007255554, Lr:0.0001\n",
      "Epoch 16, Step: 561, Loss: 0.09727747738361359, Lr:0.0001\n",
      "Epoch 16, Step: 562, Loss: 0.039783138781785965, Lr:0.0001\n",
      "Epoch 16, Step: 563, Loss: 0.030453942716121674, Lr:0.0001\n",
      "Epoch 16, Step: 564, Loss: 0.27751708030700684, Lr:0.0001\n",
      "Epoch 16, Step: 565, Loss: 0.2539824843406677, Lr:0.0001\n",
      "Epoch 16, Step: 566, Loss: 0.10127352178096771, Lr:0.0001\n",
      "Epoch 16, Step: 567, Loss: 0.07405931502580643, Lr:0.0001\n",
      "Epoch 16, Step: 568, Loss: 0.25818881392478943, Lr:0.0001\n",
      "Epoch 16, Step: 569, Loss: 0.019452784210443497, Lr:0.0001\n",
      "Epoch 16, Step: 570, Loss: 0.039866574108600616, Lr:0.0001\n",
      "Epoch 16, Step: 571, Loss: 0.05835540220141411, Lr:0.0001\n",
      "Epoch 16, Step: 572, Loss: 0.16503342986106873, Lr:0.0001\n",
      "Epoch 16, Step: 573, Loss: 0.05389387160539627, Lr:0.0001\n",
      "Epoch 16, Step: 574, Loss: 0.05480807274580002, Lr:0.0001\n",
      "Epoch 16, Step: 575, Loss: 0.03901094198226929, Lr:0.0001\n",
      "Epoch 16, Step: 576, Loss: 0.10249117016792297, Lr:0.0001\n",
      "Epoch 16, Step: 577, Loss: 0.07004581391811371, Lr:0.0001\n",
      "Epoch 16, Step: 578, Loss: 0.13863298296928406, Lr:0.0001\n",
      "Epoch 16, Step: 579, Loss: 0.14286679029464722, Lr:0.0001\n",
      "Epoch 16, Step: 580, Loss: 0.1020989865064621, Lr:0.0001\n",
      "Epoch 16, Step: 581, Loss: 0.3099537193775177, Lr:0.0001\n",
      "Epoch 16, Step: 582, Loss: 0.3215329647064209, Lr:0.0001\n",
      "Epoch 16, Step: 583, Loss: 0.13746127486228943, Lr:0.0001\n",
      "Epoch 16, Step: 584, Loss: 0.10532983392477036, Lr:0.0001\n",
      "Epoch 16, Step: 585, Loss: 0.09354104846715927, Lr:0.0001\n",
      "Epoch 16, Step: 586, Loss: 0.00778069905936718, Lr:0.0001\n",
      "Epoch 16, Step: 587, Loss: 0.0016298245172947645, Lr:0.0001\n",
      "Epoch 16, Step: 588, Loss: 0.08198461681604385, Lr:0.0001\n",
      "Epoch 16, Step: 589, Loss: 0.18188747763633728, Lr:0.0001\n",
      "Epoch 16, Step: 590, Loss: 0.05863882228732109, Lr:0.0001\n",
      "Epoch 16, Step: 591, Loss: 0.22442969679832458, Lr:0.0001\n",
      "Epoch 16, Step: 592, Loss: 0.025118770077824593, Lr:0.0001\n",
      "Epoch 16, Step: 593, Loss: 0.0412440225481987, Lr:0.0001\n",
      "Epoch 16, Step: 594, Loss: 0.10437650233507156, Lr:0.0001\n",
      "Epoch 16, Step: 595, Loss: 0.2497866451740265, Lr:0.0001\n",
      "Epoch 16, Step: 596, Loss: 0.021498071029782295, Lr:0.0001\n",
      "Epoch 16, Step: 597, Loss: 0.38973772525787354, Lr:0.0001\n",
      "Epoch 16, Step: 598, Loss: 0.07432346791028976, Lr:0.0001\n",
      "Epoch 16, Step: 599, Loss: 0.0704367384314537, Lr:0.0001\n",
      "Epoch 16, Step: 600, Loss: 0.03034026362001896, Lr:0.0001\n",
      "Epoch 16, Step: 601, Loss: 0.044826261699199677, Lr:0.0001\n",
      "Epoch 16, Step: 602, Loss: 0.04124745354056358, Lr:0.0001\n",
      "Epoch 16, Step: 603, Loss: 0.09228259325027466, Lr:0.0001\n",
      "Epoch 16, Step: 604, Loss: 0.09038031101226807, Lr:0.0001\n",
      "Epoch 16, Step: 605, Loss: 0.021170075982809067, Lr:0.0001\n",
      "Epoch 16, Step: 606, Loss: 0.03782343864440918, Lr:0.0001\n",
      "Epoch 16, Step: 607, Loss: 0.03304946422576904, Lr:0.0001\n",
      "Epoch 16, Step: 608, Loss: 0.31641560792922974, Lr:0.0001\n",
      "Epoch 16, Step: 609, Loss: 0.08789871633052826, Lr:0.0001\n",
      "Epoch 16, Step: 610, Loss: 0.07561594247817993, Lr:0.0001\n",
      "Epoch 16, Step: 611, Loss: 0.053034208714962006, Lr:0.0001\n",
      "Epoch 16, Step: 612, Loss: 0.04343268275260925, Lr:0.0001\n",
      "Epoch 16, Step: 613, Loss: 0.028163855895400047, Lr:0.0001\n",
      "Epoch 16, Step: 614, Loss: 0.12063929438591003, Lr:0.0001\n",
      "Epoch 16, Step: 615, Loss: 0.04152560234069824, Lr:0.0001\n",
      "Epoch 16, Step: 616, Loss: 0.03417714685201645, Lr:0.0001\n",
      "Epoch 16, Step: 617, Loss: 0.18532423675060272, Lr:0.0001\n",
      "Epoch 16, Step: 618, Loss: 0.05330047383904457, Lr:0.0001\n",
      "Epoch 16, Step: 619, Loss: 0.1439978927373886, Lr:0.0001\n",
      "Epoch 16, Step: 620, Loss: 0.09113416820764542, Lr:0.0001\n",
      "Epoch 16, Step: 621, Loss: 0.08720394968986511, Lr:0.0001\n",
      "Epoch 16, Step: 622, Loss: 0.04537509009242058, Lr:0.0001\n",
      "Epoch 16, Step: 623, Loss: 0.13606642186641693, Lr:0.0001\n",
      "Epoch 16, Step: 624, Loss: 0.20599579811096191, Lr:0.0001\n",
      "Epoch 16, Step: 625, Loss: 0.09189080446958542, Lr:0.0001\n",
      "Epoch 16, Step: 626, Loss: 0.30559176206588745, Lr:0.0001\n",
      "Epoch 16, Step: 627, Loss: 0.042504291981458664, Lr:0.0001\n",
      "Epoch 16, Step: 628, Loss: 0.1606995016336441, Lr:0.0001\n",
      "Epoch 16, Step: 629, Loss: 0.09044907987117767, Lr:0.0001\n",
      "Epoch 16, Step: 630, Loss: 0.18667283654212952, Lr:0.0001\n",
      "Epoch 16, Step: 631, Loss: 0.09236563742160797, Lr:0.0001\n",
      "Epoch 16, Step: 632, Loss: 0.19971612095832825, Lr:0.0001\n",
      "Epoch 16, Step: 633, Loss: 0.055867601186037064, Lr:0.0001\n",
      "Epoch 16, Step: 634, Loss: 0.02658216282725334, Lr:0.0001\n",
      "Epoch 16, Step: 635, Loss: 0.23396140336990356, Lr:0.0001\n",
      "Epoch 16, Step: 636, Loss: 0.058895740658044815, Lr:0.0001\n",
      "Epoch 16, Step: 637, Loss: 0.11760102212429047, Lr:0.0001\n",
      "Epoch 16, Step: 638, Loss: 0.05607055127620697, Lr:0.0001\n",
      "Epoch 16, Step: 639, Loss: 0.05899433046579361, Lr:0.0001\n",
      "Epoch 16, Step: 640, Loss: 0.19469018280506134, Lr:0.0001\n",
      "Epoch 16, Step: 641, Loss: 0.07277240604162216, Lr:0.0001\n",
      "Epoch 16, Step: 642, Loss: 0.04642369970679283, Lr:0.0001\n",
      "Epoch 16, Step: 643, Loss: 0.00878655631095171, Lr:0.0001\n",
      "Epoch 16, Step: 644, Loss: 0.27548038959503174, Lr:0.0001\n",
      "Epoch 16, Step: 645, Loss: 0.1582721620798111, Lr:0.0001\n",
      "Epoch 16, Step: 646, Loss: 0.017990699037909508, Lr:0.0001\n",
      "Epoch 16, Step: 647, Loss: 0.1730595827102661, Lr:0.0001\n",
      "Epoch 16, Step: 648, Loss: 0.04278435558080673, Lr:0.0001\n",
      "Epoch 16, Step: 649, Loss: 0.2592782974243164, Lr:0.0001\n",
      "Epoch 16, Step: 650, Loss: 0.11013956367969513, Lr:0.0001\n",
      "Epoch 16, Step: 651, Loss: 0.13153082132339478, Lr:0.0001\n",
      "Epoch 16, Step: 652, Loss: 0.038250457495450974, Lr:0.0001\n",
      "Epoch 16, Step: 653, Loss: 0.21603648364543915, Lr:0.0001\n",
      "Epoch 16, Step: 654, Loss: 0.2214231640100479, Lr:0.0001\n",
      "Epoch 16, Step: 655, Loss: 0.15989159047603607, Lr:0.0001\n",
      "Epoch 16, Step: 656, Loss: 0.11350805312395096, Lr:0.0001\n",
      "Epoch 16, Step: 657, Loss: 0.05070609226822853, Lr:0.0001\n",
      "Epoch 16, Step: 658, Loss: 0.032918643206357956, Lr:0.0001\n",
      "Epoch 16, Step: 659, Loss: 0.027383718639612198, Lr:0.0001\n",
      "Epoch 16, Step: 660, Loss: 0.06023680046200752, Lr:0.0001\n",
      "Epoch 16, Step: 661, Loss: 0.07870865613222122, Lr:0.0001\n",
      "Epoch 16, Step: 662, Loss: 0.08289746940135956, Lr:0.0001\n",
      "Epoch 16, Step: 663, Loss: 0.042315490543842316, Lr:0.0001\n",
      "Epoch 16, Step: 664, Loss: 0.1489836573600769, Lr:0.0001\n",
      "Epoch 16, Step: 665, Loss: 0.33406805992126465, Lr:0.0001\n",
      "Epoch 16, Step: 666, Loss: 0.014058126136660576, Lr:0.0001\n",
      "Epoch 16, Step: 667, Loss: 0.004635225981473923, Lr:0.0001\n",
      "Epoch 16, Step: 668, Loss: 0.1449548602104187, Lr:0.0001\n",
      "Epoch 16, Step: 669, Loss: 0.08425569534301758, Lr:0.0001\n",
      "Epoch 16, Step: 670, Loss: 0.13146215677261353, Lr:0.0001\n",
      "Epoch 16, Step: 671, Loss: 0.03800491243600845, Lr:0.0001\n",
      "Epoch 16, Step: 672, Loss: 0.33972540497779846, Lr:0.0001\n",
      "Epoch 16, Step: 673, Loss: 0.2043432593345642, Lr:0.0001\n",
      "Epoch 16, Step: 674, Loss: 0.2899855673313141, Lr:0.0001\n",
      "Epoch 16, Step: 675, Loss: 0.6757503747940063, Lr:0.0001\n",
      "Epoch 16, Step: 676, Loss: 0.09850513935089111, Lr:0.0001\n",
      "Epoch 16, Step: 677, Loss: 0.1686781495809555, Lr:0.0001\n",
      "Epoch 16, Step: 678, Loss: 0.058078717440366745, Lr:0.0001\n",
      "Epoch 16, Step: 679, Loss: 0.004813685081899166, Lr:0.0001\n",
      "Epoch 16, Step: 680, Loss: 0.11870604008436203, Lr:0.0001\n",
      "Epoch 16, Step: 681, Loss: 0.10670656710863113, Lr:0.0001\n",
      "Epoch 16, Step: 682, Loss: 0.30088555812835693, Lr:0.0001\n",
      "Epoch 16, Step: 683, Loss: 0.07206298410892487, Lr:0.0001\n",
      "Epoch 16, Step: 684, Loss: 0.18374791741371155, Lr:0.0001\n",
      "Epoch 16, Step: 685, Loss: 0.06162966042757034, Lr:0.0001\n",
      "Epoch 16, Step: 686, Loss: 0.10509345680475235, Lr:0.0001\n",
      "Epoch 16, Step: 687, Loss: 0.026289381086826324, Lr:0.0001\n",
      "Epoch 16, Step: 688, Loss: 0.2505975663661957, Lr:0.0001\n",
      "Epoch 16, Step: 689, Loss: 0.055234815925359726, Lr:0.0001\n",
      "Epoch 16, Step: 690, Loss: 0.11078286916017532, Lr:0.0001\n",
      "Epoch 16, Step: 691, Loss: 0.15207938849925995, Lr:0.0001\n",
      "Epoch 16, Step: 692, Loss: 0.009763287380337715, Lr:0.0001\n",
      "Epoch 16, Step: 693, Loss: 0.16995878517627716, Lr:0.0001\n",
      "Epoch 16, Step: 694, Loss: 0.3369281589984894, Lr:0.0001\n",
      "Epoch 16, Step: 695, Loss: 0.11993402242660522, Lr:0.0001\n",
      "Epoch 16, Step: 696, Loss: 0.1222723200917244, Lr:0.0001\n",
      "Epoch 16, Step: 697, Loss: 0.0851682722568512, Lr:0.0001\n",
      "Epoch 16, Step: 698, Loss: 0.1526741087436676, Lr:0.0001\n",
      "Epoch 16, Step: 699, Loss: 0.058761902153491974, Lr:0.0001\n",
      "Epoch 16, Step: 700, Loss: 0.20304681360721588, Lr:0.0001\n",
      "Epoch 16, Step: 701, Loss: 0.2044450342655182, Lr:0.0001\n",
      "Epoch 16, Step: 702, Loss: 0.3852466940879822, Lr:0.0001\n",
      "Epoch 16, Step: 703, Loss: 0.09973253309726715, Lr:0.0001\n",
      "Epoch 16, Step: 704, Loss: 0.5106731653213501, Lr:0.0001\n",
      "Epoch 16, Step: 705, Loss: 0.053209125995635986, Lr:0.0001\n",
      "Epoch 16, Step: 706, Loss: 0.691718578338623, Lr:0.0001\n",
      "Epoch 16, Step: 707, Loss: 0.19750776886940002, Lr:0.0001\n",
      "Epoch 16, Step: 708, Loss: 0.007434395141899586, Lr:0.0001\n",
      "Epoch 16, Step: 709, Loss: 0.3576834201812744, Lr:0.0001\n",
      "Epoch 16, Step: 710, Loss: 0.24192498624324799, Lr:0.0001\n",
      "Epoch 16, Step: 711, Loss: 0.03707059472799301, Lr:0.0001\n",
      "Epoch 16, Step: 712, Loss: 0.18513670563697815, Lr:0.0001\n",
      "Epoch 16, Step: 713, Loss: 0.1639563888311386, Lr:0.0001\n",
      "Epoch 16, Step: 714, Loss: 0.021234411746263504, Lr:0.0001\n",
      "Epoch 16, Step: 715, Loss: 0.036480292677879333, Lr:0.0001\n",
      "Epoch 16, Step: 716, Loss: 0.03408188000321388, Lr:0.0001\n",
      "Epoch 16, Step: 717, Loss: 0.031595803797245026, Lr:0.0001\n",
      "Epoch 16, Step: 718, Loss: 0.05558019131422043, Lr:0.0001\n",
      "Epoch 16, Step: 719, Loss: 0.025762395933270454, Lr:0.0001\n",
      "Epoch 16, Step: 720, Loss: 0.04683278128504753, Lr:0.0001\n",
      "Epoch 16, Step: 721, Loss: 0.1979958564043045, Lr:0.0001\n",
      "Epoch 16, Step: 722, Loss: 0.20259882509708405, Lr:0.0001\n",
      "Epoch 16, Step: 723, Loss: 0.04719148203730583, Lr:0.0001\n",
      "Epoch 16, Step: 724, Loss: 0.01101214624941349, Lr:0.0001\n",
      "Epoch 16, Step: 725, Loss: 0.1628127098083496, Lr:0.0001\n",
      "Epoch 16, Step: 726, Loss: 0.048304468393325806, Lr:0.0001\n",
      "Epoch 16, Step: 727, Loss: 0.027862241491675377, Lr:0.0001\n",
      "Epoch 16, Step: 728, Loss: 0.09934742003679276, Lr:0.0001\n",
      "Epoch 16, Step: 729, Loss: 0.051983851939439774, Lr:0.0001\n",
      "Epoch 16, Step: 730, Loss: 0.13420361280441284, Lr:0.0001\n",
      "Epoch 16, Step: 731, Loss: 0.03979254513978958, Lr:0.0001\n",
      "Epoch 16, Step: 732, Loss: 0.07431647926568985, Lr:0.0001\n",
      "Epoch 16, Step: 733, Loss: 0.062047846615314484, Lr:0.0001\n",
      "Epoch 16, Step: 734, Loss: 0.10467236489057541, Lr:0.0001\n",
      "Epoch 16, Step: 735, Loss: 0.7288165092468262, Lr:0.0001\n",
      "Epoch 16, Step: 736, Loss: 0.04472384601831436, Lr:0.0001\n",
      "Epoch 16, Step: 737, Loss: 0.09985071420669556, Lr:0.0001\n",
      "Epoch 16, Step: 738, Loss: 0.1939888745546341, Lr:0.0001\n",
      "Epoch 16, Step: 739, Loss: 0.3313879370689392, Lr:0.0001\n",
      "Epoch 16, Step: 740, Loss: 0.1895507127046585, Lr:0.0001\n",
      "Epoch 16, Step: 741, Loss: 0.09277822077274323, Lr:0.0001\n",
      "Epoch 16, Step: 742, Loss: 0.20091937482357025, Lr:0.0001\n",
      "Epoch 16, Step: 743, Loss: 0.05762450769543648, Lr:0.0001\n",
      "Epoch 16, Step: 744, Loss: 0.034200675785541534, Lr:0.0001\n",
      "Epoch 16, Step: 745, Loss: 0.08384497463703156, Lr:0.0001\n",
      "Epoch 16, Step: 746, Loss: 0.25178632140159607, Lr:0.0001\n",
      "Epoch 16, Step: 747, Loss: 0.11049152910709381, Lr:0.0001\n",
      "Epoch 16, Step: 748, Loss: 0.009586475789546967, Lr:0.0001\n",
      "Epoch 16, Step: 749, Loss: 0.11300662904977798, Lr:0.0001\n",
      "Epoch 16, Step: 750, Loss: 0.10013687610626221, Lr:0.0001\n",
      "Epoch 16, Step: 751, Loss: 0.15188181400299072, Lr:0.0001\n",
      "Epoch 16, Step: 752, Loss: 0.06934460252523422, Lr:0.0001\n",
      "Epoch 16, Step: 753, Loss: 0.02133823372423649, Lr:0.0001\n",
      "Epoch 16, Step: 754, Loss: 0.04561946168541908, Lr:0.0001\n",
      "Epoch 16, Step: 755, Loss: 0.048836205154657364, Lr:0.0001\n",
      "Epoch 16, Step: 756, Loss: 0.027128031477332115, Lr:0.0001\n",
      "Epoch 16, Step: 757, Loss: 0.05748871713876724, Lr:0.0001\n",
      "Epoch 16, Step: 758, Loss: 0.02443738467991352, Lr:0.0001\n",
      "Epoch 16, Step: 759, Loss: 0.15821552276611328, Lr:0.0001\n",
      "Epoch 16, Step: 760, Loss: 0.11538101732730865, Lr:0.0001\n",
      "Epoch 16, Step: 761, Loss: 0.033573366701602936, Lr:0.0001\n",
      "Epoch 16, Step: 762, Loss: 0.023872075602412224, Lr:0.0001\n",
      "Epoch 16, Step: 763, Loss: 0.03977411240339279, Lr:0.0001\n",
      "Epoch 16, Step: 764, Loss: 0.10959948599338531, Lr:0.0001\n",
      "Epoch 16, Step: 765, Loss: 0.2859498858451843, Lr:0.0001\n",
      "Epoch 16, Step: 766, Loss: 0.0310934167355299, Lr:0.0001\n",
      "Epoch 16, Step: 767, Loss: 0.049251582473516464, Lr:0.0001\n",
      "Epoch 16, Step: 768, Loss: 0.21471038460731506, Lr:0.0001\n",
      "Epoch 16, Step: 769, Loss: 0.28302067518234253, Lr:0.0001\n",
      "Epoch 16, Step: 770, Loss: 0.06381843239068985, Lr:0.0001\n",
      "Epoch 16, Step: 771, Loss: 0.04497415944933891, Lr:0.0001\n",
      "Epoch 16, Step: 772, Loss: 0.041339483112096786, Lr:0.0001\n",
      "Epoch 16, Step: 773, Loss: 0.018741898238658905, Lr:0.0001\n",
      "Epoch 16, Step: 774, Loss: 0.043428320437669754, Lr:0.0001\n",
      "Epoch 16, Step: 775, Loss: 0.05886625871062279, Lr:0.0001\n",
      "Epoch 16, Step: 776, Loss: 0.012722757644951344, Lr:0.0001\n",
      "Epoch 16, Step: 777, Loss: 0.08386481553316116, Lr:0.0001\n",
      "Epoch 16, Step: 778, Loss: 0.16261297464370728, Lr:0.0001\n",
      "Epoch 16, Step: 779, Loss: 0.10637945681810379, Lr:0.0001\n",
      "Epoch 16, Step: 780, Loss: 0.22895707190036774, Lr:0.0001\n",
      "Epoch 16, Step: 781, Loss: 0.08391281962394714, Lr:0.0001\n",
      "Epoch 16, Step: 782, Loss: 0.09969546645879745, Lr:0.0001\n",
      "Epoch 16, Step: 783, Loss: 0.03880413994193077, Lr:0.0001\n",
      "Epoch 16, Step: 784, Loss: 0.02247423678636551, Lr:0.0001\n",
      "Epoch 16, Step: 785, Loss: 0.09753384441137314, Lr:0.0001\n",
      "Epoch 16, Step: 786, Loss: 0.03448233753442764, Lr:0.0001\n",
      "Epoch 16, Step: 787, Loss: 0.041640035808086395, Lr:0.0001\n",
      "Epoch 16, Step: 788, Loss: 0.020556984469294548, Lr:0.0001\n",
      "Epoch 16, Step: 789, Loss: 0.008260741829872131, Lr:0.0001\n",
      "Epoch 16, Step: 790, Loss: 0.032963816076517105, Lr:0.0001\n",
      "Epoch 16, Step: 791, Loss: 0.04433923587203026, Lr:0.0001\n",
      "Epoch 16, Step: 792, Loss: 0.1850784569978714, Lr:0.0001\n",
      "Epoch 16, Step: 793, Loss: 0.14076413214206696, Lr:0.0001\n",
      "Epoch 16, Step: 794, Loss: 0.24559201300144196, Lr:0.0001\n",
      "Epoch 16, Step: 795, Loss: 0.03339933604001999, Lr:0.0001\n",
      "Epoch 16, Step: 796, Loss: 0.005540680605918169, Lr:0.0001\n",
      "Epoch 16, Step: 797, Loss: 0.019799867644906044, Lr:0.0001\n",
      "Epoch 16, Step: 798, Loss: 0.018375471234321594, Lr:0.0001\n",
      "Epoch 16, Step: 799, Loss: 0.05783466622233391, Lr:0.0001\n",
      "Epoch 16, Step: 800, Loss: 0.007148544304072857, Lr:0.0001\n",
      "Epoch 16, Step: 801, Loss: 0.0022758012637495995, Lr:0.0001\n",
      "Epoch 16, Step: 802, Loss: 0.008168120868504047, Lr:0.0001\n",
      "Epoch 16, Step: 803, Loss: 0.04792563617229462, Lr:0.0001\n",
      "Epoch 16, Step: 804, Loss: 0.10574024170637131, Lr:0.0001\n",
      "Epoch 16, Step: 805, Loss: 0.47814634442329407, Lr:0.0001\n",
      "Epoch 16, Step: 806, Loss: 0.12690319120883942, Lr:0.0001\n",
      "Epoch 16, Step: 807, Loss: 0.08794043958187103, Lr:0.0001\n",
      "Epoch 16, Step: 808, Loss: 0.11437078565359116, Lr:0.0001\n",
      "Epoch 16, Step: 809, Loss: 0.14758481085300446, Lr:0.0001\n",
      "Epoch 16, Step: 810, Loss: 0.020955048501491547, Lr:0.0001\n",
      "Epoch 16, Step: 811, Loss: 0.006601207423955202, Lr:0.0001\n",
      "Epoch 16, Step: 812, Loss: 0.24575494229793549, Lr:0.0001\n",
      "Epoch 16, Step: 813, Loss: 0.15741807222366333, Lr:0.0001\n",
      "Epoch 16, Step: 814, Loss: 0.11906575411558151, Lr:0.0001\n",
      "Epoch 16, Step: 815, Loss: 0.07091327756643295, Lr:0.0001\n",
      "Epoch 16, Step: 816, Loss: 0.06745006889104843, Lr:0.0001\n",
      "Epoch 16, Step: 817, Loss: 0.06820963323116302, Lr:0.0001\n",
      "Epoch 16, Step: 818, Loss: 0.04713437333703041, Lr:0.0001\n",
      "Epoch 16, Step: 819, Loss: 0.026999177411198616, Lr:0.0001\n",
      "Epoch 16, Step: 820, Loss: 0.05205428600311279, Lr:0.0001\n",
      "Epoch 16, Step: 821, Loss: 0.01998014934360981, Lr:0.0001\n",
      "Epoch 16, Step: 822, Loss: 0.013009326532483101, Lr:0.0001\n",
      "Epoch 16, Step: 823, Loss: 0.13411976397037506, Lr:0.0001\n",
      "Epoch 16, Step: 824, Loss: 0.039478104561567307, Lr:0.0001\n",
      "Epoch 16, Step: 825, Loss: 0.053876638412475586, Lr:0.0001\n",
      "Epoch 16, Step: 826, Loss: 0.08956309407949448, Lr:0.0001\n",
      "Epoch 16, Step: 827, Loss: 0.08506649732589722, Lr:0.0001\n",
      "Epoch 16, Step: 828, Loss: 0.11696720868349075, Lr:0.0001\n",
      "Epoch 16, Step: 829, Loss: 0.023299524560570717, Lr:0.0001\n",
      "Epoch 16, Step: 830, Loss: 0.031318604946136475, Lr:0.0001\n",
      "Epoch 16, Step: 831, Loss: 0.033987052738666534, Lr:0.0001\n",
      "Epoch 16, Step: 832, Loss: 0.0017103553982451558, Lr:0.0001\n",
      "Epoch 16, Step: 833, Loss: 0.436806857585907, Lr:0.0001\n",
      "Epoch 16, Step: 834, Loss: 0.02458268776535988, Lr:0.0001\n",
      "Epoch 16, Step: 835, Loss: 0.29710158705711365, Lr:0.0001\n",
      "Epoch 16, Step: 836, Loss: 0.37186378240585327, Lr:0.0001\n",
      "Epoch 16, Step: 837, Loss: 0.05061519145965576, Lr:0.0001\n",
      "Epoch 16, Step: 838, Loss: 0.1715826541185379, Lr:0.0001\n",
      "Epoch 16, Step: 839, Loss: 0.02392904832959175, Lr:0.0001\n",
      "Epoch 16, Step: 840, Loss: 0.3537246286869049, Lr:0.0001\n",
      "Epoch 16, Step: 841, Loss: 0.1583566963672638, Lr:0.0001\n",
      "Epoch 16, Step: 842, Loss: 0.045781102031469345, Lr:0.0001\n",
      "Epoch 16, Step: 843, Loss: 0.03047182597219944, Lr:0.0001\n",
      "Epoch 16, Step: 844, Loss: 0.10887692123651505, Lr:0.0001\n",
      "Epoch 16, Step: 845, Loss: 0.06058983504772186, Lr:0.0001\n",
      "Epoch 16, Step: 846, Loss: 0.17254605889320374, Lr:0.0001\n",
      "Epoch 16, Step: 847, Loss: 0.0029301100876182318, Lr:0.0001\n",
      "Epoch 16, Step: 848, Loss: 0.008543476462364197, Lr:0.0001\n",
      "Epoch 16, Step: 849, Loss: 0.04419337958097458, Lr:0.0001\n",
      "Epoch 16, Step: 850, Loss: 0.05719996616244316, Lr:0.0001\n",
      "Epoch 16, Step: 851, Loss: 0.017289111390709877, Lr:0.0001\n",
      "Epoch 16, Step: 852, Loss: 0.018122320994734764, Lr:0.0001\n",
      "Epoch 16, Step: 853, Loss: 0.18424426019191742, Lr:0.0001\n",
      "Epoch 16, Step: 854, Loss: 0.2997157573699951, Lr:0.0001\n",
      "Epoch 16, Step: 855, Loss: 0.03994027152657509, Lr:0.0001\n",
      "Epoch 16, Step: 856, Loss: 0.2921643853187561, Lr:0.0001\n",
      "Epoch 16, Step: 857, Loss: 0.1623447835445404, Lr:0.0001\n",
      "Epoch 16, Step: 858, Loss: 0.009713465347886086, Lr:0.0001\n",
      "Epoch 16, Step: 859, Loss: 0.038791876286268234, Lr:0.0001\n",
      "Epoch 16, Step: 860, Loss: 0.0451330840587616, Lr:0.0001\n",
      "Epoch 16, Step: 861, Loss: 0.10307861864566803, Lr:0.0001\n",
      "Epoch 16, Step: 862, Loss: 0.06767058372497559, Lr:0.0001\n",
      "Epoch 16, Step: 863, Loss: 0.3796682357788086, Lr:0.0001\n",
      "Epoch 16, Step: 864, Loss: 0.04426879063248634, Lr:0.0001\n",
      "Epoch 16, Step: 865, Loss: 0.12075038254261017, Lr:0.0001\n",
      "Epoch 16, Step: 866, Loss: 0.15882858633995056, Lr:0.0001\n",
      "Epoch 16, Step: 867, Loss: 0.16181455552577972, Lr:0.0001\n",
      "Epoch 16, Step: 868, Loss: 0.36176928877830505, Lr:0.0001\n",
      "Epoch 16, Step: 869, Loss: 0.05245959758758545, Lr:0.0001\n",
      "Epoch 16, Step: 870, Loss: 0.08123825490474701, Lr:0.0001\n",
      "Epoch 16, Step: 871, Loss: 0.10864067077636719, Lr:0.0001\n",
      "Epoch 16, Step: 872, Loss: 0.07396994531154633, Lr:0.0001\n",
      "Epoch 16, Step: 873, Loss: 0.08193787932395935, Lr:0.0001\n",
      "Epoch 16, Step: 874, Loss: 0.019138941541314125, Lr:0.0001\n",
      "Epoch 16, Step: 875, Loss: 0.16490565240383148, Lr:0.0001\n",
      "Epoch 16, Step: 876, Loss: 0.24717624485492706, Lr:0.0001\n",
      "Epoch 16, Step: 877, Loss: 0.02590041793882847, Lr:0.0001\n",
      "Epoch 16, Step: 878, Loss: 0.08522243797779083, Lr:0.0001\n",
      "Epoch 16, Step: 879, Loss: 0.04219271242618561, Lr:0.0001\n",
      "Epoch 16, Step: 880, Loss: 0.16035255789756775, Lr:0.0001\n",
      "Epoch 16, Step: 881, Loss: 0.07107959687709808, Lr:0.0001\n",
      "Epoch 16, Step: 882, Loss: 0.13803532719612122, Lr:0.0001\n",
      "Epoch 16, Step: 883, Loss: 0.019635707139968872, Lr:0.0001\n",
      "Epoch 16, Step: 884, Loss: 0.2643427550792694, Lr:0.0001\n",
      "Epoch 16, Step: 885, Loss: 0.0864412859082222, Lr:0.0001\n",
      "Epoch 16, Step: 886, Loss: 0.05646668002009392, Lr:0.0001\n",
      "Epoch 16, Step: 887, Loss: 0.02093014307320118, Lr:0.0001\n",
      "Epoch 16, Step: 888, Loss: 0.2552303969860077, Lr:0.0001\n",
      "Epoch 16, Step: 889, Loss: 0.044840577989816666, Lr:0.0001\n",
      "Epoch 16, Step: 890, Loss: 0.012724820524454117, Lr:0.0001\n",
      "Epoch 16, Step: 891, Loss: 0.020123815163969994, Lr:0.0001\n",
      "Epoch 16, Step: 892, Loss: 0.06711460649967194, Lr:0.0001\n",
      "Epoch 16, Step: 893, Loss: 0.15049423277378082, Lr:0.0001\n",
      "Epoch 16, Step: 894, Loss: 0.0785961002111435, Lr:0.0001\n",
      "Epoch 16, Step: 895, Loss: 0.03577129542827606, Lr:0.0001\n",
      "Epoch 16, Step: 896, Loss: 0.07964932173490524, Lr:0.0001\n",
      "Epoch 16, Step: 897, Loss: 0.10099101066589355, Lr:0.0001\n",
      "Epoch 16, Step: 898, Loss: 0.05809086188673973, Lr:0.0001\n",
      "Epoch 16, Step: 899, Loss: 0.45416057109832764, Lr:0.0001\n",
      "Epoch 16, Step: 900, Loss: 0.16078826785087585, Lr:0.0001\n",
      "Epoch 16, Step: 901, Loss: 0.017466118559241295, Lr:0.0001\n",
      "Epoch 16, Step: 902, Loss: 0.39376100897789, Lr:0.0001\n",
      "Epoch 16, Step: 903, Loss: 0.1444668471813202, Lr:0.0001\n",
      "Epoch 16, Step: 904, Loss: 0.1405036300420761, Lr:0.0001\n",
      "Epoch 16, Step: 905, Loss: 0.08351508527994156, Lr:0.0001\n",
      "Epoch 16, Step: 906, Loss: 0.05212476849555969, Lr:0.0001\n",
      "Epoch 16, Step: 907, Loss: 0.025414835661649704, Lr:0.0001\n",
      "Epoch 16, Step: 908, Loss: 0.028769364580512047, Lr:0.0001\n",
      "Epoch 16, Step: 909, Loss: 0.010086779482662678, Lr:0.0001\n",
      "Epoch 16, Step: 910, Loss: 0.011837812140583992, Lr:0.0001\n",
      "Epoch 16, Step: 911, Loss: 0.004648811649531126, Lr:0.0001\n",
      "Epoch 16, Step: 912, Loss: 0.1872822791337967, Lr:0.0001\n",
      "Epoch 16, Step: 913, Loss: 0.06579643487930298, Lr:0.0001\n",
      "Epoch 16, Step: 914, Loss: 0.00893467478454113, Lr:0.0001\n",
      "Epoch 16, Step: 915, Loss: 0.20610424876213074, Lr:0.0001\n",
      "Epoch 16, Step: 916, Loss: 0.17276744544506073, Lr:0.0001\n",
      "Epoch 16, Step: 917, Loss: 0.2085229456424713, Lr:0.0001\n",
      "Epoch 16, Step: 918, Loss: 0.43883413076400757, Lr:0.0001\n",
      "Epoch 16, Step: 919, Loss: 0.01113143004477024, Lr:0.0001\n",
      "Epoch 16, Step: 920, Loss: 0.002747886348515749, Lr:0.0001\n",
      "Epoch 16, Step: 921, Loss: 0.2990366220474243, Lr:0.0001\n",
      "Epoch 16, Step: 922, Loss: 0.019866671413183212, Lr:0.0001\n",
      "Epoch 16, Step: 923, Loss: 0.090513676404953, Lr:0.0001\n",
      "Epoch 16, Step: 924, Loss: 0.3202962577342987, Lr:0.0001\n",
      "Epoch 16, Step: 925, Loss: 0.0741075873374939, Lr:0.0001\n",
      "Epoch 16, Step: 926, Loss: 0.03661494702100754, Lr:0.0001\n",
      "Epoch 16, Step: 927, Loss: 0.11973463743925095, Lr:0.0001\n",
      "Epoch 16, Step: 928, Loss: 0.06841002404689789, Lr:0.0001\n",
      "Epoch 16, Step: 929, Loss: 0.33042919635772705, Lr:0.0001\n",
      "Epoch 16, Step: 930, Loss: 0.047538671642541885, Lr:0.0001\n",
      "Epoch 16, Step: 931, Loss: 0.017525218427181244, Lr:0.0001\n",
      "Epoch 16, Step: 932, Loss: 0.052496105432510376, Lr:0.0001\n",
      "Epoch 16, Step: 933, Loss: 0.022396622225642204, Lr:0.0001\n",
      "Epoch 16, Step: 934, Loss: 0.11743380129337311, Lr:0.0001\n",
      "Epoch 16, Step: 935, Loss: 0.06185980141162872, Lr:0.0001\n",
      "Epoch 16, Step: 936, Loss: 0.5194303393363953, Lr:0.0001\n",
      "Epoch 16, Step: 937, Loss: 0.005466601811349392, Lr:0.0001\n",
      "Epoch 16, Step: 938, Loss: 0.17947085201740265, Lr:0.0001\n",
      "Epoch 16, Step: 939, Loss: 0.12466713041067123, Lr:0.0001\n",
      "Epoch 16, Step: 940, Loss: 0.0176919624209404, Lr:0.0001\n",
      "Epoch 16, Step: 941, Loss: 0.018123425543308258, Lr:0.0001\n",
      "Epoch 16, Step: 942, Loss: 0.18949364125728607, Lr:0.0001\n",
      "Epoch 16, Step: 943, Loss: 0.2850179076194763, Lr:0.0001\n",
      "Epoch 16, Step: 944, Loss: 0.13993503153324127, Lr:0.0001\n",
      "Epoch 16, Step: 945, Loss: 0.07804489135742188, Lr:0.0001\n",
      "Epoch 16, Step: 946, Loss: 0.008696604520082474, Lr:0.0001\n",
      "Epoch 16, Step: 947, Loss: 0.16876165568828583, Lr:0.0001\n",
      "Epoch 16, Step: 948, Loss: 0.23442333936691284, Lr:0.0001\n",
      "Epoch 16, Step: 949, Loss: 0.05080762505531311, Lr:0.0001\n",
      "Epoch 16, Step: 950, Loss: 0.20604991912841797, Lr:0.0001\n",
      "Epoch 16, Step: 951, Loss: 0.08119352161884308, Lr:0.0001\n",
      "Epoch 16, Step: 952, Loss: 0.006454816088080406, Lr:0.0001\n",
      "Epoch 16, Step: 953, Loss: 0.07918090373277664, Lr:0.0001\n",
      "Epoch 16, Step: 954, Loss: 0.03244028612971306, Lr:0.0001\n",
      "Epoch 16, Step: 955, Loss: 0.06844731420278549, Lr:0.0001\n",
      "Epoch 16, Step: 956, Loss: 0.04458768293261528, Lr:0.0001\n",
      "Epoch 16, Step: 957, Loss: 0.13032148778438568, Lr:0.0001\n",
      "Epoch 16, Step: 958, Loss: 0.005913185887038708, Lr:0.0001\n",
      "Epoch 16, Step: 959, Loss: 0.06493517011404037, Lr:0.0001\n",
      "Epoch 16, Step: 960, Loss: 0.06665266305208206, Lr:0.0001\n",
      "Epoch 16, Step: 961, Loss: 0.04512332007288933, Lr:0.0001\n",
      "Epoch 16, Step: 962, Loss: 0.22627004981040955, Lr:0.0001\n",
      "Epoch 16, Step: 963, Loss: 0.07107555121183395, Lr:0.0001\n",
      "Epoch 16, Step: 964, Loss: 0.04404529929161072, Lr:0.0001\n",
      "Epoch 16, Step: 965, Loss: 0.036054760217666626, Lr:0.0001\n",
      "Epoch 16, Step: 966, Loss: 0.015812775120139122, Lr:0.0001\n",
      "Epoch 16, Step: 967, Loss: 0.09423492848873138, Lr:0.0001\n",
      "Epoch 16, Step: 968, Loss: 0.029356203973293304, Lr:0.0001\n",
      "Epoch 16, Step: 969, Loss: 0.004939859267324209, Lr:0.0001\n",
      "Epoch 16, Step: 970, Loss: 0.008155841380357742, Lr:0.0001\n",
      "Epoch 16, Step: 971, Loss: 0.093979112803936, Lr:0.0001\n",
      "Epoch 16, Step: 972, Loss: 0.08477728068828583, Lr:0.0001\n",
      "Epoch 16, Step: 973, Loss: 0.13262039422988892, Lr:0.0001\n",
      "Epoch 16, Step: 974, Loss: 0.06549850106239319, Lr:0.0001\n",
      "Epoch 16, Step: 975, Loss: 0.007029812783002853, Lr:0.0001\n",
      "Epoch 16, Step: 976, Loss: 0.16749723255634308, Lr:0.0001\n",
      "Epoch 16, Step: 977, Loss: 0.028514044359326363, Lr:0.0001\n",
      "Epoch 16, Step: 978, Loss: 0.025655701756477356, Lr:0.0001\n",
      "Epoch 16, Step: 979, Loss: 0.02121296338737011, Lr:0.0001\n",
      "Epoch 16, Step: 980, Loss: 0.3064078390598297, Lr:0.0001\n",
      "Epoch 16, Step: 981, Loss: 0.10796751081943512, Lr:0.0001\n",
      "Epoch 16, Step: 982, Loss: 0.03836015984416008, Lr:0.0001\n",
      "Epoch 16, Step: 983, Loss: 0.0234063733369112, Lr:0.0001\n",
      "Epoch 16, Step: 984, Loss: 0.09045116603374481, Lr:0.0001\n",
      "Epoch 16, Step: 985, Loss: 0.012994160875678062, Lr:0.0001\n",
      "Epoch 16, Step: 986, Loss: 0.06922337412834167, Lr:0.0001\n",
      "Epoch 16, Step: 987, Loss: 0.3018363118171692, Lr:0.0001\n",
      "Epoch 16, Step: 988, Loss: 0.13959302008152008, Lr:0.0001\n",
      "Epoch 16, Step: 989, Loss: 0.04488275200128555, Lr:0.0001\n",
      "Epoch 16, Step: 990, Loss: 0.13103744387626648, Lr:0.0001\n",
      "Epoch 16, Step: 991, Loss: 0.1741701364517212, Lr:0.0001\n",
      "Epoch 16, Step: 992, Loss: 0.00902014970779419, Lr:0.0001\n",
      "Epoch 16, Step: 993, Loss: 0.2684584856033325, Lr:0.0001\n",
      "Epoch 16, Step: 994, Loss: 0.059201303869485855, Lr:0.0001\n",
      "Epoch 16, Step: 995, Loss: 0.02113492228090763, Lr:0.0001\n",
      "Epoch 16, Step: 996, Loss: 0.08646523207426071, Lr:0.0001\n",
      "Epoch 16, Step: 997, Loss: 0.164213627576828, Lr:0.0001\n",
      "Epoch 16, Step: 998, Loss: 0.07242268323898315, Lr:0.0001\n",
      "Epoch 16, Step: 999, Loss: 0.0227599386125803, Lr:0.0001\n",
      "Epoch 16, Step: 1000, Loss: 0.0023538314271718264, Lr:0.0001\n",
      "Epoch 16, Step: 1001, Loss: 0.05166606605052948, Lr:0.0001\n",
      "Epoch 16, Step: 1002, Loss: 0.03173603117465973, Lr:0.0001\n",
      "Epoch 16, Step: 1003, Loss: 0.05828678980469704, Lr:0.0001\n",
      "Epoch 16, Step: 1004, Loss: 0.09498005360364914, Lr:0.0001\n",
      "Epoch 16, Step: 1005, Loss: 0.1290891170501709, Lr:0.0001\n",
      "Epoch 16, Step: 1006, Loss: 0.13328894972801208, Lr:0.0001\n",
      "Epoch 16, Step: 1007, Loss: 0.10441900789737701, Lr:0.0001\n",
      "Epoch 16, Step: 1008, Loss: 0.023285269737243652, Lr:0.0001\n",
      "Epoch 16, Step: 1009, Loss: 0.027917463332414627, Lr:0.0001\n",
      "Epoch 16, Step: 1010, Loss: 0.0920400470495224, Lr:0.0001\n",
      "Epoch 16, Step: 1011, Loss: 0.007849139161407948, Lr:0.0001\n",
      "Epoch 16, Step: 1012, Loss: 0.04241647198796272, Lr:0.0001\n",
      "Epoch 16, Step: 1013, Loss: 0.12112894654273987, Lr:0.0001\n",
      "Epoch 16, Step: 1014, Loss: 0.10039957612752914, Lr:0.0001\n",
      "Epoch 16, Step: 1015, Loss: 0.1042303517460823, Lr:0.0001\n",
      "Epoch 16, Step: 1016, Loss: 0.03471808880567551, Lr:0.0001\n",
      "Epoch 16, Step: 1017, Loss: 0.14887921512126923, Lr:0.0001\n",
      "Epoch 16, Step: 1018, Loss: 0.054082587361335754, Lr:0.0001\n",
      "Epoch 16, Step: 1019, Loss: 0.010675759986042976, Lr:0.0001\n",
      "Epoch 16, Step: 1020, Loss: 0.004970305599272251, Lr:0.0001\n",
      "Epoch 16, Step: 1021, Loss: 0.017721839249134064, Lr:0.0001\n",
      "Epoch 16, Step: 1022, Loss: 0.055312853306531906, Lr:0.0001\n",
      "Epoch 16, Step: 1023, Loss: 0.3266445994377136, Lr:0.0001\n",
      "Epoch 16, Step: 1024, Loss: 0.3564852774143219, Lr:0.0001\n",
      "Epoch 16, Step: 1025, Loss: 0.010240077041089535, Lr:0.0001\n",
      "Epoch 16, Step: 1026, Loss: 0.33082693815231323, Lr:0.0001\n",
      "Epoch 16, Step: 1027, Loss: 0.0580889917910099, Lr:0.0001\n",
      "Epoch 16, Step: 1028, Loss: 0.10235753655433655, Lr:0.0001\n",
      "Epoch 16, Step: 1029, Loss: 0.01872243359684944, Lr:0.0001\n",
      "Epoch 16, Step: 1030, Loss: 0.3867487907409668, Lr:0.0001\n",
      "Epoch 16, Step: 1031, Loss: 0.09942004084587097, Lr:0.0001\n",
      "Epoch 16, Step: 1032, Loss: 0.16612714529037476, Lr:0.0001\n",
      "Epoch 16, Step: 1033, Loss: 0.08015058189630508, Lr:0.0001\n",
      "Epoch 16, Step: 1034, Loss: 0.06498448550701141, Lr:0.0001\n",
      "Epoch 16, Step: 1035, Loss: 0.16884241998195648, Lr:0.0001\n",
      "Epoch 16, Step: 1036, Loss: 0.004073817748576403, Lr:0.0001\n",
      "Epoch 16, Step: 1037, Loss: 0.15213951468467712, Lr:0.0001\n",
      "Epoch 16, Step: 1038, Loss: 0.16265730559825897, Lr:0.0001\n",
      "Epoch 16, Step: 1039, Loss: 0.023605016991496086, Lr:0.0001\n",
      "Epoch 16, Step: 1040, Loss: 0.028942564502358437, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 16\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:17 loss: 0.0007 (0.0007) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.3060 data: 0.1240 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.0000 (0.0001) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.2881 data: 0.1107 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0000 (0.0558) acc1: 100.0000 (98.2143) acc5: 100.0000 (100.0000) time: 0.2844 data: 0.1091 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.2909 (0.2218) acc1: 93.7500 (93.3468) acc5: 100.0000 (100.0000) time: 0.2859 data: 0.1119 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.4275 (0.2666) acc1: 87.5000 (92.8354) acc5: 100.0000 (100.0000) time: 0.2908 data: 0.1167 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0955 (0.2438) acc1: 93.7500 (93.3824) acc5: 100.0000 (100.0000) time: 0.2964 data: 0.1182 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0081 (0.2243) acc1: 100.0000 (93.7571) acc5: 100.0000 (100.0000) time: 0.2922 data: 0.1147 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.2888 s / it)\n",
      "* Acc@1 93.757 Acc@5 100.000 loss 0.224\n",
      "Accuracy of the network on the 881 test image: 93.8%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 17, Step: 0, Loss: 0.15425607562065125, Lr:0.0001\n",
      "Epoch 17, Step: 1, Loss: 0.010155973955988884, Lr:0.0001\n",
      "Epoch 17, Step: 2, Loss: 0.23265579342842102, Lr:0.0001\n",
      "Epoch 17, Step: 3, Loss: 0.10819961875677109, Lr:0.0001\n",
      "Epoch 17, Step: 4, Loss: 0.04920947551727295, Lr:0.0001\n",
      "Epoch 17, Step: 5, Loss: 0.0076368716545403, Lr:0.0001\n",
      "Epoch 17, Step: 6, Loss: 0.06429857760667801, Lr:0.0001\n",
      "Epoch 17, Step: 7, Loss: 0.07441258430480957, Lr:0.0001\n",
      "Epoch 17, Step: 8, Loss: 0.06332916766405106, Lr:0.0001\n",
      "Epoch 17, Step: 9, Loss: 0.04089565575122833, Lr:0.0001\n",
      "Epoch 17, Step: 10, Loss: 0.2343580424785614, Lr:0.0001\n",
      "Epoch 17, Step: 11, Loss: 0.027538888156414032, Lr:0.0001\n",
      "Epoch 17, Step: 12, Loss: 0.09148618578910828, Lr:0.0001\n",
      "Epoch 17, Step: 13, Loss: 0.5322812795639038, Lr:0.0001\n",
      "Epoch 17, Step: 14, Loss: 0.07417553663253784, Lr:0.0001\n",
      "Epoch 17, Step: 15, Loss: 0.01358379889279604, Lr:0.0001\n",
      "Epoch 17, Step: 16, Loss: 0.02472272515296936, Lr:0.0001\n",
      "Epoch 17, Step: 17, Loss: 0.056744832545518875, Lr:0.0001\n",
      "Epoch 17, Step: 18, Loss: 0.0718734860420227, Lr:0.0001\n",
      "Epoch 17, Step: 19, Loss: 0.0402476042509079, Lr:0.0001\n",
      "Epoch 17, Step: 20, Loss: 0.01862526498734951, Lr:0.0001\n",
      "Epoch 17, Step: 21, Loss: 0.01807805895805359, Lr:0.0001\n",
      "Epoch 17, Step: 22, Loss: 0.056642357259988785, Lr:0.0001\n",
      "Epoch 17, Step: 23, Loss: 0.11499746888875961, Lr:0.0001\n",
      "Epoch 17, Step: 24, Loss: 0.0062990388832986355, Lr:0.0001\n",
      "Epoch 17, Step: 25, Loss: 0.02746732532978058, Lr:0.0001\n",
      "Epoch 17, Step: 26, Loss: 0.01071968674659729, Lr:0.0001\n",
      "Epoch 17, Step: 27, Loss: 0.052779797464609146, Lr:0.0001\n",
      "Epoch 17, Step: 28, Loss: 0.049476463347673416, Lr:0.0001\n",
      "Epoch 17, Step: 29, Loss: 0.1544407159090042, Lr:0.0001\n",
      "Epoch 17, Step: 30, Loss: 0.056308772414922714, Lr:0.0001\n",
      "Epoch 17, Step: 31, Loss: 0.061123814433813095, Lr:0.0001\n",
      "Epoch 17, Step: 32, Loss: 0.033454809337854385, Lr:0.0001\n",
      "Epoch 17, Step: 33, Loss: 0.11313900351524353, Lr:0.0001\n",
      "Epoch 17, Step: 34, Loss: 0.04633987322449684, Lr:0.0001\n",
      "Epoch 17, Step: 35, Loss: 0.06509076058864594, Lr:0.0001\n",
      "Epoch 17, Step: 36, Loss: 0.06240120530128479, Lr:0.0001\n",
      "Epoch 17, Step: 37, Loss: 0.2455156296491623, Lr:0.0001\n",
      "Epoch 17, Step: 38, Loss: 0.3734903931617737, Lr:0.0001\n",
      "Epoch 17, Step: 39, Loss: 0.2039090394973755, Lr:0.0001\n",
      "Epoch 17, Step: 40, Loss: 0.029145045205950737, Lr:0.0001\n",
      "Epoch 17, Step: 41, Loss: 0.08402108401060104, Lr:0.0001\n",
      "Epoch 17, Step: 42, Loss: 0.053641676902770996, Lr:0.0001\n",
      "Epoch 17, Step: 43, Loss: 0.009517665952444077, Lr:0.0001\n",
      "Epoch 17, Step: 44, Loss: 0.01921333186328411, Lr:0.0001\n",
      "Epoch 17, Step: 45, Loss: 0.06503257155418396, Lr:0.0001\n",
      "Epoch 17, Step: 46, Loss: 0.0607784241437912, Lr:0.0001\n",
      "Epoch 17, Step: 47, Loss: 0.04020654410123825, Lr:0.0001\n",
      "Epoch 17, Step: 48, Loss: 0.27994030714035034, Lr:0.0001\n",
      "Epoch 17, Step: 49, Loss: 0.010679722763597965, Lr:0.0001\n",
      "Epoch 17, Step: 50, Loss: 0.11280687153339386, Lr:0.0001\n",
      "Epoch 17, Step: 51, Loss: 0.01211996003985405, Lr:0.0001\n",
      "Epoch 17, Step: 52, Loss: 0.06592381000518799, Lr:0.0001\n",
      "Epoch 17, Step: 53, Loss: 0.10872446000576019, Lr:0.0001\n",
      "Epoch 17, Step: 54, Loss: 0.12672999501228333, Lr:0.0001\n",
      "Epoch 17, Step: 55, Loss: 0.15192697942256927, Lr:0.0001\n",
      "Epoch 17, Step: 56, Loss: 0.1043829470872879, Lr:0.0001\n",
      "Epoch 17, Step: 57, Loss: 0.09388959407806396, Lr:0.0001\n",
      "Epoch 17, Step: 58, Loss: 0.07123509049415588, Lr:0.0001\n",
      "Epoch 17, Step: 59, Loss: 0.1673438847064972, Lr:0.0001\n",
      "Epoch 17, Step: 60, Loss: 0.09655926376581192, Lr:0.0001\n",
      "Epoch 17, Step: 61, Loss: 0.0037909136153757572, Lr:0.0001\n",
      "Epoch 17, Step: 62, Loss: 0.06807208061218262, Lr:0.0001\n",
      "Epoch 17, Step: 63, Loss: 0.24205215275287628, Lr:0.0001\n",
      "Epoch 17, Step: 64, Loss: 0.028649436309933662, Lr:0.0001\n",
      "Epoch 17, Step: 65, Loss: 0.021310629323124886, Lr:0.0001\n",
      "Epoch 17, Step: 66, Loss: 0.02375522069633007, Lr:0.0001\n",
      "Epoch 17, Step: 67, Loss: 0.022199781611561775, Lr:0.0001\n",
      "Epoch 17, Step: 68, Loss: 0.04858103394508362, Lr:0.0001\n",
      "Epoch 17, Step: 69, Loss: 0.12370304018259048, Lr:0.0001\n",
      "Epoch 17, Step: 70, Loss: 0.1297415941953659, Lr:0.0001\n",
      "Epoch 17, Step: 71, Loss: 0.25905662775039673, Lr:0.0001\n",
      "Epoch 17, Step: 72, Loss: 0.0417301282286644, Lr:0.0001\n",
      "Epoch 17, Step: 73, Loss: 0.04793330654501915, Lr:0.0001\n",
      "Epoch 17, Step: 74, Loss: 0.18426431715488434, Lr:0.0001\n",
      "Epoch 17, Step: 75, Loss: 0.011455155909061432, Lr:0.0001\n",
      "Epoch 17, Step: 76, Loss: 0.2670459747314453, Lr:0.0001\n",
      "Epoch 17, Step: 77, Loss: 0.025729447603225708, Lr:0.0001\n",
      "Epoch 17, Step: 78, Loss: 0.0813208669424057, Lr:0.0001\n",
      "Epoch 17, Step: 79, Loss: 0.051807839423418045, Lr:0.0001\n",
      "Epoch 17, Step: 80, Loss: 0.07994311302900314, Lr:0.0001\n",
      "Epoch 17, Step: 81, Loss: 0.022937525063753128, Lr:0.0001\n",
      "Epoch 17, Step: 82, Loss: 0.11081738770008087, Lr:0.0001\n",
      "Epoch 17, Step: 83, Loss: 0.06404820829629898, Lr:0.0001\n",
      "Epoch 17, Step: 84, Loss: 0.09821882098913193, Lr:0.0001\n",
      "Epoch 17, Step: 85, Loss: 0.04361000284552574, Lr:0.0001\n",
      "Epoch 17, Step: 86, Loss: 0.15052786469459534, Lr:0.0001\n",
      "Epoch 17, Step: 87, Loss: 0.014881842769682407, Lr:0.0001\n",
      "Epoch 17, Step: 88, Loss: 0.026671871542930603, Lr:0.0001\n",
      "Epoch 17, Step: 89, Loss: 0.006396304350346327, Lr:0.0001\n",
      "Epoch 17, Step: 90, Loss: 0.017444955185055733, Lr:0.0001\n",
      "Epoch 17, Step: 91, Loss: 0.1254945695400238, Lr:0.0001\n",
      "Epoch 17, Step: 92, Loss: 0.059502292424440384, Lr:0.0001\n",
      "Epoch 17, Step: 93, Loss: 0.02011079154908657, Lr:0.0001\n",
      "Epoch 17, Step: 94, Loss: 0.05872698128223419, Lr:0.0001\n",
      "Epoch 17, Step: 95, Loss: 0.06527217477560043, Lr:0.0001\n",
      "Epoch 17, Step: 96, Loss: 0.034836605191230774, Lr:0.0001\n",
      "Epoch 17, Step: 97, Loss: 0.27544260025024414, Lr:0.0001\n",
      "Epoch 17, Step: 98, Loss: 0.00884960126131773, Lr:0.0001\n",
      "Epoch 17, Step: 99, Loss: 0.09379062801599503, Lr:0.0001\n",
      "Epoch 17, Step: 100, Loss: 0.04661034792661667, Lr:0.0001\n",
      "Epoch 17, Step: 101, Loss: 0.29085642099380493, Lr:0.0001\n",
      "Epoch 17, Step: 102, Loss: 0.0342547744512558, Lr:0.0001\n",
      "Epoch 17, Step: 103, Loss: 0.010336770676076412, Lr:0.0001\n",
      "Epoch 17, Step: 104, Loss: 0.08727873861789703, Lr:0.0001\n",
      "Epoch 17, Step: 105, Loss: 0.015075603500008583, Lr:0.0001\n",
      "Epoch 17, Step: 106, Loss: 0.053817249834537506, Lr:0.0001\n",
      "Epoch 17, Step: 107, Loss: 0.012928490526974201, Lr:0.0001\n",
      "Epoch 17, Step: 108, Loss: 0.21674519777297974, Lr:0.0001\n",
      "Epoch 17, Step: 109, Loss: 0.1215311586856842, Lr:0.0001\n",
      "Epoch 17, Step: 110, Loss: 0.15661102533340454, Lr:0.0001\n",
      "Epoch 17, Step: 111, Loss: 0.23539792001247406, Lr:0.0001\n",
      "Epoch 17, Step: 112, Loss: 0.12335970252752304, Lr:0.0001\n",
      "Epoch 17, Step: 113, Loss: 0.04872293025255203, Lr:0.0001\n",
      "Epoch 17, Step: 114, Loss: 0.017532577738165855, Lr:0.0001\n",
      "Epoch 17, Step: 115, Loss: 0.05066873878240585, Lr:0.0001\n",
      "Epoch 17, Step: 116, Loss: 0.004272871650755405, Lr:0.0001\n",
      "Epoch 17, Step: 117, Loss: 0.062331993132829666, Lr:0.0001\n",
      "Epoch 17, Step: 118, Loss: 0.06278499960899353, Lr:0.0001\n",
      "Epoch 17, Step: 119, Loss: 0.1221245601773262, Lr:0.0001\n",
      "Epoch 17, Step: 120, Loss: 0.253567099571228, Lr:0.0001\n",
      "Epoch 17, Step: 121, Loss: 0.02293788082897663, Lr:0.0001\n",
      "Epoch 17, Step: 122, Loss: 0.05697152763605118, Lr:0.0001\n",
      "Epoch 17, Step: 123, Loss: 0.13267843425273895, Lr:0.0001\n",
      "Epoch 17, Step: 124, Loss: 0.11722976714372635, Lr:0.0001\n",
      "Epoch 17, Step: 125, Loss: 0.04079272970557213, Lr:0.0001\n",
      "Epoch 17, Step: 126, Loss: 0.04927634820342064, Lr:0.0001\n",
      "Epoch 17, Step: 127, Loss: 0.025067420676350594, Lr:0.0001\n",
      "Epoch 17, Step: 128, Loss: 0.07808957248926163, Lr:0.0001\n",
      "Epoch 17, Step: 129, Loss: 0.09634137898683548, Lr:0.0001\n",
      "Epoch 17, Step: 130, Loss: 0.05086996778845787, Lr:0.0001\n",
      "Epoch 17, Step: 131, Loss: 0.11006654798984528, Lr:0.0001\n",
      "Epoch 17, Step: 132, Loss: 0.014119047671556473, Lr:0.0001\n",
      "Epoch 17, Step: 133, Loss: 0.06877294927835464, Lr:0.0001\n",
      "Epoch 17, Step: 134, Loss: 0.009193888865411282, Lr:0.0001\n",
      "Epoch 17, Step: 135, Loss: 0.06342845410108566, Lr:0.0001\n",
      "Epoch 17, Step: 136, Loss: 0.014345741830766201, Lr:0.0001\n",
      "Epoch 17, Step: 137, Loss: 0.017915479838848114, Lr:0.0001\n",
      "Epoch 17, Step: 138, Loss: 0.04843030497431755, Lr:0.0001\n",
      "Epoch 17, Step: 139, Loss: 0.009143542498350143, Lr:0.0001\n",
      "Epoch 17, Step: 140, Loss: 0.06991053372621536, Lr:0.0001\n",
      "Epoch 17, Step: 141, Loss: 0.022522715851664543, Lr:0.0001\n",
      "Epoch 17, Step: 142, Loss: 0.02182042971253395, Lr:0.0001\n",
      "Epoch 17, Step: 143, Loss: 0.34014782309532166, Lr:0.0001\n",
      "Epoch 17, Step: 144, Loss: 0.0232717115432024, Lr:0.0001\n",
      "Epoch 17, Step: 145, Loss: 0.010198541916906834, Lr:0.0001\n",
      "Epoch 17, Step: 146, Loss: 0.014699713326990604, Lr:0.0001\n",
      "Epoch 17, Step: 147, Loss: 0.04734964668750763, Lr:0.0001\n",
      "Epoch 17, Step: 148, Loss: 0.0012469058856368065, Lr:0.0001\n",
      "Epoch 17, Step: 149, Loss: 0.043855439871549606, Lr:0.0001\n",
      "Epoch 17, Step: 150, Loss: 0.02298622578382492, Lr:0.0001\n",
      "Epoch 17, Step: 151, Loss: 0.046548571437597275, Lr:0.0001\n",
      "Epoch 17, Step: 152, Loss: 0.27473703026771545, Lr:0.0001\n",
      "Epoch 17, Step: 153, Loss: 0.019348707050085068, Lr:0.0001\n",
      "Epoch 17, Step: 154, Loss: 0.14965127408504486, Lr:0.0001\n",
      "Epoch 17, Step: 155, Loss: 0.08613886684179306, Lr:0.0001\n",
      "Epoch 17, Step: 156, Loss: 0.051457490772008896, Lr:0.0001\n",
      "Epoch 17, Step: 157, Loss: 0.25836819410324097, Lr:0.0001\n",
      "Epoch 17, Step: 158, Loss: 0.0073086898773908615, Lr:0.0001\n",
      "Epoch 17, Step: 159, Loss: 0.03932638838887215, Lr:0.0001\n",
      "Epoch 17, Step: 160, Loss: 0.09451622515916824, Lr:0.0001\n",
      "Epoch 17, Step: 161, Loss: 0.023310178890824318, Lr:0.0001\n",
      "Epoch 17, Step: 162, Loss: 0.06643334776163101, Lr:0.0001\n",
      "Epoch 17, Step: 163, Loss: 0.05944081395864487, Lr:0.0001\n",
      "Epoch 17, Step: 164, Loss: 0.03716576471924782, Lr:0.0001\n",
      "Epoch 17, Step: 165, Loss: 0.04714149236679077, Lr:0.0001\n",
      "Epoch 17, Step: 166, Loss: 0.05427661910653114, Lr:0.0001\n",
      "Epoch 17, Step: 167, Loss: 0.0497528612613678, Lr:0.0001\n",
      "Epoch 17, Step: 168, Loss: 0.04672658070921898, Lr:0.0001\n",
      "Epoch 17, Step: 169, Loss: 0.07065270096063614, Lr:0.0001\n",
      "Epoch 17, Step: 170, Loss: 0.20609526336193085, Lr:0.0001\n",
      "Epoch 17, Step: 171, Loss: 0.11385843902826309, Lr:0.0001\n",
      "Epoch 17, Step: 172, Loss: 0.007125388365238905, Lr:0.0001\n",
      "Epoch 17, Step: 173, Loss: 0.16444475948810577, Lr:0.0001\n",
      "Epoch 17, Step: 174, Loss: 0.06040674448013306, Lr:0.0001\n",
      "Epoch 17, Step: 175, Loss: 0.042765598744153976, Lr:0.0001\n",
      "Epoch 17, Step: 176, Loss: 0.07304207235574722, Lr:0.0001\n",
      "Epoch 17, Step: 177, Loss: 0.041955720633268356, Lr:0.0001\n",
      "Epoch 17, Step: 178, Loss: 0.3052331209182739, Lr:0.0001\n",
      "Epoch 17, Step: 179, Loss: 0.0021150822285562754, Lr:0.0001\n",
      "Epoch 17, Step: 180, Loss: 0.018389640375971794, Lr:0.0001\n",
      "Epoch 17, Step: 181, Loss: 0.06834160536527634, Lr:0.0001\n",
      "Epoch 17, Step: 182, Loss: 0.0761253759264946, Lr:0.0001\n",
      "Epoch 17, Step: 183, Loss: 0.01792363077402115, Lr:0.0001\n",
      "Epoch 17, Step: 184, Loss: 0.0678839236497879, Lr:0.0001\n",
      "Epoch 17, Step: 185, Loss: 0.01797696202993393, Lr:0.0001\n",
      "Epoch 17, Step: 186, Loss: 0.0048896549269557, Lr:0.0001\n",
      "Epoch 17, Step: 187, Loss: 0.18355005979537964, Lr:0.0001\n",
      "Epoch 17, Step: 188, Loss: 0.06215517967939377, Lr:0.0001\n",
      "Epoch 17, Step: 189, Loss: 0.03315280005335808, Lr:0.0001\n",
      "Epoch 17, Step: 190, Loss: 0.19231602549552917, Lr:0.0001\n",
      "Epoch 17, Step: 191, Loss: 0.07189670205116272, Lr:0.0001\n",
      "Epoch 17, Step: 192, Loss: 0.034080199897289276, Lr:0.0001\n",
      "Epoch 17, Step: 193, Loss: 0.09538086503744125, Lr:0.0001\n",
      "Epoch 17, Step: 194, Loss: 0.1031637191772461, Lr:0.0001\n",
      "Epoch 17, Step: 195, Loss: 0.31723058223724365, Lr:0.0001\n",
      "Epoch 17, Step: 196, Loss: 0.029304195195436478, Lr:0.0001\n",
      "Epoch 17, Step: 197, Loss: 0.1384313553571701, Lr:0.0001\n",
      "Epoch 17, Step: 198, Loss: 0.05937788635492325, Lr:0.0001\n",
      "Epoch 17, Step: 199, Loss: 0.02028876170516014, Lr:0.0001\n",
      "Epoch 17, Step: 200, Loss: 0.08726584911346436, Lr:0.0001\n",
      "Epoch 17, Step: 201, Loss: 0.19735851883888245, Lr:0.0001\n",
      "Epoch 17, Step: 202, Loss: 0.25156596302986145, Lr:0.0001\n",
      "Epoch 17, Step: 203, Loss: 0.016683798283338547, Lr:0.0001\n",
      "Epoch 17, Step: 204, Loss: 0.06969690322875977, Lr:0.0001\n",
      "Epoch 17, Step: 205, Loss: 0.05314991623163223, Lr:0.0001\n",
      "Epoch 17, Step: 206, Loss: 0.2549682557582855, Lr:0.0001\n",
      "Epoch 17, Step: 207, Loss: 0.004371541552245617, Lr:0.0001\n",
      "Epoch 17, Step: 208, Loss: 0.002475739922374487, Lr:0.0001\n",
      "Epoch 17, Step: 209, Loss: 0.2574731707572937, Lr:0.0001\n",
      "Epoch 17, Step: 210, Loss: 0.0040140291675925255, Lr:0.0001\n",
      "Epoch 17, Step: 211, Loss: 0.22308725118637085, Lr:0.0001\n",
      "Epoch 17, Step: 212, Loss: 0.269591361284256, Lr:0.0001\n",
      "Epoch 17, Step: 213, Loss: 0.026738695800304413, Lr:0.0001\n",
      "Epoch 17, Step: 214, Loss: 0.03905622661113739, Lr:0.0001\n",
      "Epoch 17, Step: 215, Loss: 0.0655757337808609, Lr:0.0001\n",
      "Epoch 17, Step: 216, Loss: 0.07977638393640518, Lr:0.0001\n",
      "Epoch 17, Step: 217, Loss: 0.0693635568022728, Lr:0.0001\n",
      "Epoch 17, Step: 218, Loss: 0.1250130534172058, Lr:0.0001\n",
      "Epoch 17, Step: 219, Loss: 0.044244132936000824, Lr:0.0001\n",
      "Epoch 17, Step: 220, Loss: 0.005793948657810688, Lr:0.0001\n",
      "Epoch 17, Step: 221, Loss: 0.1626807451248169, Lr:0.0001\n",
      "Epoch 17, Step: 222, Loss: 0.026927361264824867, Lr:0.0001\n",
      "Epoch 17, Step: 223, Loss: 0.1130417212843895, Lr:0.0001\n",
      "Epoch 17, Step: 224, Loss: 0.04802659526467323, Lr:0.0001\n",
      "Epoch 17, Step: 225, Loss: 0.12849457561969757, Lr:0.0001\n",
      "Epoch 17, Step: 226, Loss: 0.07411128282546997, Lr:0.0001\n",
      "Epoch 17, Step: 227, Loss: 0.0024405629374086857, Lr:0.0001\n",
      "Epoch 17, Step: 228, Loss: 0.021812185645103455, Lr:0.0001\n",
      "Epoch 17, Step: 229, Loss: 0.16005872189998627, Lr:0.0001\n",
      "Epoch 17, Step: 230, Loss: 0.03574708476662636, Lr:0.0001\n",
      "Epoch 17, Step: 231, Loss: 0.06043557822704315, Lr:0.0001\n",
      "Epoch 17, Step: 232, Loss: 0.22134053707122803, Lr:0.0001\n",
      "Epoch 17, Step: 233, Loss: 0.0009444633033126593, Lr:0.0001\n",
      "Epoch 17, Step: 234, Loss: 0.048039402812719345, Lr:0.0001\n",
      "Epoch 17, Step: 235, Loss: 0.08639094978570938, Lr:0.0001\n",
      "Epoch 17, Step: 236, Loss: 0.1908717006444931, Lr:0.0001\n",
      "Epoch 17, Step: 237, Loss: 0.02107713557779789, Lr:0.0001\n",
      "Epoch 17, Step: 238, Loss: 0.0031397452112287283, Lr:0.0001\n",
      "Epoch 17, Step: 239, Loss: 0.1440432220697403, Lr:0.0001\n",
      "Epoch 17, Step: 240, Loss: 0.00427158921957016, Lr:0.0001\n",
      "Epoch 17, Step: 241, Loss: 0.23776616156101227, Lr:0.0001\n",
      "Epoch 17, Step: 242, Loss: 0.10062675178050995, Lr:0.0001\n",
      "Epoch 17, Step: 243, Loss: 0.02595343627035618, Lr:0.0001\n",
      "Epoch 17, Step: 244, Loss: 0.032305896282196045, Lr:0.0001\n",
      "Epoch 17, Step: 245, Loss: 0.01774323172867298, Lr:0.0001\n",
      "Epoch 17, Step: 246, Loss: 0.014656015671789646, Lr:0.0001\n",
      "Epoch 17, Step: 247, Loss: 0.017710797488689423, Lr:0.0001\n",
      "Epoch 17, Step: 248, Loss: 0.11813921481370926, Lr:0.0001\n",
      "Epoch 17, Step: 249, Loss: 0.7635365128517151, Lr:0.0001\n",
      "Epoch 17, Step: 250, Loss: 0.017583759501576424, Lr:0.0001\n",
      "Epoch 17, Step: 251, Loss: 0.08164156228303909, Lr:0.0001\n",
      "Epoch 17, Step: 252, Loss: 0.009855352342128754, Lr:0.0001\n",
      "Epoch 17, Step: 253, Loss: 0.006951700896024704, Lr:0.0001\n",
      "Epoch 17, Step: 254, Loss: 0.031054457649588585, Lr:0.0001\n",
      "Epoch 17, Step: 255, Loss: 0.1816486418247223, Lr:0.0001\n",
      "Epoch 17, Step: 256, Loss: 0.36884671449661255, Lr:0.0001\n",
      "Epoch 17, Step: 257, Loss: 0.0009460830478928983, Lr:0.0001\n",
      "Epoch 17, Step: 258, Loss: 0.052628837525844574, Lr:0.0001\n",
      "Epoch 17, Step: 259, Loss: 0.11646007746458054, Lr:0.0001\n",
      "Epoch 17, Step: 260, Loss: 0.03151947259902954, Lr:0.0001\n",
      "Epoch 17, Step: 261, Loss: 0.022264942526817322, Lr:0.0001\n",
      "Epoch 17, Step: 262, Loss: 0.027743089944124222, Lr:0.0001\n",
      "Epoch 17, Step: 263, Loss: 0.0970350131392479, Lr:0.0001\n",
      "Epoch 17, Step: 264, Loss: 0.3184754252433777, Lr:0.0001\n",
      "Epoch 17, Step: 265, Loss: 0.1435784548521042, Lr:0.0001\n",
      "Epoch 17, Step: 266, Loss: 0.04871182143688202, Lr:0.0001\n",
      "Epoch 17, Step: 267, Loss: 0.29809609055519104, Lr:0.0001\n",
      "Epoch 17, Step: 268, Loss: 0.015936752781271935, Lr:0.0001\n",
      "Epoch 17, Step: 269, Loss: 0.2551771402359009, Lr:0.0001\n",
      "Epoch 17, Step: 270, Loss: 0.002515805419534445, Lr:0.0001\n",
      "Epoch 17, Step: 271, Loss: 0.029537338763475418, Lr:0.0001\n",
      "Epoch 17, Step: 272, Loss: 0.22172372043132782, Lr:0.0001\n",
      "Epoch 17, Step: 273, Loss: 0.08025910705327988, Lr:0.0001\n",
      "Epoch 17, Step: 274, Loss: 0.09760431200265884, Lr:0.0001\n",
      "Epoch 17, Step: 275, Loss: 0.027483033016324043, Lr:0.0001\n",
      "Epoch 17, Step: 276, Loss: 0.005730821751058102, Lr:0.0001\n",
      "Epoch 17, Step: 277, Loss: 0.0015653005102649331, Lr:0.0001\n",
      "Epoch 17, Step: 278, Loss: 0.2069341540336609, Lr:0.0001\n",
      "Epoch 17, Step: 279, Loss: 0.14109724760055542, Lr:0.0001\n",
      "Epoch 17, Step: 280, Loss: 0.014845777302980423, Lr:0.0001\n",
      "Epoch 17, Step: 281, Loss: 0.02268947660923004, Lr:0.0001\n",
      "Epoch 17, Step: 282, Loss: 0.003473302349448204, Lr:0.0001\n",
      "Epoch 17, Step: 283, Loss: 0.1730194240808487, Lr:0.0001\n",
      "Epoch 17, Step: 284, Loss: 0.11827203631401062, Lr:0.0001\n",
      "Epoch 17, Step: 285, Loss: 0.12119153141975403, Lr:0.0001\n",
      "Epoch 17, Step: 286, Loss: 0.19086219370365143, Lr:0.0001\n",
      "Epoch 17, Step: 287, Loss: 0.18380782008171082, Lr:0.0001\n",
      "Epoch 17, Step: 288, Loss: 0.060196176171302795, Lr:0.0001\n",
      "Epoch 17, Step: 289, Loss: 0.010429861024022102, Lr:0.0001\n",
      "Epoch 17, Step: 290, Loss: 0.15047597885131836, Lr:0.0001\n",
      "Epoch 17, Step: 291, Loss: 0.007249411195516586, Lr:0.0001\n",
      "Epoch 17, Step: 292, Loss: 0.24649381637573242, Lr:0.0001\n",
      "Epoch 17, Step: 293, Loss: 0.21242740750312805, Lr:0.0001\n",
      "Epoch 17, Step: 294, Loss: 0.0063185859471559525, Lr:0.0001\n",
      "Epoch 17, Step: 295, Loss: 0.004651541355997324, Lr:0.0001\n",
      "Epoch 17, Step: 296, Loss: 0.026363888755440712, Lr:0.0001\n",
      "Epoch 17, Step: 297, Loss: 0.055260997265577316, Lr:0.0001\n",
      "Epoch 17, Step: 298, Loss: 0.20121730864048004, Lr:0.0001\n",
      "Epoch 17, Step: 299, Loss: 0.043755631893873215, Lr:0.0001\n",
      "Epoch 17, Step: 300, Loss: 0.21185919642448425, Lr:0.0001\n",
      "Epoch 17, Step: 301, Loss: 0.20532310009002686, Lr:0.0001\n",
      "Epoch 17, Step: 302, Loss: 0.06229264289140701, Lr:0.0001\n",
      "Epoch 17, Step: 303, Loss: 0.11504647880792618, Lr:0.0001\n",
      "Epoch 17, Step: 304, Loss: 0.020607847720384598, Lr:0.0001\n",
      "Epoch 17, Step: 305, Loss: 0.08979616314172745, Lr:0.0001\n",
      "Epoch 17, Step: 306, Loss: 0.08833950012922287, Lr:0.0001\n",
      "Epoch 17, Step: 307, Loss: 0.0693415179848671, Lr:0.0001\n",
      "Epoch 17, Step: 308, Loss: 0.0088485823944211, Lr:0.0001\n",
      "Epoch 17, Step: 309, Loss: 0.12369980663061142, Lr:0.0001\n",
      "Epoch 17, Step: 310, Loss: 0.08513019979000092, Lr:0.0001\n",
      "Epoch 17, Step: 311, Loss: 0.026965297758579254, Lr:0.0001\n",
      "Epoch 17, Step: 312, Loss: 0.03525087609887123, Lr:0.0001\n",
      "Epoch 17, Step: 313, Loss: 0.003371525788679719, Lr:0.0001\n",
      "Epoch 17, Step: 314, Loss: 0.005925283767282963, Lr:0.0001\n",
      "Epoch 17, Step: 315, Loss: 0.02886250615119934, Lr:0.0001\n",
      "Epoch 17, Step: 316, Loss: 0.2717002332210541, Lr:0.0001\n",
      "Epoch 17, Step: 317, Loss: 0.06054874509572983, Lr:0.0001\n",
      "Epoch 17, Step: 318, Loss: 0.03915991634130478, Lr:0.0001\n",
      "Epoch 17, Step: 319, Loss: 0.07194411009550095, Lr:0.0001\n",
      "Epoch 17, Step: 320, Loss: 0.04105415567755699, Lr:0.0001\n",
      "Epoch 17, Step: 321, Loss: 0.3005153238773346, Lr:0.0001\n",
      "Epoch 17, Step: 322, Loss: 0.07095281779766083, Lr:0.0001\n",
      "Epoch 17, Step: 323, Loss: 0.025647057220339775, Lr:0.0001\n",
      "Epoch 17, Step: 324, Loss: 0.051976125687360764, Lr:0.0001\n",
      "Epoch 17, Step: 325, Loss: 0.00781445112079382, Lr:0.0001\n",
      "Epoch 17, Step: 326, Loss: 0.14444032311439514, Lr:0.0001\n",
      "Epoch 17, Step: 327, Loss: 0.13327811658382416, Lr:0.0001\n",
      "Epoch 17, Step: 328, Loss: 0.0876343697309494, Lr:0.0001\n",
      "Epoch 17, Step: 329, Loss: 0.042971253395080566, Lr:0.0001\n",
      "Epoch 17, Step: 330, Loss: 0.06373482197523117, Lr:0.0001\n",
      "Epoch 17, Step: 331, Loss: 0.07424822449684143, Lr:0.0001\n",
      "Epoch 17, Step: 332, Loss: 0.04956060275435448, Lr:0.0001\n",
      "Epoch 17, Step: 333, Loss: 0.06388677656650543, Lr:0.0001\n",
      "Epoch 17, Step: 334, Loss: 0.07268840819597244, Lr:0.0001\n",
      "Epoch 17, Step: 335, Loss: 0.014584457501769066, Lr:0.0001\n",
      "Epoch 17, Step: 336, Loss: 0.07529856264591217, Lr:0.0001\n",
      "Epoch 17, Step: 337, Loss: 0.13614952564239502, Lr:0.0001\n",
      "Epoch 17, Step: 338, Loss: 0.2730219066143036, Lr:0.0001\n",
      "Epoch 17, Step: 339, Loss: 0.01159096322953701, Lr:0.0001\n",
      "Epoch 17, Step: 340, Loss: 0.12394791096448898, Lr:0.0001\n",
      "Epoch 17, Step: 341, Loss: 0.022565552964806557, Lr:0.0001\n",
      "Epoch 17, Step: 342, Loss: 0.028007330372929573, Lr:0.0001\n",
      "Epoch 17, Step: 343, Loss: 0.17892241477966309, Lr:0.0001\n",
      "Epoch 17, Step: 344, Loss: 0.21451260149478912, Lr:0.0001\n",
      "Epoch 17, Step: 345, Loss: 0.1394105851650238, Lr:0.0001\n",
      "Epoch 17, Step: 346, Loss: 0.010284725576639175, Lr:0.0001\n",
      "Epoch 17, Step: 347, Loss: 0.5659087300300598, Lr:0.0001\n",
      "Epoch 17, Step: 348, Loss: 0.10192640870809555, Lr:0.0001\n",
      "Epoch 17, Step: 349, Loss: 0.031000258401036263, Lr:0.0001\n",
      "Epoch 17, Step: 350, Loss: 0.09371171146631241, Lr:0.0001\n",
      "Epoch 17, Step: 351, Loss: 0.017934687435626984, Lr:0.0001\n",
      "Epoch 17, Step: 352, Loss: 0.13297609984874725, Lr:0.0001\n",
      "Epoch 17, Step: 353, Loss: 0.06428536772727966, Lr:0.0001\n",
      "Epoch 17, Step: 354, Loss: 0.026518061757087708, Lr:0.0001\n",
      "Epoch 17, Step: 355, Loss: 0.007691738661378622, Lr:0.0001\n",
      "Epoch 17, Step: 356, Loss: 0.27996429800987244, Lr:0.0001\n",
      "Epoch 17, Step: 357, Loss: 0.15724772214889526, Lr:0.0001\n",
      "Epoch 17, Step: 358, Loss: 0.031052440404891968, Lr:0.0001\n",
      "Epoch 17, Step: 359, Loss: 0.041190534830093384, Lr:0.0001\n",
      "Epoch 17, Step: 360, Loss: 0.04410230368375778, Lr:0.0001\n",
      "Epoch 17, Step: 361, Loss: 0.08256753534078598, Lr:0.0001\n",
      "Epoch 17, Step: 362, Loss: 0.28336960077285767, Lr:0.0001\n",
      "Epoch 17, Step: 363, Loss: 0.3143296241760254, Lr:0.0001\n",
      "Epoch 17, Step: 364, Loss: 0.06410284340381622, Lr:0.0001\n",
      "Epoch 17, Step: 365, Loss: 0.06661223620176315, Lr:0.0001\n",
      "Epoch 17, Step: 366, Loss: 0.025041842833161354, Lr:0.0001\n",
      "Epoch 17, Step: 367, Loss: 0.05139467865228653, Lr:0.0001\n",
      "Epoch 17, Step: 368, Loss: 0.019395828247070312, Lr:0.0001\n",
      "Epoch 17, Step: 369, Loss: 0.24218079447746277, Lr:0.0001\n",
      "Epoch 17, Step: 370, Loss: 0.1202494353055954, Lr:0.0001\n",
      "Epoch 17, Step: 371, Loss: 0.07397445291280746, Lr:0.0001\n",
      "Epoch 17, Step: 372, Loss: 0.09740714728832245, Lr:0.0001\n",
      "Epoch 17, Step: 373, Loss: 0.06124290078878403, Lr:0.0001\n",
      "Epoch 17, Step: 374, Loss: 0.20068030059337616, Lr:0.0001\n",
      "Epoch 17, Step: 375, Loss: 0.025070061907172203, Lr:0.0001\n",
      "Epoch 17, Step: 376, Loss: 0.4321630895137787, Lr:0.0001\n",
      "Epoch 17, Step: 377, Loss: 0.200846329331398, Lr:0.0001\n",
      "Epoch 17, Step: 378, Loss: 0.018611866980791092, Lr:0.0001\n",
      "Epoch 17, Step: 379, Loss: 0.006052514538168907, Lr:0.0001\n",
      "Epoch 17, Step: 380, Loss: 0.4204554259777069, Lr:0.0001\n",
      "Epoch 17, Step: 381, Loss: 0.024821611121296883, Lr:0.0001\n",
      "Epoch 17, Step: 382, Loss: 0.09108111262321472, Lr:0.0001\n",
      "Epoch 17, Step: 383, Loss: 0.07281379401683807, Lr:0.0001\n",
      "Epoch 17, Step: 384, Loss: 0.13966701924800873, Lr:0.0001\n",
      "Epoch 17, Step: 385, Loss: 0.02368088997900486, Lr:0.0001\n",
      "Epoch 17, Step: 386, Loss: 0.21650898456573486, Lr:0.0001\n",
      "Epoch 17, Step: 387, Loss: 0.12523511052131653, Lr:0.0001\n",
      "Epoch 17, Step: 388, Loss: 0.030677758157253265, Lr:0.0001\n",
      "Epoch 17, Step: 389, Loss: 0.21918553113937378, Lr:0.0001\n",
      "Epoch 17, Step: 390, Loss: 0.026054922491312027, Lr:0.0001\n",
      "Epoch 17, Step: 391, Loss: 0.2992248833179474, Lr:0.0001\n",
      "Epoch 17, Step: 392, Loss: 0.06269890069961548, Lr:0.0001\n",
      "Epoch 17, Step: 393, Loss: 0.059148237109184265, Lr:0.0001\n",
      "Epoch 17, Step: 394, Loss: 0.185186967253685, Lr:0.0001\n",
      "Epoch 17, Step: 395, Loss: 0.05148366838693619, Lr:0.0001\n",
      "Epoch 17, Step: 396, Loss: 0.1260848343372345, Lr:0.0001\n",
      "Epoch 17, Step: 397, Loss: 0.0033740168437361717, Lr:0.0001\n",
      "Epoch 17, Step: 398, Loss: 0.04785669222474098, Lr:0.0001\n",
      "Epoch 17, Step: 399, Loss: 0.15716350078582764, Lr:0.0001\n",
      "Epoch 17, Step: 400, Loss: 0.10953755676746368, Lr:0.0001\n",
      "Epoch 17, Step: 401, Loss: 0.21225272119045258, Lr:0.0001\n",
      "Epoch 17, Step: 402, Loss: 0.07327529042959213, Lr:0.0001\n",
      "Epoch 17, Step: 403, Loss: 0.1546076536178589, Lr:0.0001\n",
      "Epoch 17, Step: 404, Loss: 0.11564072221517563, Lr:0.0001\n",
      "Epoch 17, Step: 405, Loss: 0.018065141513943672, Lr:0.0001\n",
      "Epoch 17, Step: 406, Loss: 0.007719826884567738, Lr:0.0001\n",
      "Epoch 17, Step: 407, Loss: 0.04312455654144287, Lr:0.0001\n",
      "Epoch 17, Step: 408, Loss: 0.02089216746389866, Lr:0.0001\n",
      "Epoch 17, Step: 409, Loss: 0.22078067064285278, Lr:0.0001\n",
      "Epoch 17, Step: 410, Loss: 0.0314759835600853, Lr:0.0001\n",
      "Epoch 17, Step: 411, Loss: 0.2853056490421295, Lr:0.0001\n",
      "Epoch 17, Step: 412, Loss: 0.06683911383152008, Lr:0.0001\n",
      "Epoch 17, Step: 413, Loss: 0.21311034262180328, Lr:0.0001\n",
      "Epoch 17, Step: 414, Loss: 0.11079760640859604, Lr:0.0001\n",
      "Epoch 17, Step: 415, Loss: 0.16136597096920013, Lr:0.0001\n",
      "Epoch 17, Step: 416, Loss: 0.017356909811496735, Lr:0.0001\n",
      "Epoch 17, Step: 417, Loss: 0.04692022129893303, Lr:0.0001\n",
      "Epoch 17, Step: 418, Loss: 0.13013873994350433, Lr:0.0001\n",
      "Epoch 17, Step: 419, Loss: 0.02516970969736576, Lr:0.0001\n",
      "Epoch 17, Step: 420, Loss: 0.002498839283362031, Lr:0.0001\n",
      "Epoch 17, Step: 421, Loss: 0.002446282422170043, Lr:0.0001\n",
      "Epoch 17, Step: 422, Loss: 0.13063614070415497, Lr:0.0001\n",
      "Epoch 17, Step: 423, Loss: 0.14542628824710846, Lr:0.0001\n",
      "Epoch 17, Step: 424, Loss: 0.01682215742766857, Lr:0.0001\n",
      "Epoch 17, Step: 425, Loss: 0.0738760307431221, Lr:0.0001\n",
      "Epoch 17, Step: 426, Loss: 0.02573629468679428, Lr:0.0001\n",
      "Epoch 17, Step: 427, Loss: 0.013374079950153828, Lr:0.0001\n",
      "Epoch 17, Step: 428, Loss: 0.16348862648010254, Lr:0.0001\n",
      "Epoch 17, Step: 429, Loss: 0.24836258590221405, Lr:0.0001\n",
      "Epoch 17, Step: 430, Loss: 0.1345679610967636, Lr:0.0001\n",
      "Epoch 17, Step: 431, Loss: 0.16818669438362122, Lr:0.0001\n",
      "Epoch 17, Step: 432, Loss: 0.027750780805945396, Lr:0.0001\n",
      "Epoch 17, Step: 433, Loss: 0.03197304159402847, Lr:0.0001\n",
      "Epoch 17, Step: 434, Loss: 0.08319476246833801, Lr:0.0001\n",
      "Epoch 17, Step: 435, Loss: 0.02477831020951271, Lr:0.0001\n",
      "Epoch 17, Step: 436, Loss: 0.05005820468068123, Lr:0.0001\n",
      "Epoch 17, Step: 437, Loss: 0.051678381860256195, Lr:0.0001\n",
      "Epoch 17, Step: 438, Loss: 0.022631634026765823, Lr:0.0001\n",
      "Epoch 17, Step: 439, Loss: 0.058553021401166916, Lr:0.0001\n",
      "Epoch 17, Step: 440, Loss: 0.09834755212068558, Lr:0.0001\n",
      "Epoch 17, Step: 441, Loss: 0.014813223853707314, Lr:0.0001\n",
      "Epoch 17, Step: 442, Loss: 0.06904375553131104, Lr:0.0001\n",
      "Epoch 17, Step: 443, Loss: 0.028424996882677078, Lr:0.0001\n",
      "Epoch 17, Step: 444, Loss: 0.11350236088037491, Lr:0.0001\n",
      "Epoch 17, Step: 445, Loss: 0.05081472545862198, Lr:0.0001\n",
      "Epoch 17, Step: 446, Loss: 0.022400865331292152, Lr:0.0001\n",
      "Epoch 17, Step: 447, Loss: 0.15480266511440277, Lr:0.0001\n",
      "Epoch 17, Step: 448, Loss: 0.021055452525615692, Lr:0.0001\n",
      "Epoch 17, Step: 449, Loss: 0.0198439322412014, Lr:0.0001\n",
      "Epoch 17, Step: 450, Loss: 0.03252892196178436, Lr:0.0001\n",
      "Epoch 17, Step: 451, Loss: 0.10882958769798279, Lr:0.0001\n",
      "Epoch 17, Step: 452, Loss: 0.14367978274822235, Lr:0.0001\n",
      "Epoch 17, Step: 453, Loss: 0.09026237577199936, Lr:0.0001\n",
      "Epoch 17, Step: 454, Loss: 0.04042288661003113, Lr:0.0001\n",
      "Epoch 17, Step: 455, Loss: 0.018065989017486572, Lr:0.0001\n",
      "Epoch 17, Step: 456, Loss: 0.09648606181144714, Lr:0.0001\n",
      "Epoch 17, Step: 457, Loss: 0.006003441289067268, Lr:0.0001\n",
      "Epoch 17, Step: 458, Loss: 0.019840048626065254, Lr:0.0001\n",
      "Epoch 17, Step: 459, Loss: 0.05452114716172218, Lr:0.0001\n",
      "Epoch 17, Step: 460, Loss: 0.13459865748882294, Lr:0.0001\n",
      "Epoch 17, Step: 461, Loss: 0.010420522652566433, Lr:0.0001\n",
      "Epoch 17, Step: 462, Loss: 0.053872160613536835, Lr:0.0001\n",
      "Epoch 17, Step: 463, Loss: 0.34238871932029724, Lr:0.0001\n",
      "Epoch 17, Step: 464, Loss: 0.012563969939947128, Lr:0.0001\n",
      "Epoch 17, Step: 465, Loss: 0.03665823116898537, Lr:0.0001\n",
      "Epoch 17, Step: 466, Loss: 0.025071773678064346, Lr:0.0001\n",
      "Epoch 17, Step: 467, Loss: 0.29800817370414734, Lr:0.0001\n",
      "Epoch 17, Step: 468, Loss: 0.35644546151161194, Lr:0.0001\n",
      "Epoch 17, Step: 469, Loss: 0.028615502640604973, Lr:0.0001\n",
      "Epoch 17, Step: 470, Loss: 0.1478893756866455, Lr:0.0001\n",
      "Epoch 17, Step: 471, Loss: 0.03598128259181976, Lr:0.0001\n",
      "Epoch 17, Step: 472, Loss: 0.10407817363739014, Lr:0.0001\n",
      "Epoch 17, Step: 473, Loss: 0.03970452770590782, Lr:0.0001\n",
      "Epoch 17, Step: 474, Loss: 0.012946952134370804, Lr:0.0001\n",
      "Epoch 17, Step: 475, Loss: 0.07231053709983826, Lr:0.0001\n",
      "Epoch 17, Step: 476, Loss: 0.039364419877529144, Lr:0.0001\n",
      "Epoch 17, Step: 477, Loss: 0.005439883563667536, Lr:0.0001\n",
      "Epoch 17, Step: 478, Loss: 0.011708509176969528, Lr:0.0001\n",
      "Epoch 17, Step: 479, Loss: 0.023099670186638832, Lr:0.0001\n",
      "Epoch 17, Step: 480, Loss: 0.016858525574207306, Lr:0.0001\n",
      "Epoch 17, Step: 481, Loss: 0.06930951774120331, Lr:0.0001\n",
      "Epoch 17, Step: 482, Loss: 0.08882834017276764, Lr:0.0001\n",
      "Epoch 17, Step: 483, Loss: 0.41202881932258606, Lr:0.0001\n",
      "Epoch 17, Step: 484, Loss: 0.07384694367647171, Lr:0.0001\n",
      "Epoch 17, Step: 485, Loss: 0.2479398399591446, Lr:0.0001\n",
      "Epoch 17, Step: 486, Loss: 0.07279657572507858, Lr:0.0001\n",
      "Epoch 17, Step: 487, Loss: 0.10393782705068588, Lr:0.0001\n",
      "Epoch 17, Step: 488, Loss: 0.009028678759932518, Lr:0.0001\n",
      "Epoch 17, Step: 489, Loss: 0.012666098773479462, Lr:0.0001\n",
      "Epoch 17, Step: 490, Loss: 0.0015503439353778958, Lr:0.0001\n",
      "Epoch 17, Step: 491, Loss: 0.10274799168109894, Lr:0.0001\n",
      "Epoch 17, Step: 492, Loss: 0.024112941697239876, Lr:0.0001\n",
      "Epoch 17, Step: 493, Loss: 0.06782982498407364, Lr:0.0001\n",
      "Epoch 17, Step: 494, Loss: 0.07867629826068878, Lr:0.0001\n",
      "Epoch 17, Step: 495, Loss: 0.05134037137031555, Lr:0.0001\n",
      "Epoch 17, Step: 496, Loss: 0.20291174948215485, Lr:0.0001\n",
      "Epoch 17, Step: 497, Loss: 0.12755721807479858, Lr:0.0001\n",
      "Epoch 17, Step: 498, Loss: 0.2098759263753891, Lr:0.0001\n",
      "Epoch 17, Step: 499, Loss: 0.06631617248058319, Lr:0.0001\n",
      "Epoch 17, Step: 500, Loss: 0.038389552384614944, Lr:0.0001\n",
      "Epoch 17, Step: 501, Loss: 0.0011031886097043753, Lr:0.0001\n",
      "Epoch 17, Step: 502, Loss: 0.021559376269578934, Lr:0.0001\n",
      "Epoch 17, Step: 503, Loss: 0.08896287530660629, Lr:0.0001\n",
      "Epoch 17, Step: 504, Loss: 0.012662984430789948, Lr:0.0001\n",
      "Epoch 17, Step: 505, Loss: 0.061825454235076904, Lr:0.0001\n",
      "Epoch 17, Step: 506, Loss: 0.11758450418710709, Lr:0.0001\n",
      "Epoch 17, Step: 507, Loss: 0.011677565053105354, Lr:0.0001\n",
      "Epoch 17, Step: 508, Loss: 0.0933392122387886, Lr:0.0001\n",
      "Epoch 17, Step: 509, Loss: 0.016999704763293266, Lr:0.0001\n",
      "Epoch 17, Step: 510, Loss: 0.07742507755756378, Lr:0.0001\n",
      "Epoch 17, Step: 511, Loss: 0.06555305421352386, Lr:0.0001\n",
      "Epoch 17, Step: 512, Loss: 0.04664202034473419, Lr:0.0001\n",
      "Epoch 17, Step: 513, Loss: 0.18930210173130035, Lr:0.0001\n",
      "Epoch 17, Step: 514, Loss: 0.028922751545906067, Lr:0.0001\n",
      "Epoch 17, Step: 515, Loss: 0.015160300768911839, Lr:0.0001\n",
      "Epoch 17, Step: 516, Loss: 0.1971656233072281, Lr:0.0001\n",
      "Epoch 17, Step: 517, Loss: 0.02113949880003929, Lr:0.0001\n",
      "Epoch 17, Step: 518, Loss: 0.20522861182689667, Lr:0.0001\n",
      "Epoch 17, Step: 519, Loss: 0.12981709837913513, Lr:0.0001\n",
      "Epoch 17, Step: 520, Loss: 0.10284975171089172, Lr:0.0001\n",
      "Epoch 17, Step: 521, Loss: 0.09328649193048477, Lr:0.0001\n",
      "Epoch 17, Step: 522, Loss: 0.03089188225567341, Lr:0.0001\n",
      "Epoch 17, Step: 523, Loss: 0.060196030884981155, Lr:0.0001\n",
      "Epoch 17, Step: 524, Loss: 0.09460155665874481, Lr:0.0001\n",
      "Epoch 17, Step: 525, Loss: 0.012935926206409931, Lr:0.0001\n",
      "Epoch 17, Step: 526, Loss: 0.06249547377228737, Lr:0.0001\n",
      "Epoch 17, Step: 527, Loss: 0.011727751232683659, Lr:0.0001\n",
      "Epoch 17, Step: 528, Loss: 0.003206837922334671, Lr:0.0001\n",
      "Epoch 17, Step: 529, Loss: 0.03559194132685661, Lr:0.0001\n",
      "Epoch 17, Step: 530, Loss: 0.06405971199274063, Lr:0.0001\n",
      "Epoch 17, Step: 531, Loss: 0.011875749565660954, Lr:0.0001\n",
      "Epoch 17, Step: 532, Loss: 0.10606814920902252, Lr:0.0001\n",
      "Epoch 17, Step: 533, Loss: 0.2670226991176605, Lr:0.0001\n",
      "Epoch 17, Step: 534, Loss: 0.04552285745739937, Lr:0.0001\n",
      "Epoch 17, Step: 535, Loss: 0.103634312748909, Lr:0.0001\n",
      "Epoch 17, Step: 536, Loss: 0.05728993937373161, Lr:0.0001\n",
      "Epoch 17, Step: 537, Loss: 0.08617748320102692, Lr:0.0001\n",
      "Epoch 17, Step: 538, Loss: 0.03596324846148491, Lr:0.0001\n",
      "Epoch 17, Step: 539, Loss: 0.019036564975976944, Lr:0.0001\n",
      "Epoch 17, Step: 540, Loss: 0.13785448670387268, Lr:0.0001\n",
      "Epoch 17, Step: 541, Loss: 0.016815241426229477, Lr:0.0001\n",
      "Epoch 17, Step: 542, Loss: 0.015486638993024826, Lr:0.0001\n",
      "Epoch 17, Step: 543, Loss: 0.5178310871124268, Lr:0.0001\n",
      "Epoch 17, Step: 544, Loss: 0.14649704098701477, Lr:0.0001\n",
      "Epoch 17, Step: 545, Loss: 0.05175834521651268, Lr:0.0001\n",
      "Epoch 17, Step: 546, Loss: 0.09358189254999161, Lr:0.0001\n",
      "Epoch 17, Step: 547, Loss: 0.02500348724424839, Lr:0.0001\n",
      "Epoch 17, Step: 548, Loss: 0.25335538387298584, Lr:0.0001\n",
      "Epoch 17, Step: 549, Loss: 0.023813411593437195, Lr:0.0001\n",
      "Epoch 17, Step: 550, Loss: 0.028651561588048935, Lr:0.0001\n",
      "Epoch 17, Step: 551, Loss: 0.2236543744802475, Lr:0.0001\n",
      "Epoch 17, Step: 552, Loss: 0.013212955556809902, Lr:0.0001\n",
      "Epoch 17, Step: 553, Loss: 0.05079728364944458, Lr:0.0001\n",
      "Epoch 17, Step: 554, Loss: 0.02270444855093956, Lr:0.0001\n",
      "Epoch 17, Step: 555, Loss: 0.2885449528694153, Lr:0.0001\n",
      "Epoch 17, Step: 556, Loss: 0.04514586180448532, Lr:0.0001\n",
      "Epoch 17, Step: 557, Loss: 0.008484027348458767, Lr:0.0001\n",
      "Epoch 17, Step: 558, Loss: 0.14449074864387512, Lr:0.0001\n",
      "Epoch 17, Step: 559, Loss: 0.016209229826927185, Lr:0.0001\n",
      "Epoch 17, Step: 560, Loss: 0.07409239560365677, Lr:0.0001\n",
      "Epoch 17, Step: 561, Loss: 0.17797806859016418, Lr:0.0001\n",
      "Epoch 17, Step: 562, Loss: 0.23971548676490784, Lr:0.0001\n",
      "Epoch 17, Step: 563, Loss: 0.008289397694170475, Lr:0.0001\n",
      "Epoch 17, Step: 564, Loss: 0.10094960033893585, Lr:0.0001\n",
      "Epoch 17, Step: 565, Loss: 0.23995856940746307, Lr:0.0001\n",
      "Epoch 17, Step: 566, Loss: 0.1646290272474289, Lr:0.0001\n",
      "Epoch 17, Step: 567, Loss: 0.10320832580327988, Lr:0.0001\n",
      "Epoch 17, Step: 568, Loss: 0.03518589213490486, Lr:0.0001\n",
      "Epoch 17, Step: 569, Loss: 0.27562007308006287, Lr:0.0001\n",
      "Epoch 17, Step: 570, Loss: 0.018405217677354813, Lr:0.0001\n",
      "Epoch 17, Step: 571, Loss: 0.17480866611003876, Lr:0.0001\n",
      "Epoch 17, Step: 572, Loss: 0.05549754202365875, Lr:0.0001\n",
      "Epoch 17, Step: 573, Loss: 0.20948413014411926, Lr:0.0001\n",
      "Epoch 17, Step: 574, Loss: 0.0824073776602745, Lr:0.0001\n",
      "Epoch 17, Step: 575, Loss: 0.08090083301067352, Lr:0.0001\n",
      "Epoch 17, Step: 576, Loss: 0.08521503210067749, Lr:0.0001\n",
      "Epoch 17, Step: 577, Loss: 0.15741895139217377, Lr:0.0001\n",
      "Epoch 17, Step: 578, Loss: 0.021842585876584053, Lr:0.0001\n",
      "Epoch 17, Step: 579, Loss: 0.015741223469376564, Lr:0.0001\n",
      "Epoch 17, Step: 580, Loss: 0.04701544716954231, Lr:0.0001\n",
      "Epoch 17, Step: 581, Loss: 0.01733025722205639, Lr:0.0001\n",
      "Epoch 17, Step: 582, Loss: 0.022969212383031845, Lr:0.0001\n",
      "Epoch 17, Step: 583, Loss: 0.004295033402740955, Lr:0.0001\n",
      "Epoch 17, Step: 584, Loss: 0.22031186521053314, Lr:0.0001\n",
      "Epoch 17, Step: 585, Loss: 0.0247625932097435, Lr:0.0001\n",
      "Epoch 17, Step: 586, Loss: 0.13481050729751587, Lr:0.0001\n",
      "Epoch 17, Step: 587, Loss: 0.20341871678829193, Lr:0.0001\n",
      "Epoch 17, Step: 588, Loss: 0.08740091323852539, Lr:0.0001\n",
      "Epoch 17, Step: 589, Loss: 0.002169016981497407, Lr:0.0001\n",
      "Epoch 17, Step: 590, Loss: 0.0705285370349884, Lr:0.0001\n",
      "Epoch 17, Step: 591, Loss: 0.04815003275871277, Lr:0.0001\n",
      "Epoch 17, Step: 592, Loss: 0.0380844920873642, Lr:0.0001\n",
      "Epoch 17, Step: 593, Loss: 0.30584976077079773, Lr:0.0001\n",
      "Epoch 17, Step: 594, Loss: 0.12200038880109787, Lr:0.0001\n",
      "Epoch 17, Step: 595, Loss: 0.15188485383987427, Lr:0.0001\n",
      "Epoch 17, Step: 596, Loss: 0.044127415865659714, Lr:0.0001\n",
      "Epoch 17, Step: 597, Loss: 0.014038138091564178, Lr:0.0001\n",
      "Epoch 17, Step: 598, Loss: 0.07040361315011978, Lr:0.0001\n",
      "Epoch 17, Step: 599, Loss: 0.1323375254869461, Lr:0.0001\n",
      "Epoch 17, Step: 600, Loss: 0.048897407948970795, Lr:0.0001\n",
      "Epoch 17, Step: 601, Loss: 0.06724439561367035, Lr:0.0001\n",
      "Epoch 17, Step: 602, Loss: 0.05569572374224663, Lr:0.0001\n",
      "Epoch 17, Step: 603, Loss: 0.07833462953567505, Lr:0.0001\n",
      "Epoch 17, Step: 604, Loss: 0.005878459196537733, Lr:0.0001\n",
      "Epoch 17, Step: 605, Loss: 0.07888414710760117, Lr:0.0001\n",
      "Epoch 17, Step: 606, Loss: 0.024244993925094604, Lr:0.0001\n",
      "Epoch 17, Step: 607, Loss: 0.04278934746980667, Lr:0.0001\n",
      "Epoch 17, Step: 608, Loss: 0.1794939935207367, Lr:0.0001\n",
      "Epoch 17, Step: 609, Loss: 0.014624716714024544, Lr:0.0001\n",
      "Epoch 17, Step: 610, Loss: 0.23020707070827484, Lr:0.0001\n",
      "Epoch 17, Step: 611, Loss: 0.010283966548740864, Lr:0.0001\n",
      "Epoch 17, Step: 612, Loss: 0.03668920695781708, Lr:0.0001\n",
      "Epoch 17, Step: 613, Loss: 0.17887212336063385, Lr:0.0001\n",
      "Epoch 17, Step: 614, Loss: 0.05545364320278168, Lr:0.0001\n",
      "Epoch 17, Step: 615, Loss: 0.08453220874071121, Lr:0.0001\n",
      "Epoch 17, Step: 616, Loss: 0.08664653450250626, Lr:0.0001\n",
      "Epoch 17, Step: 617, Loss: 0.10712574422359467, Lr:0.0001\n",
      "Epoch 17, Step: 618, Loss: 0.0622272752225399, Lr:0.0001\n",
      "Epoch 17, Step: 619, Loss: 0.059483639895915985, Lr:0.0001\n",
      "Epoch 17, Step: 620, Loss: 0.15761025249958038, Lr:0.0001\n",
      "Epoch 17, Step: 621, Loss: 0.19234037399291992, Lr:0.0001\n",
      "Epoch 17, Step: 622, Loss: 0.06340114027261734, Lr:0.0001\n",
      "Epoch 17, Step: 623, Loss: 0.00484907440841198, Lr:0.0001\n",
      "Epoch 17, Step: 624, Loss: 0.0040908511728048325, Lr:0.0001\n",
      "Epoch 17, Step: 625, Loss: 0.0018259756034240127, Lr:0.0001\n",
      "Epoch 17, Step: 626, Loss: 0.6286246180534363, Lr:0.0001\n",
      "Epoch 17, Step: 627, Loss: 0.0568942055106163, Lr:0.0001\n",
      "Epoch 17, Step: 628, Loss: 0.004475519061088562, Lr:0.0001\n",
      "Epoch 17, Step: 629, Loss: 0.12202856689691544, Lr:0.0001\n",
      "Epoch 17, Step: 630, Loss: 0.09371472150087357, Lr:0.0001\n",
      "Epoch 17, Step: 631, Loss: 0.03192346915602684, Lr:0.0001\n",
      "Epoch 17, Step: 632, Loss: 0.05210915952920914, Lr:0.0001\n",
      "Epoch 17, Step: 633, Loss: 0.016381632536649704, Lr:0.0001\n",
      "Epoch 17, Step: 634, Loss: 0.051744334399700165, Lr:0.0001\n",
      "Epoch 17, Step: 635, Loss: 0.1795751452445984, Lr:0.0001\n",
      "Epoch 17, Step: 636, Loss: 0.035860516130924225, Lr:0.0001\n",
      "Epoch 17, Step: 637, Loss: 0.1265919804573059, Lr:0.0001\n",
      "Epoch 17, Step: 638, Loss: 0.09043873846530914, Lr:0.0001\n",
      "Epoch 17, Step: 639, Loss: 0.0029025666881352663, Lr:0.0001\n",
      "Epoch 17, Step: 640, Loss: 0.22361238300800323, Lr:0.0001\n",
      "Epoch 17, Step: 641, Loss: 0.029864534735679626, Lr:0.0001\n",
      "Epoch 17, Step: 642, Loss: 0.030961474403738976, Lr:0.0001\n",
      "Epoch 17, Step: 643, Loss: 0.485939085483551, Lr:0.0001\n",
      "Epoch 17, Step: 644, Loss: 0.03596208617091179, Lr:0.0001\n",
      "Epoch 17, Step: 645, Loss: 0.09655540436506271, Lr:0.0001\n",
      "Epoch 17, Step: 646, Loss: 0.009479423984885216, Lr:0.0001\n",
      "Epoch 17, Step: 647, Loss: 0.014628699980676174, Lr:0.0001\n",
      "Epoch 17, Step: 648, Loss: 0.07463504374027252, Lr:0.0001\n",
      "Epoch 17, Step: 649, Loss: 0.2563595771789551, Lr:0.0001\n",
      "Epoch 17, Step: 650, Loss: 0.03430051729083061, Lr:0.0001\n",
      "Epoch 17, Step: 651, Loss: 0.05236939340829849, Lr:0.0001\n",
      "Epoch 17, Step: 652, Loss: 0.1251903474330902, Lr:0.0001\n",
      "Epoch 17, Step: 653, Loss: 0.13459143042564392, Lr:0.0001\n",
      "Epoch 17, Step: 654, Loss: 0.013399227522313595, Lr:0.0001\n",
      "Epoch 17, Step: 655, Loss: 0.0385703481733799, Lr:0.0001\n",
      "Epoch 17, Step: 656, Loss: 0.19962045550346375, Lr:0.0001\n",
      "Epoch 17, Step: 657, Loss: 0.018195178359746933, Lr:0.0001\n",
      "Epoch 17, Step: 658, Loss: 0.2973432242870331, Lr:0.0001\n",
      "Epoch 17, Step: 659, Loss: 0.2669755220413208, Lr:0.0001\n",
      "Epoch 17, Step: 660, Loss: 0.25438717007637024, Lr:0.0001\n",
      "Epoch 17, Step: 661, Loss: 0.05673402175307274, Lr:0.0001\n",
      "Epoch 17, Step: 662, Loss: 0.029323440045118332, Lr:0.0001\n",
      "Epoch 17, Step: 663, Loss: 0.06139744818210602, Lr:0.0001\n",
      "Epoch 17, Step: 664, Loss: 0.06394480168819427, Lr:0.0001\n",
      "Epoch 17, Step: 665, Loss: 0.015591481700539589, Lr:0.0001\n",
      "Epoch 17, Step: 666, Loss: 0.10483801364898682, Lr:0.0001\n",
      "Epoch 17, Step: 667, Loss: 0.06678347289562225, Lr:0.0001\n",
      "Epoch 17, Step: 668, Loss: 0.015644440427422523, Lr:0.0001\n",
      "Epoch 17, Step: 669, Loss: 0.11291098594665527, Lr:0.0001\n",
      "Epoch 17, Step: 670, Loss: 0.0040453290566802025, Lr:0.0001\n",
      "Epoch 17, Step: 671, Loss: 0.025117237120866776, Lr:0.0001\n",
      "Epoch 17, Step: 672, Loss: 0.3087370991706848, Lr:0.0001\n",
      "Epoch 17, Step: 673, Loss: 0.041330836713314056, Lr:0.0001\n",
      "Epoch 17, Step: 674, Loss: 0.07551535218954086, Lr:0.0001\n",
      "Epoch 17, Step: 675, Loss: 0.12257220596075058, Lr:0.0001\n",
      "Epoch 17, Step: 676, Loss: 0.007323519792407751, Lr:0.0001\n",
      "Epoch 17, Step: 677, Loss: 0.10360372811555862, Lr:0.0001\n",
      "Epoch 17, Step: 678, Loss: 0.08306877315044403, Lr:0.0001\n",
      "Epoch 17, Step: 679, Loss: 0.013576011173427105, Lr:0.0001\n",
      "Epoch 17, Step: 680, Loss: 0.02377297729253769, Lr:0.0001\n",
      "Epoch 17, Step: 681, Loss: 0.07061824947595596, Lr:0.0001\n",
      "Epoch 17, Step: 682, Loss: 0.044455528259277344, Lr:0.0001\n",
      "Epoch 17, Step: 683, Loss: 0.13953585922718048, Lr:0.0001\n",
      "Epoch 17, Step: 684, Loss: 0.10986822098493576, Lr:0.0001\n",
      "Epoch 17, Step: 685, Loss: 0.24110986292362213, Lr:0.0001\n",
      "Epoch 17, Step: 686, Loss: 0.1979709267616272, Lr:0.0001\n",
      "Epoch 17, Step: 687, Loss: 0.007377182599157095, Lr:0.0001\n",
      "Epoch 17, Step: 688, Loss: 0.04732731357216835, Lr:0.0001\n",
      "Epoch 17, Step: 689, Loss: 0.011859878897666931, Lr:0.0001\n",
      "Epoch 17, Step: 690, Loss: 0.042481184005737305, Lr:0.0001\n",
      "Epoch 17, Step: 691, Loss: 0.03145153075456619, Lr:0.0001\n",
      "Epoch 17, Step: 692, Loss: 0.07192042469978333, Lr:0.0001\n",
      "Epoch 17, Step: 693, Loss: 0.05068795382976532, Lr:0.0001\n",
      "Epoch 17, Step: 694, Loss: 0.08954257518053055, Lr:0.0001\n",
      "Epoch 17, Step: 695, Loss: 0.12812235951423645, Lr:0.0001\n",
      "Epoch 17, Step: 696, Loss: 0.13113951683044434, Lr:0.0001\n",
      "Epoch 17, Step: 697, Loss: 0.12981274724006653, Lr:0.0001\n",
      "Epoch 17, Step: 698, Loss: 0.21360065042972565, Lr:0.0001\n",
      "Epoch 17, Step: 699, Loss: 0.567857027053833, Lr:0.0001\n",
      "Epoch 17, Step: 700, Loss: 0.062163036316633224, Lr:0.0001\n",
      "Epoch 17, Step: 701, Loss: 0.04921005666255951, Lr:0.0001\n",
      "Epoch 17, Step: 702, Loss: 0.04530007764697075, Lr:0.0001\n",
      "Epoch 17, Step: 703, Loss: 0.4256017506122589, Lr:0.0001\n",
      "Epoch 17, Step: 704, Loss: 0.14751170575618744, Lr:0.0001\n",
      "Epoch 17, Step: 705, Loss: 0.19146953523159027, Lr:0.0001\n",
      "Epoch 17, Step: 706, Loss: 0.06908781081438065, Lr:0.0001\n",
      "Epoch 17, Step: 707, Loss: 0.11891383677721024, Lr:0.0001\n",
      "Epoch 17, Step: 708, Loss: 0.13669385015964508, Lr:0.0001\n",
      "Epoch 17, Step: 709, Loss: 0.002789793536067009, Lr:0.0001\n",
      "Epoch 17, Step: 710, Loss: 0.07124417275190353, Lr:0.0001\n",
      "Epoch 17, Step: 711, Loss: 0.08543412387371063, Lr:0.0001\n",
      "Epoch 17, Step: 712, Loss: 0.0354989729821682, Lr:0.0001\n",
      "Epoch 17, Step: 713, Loss: 0.06072710454463959, Lr:0.0001\n",
      "Epoch 17, Step: 714, Loss: 0.1592985838651657, Lr:0.0001\n",
      "Epoch 17, Step: 715, Loss: 0.033801864832639694, Lr:0.0001\n",
      "Epoch 17, Step: 716, Loss: 0.024988094344735146, Lr:0.0001\n",
      "Epoch 17, Step: 717, Loss: 0.03879839554429054, Lr:0.0001\n",
      "Epoch 17, Step: 718, Loss: 0.2209632396697998, Lr:0.0001\n",
      "Epoch 17, Step: 719, Loss: 0.19952934980392456, Lr:0.0001\n",
      "Epoch 17, Step: 720, Loss: 0.031573422253131866, Lr:0.0001\n",
      "Epoch 17, Step: 721, Loss: 0.16090895235538483, Lr:0.0001\n",
      "Epoch 17, Step: 722, Loss: 0.14245419204235077, Lr:0.0001\n",
      "Epoch 17, Step: 723, Loss: 0.023623865097761154, Lr:0.0001\n",
      "Epoch 17, Step: 724, Loss: 0.0046171145513653755, Lr:0.0001\n",
      "Epoch 17, Step: 725, Loss: 0.025292623788118362, Lr:0.0001\n",
      "Epoch 17, Step: 726, Loss: 0.27604517340660095, Lr:0.0001\n",
      "Epoch 17, Step: 727, Loss: 0.039228446781635284, Lr:0.0001\n",
      "Epoch 17, Step: 728, Loss: 0.09608237445354462, Lr:0.0001\n",
      "Epoch 17, Step: 729, Loss: 0.23865969479084015, Lr:0.0001\n",
      "Epoch 17, Step: 730, Loss: 0.010992464609444141, Lr:0.0001\n",
      "Epoch 17, Step: 731, Loss: 0.07048933207988739, Lr:0.0001\n",
      "Epoch 17, Step: 732, Loss: 0.10657934844493866, Lr:0.0001\n",
      "Epoch 17, Step: 733, Loss: 0.011734694242477417, Lr:0.0001\n",
      "Epoch 17, Step: 734, Loss: 0.03765461966395378, Lr:0.0001\n",
      "Epoch 17, Step: 735, Loss: 0.15064550936222076, Lr:0.0001\n",
      "Epoch 17, Step: 736, Loss: 0.4571901857852936, Lr:0.0001\n",
      "Epoch 17, Step: 737, Loss: 0.011685269884765148, Lr:0.0001\n",
      "Epoch 17, Step: 738, Loss: 0.09846886247396469, Lr:0.0001\n",
      "Epoch 17, Step: 739, Loss: 0.41570430994033813, Lr:0.0001\n",
      "Epoch 17, Step: 740, Loss: 0.6443146467208862, Lr:0.0001\n",
      "Epoch 17, Step: 741, Loss: 0.11113619804382324, Lr:0.0001\n",
      "Epoch 17, Step: 742, Loss: 0.078694187104702, Lr:0.0001\n",
      "Epoch 17, Step: 743, Loss: 0.024736125022172928, Lr:0.0001\n",
      "Epoch 17, Step: 744, Loss: 0.4696113169193268, Lr:0.0001\n",
      "Epoch 17, Step: 745, Loss: 0.19779475033283234, Lr:0.0001\n",
      "Epoch 17, Step: 746, Loss: 0.038398273289203644, Lr:0.0001\n",
      "Epoch 17, Step: 747, Loss: 0.1752576231956482, Lr:0.0001\n",
      "Epoch 17, Step: 748, Loss: 0.1667490005493164, Lr:0.0001\n",
      "Epoch 17, Step: 749, Loss: 0.14566481113433838, Lr:0.0001\n",
      "Epoch 17, Step: 750, Loss: 0.1092584952712059, Lr:0.0001\n",
      "Epoch 17, Step: 751, Loss: 0.008147286251187325, Lr:0.0001\n",
      "Epoch 17, Step: 752, Loss: 0.19074781239032745, Lr:0.0001\n",
      "Epoch 17, Step: 753, Loss: 0.2872866094112396, Lr:0.0001\n",
      "Epoch 17, Step: 754, Loss: 0.02074725553393364, Lr:0.0001\n",
      "Epoch 17, Step: 755, Loss: 0.29430699348449707, Lr:0.0001\n",
      "Epoch 17, Step: 756, Loss: 0.038746822625398636, Lr:0.0001\n",
      "Epoch 17, Step: 757, Loss: 0.1326712965965271, Lr:0.0001\n",
      "Epoch 17, Step: 758, Loss: 0.008338456973433495, Lr:0.0001\n",
      "Epoch 17, Step: 759, Loss: 0.09341946244239807, Lr:0.0001\n",
      "Epoch 17, Step: 760, Loss: 0.1973470151424408, Lr:0.0001\n",
      "Epoch 17, Step: 761, Loss: 0.08887095004320145, Lr:0.0001\n",
      "Epoch 17, Step: 762, Loss: 0.3061719834804535, Lr:0.0001\n",
      "Epoch 17, Step: 763, Loss: 0.06183569133281708, Lr:0.0001\n",
      "Epoch 17, Step: 764, Loss: 0.08724672347307205, Lr:0.0001\n",
      "Epoch 17, Step: 765, Loss: 0.09262021631002426, Lr:0.0001\n",
      "Epoch 17, Step: 766, Loss: 0.22568799555301666, Lr:0.0001\n",
      "Epoch 17, Step: 767, Loss: 0.35963937640190125, Lr:0.0001\n",
      "Epoch 17, Step: 768, Loss: 0.023225748911499977, Lr:0.0001\n",
      "Epoch 17, Step: 769, Loss: 0.24273058772087097, Lr:0.0001\n",
      "Epoch 17, Step: 770, Loss: 0.06963729113340378, Lr:0.0001\n",
      "Epoch 17, Step: 771, Loss: 0.05722804740071297, Lr:0.0001\n",
      "Epoch 17, Step: 772, Loss: 0.2202073186635971, Lr:0.0001\n",
      "Epoch 17, Step: 773, Loss: 0.1867639720439911, Lr:0.0001\n",
      "Epoch 17, Step: 774, Loss: 0.07169390469789505, Lr:0.0001\n",
      "Epoch 17, Step: 775, Loss: 0.05120383948087692, Lr:0.0001\n",
      "Epoch 17, Step: 776, Loss: 0.09883655607700348, Lr:0.0001\n",
      "Epoch 17, Step: 777, Loss: 0.6322677135467529, Lr:0.0001\n",
      "Epoch 17, Step: 778, Loss: 0.011295205913484097, Lr:0.0001\n",
      "Epoch 17, Step: 779, Loss: 0.23268398642539978, Lr:0.0001\n",
      "Epoch 17, Step: 780, Loss: 0.019275130704045296, Lr:0.0001\n",
      "Epoch 17, Step: 781, Loss: 0.07871264964342117, Lr:0.0001\n",
      "Epoch 17, Step: 782, Loss: 0.34472551941871643, Lr:0.0001\n",
      "Epoch 17, Step: 783, Loss: 0.04178760573267937, Lr:0.0001\n",
      "Epoch 17, Step: 784, Loss: 0.2388181835412979, Lr:0.0001\n",
      "Epoch 17, Step: 785, Loss: 0.012643298134207726, Lr:0.0001\n",
      "Epoch 17, Step: 786, Loss: 0.0806516706943512, Lr:0.0001\n",
      "Epoch 17, Step: 787, Loss: 0.05116330459713936, Lr:0.0001\n",
      "Epoch 17, Step: 788, Loss: 0.2905137240886688, Lr:0.0001\n",
      "Epoch 17, Step: 789, Loss: 0.21279916167259216, Lr:0.0001\n",
      "Epoch 17, Step: 790, Loss: 0.09641473740339279, Lr:0.0001\n",
      "Epoch 17, Step: 791, Loss: 0.2666550874710083, Lr:0.0001\n",
      "Epoch 17, Step: 792, Loss: 0.03508014231920242, Lr:0.0001\n",
      "Epoch 17, Step: 793, Loss: 0.13000209629535675, Lr:0.0001\n",
      "Epoch 17, Step: 794, Loss: 0.00823205802589655, Lr:0.0001\n",
      "Epoch 17, Step: 795, Loss: 0.01242115069180727, Lr:0.0001\n",
      "Epoch 17, Step: 796, Loss: 0.07214752584695816, Lr:0.0001\n",
      "Epoch 17, Step: 797, Loss: 0.00783496256917715, Lr:0.0001\n",
      "Epoch 17, Step: 798, Loss: 0.023604685440659523, Lr:0.0001\n",
      "Epoch 17, Step: 799, Loss: 0.03775352984666824, Lr:0.0001\n",
      "Epoch 17, Step: 800, Loss: 0.06837687641382217, Lr:0.0001\n",
      "Epoch 17, Step: 801, Loss: 0.004202206619083881, Lr:0.0001\n",
      "Epoch 17, Step: 802, Loss: 0.32560354471206665, Lr:0.0001\n",
      "Epoch 17, Step: 803, Loss: 0.02575417049229145, Lr:0.0001\n",
      "Epoch 17, Step: 804, Loss: 0.046963710337877274, Lr:0.0001\n",
      "Epoch 17, Step: 805, Loss: 0.12732969224452972, Lr:0.0001\n",
      "Epoch 17, Step: 806, Loss: 0.06642970442771912, Lr:0.0001\n",
      "Epoch 17, Step: 807, Loss: 0.20187130570411682, Lr:0.0001\n",
      "Epoch 17, Step: 808, Loss: 0.10252434015274048, Lr:0.0001\n",
      "Epoch 17, Step: 809, Loss: 0.22574017941951752, Lr:0.0001\n",
      "Epoch 17, Step: 810, Loss: 0.23744948208332062, Lr:0.0001\n",
      "Epoch 17, Step: 811, Loss: 0.2832328677177429, Lr:0.0001\n",
      "Epoch 17, Step: 812, Loss: 0.06684421747922897, Lr:0.0001\n",
      "Epoch 17, Step: 813, Loss: 0.07850270718336105, Lr:0.0001\n",
      "Epoch 17, Step: 814, Loss: 0.2675255835056305, Lr:0.0001\n",
      "Epoch 17, Step: 815, Loss: 0.11845283955335617, Lr:0.0001\n",
      "Epoch 17, Step: 816, Loss: 0.14664766192436218, Lr:0.0001\n",
      "Epoch 17, Step: 817, Loss: 0.11754296720027924, Lr:0.0001\n",
      "Epoch 17, Step: 818, Loss: 0.207441046833992, Lr:0.0001\n",
      "Epoch 17, Step: 819, Loss: 0.1612265408039093, Lr:0.0001\n",
      "Epoch 17, Step: 820, Loss: 0.2895590364933014, Lr:0.0001\n",
      "Epoch 17, Step: 821, Loss: 0.006742424797266722, Lr:0.0001\n",
      "Epoch 17, Step: 822, Loss: 0.3509158790111542, Lr:0.0001\n",
      "Epoch 17, Step: 823, Loss: 0.13022379577159882, Lr:0.0001\n",
      "Epoch 17, Step: 824, Loss: 0.10232334583997726, Lr:0.0001\n",
      "Epoch 17, Step: 825, Loss: 0.04332816228270531, Lr:0.0001\n",
      "Epoch 17, Step: 826, Loss: 0.04603585600852966, Lr:0.0001\n",
      "Epoch 17, Step: 827, Loss: 0.032090332359075546, Lr:0.0001\n",
      "Epoch 17, Step: 828, Loss: 0.03250334411859512, Lr:0.0001\n",
      "Epoch 17, Step: 829, Loss: 0.15663672983646393, Lr:0.0001\n",
      "Epoch 17, Step: 830, Loss: 0.0736289992928505, Lr:0.0001\n",
      "Epoch 17, Step: 831, Loss: 0.1256466805934906, Lr:0.0001\n",
      "Epoch 17, Step: 832, Loss: 0.017923470586538315, Lr:0.0001\n",
      "Epoch 17, Step: 833, Loss: 0.011460262350738049, Lr:0.0001\n",
      "Epoch 17, Step: 834, Loss: 0.026792259886860847, Lr:0.0001\n",
      "Epoch 17, Step: 835, Loss: 0.03079071454703808, Lr:0.0001\n",
      "Epoch 17, Step: 836, Loss: 0.01271001249551773, Lr:0.0001\n",
      "Epoch 17, Step: 837, Loss: 0.01143021509051323, Lr:0.0001\n",
      "Epoch 17, Step: 838, Loss: 0.2718626856803894, Lr:0.0001\n",
      "Epoch 17, Step: 839, Loss: 0.20587915182113647, Lr:0.0001\n",
      "Epoch 17, Step: 840, Loss: 0.13266725838184357, Lr:0.0001\n",
      "Epoch 17, Step: 841, Loss: 0.11965014785528183, Lr:0.0001\n",
      "Epoch 17, Step: 842, Loss: 0.07065290957689285, Lr:0.0001\n",
      "Epoch 17, Step: 843, Loss: 0.18525178730487823, Lr:0.0001\n",
      "Epoch 17, Step: 844, Loss: 0.23278813064098358, Lr:0.0001\n",
      "Epoch 17, Step: 845, Loss: 0.07946561276912689, Lr:0.0001\n",
      "Epoch 17, Step: 846, Loss: 0.017981212586164474, Lr:0.0001\n",
      "Epoch 17, Step: 847, Loss: 0.057394180446863174, Lr:0.0001\n",
      "Epoch 17, Step: 848, Loss: 0.09739211201667786, Lr:0.0001\n",
      "Epoch 17, Step: 849, Loss: 0.150080144405365, Lr:0.0001\n",
      "Epoch 17, Step: 850, Loss: 0.03774350509047508, Lr:0.0001\n",
      "Epoch 17, Step: 851, Loss: 0.1342283934354782, Lr:0.0001\n",
      "Epoch 17, Step: 852, Loss: 0.051365435123443604, Lr:0.0001\n",
      "Epoch 17, Step: 853, Loss: 0.008430966176092625, Lr:0.0001\n",
      "Epoch 17, Step: 854, Loss: 0.1950383335351944, Lr:0.0001\n",
      "Epoch 17, Step: 855, Loss: 0.052992742508649826, Lr:0.0001\n",
      "Epoch 17, Step: 856, Loss: 0.15883293747901917, Lr:0.0001\n",
      "Epoch 17, Step: 857, Loss: 0.023425880819559097, Lr:0.0001\n",
      "Epoch 17, Step: 858, Loss: 0.08765438199043274, Lr:0.0001\n",
      "Epoch 17, Step: 859, Loss: 0.16333933174610138, Lr:0.0001\n",
      "Epoch 17, Step: 860, Loss: 0.03812602907419205, Lr:0.0001\n",
      "Epoch 17, Step: 861, Loss: 0.22794432938098907, Lr:0.0001\n",
      "Epoch 17, Step: 862, Loss: 0.18022729456424713, Lr:0.0001\n",
      "Epoch 17, Step: 863, Loss: 0.008863248862326145, Lr:0.0001\n",
      "Epoch 17, Step: 864, Loss: 0.02808164246380329, Lr:0.0001\n",
      "Epoch 17, Step: 865, Loss: 0.07473503798246384, Lr:0.0001\n",
      "Epoch 17, Step: 866, Loss: 0.04553377628326416, Lr:0.0001\n",
      "Epoch 17, Step: 867, Loss: 0.01799164153635502, Lr:0.0001\n",
      "Epoch 17, Step: 868, Loss: 0.08104090392589569, Lr:0.0001\n",
      "Epoch 17, Step: 869, Loss: 0.01959633082151413, Lr:0.0001\n",
      "Epoch 17, Step: 870, Loss: 0.09341282397508621, Lr:0.0001\n",
      "Epoch 17, Step: 871, Loss: 0.07100246101617813, Lr:0.0001\n",
      "Epoch 17, Step: 872, Loss: 0.03829268738627434, Lr:0.0001\n",
      "Epoch 17, Step: 873, Loss: 0.17788727581501007, Lr:0.0001\n",
      "Epoch 17, Step: 874, Loss: 0.015472272410988808, Lr:0.0001\n",
      "Epoch 17, Step: 875, Loss: 0.06131214648485184, Lr:0.0001\n",
      "Epoch 17, Step: 876, Loss: 0.015274373814463615, Lr:0.0001\n",
      "Epoch 17, Step: 877, Loss: 0.14129449427127838, Lr:0.0001\n",
      "Epoch 17, Step: 878, Loss: 0.08896485716104507, Lr:0.0001\n",
      "Epoch 17, Step: 879, Loss: 0.006545169744640589, Lr:0.0001\n",
      "Epoch 17, Step: 880, Loss: 0.01673183962702751, Lr:0.0001\n",
      "Epoch 17, Step: 881, Loss: 0.36850255727767944, Lr:0.0001\n",
      "Epoch 17, Step: 882, Loss: 0.29256919026374817, Lr:0.0001\n",
      "Epoch 17, Step: 883, Loss: 0.5113807916641235, Lr:0.0001\n",
      "Epoch 17, Step: 884, Loss: 0.19836625456809998, Lr:0.0001\n",
      "Epoch 17, Step: 885, Loss: 0.020141035318374634, Lr:0.0001\n",
      "Epoch 17, Step: 886, Loss: 0.053835075348615646, Lr:0.0001\n",
      "Epoch 17, Step: 887, Loss: 0.0388379730284214, Lr:0.0001\n",
      "Epoch 17, Step: 888, Loss: 0.058357562869787216, Lr:0.0001\n",
      "Epoch 17, Step: 889, Loss: 0.2370069921016693, Lr:0.0001\n",
      "Epoch 17, Step: 890, Loss: 0.038226738572120667, Lr:0.0001\n",
      "Epoch 17, Step: 891, Loss: 0.1318105310201645, Lr:0.0001\n",
      "Epoch 17, Step: 892, Loss: 0.2498215138912201, Lr:0.0001\n",
      "Epoch 17, Step: 893, Loss: 0.21462410688400269, Lr:0.0001\n",
      "Epoch 17, Step: 894, Loss: 0.015235137194395065, Lr:0.0001\n",
      "Epoch 17, Step: 895, Loss: 0.09892024099826813, Lr:0.0001\n",
      "Epoch 17, Step: 896, Loss: 0.08829007297754288, Lr:0.0001\n",
      "Epoch 17, Step: 897, Loss: 0.3822655975818634, Lr:0.0001\n",
      "Epoch 17, Step: 898, Loss: 0.009074968285858631, Lr:0.0001\n",
      "Epoch 17, Step: 899, Loss: 0.032952938228845596, Lr:0.0001\n",
      "Epoch 17, Step: 900, Loss: 0.06672316044569016, Lr:0.0001\n",
      "Epoch 17, Step: 901, Loss: 0.053697679191827774, Lr:0.0001\n",
      "Epoch 17, Step: 902, Loss: 0.04829014837741852, Lr:0.0001\n",
      "Epoch 17, Step: 903, Loss: 0.022630317136645317, Lr:0.0001\n",
      "Epoch 17, Step: 904, Loss: 0.06638343632221222, Lr:0.0001\n",
      "Epoch 17, Step: 905, Loss: 0.05045769363641739, Lr:0.0001\n",
      "Epoch 17, Step: 906, Loss: 0.2747051417827606, Lr:0.0001\n",
      "Epoch 17, Step: 907, Loss: 0.04428531602025032, Lr:0.0001\n",
      "Epoch 17, Step: 908, Loss: 0.06233437359333038, Lr:0.0001\n",
      "Epoch 17, Step: 909, Loss: 0.044062890112400055, Lr:0.0001\n",
      "Epoch 17, Step: 910, Loss: 0.036710187792778015, Lr:0.0001\n",
      "Epoch 17, Step: 911, Loss: 0.1812218278646469, Lr:0.0001\n",
      "Epoch 17, Step: 912, Loss: 0.023512987419962883, Lr:0.0001\n",
      "Epoch 17, Step: 913, Loss: 0.02764558047056198, Lr:0.0001\n",
      "Epoch 17, Step: 914, Loss: 0.00756837660446763, Lr:0.0001\n",
      "Epoch 17, Step: 915, Loss: 0.012717360630631447, Lr:0.0001\n",
      "Epoch 17, Step: 916, Loss: 0.20589803159236908, Lr:0.0001\n",
      "Epoch 17, Step: 917, Loss: 0.01967509277164936, Lr:0.0001\n",
      "Epoch 17, Step: 918, Loss: 0.08298598229885101, Lr:0.0001\n",
      "Epoch 17, Step: 919, Loss: 0.033997792750597, Lr:0.0001\n",
      "Epoch 17, Step: 920, Loss: 0.08997785300016403, Lr:0.0001\n",
      "Epoch 17, Step: 921, Loss: 0.037120271474123, Lr:0.0001\n",
      "Epoch 17, Step: 922, Loss: 0.20489221811294556, Lr:0.0001\n",
      "Epoch 17, Step: 923, Loss: 0.05738450959324837, Lr:0.0001\n",
      "Epoch 17, Step: 924, Loss: 0.10613196343183517, Lr:0.0001\n",
      "Epoch 17, Step: 925, Loss: 0.028312576934695244, Lr:0.0001\n",
      "Epoch 17, Step: 926, Loss: 0.07399590313434601, Lr:0.0001\n",
      "Epoch 17, Step: 927, Loss: 0.03311461955308914, Lr:0.0001\n",
      "Epoch 17, Step: 928, Loss: 0.018297329545021057, Lr:0.0001\n",
      "Epoch 17, Step: 929, Loss: 0.1125323623418808, Lr:0.0001\n",
      "Epoch 17, Step: 930, Loss: 0.4214993119239807, Lr:0.0001\n",
      "Epoch 17, Step: 931, Loss: 0.021357251331210136, Lr:0.0001\n",
      "Epoch 17, Step: 932, Loss: 0.17370034754276276, Lr:0.0001\n",
      "Epoch 17, Step: 933, Loss: 0.2025996893644333, Lr:0.0001\n",
      "Epoch 17, Step: 934, Loss: 0.15326519310474396, Lr:0.0001\n",
      "Epoch 17, Step: 935, Loss: 0.04565652832388878, Lr:0.0001\n",
      "Epoch 17, Step: 936, Loss: 0.0010810851817950606, Lr:0.0001\n",
      "Epoch 17, Step: 937, Loss: 0.03267808258533478, Lr:0.0001\n",
      "Epoch 17, Step: 938, Loss: 0.18578612804412842, Lr:0.0001\n",
      "Epoch 17, Step: 939, Loss: 0.24559564888477325, Lr:0.0001\n",
      "Epoch 17, Step: 940, Loss: 0.12070579826831818, Lr:0.0001\n",
      "Epoch 17, Step: 941, Loss: 0.09051069617271423, Lr:0.0001\n",
      "Epoch 17, Step: 942, Loss: 0.050185468047857285, Lr:0.0001\n",
      "Epoch 17, Step: 943, Loss: 0.15707792341709137, Lr:0.0001\n",
      "Epoch 17, Step: 944, Loss: 0.0076540382578969, Lr:0.0001\n",
      "Epoch 17, Step: 945, Loss: 0.1117931678891182, Lr:0.0001\n",
      "Epoch 17, Step: 946, Loss: 0.11854859441518784, Lr:0.0001\n",
      "Epoch 17, Step: 947, Loss: 0.04902336001396179, Lr:0.0001\n",
      "Epoch 17, Step: 948, Loss: 0.14090684056282043, Lr:0.0001\n",
      "Epoch 17, Step: 949, Loss: 0.2858961820602417, Lr:0.0001\n",
      "Epoch 17, Step: 950, Loss: 0.3510070741176605, Lr:0.0001\n",
      "Epoch 17, Step: 951, Loss: 0.04698493704199791, Lr:0.0001\n",
      "Epoch 17, Step: 952, Loss: 0.1303102970123291, Lr:0.0001\n",
      "Epoch 17, Step: 953, Loss: 0.11897187680006027, Lr:0.0001\n",
      "Epoch 17, Step: 954, Loss: 0.058598581701517105, Lr:0.0001\n",
      "Epoch 17, Step: 955, Loss: 0.08309249579906464, Lr:0.0001\n",
      "Epoch 17, Step: 956, Loss: 0.14924278855323792, Lr:0.0001\n",
      "Epoch 17, Step: 957, Loss: 0.07343989610671997, Lr:0.0001\n",
      "Epoch 17, Step: 958, Loss: 0.01504167914390564, Lr:0.0001\n",
      "Epoch 17, Step: 959, Loss: 0.027371687814593315, Lr:0.0001\n",
      "Epoch 17, Step: 960, Loss: 0.01755143329501152, Lr:0.0001\n",
      "Epoch 17, Step: 961, Loss: 0.04722665250301361, Lr:0.0001\n",
      "Epoch 17, Step: 962, Loss: 0.060117099434137344, Lr:0.0001\n",
      "Epoch 17, Step: 963, Loss: 0.24106521904468536, Lr:0.0001\n",
      "Epoch 17, Step: 964, Loss: 0.11865893006324768, Lr:0.0001\n",
      "Epoch 17, Step: 965, Loss: 0.024936050176620483, Lr:0.0001\n",
      "Epoch 17, Step: 966, Loss: 0.050936516374349594, Lr:0.0001\n",
      "Epoch 17, Step: 967, Loss: 0.02622121386229992, Lr:0.0001\n",
      "Epoch 17, Step: 968, Loss: 0.018133483827114105, Lr:0.0001\n",
      "Epoch 17, Step: 969, Loss: 0.06832444667816162, Lr:0.0001\n",
      "Epoch 17, Step: 970, Loss: 0.016400029882788658, Lr:0.0001\n",
      "Epoch 17, Step: 971, Loss: 0.010792572982609272, Lr:0.0001\n",
      "Epoch 17, Step: 972, Loss: 0.29470294713974, Lr:0.0001\n",
      "Epoch 17, Step: 973, Loss: 0.06902355700731277, Lr:0.0001\n",
      "Epoch 17, Step: 974, Loss: 0.010005036368966103, Lr:0.0001\n",
      "Epoch 17, Step: 975, Loss: 0.3919235169887543, Lr:0.0001\n",
      "Epoch 17, Step: 976, Loss: 0.15712428092956543, Lr:0.0001\n",
      "Epoch 17, Step: 977, Loss: 0.0804252028465271, Lr:0.0001\n",
      "Epoch 17, Step: 978, Loss: 0.12183944880962372, Lr:0.0001\n",
      "Epoch 17, Step: 979, Loss: 0.051389433443546295, Lr:0.0001\n",
      "Epoch 17, Step: 980, Loss: 0.43534040451049805, Lr:0.0001\n",
      "Epoch 17, Step: 981, Loss: 0.03089052066206932, Lr:0.0001\n",
      "Epoch 17, Step: 982, Loss: 0.0811290442943573, Lr:0.0001\n",
      "Epoch 17, Step: 983, Loss: 0.21956148743629456, Lr:0.0001\n",
      "Epoch 17, Step: 984, Loss: 0.09379182755947113, Lr:0.0001\n",
      "Epoch 17, Step: 985, Loss: 0.06721363216638565, Lr:0.0001\n",
      "Epoch 17, Step: 986, Loss: 0.21864467859268188, Lr:0.0001\n",
      "Epoch 17, Step: 987, Loss: 0.14368821680545807, Lr:0.0001\n",
      "Epoch 17, Step: 988, Loss: 0.050502292811870575, Lr:0.0001\n",
      "Epoch 17, Step: 989, Loss: 0.08736542612314224, Lr:0.0001\n",
      "Epoch 17, Step: 990, Loss: 0.0453946515917778, Lr:0.0001\n",
      "Epoch 17, Step: 991, Loss: 0.03131629899144173, Lr:0.0001\n",
      "Epoch 17, Step: 992, Loss: 0.032763127237558365, Lr:0.0001\n",
      "Epoch 17, Step: 993, Loss: 0.2826343774795532, Lr:0.0001\n",
      "Epoch 17, Step: 994, Loss: 0.029144518077373505, Lr:0.0001\n",
      "Epoch 17, Step: 995, Loss: 0.0242953822016716, Lr:0.0001\n",
      "Epoch 17, Step: 996, Loss: 0.01208183728158474, Lr:0.0001\n",
      "Epoch 17, Step: 997, Loss: 0.029944270849227905, Lr:0.0001\n",
      "Epoch 17, Step: 998, Loss: 0.10403428971767426, Lr:0.0001\n",
      "Epoch 17, Step: 999, Loss: 0.010043423622846603, Lr:0.0001\n",
      "Epoch 17, Step: 1000, Loss: 0.14059793949127197, Lr:0.0001\n",
      "Epoch 17, Step: 1001, Loss: 0.010446487925946712, Lr:0.0001\n",
      "Epoch 17, Step: 1002, Loss: 0.07785649597644806, Lr:0.0001\n",
      "Epoch 17, Step: 1003, Loss: 0.19034531712532043, Lr:0.0001\n",
      "Epoch 17, Step: 1004, Loss: 0.08075882494449615, Lr:0.0001\n",
      "Epoch 17, Step: 1005, Loss: 0.03805937245488167, Lr:0.0001\n",
      "Epoch 17, Step: 1006, Loss: 0.1686972826719284, Lr:0.0001\n",
      "Epoch 17, Step: 1007, Loss: 0.02945614978671074, Lr:0.0001\n",
      "Epoch 17, Step: 1008, Loss: 0.14902029931545258, Lr:0.0001\n",
      "Epoch 17, Step: 1009, Loss: 0.16659757494926453, Lr:0.0001\n",
      "Epoch 17, Step: 1010, Loss: 0.08382605761289597, Lr:0.0001\n",
      "Epoch 17, Step: 1011, Loss: 0.03615773841738701, Lr:0.0001\n",
      "Epoch 17, Step: 1012, Loss: 0.055619511753320694, Lr:0.0001\n",
      "Epoch 17, Step: 1013, Loss: 0.054227299988269806, Lr:0.0001\n",
      "Epoch 17, Step: 1014, Loss: 0.17924699187278748, Lr:0.0001\n",
      "Epoch 17, Step: 1015, Loss: 0.025578573346138, Lr:0.0001\n",
      "Epoch 17, Step: 1016, Loss: 0.031150460243225098, Lr:0.0001\n",
      "Epoch 17, Step: 1017, Loss: 0.147067591547966, Lr:0.0001\n",
      "Epoch 17, Step: 1018, Loss: 0.035957399755716324, Lr:0.0001\n",
      "Epoch 17, Step: 1019, Loss: 0.09804878383874893, Lr:0.0001\n",
      "Epoch 17, Step: 1020, Loss: 0.030110342428088188, Lr:0.0001\n",
      "Epoch 17, Step: 1021, Loss: 0.03888368979096413, Lr:0.0001\n",
      "Epoch 17, Step: 1022, Loss: 0.03815079107880592, Lr:0.0001\n",
      "Epoch 17, Step: 1023, Loss: 0.10231415182352066, Lr:0.0001\n",
      "Epoch 17, Step: 1024, Loss: 0.06436415016651154, Lr:0.0001\n",
      "Epoch 17, Step: 1025, Loss: 0.12497299164533615, Lr:0.0001\n",
      "Epoch 17, Step: 1026, Loss: 0.05703870952129364, Lr:0.0001\n",
      "Epoch 17, Step: 1027, Loss: 0.08688186854124069, Lr:0.0001\n",
      "Epoch 17, Step: 1028, Loss: 0.06275758892297745, Lr:0.0001\n",
      "Epoch 17, Step: 1029, Loss: 0.18821828067302704, Lr:0.0001\n",
      "Epoch 17, Step: 1030, Loss: 0.12961795926094055, Lr:0.0001\n",
      "Epoch 17, Step: 1031, Loss: 0.01269013062119484, Lr:0.0001\n",
      "Epoch 17, Step: 1032, Loss: 0.010564569383859634, Lr:0.0001\n",
      "Epoch 17, Step: 1033, Loss: 0.06319863349199295, Lr:0.0001\n",
      "Epoch 17, Step: 1034, Loss: 0.05182000249624252, Lr:0.0001\n",
      "Epoch 17, Step: 1035, Loss: 0.08399304747581482, Lr:0.0001\n",
      "Epoch 17, Step: 1036, Loss: 0.14851060509681702, Lr:0.0001\n",
      "Epoch 17, Step: 1037, Loss: 0.1577756404876709, Lr:0.0001\n",
      "Epoch 17, Step: 1038, Loss: 0.022641360759735107, Lr:0.0001\n",
      "Epoch 17, Step: 1039, Loss: 0.022044382989406586, Lr:0.0001\n",
      "Epoch 17, Step: 1040, Loss: 0.27916818857192993, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 17\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:15 loss: 0.9351 (0.9351) acc1: 81.2500 (81.2500) acc5: 100.0000 (100.0000) time: 0.2750 data: 0.1080 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:12 loss: 0.0032 (0.1103) acc1: 100.0000 (97.1591) acc5: 100.0000 (100.0000) time: 0.2812 data: 0.1086 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0092 (0.0962) acc1: 100.0000 (96.7262) acc5: 100.0000 (100.0000) time: 0.2825 data: 0.1088 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.0969 (0.1265) acc1: 93.7500 (95.1613) acc5: 100.0000 (100.0000) time: 0.2836 data: 0.1095 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.0990 (0.1302) acc1: 93.7500 (94.6646) acc5: 100.0000 (100.0000) time: 0.2844 data: 0.1105 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.1575 (0.1623) acc1: 93.7500 (93.6275) acc5: 100.0000 (100.0000) time: 0.2872 data: 0.1122 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.1575 (0.2024) acc1: 93.7500 (93.0760) acc5: 100.0000 (100.0000) time: 0.2761 data: 0.1075 max mem: 15137\n",
      "Test: Total time: 0:00:15 (0.2806 s / it)\n",
      "* Acc@1 93.076 Acc@5 100.000 loss 0.202\n",
      "Accuracy of the network on the 881 test image: 93.1%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 18, Step: 0, Loss: 0.06557348370552063, Lr:0.0001\n",
      "Epoch 18, Step: 1, Loss: 0.1612495332956314, Lr:0.0001\n",
      "Epoch 18, Step: 2, Loss: 0.038076337426900864, Lr:0.0001\n",
      "Epoch 18, Step: 3, Loss: 0.15226562321186066, Lr:0.0001\n",
      "Epoch 18, Step: 4, Loss: 0.07401107996702194, Lr:0.0001\n",
      "Epoch 18, Step: 5, Loss: 0.012939808890223503, Lr:0.0001\n",
      "Epoch 18, Step: 6, Loss: 0.056569937616586685, Lr:0.0001\n",
      "Epoch 18, Step: 7, Loss: 0.03879887983202934, Lr:0.0001\n",
      "Epoch 18, Step: 8, Loss: 0.12681666016578674, Lr:0.0001\n",
      "Epoch 18, Step: 9, Loss: 0.19440416991710663, Lr:0.0001\n",
      "Epoch 18, Step: 10, Loss: 0.05764058232307434, Lr:0.0001\n",
      "Epoch 18, Step: 11, Loss: 0.06804805248975754, Lr:0.0001\n",
      "Epoch 18, Step: 12, Loss: 0.027461864054203033, Lr:0.0001\n",
      "Epoch 18, Step: 13, Loss: 0.22469930350780487, Lr:0.0001\n",
      "Epoch 18, Step: 14, Loss: 0.19288772344589233, Lr:0.0001\n",
      "Epoch 18, Step: 15, Loss: 0.0058184233494102955, Lr:0.0001\n",
      "Epoch 18, Step: 16, Loss: 0.11767198890447617, Lr:0.0001\n",
      "Epoch 18, Step: 17, Loss: 0.1708041876554489, Lr:0.0001\n",
      "Epoch 18, Step: 18, Loss: 0.05336081236600876, Lr:0.0001\n",
      "Epoch 18, Step: 19, Loss: 0.07500316202640533, Lr:0.0001\n",
      "Epoch 18, Step: 20, Loss: 0.09950661659240723, Lr:0.0001\n",
      "Epoch 18, Step: 21, Loss: 0.2440601885318756, Lr:0.0001\n",
      "Epoch 18, Step: 22, Loss: 0.04426414892077446, Lr:0.0001\n",
      "Epoch 18, Step: 23, Loss: 0.03336073085665703, Lr:0.0001\n",
      "Epoch 18, Step: 24, Loss: 0.030174143612384796, Lr:0.0001\n",
      "Epoch 18, Step: 25, Loss: 0.08384370058774948, Lr:0.0001\n",
      "Epoch 18, Step: 26, Loss: 0.1380050778388977, Lr:0.0001\n",
      "Epoch 18, Step: 27, Loss: 0.12213306874036789, Lr:0.0001\n",
      "Epoch 18, Step: 28, Loss: 0.12133163213729858, Lr:0.0001\n",
      "Epoch 18, Step: 29, Loss: 0.04368608072400093, Lr:0.0001\n",
      "Epoch 18, Step: 30, Loss: 0.09930373728275299, Lr:0.0001\n",
      "Epoch 18, Step: 31, Loss: 0.09997782111167908, Lr:0.0001\n",
      "Epoch 18, Step: 32, Loss: 0.13366076350212097, Lr:0.0001\n",
      "Epoch 18, Step: 33, Loss: 0.2837827503681183, Lr:0.0001\n",
      "Epoch 18, Step: 34, Loss: 0.056774239987134933, Lr:0.0001\n",
      "Epoch 18, Step: 35, Loss: 0.06811121106147766, Lr:0.0001\n",
      "Epoch 18, Step: 36, Loss: 0.07901737838983536, Lr:0.0001\n",
      "Epoch 18, Step: 37, Loss: 0.005926500540226698, Lr:0.0001\n",
      "Epoch 18, Step: 38, Loss: 0.0024011435452848673, Lr:0.0001\n",
      "Epoch 18, Step: 39, Loss: 0.05721481889486313, Lr:0.0001\n",
      "Epoch 18, Step: 40, Loss: 0.011746197938919067, Lr:0.0001\n",
      "Epoch 18, Step: 41, Loss: 0.12540026009082794, Lr:0.0001\n",
      "Epoch 18, Step: 42, Loss: 0.2435711920261383, Lr:0.0001\n",
      "Epoch 18, Step: 43, Loss: 0.2081999033689499, Lr:0.0001\n",
      "Epoch 18, Step: 44, Loss: 0.13101749122142792, Lr:0.0001\n",
      "Epoch 18, Step: 45, Loss: 0.02964768186211586, Lr:0.0001\n",
      "Epoch 18, Step: 46, Loss: 0.06417024880647659, Lr:0.0001\n",
      "Epoch 18, Step: 47, Loss: 0.08377909660339355, Lr:0.0001\n",
      "Epoch 18, Step: 48, Loss: 0.04555715620517731, Lr:0.0001\n",
      "Epoch 18, Step: 49, Loss: 0.017519338056445122, Lr:0.0001\n",
      "Epoch 18, Step: 50, Loss: 0.0071960934437811375, Lr:0.0001\n",
      "Epoch 18, Step: 51, Loss: 0.1962968409061432, Lr:0.0001\n",
      "Epoch 18, Step: 52, Loss: 0.04110819846391678, Lr:0.0001\n",
      "Epoch 18, Step: 53, Loss: 0.01529734954237938, Lr:0.0001\n",
      "Epoch 18, Step: 54, Loss: 0.005275541916489601, Lr:0.0001\n",
      "Epoch 18, Step: 55, Loss: 0.026031631976366043, Lr:0.0001\n",
      "Epoch 18, Step: 56, Loss: 0.006444050930440426, Lr:0.0001\n",
      "Epoch 18, Step: 57, Loss: 0.13913680613040924, Lr:0.0001\n",
      "Epoch 18, Step: 58, Loss: 0.06277446448802948, Lr:0.0001\n",
      "Epoch 18, Step: 59, Loss: 0.2844136655330658, Lr:0.0001\n",
      "Epoch 18, Step: 60, Loss: 0.3297097384929657, Lr:0.0001\n",
      "Epoch 18, Step: 61, Loss: 0.013692270033061504, Lr:0.0001\n",
      "Epoch 18, Step: 62, Loss: 0.039822667837142944, Lr:0.0001\n",
      "Epoch 18, Step: 63, Loss: 0.02663406915962696, Lr:0.0001\n",
      "Epoch 18, Step: 64, Loss: 0.08310652524232864, Lr:0.0001\n",
      "Epoch 18, Step: 65, Loss: 0.04743427038192749, Lr:0.0001\n",
      "Epoch 18, Step: 66, Loss: 0.21348775923252106, Lr:0.0001\n",
      "Epoch 18, Step: 67, Loss: 0.08764291554689407, Lr:0.0001\n",
      "Epoch 18, Step: 68, Loss: 0.03495955467224121, Lr:0.0001\n",
      "Epoch 18, Step: 69, Loss: 0.05607135593891144, Lr:0.0001\n",
      "Epoch 18, Step: 70, Loss: 0.1239507868885994, Lr:0.0001\n",
      "Epoch 18, Step: 71, Loss: 0.1591331511735916, Lr:0.0001\n",
      "Epoch 18, Step: 72, Loss: 0.0869920551776886, Lr:0.0001\n",
      "Epoch 18, Step: 73, Loss: 0.024019794538617134, Lr:0.0001\n",
      "Epoch 18, Step: 74, Loss: 0.037976425141096115, Lr:0.0001\n",
      "Epoch 18, Step: 75, Loss: 0.08800908923149109, Lr:0.0001\n",
      "Epoch 18, Step: 76, Loss: 0.04336687549948692, Lr:0.0001\n",
      "Epoch 18, Step: 77, Loss: 0.17462104558944702, Lr:0.0001\n",
      "Epoch 18, Step: 78, Loss: 0.08332964777946472, Lr:0.0001\n",
      "Epoch 18, Step: 79, Loss: 0.02264237403869629, Lr:0.0001\n",
      "Epoch 18, Step: 80, Loss: 0.010956096462905407, Lr:0.0001\n",
      "Epoch 18, Step: 81, Loss: 0.2935074269771576, Lr:0.0001\n",
      "Epoch 18, Step: 82, Loss: 0.2325890213251114, Lr:0.0001\n",
      "Epoch 18, Step: 83, Loss: 0.1318265050649643, Lr:0.0001\n",
      "Epoch 18, Step: 84, Loss: 0.02698245644569397, Lr:0.0001\n",
      "Epoch 18, Step: 85, Loss: 0.06212327256798744, Lr:0.0001\n",
      "Epoch 18, Step: 86, Loss: 0.0029139695689082146, Lr:0.0001\n",
      "Epoch 18, Step: 87, Loss: 0.1390523463487625, Lr:0.0001\n",
      "Epoch 18, Step: 88, Loss: 0.0466294027864933, Lr:0.0001\n",
      "Epoch 18, Step: 89, Loss: 0.14933738112449646, Lr:0.0001\n",
      "Epoch 18, Step: 90, Loss: 0.11936768889427185, Lr:0.0001\n",
      "Epoch 18, Step: 91, Loss: 0.08822524547576904, Lr:0.0001\n",
      "Epoch 18, Step: 92, Loss: 0.05987204983830452, Lr:0.0001\n",
      "Epoch 18, Step: 93, Loss: 0.05444926768541336, Lr:0.0001\n",
      "Epoch 18, Step: 94, Loss: 0.23932133615016937, Lr:0.0001\n",
      "Epoch 18, Step: 95, Loss: 0.12666001915931702, Lr:0.0001\n",
      "Epoch 18, Step: 96, Loss: 0.0475231409072876, Lr:0.0001\n",
      "Epoch 18, Step: 97, Loss: 0.22228121757507324, Lr:0.0001\n",
      "Epoch 18, Step: 98, Loss: 0.14758232235908508, Lr:0.0001\n",
      "Epoch 18, Step: 99, Loss: 0.06427884846925735, Lr:0.0001\n",
      "Epoch 18, Step: 100, Loss: 0.05592356249690056, Lr:0.0001\n",
      "Epoch 18, Step: 101, Loss: 0.15360663831233978, Lr:0.0001\n",
      "Epoch 18, Step: 102, Loss: 0.0806950032711029, Lr:0.0001\n",
      "Epoch 18, Step: 103, Loss: 0.09434506297111511, Lr:0.0001\n",
      "Epoch 18, Step: 104, Loss: 0.07961279898881912, Lr:0.0001\n",
      "Epoch 18, Step: 105, Loss: 0.1734185665845871, Lr:0.0001\n",
      "Epoch 18, Step: 106, Loss: 0.03641190379858017, Lr:0.0001\n",
      "Epoch 18, Step: 107, Loss: 0.06491678208112717, Lr:0.0001\n",
      "Epoch 18, Step: 108, Loss: 0.0266214981675148, Lr:0.0001\n",
      "Epoch 18, Step: 109, Loss: 0.06622449308633804, Lr:0.0001\n",
      "Epoch 18, Step: 110, Loss: 0.07460321485996246, Lr:0.0001\n",
      "Epoch 18, Step: 111, Loss: 0.09130126982927322, Lr:0.0001\n",
      "Epoch 18, Step: 112, Loss: 0.07986827194690704, Lr:0.0001\n",
      "Epoch 18, Step: 113, Loss: 0.012071848846971989, Lr:0.0001\n",
      "Epoch 18, Step: 114, Loss: 0.0064676785841584206, Lr:0.0001\n",
      "Epoch 18, Step: 115, Loss: 0.07514739781618118, Lr:0.0001\n",
      "Epoch 18, Step: 116, Loss: 0.0562518909573555, Lr:0.0001\n",
      "Epoch 18, Step: 117, Loss: 0.05679726228117943, Lr:0.0001\n",
      "Epoch 18, Step: 118, Loss: 0.2698551118373871, Lr:0.0001\n",
      "Epoch 18, Step: 119, Loss: 0.09171956032514572, Lr:0.0001\n",
      "Epoch 18, Step: 120, Loss: 0.027217749506235123, Lr:0.0001\n",
      "Epoch 18, Step: 121, Loss: 0.07139983773231506, Lr:0.0001\n",
      "Epoch 18, Step: 122, Loss: 0.14391504228115082, Lr:0.0001\n",
      "Epoch 18, Step: 123, Loss: 0.09008731693029404, Lr:0.0001\n",
      "Epoch 18, Step: 124, Loss: 0.23244555294513702, Lr:0.0001\n",
      "Epoch 18, Step: 125, Loss: 0.062380433082580566, Lr:0.0001\n",
      "Epoch 18, Step: 126, Loss: 0.011309307999908924, Lr:0.0001\n",
      "Epoch 18, Step: 127, Loss: 0.006307820789515972, Lr:0.0001\n",
      "Epoch 18, Step: 128, Loss: 0.03845152631402016, Lr:0.0001\n",
      "Epoch 18, Step: 129, Loss: 0.03315100818872452, Lr:0.0001\n",
      "Epoch 18, Step: 130, Loss: 0.017416585236787796, Lr:0.0001\n",
      "Epoch 18, Step: 131, Loss: 0.02106068842113018, Lr:0.0001\n",
      "Epoch 18, Step: 132, Loss: 0.05852843075990677, Lr:0.0001\n",
      "Epoch 18, Step: 133, Loss: 0.025959506630897522, Lr:0.0001\n",
      "Epoch 18, Step: 134, Loss: 0.007723569869995117, Lr:0.0001\n",
      "Epoch 18, Step: 135, Loss: 0.10766847431659698, Lr:0.0001\n",
      "Epoch 18, Step: 136, Loss: 0.029367202892899513, Lr:0.0001\n",
      "Epoch 18, Step: 137, Loss: 0.23903048038482666, Lr:0.0001\n",
      "Epoch 18, Step: 138, Loss: 0.04979727044701576, Lr:0.0001\n",
      "Epoch 18, Step: 139, Loss: 0.022878892719745636, Lr:0.0001\n",
      "Epoch 18, Step: 140, Loss: 0.05894302949309349, Lr:0.0001\n",
      "Epoch 18, Step: 141, Loss: 0.18307344615459442, Lr:0.0001\n",
      "Epoch 18, Step: 142, Loss: 0.007485959213227034, Lr:0.0001\n",
      "Epoch 18, Step: 143, Loss: 0.22113339602947235, Lr:0.0001\n",
      "Epoch 18, Step: 144, Loss: 0.010392538271844387, Lr:0.0001\n",
      "Epoch 18, Step: 145, Loss: 0.0026721558533608913, Lr:0.0001\n",
      "Epoch 18, Step: 146, Loss: 0.04478367045521736, Lr:0.0001\n",
      "Epoch 18, Step: 147, Loss: 0.007970581762492657, Lr:0.0001\n",
      "Epoch 18, Step: 148, Loss: 0.08770909905433655, Lr:0.0001\n",
      "Epoch 18, Step: 149, Loss: 0.08851786702871323, Lr:0.0001\n",
      "Epoch 18, Step: 150, Loss: 0.07502999901771545, Lr:0.0001\n",
      "Epoch 18, Step: 151, Loss: 0.0638977661728859, Lr:0.0001\n",
      "Epoch 18, Step: 152, Loss: 0.005674940999597311, Lr:0.0001\n",
      "Epoch 18, Step: 153, Loss: 0.03422961011528969, Lr:0.0001\n",
      "Epoch 18, Step: 154, Loss: 0.14942879974842072, Lr:0.0001\n",
      "Epoch 18, Step: 155, Loss: 0.030388925224542618, Lr:0.0001\n",
      "Epoch 18, Step: 156, Loss: 0.15226617455482483, Lr:0.0001\n",
      "Epoch 18, Step: 157, Loss: 0.015483655966818333, Lr:0.0001\n",
      "Epoch 18, Step: 158, Loss: 0.15764570236206055, Lr:0.0001\n",
      "Epoch 18, Step: 159, Loss: 0.007669211830943823, Lr:0.0001\n",
      "Epoch 18, Step: 160, Loss: 0.0031095955055207014, Lr:0.0001\n",
      "Epoch 18, Step: 161, Loss: 0.009874722920358181, Lr:0.0001\n",
      "Epoch 18, Step: 162, Loss: 0.019908413290977478, Lr:0.0001\n",
      "Epoch 18, Step: 163, Loss: 0.17852339148521423, Lr:0.0001\n",
      "Epoch 18, Step: 164, Loss: 0.013692019507288933, Lr:0.0001\n",
      "Epoch 18, Step: 165, Loss: 0.03944001346826553, Lr:0.0001\n",
      "Epoch 18, Step: 166, Loss: 0.04284714162349701, Lr:0.0001\n",
      "Epoch 18, Step: 167, Loss: 0.04177819937467575, Lr:0.0001\n",
      "Epoch 18, Step: 168, Loss: 0.08038635551929474, Lr:0.0001\n",
      "Epoch 18, Step: 169, Loss: 0.37524786591529846, Lr:0.0001\n",
      "Epoch 18, Step: 170, Loss: 0.16713261604309082, Lr:0.0001\n",
      "Epoch 18, Step: 171, Loss: 0.02060001902282238, Lr:0.0001\n",
      "Epoch 18, Step: 172, Loss: 0.012665930204093456, Lr:0.0001\n",
      "Epoch 18, Step: 173, Loss: 0.04434657841920853, Lr:0.0001\n",
      "Epoch 18, Step: 174, Loss: 0.01838083006441593, Lr:0.0001\n",
      "Epoch 18, Step: 175, Loss: 0.04150417819619179, Lr:0.0001\n",
      "Epoch 18, Step: 176, Loss: 0.12922391295433044, Lr:0.0001\n",
      "Epoch 18, Step: 177, Loss: 0.22663605213165283, Lr:0.0001\n",
      "Epoch 18, Step: 178, Loss: 0.01953164115548134, Lr:0.0001\n",
      "Epoch 18, Step: 179, Loss: 0.025899751111865044, Lr:0.0001\n",
      "Epoch 18, Step: 180, Loss: 0.243499293923378, Lr:0.0001\n",
      "Epoch 18, Step: 181, Loss: 0.013500834815204144, Lr:0.0001\n",
      "Epoch 18, Step: 182, Loss: 0.012108289636671543, Lr:0.0001\n",
      "Epoch 18, Step: 183, Loss: 0.10994453728199005, Lr:0.0001\n",
      "Epoch 18, Step: 184, Loss: 0.07169213145971298, Lr:0.0001\n",
      "Epoch 18, Step: 185, Loss: 0.042888764292001724, Lr:0.0001\n",
      "Epoch 18, Step: 186, Loss: 0.013747069053351879, Lr:0.0001\n",
      "Epoch 18, Step: 187, Loss: 0.3358880281448364, Lr:0.0001\n",
      "Epoch 18, Step: 188, Loss: 0.18136797845363617, Lr:0.0001\n",
      "Epoch 18, Step: 189, Loss: 0.026651281863451004, Lr:0.0001\n",
      "Epoch 18, Step: 190, Loss: 0.02287093922495842, Lr:0.0001\n",
      "Epoch 18, Step: 191, Loss: 0.24934762716293335, Lr:0.0001\n",
      "Epoch 18, Step: 192, Loss: 0.06322910636663437, Lr:0.0001\n",
      "Epoch 18, Step: 193, Loss: 0.021205317229032516, Lr:0.0001\n",
      "Epoch 18, Step: 194, Loss: 0.027724048122763634, Lr:0.0001\n",
      "Epoch 18, Step: 195, Loss: 0.028215421363711357, Lr:0.0001\n",
      "Epoch 18, Step: 196, Loss: 0.6702520251274109, Lr:0.0001\n",
      "Epoch 18, Step: 197, Loss: 0.05311913043260574, Lr:0.0001\n",
      "Epoch 18, Step: 198, Loss: 0.09920593351125717, Lr:0.0001\n",
      "Epoch 18, Step: 199, Loss: 0.032892242074012756, Lr:0.0001\n",
      "Epoch 18, Step: 200, Loss: 0.024717584252357483, Lr:0.0001\n",
      "Epoch 18, Step: 201, Loss: 0.041824039071798325, Lr:0.0001\n",
      "Epoch 18, Step: 202, Loss: 0.01578732766211033, Lr:0.0001\n",
      "Epoch 18, Step: 203, Loss: 0.24827177822589874, Lr:0.0001\n",
      "Epoch 18, Step: 204, Loss: 0.023823928087949753, Lr:0.0001\n",
      "Epoch 18, Step: 205, Loss: 0.06698580086231232, Lr:0.0001\n",
      "Epoch 18, Step: 206, Loss: 0.1820407658815384, Lr:0.0001\n",
      "Epoch 18, Step: 207, Loss: 0.09093360602855682, Lr:0.0001\n",
      "Epoch 18, Step: 208, Loss: 0.030599497258663177, Lr:0.0001\n",
      "Epoch 18, Step: 209, Loss: 0.06901232898235321, Lr:0.0001\n",
      "Epoch 18, Step: 210, Loss: 0.23125122487545013, Lr:0.0001\n",
      "Epoch 18, Step: 211, Loss: 0.008876391686499119, Lr:0.0001\n",
      "Epoch 18, Step: 212, Loss: 0.09803343564271927, Lr:0.0001\n",
      "Epoch 18, Step: 213, Loss: 0.050668567419052124, Lr:0.0001\n",
      "Epoch 18, Step: 214, Loss: 0.15370477735996246, Lr:0.0001\n",
      "Epoch 18, Step: 215, Loss: 0.1478291004896164, Lr:0.0001\n",
      "Epoch 18, Step: 216, Loss: 0.06147147715091705, Lr:0.0001\n",
      "Epoch 18, Step: 217, Loss: 0.0444033220410347, Lr:0.0001\n",
      "Epoch 18, Step: 218, Loss: 0.05086643248796463, Lr:0.0001\n",
      "Epoch 18, Step: 219, Loss: 0.013652749359607697, Lr:0.0001\n",
      "Epoch 18, Step: 220, Loss: 0.1890973597764969, Lr:0.0001\n",
      "Epoch 18, Step: 221, Loss: 0.09950576722621918, Lr:0.0001\n",
      "Epoch 18, Step: 222, Loss: 0.024382207542657852, Lr:0.0001\n",
      "Epoch 18, Step: 223, Loss: 0.01613885536789894, Lr:0.0001\n",
      "Epoch 18, Step: 224, Loss: 0.16899636387825012, Lr:0.0001\n",
      "Epoch 18, Step: 225, Loss: 0.03507230058312416, Lr:0.0001\n",
      "Epoch 18, Step: 226, Loss: 0.02963116765022278, Lr:0.0001\n",
      "Epoch 18, Step: 227, Loss: 0.07779133319854736, Lr:0.0001\n",
      "Epoch 18, Step: 228, Loss: 0.19343261420726776, Lr:0.0001\n",
      "Epoch 18, Step: 229, Loss: 0.07350868731737137, Lr:0.0001\n",
      "Epoch 18, Step: 230, Loss: 0.047614872455596924, Lr:0.0001\n",
      "Epoch 18, Step: 231, Loss: 0.009144758805632591, Lr:0.0001\n",
      "Epoch 18, Step: 232, Loss: 0.027370063588023186, Lr:0.0001\n",
      "Epoch 18, Step: 233, Loss: 0.02416054531931877, Lr:0.0001\n",
      "Epoch 18, Step: 234, Loss: 0.0026626535691320896, Lr:0.0001\n",
      "Epoch 18, Step: 235, Loss: 0.06569088995456696, Lr:0.0001\n",
      "Epoch 18, Step: 236, Loss: 0.11001254618167877, Lr:0.0001\n",
      "Epoch 18, Step: 237, Loss: 0.045351892709732056, Lr:0.0001\n",
      "Epoch 18, Step: 238, Loss: 0.025900254026055336, Lr:0.0001\n",
      "Epoch 18, Step: 239, Loss: 0.02717418596148491, Lr:0.0001\n",
      "Epoch 18, Step: 240, Loss: 0.21838214993476868, Lr:0.0001\n",
      "Epoch 18, Step: 241, Loss: 0.15924423933029175, Lr:0.0001\n",
      "Epoch 18, Step: 242, Loss: 0.028983496129512787, Lr:0.0001\n",
      "Epoch 18, Step: 243, Loss: 0.010473414324223995, Lr:0.0001\n",
      "Epoch 18, Step: 244, Loss: 0.12659654021263123, Lr:0.0001\n",
      "Epoch 18, Step: 245, Loss: 0.03590502217411995, Lr:0.0001\n",
      "Epoch 18, Step: 246, Loss: 0.040634553879499435, Lr:0.0001\n",
      "Epoch 18, Step: 247, Loss: 0.03680141270160675, Lr:0.0001\n",
      "Epoch 18, Step: 248, Loss: 0.060303084552288055, Lr:0.0001\n",
      "Epoch 18, Step: 249, Loss: 0.09075219929218292, Lr:0.0001\n",
      "Epoch 18, Step: 250, Loss: 0.08446430414915085, Lr:0.0001\n",
      "Epoch 18, Step: 251, Loss: 0.25496000051498413, Lr:0.0001\n",
      "Epoch 18, Step: 252, Loss: 0.06895008683204651, Lr:0.0001\n",
      "Epoch 18, Step: 253, Loss: 0.27011510729789734, Lr:0.0001\n",
      "Epoch 18, Step: 254, Loss: 0.03798505291342735, Lr:0.0001\n",
      "Epoch 18, Step: 255, Loss: 0.12136183679103851, Lr:0.0001\n",
      "Epoch 18, Step: 256, Loss: 0.03748024255037308, Lr:0.0001\n",
      "Epoch 18, Step: 257, Loss: 0.016031136736273766, Lr:0.0001\n",
      "Epoch 18, Step: 258, Loss: 0.08109882473945618, Lr:0.0001\n",
      "Epoch 18, Step: 259, Loss: 0.059985216706991196, Lr:0.0001\n",
      "Epoch 18, Step: 260, Loss: 0.10800587385892868, Lr:0.0001\n",
      "Epoch 18, Step: 261, Loss: 0.12134766578674316, Lr:0.0001\n",
      "Epoch 18, Step: 262, Loss: 0.038451626896858215, Lr:0.0001\n",
      "Epoch 18, Step: 263, Loss: 0.20331861078739166, Lr:0.0001\n",
      "Epoch 18, Step: 264, Loss: 0.01683715544641018, Lr:0.0001\n",
      "Epoch 18, Step: 265, Loss: 0.029542600736021996, Lr:0.0001\n",
      "Epoch 18, Step: 266, Loss: 0.052662283182144165, Lr:0.0001\n",
      "Epoch 18, Step: 267, Loss: 0.016969731077551842, Lr:0.0001\n",
      "Epoch 18, Step: 268, Loss: 0.012570672668516636, Lr:0.0001\n",
      "Epoch 18, Step: 269, Loss: 0.01096370816230774, Lr:0.0001\n",
      "Epoch 18, Step: 270, Loss: 0.009043608792126179, Lr:0.0001\n",
      "Epoch 18, Step: 271, Loss: 0.16635233163833618, Lr:0.0001\n",
      "Epoch 18, Step: 272, Loss: 0.06707662343978882, Lr:0.0001\n",
      "Epoch 18, Step: 273, Loss: 0.03579855337738991, Lr:0.0001\n",
      "Epoch 18, Step: 274, Loss: 0.01538010872900486, Lr:0.0001\n",
      "Epoch 18, Step: 275, Loss: 0.06814267486333847, Lr:0.0001\n",
      "Epoch 18, Step: 276, Loss: 0.01948137767612934, Lr:0.0001\n",
      "Epoch 18, Step: 277, Loss: 0.3190634846687317, Lr:0.0001\n",
      "Epoch 18, Step: 278, Loss: 0.02680937573313713, Lr:0.0001\n",
      "Epoch 18, Step: 279, Loss: 0.2928396165370941, Lr:0.0001\n",
      "Epoch 18, Step: 280, Loss: 0.09813883155584335, Lr:0.0001\n",
      "Epoch 18, Step: 281, Loss: 0.016821248456835747, Lr:0.0001\n",
      "Epoch 18, Step: 282, Loss: 0.11560456454753876, Lr:0.0001\n",
      "Epoch 18, Step: 283, Loss: 0.04380158707499504, Lr:0.0001\n",
      "Epoch 18, Step: 284, Loss: 0.0038360983598977327, Lr:0.0001\n",
      "Epoch 18, Step: 285, Loss: 0.09294858574867249, Lr:0.0001\n",
      "Epoch 18, Step: 286, Loss: 0.016321051865816116, Lr:0.0001\n",
      "Epoch 18, Step: 287, Loss: 0.04565943777561188, Lr:0.0001\n",
      "Epoch 18, Step: 288, Loss: 0.009327318519353867, Lr:0.0001\n",
      "Epoch 18, Step: 289, Loss: 0.04258633404970169, Lr:0.0001\n",
      "Epoch 18, Step: 290, Loss: 0.1531287133693695, Lr:0.0001\n",
      "Epoch 18, Step: 291, Loss: 0.09902280569076538, Lr:0.0001\n",
      "Epoch 18, Step: 292, Loss: 0.07624388486146927, Lr:0.0001\n",
      "Epoch 18, Step: 293, Loss: 0.028575601056218147, Lr:0.0001\n",
      "Epoch 18, Step: 294, Loss: 0.005295769777148962, Lr:0.0001\n",
      "Epoch 18, Step: 295, Loss: 0.017606759443879128, Lr:0.0001\n",
      "Epoch 18, Step: 296, Loss: 0.10471268743276596, Lr:0.0001\n",
      "Epoch 18, Step: 297, Loss: 0.0027994257397949696, Lr:0.0001\n",
      "Epoch 18, Step: 298, Loss: 0.10316859185695648, Lr:0.0001\n",
      "Epoch 18, Step: 299, Loss: 0.10315674543380737, Lr:0.0001\n",
      "Epoch 18, Step: 300, Loss: 0.20008663833141327, Lr:0.0001\n",
      "Epoch 18, Step: 301, Loss: 0.2321019321680069, Lr:0.0001\n",
      "Epoch 18, Step: 302, Loss: 0.03350485861301422, Lr:0.0001\n",
      "Epoch 18, Step: 303, Loss: 0.30429428815841675, Lr:0.0001\n",
      "Epoch 18, Step: 304, Loss: 0.05636043846607208, Lr:0.0001\n",
      "Epoch 18, Step: 305, Loss: 0.06815950572490692, Lr:0.0001\n",
      "Epoch 18, Step: 306, Loss: 0.03775031492114067, Lr:0.0001\n",
      "Epoch 18, Step: 307, Loss: 0.19271010160446167, Lr:0.0001\n",
      "Epoch 18, Step: 308, Loss: 0.03283866122364998, Lr:0.0001\n",
      "Epoch 18, Step: 309, Loss: 0.5331071615219116, Lr:0.0001\n",
      "Epoch 18, Step: 310, Loss: 0.1892535239458084, Lr:0.0001\n",
      "Epoch 18, Step: 311, Loss: 0.17503394186496735, Lr:0.0001\n",
      "Epoch 18, Step: 312, Loss: 0.024034563452005386, Lr:0.0001\n",
      "Epoch 18, Step: 313, Loss: 0.07690168917179108, Lr:0.0001\n",
      "Epoch 18, Step: 314, Loss: 0.04380669817328453, Lr:0.0001\n",
      "Epoch 18, Step: 315, Loss: 0.2250773161649704, Lr:0.0001\n",
      "Epoch 18, Step: 316, Loss: 0.05957052856683731, Lr:0.0001\n",
      "Epoch 18, Step: 317, Loss: 0.10314658284187317, Lr:0.0001\n",
      "Epoch 18, Step: 318, Loss: 0.07366684079170227, Lr:0.0001\n",
      "Epoch 18, Step: 319, Loss: 0.2410532832145691, Lr:0.0001\n",
      "Epoch 18, Step: 320, Loss: 0.2618681788444519, Lr:0.0001\n",
      "Epoch 18, Step: 321, Loss: 0.006965462118387222, Lr:0.0001\n",
      "Epoch 18, Step: 322, Loss: 0.03277478739619255, Lr:0.0001\n",
      "Epoch 18, Step: 323, Loss: 0.0809946209192276, Lr:0.0001\n",
      "Epoch 18, Step: 324, Loss: 0.04146501421928406, Lr:0.0001\n",
      "Epoch 18, Step: 325, Loss: 0.19465462863445282, Lr:0.0001\n",
      "Epoch 18, Step: 326, Loss: 0.2798508107662201, Lr:0.0001\n",
      "Epoch 18, Step: 327, Loss: 0.032950498163700104, Lr:0.0001\n",
      "Epoch 18, Step: 328, Loss: 0.014874556101858616, Lr:0.0001\n",
      "Epoch 18, Step: 329, Loss: 0.01294071413576603, Lr:0.0001\n",
      "Epoch 18, Step: 330, Loss: 0.11067849397659302, Lr:0.0001\n",
      "Epoch 18, Step: 331, Loss: 0.03484134003520012, Lr:0.0001\n",
      "Epoch 18, Step: 332, Loss: 0.043006233870983124, Lr:0.0001\n",
      "Epoch 18, Step: 333, Loss: 0.12215721607208252, Lr:0.0001\n",
      "Epoch 18, Step: 334, Loss: 0.031118400394916534, Lr:0.0001\n",
      "Epoch 18, Step: 335, Loss: 0.3746134638786316, Lr:0.0001\n",
      "Epoch 18, Step: 336, Loss: 0.11075194180011749, Lr:0.0001\n",
      "Epoch 18, Step: 337, Loss: 0.12270330637693405, Lr:0.0001\n",
      "Epoch 18, Step: 338, Loss: 0.03667392581701279, Lr:0.0001\n",
      "Epoch 18, Step: 339, Loss: 0.06227153167128563, Lr:0.0001\n",
      "Epoch 18, Step: 340, Loss: 0.05137073993682861, Lr:0.0001\n",
      "Epoch 18, Step: 341, Loss: 0.3707062900066376, Lr:0.0001\n",
      "Epoch 18, Step: 342, Loss: 0.157576322555542, Lr:0.0001\n",
      "Epoch 18, Step: 343, Loss: 0.07146833091974258, Lr:0.0001\n",
      "Epoch 18, Step: 344, Loss: 0.043446581810712814, Lr:0.0001\n",
      "Epoch 18, Step: 345, Loss: 0.15254849195480347, Lr:0.0001\n",
      "Epoch 18, Step: 346, Loss: 0.015508729964494705, Lr:0.0001\n",
      "Epoch 18, Step: 347, Loss: 0.14458104968070984, Lr:0.0001\n",
      "Epoch 18, Step: 348, Loss: 0.1130913645029068, Lr:0.0001\n",
      "Epoch 18, Step: 349, Loss: 0.02998308464884758, Lr:0.0001\n",
      "Epoch 18, Step: 350, Loss: 0.014555145986378193, Lr:0.0001\n",
      "Epoch 18, Step: 351, Loss: 0.13398322463035583, Lr:0.0001\n",
      "Epoch 18, Step: 352, Loss: 0.03582232445478439, Lr:0.0001\n",
      "Epoch 18, Step: 353, Loss: 0.05032026767730713, Lr:0.0001\n",
      "Epoch 18, Step: 354, Loss: 0.055516622960567474, Lr:0.0001\n",
      "Epoch 18, Step: 355, Loss: 0.035007357597351074, Lr:0.0001\n",
      "Epoch 18, Step: 356, Loss: 0.08260834962129593, Lr:0.0001\n",
      "Epoch 18, Step: 357, Loss: 0.06350214779376984, Lr:0.0001\n",
      "Epoch 18, Step: 358, Loss: 0.19894659519195557, Lr:0.0001\n",
      "Epoch 18, Step: 359, Loss: 0.3429482579231262, Lr:0.0001\n",
      "Epoch 18, Step: 360, Loss: 0.00527828698977828, Lr:0.0001\n",
      "Epoch 18, Step: 361, Loss: 0.04641645401716232, Lr:0.0001\n",
      "Epoch 18, Step: 362, Loss: 0.04645736142992973, Lr:0.0001\n",
      "Epoch 18, Step: 363, Loss: 0.37087133526802063, Lr:0.0001\n",
      "Epoch 18, Step: 364, Loss: 0.03432302549481392, Lr:0.0001\n",
      "Epoch 18, Step: 365, Loss: 0.19837705790996552, Lr:0.0001\n",
      "Epoch 18, Step: 366, Loss: 0.04979341849684715, Lr:0.0001\n",
      "Epoch 18, Step: 367, Loss: 0.18453730642795563, Lr:0.0001\n",
      "Epoch 18, Step: 368, Loss: 0.2814696729183197, Lr:0.0001\n",
      "Epoch 18, Step: 369, Loss: 0.21946047246456146, Lr:0.0001\n",
      "Epoch 18, Step: 370, Loss: 0.00977050419896841, Lr:0.0001\n",
      "Epoch 18, Step: 371, Loss: 0.025780506432056427, Lr:0.0001\n",
      "Epoch 18, Step: 372, Loss: 0.040220554918050766, Lr:0.0001\n",
      "Epoch 18, Step: 373, Loss: 0.39047935605049133, Lr:0.0001\n",
      "Epoch 18, Step: 374, Loss: 0.05857319012284279, Lr:0.0001\n",
      "Epoch 18, Step: 375, Loss: 0.019310178235173225, Lr:0.0001\n",
      "Epoch 18, Step: 376, Loss: 0.0533776581287384, Lr:0.0001\n",
      "Epoch 18, Step: 377, Loss: 0.20127412676811218, Lr:0.0001\n",
      "Epoch 18, Step: 378, Loss: 0.009080871939659119, Lr:0.0001\n",
      "Epoch 18, Step: 379, Loss: 0.038526661694049835, Lr:0.0001\n",
      "Epoch 18, Step: 380, Loss: 0.014088921248912811, Lr:0.0001\n",
      "Epoch 18, Step: 381, Loss: 0.0654209554195404, Lr:0.0001\n",
      "Epoch 18, Step: 382, Loss: 0.00426202267408371, Lr:0.0001\n",
      "Epoch 18, Step: 383, Loss: 0.01583874225616455, Lr:0.0001\n",
      "Epoch 18, Step: 384, Loss: 0.041467975825071335, Lr:0.0001\n",
      "Epoch 18, Step: 385, Loss: 0.03967396914958954, Lr:0.0001\n",
      "Epoch 18, Step: 386, Loss: 0.09057997912168503, Lr:0.0001\n",
      "Epoch 18, Step: 387, Loss: 0.035857316106557846, Lr:0.0001\n",
      "Epoch 18, Step: 388, Loss: 0.145999476313591, Lr:0.0001\n",
      "Epoch 18, Step: 389, Loss: 0.012772462330758572, Lr:0.0001\n",
      "Epoch 18, Step: 390, Loss: 0.035115890204906464, Lr:0.0001\n",
      "Epoch 18, Step: 391, Loss: 0.027685556560754776, Lr:0.0001\n",
      "Epoch 18, Step: 392, Loss: 0.18547441065311432, Lr:0.0001\n",
      "Epoch 18, Step: 393, Loss: 0.1689821183681488, Lr:0.0001\n",
      "Epoch 18, Step: 394, Loss: 0.024904092773795128, Lr:0.0001\n",
      "Epoch 18, Step: 395, Loss: 0.11086823791265488, Lr:0.0001\n",
      "Epoch 18, Step: 396, Loss: 0.025457819923758507, Lr:0.0001\n",
      "Epoch 18, Step: 397, Loss: 0.10937304049730301, Lr:0.0001\n",
      "Epoch 18, Step: 398, Loss: 0.24351945519447327, Lr:0.0001\n",
      "Epoch 18, Step: 399, Loss: 0.03455309942364693, Lr:0.0001\n",
      "Epoch 18, Step: 400, Loss: 0.09187550097703934, Lr:0.0001\n",
      "Epoch 18, Step: 401, Loss: 0.02067418396472931, Lr:0.0001\n",
      "Epoch 18, Step: 402, Loss: 0.04544968903064728, Lr:0.0001\n",
      "Epoch 18, Step: 403, Loss: 0.11120626330375671, Lr:0.0001\n",
      "Epoch 18, Step: 404, Loss: 0.17582279443740845, Lr:0.0001\n",
      "Epoch 18, Step: 405, Loss: 0.09763606637716293, Lr:0.0001\n",
      "Epoch 18, Step: 406, Loss: 0.02808173932135105, Lr:0.0001\n",
      "Epoch 18, Step: 407, Loss: 0.036517538130283356, Lr:0.0001\n",
      "Epoch 18, Step: 408, Loss: 0.010008623823523521, Lr:0.0001\n",
      "Epoch 18, Step: 409, Loss: 0.026888221502304077, Lr:0.0001\n",
      "Epoch 18, Step: 410, Loss: 0.13547000288963318, Lr:0.0001\n",
      "Epoch 18, Step: 411, Loss: 0.1889428198337555, Lr:0.0001\n",
      "Epoch 18, Step: 412, Loss: 0.09002372622489929, Lr:0.0001\n",
      "Epoch 18, Step: 413, Loss: 0.027249140664935112, Lr:0.0001\n",
      "Epoch 18, Step: 414, Loss: 0.04292692989110947, Lr:0.0001\n",
      "Epoch 18, Step: 415, Loss: 0.022393474355340004, Lr:0.0001\n",
      "Epoch 18, Step: 416, Loss: 0.006518503185361624, Lr:0.0001\n",
      "Epoch 18, Step: 417, Loss: 0.09590112417936325, Lr:0.0001\n",
      "Epoch 18, Step: 418, Loss: 0.01964876614511013, Lr:0.0001\n",
      "Epoch 18, Step: 419, Loss: 0.06800401955842972, Lr:0.0001\n",
      "Epoch 18, Step: 420, Loss: 0.11551523208618164, Lr:0.0001\n",
      "Epoch 18, Step: 421, Loss: 0.12379725277423859, Lr:0.0001\n",
      "Epoch 18, Step: 422, Loss: 0.14048287272453308, Lr:0.0001\n",
      "Epoch 18, Step: 423, Loss: 0.10844165086746216, Lr:0.0001\n",
      "Epoch 18, Step: 424, Loss: 0.010031642392277718, Lr:0.0001\n",
      "Epoch 18, Step: 425, Loss: 0.11720198392868042, Lr:0.0001\n",
      "Epoch 18, Step: 426, Loss: 0.06585248559713364, Lr:0.0001\n",
      "Epoch 18, Step: 427, Loss: 0.0008857035427354276, Lr:0.0001\n",
      "Epoch 18, Step: 428, Loss: 0.16100899875164032, Lr:0.0001\n",
      "Epoch 18, Step: 429, Loss: 0.2857922315597534, Lr:0.0001\n",
      "Epoch 18, Step: 430, Loss: 0.007605108432471752, Lr:0.0001\n",
      "Epoch 18, Step: 431, Loss: 0.0020471252501010895, Lr:0.0001\n",
      "Epoch 18, Step: 432, Loss: 0.08202540874481201, Lr:0.0001\n",
      "Epoch 18, Step: 433, Loss: 0.050708115100860596, Lr:0.0001\n",
      "Epoch 18, Step: 434, Loss: 0.051190730184316635, Lr:0.0001\n",
      "Epoch 18, Step: 435, Loss: 0.045376092195510864, Lr:0.0001\n",
      "Epoch 18, Step: 436, Loss: 0.0033101702574640512, Lr:0.0001\n",
      "Epoch 18, Step: 437, Loss: 0.5873113870620728, Lr:0.0001\n",
      "Epoch 18, Step: 438, Loss: 0.07035090029239655, Lr:0.0001\n",
      "Epoch 18, Step: 439, Loss: 0.11844665557146072, Lr:0.0001\n",
      "Epoch 18, Step: 440, Loss: 0.10097381472587585, Lr:0.0001\n",
      "Epoch 18, Step: 441, Loss: 0.03995757922530174, Lr:0.0001\n",
      "Epoch 18, Step: 442, Loss: 0.06063609942793846, Lr:0.0001\n",
      "Epoch 18, Step: 443, Loss: 0.09104052186012268, Lr:0.0001\n",
      "Epoch 18, Step: 444, Loss: 0.013850374147295952, Lr:0.0001\n",
      "Epoch 18, Step: 445, Loss: 0.04508724436163902, Lr:0.0001\n",
      "Epoch 18, Step: 446, Loss: 0.08960328996181488, Lr:0.0001\n",
      "Epoch 18, Step: 447, Loss: 0.08220069855451584, Lr:0.0001\n",
      "Epoch 18, Step: 448, Loss: 0.09062961488962173, Lr:0.0001\n",
      "Epoch 18, Step: 449, Loss: 0.0625176802277565, Lr:0.0001\n",
      "Epoch 18, Step: 450, Loss: 0.09366724640130997, Lr:0.0001\n",
      "Epoch 18, Step: 451, Loss: 0.010557313449680805, Lr:0.0001\n",
      "Epoch 18, Step: 452, Loss: 0.09093429148197174, Lr:0.0001\n",
      "Epoch 18, Step: 453, Loss: 0.05424666404724121, Lr:0.0001\n",
      "Epoch 18, Step: 454, Loss: 0.17461355030536652, Lr:0.0001\n",
      "Epoch 18, Step: 455, Loss: 0.30113738775253296, Lr:0.0001\n",
      "Epoch 18, Step: 456, Loss: 0.13818150758743286, Lr:0.0001\n",
      "Epoch 18, Step: 457, Loss: 0.09156098961830139, Lr:0.0001\n",
      "Epoch 18, Step: 458, Loss: 0.029034161940217018, Lr:0.0001\n",
      "Epoch 18, Step: 459, Loss: 0.24323706328868866, Lr:0.0001\n",
      "Epoch 18, Step: 460, Loss: 0.0938367173075676, Lr:0.0001\n",
      "Epoch 18, Step: 461, Loss: 0.14408522844314575, Lr:0.0001\n",
      "Epoch 18, Step: 462, Loss: 0.5296001434326172, Lr:0.0001\n",
      "Epoch 18, Step: 463, Loss: 0.016829151660203934, Lr:0.0001\n",
      "Epoch 18, Step: 464, Loss: 0.3252028524875641, Lr:0.0001\n",
      "Epoch 18, Step: 465, Loss: 0.05368715897202492, Lr:0.0001\n",
      "Epoch 18, Step: 466, Loss: 0.14879553020000458, Lr:0.0001\n",
      "Epoch 18, Step: 467, Loss: 0.19454777240753174, Lr:0.0001\n",
      "Epoch 18, Step: 468, Loss: 0.06931063532829285, Lr:0.0001\n",
      "Epoch 18, Step: 469, Loss: 0.024361347779631615, Lr:0.0001\n",
      "Epoch 18, Step: 470, Loss: 0.06697613000869751, Lr:0.0001\n",
      "Epoch 18, Step: 471, Loss: 0.07913609594106674, Lr:0.0001\n",
      "Epoch 18, Step: 472, Loss: 0.09753774106502533, Lr:0.0001\n",
      "Epoch 18, Step: 473, Loss: 0.04110259190201759, Lr:0.0001\n",
      "Epoch 18, Step: 474, Loss: 0.14327332377433777, Lr:0.0001\n",
      "Epoch 18, Step: 475, Loss: 0.03416363522410393, Lr:0.0001\n",
      "Epoch 18, Step: 476, Loss: 0.02157563902437687, Lr:0.0001\n",
      "Epoch 18, Step: 477, Loss: 0.019646259024739265, Lr:0.0001\n",
      "Epoch 18, Step: 478, Loss: 0.3677150309085846, Lr:0.0001\n",
      "Epoch 18, Step: 479, Loss: 0.36291083693504333, Lr:0.0001\n",
      "Epoch 18, Step: 480, Loss: 0.03332003951072693, Lr:0.0001\n",
      "Epoch 18, Step: 481, Loss: 0.003046088619157672, Lr:0.0001\n",
      "Epoch 18, Step: 482, Loss: 0.08242741227149963, Lr:0.0001\n",
      "Epoch 18, Step: 483, Loss: 0.07038365304470062, Lr:0.0001\n",
      "Epoch 18, Step: 484, Loss: 0.33513373136520386, Lr:0.0001\n",
      "Epoch 18, Step: 485, Loss: 0.04200851917266846, Lr:0.0001\n",
      "Epoch 18, Step: 486, Loss: 0.013050118461251259, Lr:0.0001\n",
      "Epoch 18, Step: 487, Loss: 0.05462243780493736, Lr:0.0001\n",
      "Epoch 18, Step: 488, Loss: 0.5464391708374023, Lr:0.0001\n",
      "Epoch 18, Step: 489, Loss: 0.0708557516336441, Lr:0.0001\n",
      "Epoch 18, Step: 490, Loss: 0.18207497894763947, Lr:0.0001\n",
      "Epoch 18, Step: 491, Loss: 0.06861245632171631, Lr:0.0001\n",
      "Epoch 18, Step: 492, Loss: 0.24183720350265503, Lr:0.0001\n",
      "Epoch 18, Step: 493, Loss: 0.16880837082862854, Lr:0.0001\n",
      "Epoch 18, Step: 494, Loss: 0.09383810311555862, Lr:0.0001\n",
      "Epoch 18, Step: 495, Loss: 0.03924068063497543, Lr:0.0001\n",
      "Epoch 18, Step: 496, Loss: 0.21309718489646912, Lr:0.0001\n",
      "Epoch 18, Step: 497, Loss: 0.05914415046572685, Lr:0.0001\n",
      "Epoch 18, Step: 498, Loss: 0.026233822107315063, Lr:0.0001\n",
      "Epoch 18, Step: 499, Loss: 0.03028114140033722, Lr:0.0001\n",
      "Epoch 18, Step: 500, Loss: 0.0056787533685564995, Lr:0.0001\n",
      "Epoch 18, Step: 501, Loss: 0.1431988775730133, Lr:0.0001\n",
      "Epoch 18, Step: 502, Loss: 0.010663064196705818, Lr:0.0001\n",
      "Epoch 18, Step: 503, Loss: 0.01487643551081419, Lr:0.0001\n",
      "Epoch 18, Step: 504, Loss: 0.04580232501029968, Lr:0.0001\n",
      "Epoch 18, Step: 505, Loss: 0.02022087387740612, Lr:0.0001\n",
      "Epoch 18, Step: 506, Loss: 0.09572490304708481, Lr:0.0001\n",
      "Epoch 18, Step: 507, Loss: 0.016161983832716942, Lr:0.0001\n",
      "Epoch 18, Step: 508, Loss: 0.1320173442363739, Lr:0.0001\n",
      "Epoch 18, Step: 509, Loss: 0.1645919531583786, Lr:0.0001\n",
      "Epoch 18, Step: 510, Loss: 0.09458121657371521, Lr:0.0001\n",
      "Epoch 18, Step: 511, Loss: 0.14227524399757385, Lr:0.0001\n",
      "Epoch 18, Step: 512, Loss: 0.08212552964687347, Lr:0.0001\n",
      "Epoch 18, Step: 513, Loss: 0.07032284140586853, Lr:0.0001\n",
      "Epoch 18, Step: 514, Loss: 0.308622270822525, Lr:0.0001\n",
      "Epoch 18, Step: 515, Loss: 0.03859122097492218, Lr:0.0001\n",
      "Epoch 18, Step: 516, Loss: 0.04472541809082031, Lr:0.0001\n",
      "Epoch 18, Step: 517, Loss: 0.08811163902282715, Lr:0.0001\n",
      "Epoch 18, Step: 518, Loss: 0.113210529088974, Lr:0.0001\n",
      "Epoch 18, Step: 519, Loss: 0.0914662554860115, Lr:0.0001\n",
      "Epoch 18, Step: 520, Loss: 0.028739186003804207, Lr:0.0001\n",
      "Epoch 18, Step: 521, Loss: 0.026147065684199333, Lr:0.0001\n",
      "Epoch 18, Step: 522, Loss: 0.08600693196058273, Lr:0.0001\n",
      "Epoch 18, Step: 523, Loss: 0.04928407073020935, Lr:0.0001\n",
      "Epoch 18, Step: 524, Loss: 0.08920706063508987, Lr:0.0001\n",
      "Epoch 18, Step: 525, Loss: 0.06988906115293503, Lr:0.0001\n",
      "Epoch 18, Step: 526, Loss: 0.0035326601937413216, Lr:0.0001\n",
      "Epoch 18, Step: 527, Loss: 0.015159666538238525, Lr:0.0001\n",
      "Epoch 18, Step: 528, Loss: 0.0939890593290329, Lr:0.0001\n",
      "Epoch 18, Step: 529, Loss: 0.1455233097076416, Lr:0.0001\n",
      "Epoch 18, Step: 530, Loss: 0.12864041328430176, Lr:0.0001\n",
      "Epoch 18, Step: 531, Loss: 0.04811982065439224, Lr:0.0001\n",
      "Epoch 18, Step: 532, Loss: 0.5016778111457825, Lr:0.0001\n",
      "Epoch 18, Step: 533, Loss: 0.061741672456264496, Lr:0.0001\n",
      "Epoch 18, Step: 534, Loss: 0.01172716449946165, Lr:0.0001\n",
      "Epoch 18, Step: 535, Loss: 0.42060714960098267, Lr:0.0001\n",
      "Epoch 18, Step: 536, Loss: 0.09482128173112869, Lr:0.0001\n",
      "Epoch 18, Step: 537, Loss: 0.01680859737098217, Lr:0.0001\n",
      "Epoch 18, Step: 538, Loss: 0.17996004223823547, Lr:0.0001\n",
      "Epoch 18, Step: 539, Loss: 0.04682108759880066, Lr:0.0001\n",
      "Epoch 18, Step: 540, Loss: 0.003645020304247737, Lr:0.0001\n",
      "Epoch 18, Step: 541, Loss: 0.07867201417684555, Lr:0.0001\n",
      "Epoch 18, Step: 542, Loss: 0.4565291702747345, Lr:0.0001\n",
      "Epoch 18, Step: 543, Loss: 0.032260097563266754, Lr:0.0001\n",
      "Epoch 18, Step: 544, Loss: 0.2988615930080414, Lr:0.0001\n",
      "Epoch 18, Step: 545, Loss: 0.23176787793636322, Lr:0.0001\n",
      "Epoch 18, Step: 546, Loss: 0.2746073305606842, Lr:0.0001\n",
      "Epoch 18, Step: 547, Loss: 0.34421706199645996, Lr:0.0001\n",
      "Epoch 18, Step: 548, Loss: 0.7766168117523193, Lr:0.0001\n",
      "Epoch 18, Step: 549, Loss: 0.2066497504711151, Lr:0.0001\n",
      "Epoch 18, Step: 550, Loss: 0.00517065916210413, Lr:0.0001\n",
      "Epoch 18, Step: 551, Loss: 0.19228103756904602, Lr:0.0001\n",
      "Epoch 18, Step: 552, Loss: 0.09712368249893188, Lr:0.0001\n",
      "Epoch 18, Step: 553, Loss: 0.2332313060760498, Lr:0.0001\n",
      "Epoch 18, Step: 554, Loss: 0.7968271970748901, Lr:0.0001\n",
      "Epoch 18, Step: 555, Loss: 0.29676690697669983, Lr:0.0001\n",
      "Epoch 18, Step: 556, Loss: 0.028231222182512283, Lr:0.0001\n",
      "Epoch 18, Step: 557, Loss: 0.05017551779747009, Lr:0.0001\n",
      "Epoch 18, Step: 558, Loss: 0.5619939565658569, Lr:0.0001\n",
      "Epoch 18, Step: 559, Loss: 0.037328463047742844, Lr:0.0001\n",
      "Epoch 18, Step: 560, Loss: 0.1548343300819397, Lr:0.0001\n",
      "Epoch 18, Step: 561, Loss: 0.43033871054649353, Lr:0.0001\n",
      "Epoch 18, Step: 562, Loss: 0.004344866145402193, Lr:0.0001\n",
      "Epoch 18, Step: 563, Loss: 0.32454970479011536, Lr:0.0001\n",
      "Epoch 18, Step: 564, Loss: 0.2582927644252777, Lr:0.0001\n",
      "Epoch 18, Step: 565, Loss: 0.2718617916107178, Lr:0.0001\n",
      "Epoch 18, Step: 566, Loss: 0.36753442883491516, Lr:0.0001\n",
      "Epoch 18, Step: 567, Loss: 0.16607525944709778, Lr:0.0001\n",
      "Epoch 18, Step: 568, Loss: 0.12218163162469864, Lr:0.0001\n",
      "Epoch 18, Step: 569, Loss: 0.356028288602829, Lr:0.0001\n",
      "Epoch 18, Step: 570, Loss: 0.23320776224136353, Lr:0.0001\n",
      "Epoch 18, Step: 571, Loss: 0.33998212218284607, Lr:0.0001\n",
      "Epoch 18, Step: 572, Loss: 0.07282451540231705, Lr:0.0001\n",
      "Epoch 18, Step: 573, Loss: 0.023221679031848907, Lr:0.0001\n",
      "Epoch 18, Step: 574, Loss: 0.013979149982333183, Lr:0.0001\n",
      "Epoch 18, Step: 575, Loss: 0.03731793910264969, Lr:0.0001\n",
      "Epoch 18, Step: 576, Loss: 0.2444756180047989, Lr:0.0001\n",
      "Epoch 18, Step: 577, Loss: 0.05175207555294037, Lr:0.0001\n",
      "Epoch 18, Step: 578, Loss: 0.0659535676240921, Lr:0.0001\n",
      "Epoch 18, Step: 579, Loss: 0.12579742074012756, Lr:0.0001\n",
      "Epoch 18, Step: 580, Loss: 0.07202273607254028, Lr:0.0001\n",
      "Epoch 18, Step: 581, Loss: 0.1911204755306244, Lr:0.0001\n",
      "Epoch 18, Step: 582, Loss: 0.05218473821878433, Lr:0.0001\n",
      "Epoch 18, Step: 583, Loss: 0.13815374672412872, Lr:0.0001\n",
      "Epoch 18, Step: 584, Loss: 0.17871913313865662, Lr:0.0001\n",
      "Epoch 18, Step: 585, Loss: 0.2314012348651886, Lr:0.0001\n",
      "Epoch 18, Step: 586, Loss: 0.30404260754585266, Lr:0.0001\n",
      "Epoch 18, Step: 587, Loss: 0.059421177953481674, Lr:0.0001\n",
      "Epoch 18, Step: 588, Loss: 0.22417040169239044, Lr:0.0001\n",
      "Epoch 18, Step: 589, Loss: 0.09254282712936401, Lr:0.0001\n",
      "Epoch 18, Step: 590, Loss: 0.04875824972987175, Lr:0.0001\n",
      "Epoch 18, Step: 591, Loss: 0.02756262756884098, Lr:0.0001\n",
      "Epoch 18, Step: 592, Loss: 0.11591241508722305, Lr:0.0001\n",
      "Epoch 18, Step: 593, Loss: 0.14580930769443512, Lr:0.0001\n",
      "Epoch 18, Step: 594, Loss: 0.17447075247764587, Lr:0.0001\n",
      "Epoch 18, Step: 595, Loss: 0.24951446056365967, Lr:0.0001\n",
      "Epoch 18, Step: 596, Loss: 0.011099898256361485, Lr:0.0001\n",
      "Epoch 18, Step: 597, Loss: 0.1019643172621727, Lr:0.0001\n",
      "Epoch 18, Step: 598, Loss: 0.20807111263275146, Lr:0.0001\n",
      "Epoch 18, Step: 599, Loss: 0.19879518449306488, Lr:0.0001\n",
      "Epoch 18, Step: 600, Loss: 0.044020846486091614, Lr:0.0001\n",
      "Epoch 18, Step: 601, Loss: 0.10915979743003845, Lr:0.0001\n",
      "Epoch 18, Step: 602, Loss: 0.04798828065395355, Lr:0.0001\n",
      "Epoch 18, Step: 603, Loss: 0.15922771394252777, Lr:0.0001\n",
      "Epoch 18, Step: 604, Loss: 0.0751289576292038, Lr:0.0001\n",
      "Epoch 18, Step: 605, Loss: 0.02648085728287697, Lr:0.0001\n",
      "Epoch 18, Step: 606, Loss: 0.03474682569503784, Lr:0.0001\n",
      "Epoch 18, Step: 607, Loss: 0.08403495699167252, Lr:0.0001\n",
      "Epoch 18, Step: 608, Loss: 0.10704907774925232, Lr:0.0001\n",
      "Epoch 18, Step: 609, Loss: 0.009873926639556885, Lr:0.0001\n",
      "Epoch 18, Step: 610, Loss: 0.05009617656469345, Lr:0.0001\n",
      "Epoch 18, Step: 611, Loss: 0.049754805862903595, Lr:0.0001\n",
      "Epoch 18, Step: 612, Loss: 0.014830989763140678, Lr:0.0001\n",
      "Epoch 18, Step: 613, Loss: 0.43587589263916016, Lr:0.0001\n",
      "Epoch 18, Step: 614, Loss: 0.14861053228378296, Lr:0.0001\n",
      "Epoch 18, Step: 615, Loss: 0.06426279246807098, Lr:0.0001\n",
      "Epoch 18, Step: 616, Loss: 0.01375774946063757, Lr:0.0001\n",
      "Epoch 18, Step: 617, Loss: 0.09647616744041443, Lr:0.0001\n",
      "Epoch 18, Step: 618, Loss: 0.043090324848890305, Lr:0.0001\n",
      "Epoch 18, Step: 619, Loss: 0.06117989867925644, Lr:0.0001\n",
      "Epoch 18, Step: 620, Loss: 0.1590825617313385, Lr:0.0001\n",
      "Epoch 18, Step: 621, Loss: 0.060302332043647766, Lr:0.0001\n",
      "Epoch 18, Step: 622, Loss: 0.22489528357982635, Lr:0.0001\n",
      "Epoch 18, Step: 623, Loss: 0.05973755195736885, Lr:0.0001\n",
      "Epoch 18, Step: 624, Loss: 0.01886676624417305, Lr:0.0001\n",
      "Epoch 18, Step: 625, Loss: 0.03977961093187332, Lr:0.0001\n",
      "Epoch 18, Step: 626, Loss: 0.04461343586444855, Lr:0.0001\n",
      "Epoch 18, Step: 627, Loss: 0.12258431315422058, Lr:0.0001\n",
      "Epoch 18, Step: 628, Loss: 0.16958960890769958, Lr:0.0001\n",
      "Epoch 18, Step: 629, Loss: 0.019024815410375595, Lr:0.0001\n",
      "Epoch 18, Step: 630, Loss: 0.0915679857134819, Lr:0.0001\n",
      "Epoch 18, Step: 631, Loss: 0.02079288475215435, Lr:0.0001\n",
      "Epoch 18, Step: 632, Loss: 0.030905980616807938, Lr:0.0001\n",
      "Epoch 18, Step: 633, Loss: 0.1454082429409027, Lr:0.0001\n",
      "Epoch 18, Step: 634, Loss: 0.09228024631738663, Lr:0.0001\n",
      "Epoch 18, Step: 635, Loss: 0.29884058237075806, Lr:0.0001\n",
      "Epoch 18, Step: 636, Loss: 0.035424210131168365, Lr:0.0001\n",
      "Epoch 18, Step: 637, Loss: 0.10770568251609802, Lr:0.0001\n",
      "Epoch 18, Step: 638, Loss: 0.014604191295802593, Lr:0.0001\n",
      "Epoch 18, Step: 639, Loss: 0.08955729007720947, Lr:0.0001\n",
      "Epoch 18, Step: 640, Loss: 0.07857568562030792, Lr:0.0001\n",
      "Epoch 18, Step: 641, Loss: 0.019558286294341087, Lr:0.0001\n",
      "Epoch 18, Step: 642, Loss: 0.11254443228244781, Lr:0.0001\n",
      "Epoch 18, Step: 643, Loss: 0.014937054365873337, Lr:0.0001\n",
      "Epoch 18, Step: 644, Loss: 0.3115479052066803, Lr:0.0001\n",
      "Epoch 18, Step: 645, Loss: 0.03151797875761986, Lr:0.0001\n",
      "Epoch 18, Step: 646, Loss: 0.44524458050727844, Lr:0.0001\n",
      "Epoch 18, Step: 647, Loss: 0.03319999575614929, Lr:0.0001\n",
      "Epoch 18, Step: 648, Loss: 0.007228504866361618, Lr:0.0001\n",
      "Epoch 18, Step: 649, Loss: 0.15529733896255493, Lr:0.0001\n",
      "Epoch 18, Step: 650, Loss: 0.025693167001008987, Lr:0.0001\n",
      "Epoch 18, Step: 651, Loss: 0.005405505653470755, Lr:0.0001\n",
      "Epoch 18, Step: 652, Loss: 0.010256034322082996, Lr:0.0001\n",
      "Epoch 18, Step: 653, Loss: 0.018294887617230415, Lr:0.0001\n",
      "Epoch 18, Step: 654, Loss: 0.012540080584585667, Lr:0.0001\n",
      "Epoch 18, Step: 655, Loss: 0.04306430369615555, Lr:0.0001\n",
      "Epoch 18, Step: 656, Loss: 0.06323318928480148, Lr:0.0001\n",
      "Epoch 18, Step: 657, Loss: 0.014088465832173824, Lr:0.0001\n",
      "Epoch 18, Step: 658, Loss: 0.27173641324043274, Lr:0.0001\n",
      "Epoch 18, Step: 659, Loss: 0.048551350831985474, Lr:0.0001\n",
      "Epoch 18, Step: 660, Loss: 0.010669227689504623, Lr:0.0001\n",
      "Epoch 18, Step: 661, Loss: 0.055076438933610916, Lr:0.0001\n",
      "Epoch 18, Step: 662, Loss: 0.4225928783416748, Lr:0.0001\n",
      "Epoch 18, Step: 663, Loss: 0.021714258939027786, Lr:0.0001\n",
      "Epoch 18, Step: 664, Loss: 0.05432219058275223, Lr:0.0001\n",
      "Epoch 18, Step: 665, Loss: 0.027776401489973068, Lr:0.0001\n",
      "Epoch 18, Step: 666, Loss: 0.02659488096833229, Lr:0.0001\n",
      "Epoch 18, Step: 667, Loss: 0.011545215733349323, Lr:0.0001\n",
      "Epoch 18, Step: 668, Loss: 0.025279436260461807, Lr:0.0001\n",
      "Epoch 18, Step: 669, Loss: 0.4294414520263672, Lr:0.0001\n",
      "Epoch 18, Step: 670, Loss: 0.033241063356399536, Lr:0.0001\n",
      "Epoch 18, Step: 671, Loss: 0.02952064387500286, Lr:0.0001\n",
      "Epoch 18, Step: 672, Loss: 0.007210014387965202, Lr:0.0001\n",
      "Epoch 18, Step: 673, Loss: 0.27244845032691956, Lr:0.0001\n",
      "Epoch 18, Step: 674, Loss: 0.08856477588415146, Lr:0.0001\n",
      "Epoch 18, Step: 675, Loss: 0.017369790002703667, Lr:0.0001\n",
      "Epoch 18, Step: 676, Loss: 0.08225961774587631, Lr:0.0001\n",
      "Epoch 18, Step: 677, Loss: 0.027038002386689186, Lr:0.0001\n",
      "Epoch 18, Step: 678, Loss: 0.07808399945497513, Lr:0.0001\n",
      "Epoch 18, Step: 679, Loss: 0.03563540428876877, Lr:0.0001\n",
      "Epoch 18, Step: 680, Loss: 0.08142855018377304, Lr:0.0001\n",
      "Epoch 18, Step: 681, Loss: 0.0038528444711118937, Lr:0.0001\n",
      "Epoch 18, Step: 682, Loss: 0.01852158084511757, Lr:0.0001\n",
      "Epoch 18, Step: 683, Loss: 0.004174732603132725, Lr:0.0001\n",
      "Epoch 18, Step: 684, Loss: 0.16950199007987976, Lr:0.0001\n",
      "Epoch 18, Step: 685, Loss: 0.021801628172397614, Lr:0.0001\n",
      "Epoch 18, Step: 686, Loss: 0.14649616181850433, Lr:0.0001\n",
      "Epoch 18, Step: 687, Loss: 0.10117551684379578, Lr:0.0001\n",
      "Epoch 18, Step: 688, Loss: 0.23023658990859985, Lr:0.0001\n",
      "Epoch 18, Step: 689, Loss: 0.024291053414344788, Lr:0.0001\n",
      "Epoch 18, Step: 690, Loss: 0.012709884904325008, Lr:0.0001\n",
      "Epoch 18, Step: 691, Loss: 0.06664032489061356, Lr:0.0001\n",
      "Epoch 18, Step: 692, Loss: 0.05453486368060112, Lr:0.0001\n",
      "Epoch 18, Step: 693, Loss: 0.08212906867265701, Lr:0.0001\n",
      "Epoch 18, Step: 694, Loss: 0.010083390399813652, Lr:0.0001\n",
      "Epoch 18, Step: 695, Loss: 0.19468683004379272, Lr:0.0001\n",
      "Epoch 18, Step: 696, Loss: 0.11159035563468933, Lr:0.0001\n",
      "Epoch 18, Step: 697, Loss: 0.2587788701057434, Lr:0.0001\n",
      "Epoch 18, Step: 698, Loss: 0.024576527997851372, Lr:0.0001\n",
      "Epoch 18, Step: 699, Loss: 0.035540733486413956, Lr:0.0001\n",
      "Epoch 18, Step: 700, Loss: 0.2463093400001526, Lr:0.0001\n",
      "Epoch 18, Step: 701, Loss: 0.05295006185770035, Lr:0.0001\n",
      "Epoch 18, Step: 702, Loss: 0.08373626321554184, Lr:0.0001\n",
      "Epoch 18, Step: 703, Loss: 0.004754990339279175, Lr:0.0001\n",
      "Epoch 18, Step: 704, Loss: 0.13925984501838684, Lr:0.0001\n",
      "Epoch 18, Step: 705, Loss: 0.07407649606466293, Lr:0.0001\n",
      "Epoch 18, Step: 706, Loss: 0.24083463847637177, Lr:0.0001\n",
      "Epoch 18, Step: 707, Loss: 0.03848615288734436, Lr:0.0001\n",
      "Epoch 18, Step: 708, Loss: 0.013197725638747215, Lr:0.0001\n",
      "Epoch 18, Step: 709, Loss: 0.7258650064468384, Lr:0.0001\n",
      "Epoch 18, Step: 710, Loss: 0.06067759916186333, Lr:0.0001\n",
      "Epoch 18, Step: 711, Loss: 0.15526780486106873, Lr:0.0001\n",
      "Epoch 18, Step: 712, Loss: 0.15066717565059662, Lr:0.0001\n",
      "Epoch 18, Step: 713, Loss: 0.10694326460361481, Lr:0.0001\n",
      "Epoch 18, Step: 714, Loss: 0.013647157698869705, Lr:0.0001\n",
      "Epoch 18, Step: 715, Loss: 0.11013594269752502, Lr:0.0001\n",
      "Epoch 18, Step: 716, Loss: 0.32714182138442993, Lr:0.0001\n",
      "Epoch 18, Step: 717, Loss: 0.14198052883148193, Lr:0.0001\n",
      "Epoch 18, Step: 718, Loss: 0.054817892611026764, Lr:0.0001\n",
      "Epoch 18, Step: 719, Loss: 0.01461665891110897, Lr:0.0001\n",
      "Epoch 18, Step: 720, Loss: 0.18108344078063965, Lr:0.0001\n",
      "Epoch 18, Step: 721, Loss: 0.039421092718839645, Lr:0.0001\n",
      "Epoch 18, Step: 722, Loss: 0.004846703726798296, Lr:0.0001\n",
      "Epoch 18, Step: 723, Loss: 0.10793882608413696, Lr:0.0001\n",
      "Epoch 18, Step: 724, Loss: 0.32121291756629944, Lr:0.0001\n",
      "Epoch 18, Step: 725, Loss: 0.2027568221092224, Lr:0.0001\n",
      "Epoch 18, Step: 726, Loss: 0.008986905217170715, Lr:0.0001\n",
      "Epoch 18, Step: 727, Loss: 0.0050737131386995316, Lr:0.0001\n",
      "Epoch 18, Step: 728, Loss: 0.004934683907777071, Lr:0.0001\n",
      "Epoch 18, Step: 729, Loss: 0.02835812233388424, Lr:0.0001\n",
      "Epoch 18, Step: 730, Loss: 0.08369452506303787, Lr:0.0001\n",
      "Epoch 18, Step: 731, Loss: 0.03911343589425087, Lr:0.0001\n",
      "Epoch 18, Step: 732, Loss: 0.025039363652467728, Lr:0.0001\n",
      "Epoch 18, Step: 733, Loss: 0.025488972663879395, Lr:0.0001\n",
      "Epoch 18, Step: 734, Loss: 0.04509879648685455, Lr:0.0001\n",
      "Epoch 18, Step: 735, Loss: 0.033211298286914825, Lr:0.0001\n",
      "Epoch 18, Step: 736, Loss: 0.14964857697486877, Lr:0.0001\n",
      "Epoch 18, Step: 737, Loss: 0.03588627278804779, Lr:0.0001\n",
      "Epoch 18, Step: 738, Loss: 0.1531638503074646, Lr:0.0001\n",
      "Epoch 18, Step: 739, Loss: 0.10166493058204651, Lr:0.0001\n",
      "Epoch 18, Step: 740, Loss: 0.1965930163860321, Lr:0.0001\n",
      "Epoch 18, Step: 741, Loss: 0.07591453194618225, Lr:0.0001\n",
      "Epoch 18, Step: 742, Loss: 0.027399146929383278, Lr:0.0001\n",
      "Epoch 18, Step: 743, Loss: 0.12369060516357422, Lr:0.0001\n",
      "Epoch 18, Step: 744, Loss: 0.028879258781671524, Lr:0.0001\n",
      "Epoch 18, Step: 745, Loss: 0.0027589520905166864, Lr:0.0001\n",
      "Epoch 18, Step: 746, Loss: 0.031378403306007385, Lr:0.0001\n",
      "Epoch 18, Step: 747, Loss: 0.07907018065452576, Lr:0.0001\n",
      "Epoch 18, Step: 748, Loss: 0.007278088945895433, Lr:0.0001\n",
      "Epoch 18, Step: 749, Loss: 0.04590707644820213, Lr:0.0001\n",
      "Epoch 18, Step: 750, Loss: 0.026582347229123116, Lr:0.0001\n",
      "Epoch 18, Step: 751, Loss: 0.024263722822070122, Lr:0.0001\n",
      "Epoch 18, Step: 752, Loss: 0.028355371206998825, Lr:0.0001\n",
      "Epoch 18, Step: 753, Loss: 0.0074374801479279995, Lr:0.0001\n",
      "Epoch 18, Step: 754, Loss: 0.014906949363648891, Lr:0.0001\n",
      "Epoch 18, Step: 755, Loss: 0.04503187537193298, Lr:0.0001\n",
      "Epoch 18, Step: 756, Loss: 0.04505430534482002, Lr:0.0001\n",
      "Epoch 18, Step: 757, Loss: 0.004080810584127903, Lr:0.0001\n",
      "Epoch 18, Step: 758, Loss: 0.010200031101703644, Lr:0.0001\n",
      "Epoch 18, Step: 759, Loss: 0.05615247040987015, Lr:0.0001\n",
      "Epoch 18, Step: 760, Loss: 0.1390790045261383, Lr:0.0001\n",
      "Epoch 18, Step: 761, Loss: 0.1351325660943985, Lr:0.0001\n",
      "Epoch 18, Step: 762, Loss: 0.07248739153146744, Lr:0.0001\n",
      "Epoch 18, Step: 763, Loss: 0.01548970676958561, Lr:0.0001\n",
      "Epoch 18, Step: 764, Loss: 0.03482009842991829, Lr:0.0001\n",
      "Epoch 18, Step: 765, Loss: 0.0034342072904109955, Lr:0.0001\n",
      "Epoch 18, Step: 766, Loss: 0.28559041023254395, Lr:0.0001\n",
      "Epoch 18, Step: 767, Loss: 0.10137507319450378, Lr:0.0001\n",
      "Epoch 18, Step: 768, Loss: 0.10145139694213867, Lr:0.0001\n",
      "Epoch 18, Step: 769, Loss: 0.06834739446640015, Lr:0.0001\n",
      "Epoch 18, Step: 770, Loss: 0.044105857610702515, Lr:0.0001\n",
      "Epoch 18, Step: 771, Loss: 0.007207871414721012, Lr:0.0001\n",
      "Epoch 18, Step: 772, Loss: 0.030924847349524498, Lr:0.0001\n",
      "Epoch 18, Step: 773, Loss: 0.3640923798084259, Lr:0.0001\n",
      "Epoch 18, Step: 774, Loss: 0.018193773925304413, Lr:0.0001\n",
      "Epoch 18, Step: 775, Loss: 0.05791892856359482, Lr:0.0001\n",
      "Epoch 18, Step: 776, Loss: 0.061481863260269165, Lr:0.0001\n",
      "Epoch 18, Step: 777, Loss: 0.08429674804210663, Lr:0.0001\n",
      "Epoch 18, Step: 778, Loss: 0.02265107072889805, Lr:0.0001\n",
      "Epoch 18, Step: 779, Loss: 0.08990899473428726, Lr:0.0001\n",
      "Epoch 18, Step: 780, Loss: 0.060577262192964554, Lr:0.0001\n",
      "Epoch 18, Step: 781, Loss: 0.01311391033232212, Lr:0.0001\n",
      "Epoch 18, Step: 782, Loss: 0.0038241350557655096, Lr:0.0001\n",
      "Epoch 18, Step: 783, Loss: 0.02492561936378479, Lr:0.0001\n",
      "Epoch 18, Step: 784, Loss: 0.014288035221397877, Lr:0.0001\n",
      "Epoch 18, Step: 785, Loss: 0.009777375496923923, Lr:0.0001\n",
      "Epoch 18, Step: 786, Loss: 0.04682457819581032, Lr:0.0001\n",
      "Epoch 18, Step: 787, Loss: 0.09161271154880524, Lr:0.0001\n",
      "Epoch 18, Step: 788, Loss: 0.09561938792467117, Lr:0.0001\n",
      "Epoch 18, Step: 789, Loss: 0.018804330378770828, Lr:0.0001\n",
      "Epoch 18, Step: 790, Loss: 0.01686224155128002, Lr:0.0001\n",
      "Epoch 18, Step: 791, Loss: 0.24693462252616882, Lr:0.0001\n",
      "Epoch 18, Step: 792, Loss: 0.016369357705116272, Lr:0.0001\n",
      "Epoch 18, Step: 793, Loss: 0.2289051115512848, Lr:0.0001\n",
      "Epoch 18, Step: 794, Loss: 0.039329636842012405, Lr:0.0001\n",
      "Epoch 18, Step: 795, Loss: 0.19633781909942627, Lr:0.0001\n",
      "Epoch 18, Step: 796, Loss: 0.0393681637942791, Lr:0.0001\n",
      "Epoch 18, Step: 797, Loss: 0.0069337086752057076, Lr:0.0001\n",
      "Epoch 18, Step: 798, Loss: 0.013781875371932983, Lr:0.0001\n",
      "Epoch 18, Step: 799, Loss: 0.004564736038446426, Lr:0.0001\n",
      "Epoch 18, Step: 800, Loss: 0.14299622178077698, Lr:0.0001\n",
      "Epoch 18, Step: 801, Loss: 0.012201318517327309, Lr:0.0001\n",
      "Epoch 18, Step: 802, Loss: 0.04748990014195442, Lr:0.0001\n",
      "Epoch 18, Step: 803, Loss: 0.030339771881699562, Lr:0.0001\n",
      "Epoch 18, Step: 804, Loss: 0.12502865493297577, Lr:0.0001\n",
      "Epoch 18, Step: 805, Loss: 0.004720771685242653, Lr:0.0001\n",
      "Epoch 18, Step: 806, Loss: 0.34104588627815247, Lr:0.0001\n",
      "Epoch 18, Step: 807, Loss: 0.03590894863009453, Lr:0.0001\n",
      "Epoch 18, Step: 808, Loss: 0.06425601243972778, Lr:0.0001\n",
      "Epoch 18, Step: 809, Loss: 0.005682243034243584, Lr:0.0001\n",
      "Epoch 18, Step: 810, Loss: 0.0057800947688519955, Lr:0.0001\n",
      "Epoch 18, Step: 811, Loss: 0.28266724944114685, Lr:0.0001\n",
      "Epoch 18, Step: 812, Loss: 0.15555591881275177, Lr:0.0001\n",
      "Epoch 18, Step: 813, Loss: 0.021758735179901123, Lr:0.0001\n",
      "Epoch 18, Step: 814, Loss: 0.16645440459251404, Lr:0.0001\n",
      "Epoch 18, Step: 815, Loss: 0.021968455985188484, Lr:0.0001\n",
      "Epoch 18, Step: 816, Loss: 0.09466330707073212, Lr:0.0001\n",
      "Epoch 18, Step: 817, Loss: 0.2757596969604492, Lr:0.0001\n",
      "Epoch 18, Step: 818, Loss: 0.1717972755432129, Lr:0.0001\n",
      "Epoch 18, Step: 819, Loss: 0.013323675841093063, Lr:0.0001\n",
      "Epoch 18, Step: 820, Loss: 0.036003291606903076, Lr:0.0001\n",
      "Epoch 18, Step: 821, Loss: 0.0035499357618391514, Lr:0.0001\n",
      "Epoch 18, Step: 822, Loss: 0.013644772581756115, Lr:0.0001\n",
      "Epoch 18, Step: 823, Loss: 0.0028198473155498505, Lr:0.0001\n",
      "Epoch 18, Step: 824, Loss: 0.2921905219554901, Lr:0.0001\n",
      "Epoch 18, Step: 825, Loss: 0.01636539027094841, Lr:0.0001\n",
      "Epoch 18, Step: 826, Loss: 0.05733382701873779, Lr:0.0001\n",
      "Epoch 18, Step: 827, Loss: 0.015847133472561836, Lr:0.0001\n",
      "Epoch 18, Step: 828, Loss: 0.10423199832439423, Lr:0.0001\n",
      "Epoch 18, Step: 829, Loss: 0.013123518787324429, Lr:0.0001\n",
      "Epoch 18, Step: 830, Loss: 0.09836932271718979, Lr:0.0001\n",
      "Epoch 18, Step: 831, Loss: 0.022732989862561226, Lr:0.0001\n",
      "Epoch 18, Step: 832, Loss: 0.055181682109832764, Lr:0.0001\n",
      "Epoch 18, Step: 833, Loss: 0.36974743008613586, Lr:0.0001\n",
      "Epoch 18, Step: 834, Loss: 0.34489646553993225, Lr:0.0001\n",
      "Epoch 18, Step: 835, Loss: 0.03499941900372505, Lr:0.0001\n",
      "Epoch 18, Step: 836, Loss: 0.18183442950248718, Lr:0.0001\n",
      "Epoch 18, Step: 837, Loss: 0.05264005810022354, Lr:0.0001\n",
      "Epoch 18, Step: 838, Loss: 0.046049270778894424, Lr:0.0001\n",
      "Epoch 18, Step: 839, Loss: 0.08481135964393616, Lr:0.0001\n",
      "Epoch 18, Step: 840, Loss: 0.005508154630661011, Lr:0.0001\n",
      "Epoch 18, Step: 841, Loss: 0.023578761145472527, Lr:0.0001\n",
      "Epoch 18, Step: 842, Loss: 0.007334745489060879, Lr:0.0001\n",
      "Epoch 18, Step: 843, Loss: 0.35418179631233215, Lr:0.0001\n",
      "Epoch 18, Step: 844, Loss: 0.13042469322681427, Lr:0.0001\n",
      "Epoch 18, Step: 845, Loss: 0.06682927906513214, Lr:0.0001\n",
      "Epoch 18, Step: 846, Loss: 0.010143477469682693, Lr:0.0001\n",
      "Epoch 18, Step: 847, Loss: 0.09905047714710236, Lr:0.0001\n",
      "Epoch 18, Step: 848, Loss: 0.06715815514326096, Lr:0.0001\n",
      "Epoch 18, Step: 849, Loss: 0.00915051344782114, Lr:0.0001\n",
      "Epoch 18, Step: 850, Loss: 0.05867486819624901, Lr:0.0001\n",
      "Epoch 18, Step: 851, Loss: 0.049928877502679825, Lr:0.0001\n",
      "Epoch 18, Step: 852, Loss: 0.055538248270750046, Lr:0.0001\n",
      "Epoch 18, Step: 853, Loss: 0.13320592045783997, Lr:0.0001\n",
      "Epoch 18, Step: 854, Loss: 0.153453528881073, Lr:0.0001\n",
      "Epoch 18, Step: 855, Loss: 0.10958711057901382, Lr:0.0001\n",
      "Epoch 18, Step: 856, Loss: 0.39918753504753113, Lr:0.0001\n",
      "Epoch 18, Step: 857, Loss: 0.21054139733314514, Lr:0.0001\n",
      "Epoch 18, Step: 858, Loss: 0.15722255408763885, Lr:0.0001\n",
      "Epoch 18, Step: 859, Loss: 0.2794007956981659, Lr:0.0001\n",
      "Epoch 18, Step: 860, Loss: 0.09424333274364471, Lr:0.0001\n",
      "Epoch 18, Step: 861, Loss: 0.01267552562057972, Lr:0.0001\n",
      "Epoch 18, Step: 862, Loss: 0.03744678944349289, Lr:0.0001\n",
      "Epoch 18, Step: 863, Loss: 0.08272247016429901, Lr:0.0001\n",
      "Epoch 18, Step: 864, Loss: 0.0852409154176712, Lr:0.0001\n",
      "Epoch 18, Step: 865, Loss: 0.3931431174278259, Lr:0.0001\n",
      "Epoch 18, Step: 866, Loss: 0.02738676592707634, Lr:0.0001\n",
      "Epoch 18, Step: 867, Loss: 0.13741064071655273, Lr:0.0001\n",
      "Epoch 18, Step: 868, Loss: 0.11075837165117264, Lr:0.0001\n",
      "Epoch 18, Step: 869, Loss: 0.029690179973840714, Lr:0.0001\n",
      "Epoch 18, Step: 870, Loss: 0.03328994661569595, Lr:0.0001\n",
      "Epoch 18, Step: 871, Loss: 0.19371919333934784, Lr:0.0001\n",
      "Epoch 18, Step: 872, Loss: 0.042715806514024734, Lr:0.0001\n",
      "Epoch 18, Step: 873, Loss: 0.08089537918567657, Lr:0.0001\n",
      "Epoch 18, Step: 874, Loss: 0.11921170353889465, Lr:0.0001\n",
      "Epoch 18, Step: 875, Loss: 0.07919369637966156, Lr:0.0001\n",
      "Epoch 18, Step: 876, Loss: 0.0695158913731575, Lr:0.0001\n",
      "Epoch 18, Step: 877, Loss: 0.00655350461602211, Lr:0.0001\n",
      "Epoch 18, Step: 878, Loss: 0.07588127255439758, Lr:0.0001\n",
      "Epoch 18, Step: 879, Loss: 0.07301250100135803, Lr:0.0001\n",
      "Epoch 18, Step: 880, Loss: 0.16414959728717804, Lr:0.0001\n",
      "Epoch 18, Step: 881, Loss: 0.07040728628635406, Lr:0.0001\n",
      "Epoch 18, Step: 882, Loss: 0.16290302574634552, Lr:0.0001\n",
      "Epoch 18, Step: 883, Loss: 0.0844978541135788, Lr:0.0001\n",
      "Epoch 18, Step: 884, Loss: 0.07634080946445465, Lr:0.0001\n",
      "Epoch 18, Step: 885, Loss: 0.013147091493010521, Lr:0.0001\n",
      "Epoch 18, Step: 886, Loss: 0.037908885627985, Lr:0.0001\n",
      "Epoch 18, Step: 887, Loss: 0.017909647896885872, Lr:0.0001\n",
      "Epoch 18, Step: 888, Loss: 0.20915193855762482, Lr:0.0001\n",
      "Epoch 18, Step: 889, Loss: 0.03948739543557167, Lr:0.0001\n",
      "Epoch 18, Step: 890, Loss: 0.025486545637249947, Lr:0.0001\n",
      "Epoch 18, Step: 891, Loss: 0.05277075991034508, Lr:0.0001\n",
      "Epoch 18, Step: 892, Loss: 0.2311166673898697, Lr:0.0001\n",
      "Epoch 18, Step: 893, Loss: 0.0007891174172982574, Lr:0.0001\n",
      "Epoch 18, Step: 894, Loss: 0.030156169086694717, Lr:0.0001\n",
      "Epoch 18, Step: 895, Loss: 0.0925649106502533, Lr:0.0001\n",
      "Epoch 18, Step: 896, Loss: 0.031597234308719635, Lr:0.0001\n",
      "Epoch 18, Step: 897, Loss: 0.024974210187792778, Lr:0.0001\n",
      "Epoch 18, Step: 898, Loss: 0.2081405222415924, Lr:0.0001\n",
      "Epoch 18, Step: 899, Loss: 0.039279960095882416, Lr:0.0001\n",
      "Epoch 18, Step: 900, Loss: 0.07507602125406265, Lr:0.0001\n",
      "Epoch 18, Step: 901, Loss: 0.05174224078655243, Lr:0.0001\n",
      "Epoch 18, Step: 902, Loss: 0.2629859447479248, Lr:0.0001\n",
      "Epoch 18, Step: 903, Loss: 0.06141047552227974, Lr:0.0001\n",
      "Epoch 18, Step: 904, Loss: 0.008504764176905155, Lr:0.0001\n",
      "Epoch 18, Step: 905, Loss: 0.03476552292704582, Lr:0.0001\n",
      "Epoch 18, Step: 906, Loss: 0.2555939853191376, Lr:0.0001\n",
      "Epoch 18, Step: 907, Loss: 0.024655422195792198, Lr:0.0001\n",
      "Epoch 18, Step: 908, Loss: 0.06776101142168045, Lr:0.0001\n",
      "Epoch 18, Step: 909, Loss: 0.15759426355361938, Lr:0.0001\n",
      "Epoch 18, Step: 910, Loss: 0.050516001880168915, Lr:0.0001\n",
      "Epoch 18, Step: 911, Loss: 0.009281598031520844, Lr:0.0001\n",
      "Epoch 18, Step: 912, Loss: 0.00914826150983572, Lr:0.0001\n",
      "Epoch 18, Step: 913, Loss: 0.006891363766044378, Lr:0.0001\n",
      "Epoch 18, Step: 914, Loss: 0.24314871430397034, Lr:0.0001\n",
      "Epoch 18, Step: 915, Loss: 0.12275564670562744, Lr:0.0001\n",
      "Epoch 18, Step: 916, Loss: 0.10753708332777023, Lr:0.0001\n",
      "Epoch 18, Step: 917, Loss: 0.02907879278063774, Lr:0.0001\n",
      "Epoch 18, Step: 918, Loss: 0.031028583645820618, Lr:0.0001\n",
      "Epoch 18, Step: 919, Loss: 0.027249304577708244, Lr:0.0001\n",
      "Epoch 18, Step: 920, Loss: 0.13090689480304718, Lr:0.0001\n",
      "Epoch 18, Step: 921, Loss: 0.08939974009990692, Lr:0.0001\n",
      "Epoch 18, Step: 922, Loss: 0.15729543566703796, Lr:0.0001\n",
      "Epoch 18, Step: 923, Loss: 0.008931145071983337, Lr:0.0001\n",
      "Epoch 18, Step: 924, Loss: 0.007440680172294378, Lr:0.0001\n",
      "Epoch 18, Step: 925, Loss: 0.28556060791015625, Lr:0.0001\n",
      "Epoch 18, Step: 926, Loss: 0.016110092401504517, Lr:0.0001\n",
      "Epoch 18, Step: 927, Loss: 0.0034519555047154427, Lr:0.0001\n",
      "Epoch 18, Step: 928, Loss: 0.049749527126550674, Lr:0.0001\n",
      "Epoch 18, Step: 929, Loss: 0.019519537687301636, Lr:0.0001\n",
      "Epoch 18, Step: 930, Loss: 0.007741681300103664, Lr:0.0001\n",
      "Epoch 18, Step: 931, Loss: 0.0061205611564219, Lr:0.0001\n",
      "Epoch 18, Step: 932, Loss: 0.0342155285179615, Lr:0.0001\n",
      "Epoch 18, Step: 933, Loss: 0.03178614005446434, Lr:0.0001\n",
      "Epoch 18, Step: 934, Loss: 0.23714594542980194, Lr:0.0001\n",
      "Epoch 18, Step: 935, Loss: 0.13679565489292145, Lr:0.0001\n",
      "Epoch 18, Step: 936, Loss: 0.09478256851434708, Lr:0.0001\n",
      "Epoch 18, Step: 937, Loss: 0.1140388771891594, Lr:0.0001\n",
      "Epoch 18, Step: 938, Loss: 0.1210138127207756, Lr:0.0001\n",
      "Epoch 18, Step: 939, Loss: 0.016603372991085052, Lr:0.0001\n",
      "Epoch 18, Step: 940, Loss: 0.03745801001787186, Lr:0.0001\n",
      "Epoch 18, Step: 941, Loss: 0.023012716323137283, Lr:0.0001\n",
      "Epoch 18, Step: 942, Loss: 0.021122967824339867, Lr:0.0001\n",
      "Epoch 18, Step: 943, Loss: 0.09017026424407959, Lr:0.0001\n",
      "Epoch 18, Step: 944, Loss: 0.1141880601644516, Lr:0.0001\n",
      "Epoch 18, Step: 945, Loss: 0.059636205434799194, Lr:0.0001\n",
      "Epoch 18, Step: 946, Loss: 0.010978792794048786, Lr:0.0001\n",
      "Epoch 18, Step: 947, Loss: 0.077924445271492, Lr:0.0001\n",
      "Epoch 18, Step: 948, Loss: 0.0544409304857254, Lr:0.0001\n",
      "Epoch 18, Step: 949, Loss: 0.3674273192882538, Lr:0.0001\n",
      "Epoch 18, Step: 950, Loss: 0.008534866385161877, Lr:0.0001\n",
      "Epoch 18, Step: 951, Loss: 0.005283995997160673, Lr:0.0001\n",
      "Epoch 18, Step: 952, Loss: 0.10646001249551773, Lr:0.0001\n",
      "Epoch 18, Step: 953, Loss: 0.12967664003372192, Lr:0.0001\n",
      "Epoch 18, Step: 954, Loss: 0.048901453614234924, Lr:0.0001\n",
      "Epoch 18, Step: 955, Loss: 0.028343375772237778, Lr:0.0001\n",
      "Epoch 18, Step: 956, Loss: 0.2010136842727661, Lr:0.0001\n",
      "Epoch 18, Step: 957, Loss: 0.07370983064174652, Lr:0.0001\n",
      "Epoch 18, Step: 958, Loss: 0.011322827078402042, Lr:0.0001\n",
      "Epoch 18, Step: 959, Loss: 0.09191694110631943, Lr:0.0001\n",
      "Epoch 18, Step: 960, Loss: 0.19742320477962494, Lr:0.0001\n",
      "Epoch 18, Step: 961, Loss: 0.26199930906295776, Lr:0.0001\n",
      "Epoch 18, Step: 962, Loss: 0.051444392651319504, Lr:0.0001\n",
      "Epoch 18, Step: 963, Loss: 0.16738177835941315, Lr:0.0001\n",
      "Epoch 18, Step: 964, Loss: 0.014486894011497498, Lr:0.0001\n",
      "Epoch 18, Step: 965, Loss: 0.014679981395602226, Lr:0.0001\n",
      "Epoch 18, Step: 966, Loss: 0.0472194068133831, Lr:0.0001\n",
      "Epoch 18, Step: 967, Loss: 0.02544361725449562, Lr:0.0001\n",
      "Epoch 18, Step: 968, Loss: 0.14731286466121674, Lr:0.0001\n",
      "Epoch 18, Step: 969, Loss: 0.15435245633125305, Lr:0.0001\n",
      "Epoch 18, Step: 970, Loss: 0.016091303899884224, Lr:0.0001\n",
      "Epoch 18, Step: 971, Loss: 0.015490030869841576, Lr:0.0001\n",
      "Epoch 18, Step: 972, Loss: 0.028388826176524162, Lr:0.0001\n",
      "Epoch 18, Step: 973, Loss: 0.06162899732589722, Lr:0.0001\n",
      "Epoch 18, Step: 974, Loss: 0.10294373333454132, Lr:0.0001\n",
      "Epoch 18, Step: 975, Loss: 0.040281202644109726, Lr:0.0001\n",
      "Epoch 18, Step: 976, Loss: 0.07404130697250366, Lr:0.0001\n",
      "Epoch 18, Step: 977, Loss: 0.16655603051185608, Lr:0.0001\n",
      "Epoch 18, Step: 978, Loss: 0.04725571349263191, Lr:0.0001\n",
      "Epoch 18, Step: 979, Loss: 0.1368183195590973, Lr:0.0001\n",
      "Epoch 18, Step: 980, Loss: 0.02882407233119011, Lr:0.0001\n",
      "Epoch 18, Step: 981, Loss: 0.29542040824890137, Lr:0.0001\n",
      "Epoch 18, Step: 982, Loss: 0.016637688502669334, Lr:0.0001\n",
      "Epoch 18, Step: 983, Loss: 0.0013680332340300083, Lr:0.0001\n",
      "Epoch 18, Step: 984, Loss: 0.07179395109415054, Lr:0.0001\n",
      "Epoch 18, Step: 985, Loss: 0.015092343091964722, Lr:0.0001\n",
      "Epoch 18, Step: 986, Loss: 0.019467396661639214, Lr:0.0001\n",
      "Epoch 18, Step: 987, Loss: 0.2648050785064697, Lr:0.0001\n",
      "Epoch 18, Step: 988, Loss: 0.018376903608441353, Lr:0.0001\n",
      "Epoch 18, Step: 989, Loss: 0.10937164723873138, Lr:0.0001\n",
      "Epoch 18, Step: 990, Loss: 0.12236429005861282, Lr:0.0001\n",
      "Epoch 18, Step: 991, Loss: 0.0078000156208872795, Lr:0.0001\n",
      "Epoch 18, Step: 992, Loss: 0.11312717199325562, Lr:0.0001\n",
      "Epoch 18, Step: 993, Loss: 0.027983127161860466, Lr:0.0001\n",
      "Epoch 18, Step: 994, Loss: 0.03804000839591026, Lr:0.0001\n",
      "Epoch 18, Step: 995, Loss: 0.3847062587738037, Lr:0.0001\n",
      "Epoch 18, Step: 996, Loss: 0.25887566804885864, Lr:0.0001\n",
      "Epoch 18, Step: 997, Loss: 0.03101726435124874, Lr:0.0001\n",
      "Epoch 18, Step: 998, Loss: 0.02138906717300415, Lr:0.0001\n",
      "Epoch 18, Step: 999, Loss: 0.3234315514564514, Lr:0.0001\n",
      "Epoch 18, Step: 1000, Loss: 0.14443737268447876, Lr:0.0001\n",
      "Epoch 18, Step: 1001, Loss: 0.11637992411851883, Lr:0.0001\n",
      "Epoch 18, Step: 1002, Loss: 0.017434677109122276, Lr:0.0001\n",
      "Epoch 18, Step: 1003, Loss: 0.044854793697595596, Lr:0.0001\n",
      "Epoch 18, Step: 1004, Loss: 0.024490708485245705, Lr:0.0001\n",
      "Epoch 18, Step: 1005, Loss: 0.004747553262859583, Lr:0.0001\n",
      "Epoch 18, Step: 1006, Loss: 0.008657015860080719, Lr:0.0001\n",
      "Epoch 18, Step: 1007, Loss: 0.005306590348482132, Lr:0.0001\n",
      "Epoch 18, Step: 1008, Loss: 0.01237989217042923, Lr:0.0001\n",
      "Epoch 18, Step: 1009, Loss: 0.12436656653881073, Lr:0.0001\n",
      "Epoch 18, Step: 1010, Loss: 0.12176204472780228, Lr:0.0001\n",
      "Epoch 18, Step: 1011, Loss: 0.01481880433857441, Lr:0.0001\n",
      "Epoch 18, Step: 1012, Loss: 0.060786183923482895, Lr:0.0001\n",
      "Epoch 18, Step: 1013, Loss: 0.23855750262737274, Lr:0.0001\n",
      "Epoch 18, Step: 1014, Loss: 0.025109361857175827, Lr:0.0001\n",
      "Epoch 18, Step: 1015, Loss: 0.1694095879793167, Lr:0.0001\n",
      "Epoch 18, Step: 1016, Loss: 0.027781907469034195, Lr:0.0001\n",
      "Epoch 18, Step: 1017, Loss: 0.011111284606158733, Lr:0.0001\n",
      "Epoch 18, Step: 1018, Loss: 0.3387458920478821, Lr:0.0001\n",
      "Epoch 18, Step: 1019, Loss: 0.0840659812092781, Lr:0.0001\n",
      "Epoch 18, Step: 1020, Loss: 0.013068575412034988, Lr:0.0001\n",
      "Epoch 18, Step: 1021, Loss: 0.10760433971881866, Lr:0.0001\n",
      "Epoch 18, Step: 1022, Loss: 0.013682699762284756, Lr:0.0001\n",
      "Epoch 18, Step: 1023, Loss: 0.04461102932691574, Lr:0.0001\n",
      "Epoch 18, Step: 1024, Loss: 0.2548772096633911, Lr:0.0001\n",
      "Epoch 18, Step: 1025, Loss: 0.0034667591098695993, Lr:0.0001\n",
      "Epoch 18, Step: 1026, Loss: 0.0626068040728569, Lr:0.0001\n",
      "Epoch 18, Step: 1027, Loss: 0.06203192099928856, Lr:0.0001\n",
      "Epoch 18, Step: 1028, Loss: 0.574975848197937, Lr:0.0001\n",
      "Epoch 18, Step: 1029, Loss: 0.33631426095962524, Lr:0.0001\n",
      "Epoch 18, Step: 1030, Loss: 0.12859851121902466, Lr:0.0001\n",
      "Epoch 18, Step: 1031, Loss: 0.18161335587501526, Lr:0.0001\n",
      "Epoch 18, Step: 1032, Loss: 0.05007603392004967, Lr:0.0001\n",
      "Epoch 18, Step: 1033, Loss: 0.02046746201813221, Lr:0.0001\n",
      "Epoch 18, Step: 1034, Loss: 0.3934904634952545, Lr:0.0001\n",
      "Epoch 18, Step: 1035, Loss: 0.08868475258350372, Lr:0.0001\n",
      "Epoch 18, Step: 1036, Loss: 0.09228486567735672, Lr:0.0001\n",
      "Epoch 18, Step: 1037, Loss: 0.15890561044216156, Lr:0.0001\n",
      "Epoch 18, Step: 1038, Loss: 0.028619349002838135, Lr:0.0001\n",
      "Epoch 18, Step: 1039, Loss: 0.019750254228711128, Lr:0.0001\n",
      "Epoch 18, Step: 1040, Loss: 0.052058909088373184, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 18\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:15 loss: 0.5160 (0.5160) acc1: 93.7500 (93.7500) acc5: 100.0000 (100.0000) time: 0.2855 data: 0.1065 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:12 loss: 0.0014 (0.0693) acc1: 100.0000 (98.8636) acc5: 100.0000 (100.0000) time: 0.2813 data: 0.1067 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0020 (0.0891) acc1: 100.0000 (97.0238) acc5: 100.0000 (100.0000) time: 0.2815 data: 0.1073 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.0672 (0.1758) acc1: 93.7500 (94.9597) acc5: 100.0000 (100.0000) time: 0.2844 data: 0.1097 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.0760 (0.1677) acc1: 93.7500 (95.1220) acc5: 100.0000 (100.0000) time: 0.2857 data: 0.1130 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0760 (0.1593) acc1: 93.7500 (95.2206) acc5: 100.0000 (100.0000) time: 0.2875 data: 0.1149 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0249 (0.1551) acc1: 100.0000 (95.3462) acc5: 100.0000 (100.0000) time: 0.2745 data: 0.1083 max mem: 15137\n",
      "Test: Total time: 0:00:15 (0.2804 s / it)\n",
      "* Acc@1 95.346 Acc@5 100.000 loss 0.155\n",
      "Accuracy of the network on the 881 test image: 95.3%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 19, Step: 0, Loss: 0.15434718132019043, Lr:0.0001\n",
      "Epoch 19, Step: 1, Loss: 0.09309890121221542, Lr:0.0001\n",
      "Epoch 19, Step: 2, Loss: 0.02075635828077793, Lr:0.0001\n",
      "Epoch 19, Step: 3, Loss: 0.05974398925900459, Lr:0.0001\n",
      "Epoch 19, Step: 4, Loss: 0.09032013267278671, Lr:0.0001\n",
      "Epoch 19, Step: 5, Loss: 0.07494263350963593, Lr:0.0001\n",
      "Epoch 19, Step: 6, Loss: 0.0292871855199337, Lr:0.0001\n",
      "Epoch 19, Step: 7, Loss: 0.012605231255292892, Lr:0.0001\n",
      "Epoch 19, Step: 8, Loss: 0.2929559648036957, Lr:0.0001\n",
      "Epoch 19, Step: 9, Loss: 0.06933858245611191, Lr:0.0001\n",
      "Epoch 19, Step: 10, Loss: 0.24170106649398804, Lr:0.0001\n",
      "Epoch 19, Step: 11, Loss: 0.144797220826149, Lr:0.0001\n",
      "Epoch 19, Step: 12, Loss: 0.07197704911231995, Lr:0.0001\n",
      "Epoch 19, Step: 13, Loss: 0.18840865790843964, Lr:0.0001\n",
      "Epoch 19, Step: 14, Loss: 0.09011811017990112, Lr:0.0001\n",
      "Epoch 19, Step: 15, Loss: 0.11439831554889679, Lr:0.0001\n",
      "Epoch 19, Step: 16, Loss: 0.14436613023281097, Lr:0.0001\n",
      "Epoch 19, Step: 17, Loss: 0.062174342572689056, Lr:0.0001\n",
      "Epoch 19, Step: 18, Loss: 0.005081475712358952, Lr:0.0001\n",
      "Epoch 19, Step: 19, Loss: 0.05318991839885712, Lr:0.0001\n",
      "Epoch 19, Step: 20, Loss: 0.3164645731449127, Lr:0.0001\n",
      "Epoch 19, Step: 21, Loss: 0.059155236929655075, Lr:0.0001\n",
      "Epoch 19, Step: 22, Loss: 0.2551749348640442, Lr:0.0001\n",
      "Epoch 19, Step: 23, Loss: 0.05043630301952362, Lr:0.0001\n",
      "Epoch 19, Step: 24, Loss: 0.08370563387870789, Lr:0.0001\n",
      "Epoch 19, Step: 25, Loss: 0.014292620122432709, Lr:0.0001\n",
      "Epoch 19, Step: 26, Loss: 0.059948474168777466, Lr:0.0001\n",
      "Epoch 19, Step: 27, Loss: 0.008374152705073357, Lr:0.0001\n",
      "Epoch 19, Step: 28, Loss: 0.007419436704367399, Lr:0.0001\n",
      "Epoch 19, Step: 29, Loss: 0.06275632232427597, Lr:0.0001\n",
      "Epoch 19, Step: 30, Loss: 0.1383875459432602, Lr:0.0001\n",
      "Epoch 19, Step: 31, Loss: 0.12019834667444229, Lr:0.0001\n",
      "Epoch 19, Step: 32, Loss: 0.12624338269233704, Lr:0.0001\n",
      "Epoch 19, Step: 33, Loss: 0.06286493688821793, Lr:0.0001\n",
      "Epoch 19, Step: 34, Loss: 0.10134118795394897, Lr:0.0001\n",
      "Epoch 19, Step: 35, Loss: 0.0707787573337555, Lr:0.0001\n",
      "Epoch 19, Step: 36, Loss: 0.054140083491802216, Lr:0.0001\n",
      "Epoch 19, Step: 37, Loss: 0.17497414350509644, Lr:0.0001\n",
      "Epoch 19, Step: 38, Loss: 0.06630650162696838, Lr:0.0001\n",
      "Epoch 19, Step: 39, Loss: 0.0790787860751152, Lr:0.0001\n",
      "Epoch 19, Step: 40, Loss: 0.4704402983188629, Lr:0.0001\n",
      "Epoch 19, Step: 41, Loss: 0.04188619181513786, Lr:0.0001\n",
      "Epoch 19, Step: 42, Loss: 0.03203152120113373, Lr:0.0001\n",
      "Epoch 19, Step: 43, Loss: 0.0491265133023262, Lr:0.0001\n",
      "Epoch 19, Step: 44, Loss: 0.07117543369531631, Lr:0.0001\n",
      "Epoch 19, Step: 45, Loss: 0.0172811858355999, Lr:0.0001\n",
      "Epoch 19, Step: 46, Loss: 0.015277287922799587, Lr:0.0001\n",
      "Epoch 19, Step: 47, Loss: 0.07999511063098907, Lr:0.0001\n",
      "Epoch 19, Step: 48, Loss: 0.048961494117975235, Lr:0.0001\n",
      "Epoch 19, Step: 49, Loss: 0.0563165619969368, Lr:0.0001\n",
      "Epoch 19, Step: 50, Loss: 0.047088030725717545, Lr:0.0001\n",
      "Epoch 19, Step: 51, Loss: 0.004939899314194918, Lr:0.0001\n",
      "Epoch 19, Step: 52, Loss: 0.06421010941267014, Lr:0.0001\n",
      "Epoch 19, Step: 53, Loss: 0.170577272772789, Lr:0.0001\n",
      "Epoch 19, Step: 54, Loss: 0.32768526673316956, Lr:0.0001\n",
      "Epoch 19, Step: 55, Loss: 0.09368502348661423, Lr:0.0001\n",
      "Epoch 19, Step: 56, Loss: 0.023797880858182907, Lr:0.0001\n",
      "Epoch 19, Step: 57, Loss: 0.04994931071996689, Lr:0.0001\n",
      "Epoch 19, Step: 58, Loss: 0.22809268534183502, Lr:0.0001\n",
      "Epoch 19, Step: 59, Loss: 0.04455144330859184, Lr:0.0001\n",
      "Epoch 19, Step: 60, Loss: 0.020602257922291756, Lr:0.0001\n",
      "Epoch 19, Step: 61, Loss: 0.04721687361598015, Lr:0.0001\n",
      "Epoch 19, Step: 62, Loss: 0.031244825571775436, Lr:0.0001\n",
      "Epoch 19, Step: 63, Loss: 0.09396487474441528, Lr:0.0001\n",
      "Epoch 19, Step: 64, Loss: 0.012918291613459587, Lr:0.0001\n",
      "Epoch 19, Step: 65, Loss: 0.03544114530086517, Lr:0.0001\n",
      "Epoch 19, Step: 66, Loss: 0.010645412839949131, Lr:0.0001\n",
      "Epoch 19, Step: 67, Loss: 0.03678132966160774, Lr:0.0001\n",
      "Epoch 19, Step: 68, Loss: 0.0753636285662651, Lr:0.0001\n",
      "Epoch 19, Step: 69, Loss: 0.03571457043290138, Lr:0.0001\n",
      "Epoch 19, Step: 70, Loss: 0.017045319080352783, Lr:0.0001\n",
      "Epoch 19, Step: 71, Loss: 0.07335225492715836, Lr:0.0001\n",
      "Epoch 19, Step: 72, Loss: 0.02281823754310608, Lr:0.0001\n",
      "Epoch 19, Step: 73, Loss: 0.031982421875, Lr:0.0001\n",
      "Epoch 19, Step: 74, Loss: 0.024966131895780563, Lr:0.0001\n",
      "Epoch 19, Step: 75, Loss: 0.03179238736629486, Lr:0.0001\n",
      "Epoch 19, Step: 76, Loss: 0.23052886128425598, Lr:0.0001\n",
      "Epoch 19, Step: 77, Loss: 0.010913202539086342, Lr:0.0001\n",
      "Epoch 19, Step: 78, Loss: 0.0904962420463562, Lr:0.0001\n",
      "Epoch 19, Step: 79, Loss: 0.18376654386520386, Lr:0.0001\n",
      "Epoch 19, Step: 80, Loss: 0.04647962003946304, Lr:0.0001\n",
      "Epoch 19, Step: 81, Loss: 0.0024367766454815865, Lr:0.0001\n",
      "Epoch 19, Step: 82, Loss: 0.02348140999674797, Lr:0.0001\n",
      "Epoch 19, Step: 83, Loss: 0.04831233620643616, Lr:0.0001\n",
      "Epoch 19, Step: 84, Loss: 0.0030686557292938232, Lr:0.0001\n",
      "Epoch 19, Step: 85, Loss: 0.06909903138875961, Lr:0.0001\n",
      "Epoch 19, Step: 86, Loss: 0.04768155887722969, Lr:0.0001\n",
      "Epoch 19, Step: 87, Loss: 0.004955097567290068, Lr:0.0001\n",
      "Epoch 19, Step: 88, Loss: 0.04389436915516853, Lr:0.0001\n",
      "Epoch 19, Step: 89, Loss: 0.09597767144441605, Lr:0.0001\n",
      "Epoch 19, Step: 90, Loss: 0.01576676219701767, Lr:0.0001\n",
      "Epoch 19, Step: 91, Loss: 0.015425551682710648, Lr:0.0001\n",
      "Epoch 19, Step: 92, Loss: 0.02253401093184948, Lr:0.0001\n",
      "Epoch 19, Step: 93, Loss: 0.19037769734859467, Lr:0.0001\n",
      "Epoch 19, Step: 94, Loss: 0.04929302632808685, Lr:0.0001\n",
      "Epoch 19, Step: 95, Loss: 0.024549895897507668, Lr:0.0001\n",
      "Epoch 19, Step: 96, Loss: 0.02175814099609852, Lr:0.0001\n",
      "Epoch 19, Step: 97, Loss: 0.03561462461948395, Lr:0.0001\n",
      "Epoch 19, Step: 98, Loss: 0.14872592687606812, Lr:0.0001\n",
      "Epoch 19, Step: 99, Loss: 0.020566636696457863, Lr:0.0001\n",
      "Epoch 19, Step: 100, Loss: 0.11044689267873764, Lr:0.0001\n",
      "Epoch 19, Step: 101, Loss: 0.14120736718177795, Lr:0.0001\n",
      "Epoch 19, Step: 102, Loss: 0.07856694608926773, Lr:0.0001\n",
      "Epoch 19, Step: 103, Loss: 0.12729160487651825, Lr:0.0001\n",
      "Epoch 19, Step: 104, Loss: 0.053035326302051544, Lr:0.0001\n",
      "Epoch 19, Step: 105, Loss: 0.07553277909755707, Lr:0.0001\n",
      "Epoch 19, Step: 106, Loss: 0.02868315577507019, Lr:0.0001\n",
      "Epoch 19, Step: 107, Loss: 0.03478982299566269, Lr:0.0001\n",
      "Epoch 19, Step: 108, Loss: 0.18410488963127136, Lr:0.0001\n",
      "Epoch 19, Step: 109, Loss: 0.024117249995470047, Lr:0.0001\n",
      "Epoch 19, Step: 110, Loss: 0.06652937084436417, Lr:0.0001\n",
      "Epoch 19, Step: 111, Loss: 0.002591641154140234, Lr:0.0001\n",
      "Epoch 19, Step: 112, Loss: 0.028243310749530792, Lr:0.0001\n",
      "Epoch 19, Step: 113, Loss: 0.1069253608584404, Lr:0.0001\n",
      "Epoch 19, Step: 114, Loss: 0.04159598797559738, Lr:0.0001\n",
      "Epoch 19, Step: 115, Loss: 0.1309313178062439, Lr:0.0001\n",
      "Epoch 19, Step: 116, Loss: 0.09244450181722641, Lr:0.0001\n",
      "Epoch 19, Step: 117, Loss: 0.009684659540653229, Lr:0.0001\n",
      "Epoch 19, Step: 118, Loss: 0.008920609951019287, Lr:0.0001\n",
      "Epoch 19, Step: 119, Loss: 0.005087673664093018, Lr:0.0001\n",
      "Epoch 19, Step: 120, Loss: 0.10328524559736252, Lr:0.0001\n",
      "Epoch 19, Step: 121, Loss: 0.009878435172140598, Lr:0.0001\n",
      "Epoch 19, Step: 122, Loss: 0.01557860802859068, Lr:0.0001\n",
      "Epoch 19, Step: 123, Loss: 0.0219452865421772, Lr:0.0001\n",
      "Epoch 19, Step: 124, Loss: 0.01993458904325962, Lr:0.0001\n",
      "Epoch 19, Step: 125, Loss: 0.014068127609789371, Lr:0.0001\n",
      "Epoch 19, Step: 126, Loss: 0.02003316767513752, Lr:0.0001\n",
      "Epoch 19, Step: 127, Loss: 0.02740105241537094, Lr:0.0001\n",
      "Epoch 19, Step: 128, Loss: 0.03726726397871971, Lr:0.0001\n",
      "Epoch 19, Step: 129, Loss: 0.028306329622864723, Lr:0.0001\n",
      "Epoch 19, Step: 130, Loss: 0.017343079671263695, Lr:0.0001\n",
      "Epoch 19, Step: 131, Loss: 0.0795375257730484, Lr:0.0001\n",
      "Epoch 19, Step: 132, Loss: 0.01660369336605072, Lr:0.0001\n",
      "Epoch 19, Step: 133, Loss: 0.0063084810972213745, Lr:0.0001\n",
      "Epoch 19, Step: 134, Loss: 0.023079484701156616, Lr:0.0001\n",
      "Epoch 19, Step: 135, Loss: 0.014047395437955856, Lr:0.0001\n",
      "Epoch 19, Step: 136, Loss: 0.043238382786512375, Lr:0.0001\n",
      "Epoch 19, Step: 137, Loss: 0.13414305448532104, Lr:0.0001\n",
      "Epoch 19, Step: 138, Loss: 0.06151397526264191, Lr:0.0001\n",
      "Epoch 19, Step: 139, Loss: 0.005224225111305714, Lr:0.0001\n",
      "Epoch 19, Step: 140, Loss: 0.010844186879694462, Lr:0.0001\n",
      "Epoch 19, Step: 141, Loss: 0.004488184116780758, Lr:0.0001\n",
      "Epoch 19, Step: 142, Loss: 0.06349452584981918, Lr:0.0001\n",
      "Epoch 19, Step: 143, Loss: 0.009128352627158165, Lr:0.0001\n",
      "Epoch 19, Step: 144, Loss: 0.017595065757632256, Lr:0.0001\n",
      "Epoch 19, Step: 145, Loss: 0.07235321402549744, Lr:0.0001\n",
      "Epoch 19, Step: 146, Loss: 0.051649123430252075, Lr:0.0001\n",
      "Epoch 19, Step: 147, Loss: 0.03174600005149841, Lr:0.0001\n",
      "Epoch 19, Step: 148, Loss: 0.1916363686323166, Lr:0.0001\n",
      "Epoch 19, Step: 149, Loss: 0.0033636107109487057, Lr:0.0001\n",
      "Epoch 19, Step: 150, Loss: 0.03999261558055878, Lr:0.0001\n",
      "Epoch 19, Step: 151, Loss: 0.17172649502754211, Lr:0.0001\n",
      "Epoch 19, Step: 152, Loss: 0.10782741010189056, Lr:0.0001\n",
      "Epoch 19, Step: 153, Loss: 0.02880028635263443, Lr:0.0001\n",
      "Epoch 19, Step: 154, Loss: 0.07800881564617157, Lr:0.0001\n",
      "Epoch 19, Step: 155, Loss: 0.006746470928192139, Lr:0.0001\n",
      "Epoch 19, Step: 156, Loss: 0.019952131435275078, Lr:0.0001\n",
      "Epoch 19, Step: 157, Loss: 0.0802941843867302, Lr:0.0001\n",
      "Epoch 19, Step: 158, Loss: 0.1307288557291031, Lr:0.0001\n",
      "Epoch 19, Step: 159, Loss: 0.002549391472712159, Lr:0.0001\n",
      "Epoch 19, Step: 160, Loss: 0.009757540188729763, Lr:0.0001\n",
      "Epoch 19, Step: 161, Loss: 0.028594087809324265, Lr:0.0001\n",
      "Epoch 19, Step: 162, Loss: 0.09889283776283264, Lr:0.0001\n",
      "Epoch 19, Step: 163, Loss: 0.004444291349500418, Lr:0.0001\n",
      "Epoch 19, Step: 164, Loss: 0.012603272683918476, Lr:0.0001\n",
      "Epoch 19, Step: 165, Loss: 0.1491464376449585, Lr:0.0001\n",
      "Epoch 19, Step: 166, Loss: 0.16180314123630524, Lr:0.0001\n",
      "Epoch 19, Step: 167, Loss: 0.011250467039644718, Lr:0.0001\n",
      "Epoch 19, Step: 168, Loss: 0.004017321392893791, Lr:0.0001\n",
      "Epoch 19, Step: 169, Loss: 0.04428869113326073, Lr:0.0001\n",
      "Epoch 19, Step: 170, Loss: 0.0035041801165789366, Lr:0.0001\n",
      "Epoch 19, Step: 171, Loss: 0.07177126407623291, Lr:0.0001\n",
      "Epoch 19, Step: 172, Loss: 0.0077102528885006905, Lr:0.0001\n",
      "Epoch 19, Step: 173, Loss: 0.0038975204806774855, Lr:0.0001\n",
      "Epoch 19, Step: 174, Loss: 0.030082929879426956, Lr:0.0001\n",
      "Epoch 19, Step: 175, Loss: 0.0004922306980006397, Lr:0.0001\n",
      "Epoch 19, Step: 176, Loss: 0.37695565819740295, Lr:0.0001\n",
      "Epoch 19, Step: 177, Loss: 0.02199888974428177, Lr:0.0001\n",
      "Epoch 19, Step: 178, Loss: 0.005558631848543882, Lr:0.0001\n",
      "Epoch 19, Step: 179, Loss: 0.00637061009183526, Lr:0.0001\n",
      "Epoch 19, Step: 180, Loss: 0.2478942573070526, Lr:0.0001\n",
      "Epoch 19, Step: 181, Loss: 0.09550207108259201, Lr:0.0001\n",
      "Epoch 19, Step: 182, Loss: 0.09303499758243561, Lr:0.0001\n",
      "Epoch 19, Step: 183, Loss: 0.052625060081481934, Lr:0.0001\n",
      "Epoch 19, Step: 184, Loss: 0.0012764218263328075, Lr:0.0001\n",
      "Epoch 19, Step: 185, Loss: 0.010678252205252647, Lr:0.0001\n",
      "Epoch 19, Step: 186, Loss: 0.02445858344435692, Lr:0.0001\n",
      "Epoch 19, Step: 187, Loss: 0.08000195026397705, Lr:0.0001\n",
      "Epoch 19, Step: 188, Loss: 0.1791934370994568, Lr:0.0001\n",
      "Epoch 19, Step: 189, Loss: 0.1372554451227188, Lr:0.0001\n",
      "Epoch 19, Step: 190, Loss: 0.04025767371058464, Lr:0.0001\n",
      "Epoch 19, Step: 191, Loss: 0.03422598913311958, Lr:0.0001\n",
      "Epoch 19, Step: 192, Loss: 0.006020096596330404, Lr:0.0001\n",
      "Epoch 19, Step: 193, Loss: 0.15838444232940674, Lr:0.0001\n",
      "Epoch 19, Step: 194, Loss: 0.1536966860294342, Lr:0.0001\n",
      "Epoch 19, Step: 195, Loss: 0.024597644805908203, Lr:0.0001\n",
      "Epoch 19, Step: 196, Loss: 0.08661311119794846, Lr:0.0001\n",
      "Epoch 19, Step: 197, Loss: 0.06791772693395615, Lr:0.0001\n",
      "Epoch 19, Step: 198, Loss: 0.010018376633524895, Lr:0.0001\n",
      "Epoch 19, Step: 199, Loss: 0.03133874014019966, Lr:0.0001\n",
      "Epoch 19, Step: 200, Loss: 0.12830984592437744, Lr:0.0001\n",
      "Epoch 19, Step: 201, Loss: 0.0056483629159629345, Lr:0.0001\n",
      "Epoch 19, Step: 202, Loss: 0.4681676924228668, Lr:0.0001\n",
      "Epoch 19, Step: 203, Loss: 0.0946161076426506, Lr:0.0001\n",
      "Epoch 19, Step: 204, Loss: 0.044143468141555786, Lr:0.0001\n",
      "Epoch 19, Step: 205, Loss: 0.023386895656585693, Lr:0.0001\n",
      "Epoch 19, Step: 206, Loss: 0.02859690599143505, Lr:0.0001\n",
      "Epoch 19, Step: 207, Loss: 0.039832912385463715, Lr:0.0001\n",
      "Epoch 19, Step: 208, Loss: 0.022617846727371216, Lr:0.0001\n",
      "Epoch 19, Step: 209, Loss: 0.1403014212846756, Lr:0.0001\n",
      "Epoch 19, Step: 210, Loss: 0.07245385646820068, Lr:0.0001\n",
      "Epoch 19, Step: 211, Loss: 0.06992218643426895, Lr:0.0001\n",
      "Epoch 19, Step: 212, Loss: 0.009287782944738865, Lr:0.0001\n",
      "Epoch 19, Step: 213, Loss: 0.05744156241416931, Lr:0.0001\n",
      "Epoch 19, Step: 214, Loss: 0.27943098545074463, Lr:0.0001\n",
      "Epoch 19, Step: 215, Loss: 0.195513516664505, Lr:0.0001\n",
      "Epoch 19, Step: 216, Loss: 0.07776788622140884, Lr:0.0001\n",
      "Epoch 19, Step: 217, Loss: 0.10047267377376556, Lr:0.0001\n",
      "Epoch 19, Step: 218, Loss: 0.004843713715672493, Lr:0.0001\n",
      "Epoch 19, Step: 219, Loss: 0.049963951110839844, Lr:0.0001\n",
      "Epoch 19, Step: 220, Loss: 0.01536601223051548, Lr:0.0001\n",
      "Epoch 19, Step: 221, Loss: 0.02040286734700203, Lr:0.0001\n",
      "Epoch 19, Step: 222, Loss: 0.16172800958156586, Lr:0.0001\n",
      "Epoch 19, Step: 223, Loss: 0.02946147695183754, Lr:0.0001\n",
      "Epoch 19, Step: 224, Loss: 0.165335014462471, Lr:0.0001\n",
      "Epoch 19, Step: 225, Loss: 0.034743450582027435, Lr:0.0001\n",
      "Epoch 19, Step: 226, Loss: 0.029029957950115204, Lr:0.0001\n",
      "Epoch 19, Step: 227, Loss: 0.002254488179460168, Lr:0.0001\n",
      "Epoch 19, Step: 228, Loss: 0.04081382229924202, Lr:0.0001\n",
      "Epoch 19, Step: 229, Loss: 0.04691267013549805, Lr:0.0001\n",
      "Epoch 19, Step: 230, Loss: 0.03087969310581684, Lr:0.0001\n",
      "Epoch 19, Step: 231, Loss: 0.00346330925822258, Lr:0.0001\n",
      "Epoch 19, Step: 232, Loss: 1.7535749673843384, Lr:0.0001\n",
      "Epoch 19, Step: 233, Loss: 0.046982526779174805, Lr:0.0001\n",
      "Epoch 19, Step: 234, Loss: 0.03353959321975708, Lr:0.0001\n",
      "Epoch 19, Step: 235, Loss: 0.1975342333316803, Lr:0.0001\n",
      "Epoch 19, Step: 236, Loss: 0.27974987030029297, Lr:0.0001\n",
      "Epoch 19, Step: 237, Loss: 0.060315169394016266, Lr:0.0001\n",
      "Epoch 19, Step: 238, Loss: 0.013488457538187504, Lr:0.0001\n",
      "Epoch 19, Step: 239, Loss: 0.07217740267515182, Lr:0.0001\n",
      "Epoch 19, Step: 240, Loss: 0.03019157610833645, Lr:0.0001\n",
      "Epoch 19, Step: 241, Loss: 0.011493399739265442, Lr:0.0001\n",
      "Epoch 19, Step: 242, Loss: 0.01314100343734026, Lr:0.0001\n",
      "Epoch 19, Step: 243, Loss: 0.001810809480957687, Lr:0.0001\n",
      "Epoch 19, Step: 244, Loss: 0.27262938022613525, Lr:0.0001\n",
      "Epoch 19, Step: 245, Loss: 0.027436692267656326, Lr:0.0001\n",
      "Epoch 19, Step: 246, Loss: 0.03067840076982975, Lr:0.0001\n",
      "Epoch 19, Step: 247, Loss: 0.09824878722429276, Lr:0.0001\n",
      "Epoch 19, Step: 248, Loss: 0.02305537462234497, Lr:0.0001\n",
      "Epoch 19, Step: 249, Loss: 0.052623599767684937, Lr:0.0001\n",
      "Epoch 19, Step: 250, Loss: 0.29264944791793823, Lr:0.0001\n",
      "Epoch 19, Step: 251, Loss: 0.06157304719090462, Lr:0.0001\n",
      "Epoch 19, Step: 252, Loss: 0.039033081382513046, Lr:0.0001\n",
      "Epoch 19, Step: 253, Loss: 0.020016802474856377, Lr:0.0001\n",
      "Epoch 19, Step: 254, Loss: 0.10447265952825546, Lr:0.0001\n",
      "Epoch 19, Step: 255, Loss: 0.25790905952453613, Lr:0.0001\n",
      "Epoch 19, Step: 256, Loss: 0.048673614859580994, Lr:0.0001\n",
      "Epoch 19, Step: 257, Loss: 0.022830627858638763, Lr:0.0001\n",
      "Epoch 19, Step: 258, Loss: 0.02154300920665264, Lr:0.0001\n",
      "Epoch 19, Step: 259, Loss: 0.01116853952407837, Lr:0.0001\n",
      "Epoch 19, Step: 260, Loss: 0.3396129906177521, Lr:0.0001\n",
      "Epoch 19, Step: 261, Loss: 0.10576610267162323, Lr:0.0001\n",
      "Epoch 19, Step: 262, Loss: 0.023680388927459717, Lr:0.0001\n",
      "Epoch 19, Step: 263, Loss: 0.006923763547092676, Lr:0.0001\n",
      "Epoch 19, Step: 264, Loss: 0.023947222158312798, Lr:0.0001\n",
      "Epoch 19, Step: 265, Loss: 0.11894848197698593, Lr:0.0001\n",
      "Epoch 19, Step: 266, Loss: 0.07151158899068832, Lr:0.0001\n",
      "Epoch 19, Step: 267, Loss: 0.041141364723443985, Lr:0.0001\n",
      "Epoch 19, Step: 268, Loss: 0.38518109917640686, Lr:0.0001\n",
      "Epoch 19, Step: 269, Loss: 0.0454346239566803, Lr:0.0001\n",
      "Epoch 19, Step: 270, Loss: 0.07369107753038406, Lr:0.0001\n",
      "Epoch 19, Step: 271, Loss: 0.1568087339401245, Lr:0.0001\n",
      "Epoch 19, Step: 272, Loss: 0.24837791919708252, Lr:0.0001\n",
      "Epoch 19, Step: 273, Loss: 0.0013430999824777246, Lr:0.0001\n",
      "Epoch 19, Step: 274, Loss: 0.02711925283074379, Lr:0.0001\n",
      "Epoch 19, Step: 275, Loss: 0.059505395591259, Lr:0.0001\n",
      "Epoch 19, Step: 276, Loss: 0.01243832428008318, Lr:0.0001\n",
      "Epoch 19, Step: 277, Loss: 0.09532572329044342, Lr:0.0001\n",
      "Epoch 19, Step: 278, Loss: 0.10234181582927704, Lr:0.0001\n",
      "Epoch 19, Step: 279, Loss: 0.285290002822876, Lr:0.0001\n",
      "Epoch 19, Step: 280, Loss: 0.391061007976532, Lr:0.0001\n",
      "Epoch 19, Step: 281, Loss: 0.017061440274119377, Lr:0.0001\n",
      "Epoch 19, Step: 282, Loss: 0.004232311155647039, Lr:0.0001\n",
      "Epoch 19, Step: 283, Loss: 0.07702726125717163, Lr:0.0001\n",
      "Epoch 19, Step: 284, Loss: 0.02905663102865219, Lr:0.0001\n",
      "Epoch 19, Step: 285, Loss: 0.021065298467874527, Lr:0.0001\n",
      "Epoch 19, Step: 286, Loss: 0.007086384575814009, Lr:0.0001\n",
      "Epoch 19, Step: 287, Loss: 0.11409062147140503, Lr:0.0001\n",
      "Epoch 19, Step: 288, Loss: 0.014295967295765877, Lr:0.0001\n",
      "Epoch 19, Step: 289, Loss: 0.01186299230903387, Lr:0.0001\n",
      "Epoch 19, Step: 290, Loss: 0.19013957679271698, Lr:0.0001\n",
      "Epoch 19, Step: 291, Loss: 0.09852857142686844, Lr:0.0001\n",
      "Epoch 19, Step: 292, Loss: 0.02614225447177887, Lr:0.0001\n",
      "Epoch 19, Step: 293, Loss: 0.10504696518182755, Lr:0.0001\n",
      "Epoch 19, Step: 294, Loss: 0.30807745456695557, Lr:0.0001\n",
      "Epoch 19, Step: 295, Loss: 0.3402402997016907, Lr:0.0001\n",
      "Epoch 19, Step: 296, Loss: 0.00711546465754509, Lr:0.0001\n",
      "Epoch 19, Step: 297, Loss: 0.021814940497279167, Lr:0.0001\n",
      "Epoch 19, Step: 298, Loss: 0.061231259256601334, Lr:0.0001\n",
      "Epoch 19, Step: 299, Loss: 0.04495115205645561, Lr:0.0001\n",
      "Epoch 19, Step: 300, Loss: 0.2518329620361328, Lr:0.0001\n",
      "Epoch 19, Step: 301, Loss: 0.02138322778046131, Lr:0.0001\n",
      "Epoch 19, Step: 302, Loss: 0.03344932571053505, Lr:0.0001\n",
      "Epoch 19, Step: 303, Loss: 0.01751263439655304, Lr:0.0001\n",
      "Epoch 19, Step: 304, Loss: 0.07264316827058792, Lr:0.0001\n",
      "Epoch 19, Step: 305, Loss: 0.1575024276971817, Lr:0.0001\n",
      "Epoch 19, Step: 306, Loss: 0.03757888078689575, Lr:0.0001\n",
      "Epoch 19, Step: 307, Loss: 0.010617442429065704, Lr:0.0001\n",
      "Epoch 19, Step: 308, Loss: 0.2934279441833496, Lr:0.0001\n",
      "Epoch 19, Step: 309, Loss: 0.23658736050128937, Lr:0.0001\n",
      "Epoch 19, Step: 310, Loss: 0.07054425030946732, Lr:0.0001\n",
      "Epoch 19, Step: 311, Loss: 0.08264122158288956, Lr:0.0001\n",
      "Epoch 19, Step: 312, Loss: 0.047618087381124496, Lr:0.0001\n",
      "Epoch 19, Step: 313, Loss: 0.05778462067246437, Lr:0.0001\n",
      "Epoch 19, Step: 314, Loss: 0.01604793220758438, Lr:0.0001\n",
      "Epoch 19, Step: 315, Loss: 0.21831847727298737, Lr:0.0001\n",
      "Epoch 19, Step: 316, Loss: 0.006329204421490431, Lr:0.0001\n",
      "Epoch 19, Step: 317, Loss: 0.0581156462430954, Lr:0.0001\n",
      "Epoch 19, Step: 318, Loss: 0.09060711413621902, Lr:0.0001\n",
      "Epoch 19, Step: 319, Loss: 0.10379169881343842, Lr:0.0001\n",
      "Epoch 19, Step: 320, Loss: 0.0292961485683918, Lr:0.0001\n",
      "Epoch 19, Step: 321, Loss: 0.026156194508075714, Lr:0.0001\n",
      "Epoch 19, Step: 322, Loss: 0.029000140726566315, Lr:0.0001\n",
      "Epoch 19, Step: 323, Loss: 0.011117960326373577, Lr:0.0001\n",
      "Epoch 19, Step: 324, Loss: 0.1880115568637848, Lr:0.0001\n",
      "Epoch 19, Step: 325, Loss: 0.16065427660942078, Lr:0.0001\n",
      "Epoch 19, Step: 326, Loss: 0.050556767731904984, Lr:0.0001\n",
      "Epoch 19, Step: 327, Loss: 0.08762451261281967, Lr:0.0001\n",
      "Epoch 19, Step: 328, Loss: 0.07795960456132889, Lr:0.0001\n",
      "Epoch 19, Step: 329, Loss: 0.0875144675374031, Lr:0.0001\n",
      "Epoch 19, Step: 330, Loss: 0.05737978219985962, Lr:0.0001\n",
      "Epoch 19, Step: 331, Loss: 0.12513016164302826, Lr:0.0001\n",
      "Epoch 19, Step: 332, Loss: 0.1034955084323883, Lr:0.0001\n",
      "Epoch 19, Step: 333, Loss: 0.021685628220438957, Lr:0.0001\n",
      "Epoch 19, Step: 334, Loss: 0.0552329383790493, Lr:0.0001\n",
      "Epoch 19, Step: 335, Loss: 0.009450530633330345, Lr:0.0001\n",
      "Epoch 19, Step: 336, Loss: 0.06881893426179886, Lr:0.0001\n",
      "Epoch 19, Step: 337, Loss: 0.018954500555992126, Lr:0.0001\n",
      "Epoch 19, Step: 338, Loss: 0.07881001383066177, Lr:0.0001\n",
      "Epoch 19, Step: 339, Loss: 0.02040526643395424, Lr:0.0001\n",
      "Epoch 19, Step: 340, Loss: 0.022958310320973396, Lr:0.0001\n",
      "Epoch 19, Step: 341, Loss: 0.21836857497692108, Lr:0.0001\n",
      "Epoch 19, Step: 342, Loss: 0.0747293159365654, Lr:0.0001\n",
      "Epoch 19, Step: 343, Loss: 0.038360051810741425, Lr:0.0001\n",
      "Epoch 19, Step: 344, Loss: 0.025775985792279243, Lr:0.0001\n",
      "Epoch 19, Step: 345, Loss: 0.23247715830802917, Lr:0.0001\n",
      "Epoch 19, Step: 346, Loss: 0.026860272511839867, Lr:0.0001\n",
      "Epoch 19, Step: 347, Loss: 0.0305954460054636, Lr:0.0001\n",
      "Epoch 19, Step: 348, Loss: 0.3395891785621643, Lr:0.0001\n",
      "Epoch 19, Step: 349, Loss: 0.004992464557290077, Lr:0.0001\n",
      "Epoch 19, Step: 350, Loss: 0.039808373898267746, Lr:0.0001\n",
      "Epoch 19, Step: 351, Loss: 0.021748488768935204, Lr:0.0001\n",
      "Epoch 19, Step: 352, Loss: 0.0012734185438603163, Lr:0.0001\n",
      "Epoch 19, Step: 353, Loss: 0.004080622456967831, Lr:0.0001\n",
      "Epoch 19, Step: 354, Loss: 0.0819982960820198, Lr:0.0001\n",
      "Epoch 19, Step: 355, Loss: 0.2623749077320099, Lr:0.0001\n",
      "Epoch 19, Step: 356, Loss: 0.08744753152132034, Lr:0.0001\n",
      "Epoch 19, Step: 357, Loss: 0.012905444949865341, Lr:0.0001\n",
      "Epoch 19, Step: 358, Loss: 0.012558594346046448, Lr:0.0001\n",
      "Epoch 19, Step: 359, Loss: 0.015055835247039795, Lr:0.0001\n",
      "Epoch 19, Step: 360, Loss: 0.2931756377220154, Lr:0.0001\n",
      "Epoch 19, Step: 361, Loss: 0.05166672542691231, Lr:0.0001\n",
      "Epoch 19, Step: 362, Loss: 0.13929134607315063, Lr:0.0001\n",
      "Epoch 19, Step: 363, Loss: 0.4303102195262909, Lr:0.0001\n",
      "Epoch 19, Step: 364, Loss: 0.09408470243215561, Lr:0.0001\n",
      "Epoch 19, Step: 365, Loss: 0.033276308327913284, Lr:0.0001\n",
      "Epoch 19, Step: 366, Loss: 0.006739725358784199, Lr:0.0001\n",
      "Epoch 19, Step: 367, Loss: 0.02572210319340229, Lr:0.0001\n",
      "Epoch 19, Step: 368, Loss: 0.10537805408239365, Lr:0.0001\n",
      "Epoch 19, Step: 369, Loss: 0.05083443596959114, Lr:0.0001\n",
      "Epoch 19, Step: 370, Loss: 0.011729445308446884, Lr:0.0001\n",
      "Epoch 19, Step: 371, Loss: 0.06284809112548828, Lr:0.0001\n",
      "Epoch 19, Step: 372, Loss: 0.15601445734500885, Lr:0.0001\n",
      "Epoch 19, Step: 373, Loss: 0.042680252343416214, Lr:0.0001\n",
      "Epoch 19, Step: 374, Loss: 0.04743366315960884, Lr:0.0001\n",
      "Epoch 19, Step: 375, Loss: 0.03842576593160629, Lr:0.0001\n",
      "Epoch 19, Step: 376, Loss: 0.003674023784697056, Lr:0.0001\n",
      "Epoch 19, Step: 377, Loss: 0.3116239607334137, Lr:0.0001\n",
      "Epoch 19, Step: 378, Loss: 0.16118690371513367, Lr:0.0001\n",
      "Epoch 19, Step: 379, Loss: 0.01915409043431282, Lr:0.0001\n",
      "Epoch 19, Step: 380, Loss: 0.06167656555771828, Lr:0.0001\n",
      "Epoch 19, Step: 381, Loss: 0.013519864529371262, Lr:0.0001\n",
      "Epoch 19, Step: 382, Loss: 0.0051946984604001045, Lr:0.0001\n",
      "Epoch 19, Step: 383, Loss: 0.036521367728710175, Lr:0.0001\n",
      "Epoch 19, Step: 384, Loss: 0.1767212450504303, Lr:0.0001\n",
      "Epoch 19, Step: 385, Loss: 0.08390292525291443, Lr:0.0001\n",
      "Epoch 19, Step: 386, Loss: 0.02632235549390316, Lr:0.0001\n",
      "Epoch 19, Step: 387, Loss: 0.10386280715465546, Lr:0.0001\n",
      "Epoch 19, Step: 388, Loss: 0.004859066102653742, Lr:0.0001\n",
      "Epoch 19, Step: 389, Loss: 0.12060613930225372, Lr:0.0001\n",
      "Epoch 19, Step: 390, Loss: 0.14075562357902527, Lr:0.0001\n",
      "Epoch 19, Step: 391, Loss: 0.23782269656658173, Lr:0.0001\n",
      "Epoch 19, Step: 392, Loss: 0.062457941472530365, Lr:0.0001\n",
      "Epoch 19, Step: 393, Loss: 0.12086348235607147, Lr:0.0001\n",
      "Epoch 19, Step: 394, Loss: 0.06465842574834824, Lr:0.0001\n",
      "Epoch 19, Step: 395, Loss: 0.03478081151843071, Lr:0.0001\n",
      "Epoch 19, Step: 396, Loss: 0.08639054000377655, Lr:0.0001\n",
      "Epoch 19, Step: 397, Loss: 0.0439641997218132, Lr:0.0001\n",
      "Epoch 19, Step: 398, Loss: 0.02750416472554207, Lr:0.0001\n",
      "Epoch 19, Step: 399, Loss: 0.07333856076002121, Lr:0.0001\n",
      "Epoch 19, Step: 400, Loss: 0.17546844482421875, Lr:0.0001\n",
      "Epoch 19, Step: 401, Loss: 0.21224132180213928, Lr:0.0001\n",
      "Epoch 19, Step: 402, Loss: 0.05363909527659416, Lr:0.0001\n",
      "Epoch 19, Step: 403, Loss: 0.008442687802016735, Lr:0.0001\n",
      "Epoch 19, Step: 404, Loss: 0.07953976094722748, Lr:0.0001\n",
      "Epoch 19, Step: 405, Loss: 0.010744749568402767, Lr:0.0001\n",
      "Epoch 19, Step: 406, Loss: 0.1369566172361374, Lr:0.0001\n",
      "Epoch 19, Step: 407, Loss: 0.06995644420385361, Lr:0.0001\n",
      "Epoch 19, Step: 408, Loss: 0.03500235080718994, Lr:0.0001\n",
      "Epoch 19, Step: 409, Loss: 0.08080092817544937, Lr:0.0001\n",
      "Epoch 19, Step: 410, Loss: 0.06348340958356857, Lr:0.0001\n",
      "Epoch 19, Step: 411, Loss: 0.08387333899736404, Lr:0.0001\n",
      "Epoch 19, Step: 412, Loss: 0.15758304297924042, Lr:0.0001\n",
      "Epoch 19, Step: 413, Loss: 0.1204165518283844, Lr:0.0001\n",
      "Epoch 19, Step: 414, Loss: 0.051873259246349335, Lr:0.0001\n",
      "Epoch 19, Step: 415, Loss: 0.028862211853265762, Lr:0.0001\n",
      "Epoch 19, Step: 416, Loss: 0.14955736696720123, Lr:0.0001\n",
      "Epoch 19, Step: 417, Loss: 0.012819236144423485, Lr:0.0001\n",
      "Epoch 19, Step: 418, Loss: 0.013956552371382713, Lr:0.0001\n",
      "Epoch 19, Step: 419, Loss: 0.03138251230120659, Lr:0.0001\n",
      "Epoch 19, Step: 420, Loss: 0.0049817836843431, Lr:0.0001\n",
      "Epoch 19, Step: 421, Loss: 0.031016536056995392, Lr:0.0001\n",
      "Epoch 19, Step: 422, Loss: 0.21964724361896515, Lr:0.0001\n",
      "Epoch 19, Step: 423, Loss: 0.35944631695747375, Lr:0.0001\n",
      "Epoch 19, Step: 424, Loss: 0.012799397110939026, Lr:0.0001\n",
      "Epoch 19, Step: 425, Loss: 0.012256581336259842, Lr:0.0001\n",
      "Epoch 19, Step: 426, Loss: 0.1652166098356247, Lr:0.0001\n",
      "Epoch 19, Step: 427, Loss: 0.01620600000023842, Lr:0.0001\n",
      "Epoch 19, Step: 428, Loss: 0.01661519892513752, Lr:0.0001\n",
      "Epoch 19, Step: 429, Loss: 0.005997826345264912, Lr:0.0001\n",
      "Epoch 19, Step: 430, Loss: 0.15657544136047363, Lr:0.0001\n",
      "Epoch 19, Step: 431, Loss: 0.009030220098793507, Lr:0.0001\n",
      "Epoch 19, Step: 432, Loss: 0.18268796801567078, Lr:0.0001\n",
      "Epoch 19, Step: 433, Loss: 0.0347522497177124, Lr:0.0001\n",
      "Epoch 19, Step: 434, Loss: 0.08051497489213943, Lr:0.0001\n",
      "Epoch 19, Step: 435, Loss: 0.0770859569311142, Lr:0.0001\n",
      "Epoch 19, Step: 436, Loss: 0.2960531413555145, Lr:0.0001\n",
      "Epoch 19, Step: 437, Loss: 0.07744114845991135, Lr:0.0001\n",
      "Epoch 19, Step: 438, Loss: 0.08713085204362869, Lr:0.0001\n",
      "Epoch 19, Step: 439, Loss: 0.003672968130558729, Lr:0.0001\n",
      "Epoch 19, Step: 440, Loss: 0.01481798104941845, Lr:0.0001\n",
      "Epoch 19, Step: 441, Loss: 0.09032544493675232, Lr:0.0001\n",
      "Epoch 19, Step: 442, Loss: 0.08632603287696838, Lr:0.0001\n",
      "Epoch 19, Step: 443, Loss: 0.10920238494873047, Lr:0.0001\n",
      "Epoch 19, Step: 444, Loss: 0.01751147024333477, Lr:0.0001\n",
      "Epoch 19, Step: 445, Loss: 0.07721176743507385, Lr:0.0001\n",
      "Epoch 19, Step: 446, Loss: 0.06679968535900116, Lr:0.0001\n",
      "Epoch 19, Step: 447, Loss: 0.022523758932948112, Lr:0.0001\n",
      "Epoch 19, Step: 448, Loss: 0.07558418810367584, Lr:0.0001\n",
      "Epoch 19, Step: 449, Loss: 0.10625123977661133, Lr:0.0001\n",
      "Epoch 19, Step: 450, Loss: 0.10448186099529266, Lr:0.0001\n",
      "Epoch 19, Step: 451, Loss: 0.04573765769600868, Lr:0.0001\n",
      "Epoch 19, Step: 452, Loss: 0.04482084512710571, Lr:0.0001\n",
      "Epoch 19, Step: 453, Loss: 0.03693809360265732, Lr:0.0001\n",
      "Epoch 19, Step: 454, Loss: 0.07224765419960022, Lr:0.0001\n",
      "Epoch 19, Step: 455, Loss: 0.09502066671848297, Lr:0.0001\n",
      "Epoch 19, Step: 456, Loss: 0.03111911006271839, Lr:0.0001\n",
      "Epoch 19, Step: 457, Loss: 0.006401448510587215, Lr:0.0001\n",
      "Epoch 19, Step: 458, Loss: 0.006651409436017275, Lr:0.0001\n",
      "Epoch 19, Step: 459, Loss: 0.09250617772340775, Lr:0.0001\n",
      "Epoch 19, Step: 460, Loss: 0.4718675911426544, Lr:0.0001\n",
      "Epoch 19, Step: 461, Loss: 0.08017085492610931, Lr:0.0001\n",
      "Epoch 19, Step: 462, Loss: 0.0018300404772162437, Lr:0.0001\n",
      "Epoch 19, Step: 463, Loss: 0.04946647584438324, Lr:0.0001\n",
      "Epoch 19, Step: 464, Loss: 0.004516212269663811, Lr:0.0001\n",
      "Epoch 19, Step: 465, Loss: 0.09837645292282104, Lr:0.0001\n",
      "Epoch 19, Step: 466, Loss: 0.005474715493619442, Lr:0.0001\n",
      "Epoch 19, Step: 467, Loss: 0.044179730117321014, Lr:0.0001\n",
      "Epoch 19, Step: 468, Loss: 0.28388118743896484, Lr:0.0001\n",
      "Epoch 19, Step: 469, Loss: 0.19187091290950775, Lr:0.0001\n",
      "Epoch 19, Step: 470, Loss: 0.08728185296058655, Lr:0.0001\n",
      "Epoch 19, Step: 471, Loss: 0.08632045239210129, Lr:0.0001\n",
      "Epoch 19, Step: 472, Loss: 0.02779153175652027, Lr:0.0001\n",
      "Epoch 19, Step: 473, Loss: 0.05761171132326126, Lr:0.0001\n",
      "Epoch 19, Step: 474, Loss: 0.0069857072085142136, Lr:0.0001\n",
      "Epoch 19, Step: 475, Loss: 0.45183855295181274, Lr:0.0001\n",
      "Epoch 19, Step: 476, Loss: 0.3298131823539734, Lr:0.0001\n",
      "Epoch 19, Step: 477, Loss: 0.09320119768381119, Lr:0.0001\n",
      "Epoch 19, Step: 478, Loss: 0.09759580343961716, Lr:0.0001\n",
      "Epoch 19, Step: 479, Loss: 0.09646809846162796, Lr:0.0001\n",
      "Epoch 19, Step: 480, Loss: 0.0615788996219635, Lr:0.0001\n",
      "Epoch 19, Step: 481, Loss: 0.11049889028072357, Lr:0.0001\n",
      "Epoch 19, Step: 482, Loss: 0.0425434447824955, Lr:0.0001\n",
      "Epoch 19, Step: 483, Loss: 0.1498388648033142, Lr:0.0001\n",
      "Epoch 19, Step: 484, Loss: 0.11132864654064178, Lr:0.0001\n",
      "Epoch 19, Step: 485, Loss: 0.0103257792070508, Lr:0.0001\n",
      "Epoch 19, Step: 486, Loss: 0.004277204629033804, Lr:0.0001\n",
      "Epoch 19, Step: 487, Loss: 0.013968038372695446, Lr:0.0001\n",
      "Epoch 19, Step: 488, Loss: 0.1209196075797081, Lr:0.0001\n",
      "Epoch 19, Step: 489, Loss: 0.44307857751846313, Lr:0.0001\n",
      "Epoch 19, Step: 490, Loss: 0.004819163121283054, Lr:0.0001\n",
      "Epoch 19, Step: 491, Loss: 0.0450240857899189, Lr:0.0001\n",
      "Epoch 19, Step: 492, Loss: 0.0120930727571249, Lr:0.0001\n",
      "Epoch 19, Step: 493, Loss: 0.10048891603946686, Lr:0.0001\n",
      "Epoch 19, Step: 494, Loss: 0.08789432048797607, Lr:0.0001\n",
      "Epoch 19, Step: 495, Loss: 0.023218944668769836, Lr:0.0001\n",
      "Epoch 19, Step: 496, Loss: 0.06353980302810669, Lr:0.0001\n",
      "Epoch 19, Step: 497, Loss: 0.028781935572624207, Lr:0.0001\n",
      "Epoch 19, Step: 498, Loss: 0.04906279966235161, Lr:0.0001\n",
      "Epoch 19, Step: 499, Loss: 0.014483058825135231, Lr:0.0001\n",
      "Epoch 19, Step: 500, Loss: 0.2764994502067566, Lr:0.0001\n",
      "Epoch 19, Step: 501, Loss: 0.046966977417469025, Lr:0.0001\n",
      "Epoch 19, Step: 502, Loss: 0.03386130928993225, Lr:0.0001\n",
      "Epoch 19, Step: 503, Loss: 0.039578575640916824, Lr:0.0001\n",
      "Epoch 19, Step: 504, Loss: 0.05438777059316635, Lr:0.0001\n",
      "Epoch 19, Step: 505, Loss: 0.08242655545473099, Lr:0.0001\n",
      "Epoch 19, Step: 506, Loss: 0.1648157238960266, Lr:0.0001\n",
      "Epoch 19, Step: 507, Loss: 0.045573871582746506, Lr:0.0001\n",
      "Epoch 19, Step: 508, Loss: 0.016860755160450935, Lr:0.0001\n",
      "Epoch 19, Step: 509, Loss: 0.02251446433365345, Lr:0.0001\n",
      "Epoch 19, Step: 510, Loss: 0.06706880778074265, Lr:0.0001\n",
      "Epoch 19, Step: 511, Loss: 0.0766565129160881, Lr:0.0001\n",
      "Epoch 19, Step: 512, Loss: 0.021311873570084572, Lr:0.0001\n",
      "Epoch 19, Step: 513, Loss: 0.02635706588625908, Lr:0.0001\n",
      "Epoch 19, Step: 514, Loss: 0.0028208536095917225, Lr:0.0001\n",
      "Epoch 19, Step: 515, Loss: 0.08567161113023758, Lr:0.0001\n",
      "Epoch 19, Step: 516, Loss: 0.044973645359277725, Lr:0.0001\n",
      "Epoch 19, Step: 517, Loss: 0.18356360495090485, Lr:0.0001\n",
      "Epoch 19, Step: 518, Loss: 0.012473510578274727, Lr:0.0001\n",
      "Epoch 19, Step: 519, Loss: 0.17188523709774017, Lr:0.0001\n",
      "Epoch 19, Step: 520, Loss: 0.01713792234659195, Lr:0.0001\n",
      "Epoch 19, Step: 521, Loss: 0.36577993631362915, Lr:0.0001\n",
      "Epoch 19, Step: 522, Loss: 0.0035761164035648108, Lr:0.0001\n",
      "Epoch 19, Step: 523, Loss: 0.015048247762024403, Lr:0.0001\n",
      "Epoch 19, Step: 524, Loss: 0.11858589202165604, Lr:0.0001\n",
      "Epoch 19, Step: 525, Loss: 0.023186026141047478, Lr:0.0001\n",
      "Epoch 19, Step: 526, Loss: 0.08113188296556473, Lr:0.0001\n",
      "Epoch 19, Step: 527, Loss: 0.15423156321048737, Lr:0.0001\n",
      "Epoch 19, Step: 528, Loss: 0.010637941770255566, Lr:0.0001\n",
      "Epoch 19, Step: 529, Loss: 0.011500172317028046, Lr:0.0001\n",
      "Epoch 19, Step: 530, Loss: 0.03690914064645767, Lr:0.0001\n",
      "Epoch 19, Step: 531, Loss: 0.04395632818341255, Lr:0.0001\n",
      "Epoch 19, Step: 532, Loss: 0.07886403053998947, Lr:0.0001\n",
      "Epoch 19, Step: 533, Loss: 0.035191651433706284, Lr:0.0001\n",
      "Epoch 19, Step: 534, Loss: 0.033085837960243225, Lr:0.0001\n",
      "Epoch 19, Step: 535, Loss: 0.0066767106764018536, Lr:0.0001\n",
      "Epoch 19, Step: 536, Loss: 0.05333365872502327, Lr:0.0001\n",
      "Epoch 19, Step: 537, Loss: 0.0033318758942186832, Lr:0.0001\n",
      "Epoch 19, Step: 538, Loss: 0.001195839256979525, Lr:0.0001\n",
      "Epoch 19, Step: 539, Loss: 0.06016409024596214, Lr:0.0001\n",
      "Epoch 19, Step: 540, Loss: 0.010382440872490406, Lr:0.0001\n",
      "Epoch 19, Step: 541, Loss: 0.064632847905159, Lr:0.0001\n",
      "Epoch 19, Step: 542, Loss: 0.026730747893452644, Lr:0.0001\n",
      "Epoch 19, Step: 543, Loss: 0.4507664442062378, Lr:0.0001\n",
      "Epoch 19, Step: 544, Loss: 0.025585299357771873, Lr:0.0001\n",
      "Epoch 19, Step: 545, Loss: 0.03533414378762245, Lr:0.0001\n",
      "Epoch 19, Step: 546, Loss: 0.008501390926539898, Lr:0.0001\n",
      "Epoch 19, Step: 547, Loss: 0.05997791886329651, Lr:0.0001\n",
      "Epoch 19, Step: 548, Loss: 0.23608365654945374, Lr:0.0001\n",
      "Epoch 19, Step: 549, Loss: 0.022174447774887085, Lr:0.0001\n",
      "Epoch 19, Step: 550, Loss: 0.005912892986088991, Lr:0.0001\n",
      "Epoch 19, Step: 551, Loss: 0.09196436405181885, Lr:0.0001\n",
      "Epoch 19, Step: 552, Loss: 0.08808261156082153, Lr:0.0001\n",
      "Epoch 19, Step: 553, Loss: 0.007036346942186356, Lr:0.0001\n",
      "Epoch 19, Step: 554, Loss: 0.11347698420286179, Lr:0.0001\n",
      "Epoch 19, Step: 555, Loss: 0.09277403354644775, Lr:0.0001\n",
      "Epoch 19, Step: 556, Loss: 0.018621953204274178, Lr:0.0001\n",
      "Epoch 19, Step: 557, Loss: 0.0012023302260786295, Lr:0.0001\n",
      "Epoch 19, Step: 558, Loss: 0.264474481344223, Lr:0.0001\n",
      "Epoch 19, Step: 559, Loss: 0.08827442675828934, Lr:0.0001\n",
      "Epoch 19, Step: 560, Loss: 0.04875924065709114, Lr:0.0001\n",
      "Epoch 19, Step: 561, Loss: 0.07707922905683517, Lr:0.0001\n",
      "Epoch 19, Step: 562, Loss: 0.03272640332579613, Lr:0.0001\n",
      "Epoch 19, Step: 563, Loss: 0.026165375486016273, Lr:0.0001\n",
      "Epoch 19, Step: 564, Loss: 0.029675086960196495, Lr:0.0001\n",
      "Epoch 19, Step: 565, Loss: 0.33499714732170105, Lr:0.0001\n",
      "Epoch 19, Step: 566, Loss: 0.10860349237918854, Lr:0.0001\n",
      "Epoch 19, Step: 567, Loss: 0.02124885842204094, Lr:0.0001\n",
      "Epoch 19, Step: 568, Loss: 0.08995633572340012, Lr:0.0001\n",
      "Epoch 19, Step: 569, Loss: 0.31787994503974915, Lr:0.0001\n",
      "Epoch 19, Step: 570, Loss: 0.0284265223890543, Lr:0.0001\n",
      "Epoch 19, Step: 571, Loss: 0.11432313919067383, Lr:0.0001\n",
      "Epoch 19, Step: 572, Loss: 0.1657019853591919, Lr:0.0001\n",
      "Epoch 19, Step: 573, Loss: 0.058132387697696686, Lr:0.0001\n",
      "Epoch 19, Step: 574, Loss: 0.08310993760824203, Lr:0.0001\n",
      "Epoch 19, Step: 575, Loss: 0.04819951206445694, Lr:0.0001\n",
      "Epoch 19, Step: 576, Loss: 0.24177949130535126, Lr:0.0001\n",
      "Epoch 19, Step: 577, Loss: 0.0472659207880497, Lr:0.0001\n",
      "Epoch 19, Step: 578, Loss: 0.05710134282708168, Lr:0.0001\n",
      "Epoch 19, Step: 579, Loss: 0.05803535878658295, Lr:0.0001\n",
      "Epoch 19, Step: 580, Loss: 0.019813256338238716, Lr:0.0001\n",
      "Epoch 19, Step: 581, Loss: 0.01384616456925869, Lr:0.0001\n",
      "Epoch 19, Step: 582, Loss: 0.08539386838674545, Lr:0.0001\n",
      "Epoch 19, Step: 583, Loss: 0.030421966686844826, Lr:0.0001\n",
      "Epoch 19, Step: 584, Loss: 0.06284864991903305, Lr:0.0001\n",
      "Epoch 19, Step: 585, Loss: 0.021424859762191772, Lr:0.0001\n",
      "Epoch 19, Step: 586, Loss: 0.2053971290588379, Lr:0.0001\n",
      "Epoch 19, Step: 587, Loss: 0.004138053394854069, Lr:0.0001\n",
      "Epoch 19, Step: 588, Loss: 0.16804184019565582, Lr:0.0001\n",
      "Epoch 19, Step: 589, Loss: 0.16687963902950287, Lr:0.0001\n",
      "Epoch 19, Step: 590, Loss: 0.06555637717247009, Lr:0.0001\n",
      "Epoch 19, Step: 591, Loss: 0.057656869292259216, Lr:0.0001\n",
      "Epoch 19, Step: 592, Loss: 0.0554426833987236, Lr:0.0001\n",
      "Epoch 19, Step: 593, Loss: 0.023225262761116028, Lr:0.0001\n",
      "Epoch 19, Step: 594, Loss: 0.03394051641225815, Lr:0.0001\n",
      "Epoch 19, Step: 595, Loss: 0.21104741096496582, Lr:0.0001\n",
      "Epoch 19, Step: 596, Loss: 0.03795376047492027, Lr:0.0001\n",
      "Epoch 19, Step: 597, Loss: 0.03090580552816391, Lr:0.0001\n",
      "Epoch 19, Step: 598, Loss: 0.031637437641620636, Lr:0.0001\n",
      "Epoch 19, Step: 599, Loss: 0.06826184689998627, Lr:0.0001\n",
      "Epoch 19, Step: 600, Loss: 0.09430597722530365, Lr:0.0001\n",
      "Epoch 19, Step: 601, Loss: 0.19964587688446045, Lr:0.0001\n",
      "Epoch 19, Step: 602, Loss: 0.06277187913656235, Lr:0.0001\n",
      "Epoch 19, Step: 603, Loss: 0.0791623592376709, Lr:0.0001\n",
      "Epoch 19, Step: 604, Loss: 0.06633637100458145, Lr:0.0001\n",
      "Epoch 19, Step: 605, Loss: 0.0012312467442825437, Lr:0.0001\n",
      "Epoch 19, Step: 606, Loss: 0.040342193096876144, Lr:0.0001\n",
      "Epoch 19, Step: 607, Loss: 0.1162000223994255, Lr:0.0001\n",
      "Epoch 19, Step: 608, Loss: 0.038068730384111404, Lr:0.0001\n",
      "Epoch 19, Step: 609, Loss: 0.0053983223624527454, Lr:0.0001\n",
      "Epoch 19, Step: 610, Loss: 0.0018841163255274296, Lr:0.0001\n",
      "Epoch 19, Step: 611, Loss: 0.07528089731931686, Lr:0.0001\n",
      "Epoch 19, Step: 612, Loss: 0.014188531786203384, Lr:0.0001\n",
      "Epoch 19, Step: 613, Loss: 0.03918358311057091, Lr:0.0001\n",
      "Epoch 19, Step: 614, Loss: 0.02904001995921135, Lr:0.0001\n",
      "Epoch 19, Step: 615, Loss: 0.12406005710363388, Lr:0.0001\n",
      "Epoch 19, Step: 616, Loss: 0.1072826012969017, Lr:0.0001\n",
      "Epoch 19, Step: 617, Loss: 0.2805711328983307, Lr:0.0001\n",
      "Epoch 19, Step: 618, Loss: 0.08810359984636307, Lr:0.0001\n",
      "Epoch 19, Step: 619, Loss: 0.004433843307197094, Lr:0.0001\n",
      "Epoch 19, Step: 620, Loss: 0.12327905744314194, Lr:0.0001\n",
      "Epoch 19, Step: 621, Loss: 0.02841453067958355, Lr:0.0001\n",
      "Epoch 19, Step: 622, Loss: 0.11594773828983307, Lr:0.0001\n",
      "Epoch 19, Step: 623, Loss: 0.03373187407851219, Lr:0.0001\n",
      "Epoch 19, Step: 624, Loss: 0.0053984797559678555, Lr:0.0001\n",
      "Epoch 19, Step: 625, Loss: 0.07368402928113937, Lr:0.0001\n",
      "Epoch 19, Step: 626, Loss: 0.15585939586162567, Lr:0.0001\n",
      "Epoch 19, Step: 627, Loss: 0.027141885831952095, Lr:0.0001\n",
      "Epoch 19, Step: 628, Loss: 0.00866102334111929, Lr:0.0001\n",
      "Epoch 19, Step: 629, Loss: 0.0014060282846912742, Lr:0.0001\n",
      "Epoch 19, Step: 630, Loss: 0.04647953435778618, Lr:0.0001\n",
      "Epoch 19, Step: 631, Loss: 0.2699648141860962, Lr:0.0001\n",
      "Epoch 19, Step: 632, Loss: 0.31547388434410095, Lr:0.0001\n",
      "Epoch 19, Step: 633, Loss: 0.008654040284454823, Lr:0.0001\n",
      "Epoch 19, Step: 634, Loss: 0.025947200134396553, Lr:0.0001\n",
      "Epoch 19, Step: 635, Loss: 0.005697530694305897, Lr:0.0001\n",
      "Epoch 19, Step: 636, Loss: 0.332682728767395, Lr:0.0001\n",
      "Epoch 19, Step: 637, Loss: 0.0745110884308815, Lr:0.0001\n",
      "Epoch 19, Step: 638, Loss: 0.04396989196538925, Lr:0.0001\n",
      "Epoch 19, Step: 639, Loss: 0.04780454933643341, Lr:0.0001\n",
      "Epoch 19, Step: 640, Loss: 0.454898864030838, Lr:0.0001\n",
      "Epoch 19, Step: 641, Loss: 0.03997185453772545, Lr:0.0001\n",
      "Epoch 19, Step: 642, Loss: 0.012082514353096485, Lr:0.0001\n",
      "Epoch 19, Step: 643, Loss: 0.01459412556141615, Lr:0.0001\n",
      "Epoch 19, Step: 644, Loss: 0.012722923420369625, Lr:0.0001\n",
      "Epoch 19, Step: 645, Loss: 0.009455574676394463, Lr:0.0001\n",
      "Epoch 19, Step: 646, Loss: 0.06333665549755096, Lr:0.0001\n",
      "Epoch 19, Step: 647, Loss: 0.3805820047855377, Lr:0.0001\n",
      "Epoch 19, Step: 648, Loss: 0.23153060674667358, Lr:0.0001\n",
      "Epoch 19, Step: 649, Loss: 0.03845784068107605, Lr:0.0001\n",
      "Epoch 19, Step: 650, Loss: 0.09192361682653427, Lr:0.0001\n",
      "Epoch 19, Step: 651, Loss: 0.16193334758281708, Lr:0.0001\n",
      "Epoch 19, Step: 652, Loss: 0.033526770770549774, Lr:0.0001\n",
      "Epoch 19, Step: 653, Loss: 0.05799374729394913, Lr:0.0001\n",
      "Epoch 19, Step: 654, Loss: 0.024370888248085976, Lr:0.0001\n",
      "Epoch 19, Step: 655, Loss: 0.28430378437042236, Lr:0.0001\n",
      "Epoch 19, Step: 656, Loss: 0.003885002341121435, Lr:0.0001\n",
      "Epoch 19, Step: 657, Loss: 0.0066343569196760654, Lr:0.0001\n",
      "Epoch 19, Step: 658, Loss: 0.035932738333940506, Lr:0.0001\n",
      "Epoch 19, Step: 659, Loss: 0.26692381501197815, Lr:0.0001\n",
      "Epoch 19, Step: 660, Loss: 0.011369484476745129, Lr:0.0001\n",
      "Epoch 19, Step: 661, Loss: 0.12143821269273758, Lr:0.0001\n",
      "Epoch 19, Step: 662, Loss: 0.0889614000916481, Lr:0.0001\n",
      "Epoch 19, Step: 663, Loss: 0.010965768247842789, Lr:0.0001\n",
      "Epoch 19, Step: 664, Loss: 0.10149182379245758, Lr:0.0001\n",
      "Epoch 19, Step: 665, Loss: 0.1673061102628708, Lr:0.0001\n",
      "Epoch 19, Step: 666, Loss: 0.1567426323890686, Lr:0.0001\n",
      "Epoch 19, Step: 667, Loss: 0.010123047046363354, Lr:0.0001\n",
      "Epoch 19, Step: 668, Loss: 0.0053306990303099155, Lr:0.0001\n",
      "Epoch 19, Step: 669, Loss: 0.10202864557504654, Lr:0.0001\n",
      "Epoch 19, Step: 670, Loss: 0.04278375208377838, Lr:0.0001\n",
      "Epoch 19, Step: 671, Loss: 0.1298695206642151, Lr:0.0001\n",
      "Epoch 19, Step: 672, Loss: 0.2187814563512802, Lr:0.0001\n",
      "Epoch 19, Step: 673, Loss: 0.0030498546548187733, Lr:0.0001\n",
      "Epoch 19, Step: 674, Loss: 0.02816210687160492, Lr:0.0001\n",
      "Epoch 19, Step: 675, Loss: 0.158695787191391, Lr:0.0001\n",
      "Epoch 19, Step: 676, Loss: 0.040799207985401154, Lr:0.0001\n",
      "Epoch 19, Step: 677, Loss: 0.11970812827348709, Lr:0.0001\n",
      "Epoch 19, Step: 678, Loss: 0.025871869176626205, Lr:0.0001\n",
      "Epoch 19, Step: 679, Loss: 0.18497224152088165, Lr:0.0001\n",
      "Epoch 19, Step: 680, Loss: 0.15298932790756226, Lr:0.0001\n",
      "Epoch 19, Step: 681, Loss: 0.04428472742438316, Lr:0.0001\n",
      "Epoch 19, Step: 682, Loss: 0.0409495085477829, Lr:0.0001\n",
      "Epoch 19, Step: 683, Loss: 0.009576990269124508, Lr:0.0001\n",
      "Epoch 19, Step: 684, Loss: 0.03955354914069176, Lr:0.0001\n",
      "Epoch 19, Step: 685, Loss: 0.044033318758010864, Lr:0.0001\n",
      "Epoch 19, Step: 686, Loss: 0.027955379337072372, Lr:0.0001\n",
      "Epoch 19, Step: 687, Loss: 0.03182308003306389, Lr:0.0001\n",
      "Epoch 19, Step: 688, Loss: 0.037668921053409576, Lr:0.0001\n",
      "Epoch 19, Step: 689, Loss: 0.014685222879052162, Lr:0.0001\n",
      "Epoch 19, Step: 690, Loss: 0.12021268159151077, Lr:0.0001\n",
      "Epoch 19, Step: 691, Loss: 0.014755524694919586, Lr:0.0001\n",
      "Epoch 19, Step: 692, Loss: 0.007345323916524649, Lr:0.0001\n",
      "Epoch 19, Step: 693, Loss: 0.10079450905323029, Lr:0.0001\n",
      "Epoch 19, Step: 694, Loss: 0.007397735025733709, Lr:0.0001\n",
      "Epoch 19, Step: 695, Loss: 0.02668089047074318, Lr:0.0001\n",
      "Epoch 19, Step: 696, Loss: 0.14487296342849731, Lr:0.0001\n",
      "Epoch 19, Step: 697, Loss: 0.01527136005461216, Lr:0.0001\n",
      "Epoch 19, Step: 698, Loss: 0.10033990442752838, Lr:0.0001\n",
      "Epoch 19, Step: 699, Loss: 0.08089011162519455, Lr:0.0001\n",
      "Epoch 19, Step: 700, Loss: 0.013118457980453968, Lr:0.0001\n",
      "Epoch 19, Step: 701, Loss: 0.14594890177249908, Lr:0.0001\n",
      "Epoch 19, Step: 702, Loss: 0.002766565652564168, Lr:0.0001\n",
      "Epoch 19, Step: 703, Loss: 0.13229316473007202, Lr:0.0001\n",
      "Epoch 19, Step: 704, Loss: 0.006111237220466137, Lr:0.0001\n",
      "Epoch 19, Step: 705, Loss: 0.008039981126785278, Lr:0.0001\n",
      "Epoch 19, Step: 706, Loss: 0.03730112686753273, Lr:0.0001\n",
      "Epoch 19, Step: 707, Loss: 0.007314891088753939, Lr:0.0001\n",
      "Epoch 19, Step: 708, Loss: 0.2408592253923416, Lr:0.0001\n",
      "Epoch 19, Step: 709, Loss: 0.015259739942848682, Lr:0.0001\n",
      "Epoch 19, Step: 710, Loss: 0.12170473486185074, Lr:0.0001\n",
      "Epoch 19, Step: 711, Loss: 0.020999494940042496, Lr:0.0001\n",
      "Epoch 19, Step: 712, Loss: 0.4258241355419159, Lr:0.0001\n",
      "Epoch 19, Step: 713, Loss: 0.2240961343050003, Lr:0.0001\n",
      "Epoch 19, Step: 714, Loss: 0.1715465486049652, Lr:0.0001\n",
      "Epoch 19, Step: 715, Loss: 0.07071113586425781, Lr:0.0001\n",
      "Epoch 19, Step: 716, Loss: 0.07042430341243744, Lr:0.0001\n",
      "Epoch 19, Step: 717, Loss: 0.06983508169651031, Lr:0.0001\n",
      "Epoch 19, Step: 718, Loss: 0.004418718628585339, Lr:0.0001\n",
      "Epoch 19, Step: 719, Loss: 0.17372989654541016, Lr:0.0001\n",
      "Epoch 19, Step: 720, Loss: 0.13177621364593506, Lr:0.0001\n",
      "Epoch 19, Step: 721, Loss: 0.05021904036402702, Lr:0.0001\n",
      "Epoch 19, Step: 722, Loss: 0.6149173974990845, Lr:0.0001\n",
      "Epoch 19, Step: 723, Loss: 0.0062383986078202724, Lr:0.0001\n",
      "Epoch 19, Step: 724, Loss: 0.027610596269369125, Lr:0.0001\n",
      "Epoch 19, Step: 725, Loss: 0.0976620689034462, Lr:0.0001\n",
      "Epoch 19, Step: 726, Loss: 0.02326378971338272, Lr:0.0001\n",
      "Epoch 19, Step: 727, Loss: 0.06461670249700546, Lr:0.0001\n",
      "Epoch 19, Step: 728, Loss: 0.008649970404803753, Lr:0.0001\n",
      "Epoch 19, Step: 729, Loss: 0.3387182950973511, Lr:0.0001\n",
      "Epoch 19, Step: 730, Loss: 0.10810469090938568, Lr:0.0001\n",
      "Epoch 19, Step: 731, Loss: 0.03196162357926369, Lr:0.0001\n",
      "Epoch 19, Step: 732, Loss: 0.16694557666778564, Lr:0.0001\n",
      "Epoch 19, Step: 733, Loss: 0.010867569595575333, Lr:0.0001\n",
      "Epoch 19, Step: 734, Loss: 0.04131056368350983, Lr:0.0001\n",
      "Epoch 19, Step: 735, Loss: 0.04033565893769264, Lr:0.0001\n",
      "Epoch 19, Step: 736, Loss: 0.05689395219087601, Lr:0.0001\n",
      "Epoch 19, Step: 737, Loss: 0.04048626497387886, Lr:0.0001\n",
      "Epoch 19, Step: 738, Loss: 0.00813327543437481, Lr:0.0001\n",
      "Epoch 19, Step: 739, Loss: 0.04699501022696495, Lr:0.0001\n",
      "Epoch 19, Step: 740, Loss: 0.06114736944437027, Lr:0.0001\n",
      "Epoch 19, Step: 741, Loss: 0.38894617557525635, Lr:0.0001\n",
      "Epoch 19, Step: 742, Loss: 0.02689433842897415, Lr:0.0001\n",
      "Epoch 19, Step: 743, Loss: 0.08118300139904022, Lr:0.0001\n",
      "Epoch 19, Step: 744, Loss: 0.05304509028792381, Lr:0.0001\n",
      "Epoch 19, Step: 745, Loss: 0.04542623832821846, Lr:0.0001\n",
      "Epoch 19, Step: 746, Loss: 0.09324543923139572, Lr:0.0001\n",
      "Epoch 19, Step: 747, Loss: 0.03765442594885826, Lr:0.0001\n",
      "Epoch 19, Step: 748, Loss: 0.07329295575618744, Lr:0.0001\n",
      "Epoch 19, Step: 749, Loss: 0.4889064133167267, Lr:0.0001\n",
      "Epoch 19, Step: 750, Loss: 0.08168540149927139, Lr:0.0001\n",
      "Epoch 19, Step: 751, Loss: 0.15353946387767792, Lr:0.0001\n",
      "Epoch 19, Step: 752, Loss: 0.007875636219978333, Lr:0.0001\n",
      "Epoch 19, Step: 753, Loss: 0.18089577555656433, Lr:0.0001\n",
      "Epoch 19, Step: 754, Loss: 0.1266806423664093, Lr:0.0001\n",
      "Epoch 19, Step: 755, Loss: 0.16656669974327087, Lr:0.0001\n",
      "Epoch 19, Step: 756, Loss: 0.1559394896030426, Lr:0.0001\n",
      "Epoch 19, Step: 757, Loss: 0.037416961044073105, Lr:0.0001\n",
      "Epoch 19, Step: 758, Loss: 0.31980928778648376, Lr:0.0001\n",
      "Epoch 19, Step: 759, Loss: 0.4593678116798401, Lr:0.0001\n",
      "Epoch 19, Step: 760, Loss: 0.09927552938461304, Lr:0.0001\n",
      "Epoch 19, Step: 761, Loss: 0.26666682958602905, Lr:0.0001\n",
      "Epoch 19, Step: 762, Loss: 0.032899484038352966, Lr:0.0001\n",
      "Epoch 19, Step: 763, Loss: 0.21005041897296906, Lr:0.0001\n",
      "Epoch 19, Step: 764, Loss: 0.25933194160461426, Lr:0.0001\n",
      "Epoch 19, Step: 765, Loss: 0.3713642954826355, Lr:0.0001\n",
      "Epoch 19, Step: 766, Loss: 0.04631679877638817, Lr:0.0001\n",
      "Epoch 19, Step: 767, Loss: 0.16352790594100952, Lr:0.0001\n",
      "Epoch 19, Step: 768, Loss: 0.09640484303236008, Lr:0.0001\n",
      "Epoch 19, Step: 769, Loss: 0.007685672026127577, Lr:0.0001\n",
      "Epoch 19, Step: 770, Loss: 0.19280694425106049, Lr:0.0001\n",
      "Epoch 19, Step: 771, Loss: 0.04289985075592995, Lr:0.0001\n",
      "Epoch 19, Step: 772, Loss: 0.07762506604194641, Lr:0.0001\n",
      "Epoch 19, Step: 773, Loss: 0.008247855119407177, Lr:0.0001\n",
      "Epoch 19, Step: 774, Loss: 0.050686176866292953, Lr:0.0001\n",
      "Epoch 19, Step: 775, Loss: 0.21191653609275818, Lr:0.0001\n",
      "Epoch 19, Step: 776, Loss: 0.13579456508159637, Lr:0.0001\n",
      "Epoch 19, Step: 777, Loss: 0.16714657843112946, Lr:0.0001\n",
      "Epoch 19, Step: 778, Loss: 0.08485768735408783, Lr:0.0001\n",
      "Epoch 19, Step: 779, Loss: 0.09029871970415115, Lr:0.0001\n",
      "Epoch 19, Step: 780, Loss: 0.05537199229001999, Lr:0.0001\n",
      "Epoch 19, Step: 781, Loss: 0.009329915046691895, Lr:0.0001\n",
      "Epoch 19, Step: 782, Loss: 0.3084787130355835, Lr:0.0001\n",
      "Epoch 19, Step: 783, Loss: 0.013584577478468418, Lr:0.0001\n",
      "Epoch 19, Step: 784, Loss: 0.2813243269920349, Lr:0.0001\n",
      "Epoch 19, Step: 785, Loss: 0.13814756274223328, Lr:0.0001\n",
      "Epoch 19, Step: 786, Loss: 0.17547167837619781, Lr:0.0001\n",
      "Epoch 19, Step: 787, Loss: 0.05273541808128357, Lr:0.0001\n",
      "Epoch 19, Step: 788, Loss: 0.018412718549370766, Lr:0.0001\n",
      "Epoch 19, Step: 789, Loss: 0.14848241209983826, Lr:0.0001\n",
      "Epoch 19, Step: 790, Loss: 0.034590017050504684, Lr:0.0001\n",
      "Epoch 19, Step: 791, Loss: 0.21625478565692902, Lr:0.0001\n",
      "Epoch 19, Step: 792, Loss: 0.00329846004024148, Lr:0.0001\n",
      "Epoch 19, Step: 793, Loss: 0.031540509313344955, Lr:0.0001\n",
      "Epoch 19, Step: 794, Loss: 0.03098413720726967, Lr:0.0001\n",
      "Epoch 19, Step: 795, Loss: 0.0030942477751523256, Lr:0.0001\n",
      "Epoch 19, Step: 796, Loss: 0.15113992989063263, Lr:0.0001\n",
      "Epoch 19, Step: 797, Loss: 0.08317083865404129, Lr:0.0001\n",
      "Epoch 19, Step: 798, Loss: 0.013401355594396591, Lr:0.0001\n",
      "Epoch 19, Step: 799, Loss: 0.0018603202188387513, Lr:0.0001\n",
      "Epoch 19, Step: 800, Loss: 0.12295922636985779, Lr:0.0001\n",
      "Epoch 19, Step: 801, Loss: 0.08715756982564926, Lr:0.0001\n",
      "Epoch 19, Step: 802, Loss: 0.05929277464747429, Lr:0.0001\n",
      "Epoch 19, Step: 803, Loss: 0.08772563934326172, Lr:0.0001\n",
      "Epoch 19, Step: 804, Loss: 0.016591094434261322, Lr:0.0001\n",
      "Epoch 19, Step: 805, Loss: 0.32982662320137024, Lr:0.0001\n",
      "Epoch 19, Step: 806, Loss: 0.04801587387919426, Lr:0.0001\n",
      "Epoch 19, Step: 807, Loss: 0.04744112864136696, Lr:0.0001\n",
      "Epoch 19, Step: 808, Loss: 0.16300949454307556, Lr:0.0001\n",
      "Epoch 19, Step: 809, Loss: 0.018374115228652954, Lr:0.0001\n",
      "Epoch 19, Step: 810, Loss: 0.07426634430885315, Lr:0.0001\n",
      "Epoch 19, Step: 811, Loss: 0.40963026881217957, Lr:0.0001\n",
      "Epoch 19, Step: 812, Loss: 0.004801899194717407, Lr:0.0001\n",
      "Epoch 19, Step: 813, Loss: 0.019643669947981834, Lr:0.0001\n",
      "Epoch 19, Step: 814, Loss: 0.10501803457736969, Lr:0.0001\n",
      "Epoch 19, Step: 815, Loss: 0.2519191801548004, Lr:0.0001\n",
      "Epoch 19, Step: 816, Loss: 0.015194138512015343, Lr:0.0001\n",
      "Epoch 19, Step: 817, Loss: 0.13839973509311676, Lr:0.0001\n",
      "Epoch 19, Step: 818, Loss: 0.027327291667461395, Lr:0.0001\n",
      "Epoch 19, Step: 819, Loss: 0.07465938478708267, Lr:0.0001\n",
      "Epoch 19, Step: 820, Loss: 0.1913948655128479, Lr:0.0001\n",
      "Epoch 19, Step: 821, Loss: 0.12267614901065826, Lr:0.0001\n",
      "Epoch 19, Step: 822, Loss: 0.08337080478668213, Lr:0.0001\n",
      "Epoch 19, Step: 823, Loss: 0.12088753283023834, Lr:0.0001\n",
      "Epoch 19, Step: 824, Loss: 0.17189641296863556, Lr:0.0001\n",
      "Epoch 19, Step: 825, Loss: 0.20062266290187836, Lr:0.0001\n",
      "Epoch 19, Step: 826, Loss: 0.03437167778611183, Lr:0.0001\n",
      "Epoch 19, Step: 827, Loss: 0.07354708015918732, Lr:0.0001\n",
      "Epoch 19, Step: 828, Loss: 0.16460055112838745, Lr:0.0001\n",
      "Epoch 19, Step: 829, Loss: 0.11366435885429382, Lr:0.0001\n",
      "Epoch 19, Step: 830, Loss: 0.3099019527435303, Lr:0.0001\n",
      "Epoch 19, Step: 831, Loss: 0.01297037024050951, Lr:0.0001\n",
      "Epoch 19, Step: 832, Loss: 0.1637161374092102, Lr:0.0001\n",
      "Epoch 19, Step: 833, Loss: 0.19135122001171112, Lr:0.0001\n",
      "Epoch 19, Step: 834, Loss: 0.0315597727894783, Lr:0.0001\n",
      "Epoch 19, Step: 835, Loss: 0.018060823902487755, Lr:0.0001\n",
      "Epoch 19, Step: 836, Loss: 0.0694521814584732, Lr:0.0001\n",
      "Epoch 19, Step: 837, Loss: 0.06183348596096039, Lr:0.0001\n",
      "Epoch 19, Step: 838, Loss: 0.46637359261512756, Lr:0.0001\n",
      "Epoch 19, Step: 839, Loss: 0.25318410992622375, Lr:0.0001\n",
      "Epoch 19, Step: 840, Loss: 0.0829530879855156, Lr:0.0001\n",
      "Epoch 19, Step: 841, Loss: 0.0253794826567173, Lr:0.0001\n",
      "Epoch 19, Step: 842, Loss: 0.05316302180290222, Lr:0.0001\n",
      "Epoch 19, Step: 843, Loss: 0.07649155706167221, Lr:0.0001\n",
      "Epoch 19, Step: 844, Loss: 0.35885393619537354, Lr:0.0001\n",
      "Epoch 19, Step: 845, Loss: 0.12365824729204178, Lr:0.0001\n",
      "Epoch 19, Step: 846, Loss: 0.001616153516806662, Lr:0.0001\n",
      "Epoch 19, Step: 847, Loss: 0.07666222751140594, Lr:0.0001\n",
      "Epoch 19, Step: 848, Loss: 0.02695748582482338, Lr:0.0001\n",
      "Epoch 19, Step: 849, Loss: 0.025811750441789627, Lr:0.0001\n",
      "Epoch 19, Step: 850, Loss: 0.08143560588359833, Lr:0.0001\n",
      "Epoch 19, Step: 851, Loss: 0.14013656973838806, Lr:0.0001\n",
      "Epoch 19, Step: 852, Loss: 0.021356377750635147, Lr:0.0001\n",
      "Epoch 19, Step: 853, Loss: 0.049888916313648224, Lr:0.0001\n",
      "Epoch 19, Step: 854, Loss: 0.05880165100097656, Lr:0.0001\n",
      "Epoch 19, Step: 855, Loss: 0.019400907680392265, Lr:0.0001\n",
      "Epoch 19, Step: 856, Loss: 0.1129387766122818, Lr:0.0001\n",
      "Epoch 19, Step: 857, Loss: 0.14697988331317902, Lr:0.0001\n",
      "Epoch 19, Step: 858, Loss: 0.12330455332994461, Lr:0.0001\n",
      "Epoch 19, Step: 859, Loss: 0.031249335035681725, Lr:0.0001\n",
      "Epoch 19, Step: 860, Loss: 0.07388116419315338, Lr:0.0001\n",
      "Epoch 19, Step: 861, Loss: 0.058697693049907684, Lr:0.0001\n",
      "Epoch 19, Step: 862, Loss: 0.17171674966812134, Lr:0.0001\n",
      "Epoch 19, Step: 863, Loss: 0.07885771244764328, Lr:0.0001\n",
      "Epoch 19, Step: 864, Loss: 0.013796119019389153, Lr:0.0001\n",
      "Epoch 19, Step: 865, Loss: 0.21295486390590668, Lr:0.0001\n",
      "Epoch 19, Step: 866, Loss: 0.002374888863414526, Lr:0.0001\n",
      "Epoch 19, Step: 867, Loss: 0.07777735590934753, Lr:0.0001\n",
      "Epoch 19, Step: 868, Loss: 0.05158383771777153, Lr:0.0001\n",
      "Epoch 19, Step: 869, Loss: 0.024713367223739624, Lr:0.0001\n",
      "Epoch 19, Step: 870, Loss: 0.03616441413760185, Lr:0.0001\n",
      "Epoch 19, Step: 871, Loss: 0.2782997786998749, Lr:0.0001\n",
      "Epoch 19, Step: 872, Loss: 0.02794010192155838, Lr:0.0001\n",
      "Epoch 19, Step: 873, Loss: 0.05592205375432968, Lr:0.0001\n",
      "Epoch 19, Step: 874, Loss: 0.13374511897563934, Lr:0.0001\n",
      "Epoch 19, Step: 875, Loss: 0.0711192935705185, Lr:0.0001\n",
      "Epoch 19, Step: 876, Loss: 0.15831109881401062, Lr:0.0001\n",
      "Epoch 19, Step: 877, Loss: 0.012951318174600601, Lr:0.0001\n",
      "Epoch 19, Step: 878, Loss: 0.4099346101284027, Lr:0.0001\n",
      "Epoch 19, Step: 879, Loss: 0.11465762555599213, Lr:0.0001\n",
      "Epoch 19, Step: 880, Loss: 0.022486358880996704, Lr:0.0001\n",
      "Epoch 19, Step: 881, Loss: 0.07202810794115067, Lr:0.0001\n",
      "Epoch 19, Step: 882, Loss: 0.06456373631954193, Lr:0.0001\n",
      "Epoch 19, Step: 883, Loss: 0.0617697536945343, Lr:0.0001\n",
      "Epoch 19, Step: 884, Loss: 0.04754818603396416, Lr:0.0001\n",
      "Epoch 19, Step: 885, Loss: 0.06178343668580055, Lr:0.0001\n",
      "Epoch 19, Step: 886, Loss: 0.006604605354368687, Lr:0.0001\n",
      "Epoch 19, Step: 887, Loss: 0.010649538598954678, Lr:0.0001\n",
      "Epoch 19, Step: 888, Loss: 0.05728466436266899, Lr:0.0001\n",
      "Epoch 19, Step: 889, Loss: 0.019301457330584526, Lr:0.0001\n",
      "Epoch 19, Step: 890, Loss: 0.026600079610943794, Lr:0.0001\n",
      "Epoch 19, Step: 891, Loss: 0.0425148569047451, Lr:0.0001\n",
      "Epoch 19, Step: 892, Loss: 0.01496176328510046, Lr:0.0001\n",
      "Epoch 19, Step: 893, Loss: 0.017102710902690887, Lr:0.0001\n",
      "Epoch 19, Step: 894, Loss: 0.26244157552719116, Lr:0.0001\n",
      "Epoch 19, Step: 895, Loss: 0.014233672060072422, Lr:0.0001\n",
      "Epoch 19, Step: 896, Loss: 0.0858546793460846, Lr:0.0001\n",
      "Epoch 19, Step: 897, Loss: 0.12108586728572845, Lr:0.0001\n",
      "Epoch 19, Step: 898, Loss: 0.012177161872386932, Lr:0.0001\n",
      "Epoch 19, Step: 899, Loss: 0.02480238676071167, Lr:0.0001\n",
      "Epoch 19, Step: 900, Loss: 0.27255165576934814, Lr:0.0001\n",
      "Epoch 19, Step: 901, Loss: 0.17389993369579315, Lr:0.0001\n",
      "Epoch 19, Step: 902, Loss: 0.04876270145177841, Lr:0.0001\n",
      "Epoch 19, Step: 903, Loss: 0.019687093794345856, Lr:0.0001\n",
      "Epoch 19, Step: 904, Loss: 0.11878831684589386, Lr:0.0001\n",
      "Epoch 19, Step: 905, Loss: 0.07863949984312057, Lr:0.0001\n",
      "Epoch 19, Step: 906, Loss: 0.23100470006465912, Lr:0.0001\n",
      "Epoch 19, Step: 907, Loss: 0.09756758064031601, Lr:0.0001\n",
      "Epoch 19, Step: 908, Loss: 0.006608919240534306, Lr:0.0001\n",
      "Epoch 19, Step: 909, Loss: 0.0833529531955719, Lr:0.0001\n",
      "Epoch 19, Step: 910, Loss: 0.16611501574516296, Lr:0.0001\n",
      "Epoch 19, Step: 911, Loss: 0.1902696192264557, Lr:0.0001\n",
      "Epoch 19, Step: 912, Loss: 0.008358031511306763, Lr:0.0001\n",
      "Epoch 19, Step: 913, Loss: 0.2344251275062561, Lr:0.0001\n",
      "Epoch 19, Step: 914, Loss: 0.18017524480819702, Lr:0.0001\n",
      "Epoch 19, Step: 915, Loss: 0.05246216431260109, Lr:0.0001\n",
      "Epoch 19, Step: 916, Loss: 0.020999502390623093, Lr:0.0001\n",
      "Epoch 19, Step: 917, Loss: 0.1732744574546814, Lr:0.0001\n",
      "Epoch 19, Step: 918, Loss: 0.010967688634991646, Lr:0.0001\n",
      "Epoch 19, Step: 919, Loss: 0.02110438235104084, Lr:0.0001\n",
      "Epoch 19, Step: 920, Loss: 0.11028068512678146, Lr:0.0001\n",
      "Epoch 19, Step: 921, Loss: 0.09699181467294693, Lr:0.0001\n",
      "Epoch 19, Step: 922, Loss: 0.04886041209101677, Lr:0.0001\n",
      "Epoch 19, Step: 923, Loss: 0.15388692915439606, Lr:0.0001\n",
      "Epoch 19, Step: 924, Loss: 0.0319301001727581, Lr:0.0001\n",
      "Epoch 19, Step: 925, Loss: 0.04255049675703049, Lr:0.0001\n",
      "Epoch 19, Step: 926, Loss: 0.4097851812839508, Lr:0.0001\n",
      "Epoch 19, Step: 927, Loss: 0.14180901646614075, Lr:0.0001\n",
      "Epoch 19, Step: 928, Loss: 0.0700850859284401, Lr:0.0001\n",
      "Epoch 19, Step: 929, Loss: 0.1170947328209877, Lr:0.0001\n",
      "Epoch 19, Step: 930, Loss: 0.1821696162223816, Lr:0.0001\n",
      "Epoch 19, Step: 931, Loss: 0.005210304167121649, Lr:0.0001\n",
      "Epoch 19, Step: 932, Loss: 0.0360405258834362, Lr:0.0001\n",
      "Epoch 19, Step: 933, Loss: 0.027434881776571274, Lr:0.0001\n",
      "Epoch 19, Step: 934, Loss: 0.08187975734472275, Lr:0.0001\n",
      "Epoch 19, Step: 935, Loss: 0.04671593755483627, Lr:0.0001\n",
      "Epoch 19, Step: 936, Loss: 0.0017263632034882903, Lr:0.0001\n",
      "Epoch 19, Step: 937, Loss: 0.17819103598594666, Lr:0.0001\n",
      "Epoch 19, Step: 938, Loss: 0.004017991945147514, Lr:0.0001\n",
      "Epoch 19, Step: 939, Loss: 0.03440803661942482, Lr:0.0001\n",
      "Epoch 19, Step: 940, Loss: 0.031036125496029854, Lr:0.0001\n",
      "Epoch 19, Step: 941, Loss: 0.039646074175834656, Lr:0.0001\n",
      "Epoch 19, Step: 942, Loss: 0.004077339544892311, Lr:0.0001\n",
      "Epoch 19, Step: 943, Loss: 0.03287942707538605, Lr:0.0001\n",
      "Epoch 19, Step: 944, Loss: 0.010005024261772633, Lr:0.0001\n",
      "Epoch 19, Step: 945, Loss: 0.22856183350086212, Lr:0.0001\n",
      "Epoch 19, Step: 946, Loss: 0.0032389594707638025, Lr:0.0001\n",
      "Epoch 19, Step: 947, Loss: 0.039117902517318726, Lr:0.0001\n",
      "Epoch 19, Step: 948, Loss: 0.08804623782634735, Lr:0.0001\n",
      "Epoch 19, Step: 949, Loss: 0.07485533505678177, Lr:0.0001\n",
      "Epoch 19, Step: 950, Loss: 0.03228527680039406, Lr:0.0001\n",
      "Epoch 19, Step: 951, Loss: 0.04385749623179436, Lr:0.0001\n",
      "Epoch 19, Step: 952, Loss: 0.2600104808807373, Lr:0.0001\n",
      "Epoch 19, Step: 953, Loss: 0.06607762724161148, Lr:0.0001\n",
      "Epoch 19, Step: 954, Loss: 0.06219339370727539, Lr:0.0001\n",
      "Epoch 19, Step: 955, Loss: 0.012481467798352242, Lr:0.0001\n",
      "Epoch 19, Step: 956, Loss: 0.006034309044480324, Lr:0.0001\n",
      "Epoch 19, Step: 957, Loss: 0.04888373613357544, Lr:0.0001\n",
      "Epoch 19, Step: 958, Loss: 0.022327575832605362, Lr:0.0001\n",
      "Epoch 19, Step: 959, Loss: 0.030291281640529633, Lr:0.0001\n",
      "Epoch 19, Step: 960, Loss: 0.07661444693803787, Lr:0.0001\n",
      "Epoch 19, Step: 961, Loss: 0.23142537474632263, Lr:0.0001\n",
      "Epoch 19, Step: 962, Loss: 0.015202080830931664, Lr:0.0001\n",
      "Epoch 19, Step: 963, Loss: 0.24889954924583435, Lr:0.0001\n",
      "Epoch 19, Step: 964, Loss: 0.4305873513221741, Lr:0.0001\n",
      "Epoch 19, Step: 965, Loss: 0.2840906083583832, Lr:0.0001\n",
      "Epoch 19, Step: 966, Loss: 0.1135047972202301, Lr:0.0001\n",
      "Epoch 19, Step: 967, Loss: 0.07997461408376694, Lr:0.0001\n",
      "Epoch 19, Step: 968, Loss: 0.11185909062623978, Lr:0.0001\n",
      "Epoch 19, Step: 969, Loss: 0.23765063285827637, Lr:0.0001\n",
      "Epoch 19, Step: 970, Loss: 0.2424228936433792, Lr:0.0001\n",
      "Epoch 19, Step: 971, Loss: 0.19696307182312012, Lr:0.0001\n",
      "Epoch 19, Step: 972, Loss: 0.03839042782783508, Lr:0.0001\n",
      "Epoch 19, Step: 973, Loss: 0.15872693061828613, Lr:0.0001\n",
      "Epoch 19, Step: 974, Loss: 0.05303720384836197, Lr:0.0001\n",
      "Epoch 19, Step: 975, Loss: 0.08701108396053314, Lr:0.0001\n",
      "Epoch 19, Step: 976, Loss: 0.04427424818277359, Lr:0.0001\n",
      "Epoch 19, Step: 977, Loss: 0.007072831504046917, Lr:0.0001\n",
      "Epoch 19, Step: 978, Loss: 0.051996514201164246, Lr:0.0001\n",
      "Epoch 19, Step: 979, Loss: 0.1213347315788269, Lr:0.0001\n",
      "Epoch 19, Step: 980, Loss: 0.07644768059253693, Lr:0.0001\n",
      "Epoch 19, Step: 981, Loss: 0.35389864444732666, Lr:0.0001\n",
      "Epoch 19, Step: 982, Loss: 0.005021132528781891, Lr:0.0001\n",
      "Epoch 19, Step: 983, Loss: 0.03024253249168396, Lr:0.0001\n",
      "Epoch 19, Step: 984, Loss: 0.10703402757644653, Lr:0.0001\n",
      "Epoch 19, Step: 985, Loss: 0.04189235717058182, Lr:0.0001\n",
      "Epoch 19, Step: 986, Loss: 0.3288573622703552, Lr:0.0001\n",
      "Epoch 19, Step: 987, Loss: 0.11732152849435806, Lr:0.0001\n",
      "Epoch 19, Step: 988, Loss: 0.010461362078785896, Lr:0.0001\n",
      "Epoch 19, Step: 989, Loss: 0.013747365213930607, Lr:0.0001\n",
      "Epoch 19, Step: 990, Loss: 0.18215426802635193, Lr:0.0001\n",
      "Epoch 19, Step: 991, Loss: 0.31234732270240784, Lr:0.0001\n",
      "Epoch 19, Step: 992, Loss: 0.17722465097904205, Lr:0.0001\n",
      "Epoch 19, Step: 993, Loss: 0.03705441951751709, Lr:0.0001\n",
      "Epoch 19, Step: 994, Loss: 0.013108472339808941, Lr:0.0001\n",
      "Epoch 19, Step: 995, Loss: 0.5070759654045105, Lr:0.0001\n",
      "Epoch 19, Step: 996, Loss: 0.01636391505599022, Lr:0.0001\n",
      "Epoch 19, Step: 997, Loss: 0.13429667055606842, Lr:0.0001\n",
      "Epoch 19, Step: 998, Loss: 0.026681026443839073, Lr:0.0001\n",
      "Epoch 19, Step: 999, Loss: 0.031898126006126404, Lr:0.0001\n",
      "Epoch 19, Step: 1000, Loss: 0.10374447703361511, Lr:0.0001\n",
      "Epoch 19, Step: 1001, Loss: 0.02533184550702572, Lr:0.0001\n",
      "Epoch 19, Step: 1002, Loss: 0.09933385998010635, Lr:0.0001\n",
      "Epoch 19, Step: 1003, Loss: 0.05473881959915161, Lr:0.0001\n",
      "Epoch 19, Step: 1004, Loss: 0.03492326661944389, Lr:0.0001\n",
      "Epoch 19, Step: 1005, Loss: 0.00895619671791792, Lr:0.0001\n",
      "Epoch 19, Step: 1006, Loss: 0.06720240414142609, Lr:0.0001\n",
      "Epoch 19, Step: 1007, Loss: 0.18900932371616364, Lr:0.0001\n",
      "Epoch 19, Step: 1008, Loss: 0.07913786917924881, Lr:0.0001\n",
      "Epoch 19, Step: 1009, Loss: 0.034439049661159515, Lr:0.0001\n",
      "Epoch 19, Step: 1010, Loss: 0.05600321665406227, Lr:0.0001\n",
      "Epoch 19, Step: 1011, Loss: 0.12348940223455429, Lr:0.0001\n",
      "Epoch 19, Step: 1012, Loss: 0.0070840963162481785, Lr:0.0001\n",
      "Epoch 19, Step: 1013, Loss: 0.03931298106908798, Lr:0.0001\n",
      "Epoch 19, Step: 1014, Loss: 0.02659222111105919, Lr:0.0001\n",
      "Epoch 19, Step: 1015, Loss: 0.030518358573317528, Lr:0.0001\n",
      "Epoch 19, Step: 1016, Loss: 0.017046786844730377, Lr:0.0001\n",
      "Epoch 19, Step: 1017, Loss: 0.21501781046390533, Lr:0.0001\n",
      "Epoch 19, Step: 1018, Loss: 0.1472778469324112, Lr:0.0001\n",
      "Epoch 19, Step: 1019, Loss: 0.025793779641389847, Lr:0.0001\n",
      "Epoch 19, Step: 1020, Loss: 0.2303910106420517, Lr:0.0001\n",
      "Epoch 19, Step: 1021, Loss: 0.0715668797492981, Lr:0.0001\n",
      "Epoch 19, Step: 1022, Loss: 0.045358289033174515, Lr:0.0001\n",
      "Epoch 19, Step: 1023, Loss: 0.005604858510196209, Lr:0.0001\n",
      "Epoch 19, Step: 1024, Loss: 0.08886316418647766, Lr:0.0001\n",
      "Epoch 19, Step: 1025, Loss: 0.05680513754487038, Lr:0.0001\n",
      "Epoch 19, Step: 1026, Loss: 0.017987368628382683, Lr:0.0001\n",
      "Epoch 19, Step: 1027, Loss: 0.2233482003211975, Lr:0.0001\n",
      "Epoch 19, Step: 1028, Loss: 0.011559456586837769, Lr:0.0001\n",
      "Epoch 19, Step: 1029, Loss: 0.16846351325511932, Lr:0.0001\n",
      "Epoch 19, Step: 1030, Loss: 0.16528251767158508, Lr:0.0001\n",
      "Epoch 19, Step: 1031, Loss: 0.09345120191574097, Lr:0.0001\n",
      "Epoch 19, Step: 1032, Loss: 0.02130904607474804, Lr:0.0001\n",
      "Epoch 19, Step: 1033, Loss: 0.0313870906829834, Lr:0.0001\n",
      "Epoch 19, Step: 1034, Loss: 0.0707588791847229, Lr:0.0001\n",
      "Epoch 19, Step: 1035, Loss: 0.062060482800006866, Lr:0.0001\n",
      "Epoch 19, Step: 1036, Loss: 0.18328054249286652, Lr:0.0001\n",
      "Epoch 19, Step: 1037, Loss: 0.0697937160730362, Lr:0.0001\n",
      "Epoch 19, Step: 1038, Loss: 0.01015016995370388, Lr:0.0001\n",
      "Epoch 19, Step: 1039, Loss: 0.06982789188623428, Lr:0.0001\n",
      "Epoch 19, Step: 1040, Loss: 0.10549916326999664, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 19\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:15 loss: 0.0275 (0.0275) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.2717 data: 0.1047 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:12 loss: 0.0024 (0.0070) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.2797 data: 0.1061 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0024 (0.0182) acc1: 100.0000 (99.4048) acc5: 100.0000 (100.0000) time: 0.2795 data: 0.1063 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.0379 (0.3055) acc1: 100.0000 (94.9597) acc5: 100.0000 (100.0000) time: 0.2824 data: 0.1090 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.0992 (0.2725) acc1: 93.7500 (94.8171) acc5: 100.0000 (100.0000) time: 0.2878 data: 0.1133 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0554 (0.2696) acc1: 93.7500 (94.3627) acc5: 100.0000 (100.0000) time: 0.2885 data: 0.1132 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0554 (0.3567) acc1: 93.7500 (93.9841) acc5: 100.0000 (100.0000) time: 0.2743 data: 0.1073 max mem: 15137\n",
      "Test: Total time: 0:00:15 (0.2793 s / it)\n",
      "* Acc@1 93.984 Acc@5 100.000 loss 0.357\n",
      "Accuracy of the network on the 881 test image: 94.0%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 20, Step: 0, Loss: 0.11120447516441345, Lr:0.0001\n",
      "Epoch 20, Step: 1, Loss: 0.06180330738425255, Lr:0.0001\n",
      "Epoch 20, Step: 2, Loss: 0.07869858294725418, Lr:0.0001\n",
      "Epoch 20, Step: 3, Loss: 0.043199364095926285, Lr:0.0001\n",
      "Epoch 20, Step: 4, Loss: 0.07729316502809525, Lr:0.0001\n",
      "Epoch 20, Step: 5, Loss: 0.041878245770931244, Lr:0.0001\n",
      "Epoch 20, Step: 6, Loss: 0.010978423058986664, Lr:0.0001\n",
      "Epoch 20, Step: 7, Loss: 0.03057534247636795, Lr:0.0001\n",
      "Epoch 20, Step: 8, Loss: 0.05098940059542656, Lr:0.0001\n",
      "Epoch 20, Step: 9, Loss: 0.06127510219812393, Lr:0.0001\n",
      "Epoch 20, Step: 10, Loss: 0.02616407349705696, Lr:0.0001\n",
      "Epoch 20, Step: 11, Loss: 0.016284644603729248, Lr:0.0001\n",
      "Epoch 20, Step: 12, Loss: 0.028480535373091698, Lr:0.0001\n",
      "Epoch 20, Step: 13, Loss: 0.026069525629281998, Lr:0.0001\n",
      "Epoch 20, Step: 14, Loss: 0.06872878223657608, Lr:0.0001\n",
      "Epoch 20, Step: 15, Loss: 0.0912390872836113, Lr:0.0001\n",
      "Epoch 20, Step: 16, Loss: 0.021960094571113586, Lr:0.0001\n",
      "Epoch 20, Step: 17, Loss: 0.2676860988140106, Lr:0.0001\n",
      "Epoch 20, Step: 18, Loss: 0.025464806705713272, Lr:0.0001\n",
      "Epoch 20, Step: 19, Loss: 0.04345174506306648, Lr:0.0001\n",
      "Epoch 20, Step: 20, Loss: 0.0036689748521894217, Lr:0.0001\n",
      "Epoch 20, Step: 21, Loss: 0.020384589210152626, Lr:0.0001\n",
      "Epoch 20, Step: 22, Loss: 0.0851868987083435, Lr:0.0001\n",
      "Epoch 20, Step: 23, Loss: 0.16208209097385406, Lr:0.0001\n",
      "Epoch 20, Step: 24, Loss: 0.2367849349975586, Lr:0.0001\n",
      "Epoch 20, Step: 25, Loss: 0.12161628156900406, Lr:0.0001\n",
      "Epoch 20, Step: 26, Loss: 0.012484767474234104, Lr:0.0001\n",
      "Epoch 20, Step: 27, Loss: 0.06892123073339462, Lr:0.0001\n",
      "Epoch 20, Step: 28, Loss: 0.056065578013658524, Lr:0.0001\n",
      "Epoch 20, Step: 29, Loss: 0.043065816164016724, Lr:0.0001\n",
      "Epoch 20, Step: 30, Loss: 0.08631565421819687, Lr:0.0001\n",
      "Epoch 20, Step: 31, Loss: 0.01789345219731331, Lr:0.0001\n",
      "Epoch 20, Step: 32, Loss: 0.15495064854621887, Lr:0.0001\n",
      "Epoch 20, Step: 33, Loss: 0.28123924136161804, Lr:0.0001\n",
      "Epoch 20, Step: 34, Loss: 0.35804569721221924, Lr:0.0001\n",
      "Epoch 20, Step: 35, Loss: 0.05407913029193878, Lr:0.0001\n",
      "Epoch 20, Step: 36, Loss: 0.13085411489009857, Lr:0.0001\n",
      "Epoch 20, Step: 37, Loss: 0.16594667732715607, Lr:0.0001\n",
      "Epoch 20, Step: 38, Loss: 0.02734481543302536, Lr:0.0001\n",
      "Epoch 20, Step: 39, Loss: 0.04866218939423561, Lr:0.0001\n",
      "Epoch 20, Step: 40, Loss: 0.038885343819856644, Lr:0.0001\n",
      "Epoch 20, Step: 41, Loss: 0.1445934772491455, Lr:0.0001\n",
      "Epoch 20, Step: 42, Loss: 0.03213810175657272, Lr:0.0001\n",
      "Epoch 20, Step: 43, Loss: 0.021355636417865753, Lr:0.0001\n",
      "Epoch 20, Step: 44, Loss: 0.0014530231710523367, Lr:0.0001\n",
      "Epoch 20, Step: 45, Loss: 0.06539278477430344, Lr:0.0001\n",
      "Epoch 20, Step: 46, Loss: 0.0376148447394371, Lr:0.0001\n",
      "Epoch 20, Step: 47, Loss: 0.03378089517354965, Lr:0.0001\n",
      "Epoch 20, Step: 48, Loss: 0.0199818704277277, Lr:0.0001\n",
      "Epoch 20, Step: 49, Loss: 0.1063656434416771, Lr:0.0001\n",
      "Epoch 20, Step: 50, Loss: 0.017024345695972443, Lr:0.0001\n",
      "Epoch 20, Step: 51, Loss: 0.0047855256125330925, Lr:0.0001\n",
      "Epoch 20, Step: 52, Loss: 0.024750644341111183, Lr:0.0001\n",
      "Epoch 20, Step: 53, Loss: 0.016153091564774513, Lr:0.0001\n",
      "Epoch 20, Step: 54, Loss: 0.27331066131591797, Lr:0.0001\n",
      "Epoch 20, Step: 55, Loss: 0.13722895085811615, Lr:0.0001\n",
      "Epoch 20, Step: 56, Loss: 0.015445612370967865, Lr:0.0001\n",
      "Epoch 20, Step: 57, Loss: 0.22588424384593964, Lr:0.0001\n",
      "Epoch 20, Step: 58, Loss: 0.15734319388866425, Lr:0.0001\n",
      "Epoch 20, Step: 59, Loss: 0.003450520569458604, Lr:0.0001\n",
      "Epoch 20, Step: 60, Loss: 0.10991150140762329, Lr:0.0001\n",
      "Epoch 20, Step: 61, Loss: 0.020739493891596794, Lr:0.0001\n",
      "Epoch 20, Step: 62, Loss: 0.043172840029001236, Lr:0.0001\n",
      "Epoch 20, Step: 63, Loss: 0.011558323167264462, Lr:0.0001\n",
      "Epoch 20, Step: 64, Loss: 0.007896674796938896, Lr:0.0001\n",
      "Epoch 20, Step: 65, Loss: 0.08067267388105392, Lr:0.0001\n",
      "Epoch 20, Step: 66, Loss: 0.07637360692024231, Lr:0.0001\n",
      "Epoch 20, Step: 67, Loss: 0.006634152494370937, Lr:0.0001\n",
      "Epoch 20, Step: 68, Loss: 0.08216138929128647, Lr:0.0001\n",
      "Epoch 20, Step: 69, Loss: 0.048002175986766815, Lr:0.0001\n",
      "Epoch 20, Step: 70, Loss: 0.016505207866430283, Lr:0.0001\n",
      "Epoch 20, Step: 71, Loss: 0.06074975058436394, Lr:0.0001\n",
      "Epoch 20, Step: 72, Loss: 0.1284211128950119, Lr:0.0001\n",
      "Epoch 20, Step: 73, Loss: 0.11677251756191254, Lr:0.0001\n",
      "Epoch 20, Step: 74, Loss: 0.012254650704562664, Lr:0.0001\n",
      "Epoch 20, Step: 75, Loss: 0.04470240697264671, Lr:0.0001\n",
      "Epoch 20, Step: 76, Loss: 0.010294482111930847, Lr:0.0001\n",
      "Epoch 20, Step: 77, Loss: 0.0282096229493618, Lr:0.0001\n",
      "Epoch 20, Step: 78, Loss: 0.001571929664351046, Lr:0.0001\n",
      "Epoch 20, Step: 79, Loss: 0.026966802775859833, Lr:0.0001\n",
      "Epoch 20, Step: 80, Loss: 0.2625698149204254, Lr:0.0001\n",
      "Epoch 20, Step: 81, Loss: 0.027124905958771706, Lr:0.0001\n",
      "Epoch 20, Step: 82, Loss: 0.003789209295064211, Lr:0.0001\n",
      "Epoch 20, Step: 83, Loss: 0.24984364211559296, Lr:0.0001\n",
      "Epoch 20, Step: 84, Loss: 0.18348777294158936, Lr:0.0001\n",
      "Epoch 20, Step: 85, Loss: 0.04953024908900261, Lr:0.0001\n",
      "Epoch 20, Step: 86, Loss: 0.03274114429950714, Lr:0.0001\n",
      "Epoch 20, Step: 87, Loss: 0.017082562670111656, Lr:0.0001\n",
      "Epoch 20, Step: 88, Loss: 0.03168116882443428, Lr:0.0001\n",
      "Epoch 20, Step: 89, Loss: 0.05381588265299797, Lr:0.0001\n",
      "Epoch 20, Step: 90, Loss: 0.05325512960553169, Lr:0.0001\n",
      "Epoch 20, Step: 91, Loss: 0.06680644303560257, Lr:0.0001\n",
      "Epoch 20, Step: 92, Loss: 0.09298600256443024, Lr:0.0001\n",
      "Epoch 20, Step: 93, Loss: 0.2107190489768982, Lr:0.0001\n",
      "Epoch 20, Step: 94, Loss: 0.10250900685787201, Lr:0.0001\n",
      "Epoch 20, Step: 95, Loss: 0.11853891611099243, Lr:0.0001\n",
      "Epoch 20, Step: 96, Loss: 0.24444173276424408, Lr:0.0001\n",
      "Epoch 20, Step: 97, Loss: 0.022334251552820206, Lr:0.0001\n",
      "Epoch 20, Step: 98, Loss: 0.23017466068267822, Lr:0.0001\n",
      "Epoch 20, Step: 99, Loss: 0.05811745300889015, Lr:0.0001\n",
      "Epoch 20, Step: 100, Loss: 0.23785090446472168, Lr:0.0001\n",
      "Epoch 20, Step: 101, Loss: 0.12794560194015503, Lr:0.0001\n",
      "Epoch 20, Step: 102, Loss: 0.04325733333826065, Lr:0.0001\n",
      "Epoch 20, Step: 103, Loss: 0.028762247413396835, Lr:0.0001\n",
      "Epoch 20, Step: 104, Loss: 0.1447795182466507, Lr:0.0001\n",
      "Epoch 20, Step: 105, Loss: 0.022916529327630997, Lr:0.0001\n",
      "Epoch 20, Step: 106, Loss: 0.024040568619966507, Lr:0.0001\n",
      "Epoch 20, Step: 107, Loss: 0.1904369741678238, Lr:0.0001\n",
      "Epoch 20, Step: 108, Loss: 0.0037509286776185036, Lr:0.0001\n",
      "Epoch 20, Step: 109, Loss: 0.2537848651409149, Lr:0.0001\n",
      "Epoch 20, Step: 110, Loss: 0.08366070687770844, Lr:0.0001\n",
      "Epoch 20, Step: 111, Loss: 0.3353196978569031, Lr:0.0001\n",
      "Epoch 20, Step: 112, Loss: 0.008771701715886593, Lr:0.0001\n",
      "Epoch 20, Step: 113, Loss: 0.10767871141433716, Lr:0.0001\n",
      "Epoch 20, Step: 114, Loss: 0.08800051361322403, Lr:0.0001\n",
      "Epoch 20, Step: 115, Loss: 0.06672818213701248, Lr:0.0001\n",
      "Epoch 20, Step: 116, Loss: 0.15588945150375366, Lr:0.0001\n",
      "Epoch 20, Step: 117, Loss: 0.05005648732185364, Lr:0.0001\n",
      "Epoch 20, Step: 118, Loss: 0.04501195624470711, Lr:0.0001\n",
      "Epoch 20, Step: 119, Loss: 0.023462537676095963, Lr:0.0001\n",
      "Epoch 20, Step: 120, Loss: 0.0068921782076358795, Lr:0.0001\n",
      "Epoch 20, Step: 121, Loss: 0.005475138314068317, Lr:0.0001\n",
      "Epoch 20, Step: 122, Loss: 0.08401697874069214, Lr:0.0001\n",
      "Epoch 20, Step: 123, Loss: 0.002778061665594578, Lr:0.0001\n",
      "Epoch 20, Step: 124, Loss: 0.017607513815164566, Lr:0.0001\n",
      "Epoch 20, Step: 125, Loss: 0.012391881085932255, Lr:0.0001\n",
      "Epoch 20, Step: 126, Loss: 0.02294759638607502, Lr:0.0001\n",
      "Epoch 20, Step: 127, Loss: 0.13947318494319916, Lr:0.0001\n",
      "Epoch 20, Step: 128, Loss: 0.289909303188324, Lr:0.0001\n",
      "Epoch 20, Step: 129, Loss: 0.05550462380051613, Lr:0.0001\n",
      "Epoch 20, Step: 130, Loss: 0.18930663168430328, Lr:0.0001\n",
      "Epoch 20, Step: 131, Loss: 0.0831647664308548, Lr:0.0001\n",
      "Epoch 20, Step: 132, Loss: 0.01134442538022995, Lr:0.0001\n",
      "Epoch 20, Step: 133, Loss: 0.04798034206032753, Lr:0.0001\n",
      "Epoch 20, Step: 134, Loss: 0.0193976741284132, Lr:0.0001\n",
      "Epoch 20, Step: 135, Loss: 0.02593829296529293, Lr:0.0001\n",
      "Epoch 20, Step: 136, Loss: 0.012551840394735336, Lr:0.0001\n",
      "Epoch 20, Step: 137, Loss: 0.1000310480594635, Lr:0.0001\n",
      "Epoch 20, Step: 138, Loss: 0.023215336725115776, Lr:0.0001\n",
      "Epoch 20, Step: 139, Loss: 0.31122052669525146, Lr:0.0001\n",
      "Epoch 20, Step: 140, Loss: 0.07923894375562668, Lr:0.0001\n",
      "Epoch 20, Step: 141, Loss: 0.04901788383722305, Lr:0.0001\n",
      "Epoch 20, Step: 142, Loss: 0.2015535980463028, Lr:0.0001\n",
      "Epoch 20, Step: 143, Loss: 0.1389458328485489, Lr:0.0001\n",
      "Epoch 20, Step: 144, Loss: 0.0072655631229281425, Lr:0.0001\n",
      "Epoch 20, Step: 145, Loss: 0.08049693703651428, Lr:0.0001\n",
      "Epoch 20, Step: 146, Loss: 0.009887239895761013, Lr:0.0001\n",
      "Epoch 20, Step: 147, Loss: 0.05318975821137428, Lr:0.0001\n",
      "Epoch 20, Step: 148, Loss: 0.005515766330063343, Lr:0.0001\n",
      "Epoch 20, Step: 149, Loss: 0.04177200794219971, Lr:0.0001\n",
      "Epoch 20, Step: 150, Loss: 0.21880865097045898, Lr:0.0001\n",
      "Epoch 20, Step: 151, Loss: 0.04520726576447487, Lr:0.0001\n",
      "Epoch 20, Step: 152, Loss: 0.032561637461185455, Lr:0.0001\n",
      "Epoch 20, Step: 153, Loss: 0.10454782843589783, Lr:0.0001\n",
      "Epoch 20, Step: 154, Loss: 0.14062881469726562, Lr:0.0001\n",
      "Epoch 20, Step: 155, Loss: 0.07400970160961151, Lr:0.0001\n",
      "Epoch 20, Step: 156, Loss: 0.1354609578847885, Lr:0.0001\n",
      "Epoch 20, Step: 157, Loss: 0.037347521632909775, Lr:0.0001\n",
      "Epoch 20, Step: 158, Loss: 0.07444338500499725, Lr:0.0001\n",
      "Epoch 20, Step: 159, Loss: 0.00514101842418313, Lr:0.0001\n",
      "Epoch 20, Step: 160, Loss: 0.06970269978046417, Lr:0.0001\n",
      "Epoch 20, Step: 161, Loss: 0.011231113225221634, Lr:0.0001\n",
      "Epoch 20, Step: 162, Loss: 0.1167752668261528, Lr:0.0001\n",
      "Epoch 20, Step: 163, Loss: 0.0033499719575047493, Lr:0.0001\n",
      "Epoch 20, Step: 164, Loss: 0.04201696068048477, Lr:0.0001\n",
      "Epoch 20, Step: 165, Loss: 0.09806865453720093, Lr:0.0001\n",
      "Epoch 20, Step: 166, Loss: 0.0032610290218144655, Lr:0.0001\n",
      "Epoch 20, Step: 167, Loss: 0.0695316269993782, Lr:0.0001\n",
      "Epoch 20, Step: 168, Loss: 0.029951859265565872, Lr:0.0001\n",
      "Epoch 20, Step: 169, Loss: 0.04207858815789223, Lr:0.0001\n",
      "Epoch 20, Step: 170, Loss: 0.194005087018013, Lr:0.0001\n",
      "Epoch 20, Step: 171, Loss: 0.0827566608786583, Lr:0.0001\n",
      "Epoch 20, Step: 172, Loss: 0.02892106957733631, Lr:0.0001\n",
      "Epoch 20, Step: 173, Loss: 0.025369320064783096, Lr:0.0001\n",
      "Epoch 20, Step: 174, Loss: 0.004932226613163948, Lr:0.0001\n",
      "Epoch 20, Step: 175, Loss: 0.03718307241797447, Lr:0.0001\n",
      "Epoch 20, Step: 176, Loss: 0.021705154329538345, Lr:0.0001\n",
      "Epoch 20, Step: 177, Loss: 0.055358462035655975, Lr:0.0001\n",
      "Epoch 20, Step: 178, Loss: 0.023717408999800682, Lr:0.0001\n",
      "Epoch 20, Step: 179, Loss: 0.06690188497304916, Lr:0.0001\n",
      "Epoch 20, Step: 180, Loss: 0.0069277225993573666, Lr:0.0001\n",
      "Epoch 20, Step: 181, Loss: 0.06994562596082687, Lr:0.0001\n",
      "Epoch 20, Step: 182, Loss: 0.04004295542836189, Lr:0.0001\n",
      "Epoch 20, Step: 183, Loss: 0.25097325444221497, Lr:0.0001\n",
      "Epoch 20, Step: 184, Loss: 0.007004758343100548, Lr:0.0001\n",
      "Epoch 20, Step: 185, Loss: 0.22977003455162048, Lr:0.0001\n",
      "Epoch 20, Step: 186, Loss: 0.31386464834213257, Lr:0.0001\n",
      "Epoch 20, Step: 187, Loss: 0.018736323341727257, Lr:0.0001\n",
      "Epoch 20, Step: 188, Loss: 0.017725404351949692, Lr:0.0001\n",
      "Epoch 20, Step: 189, Loss: 0.00808708369731903, Lr:0.0001\n",
      "Epoch 20, Step: 190, Loss: 0.003931665793061256, Lr:0.0001\n",
      "Epoch 20, Step: 191, Loss: 0.016008591279387474, Lr:0.0001\n",
      "Epoch 20, Step: 192, Loss: 0.07154388725757599, Lr:0.0001\n",
      "Epoch 20, Step: 193, Loss: 0.014444837346673012, Lr:0.0001\n",
      "Epoch 20, Step: 194, Loss: 0.23495566844940186, Lr:0.0001\n",
      "Epoch 20, Step: 195, Loss: 0.004428161773830652, Lr:0.0001\n",
      "Epoch 20, Step: 196, Loss: 0.0038053563330322504, Lr:0.0001\n",
      "Epoch 20, Step: 197, Loss: 0.12415550649166107, Lr:0.0001\n",
      "Epoch 20, Step: 198, Loss: 0.02350754663348198, Lr:0.0001\n",
      "Epoch 20, Step: 199, Loss: 0.020355187356472015, Lr:0.0001\n",
      "Epoch 20, Step: 200, Loss: 0.007242468185722828, Lr:0.0001\n",
      "Epoch 20, Step: 201, Loss: 0.07583282887935638, Lr:0.0001\n",
      "Epoch 20, Step: 202, Loss: 0.07927050441503525, Lr:0.0001\n",
      "Epoch 20, Step: 203, Loss: 0.14018777012825012, Lr:0.0001\n",
      "Epoch 20, Step: 204, Loss: 0.14226530492305756, Lr:0.0001\n",
      "Epoch 20, Step: 205, Loss: 0.009988635778427124, Lr:0.0001\n",
      "Epoch 20, Step: 206, Loss: 0.004943196661770344, Lr:0.0001\n",
      "Epoch 20, Step: 207, Loss: 0.0051700398325920105, Lr:0.0001\n",
      "Epoch 20, Step: 208, Loss: 0.08227924257516861, Lr:0.0001\n",
      "Epoch 20, Step: 209, Loss: 0.13240709900856018, Lr:0.0001\n",
      "Epoch 20, Step: 210, Loss: 0.1285269856452942, Lr:0.0001\n",
      "Epoch 20, Step: 211, Loss: 0.07433773577213287, Lr:0.0001\n",
      "Epoch 20, Step: 212, Loss: 0.015120568685233593, Lr:0.0001\n",
      "Epoch 20, Step: 213, Loss: 0.021510612219572067, Lr:0.0001\n",
      "Epoch 20, Step: 214, Loss: 0.09165509790182114, Lr:0.0001\n",
      "Epoch 20, Step: 215, Loss: 0.015811346471309662, Lr:0.0001\n",
      "Epoch 20, Step: 216, Loss: 0.028140611946582794, Lr:0.0001\n",
      "Epoch 20, Step: 217, Loss: 0.23455332219600677, Lr:0.0001\n",
      "Epoch 20, Step: 218, Loss: 0.09313241392374039, Lr:0.0001\n",
      "Epoch 20, Step: 219, Loss: 0.08655289560556412, Lr:0.0001\n",
      "Epoch 20, Step: 220, Loss: 0.02400178462266922, Lr:0.0001\n",
      "Epoch 20, Step: 221, Loss: 0.014283227734267712, Lr:0.0001\n",
      "Epoch 20, Step: 222, Loss: 0.0057432823814451694, Lr:0.0001\n",
      "Epoch 20, Step: 223, Loss: 0.36784234642982483, Lr:0.0001\n",
      "Epoch 20, Step: 224, Loss: 0.0006275548366829753, Lr:0.0001\n",
      "Epoch 20, Step: 225, Loss: 0.17128048837184906, Lr:0.0001\n",
      "Epoch 20, Step: 226, Loss: 0.1521439403295517, Lr:0.0001\n",
      "Epoch 20, Step: 227, Loss: 0.0013791375095024705, Lr:0.0001\n",
      "Epoch 20, Step: 228, Loss: 0.0007846617954783142, Lr:0.0001\n",
      "Epoch 20, Step: 229, Loss: 0.015973487868905067, Lr:0.0001\n",
      "Epoch 20, Step: 230, Loss: 0.09110037982463837, Lr:0.0001\n",
      "Epoch 20, Step: 231, Loss: 0.06834083795547485, Lr:0.0001\n",
      "Epoch 20, Step: 232, Loss: 0.1181068867444992, Lr:0.0001\n",
      "Epoch 20, Step: 233, Loss: 0.07122831791639328, Lr:0.0001\n",
      "Epoch 20, Step: 234, Loss: 0.032745182514190674, Lr:0.0001\n",
      "Epoch 20, Step: 235, Loss: 0.015699274837970734, Lr:0.0001\n",
      "Epoch 20, Step: 236, Loss: 0.029677925631403923, Lr:0.0001\n",
      "Epoch 20, Step: 237, Loss: 0.2152310609817505, Lr:0.0001\n",
      "Epoch 20, Step: 238, Loss: 0.12701818346977234, Lr:0.0001\n",
      "Epoch 20, Step: 239, Loss: 0.05648220330476761, Lr:0.0001\n",
      "Epoch 20, Step: 240, Loss: 0.20904316008090973, Lr:0.0001\n",
      "Epoch 20, Step: 241, Loss: 0.0694669634103775, Lr:0.0001\n",
      "Epoch 20, Step: 242, Loss: 0.057525552809238434, Lr:0.0001\n",
      "Epoch 20, Step: 243, Loss: 0.010322258807718754, Lr:0.0001\n",
      "Epoch 20, Step: 244, Loss: 0.8560566306114197, Lr:0.0001\n",
      "Epoch 20, Step: 245, Loss: 0.0880468562245369, Lr:0.0001\n",
      "Epoch 20, Step: 246, Loss: 0.04704894497990608, Lr:0.0001\n",
      "Epoch 20, Step: 247, Loss: 0.043559204787015915, Lr:0.0001\n",
      "Epoch 20, Step: 248, Loss: 0.025567807257175446, Lr:0.0001\n",
      "Epoch 20, Step: 249, Loss: 0.2922106683254242, Lr:0.0001\n",
      "Epoch 20, Step: 250, Loss: 0.09906985610723495, Lr:0.0001\n",
      "Epoch 20, Step: 251, Loss: 0.05770955979824066, Lr:0.0001\n",
      "Epoch 20, Step: 252, Loss: 0.09004082530736923, Lr:0.0001\n",
      "Epoch 20, Step: 253, Loss: 0.07064570486545563, Lr:0.0001\n",
      "Epoch 20, Step: 254, Loss: 0.04898231104016304, Lr:0.0001\n",
      "Epoch 20, Step: 255, Loss: 0.5812602639198303, Lr:0.0001\n",
      "Epoch 20, Step: 256, Loss: 0.0361766442656517, Lr:0.0001\n",
      "Epoch 20, Step: 257, Loss: 0.41052305698394775, Lr:0.0001\n",
      "Epoch 20, Step: 258, Loss: 0.3542284667491913, Lr:0.0001\n",
      "Epoch 20, Step: 259, Loss: 0.07899678498506546, Lr:0.0001\n",
      "Epoch 20, Step: 260, Loss: 0.16228826344013214, Lr:0.0001\n",
      "Epoch 20, Step: 261, Loss: 0.301937997341156, Lr:0.0001\n",
      "Epoch 20, Step: 262, Loss: 0.13032512366771698, Lr:0.0001\n",
      "Epoch 20, Step: 263, Loss: 0.36108919978141785, Lr:0.0001\n",
      "Epoch 20, Step: 264, Loss: 0.1913127899169922, Lr:0.0001\n",
      "Epoch 20, Step: 265, Loss: 0.0312843881547451, Lr:0.0001\n",
      "Epoch 20, Step: 266, Loss: 0.04995095729827881, Lr:0.0001\n",
      "Epoch 20, Step: 267, Loss: 0.08096491545438766, Lr:0.0001\n",
      "Epoch 20, Step: 268, Loss: 0.7068547010421753, Lr:0.0001\n",
      "Epoch 20, Step: 269, Loss: 0.3164212703704834, Lr:0.0001\n",
      "Epoch 20, Step: 270, Loss: 0.10533638298511505, Lr:0.0001\n",
      "Epoch 20, Step: 271, Loss: 0.46762675046920776, Lr:0.0001\n",
      "Epoch 20, Step: 272, Loss: 0.1772005259990692, Lr:0.0001\n",
      "Epoch 20, Step: 273, Loss: 0.02481738105416298, Lr:0.0001\n",
      "Epoch 20, Step: 274, Loss: 0.04844721406698227, Lr:0.0001\n",
      "Epoch 20, Step: 275, Loss: 0.09771346300840378, Lr:0.0001\n",
      "Epoch 20, Step: 276, Loss: 0.020050087943673134, Lr:0.0001\n",
      "Epoch 20, Step: 277, Loss: 0.2593284547328949, Lr:0.0001\n",
      "Epoch 20, Step: 278, Loss: 0.01618155650794506, Lr:0.0001\n",
      "Epoch 20, Step: 279, Loss: 0.12478665262460709, Lr:0.0001\n",
      "Epoch 20, Step: 280, Loss: 0.06433980166912079, Lr:0.0001\n",
      "Epoch 20, Step: 281, Loss: 0.1081370860338211, Lr:0.0001\n",
      "Epoch 20, Step: 282, Loss: 0.26043015718460083, Lr:0.0001\n",
      "Epoch 20, Step: 283, Loss: 0.10731241106987, Lr:0.0001\n",
      "Epoch 20, Step: 284, Loss: 0.029608191922307014, Lr:0.0001\n",
      "Epoch 20, Step: 285, Loss: 0.16707223653793335, Lr:0.0001\n",
      "Epoch 20, Step: 286, Loss: 0.11128462851047516, Lr:0.0001\n",
      "Epoch 20, Step: 287, Loss: 0.14652147889137268, Lr:0.0001\n",
      "Epoch 20, Step: 288, Loss: 0.03350502625107765, Lr:0.0001\n",
      "Epoch 20, Step: 289, Loss: 0.9187796115875244, Lr:0.0001\n",
      "Epoch 20, Step: 290, Loss: 0.16673339903354645, Lr:0.0001\n",
      "Epoch 20, Step: 291, Loss: 0.013599617406725883, Lr:0.0001\n",
      "Epoch 20, Step: 292, Loss: 0.10668415576219559, Lr:0.0001\n",
      "Epoch 20, Step: 293, Loss: 0.010783429257571697, Lr:0.0001\n",
      "Epoch 20, Step: 294, Loss: 0.14737458527088165, Lr:0.0001\n",
      "Epoch 20, Step: 295, Loss: 0.3448016345500946, Lr:0.0001\n",
      "Epoch 20, Step: 296, Loss: 0.019889619201421738, Lr:0.0001\n",
      "Epoch 20, Step: 297, Loss: 0.07817308604717255, Lr:0.0001\n",
      "Epoch 20, Step: 298, Loss: 0.15120774507522583, Lr:0.0001\n",
      "Epoch 20, Step: 299, Loss: 0.14424660801887512, Lr:0.0001\n",
      "Epoch 20, Step: 300, Loss: 0.2685050964355469, Lr:0.0001\n",
      "Epoch 20, Step: 301, Loss: 0.006717677228152752, Lr:0.0001\n",
      "Epoch 20, Step: 302, Loss: 0.01627568155527115, Lr:0.0001\n",
      "Epoch 20, Step: 303, Loss: 0.11806163936853409, Lr:0.0001\n",
      "Epoch 20, Step: 304, Loss: 0.08175078779459, Lr:0.0001\n",
      "Epoch 20, Step: 305, Loss: 0.023739106953144073, Lr:0.0001\n",
      "Epoch 20, Step: 306, Loss: 0.24100042879581451, Lr:0.0001\n",
      "Epoch 20, Step: 307, Loss: 0.1736823171377182, Lr:0.0001\n",
      "Epoch 20, Step: 308, Loss: 0.03680340200662613, Lr:0.0001\n",
      "Epoch 20, Step: 309, Loss: 0.23543918132781982, Lr:0.0001\n",
      "Epoch 20, Step: 310, Loss: 0.05924445018172264, Lr:0.0001\n",
      "Epoch 20, Step: 311, Loss: 0.07163305580615997, Lr:0.0001\n",
      "Epoch 20, Step: 312, Loss: 0.5993815064430237, Lr:0.0001\n",
      "Epoch 20, Step: 313, Loss: 0.022872652858495712, Lr:0.0001\n",
      "Epoch 20, Step: 314, Loss: 0.010449805296957493, Lr:0.0001\n",
      "Epoch 20, Step: 315, Loss: 0.03879668191075325, Lr:0.0001\n",
      "Epoch 20, Step: 316, Loss: 0.004326167982071638, Lr:0.0001\n",
      "Epoch 20, Step: 317, Loss: 0.017512887716293335, Lr:0.0001\n",
      "Epoch 20, Step: 318, Loss: 0.017638811841607094, Lr:0.0001\n",
      "Epoch 20, Step: 319, Loss: 0.025226566940546036, Lr:0.0001\n",
      "Epoch 20, Step: 320, Loss: 0.08808537572622299, Lr:0.0001\n",
      "Epoch 20, Step: 321, Loss: 0.20761485397815704, Lr:0.0001\n",
      "Epoch 20, Step: 322, Loss: 0.20695921778678894, Lr:0.0001\n",
      "Epoch 20, Step: 323, Loss: 0.0333704799413681, Lr:0.0001\n",
      "Epoch 20, Step: 324, Loss: 0.13296541571617126, Lr:0.0001\n",
      "Epoch 20, Step: 325, Loss: 0.30057165026664734, Lr:0.0001\n",
      "Epoch 20, Step: 326, Loss: 0.023401105776429176, Lr:0.0001\n",
      "Epoch 20, Step: 327, Loss: 0.12723921239376068, Lr:0.0001\n",
      "Epoch 20, Step: 328, Loss: 0.1585487425327301, Lr:0.0001\n",
      "Epoch 20, Step: 329, Loss: 0.08856689184904099, Lr:0.0001\n",
      "Epoch 20, Step: 330, Loss: 0.04155290499329567, Lr:0.0001\n",
      "Epoch 20, Step: 331, Loss: 0.034007590264081955, Lr:0.0001\n",
      "Epoch 20, Step: 332, Loss: 0.11063969880342484, Lr:0.0001\n",
      "Epoch 20, Step: 333, Loss: 0.13231076300144196, Lr:0.0001\n",
      "Epoch 20, Step: 334, Loss: 0.0877690315246582, Lr:0.0001\n",
      "Epoch 20, Step: 335, Loss: 0.06764824688434601, Lr:0.0001\n",
      "Epoch 20, Step: 336, Loss: 0.09839272499084473, Lr:0.0001\n",
      "Epoch 20, Step: 337, Loss: 0.011882130056619644, Lr:0.0001\n",
      "Epoch 20, Step: 338, Loss: 0.06836763769388199, Lr:0.0001\n",
      "Epoch 20, Step: 339, Loss: 0.14355745911598206, Lr:0.0001\n",
      "Epoch 20, Step: 340, Loss: 0.07103883475065231, Lr:0.0001\n",
      "Epoch 20, Step: 341, Loss: 0.05877403914928436, Lr:0.0001\n",
      "Epoch 20, Step: 342, Loss: 0.0006203744560480118, Lr:0.0001\n",
      "Epoch 20, Step: 343, Loss: 0.14580945670604706, Lr:0.0001\n",
      "Epoch 20, Step: 344, Loss: 0.004185419995337725, Lr:0.0001\n",
      "Epoch 20, Step: 345, Loss: 0.048312801867723465, Lr:0.0001\n",
      "Epoch 20, Step: 346, Loss: 0.07044839859008789, Lr:0.0001\n",
      "Epoch 20, Step: 347, Loss: 0.03888031840324402, Lr:0.0001\n",
      "Epoch 20, Step: 348, Loss: 0.05249191075563431, Lr:0.0001\n",
      "Epoch 20, Step: 349, Loss: 0.44686591625213623, Lr:0.0001\n",
      "Epoch 20, Step: 350, Loss: 0.02056349627673626, Lr:0.0001\n",
      "Epoch 20, Step: 351, Loss: 0.07411795854568481, Lr:0.0001\n",
      "Epoch 20, Step: 352, Loss: 0.18886813521385193, Lr:0.0001\n",
      "Epoch 20, Step: 353, Loss: 0.005166554357856512, Lr:0.0001\n",
      "Epoch 20, Step: 354, Loss: 0.051781680434942245, Lr:0.0001\n",
      "Epoch 20, Step: 355, Loss: 0.13875354826450348, Lr:0.0001\n",
      "Epoch 20, Step: 356, Loss: 0.038979921489953995, Lr:0.0001\n",
      "Epoch 20, Step: 357, Loss: 0.08543658256530762, Lr:0.0001\n",
      "Epoch 20, Step: 358, Loss: 0.07631275057792664, Lr:0.0001\n",
      "Epoch 20, Step: 359, Loss: 0.18704643845558167, Lr:0.0001\n",
      "Epoch 20, Step: 360, Loss: 0.06264009326696396, Lr:0.0001\n",
      "Epoch 20, Step: 361, Loss: 0.08228591084480286, Lr:0.0001\n",
      "Epoch 20, Step: 362, Loss: 0.05316093936562538, Lr:0.0001\n",
      "Epoch 20, Step: 363, Loss: 0.2068209946155548, Lr:0.0001\n",
      "Epoch 20, Step: 364, Loss: 0.13763998448848724, Lr:0.0001\n",
      "Epoch 20, Step: 365, Loss: 0.033681720495224, Lr:0.0001\n",
      "Epoch 20, Step: 366, Loss: 0.27872395515441895, Lr:0.0001\n",
      "Epoch 20, Step: 367, Loss: 0.011522316373884678, Lr:0.0001\n",
      "Epoch 20, Step: 368, Loss: 0.022656535729765892, Lr:0.0001\n",
      "Epoch 20, Step: 369, Loss: 0.07534139603376389, Lr:0.0001\n",
      "Epoch 20, Step: 370, Loss: 0.09124240279197693, Lr:0.0001\n",
      "Epoch 20, Step: 371, Loss: 0.07879731059074402, Lr:0.0001\n",
      "Epoch 20, Step: 372, Loss: 0.022223221138119698, Lr:0.0001\n",
      "Epoch 20, Step: 373, Loss: 0.036705102771520615, Lr:0.0001\n",
      "Epoch 20, Step: 374, Loss: 0.325239360332489, Lr:0.0001\n",
      "Epoch 20, Step: 375, Loss: 0.43160346150398254, Lr:0.0001\n",
      "Epoch 20, Step: 376, Loss: 0.06570940464735031, Lr:0.0001\n",
      "Epoch 20, Step: 377, Loss: 0.1760210394859314, Lr:0.0001\n",
      "Epoch 20, Step: 378, Loss: 0.026202550157904625, Lr:0.0001\n",
      "Epoch 20, Step: 379, Loss: 0.08739694952964783, Lr:0.0001\n",
      "Epoch 20, Step: 380, Loss: 0.06065569072961807, Lr:0.0001\n",
      "Epoch 20, Step: 381, Loss: 0.03736823797225952, Lr:0.0001\n",
      "Epoch 20, Step: 382, Loss: 0.012492842972278595, Lr:0.0001\n",
      "Epoch 20, Step: 383, Loss: 0.3002740442752838, Lr:0.0001\n",
      "Epoch 20, Step: 384, Loss: 0.15722998976707458, Lr:0.0001\n",
      "Epoch 20, Step: 385, Loss: 0.06281853467226028, Lr:0.0001\n",
      "Epoch 20, Step: 386, Loss: 0.17250941693782806, Lr:0.0001\n",
      "Epoch 20, Step: 387, Loss: 0.21269409358501434, Lr:0.0001\n",
      "Epoch 20, Step: 388, Loss: 0.15913844108581543, Lr:0.0001\n",
      "Epoch 20, Step: 389, Loss: 0.061169274151325226, Lr:0.0001\n",
      "Epoch 20, Step: 390, Loss: 0.11796960979700089, Lr:0.0001\n",
      "Epoch 20, Step: 391, Loss: 0.061788324266672134, Lr:0.0001\n",
      "Epoch 20, Step: 392, Loss: 0.09765960276126862, Lr:0.0001\n",
      "Epoch 20, Step: 393, Loss: 0.002834523329511285, Lr:0.0001\n",
      "Epoch 20, Step: 394, Loss: 0.024573195725679398, Lr:0.0001\n",
      "Epoch 20, Step: 395, Loss: 0.11759370565414429, Lr:0.0001\n",
      "Epoch 20, Step: 396, Loss: 0.42156022787094116, Lr:0.0001\n",
      "Epoch 20, Step: 397, Loss: 0.12633980810642242, Lr:0.0001\n",
      "Epoch 20, Step: 398, Loss: 0.11228064447641373, Lr:0.0001\n",
      "Epoch 20, Step: 399, Loss: 0.00870581902563572, Lr:0.0001\n",
      "Epoch 20, Step: 400, Loss: 0.08156867325305939, Lr:0.0001\n",
      "Epoch 20, Step: 401, Loss: 0.008298169821500778, Lr:0.0001\n",
      "Epoch 20, Step: 402, Loss: 0.041579797863960266, Lr:0.0001\n",
      "Epoch 20, Step: 403, Loss: 0.12857992947101593, Lr:0.0001\n",
      "Epoch 20, Step: 404, Loss: 0.21390779316425323, Lr:0.0001\n",
      "Epoch 20, Step: 405, Loss: 0.08812503516674042, Lr:0.0001\n",
      "Epoch 20, Step: 406, Loss: 0.19335442781448364, Lr:0.0001\n",
      "Epoch 20, Step: 407, Loss: 0.1310824602842331, Lr:0.0001\n",
      "Epoch 20, Step: 408, Loss: 0.04834429547190666, Lr:0.0001\n",
      "Epoch 20, Step: 409, Loss: 0.06502661854028702, Lr:0.0001\n",
      "Epoch 20, Step: 410, Loss: 0.032419353723526, Lr:0.0001\n",
      "Epoch 20, Step: 411, Loss: 0.2867504060268402, Lr:0.0001\n",
      "Epoch 20, Step: 412, Loss: 0.027432121336460114, Lr:0.0001\n",
      "Epoch 20, Step: 413, Loss: 0.052120842039585114, Lr:0.0001\n",
      "Epoch 20, Step: 414, Loss: 0.052489764988422394, Lr:0.0001\n",
      "Epoch 20, Step: 415, Loss: 0.02751179039478302, Lr:0.0001\n",
      "Epoch 20, Step: 416, Loss: 0.06708959490060806, Lr:0.0001\n",
      "Epoch 20, Step: 417, Loss: 0.25609901547431946, Lr:0.0001\n",
      "Epoch 20, Step: 418, Loss: 0.11682650446891785, Lr:0.0001\n",
      "Epoch 20, Step: 419, Loss: 0.017902106046676636, Lr:0.0001\n",
      "Epoch 20, Step: 420, Loss: 0.2284388691186905, Lr:0.0001\n",
      "Epoch 20, Step: 421, Loss: 0.3370852470397949, Lr:0.0001\n",
      "Epoch 20, Step: 422, Loss: 0.023307131603360176, Lr:0.0001\n",
      "Epoch 20, Step: 423, Loss: 0.03888281434774399, Lr:0.0001\n",
      "Epoch 20, Step: 424, Loss: 0.0655236765742302, Lr:0.0001\n",
      "Epoch 20, Step: 425, Loss: 0.00843802560120821, Lr:0.0001\n",
      "Epoch 20, Step: 426, Loss: 0.04791887477040291, Lr:0.0001\n",
      "Epoch 20, Step: 427, Loss: 0.010039323940873146, Lr:0.0001\n",
      "Epoch 20, Step: 428, Loss: 0.030499601736664772, Lr:0.0001\n",
      "Epoch 20, Step: 429, Loss: 0.09054457396268845, Lr:0.0001\n",
      "Epoch 20, Step: 430, Loss: 0.08088423311710358, Lr:0.0001\n",
      "Epoch 20, Step: 431, Loss: 0.0853436291217804, Lr:0.0001\n",
      "Epoch 20, Step: 432, Loss: 0.04953731223940849, Lr:0.0001\n",
      "Epoch 20, Step: 433, Loss: 0.024336040019989014, Lr:0.0001\n",
      "Epoch 20, Step: 434, Loss: 0.18843810260295868, Lr:0.0001\n",
      "Epoch 20, Step: 435, Loss: 0.03827008977532387, Lr:0.0001\n",
      "Epoch 20, Step: 436, Loss: 0.08309785276651382, Lr:0.0001\n",
      "Epoch 20, Step: 437, Loss: 0.12236324697732925, Lr:0.0001\n",
      "Epoch 20, Step: 438, Loss: 0.016945509240031242, Lr:0.0001\n",
      "Epoch 20, Step: 439, Loss: 0.04363107308745384, Lr:0.0001\n",
      "Epoch 20, Step: 440, Loss: 0.1630612313747406, Lr:0.0001\n",
      "Epoch 20, Step: 441, Loss: 0.016812454909086227, Lr:0.0001\n",
      "Epoch 20, Step: 442, Loss: 0.16484203934669495, Lr:0.0001\n",
      "Epoch 20, Step: 443, Loss: 0.10467048734426498, Lr:0.0001\n",
      "Epoch 20, Step: 444, Loss: 0.022754760459065437, Lr:0.0001\n",
      "Epoch 20, Step: 445, Loss: 0.012676062062382698, Lr:0.0001\n",
      "Epoch 20, Step: 446, Loss: 0.14485479891300201, Lr:0.0001\n",
      "Epoch 20, Step: 447, Loss: 0.14830376207828522, Lr:0.0001\n",
      "Epoch 20, Step: 448, Loss: 0.05588281899690628, Lr:0.0001\n",
      "Epoch 20, Step: 449, Loss: 0.03762329742312431, Lr:0.0001\n",
      "Epoch 20, Step: 450, Loss: 0.012683022767305374, Lr:0.0001\n",
      "Epoch 20, Step: 451, Loss: 0.06615473330020905, Lr:0.0001\n",
      "Epoch 20, Step: 452, Loss: 0.15697425603866577, Lr:0.0001\n",
      "Epoch 20, Step: 453, Loss: 0.023776810616254807, Lr:0.0001\n",
      "Epoch 20, Step: 454, Loss: 0.10075885057449341, Lr:0.0001\n",
      "Epoch 20, Step: 455, Loss: 0.06008949130773544, Lr:0.0001\n",
      "Epoch 20, Step: 456, Loss: 0.02024904638528824, Lr:0.0001\n",
      "Epoch 20, Step: 457, Loss: 0.05798400565981865, Lr:0.0001\n",
      "Epoch 20, Step: 458, Loss: 0.08573593944311142, Lr:0.0001\n",
      "Epoch 20, Step: 459, Loss: 0.19331324100494385, Lr:0.0001\n",
      "Epoch 20, Step: 460, Loss: 0.15312346816062927, Lr:0.0001\n",
      "Epoch 20, Step: 461, Loss: 0.07083161920309067, Lr:0.0001\n",
      "Epoch 20, Step: 462, Loss: 0.014972036704421043, Lr:0.0001\n",
      "Epoch 20, Step: 463, Loss: 0.10262183845043182, Lr:0.0001\n",
      "Epoch 20, Step: 464, Loss: 0.1430990993976593, Lr:0.0001\n",
      "Epoch 20, Step: 465, Loss: 0.03923903405666351, Lr:0.0001\n",
      "Epoch 20, Step: 466, Loss: 0.05726637318730354, Lr:0.0001\n",
      "Epoch 20, Step: 467, Loss: 0.1416267305612564, Lr:0.0001\n",
      "Epoch 20, Step: 468, Loss: 0.05452216416597366, Lr:0.0001\n",
      "Epoch 20, Step: 469, Loss: 0.1819016933441162, Lr:0.0001\n",
      "Epoch 20, Step: 470, Loss: 0.05789153277873993, Lr:0.0001\n",
      "Epoch 20, Step: 471, Loss: 0.018576208502054214, Lr:0.0001\n",
      "Epoch 20, Step: 472, Loss: 0.009886471554636955, Lr:0.0001\n",
      "Epoch 20, Step: 473, Loss: 0.28827884793281555, Lr:0.0001\n",
      "Epoch 20, Step: 474, Loss: 0.008336774073541164, Lr:0.0001\n",
      "Epoch 20, Step: 475, Loss: 0.08841841667890549, Lr:0.0001\n",
      "Epoch 20, Step: 476, Loss: 0.06028987467288971, Lr:0.0001\n",
      "Epoch 20, Step: 477, Loss: 0.10386257618665695, Lr:0.0001\n",
      "Epoch 20, Step: 478, Loss: 0.031805966049432755, Lr:0.0001\n",
      "Epoch 20, Step: 479, Loss: 0.28877121210098267, Lr:0.0001\n",
      "Epoch 20, Step: 480, Loss: 0.011941924691200256, Lr:0.0001\n",
      "Epoch 20, Step: 481, Loss: 0.034962449222803116, Lr:0.0001\n",
      "Epoch 20, Step: 482, Loss: 0.34377798438072205, Lr:0.0001\n",
      "Epoch 20, Step: 483, Loss: 0.07399401813745499, Lr:0.0001\n",
      "Epoch 20, Step: 484, Loss: 0.27479812502861023, Lr:0.0001\n",
      "Epoch 20, Step: 485, Loss: 0.025631133466959, Lr:0.0001\n",
      "Epoch 20, Step: 486, Loss: 0.07276732474565506, Lr:0.0001\n",
      "Epoch 20, Step: 487, Loss: 0.3069921135902405, Lr:0.0001\n",
      "Epoch 20, Step: 488, Loss: 0.0067209517583251, Lr:0.0001\n",
      "Epoch 20, Step: 489, Loss: 0.013842808082699776, Lr:0.0001\n",
      "Epoch 20, Step: 490, Loss: 0.022334298118948936, Lr:0.0001\n",
      "Epoch 20, Step: 491, Loss: 0.05431410297751427, Lr:0.0001\n",
      "Epoch 20, Step: 492, Loss: 0.3689994513988495, Lr:0.0001\n",
      "Epoch 20, Step: 493, Loss: 0.015544215217232704, Lr:0.0001\n",
      "Epoch 20, Step: 494, Loss: 0.15828797221183777, Lr:0.0001\n",
      "Epoch 20, Step: 495, Loss: 0.012436393648386002, Lr:0.0001\n",
      "Epoch 20, Step: 496, Loss: 0.17432886362075806, Lr:0.0001\n",
      "Epoch 20, Step: 497, Loss: 0.4033576548099518, Lr:0.0001\n",
      "Epoch 20, Step: 498, Loss: 0.10269120335578918, Lr:0.0001\n",
      "Epoch 20, Step: 499, Loss: 0.0009117082809098065, Lr:0.0001\n",
      "Epoch 20, Step: 500, Loss: 0.02941899560391903, Lr:0.0001\n",
      "Epoch 20, Step: 501, Loss: 0.028781088069081306, Lr:0.0001\n",
      "Epoch 20, Step: 502, Loss: 0.004349207039922476, Lr:0.0001\n",
      "Epoch 20, Step: 503, Loss: 0.08541196584701538, Lr:0.0001\n",
      "Epoch 20, Step: 504, Loss: 0.03592131659388542, Lr:0.0001\n",
      "Epoch 20, Step: 505, Loss: 0.04674199968576431, Lr:0.0001\n",
      "Epoch 20, Step: 506, Loss: 0.030314592644572258, Lr:0.0001\n",
      "Epoch 20, Step: 507, Loss: 0.06131942197680473, Lr:0.0001\n",
      "Epoch 20, Step: 508, Loss: 0.10493262112140656, Lr:0.0001\n",
      "Epoch 20, Step: 509, Loss: 0.004321674350649118, Lr:0.0001\n",
      "Epoch 20, Step: 510, Loss: 0.11060185730457306, Lr:0.0001\n",
      "Epoch 20, Step: 511, Loss: 0.11784131824970245, Lr:0.0001\n",
      "Epoch 20, Step: 512, Loss: 0.05810275673866272, Lr:0.0001\n",
      "Epoch 20, Step: 513, Loss: 0.02918979525566101, Lr:0.0001\n",
      "Epoch 20, Step: 514, Loss: 0.04802383482456207, Lr:0.0001\n",
      "Epoch 20, Step: 515, Loss: 0.2219289243221283, Lr:0.0001\n",
      "Epoch 20, Step: 516, Loss: 0.054987601935863495, Lr:0.0001\n",
      "Epoch 20, Step: 517, Loss: 0.007106127217411995, Lr:0.0001\n",
      "Epoch 20, Step: 518, Loss: 0.06885029375553131, Lr:0.0001\n",
      "Epoch 20, Step: 519, Loss: 0.04938826337456703, Lr:0.0001\n",
      "Epoch 20, Step: 520, Loss: 0.030021067708730698, Lr:0.0001\n",
      "Epoch 20, Step: 521, Loss: 0.005429657641798258, Lr:0.0001\n",
      "Epoch 20, Step: 522, Loss: 0.1668505072593689, Lr:0.0001\n",
      "Epoch 20, Step: 523, Loss: 0.01566157676279545, Lr:0.0001\n",
      "Epoch 20, Step: 524, Loss: 0.03180016949772835, Lr:0.0001\n",
      "Epoch 20, Step: 525, Loss: 0.05706079304218292, Lr:0.0001\n",
      "Epoch 20, Step: 526, Loss: 0.11172877252101898, Lr:0.0001\n",
      "Epoch 20, Step: 527, Loss: 0.010602381080389023, Lr:0.0001\n",
      "Epoch 20, Step: 528, Loss: 0.015471545979380608, Lr:0.0001\n",
      "Epoch 20, Step: 529, Loss: 0.0043999310582876205, Lr:0.0001\n",
      "Epoch 20, Step: 530, Loss: 0.11580074578523636, Lr:0.0001\n",
      "Epoch 20, Step: 531, Loss: 0.0007837304146960378, Lr:0.0001\n",
      "Epoch 20, Step: 532, Loss: 0.04556042701005936, Lr:0.0001\n",
      "Epoch 20, Step: 533, Loss: 0.001071052742190659, Lr:0.0001\n",
      "Epoch 20, Step: 534, Loss: 0.06264086067676544, Lr:0.0001\n",
      "Epoch 20, Step: 535, Loss: 0.06535901874303818, Lr:0.0001\n",
      "Epoch 20, Step: 536, Loss: 0.07969404757022858, Lr:0.0001\n",
      "Epoch 20, Step: 537, Loss: 0.48980778455734253, Lr:0.0001\n",
      "Epoch 20, Step: 538, Loss: 0.02299201674759388, Lr:0.0001\n",
      "Epoch 20, Step: 539, Loss: 0.032413549721241, Lr:0.0001\n",
      "Epoch 20, Step: 540, Loss: 0.06749215722084045, Lr:0.0001\n",
      "Epoch 20, Step: 541, Loss: 0.10062146186828613, Lr:0.0001\n",
      "Epoch 20, Step: 542, Loss: 0.055091992020606995, Lr:0.0001\n",
      "Epoch 20, Step: 543, Loss: 0.07825317978858948, Lr:0.0001\n",
      "Epoch 20, Step: 544, Loss: 0.05536133795976639, Lr:0.0001\n",
      "Epoch 20, Step: 545, Loss: 0.18379059433937073, Lr:0.0001\n",
      "Epoch 20, Step: 546, Loss: 0.017440540716052055, Lr:0.0001\n",
      "Epoch 20, Step: 547, Loss: 0.048818644136190414, Lr:0.0001\n",
      "Epoch 20, Step: 548, Loss: 0.16269204020500183, Lr:0.0001\n",
      "Epoch 20, Step: 549, Loss: 0.08726444840431213, Lr:0.0001\n",
      "Epoch 20, Step: 550, Loss: 0.06805411726236343, Lr:0.0001\n",
      "Epoch 20, Step: 551, Loss: 0.05922280624508858, Lr:0.0001\n",
      "Epoch 20, Step: 552, Loss: 0.14519287645816803, Lr:0.0001\n",
      "Epoch 20, Step: 553, Loss: 0.034813057631254196, Lr:0.0001\n",
      "Epoch 20, Step: 554, Loss: 0.02256380021572113, Lr:0.0001\n",
      "Epoch 20, Step: 555, Loss: 0.16442415118217468, Lr:0.0001\n",
      "Epoch 20, Step: 556, Loss: 0.06619737297296524, Lr:0.0001\n",
      "Epoch 20, Step: 557, Loss: 0.026140160858631134, Lr:0.0001\n",
      "Epoch 20, Step: 558, Loss: 0.017051905393600464, Lr:0.0001\n",
      "Epoch 20, Step: 559, Loss: 0.10741422325372696, Lr:0.0001\n",
      "Epoch 20, Step: 560, Loss: 0.11685919761657715, Lr:0.0001\n",
      "Epoch 20, Step: 561, Loss: 0.4829351305961609, Lr:0.0001\n",
      "Epoch 20, Step: 562, Loss: 0.23045071959495544, Lr:0.0001\n",
      "Epoch 20, Step: 563, Loss: 0.04977262020111084, Lr:0.0001\n",
      "Epoch 20, Step: 564, Loss: 0.023224838078022003, Lr:0.0001\n",
      "Epoch 20, Step: 565, Loss: 0.06388001888990402, Lr:0.0001\n",
      "Epoch 20, Step: 566, Loss: 0.21540939807891846, Lr:0.0001\n",
      "Epoch 20, Step: 567, Loss: 0.0581204853951931, Lr:0.0001\n",
      "Epoch 20, Step: 568, Loss: 0.021629976108670235, Lr:0.0001\n",
      "Epoch 20, Step: 569, Loss: 0.005093610845506191, Lr:0.0001\n",
      "Epoch 20, Step: 570, Loss: 0.01661335863173008, Lr:0.0001\n",
      "Epoch 20, Step: 571, Loss: 0.25646069645881653, Lr:0.0001\n",
      "Epoch 20, Step: 572, Loss: 0.011555223725736141, Lr:0.0001\n",
      "Epoch 20, Step: 573, Loss: 0.06876792758703232, Lr:0.0001\n",
      "Epoch 20, Step: 574, Loss: 0.24581362307071686, Lr:0.0001\n",
      "Epoch 20, Step: 575, Loss: 0.02780750021338463, Lr:0.0001\n",
      "Epoch 20, Step: 576, Loss: 0.15537092089653015, Lr:0.0001\n",
      "Epoch 20, Step: 577, Loss: 0.1689120978116989, Lr:0.0001\n",
      "Epoch 20, Step: 578, Loss: 0.004474680405110121, Lr:0.0001\n",
      "Epoch 20, Step: 579, Loss: 0.08502139896154404, Lr:0.0001\n",
      "Epoch 20, Step: 580, Loss: 0.1506810039281845, Lr:0.0001\n",
      "Epoch 20, Step: 581, Loss: 0.18448536098003387, Lr:0.0001\n",
      "Epoch 20, Step: 582, Loss: 0.04178188368678093, Lr:0.0001\n",
      "Epoch 20, Step: 583, Loss: 0.023149855434894562, Lr:0.0001\n",
      "Epoch 20, Step: 584, Loss: 0.028408922255039215, Lr:0.0001\n",
      "Epoch 20, Step: 585, Loss: 0.17508399486541748, Lr:0.0001\n",
      "Epoch 20, Step: 586, Loss: 0.06689760088920593, Lr:0.0001\n",
      "Epoch 20, Step: 587, Loss: 0.16311775147914886, Lr:0.0001\n",
      "Epoch 20, Step: 588, Loss: 0.05303569883108139, Lr:0.0001\n",
      "Epoch 20, Step: 589, Loss: 0.021859917789697647, Lr:0.0001\n",
      "Epoch 20, Step: 590, Loss: 0.027143796905875206, Lr:0.0001\n",
      "Epoch 20, Step: 591, Loss: 0.07332406938076019, Lr:0.0001\n",
      "Epoch 20, Step: 592, Loss: 0.024442480877041817, Lr:0.0001\n",
      "Epoch 20, Step: 593, Loss: 0.07190832495689392, Lr:0.0001\n",
      "Epoch 20, Step: 594, Loss: 0.12429405748844147, Lr:0.0001\n",
      "Epoch 20, Step: 595, Loss: 0.1733381748199463, Lr:0.0001\n",
      "Epoch 20, Step: 596, Loss: 0.049121126532554626, Lr:0.0001\n",
      "Epoch 20, Step: 597, Loss: 0.086048424243927, Lr:0.0001\n",
      "Epoch 20, Step: 598, Loss: 0.14029455184936523, Lr:0.0001\n",
      "Epoch 20, Step: 599, Loss: 0.1288115531206131, Lr:0.0001\n",
      "Epoch 20, Step: 600, Loss: 0.28182974457740784, Lr:0.0001\n",
      "Epoch 20, Step: 601, Loss: 0.037376269698143005, Lr:0.0001\n",
      "Epoch 20, Step: 602, Loss: 0.11001228541135788, Lr:0.0001\n",
      "Epoch 20, Step: 603, Loss: 0.23376992344856262, Lr:0.0001\n",
      "Epoch 20, Step: 604, Loss: 0.00979413278400898, Lr:0.0001\n",
      "Epoch 20, Step: 605, Loss: 0.028091685846447945, Lr:0.0001\n",
      "Epoch 20, Step: 606, Loss: 0.10325656086206436, Lr:0.0001\n",
      "Epoch 20, Step: 607, Loss: 0.1422724425792694, Lr:0.0001\n",
      "Epoch 20, Step: 608, Loss: 0.08107973635196686, Lr:0.0001\n",
      "Epoch 20, Step: 609, Loss: 0.1269497126340866, Lr:0.0001\n",
      "Epoch 20, Step: 610, Loss: 0.15014976263046265, Lr:0.0001\n",
      "Epoch 20, Step: 611, Loss: 0.12968680262565613, Lr:0.0001\n",
      "Epoch 20, Step: 612, Loss: 0.03883513808250427, Lr:0.0001\n",
      "Epoch 20, Step: 613, Loss: 0.05994250997900963, Lr:0.0001\n",
      "Epoch 20, Step: 614, Loss: 0.21293561160564423, Lr:0.0001\n",
      "Epoch 20, Step: 615, Loss: 0.011687757447361946, Lr:0.0001\n",
      "Epoch 20, Step: 616, Loss: 0.010355319827795029, Lr:0.0001\n",
      "Epoch 20, Step: 617, Loss: 0.009882905520498753, Lr:0.0001\n",
      "Epoch 20, Step: 618, Loss: 0.05087130516767502, Lr:0.0001\n",
      "Epoch 20, Step: 619, Loss: 0.04377054050564766, Lr:0.0001\n",
      "Epoch 20, Step: 620, Loss: 0.1009300947189331, Lr:0.0001\n",
      "Epoch 20, Step: 621, Loss: 0.1445099413394928, Lr:0.0001\n",
      "Epoch 20, Step: 622, Loss: 0.011981874704360962, Lr:0.0001\n",
      "Epoch 20, Step: 623, Loss: 0.02525118738412857, Lr:0.0001\n",
      "Epoch 20, Step: 624, Loss: 0.15398404002189636, Lr:0.0001\n",
      "Epoch 20, Step: 625, Loss: 0.010370573028922081, Lr:0.0001\n",
      "Epoch 20, Step: 626, Loss: 0.041838787496089935, Lr:0.0001\n",
      "Epoch 20, Step: 627, Loss: 0.1495935320854187, Lr:0.0001\n",
      "Epoch 20, Step: 628, Loss: 0.09141221642494202, Lr:0.0001\n",
      "Epoch 20, Step: 629, Loss: 0.10083802789449692, Lr:0.0001\n",
      "Epoch 20, Step: 630, Loss: 0.02842382714152336, Lr:0.0001\n",
      "Epoch 20, Step: 631, Loss: 0.20206065475940704, Lr:0.0001\n",
      "Epoch 20, Step: 632, Loss: 0.054221563041210175, Lr:0.0001\n",
      "Epoch 20, Step: 633, Loss: 0.05698297545313835, Lr:0.0001\n",
      "Epoch 20, Step: 634, Loss: 0.1947239637374878, Lr:0.0001\n",
      "Epoch 20, Step: 635, Loss: 0.15422432124614716, Lr:0.0001\n",
      "Epoch 20, Step: 636, Loss: 0.017873696982860565, Lr:0.0001\n",
      "Epoch 20, Step: 637, Loss: 0.04319949075579643, Lr:0.0001\n",
      "Epoch 20, Step: 638, Loss: 0.003205136861652136, Lr:0.0001\n",
      "Epoch 20, Step: 639, Loss: 0.06497969478368759, Lr:0.0001\n",
      "Epoch 20, Step: 640, Loss: 0.0070440685376524925, Lr:0.0001\n",
      "Epoch 20, Step: 641, Loss: 0.08001738786697388, Lr:0.0001\n",
      "Epoch 20, Step: 642, Loss: 0.1347159594297409, Lr:0.0001\n",
      "Epoch 20, Step: 643, Loss: 0.01744665391743183, Lr:0.0001\n",
      "Epoch 20, Step: 644, Loss: 0.015724869444966316, Lr:0.0001\n",
      "Epoch 20, Step: 645, Loss: 0.03161653131246567, Lr:0.0001\n",
      "Epoch 20, Step: 646, Loss: 0.04317736625671387, Lr:0.0001\n",
      "Epoch 20, Step: 647, Loss: 0.11083748191595078, Lr:0.0001\n",
      "Epoch 20, Step: 648, Loss: 0.010594896972179413, Lr:0.0001\n",
      "Epoch 20, Step: 649, Loss: 0.11202452331781387, Lr:0.0001\n",
      "Epoch 20, Step: 650, Loss: 0.030640872195363045, Lr:0.0001\n",
      "Epoch 20, Step: 651, Loss: 0.05500216782093048, Lr:0.0001\n",
      "Epoch 20, Step: 652, Loss: 0.02477661706507206, Lr:0.0001\n",
      "Epoch 20, Step: 653, Loss: 0.04403652250766754, Lr:0.0001\n",
      "Epoch 20, Step: 654, Loss: 0.16351383924484253, Lr:0.0001\n",
      "Epoch 20, Step: 655, Loss: 0.0167437382042408, Lr:0.0001\n",
      "Epoch 20, Step: 656, Loss: 0.05479269102215767, Lr:0.0001\n",
      "Epoch 20, Step: 657, Loss: 0.048838213086128235, Lr:0.0001\n",
      "Epoch 20, Step: 658, Loss: 0.2346848100423813, Lr:0.0001\n",
      "Epoch 20, Step: 659, Loss: 0.026773780584335327, Lr:0.0001\n",
      "Epoch 20, Step: 660, Loss: 0.05410456284880638, Lr:0.0001\n",
      "Epoch 20, Step: 661, Loss: 0.03756500035524368, Lr:0.0001\n",
      "Epoch 20, Step: 662, Loss: 0.009329673834145069, Lr:0.0001\n",
      "Epoch 20, Step: 663, Loss: 0.17176808416843414, Lr:0.0001\n",
      "Epoch 20, Step: 664, Loss: 0.007098961155861616, Lr:0.0001\n",
      "Epoch 20, Step: 665, Loss: 0.279094934463501, Lr:0.0001\n",
      "Epoch 20, Step: 666, Loss: 0.10846414417028427, Lr:0.0001\n",
      "Epoch 20, Step: 667, Loss: 0.4469539523124695, Lr:0.0001\n",
      "Epoch 20, Step: 668, Loss: 0.09525785595178604, Lr:0.0001\n",
      "Epoch 20, Step: 669, Loss: 0.035432543605566025, Lr:0.0001\n",
      "Epoch 20, Step: 670, Loss: 0.2171775996685028, Lr:0.0001\n",
      "Epoch 20, Step: 671, Loss: 0.0027756865601986647, Lr:0.0001\n",
      "Epoch 20, Step: 672, Loss: 0.178570955991745, Lr:0.0001\n",
      "Epoch 20, Step: 673, Loss: 0.015253824181854725, Lr:0.0001\n",
      "Epoch 20, Step: 674, Loss: 0.08649210631847382, Lr:0.0001\n",
      "Epoch 20, Step: 675, Loss: 0.1452382206916809, Lr:0.0001\n",
      "Epoch 20, Step: 676, Loss: 0.10347949713468552, Lr:0.0001\n",
      "Epoch 20, Step: 677, Loss: 0.05417432263493538, Lr:0.0001\n",
      "Epoch 20, Step: 678, Loss: 0.09462574124336243, Lr:0.0001\n",
      "Epoch 20, Step: 679, Loss: 0.02400977909564972, Lr:0.0001\n",
      "Epoch 20, Step: 680, Loss: 0.011556686833500862, Lr:0.0001\n",
      "Epoch 20, Step: 681, Loss: 0.05883626267313957, Lr:0.0001\n",
      "Epoch 20, Step: 682, Loss: 0.03867829218506813, Lr:0.0001\n",
      "Epoch 20, Step: 683, Loss: 0.1591981053352356, Lr:0.0001\n",
      "Epoch 20, Step: 684, Loss: 0.010148235596716404, Lr:0.0001\n",
      "Epoch 20, Step: 685, Loss: 0.08748728781938553, Lr:0.0001\n",
      "Epoch 20, Step: 686, Loss: 0.005851315800100565, Lr:0.0001\n",
      "Epoch 20, Step: 687, Loss: 0.021681860089302063, Lr:0.0001\n",
      "Epoch 20, Step: 688, Loss: 0.023705244064331055, Lr:0.0001\n",
      "Epoch 20, Step: 689, Loss: 0.10835444182157516, Lr:0.0001\n",
      "Epoch 20, Step: 690, Loss: 0.006792210508137941, Lr:0.0001\n",
      "Epoch 20, Step: 691, Loss: 0.03770272061228752, Lr:0.0001\n",
      "Epoch 20, Step: 692, Loss: 0.06865613162517548, Lr:0.0001\n",
      "Epoch 20, Step: 693, Loss: 0.001246196567080915, Lr:0.0001\n",
      "Epoch 20, Step: 694, Loss: 0.011771781370043755, Lr:0.0001\n",
      "Epoch 20, Step: 695, Loss: 0.021252214908599854, Lr:0.0001\n",
      "Epoch 20, Step: 696, Loss: 0.27661609649658203, Lr:0.0001\n",
      "Epoch 20, Step: 697, Loss: 0.05158773437142372, Lr:0.0001\n",
      "Epoch 20, Step: 698, Loss: 0.007207703310996294, Lr:0.0001\n",
      "Epoch 20, Step: 699, Loss: 0.030336566269397736, Lr:0.0001\n",
      "Epoch 20, Step: 700, Loss: 0.022044967859983444, Lr:0.0001\n",
      "Epoch 20, Step: 701, Loss: 0.07206706702709198, Lr:0.0001\n",
      "Epoch 20, Step: 702, Loss: 0.013635281473398209, Lr:0.0001\n",
      "Epoch 20, Step: 703, Loss: 0.006408141925930977, Lr:0.0001\n",
      "Epoch 20, Step: 704, Loss: 0.0012405201559886336, Lr:0.0001\n",
      "Epoch 20, Step: 705, Loss: 0.00974306371062994, Lr:0.0001\n",
      "Epoch 20, Step: 706, Loss: 0.2484000027179718, Lr:0.0001\n",
      "Epoch 20, Step: 707, Loss: 0.07790407538414001, Lr:0.0001\n",
      "Epoch 20, Step: 708, Loss: 0.13453905284404755, Lr:0.0001\n",
      "Epoch 20, Step: 709, Loss: 0.05864505469799042, Lr:0.0001\n",
      "Epoch 20, Step: 710, Loss: 0.0053716180846095085, Lr:0.0001\n",
      "Epoch 20, Step: 711, Loss: 0.03210665285587311, Lr:0.0001\n",
      "Epoch 20, Step: 712, Loss: 0.0037501477636396885, Lr:0.0001\n",
      "Epoch 20, Step: 713, Loss: 0.02359856851398945, Lr:0.0001\n",
      "Epoch 20, Step: 714, Loss: 0.11384997516870499, Lr:0.0001\n",
      "Epoch 20, Step: 715, Loss: 0.016532940790057182, Lr:0.0001\n",
      "Epoch 20, Step: 716, Loss: 0.15425485372543335, Lr:0.0001\n",
      "Epoch 20, Step: 717, Loss: 0.04171750321984291, Lr:0.0001\n",
      "Epoch 20, Step: 718, Loss: 0.0744171291589737, Lr:0.0001\n",
      "Epoch 20, Step: 719, Loss: 0.037702590227127075, Lr:0.0001\n",
      "Epoch 20, Step: 720, Loss: 0.05353643745183945, Lr:0.0001\n",
      "Epoch 20, Step: 721, Loss: 0.013238221406936646, Lr:0.0001\n",
      "Epoch 20, Step: 722, Loss: 0.05775292217731476, Lr:0.0001\n",
      "Epoch 20, Step: 723, Loss: 0.0348639078438282, Lr:0.0001\n",
      "Epoch 20, Step: 724, Loss: 0.05292005091905594, Lr:0.0001\n",
      "Epoch 20, Step: 725, Loss: 0.024823278188705444, Lr:0.0001\n",
      "Epoch 20, Step: 726, Loss: 0.01085505448281765, Lr:0.0001\n",
      "Epoch 20, Step: 727, Loss: 0.03554831072688103, Lr:0.0001\n",
      "Epoch 20, Step: 728, Loss: 0.024316156283020973, Lr:0.0001\n",
      "Epoch 20, Step: 729, Loss: 0.07897482812404633, Lr:0.0001\n",
      "Epoch 20, Step: 730, Loss: 0.010664312168955803, Lr:0.0001\n",
      "Epoch 20, Step: 731, Loss: 0.01821436733007431, Lr:0.0001\n",
      "Epoch 20, Step: 732, Loss: 0.02193959429860115, Lr:0.0001\n",
      "Epoch 20, Step: 733, Loss: 0.0145454416051507, Lr:0.0001\n",
      "Epoch 20, Step: 734, Loss: 0.004363781772553921, Lr:0.0001\n",
      "Epoch 20, Step: 735, Loss: 0.05774577707052231, Lr:0.0001\n",
      "Epoch 20, Step: 736, Loss: 0.08496852219104767, Lr:0.0001\n",
      "Epoch 20, Step: 737, Loss: 0.04853504151105881, Lr:0.0001\n",
      "Epoch 20, Step: 738, Loss: 0.013160278089344501, Lr:0.0001\n",
      "Epoch 20, Step: 739, Loss: 0.0467454232275486, Lr:0.0001\n",
      "Epoch 20, Step: 740, Loss: 0.019201502203941345, Lr:0.0001\n",
      "Epoch 20, Step: 741, Loss: 0.6869085431098938, Lr:0.0001\n",
      "Epoch 20, Step: 742, Loss: 0.020924557000398636, Lr:0.0001\n",
      "Epoch 20, Step: 743, Loss: 0.03217695280909538, Lr:0.0001\n",
      "Epoch 20, Step: 744, Loss: 0.21511538326740265, Lr:0.0001\n",
      "Epoch 20, Step: 745, Loss: 0.04219772666692734, Lr:0.0001\n",
      "Epoch 20, Step: 746, Loss: 0.017522292211651802, Lr:0.0001\n",
      "Epoch 20, Step: 747, Loss: 0.022785380482673645, Lr:0.0001\n",
      "Epoch 20, Step: 748, Loss: 0.11438260227441788, Lr:0.0001\n",
      "Epoch 20, Step: 749, Loss: 0.054017022252082825, Lr:0.0001\n",
      "Epoch 20, Step: 750, Loss: 0.09497890621423721, Lr:0.0001\n",
      "Epoch 20, Step: 751, Loss: 0.13159894943237305, Lr:0.0001\n",
      "Epoch 20, Step: 752, Loss: 0.13837747275829315, Lr:0.0001\n",
      "Epoch 20, Step: 753, Loss: 0.15314488112926483, Lr:0.0001\n",
      "Epoch 20, Step: 754, Loss: 0.05052779242396355, Lr:0.0001\n",
      "Epoch 20, Step: 755, Loss: 0.011305904015898705, Lr:0.0001\n",
      "Epoch 20, Step: 756, Loss: 0.04517168179154396, Lr:0.0001\n",
      "Epoch 20, Step: 757, Loss: 0.09678631275892258, Lr:0.0001\n",
      "Epoch 20, Step: 758, Loss: 0.016863930970430374, Lr:0.0001\n",
      "Epoch 20, Step: 759, Loss: 0.055930398404598236, Lr:0.0001\n",
      "Epoch 20, Step: 760, Loss: 0.09915805608034134, Lr:0.0001\n",
      "Epoch 20, Step: 761, Loss: 0.014400134794414043, Lr:0.0001\n",
      "Epoch 20, Step: 762, Loss: 0.0007909798878245056, Lr:0.0001\n",
      "Epoch 20, Step: 763, Loss: 0.03506584092974663, Lr:0.0001\n",
      "Epoch 20, Step: 764, Loss: 0.00393671402707696, Lr:0.0001\n",
      "Epoch 20, Step: 765, Loss: 0.3079916834831238, Lr:0.0001\n",
      "Epoch 20, Step: 766, Loss: 0.2600550353527069, Lr:0.0001\n",
      "Epoch 20, Step: 767, Loss: 0.004465337842702866, Lr:0.0001\n",
      "Epoch 20, Step: 768, Loss: 0.019051410257816315, Lr:0.0001\n",
      "Epoch 20, Step: 769, Loss: 0.0666172131896019, Lr:0.0001\n",
      "Epoch 20, Step: 770, Loss: 0.006038140505552292, Lr:0.0001\n",
      "Epoch 20, Step: 771, Loss: 0.03167029097676277, Lr:0.0001\n",
      "Epoch 20, Step: 772, Loss: 0.332644522190094, Lr:0.0001\n",
      "Epoch 20, Step: 773, Loss: 0.006504755467176437, Lr:0.0001\n",
      "Epoch 20, Step: 774, Loss: 0.2062074840068817, Lr:0.0001\n",
      "Epoch 20, Step: 775, Loss: 0.09224141389131546, Lr:0.0001\n",
      "Epoch 20, Step: 776, Loss: 0.035725053399801254, Lr:0.0001\n",
      "Epoch 20, Step: 777, Loss: 0.121468186378479, Lr:0.0001\n",
      "Epoch 20, Step: 778, Loss: 0.04550553485751152, Lr:0.0001\n",
      "Epoch 20, Step: 779, Loss: 0.0483117401599884, Lr:0.0001\n",
      "Epoch 20, Step: 780, Loss: 0.05336305499076843, Lr:0.0001\n",
      "Epoch 20, Step: 781, Loss: 0.07819342613220215, Lr:0.0001\n",
      "Epoch 20, Step: 782, Loss: 0.034969791769981384, Lr:0.0001\n",
      "Epoch 20, Step: 783, Loss: 0.0480990968644619, Lr:0.0001\n",
      "Epoch 20, Step: 784, Loss: 0.03755580261349678, Lr:0.0001\n",
      "Epoch 20, Step: 785, Loss: 0.1574738770723343, Lr:0.0001\n",
      "Epoch 20, Step: 786, Loss: 0.004276358522474766, Lr:0.0001\n",
      "Epoch 20, Step: 787, Loss: 0.049741748720407486, Lr:0.0001\n",
      "Epoch 20, Step: 788, Loss: 0.012605701573193073, Lr:0.0001\n",
      "Epoch 20, Step: 789, Loss: 0.0930592268705368, Lr:0.0001\n",
      "Epoch 20, Step: 790, Loss: 0.06610630452632904, Lr:0.0001\n",
      "Epoch 20, Step: 791, Loss: 0.05405023694038391, Lr:0.0001\n",
      "Epoch 20, Step: 792, Loss: 0.0991799607872963, Lr:0.0001\n",
      "Epoch 20, Step: 793, Loss: 0.039170969277620316, Lr:0.0001\n",
      "Epoch 20, Step: 794, Loss: 0.040010251104831696, Lr:0.0001\n",
      "Epoch 20, Step: 795, Loss: 0.18344295024871826, Lr:0.0001\n",
      "Epoch 20, Step: 796, Loss: 0.024080002680420876, Lr:0.0001\n",
      "Epoch 20, Step: 797, Loss: 0.03652589023113251, Lr:0.0001\n",
      "Epoch 20, Step: 798, Loss: 0.0022464923094958067, Lr:0.0001\n",
      "Epoch 20, Step: 799, Loss: 0.11658071726560593, Lr:0.0001\n",
      "Epoch 20, Step: 800, Loss: 0.23533792793750763, Lr:0.0001\n",
      "Epoch 20, Step: 801, Loss: 0.48090672492980957, Lr:0.0001\n",
      "Epoch 20, Step: 802, Loss: 0.017611002549529076, Lr:0.0001\n",
      "Epoch 20, Step: 803, Loss: 0.21862901747226715, Lr:0.0001\n",
      "Epoch 20, Step: 804, Loss: 0.004891241434961557, Lr:0.0001\n",
      "Epoch 20, Step: 805, Loss: 0.23734676837921143, Lr:0.0001\n",
      "Epoch 20, Step: 806, Loss: 0.08782661706209183, Lr:0.0001\n",
      "Epoch 20, Step: 807, Loss: 0.04781617596745491, Lr:0.0001\n",
      "Epoch 20, Step: 808, Loss: 0.27567872405052185, Lr:0.0001\n",
      "Epoch 20, Step: 809, Loss: 0.04523845389485359, Lr:0.0001\n",
      "Epoch 20, Step: 810, Loss: 0.06452824920415878, Lr:0.0001\n",
      "Epoch 20, Step: 811, Loss: 0.018168771639466286, Lr:0.0001\n",
      "Epoch 20, Step: 812, Loss: 0.036352794617414474, Lr:0.0001\n",
      "Epoch 20, Step: 813, Loss: 0.026900697499513626, Lr:0.0001\n",
      "Epoch 20, Step: 814, Loss: 0.3266749978065491, Lr:0.0001\n",
      "Epoch 20, Step: 815, Loss: 0.16984371840953827, Lr:0.0001\n",
      "Epoch 20, Step: 816, Loss: 0.06513001769781113, Lr:0.0001\n",
      "Epoch 20, Step: 817, Loss: 0.00714864069595933, Lr:0.0001\n",
      "Epoch 20, Step: 818, Loss: 0.05231255292892456, Lr:0.0001\n",
      "Epoch 20, Step: 819, Loss: 0.04423170164227486, Lr:0.0001\n",
      "Epoch 20, Step: 820, Loss: 0.052538372576236725, Lr:0.0001\n",
      "Epoch 20, Step: 821, Loss: 0.04925526678562164, Lr:0.0001\n",
      "Epoch 20, Step: 822, Loss: 0.022543635219335556, Lr:0.0001\n",
      "Epoch 20, Step: 823, Loss: 0.0021766142453998327, Lr:0.0001\n",
      "Epoch 20, Step: 824, Loss: 0.012241591699421406, Lr:0.0001\n",
      "Epoch 20, Step: 825, Loss: 0.1025530993938446, Lr:0.0001\n",
      "Epoch 20, Step: 826, Loss: 0.10700956732034683, Lr:0.0001\n",
      "Epoch 20, Step: 827, Loss: 0.43537843227386475, Lr:0.0001\n",
      "Epoch 20, Step: 828, Loss: 0.03940775245428085, Lr:0.0001\n",
      "Epoch 20, Step: 829, Loss: 0.02379542961716652, Lr:0.0001\n",
      "Epoch 20, Step: 830, Loss: 0.021298279985785484, Lr:0.0001\n",
      "Epoch 20, Step: 831, Loss: 0.013853490352630615, Lr:0.0001\n",
      "Epoch 20, Step: 832, Loss: 0.1630791872739792, Lr:0.0001\n",
      "Epoch 20, Step: 833, Loss: 0.02138146385550499, Lr:0.0001\n",
      "Epoch 20, Step: 834, Loss: 0.006136456038802862, Lr:0.0001\n",
      "Epoch 20, Step: 835, Loss: 0.19723306596279144, Lr:0.0001\n",
      "Epoch 20, Step: 836, Loss: 0.008240771479904652, Lr:0.0001\n",
      "Epoch 20, Step: 837, Loss: 0.14666777849197388, Lr:0.0001\n",
      "Epoch 20, Step: 838, Loss: 0.04655611142516136, Lr:0.0001\n",
      "Epoch 20, Step: 839, Loss: 0.1539556235074997, Lr:0.0001\n",
      "Epoch 20, Step: 840, Loss: 0.07539762556552887, Lr:0.0001\n",
      "Epoch 20, Step: 841, Loss: 0.06633149087429047, Lr:0.0001\n",
      "Epoch 20, Step: 842, Loss: 0.027703572064638138, Lr:0.0001\n",
      "Epoch 20, Step: 843, Loss: 0.029968541115522385, Lr:0.0001\n",
      "Epoch 20, Step: 844, Loss: 0.06627657264471054, Lr:0.0001\n",
      "Epoch 20, Step: 845, Loss: 0.2295617312192917, Lr:0.0001\n",
      "Epoch 20, Step: 846, Loss: 0.09269680827856064, Lr:0.0001\n",
      "Epoch 20, Step: 847, Loss: 0.023231875151395798, Lr:0.0001\n",
      "Epoch 20, Step: 848, Loss: 0.04765623062849045, Lr:0.0001\n",
      "Epoch 20, Step: 849, Loss: 0.013950704596936703, Lr:0.0001\n",
      "Epoch 20, Step: 850, Loss: 0.023432185873389244, Lr:0.0001\n",
      "Epoch 20, Step: 851, Loss: 0.00324046122841537, Lr:0.0001\n",
      "Epoch 20, Step: 852, Loss: 0.09133651852607727, Lr:0.0001\n",
      "Epoch 20, Step: 853, Loss: 0.18976245820522308, Lr:0.0001\n",
      "Epoch 20, Step: 854, Loss: 0.08344557136297226, Lr:0.0001\n",
      "Epoch 20, Step: 855, Loss: 0.12030307203531265, Lr:0.0001\n",
      "Epoch 20, Step: 856, Loss: 0.00421151053160429, Lr:0.0001\n",
      "Epoch 20, Step: 857, Loss: 0.22289367020130157, Lr:0.0001\n",
      "Epoch 20, Step: 858, Loss: 0.005504576489329338, Lr:0.0001\n",
      "Epoch 20, Step: 859, Loss: 0.07498505711555481, Lr:0.0001\n",
      "Epoch 20, Step: 860, Loss: 0.4897281527519226, Lr:0.0001\n",
      "Epoch 20, Step: 861, Loss: 0.02684570476412773, Lr:0.0001\n",
      "Epoch 20, Step: 862, Loss: 0.27053141593933105, Lr:0.0001\n",
      "Epoch 20, Step: 863, Loss: 0.11460182070732117, Lr:0.0001\n",
      "Epoch 20, Step: 864, Loss: 0.03437787666916847, Lr:0.0001\n",
      "Epoch 20, Step: 865, Loss: 0.0002166968770325184, Lr:0.0001\n",
      "Epoch 20, Step: 866, Loss: 0.005160255823284388, Lr:0.0001\n",
      "Epoch 20, Step: 867, Loss: 0.010026269592344761, Lr:0.0001\n",
      "Epoch 20, Step: 868, Loss: 0.03397632762789726, Lr:0.0001\n",
      "Epoch 20, Step: 869, Loss: 0.04059670865535736, Lr:0.0001\n",
      "Epoch 20, Step: 870, Loss: 0.10884989798069, Lr:0.0001\n",
      "Epoch 20, Step: 871, Loss: 0.006428088527172804, Lr:0.0001\n",
      "Epoch 20, Step: 872, Loss: 0.015284616500139236, Lr:0.0001\n",
      "Epoch 20, Step: 873, Loss: 0.45197221636772156, Lr:0.0001\n",
      "Epoch 20, Step: 874, Loss: 0.3519114553928375, Lr:0.0001\n",
      "Epoch 20, Step: 875, Loss: 0.052353501319885254, Lr:0.0001\n",
      "Epoch 20, Step: 876, Loss: 0.0375995896756649, Lr:0.0001\n",
      "Epoch 20, Step: 877, Loss: 0.043218567967414856, Lr:0.0001\n",
      "Epoch 20, Step: 878, Loss: 0.02304302714765072, Lr:0.0001\n",
      "Epoch 20, Step: 879, Loss: 0.06810940057039261, Lr:0.0001\n",
      "Epoch 20, Step: 880, Loss: 0.0019927567336708307, Lr:0.0001\n",
      "Epoch 20, Step: 881, Loss: 0.24098484218120575, Lr:0.0001\n",
      "Epoch 20, Step: 882, Loss: 0.23728740215301514, Lr:0.0001\n",
      "Epoch 20, Step: 883, Loss: 0.020363375544548035, Lr:0.0001\n",
      "Epoch 20, Step: 884, Loss: 0.040755853056907654, Lr:0.0001\n",
      "Epoch 20, Step: 885, Loss: 0.06566417962312698, Lr:0.0001\n",
      "Epoch 20, Step: 886, Loss: 0.21102015674114227, Lr:0.0001\n",
      "Epoch 20, Step: 887, Loss: 0.021228143945336342, Lr:0.0001\n",
      "Epoch 20, Step: 888, Loss: 0.07092384248971939, Lr:0.0001\n",
      "Epoch 20, Step: 889, Loss: 0.07690826058387756, Lr:0.0001\n",
      "Epoch 20, Step: 890, Loss: 0.09706742316484451, Lr:0.0001\n",
      "Epoch 20, Step: 891, Loss: 0.1142600029706955, Lr:0.0001\n",
      "Epoch 20, Step: 892, Loss: 0.03468878194689751, Lr:0.0001\n",
      "Epoch 20, Step: 893, Loss: 0.07003839313983917, Lr:0.0001\n",
      "Epoch 20, Step: 894, Loss: 0.23661412298679352, Lr:0.0001\n",
      "Epoch 20, Step: 895, Loss: 0.20733699202537537, Lr:0.0001\n",
      "Epoch 20, Step: 896, Loss: 0.014468161389231682, Lr:0.0001\n",
      "Epoch 20, Step: 897, Loss: 0.03245864063501358, Lr:0.0001\n",
      "Epoch 20, Step: 898, Loss: 0.0025472750421613455, Lr:0.0001\n",
      "Epoch 20, Step: 899, Loss: 0.11184858530759811, Lr:0.0001\n",
      "Epoch 20, Step: 900, Loss: 0.38724398612976074, Lr:0.0001\n",
      "Epoch 20, Step: 901, Loss: 0.0844775065779686, Lr:0.0001\n",
      "Epoch 20, Step: 902, Loss: 0.2301206886768341, Lr:0.0001\n",
      "Epoch 20, Step: 903, Loss: 0.034745343029499054, Lr:0.0001\n",
      "Epoch 20, Step: 904, Loss: 0.2655330002307892, Lr:0.0001\n",
      "Epoch 20, Step: 905, Loss: 0.010302803479135036, Lr:0.0001\n",
      "Epoch 20, Step: 906, Loss: 0.11986961215734482, Lr:0.0001\n",
      "Epoch 20, Step: 907, Loss: 0.009194158017635345, Lr:0.0001\n",
      "Epoch 20, Step: 908, Loss: 0.04870718717575073, Lr:0.0001\n",
      "Epoch 20, Step: 909, Loss: 0.08440084755420685, Lr:0.0001\n",
      "Epoch 20, Step: 910, Loss: 0.021355964243412018, Lr:0.0001\n",
      "Epoch 20, Step: 911, Loss: 0.03227749466896057, Lr:0.0001\n",
      "Epoch 20, Step: 912, Loss: 0.04255793243646622, Lr:0.0001\n",
      "Epoch 20, Step: 913, Loss: 0.034863606095314026, Lr:0.0001\n",
      "Epoch 20, Step: 914, Loss: 0.0009901720331981778, Lr:0.0001\n",
      "Epoch 20, Step: 915, Loss: 0.02398330345749855, Lr:0.0001\n",
      "Epoch 20, Step: 916, Loss: 0.08463559299707413, Lr:0.0001\n",
      "Epoch 20, Step: 917, Loss: 0.07268419116735458, Lr:0.0001\n",
      "Epoch 20, Step: 918, Loss: 0.01889682561159134, Lr:0.0001\n",
      "Epoch 20, Step: 919, Loss: 0.03129440173506737, Lr:0.0001\n",
      "Epoch 20, Step: 920, Loss: 0.016081850975751877, Lr:0.0001\n",
      "Epoch 20, Step: 921, Loss: 0.007840192876756191, Lr:0.0001\n",
      "Epoch 20, Step: 922, Loss: 0.01576528325676918, Lr:0.0001\n",
      "Epoch 20, Step: 923, Loss: 0.09308718144893646, Lr:0.0001\n",
      "Epoch 20, Step: 924, Loss: 0.18723081052303314, Lr:0.0001\n",
      "Epoch 20, Step: 925, Loss: 0.04276416823267937, Lr:0.0001\n",
      "Epoch 20, Step: 926, Loss: 0.006657070480287075, Lr:0.0001\n",
      "Epoch 20, Step: 927, Loss: 0.025159988552331924, Lr:0.0001\n",
      "Epoch 20, Step: 928, Loss: 0.07899544388055801, Lr:0.0001\n",
      "Epoch 20, Step: 929, Loss: 0.0547916479408741, Lr:0.0001\n",
      "Epoch 20, Step: 930, Loss: 0.00694304658100009, Lr:0.0001\n",
      "Epoch 20, Step: 931, Loss: 0.0932922288775444, Lr:0.0001\n",
      "Epoch 20, Step: 932, Loss: 0.13863450288772583, Lr:0.0001\n",
      "Epoch 20, Step: 933, Loss: 0.015617717057466507, Lr:0.0001\n",
      "Epoch 20, Step: 934, Loss: 0.04438617080450058, Lr:0.0001\n",
      "Epoch 20, Step: 935, Loss: 0.31934863328933716, Lr:0.0001\n",
      "Epoch 20, Step: 936, Loss: 0.3148679733276367, Lr:0.0001\n",
      "Epoch 20, Step: 937, Loss: 0.020202871412038803, Lr:0.0001\n",
      "Epoch 20, Step: 938, Loss: 0.0028158335480839014, Lr:0.0001\n",
      "Epoch 20, Step: 939, Loss: 0.19337184727191925, Lr:0.0001\n",
      "Epoch 20, Step: 940, Loss: 0.04183586686849594, Lr:0.0001\n",
      "Epoch 20, Step: 941, Loss: 0.3060828745365143, Lr:0.0001\n",
      "Epoch 20, Step: 942, Loss: 0.02873343601822853, Lr:0.0001\n",
      "Epoch 20, Step: 943, Loss: 0.061814334243535995, Lr:0.0001\n",
      "Epoch 20, Step: 944, Loss: 0.0016544294776394963, Lr:0.0001\n",
      "Epoch 20, Step: 945, Loss: 0.007714313454926014, Lr:0.0001\n",
      "Epoch 20, Step: 946, Loss: 0.005103223957121372, Lr:0.0001\n",
      "Epoch 20, Step: 947, Loss: 0.04434855654835701, Lr:0.0001\n",
      "Epoch 20, Step: 948, Loss: 0.02358902245759964, Lr:0.0001\n",
      "Epoch 20, Step: 949, Loss: 0.08303984999656677, Lr:0.0001\n",
      "Epoch 20, Step: 950, Loss: 0.08338199555873871, Lr:0.0001\n",
      "Epoch 20, Step: 951, Loss: 0.16718992590904236, Lr:0.0001\n",
      "Epoch 20, Step: 952, Loss: 0.0007940102368593216, Lr:0.0001\n",
      "Epoch 20, Step: 953, Loss: 0.030389752238988876, Lr:0.0001\n",
      "Epoch 20, Step: 954, Loss: 0.04043828323483467, Lr:0.0001\n",
      "Epoch 20, Step: 955, Loss: 0.10567915439605713, Lr:0.0001\n",
      "Epoch 20, Step: 956, Loss: 0.08381060510873795, Lr:0.0001\n",
      "Epoch 20, Step: 957, Loss: 0.03882116079330444, Lr:0.0001\n",
      "Epoch 20, Step: 958, Loss: 0.0909179300069809, Lr:0.0001\n",
      "Epoch 20, Step: 959, Loss: 0.00046158849727362394, Lr:0.0001\n",
      "Epoch 20, Step: 960, Loss: 0.0014856945490464568, Lr:0.0001\n",
      "Epoch 20, Step: 961, Loss: 0.036759696900844574, Lr:0.0001\n",
      "Epoch 20, Step: 962, Loss: 0.12671062350273132, Lr:0.0001\n",
      "Epoch 20, Step: 963, Loss: 0.0117178438231349, Lr:0.0001\n",
      "Epoch 20, Step: 964, Loss: 0.14021629095077515, Lr:0.0001\n",
      "Epoch 20, Step: 965, Loss: 0.03487148880958557, Lr:0.0001\n",
      "Epoch 20, Step: 966, Loss: 0.018943969160318375, Lr:0.0001\n",
      "Epoch 20, Step: 967, Loss: 0.04355393350124359, Lr:0.0001\n",
      "Epoch 20, Step: 968, Loss: 0.1583775281906128, Lr:0.0001\n",
      "Epoch 20, Step: 969, Loss: 0.009210371412336826, Lr:0.0001\n",
      "Epoch 20, Step: 970, Loss: 0.18985208868980408, Lr:0.0001\n",
      "Epoch 20, Step: 971, Loss: 0.0354761965572834, Lr:0.0001\n",
      "Epoch 20, Step: 972, Loss: 0.0006374904187396169, Lr:0.0001\n",
      "Epoch 20, Step: 973, Loss: 0.005146091803908348, Lr:0.0001\n",
      "Epoch 20, Step: 974, Loss: 0.034434352070093155, Lr:0.0001\n",
      "Epoch 20, Step: 975, Loss: 0.05265296250581741, Lr:0.0001\n",
      "Epoch 20, Step: 976, Loss: 0.007619722280651331, Lr:0.0001\n",
      "Epoch 20, Step: 977, Loss: 0.009089172817766666, Lr:0.0001\n",
      "Epoch 20, Step: 978, Loss: 0.22107689082622528, Lr:0.0001\n",
      "Epoch 20, Step: 979, Loss: 0.05947927013039589, Lr:0.0001\n",
      "Epoch 20, Step: 980, Loss: 0.006044016685336828, Lr:0.0001\n",
      "Epoch 20, Step: 981, Loss: 0.14818313717842102, Lr:0.0001\n",
      "Epoch 20, Step: 982, Loss: 0.13648708164691925, Lr:0.0001\n",
      "Epoch 20, Step: 983, Loss: 0.08654835820198059, Lr:0.0001\n",
      "Epoch 20, Step: 984, Loss: 0.34974241256713867, Lr:0.0001\n",
      "Epoch 20, Step: 985, Loss: 0.2922991216182709, Lr:0.0001\n",
      "Epoch 20, Step: 986, Loss: 0.09052787721157074, Lr:0.0001\n",
      "Epoch 20, Step: 987, Loss: 0.05581804737448692, Lr:0.0001\n",
      "Epoch 20, Step: 988, Loss: 0.1703534722328186, Lr:0.0001\n",
      "Epoch 20, Step: 989, Loss: 0.010916919447481632, Lr:0.0001\n",
      "Epoch 20, Step: 990, Loss: 0.00698784040287137, Lr:0.0001\n",
      "Epoch 20, Step: 991, Loss: 0.15124957263469696, Lr:0.0001\n",
      "Epoch 20, Step: 992, Loss: 0.016683366149663925, Lr:0.0001\n",
      "Epoch 20, Step: 993, Loss: 0.2807767987251282, Lr:0.0001\n",
      "Epoch 20, Step: 994, Loss: 0.05828045308589935, Lr:0.0001\n",
      "Epoch 20, Step: 995, Loss: 0.055028919130563736, Lr:0.0001\n",
      "Epoch 20, Step: 996, Loss: 0.05671093240380287, Lr:0.0001\n",
      "Epoch 20, Step: 997, Loss: 0.086905837059021, Lr:0.0001\n",
      "Epoch 20, Step: 998, Loss: 0.03002551756799221, Lr:0.0001\n",
      "Epoch 20, Step: 999, Loss: 0.17401832342147827, Lr:0.0001\n",
      "Epoch 20, Step: 1000, Loss: 0.12239819020032883, Lr:0.0001\n",
      "Epoch 20, Step: 1001, Loss: 0.022676782682538033, Lr:0.0001\n",
      "Epoch 20, Step: 1002, Loss: 0.2832297086715698, Lr:0.0001\n",
      "Epoch 20, Step: 1003, Loss: 0.252848744392395, Lr:0.0001\n",
      "Epoch 20, Step: 1004, Loss: 0.10547684878110886, Lr:0.0001\n",
      "Epoch 20, Step: 1005, Loss: 0.04131659120321274, Lr:0.0001\n",
      "Epoch 20, Step: 1006, Loss: 0.028835855424404144, Lr:0.0001\n",
      "Epoch 20, Step: 1007, Loss: 0.23758305609226227, Lr:0.0001\n",
      "Epoch 20, Step: 1008, Loss: 0.04520821571350098, Lr:0.0001\n",
      "Epoch 20, Step: 1009, Loss: 0.009238697588443756, Lr:0.0001\n",
      "Epoch 20, Step: 1010, Loss: 0.0968756452202797, Lr:0.0001\n",
      "Epoch 20, Step: 1011, Loss: 0.020075704902410507, Lr:0.0001\n",
      "Epoch 20, Step: 1012, Loss: 0.025593644008040428, Lr:0.0001\n",
      "Epoch 20, Step: 1013, Loss: 0.012907586060464382, Lr:0.0001\n",
      "Epoch 20, Step: 1014, Loss: 0.17163516581058502, Lr:0.0001\n",
      "Epoch 20, Step: 1015, Loss: 0.08366798609495163, Lr:0.0001\n",
      "Epoch 20, Step: 1016, Loss: 0.043115533888339996, Lr:0.0001\n",
      "Epoch 20, Step: 1017, Loss: 0.16661198437213898, Lr:0.0001\n",
      "Epoch 20, Step: 1018, Loss: 0.048131320625543594, Lr:0.0001\n",
      "Epoch 20, Step: 1019, Loss: 0.012545471079647541, Lr:0.0001\n",
      "Epoch 20, Step: 1020, Loss: 0.17345789074897766, Lr:0.0001\n",
      "Epoch 20, Step: 1021, Loss: 0.017405947670340538, Lr:0.0001\n",
      "Epoch 20, Step: 1022, Loss: 0.11458052694797516, Lr:0.0001\n",
      "Epoch 20, Step: 1023, Loss: 0.031670935451984406, Lr:0.0001\n",
      "Epoch 20, Step: 1024, Loss: 0.012928364798426628, Lr:0.0001\n",
      "Epoch 20, Step: 1025, Loss: 0.09981966018676758, Lr:0.0001\n",
      "Epoch 20, Step: 1026, Loss: 0.01194069255143404, Lr:0.0001\n",
      "Epoch 20, Step: 1027, Loss: 0.01477715466171503, Lr:0.0001\n",
      "Epoch 20, Step: 1028, Loss: 0.19429785013198853, Lr:0.0001\n",
      "Epoch 20, Step: 1029, Loss: 0.03157026693224907, Lr:0.0001\n",
      "Epoch 20, Step: 1030, Loss: 0.02702995017170906, Lr:0.0001\n",
      "Epoch 20, Step: 1031, Loss: 0.012274925597012043, Lr:0.0001\n",
      "Epoch 20, Step: 1032, Loss: 0.024991990998387337, Lr:0.0001\n",
      "Epoch 20, Step: 1033, Loss: 0.002028468530625105, Lr:0.0001\n",
      "Epoch 20, Step: 1034, Loss: 0.1685255914926529, Lr:0.0001\n",
      "Epoch 20, Step: 1035, Loss: 0.014307569712400436, Lr:0.0001\n",
      "Epoch 20, Step: 1036, Loss: 0.02475953847169876, Lr:0.0001\n",
      "Epoch 20, Step: 1037, Loss: 0.008255589753389359, Lr:0.0001\n",
      "Epoch 20, Step: 1038, Loss: 0.05680840089917183, Lr:0.0001\n",
      "Epoch 20, Step: 1039, Loss: 0.0015924873296171427, Lr:0.0001\n",
      "Epoch 20, Step: 1040, Loss: 0.023053312674164772, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 20\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:15 loss: 0.3166 (0.3166) acc1: 87.5000 (87.5000) acc5: 100.0000 (100.0000) time: 0.2700 data: 0.1040 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:12 loss: 0.0006 (0.0500) acc1: 100.0000 (97.7273) acc5: 100.0000 (100.0000) time: 0.2817 data: 0.1083 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0007 (0.0378) acc1: 100.0000 (98.2143) acc5: 100.0000 (100.0000) time: 0.2828 data: 0.1086 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.0100 (0.1278) acc1: 100.0000 (96.3710) acc5: 100.0000 (100.0000) time: 0.2831 data: 0.1093 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.0332 (0.1623) acc1: 100.0000 (95.4268) acc5: 100.0000 (100.0000) time: 0.2859 data: 0.1121 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.1216 (0.1773) acc1: 93.7500 (95.2206) acc5: 100.0000 (100.0000) time: 0.2883 data: 0.1134 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.1116 (0.2066) acc1: 100.0000 (94.6652) acc5: 100.0000 (100.0000) time: 0.2765 data: 0.1083 max mem: 15137\n",
      "Test: Total time: 0:00:15 (0.2809 s / it)\n",
      "* Acc@1 94.665 Acc@5 100.000 loss 0.207\n",
      "Accuracy of the network on the 881 test image: 94.7%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 21, Step: 0, Loss: 0.018299894407391548, Lr:0.0001\n",
      "Epoch 21, Step: 1, Loss: 0.03699195012450218, Lr:0.0001\n",
      "Epoch 21, Step: 2, Loss: 0.3046296238899231, Lr:0.0001\n",
      "Epoch 21, Step: 3, Loss: 0.07366123795509338, Lr:0.0001\n",
      "Epoch 21, Step: 4, Loss: 0.06674452871084213, Lr:0.0001\n",
      "Epoch 21, Step: 5, Loss: 0.1049543246626854, Lr:0.0001\n",
      "Epoch 21, Step: 6, Loss: 0.11314369738101959, Lr:0.0001\n",
      "Epoch 21, Step: 7, Loss: 0.05514729022979736, Lr:0.0001\n",
      "Epoch 21, Step: 8, Loss: 0.20261424779891968, Lr:0.0001\n",
      "Epoch 21, Step: 9, Loss: 0.26585400104522705, Lr:0.0001\n",
      "Epoch 21, Step: 10, Loss: 0.007031135726720095, Lr:0.0001\n",
      "Epoch 21, Step: 11, Loss: 0.02483258582651615, Lr:0.0001\n",
      "Epoch 21, Step: 12, Loss: 0.006953837815672159, Lr:0.0001\n",
      "Epoch 21, Step: 13, Loss: 0.04780147969722748, Lr:0.0001\n",
      "Epoch 21, Step: 14, Loss: 0.43296337127685547, Lr:0.0001\n",
      "Epoch 21, Step: 15, Loss: 0.0734473243355751, Lr:0.0001\n",
      "Epoch 21, Step: 16, Loss: 0.07298237830400467, Lr:0.0001\n",
      "Epoch 21, Step: 17, Loss: 0.05641411617398262, Lr:0.0001\n",
      "Epoch 21, Step: 18, Loss: 0.0422351099550724, Lr:0.0001\n",
      "Epoch 21, Step: 19, Loss: 0.028854861855506897, Lr:0.0001\n",
      "Epoch 21, Step: 20, Loss: 0.07591832429170609, Lr:0.0001\n",
      "Epoch 21, Step: 21, Loss: 0.15867455303668976, Lr:0.0001\n",
      "Epoch 21, Step: 22, Loss: 0.09376184642314911, Lr:0.0001\n",
      "Epoch 21, Step: 23, Loss: 0.0756029412150383, Lr:0.0001\n",
      "Epoch 21, Step: 24, Loss: 0.00324561377055943, Lr:0.0001\n",
      "Epoch 21, Step: 25, Loss: 0.060784876346588135, Lr:0.0001\n",
      "Epoch 21, Step: 26, Loss: 0.04283490404486656, Lr:0.0001\n",
      "Epoch 21, Step: 27, Loss: 0.11953594535589218, Lr:0.0001\n",
      "Epoch 21, Step: 28, Loss: 0.04193822667002678, Lr:0.0001\n",
      "Epoch 21, Step: 29, Loss: 0.18640859425067902, Lr:0.0001\n",
      "Epoch 21, Step: 30, Loss: 0.22679951786994934, Lr:0.0001\n",
      "Epoch 21, Step: 31, Loss: 0.0598914735019207, Lr:0.0001\n",
      "Epoch 21, Step: 32, Loss: 0.020776551216840744, Lr:0.0001\n",
      "Epoch 21, Step: 33, Loss: 0.05416610464453697, Lr:0.0001\n",
      "Epoch 21, Step: 34, Loss: 0.041736163198947906, Lr:0.0001\n",
      "Epoch 21, Step: 35, Loss: 0.084343321621418, Lr:0.0001\n",
      "Epoch 21, Step: 36, Loss: 0.0957605391740799, Lr:0.0001\n",
      "Epoch 21, Step: 37, Loss: 0.30746525526046753, Lr:0.0001\n",
      "Epoch 21, Step: 38, Loss: 0.09005730599164963, Lr:0.0001\n",
      "Epoch 21, Step: 39, Loss: 0.05523710697889328, Lr:0.0001\n",
      "Epoch 21, Step: 40, Loss: 0.09324360638856888, Lr:0.0001\n",
      "Epoch 21, Step: 41, Loss: 0.007496540900319815, Lr:0.0001\n",
      "Epoch 21, Step: 42, Loss: 0.003280043601989746, Lr:0.0001\n",
      "Epoch 21, Step: 43, Loss: 0.04147612676024437, Lr:0.0001\n",
      "Epoch 21, Step: 44, Loss: 0.022635752335190773, Lr:0.0001\n",
      "Epoch 21, Step: 45, Loss: 0.21229006350040436, Lr:0.0001\n",
      "Epoch 21, Step: 46, Loss: 0.024412907660007477, Lr:0.0001\n",
      "Epoch 21, Step: 47, Loss: 0.429502010345459, Lr:0.0001\n",
      "Epoch 21, Step: 48, Loss: 0.4835548996925354, Lr:0.0001\n",
      "Epoch 21, Step: 49, Loss: 0.06490930169820786, Lr:0.0001\n",
      "Epoch 21, Step: 50, Loss: 0.015204744413495064, Lr:0.0001\n",
      "Epoch 21, Step: 51, Loss: 0.10482808202505112, Lr:0.0001\n",
      "Epoch 21, Step: 52, Loss: 0.20300449430942535, Lr:0.0001\n",
      "Epoch 21, Step: 53, Loss: 0.08921175450086594, Lr:0.0001\n",
      "Epoch 21, Step: 54, Loss: 0.05079835653305054, Lr:0.0001\n",
      "Epoch 21, Step: 55, Loss: 0.11713730543851852, Lr:0.0001\n",
      "Epoch 21, Step: 56, Loss: 0.047569286078214645, Lr:0.0001\n",
      "Epoch 21, Step: 57, Loss: 0.04288308322429657, Lr:0.0001\n",
      "Epoch 21, Step: 58, Loss: 0.008569082245230675, Lr:0.0001\n",
      "Epoch 21, Step: 59, Loss: 0.011763812974095345, Lr:0.0001\n",
      "Epoch 21, Step: 60, Loss: 0.040472857654094696, Lr:0.0001\n",
      "Epoch 21, Step: 61, Loss: 0.18019387125968933, Lr:0.0001\n",
      "Epoch 21, Step: 62, Loss: 0.0753224790096283, Lr:0.0001\n",
      "Epoch 21, Step: 63, Loss: 0.06522218137979507, Lr:0.0001\n",
      "Epoch 21, Step: 64, Loss: 0.06349986791610718, Lr:0.0001\n",
      "Epoch 21, Step: 65, Loss: 0.030942842364311218, Lr:0.0001\n",
      "Epoch 21, Step: 66, Loss: 0.021258093416690826, Lr:0.0001\n",
      "Epoch 21, Step: 67, Loss: 0.05160669982433319, Lr:0.0001\n",
      "Epoch 21, Step: 68, Loss: 0.0795353427529335, Lr:0.0001\n",
      "Epoch 21, Step: 69, Loss: 0.018680475652217865, Lr:0.0001\n",
      "Epoch 21, Step: 70, Loss: 0.05129004642367363, Lr:0.0001\n",
      "Epoch 21, Step: 71, Loss: 0.057715803384780884, Lr:0.0001\n",
      "Epoch 21, Step: 72, Loss: 0.03795840963721275, Lr:0.0001\n",
      "Epoch 21, Step: 73, Loss: 0.04478788003325462, Lr:0.0001\n",
      "Epoch 21, Step: 74, Loss: 0.010959366336464882, Lr:0.0001\n",
      "Epoch 21, Step: 75, Loss: 0.01537333708256483, Lr:0.0001\n",
      "Epoch 21, Step: 76, Loss: 0.17022258043289185, Lr:0.0001\n",
      "Epoch 21, Step: 77, Loss: 0.035051096230745316, Lr:0.0001\n",
      "Epoch 21, Step: 78, Loss: 0.007074727211147547, Lr:0.0001\n",
      "Epoch 21, Step: 79, Loss: 0.005086241289973259, Lr:0.0001\n",
      "Epoch 21, Step: 80, Loss: 0.12018682062625885, Lr:0.0001\n",
      "Epoch 21, Step: 81, Loss: 0.18407218158245087, Lr:0.0001\n",
      "Epoch 21, Step: 82, Loss: 0.03173444792628288, Lr:0.0001\n",
      "Epoch 21, Step: 83, Loss: 0.0025172929745167494, Lr:0.0001\n",
      "Epoch 21, Step: 84, Loss: 0.01245544571429491, Lr:0.0001\n",
      "Epoch 21, Step: 85, Loss: 0.053494036197662354, Lr:0.0001\n",
      "Epoch 21, Step: 86, Loss: 0.06898532062768936, Lr:0.0001\n",
      "Epoch 21, Step: 87, Loss: 0.20155467092990875, Lr:0.0001\n",
      "Epoch 21, Step: 88, Loss: 0.06574246287345886, Lr:0.0001\n",
      "Epoch 21, Step: 89, Loss: 0.02662518247961998, Lr:0.0001\n",
      "Epoch 21, Step: 90, Loss: 0.010293466970324516, Lr:0.0001\n",
      "Epoch 21, Step: 91, Loss: 0.012081611901521683, Lr:0.0001\n",
      "Epoch 21, Step: 92, Loss: 0.19113722443580627, Lr:0.0001\n",
      "Epoch 21, Step: 93, Loss: 0.025193285197019577, Lr:0.0001\n",
      "Epoch 21, Step: 94, Loss: 0.03769620135426521, Lr:0.0001\n",
      "Epoch 21, Step: 95, Loss: 0.04125941917300224, Lr:0.0001\n",
      "Epoch 21, Step: 96, Loss: 0.06416155397891998, Lr:0.0001\n",
      "Epoch 21, Step: 97, Loss: 0.18106381595134735, Lr:0.0001\n",
      "Epoch 21, Step: 98, Loss: 0.02596566081047058, Lr:0.0001\n",
      "Epoch 21, Step: 99, Loss: 0.03930163383483887, Lr:0.0001\n",
      "Epoch 21, Step: 100, Loss: 0.07118585705757141, Lr:0.0001\n",
      "Epoch 21, Step: 101, Loss: 0.1885858029127121, Lr:0.0001\n",
      "Epoch 21, Step: 102, Loss: 0.001925226766616106, Lr:0.0001\n",
      "Epoch 21, Step: 103, Loss: 0.01274062879383564, Lr:0.0001\n",
      "Epoch 21, Step: 104, Loss: 0.11268571764230728, Lr:0.0001\n",
      "Epoch 21, Step: 105, Loss: 0.06073961406946182, Lr:0.0001\n",
      "Epoch 21, Step: 106, Loss: 0.03452606871724129, Lr:0.0001\n",
      "Epoch 21, Step: 107, Loss: 0.10349314659833908, Lr:0.0001\n",
      "Epoch 21, Step: 108, Loss: 0.055333949625492096, Lr:0.0001\n",
      "Epoch 21, Step: 109, Loss: 0.136040598154068, Lr:0.0001\n",
      "Epoch 21, Step: 110, Loss: 0.017476461827754974, Lr:0.0001\n",
      "Epoch 21, Step: 111, Loss: 0.017635898664593697, Lr:0.0001\n",
      "Epoch 21, Step: 112, Loss: 0.41106584668159485, Lr:0.0001\n",
      "Epoch 21, Step: 113, Loss: 0.06566989421844482, Lr:0.0001\n",
      "Epoch 21, Step: 114, Loss: 0.0667106956243515, Lr:0.0001\n",
      "Epoch 21, Step: 115, Loss: 0.008431018330156803, Lr:0.0001\n",
      "Epoch 21, Step: 116, Loss: 0.017797153443098068, Lr:0.0001\n",
      "Epoch 21, Step: 117, Loss: 0.03831828385591507, Lr:0.0001\n",
      "Epoch 21, Step: 118, Loss: 0.016223637387156487, Lr:0.0001\n",
      "Epoch 21, Step: 119, Loss: 0.055374324321746826, Lr:0.0001\n",
      "Epoch 21, Step: 120, Loss: 0.005910851061344147, Lr:0.0001\n",
      "Epoch 21, Step: 121, Loss: 0.12523816525936127, Lr:0.0001\n",
      "Epoch 21, Step: 122, Loss: 0.05368754640221596, Lr:0.0001\n",
      "Epoch 21, Step: 123, Loss: 0.0022951755672693253, Lr:0.0001\n",
      "Epoch 21, Step: 124, Loss: 0.032428495585918427, Lr:0.0001\n",
      "Epoch 21, Step: 125, Loss: 0.01818578876554966, Lr:0.0001\n",
      "Epoch 21, Step: 126, Loss: 0.04369775205850601, Lr:0.0001\n",
      "Epoch 21, Step: 127, Loss: 0.0101762805134058, Lr:0.0001\n",
      "Epoch 21, Step: 128, Loss: 0.0148075046017766, Lr:0.0001\n",
      "Epoch 21, Step: 129, Loss: 0.01944045163691044, Lr:0.0001\n",
      "Epoch 21, Step: 130, Loss: 0.13226953148841858, Lr:0.0001\n",
      "Epoch 21, Step: 131, Loss: 0.10023677349090576, Lr:0.0001\n",
      "Epoch 21, Step: 132, Loss: 0.0012127909576520324, Lr:0.0001\n",
      "Epoch 21, Step: 133, Loss: 0.02628759853541851, Lr:0.0001\n",
      "Epoch 21, Step: 134, Loss: 0.023907793685793877, Lr:0.0001\n",
      "Epoch 21, Step: 135, Loss: 0.174024760723114, Lr:0.0001\n",
      "Epoch 21, Step: 136, Loss: 0.226057767868042, Lr:0.0001\n",
      "Epoch 21, Step: 137, Loss: 0.029777903109788895, Lr:0.0001\n",
      "Epoch 21, Step: 138, Loss: 0.05059594288468361, Lr:0.0001\n",
      "Epoch 21, Step: 139, Loss: 0.04456857219338417, Lr:0.0001\n",
      "Epoch 21, Step: 140, Loss: 0.09876123070716858, Lr:0.0001\n",
      "Epoch 21, Step: 141, Loss: 0.023985978215932846, Lr:0.0001\n",
      "Epoch 21, Step: 142, Loss: 0.0001249948691111058, Lr:0.0001\n",
      "Epoch 21, Step: 143, Loss: 0.040242698043584824, Lr:0.0001\n",
      "Epoch 21, Step: 144, Loss: 0.0642634853720665, Lr:0.0001\n",
      "Epoch 21, Step: 145, Loss: 0.003065698081627488, Lr:0.0001\n",
      "Epoch 21, Step: 146, Loss: 0.10194983333349228, Lr:0.0001\n",
      "Epoch 21, Step: 147, Loss: 0.06835509091615677, Lr:0.0001\n",
      "Epoch 21, Step: 148, Loss: 0.014084931463003159, Lr:0.0001\n",
      "Epoch 21, Step: 149, Loss: 0.12066502869129181, Lr:0.0001\n",
      "Epoch 21, Step: 150, Loss: 0.04811551794409752, Lr:0.0001\n",
      "Epoch 21, Step: 151, Loss: 0.03203188255429268, Lr:0.0001\n",
      "Epoch 21, Step: 152, Loss: 0.23627369105815887, Lr:0.0001\n",
      "Epoch 21, Step: 153, Loss: 0.002247034339234233, Lr:0.0001\n",
      "Epoch 21, Step: 154, Loss: 0.007271090988069773, Lr:0.0001\n",
      "Epoch 21, Step: 155, Loss: 0.0183353740721941, Lr:0.0001\n",
      "Epoch 21, Step: 156, Loss: 0.10442376136779785, Lr:0.0001\n",
      "Epoch 21, Step: 157, Loss: 0.03538816422224045, Lr:0.0001\n",
      "Epoch 21, Step: 158, Loss: 0.06159862130880356, Lr:0.0001\n",
      "Epoch 21, Step: 159, Loss: 0.24275679886341095, Lr:0.0001\n",
      "Epoch 21, Step: 160, Loss: 0.06511053442955017, Lr:0.0001\n",
      "Epoch 21, Step: 161, Loss: 0.20841960608959198, Lr:0.0001\n",
      "Epoch 21, Step: 162, Loss: 0.5573895573616028, Lr:0.0001\n",
      "Epoch 21, Step: 163, Loss: 0.01694117672741413, Lr:0.0001\n",
      "Epoch 21, Step: 164, Loss: 0.16383497416973114, Lr:0.0001\n",
      "Epoch 21, Step: 165, Loss: 0.009474663995206356, Lr:0.0001\n",
      "Epoch 21, Step: 166, Loss: 0.0024079952854663134, Lr:0.0001\n",
      "Epoch 21, Step: 167, Loss: 0.01084192469716072, Lr:0.0001\n",
      "Epoch 21, Step: 168, Loss: 0.19193951785564423, Lr:0.0001\n",
      "Epoch 21, Step: 169, Loss: 0.01049191877245903, Lr:0.0001\n",
      "Epoch 21, Step: 170, Loss: 0.1285330057144165, Lr:0.0001\n",
      "Epoch 21, Step: 171, Loss: 0.0768272653222084, Lr:0.0001\n",
      "Epoch 21, Step: 172, Loss: 0.07211129367351532, Lr:0.0001\n",
      "Epoch 21, Step: 173, Loss: 0.0034436581190675497, Lr:0.0001\n",
      "Epoch 21, Step: 174, Loss: 0.33440589904785156, Lr:0.0001\n",
      "Epoch 21, Step: 175, Loss: 0.09480925649404526, Lr:0.0001\n",
      "Epoch 21, Step: 176, Loss: 0.0014924912247806787, Lr:0.0001\n",
      "Epoch 21, Step: 177, Loss: 0.21638882160186768, Lr:0.0001\n",
      "Epoch 21, Step: 178, Loss: 0.050418671220541, Lr:0.0001\n",
      "Epoch 21, Step: 179, Loss: 0.0931691974401474, Lr:0.0001\n",
      "Epoch 21, Step: 180, Loss: 0.019098177552223206, Lr:0.0001\n",
      "Epoch 21, Step: 181, Loss: 0.021798858419060707, Lr:0.0001\n",
      "Epoch 21, Step: 182, Loss: 0.00626356340944767, Lr:0.0001\n",
      "Epoch 21, Step: 183, Loss: 0.34037017822265625, Lr:0.0001\n",
      "Epoch 21, Step: 184, Loss: 0.023469356819987297, Lr:0.0001\n",
      "Epoch 21, Step: 185, Loss: 0.00670801242813468, Lr:0.0001\n",
      "Epoch 21, Step: 186, Loss: 0.01878802478313446, Lr:0.0001\n",
      "Epoch 21, Step: 187, Loss: 0.003007484832778573, Lr:0.0001\n",
      "Epoch 21, Step: 188, Loss: 0.015999726951122284, Lr:0.0001\n",
      "Epoch 21, Step: 189, Loss: 0.04289473593235016, Lr:0.0001\n",
      "Epoch 21, Step: 190, Loss: 0.008618387393653393, Lr:0.0001\n",
      "Epoch 21, Step: 191, Loss: 0.02789190597832203, Lr:0.0001\n",
      "Epoch 21, Step: 192, Loss: 0.0073470743373036385, Lr:0.0001\n",
      "Epoch 21, Step: 193, Loss: 0.0026924123521894217, Lr:0.0001\n",
      "Epoch 21, Step: 194, Loss: 0.04201527312397957, Lr:0.0001\n",
      "Epoch 21, Step: 195, Loss: 0.0557602196931839, Lr:0.0001\n",
      "Epoch 21, Step: 196, Loss: 0.014039905741810799, Lr:0.0001\n",
      "Epoch 21, Step: 197, Loss: 0.01767623983323574, Lr:0.0001\n",
      "Epoch 21, Step: 198, Loss: 0.12142514437437057, Lr:0.0001\n",
      "Epoch 21, Step: 199, Loss: 0.01516999676823616, Lr:0.0001\n",
      "Epoch 21, Step: 200, Loss: 0.028266843408346176, Lr:0.0001\n",
      "Epoch 21, Step: 201, Loss: 0.06617367267608643, Lr:0.0001\n",
      "Epoch 21, Step: 202, Loss: 0.004086834844201803, Lr:0.0001\n",
      "Epoch 21, Step: 203, Loss: 0.048398207873106, Lr:0.0001\n",
      "Epoch 21, Step: 204, Loss: 0.013791156932711601, Lr:0.0001\n",
      "Epoch 21, Step: 205, Loss: 0.2737218737602234, Lr:0.0001\n",
      "Epoch 21, Step: 206, Loss: 0.14918246865272522, Lr:0.0001\n",
      "Epoch 21, Step: 207, Loss: 0.2635456621646881, Lr:0.0001\n",
      "Epoch 21, Step: 208, Loss: 0.003448756877332926, Lr:0.0001\n",
      "Epoch 21, Step: 209, Loss: 0.003956370055675507, Lr:0.0001\n",
      "Epoch 21, Step: 210, Loss: 0.16176699101924896, Lr:0.0001\n",
      "Epoch 21, Step: 211, Loss: 0.014614912681281567, Lr:0.0001\n",
      "Epoch 21, Step: 212, Loss: 0.38888025283813477, Lr:0.0001\n",
      "Epoch 21, Step: 213, Loss: 0.001644328236579895, Lr:0.0001\n",
      "Epoch 21, Step: 214, Loss: 0.013381893746554852, Lr:0.0001\n",
      "Epoch 21, Step: 215, Loss: 0.002062308369204402, Lr:0.0001\n",
      "Epoch 21, Step: 216, Loss: 0.3161279857158661, Lr:0.0001\n",
      "Epoch 21, Step: 217, Loss: 0.006367780733853579, Lr:0.0001\n",
      "Epoch 21, Step: 218, Loss: 0.07016950845718384, Lr:0.0001\n",
      "Epoch 21, Step: 219, Loss: 0.030418183654546738, Lr:0.0001\n",
      "Epoch 21, Step: 220, Loss: 0.011821662075817585, Lr:0.0001\n",
      "Epoch 21, Step: 221, Loss: 0.13107086718082428, Lr:0.0001\n",
      "Epoch 21, Step: 222, Loss: 0.006315199192613363, Lr:0.0001\n",
      "Epoch 21, Step: 223, Loss: 0.04743808135390282, Lr:0.0001\n",
      "Epoch 21, Step: 224, Loss: 0.05632748827338219, Lr:0.0001\n",
      "Epoch 21, Step: 225, Loss: 0.032850634306669235, Lr:0.0001\n",
      "Epoch 21, Step: 226, Loss: 0.11924048513174057, Lr:0.0001\n",
      "Epoch 21, Step: 227, Loss: 0.03486707806587219, Lr:0.0001\n",
      "Epoch 21, Step: 228, Loss: 0.1043415367603302, Lr:0.0001\n",
      "Epoch 21, Step: 229, Loss: 0.007877789437770844, Lr:0.0001\n",
      "Epoch 21, Step: 230, Loss: 0.014634496532380581, Lr:0.0001\n",
      "Epoch 21, Step: 231, Loss: 0.14209416508674622, Lr:0.0001\n",
      "Epoch 21, Step: 232, Loss: 0.13586151599884033, Lr:0.0001\n",
      "Epoch 21, Step: 233, Loss: 0.012519446201622486, Lr:0.0001\n",
      "Epoch 21, Step: 234, Loss: 0.005410177167505026, Lr:0.0001\n",
      "Epoch 21, Step: 235, Loss: 0.015724660828709602, Lr:0.0001\n",
      "Epoch 21, Step: 236, Loss: 0.18267686665058136, Lr:0.0001\n",
      "Epoch 21, Step: 237, Loss: 0.29098251461982727, Lr:0.0001\n",
      "Epoch 21, Step: 238, Loss: 0.013684761710464954, Lr:0.0001\n",
      "Epoch 21, Step: 239, Loss: 0.021132662892341614, Lr:0.0001\n",
      "Epoch 21, Step: 240, Loss: 0.2710384130477905, Lr:0.0001\n",
      "Epoch 21, Step: 241, Loss: 0.023721968755126, Lr:0.0001\n",
      "Epoch 21, Step: 242, Loss: 0.04517821595072746, Lr:0.0001\n",
      "Epoch 21, Step: 243, Loss: 0.2094542682170868, Lr:0.0001\n",
      "Epoch 21, Step: 244, Loss: 0.023920264095067978, Lr:0.0001\n",
      "Epoch 21, Step: 245, Loss: 0.022822868078947067, Lr:0.0001\n",
      "Epoch 21, Step: 246, Loss: 0.011752442456781864, Lr:0.0001\n",
      "Epoch 21, Step: 247, Loss: 0.10112617164850235, Lr:0.0001\n",
      "Epoch 21, Step: 248, Loss: 0.012982252985239029, Lr:0.0001\n",
      "Epoch 21, Step: 249, Loss: 0.017671311274170876, Lr:0.0001\n",
      "Epoch 21, Step: 250, Loss: 0.18370716273784637, Lr:0.0001\n",
      "Epoch 21, Step: 251, Loss: 0.01019849069416523, Lr:0.0001\n",
      "Epoch 21, Step: 252, Loss: 0.007678203284740448, Lr:0.0001\n",
      "Epoch 21, Step: 253, Loss: 0.08550319820642471, Lr:0.0001\n",
      "Epoch 21, Step: 254, Loss: 0.01126719731837511, Lr:0.0001\n",
      "Epoch 21, Step: 255, Loss: 0.0058343177661299706, Lr:0.0001\n",
      "Epoch 21, Step: 256, Loss: 0.13511492311954498, Lr:0.0001\n",
      "Epoch 21, Step: 257, Loss: 0.03938364237546921, Lr:0.0001\n",
      "Epoch 21, Step: 258, Loss: 0.31201624870300293, Lr:0.0001\n",
      "Epoch 21, Step: 259, Loss: 0.012316747568547726, Lr:0.0001\n",
      "Epoch 21, Step: 260, Loss: 0.19640450179576874, Lr:0.0001\n",
      "Epoch 21, Step: 261, Loss: 0.0414462648332119, Lr:0.0001\n",
      "Epoch 21, Step: 262, Loss: 0.062099993228912354, Lr:0.0001\n",
      "Epoch 21, Step: 263, Loss: 0.12366856634616852, Lr:0.0001\n",
      "Epoch 21, Step: 264, Loss: 0.07626562565565109, Lr:0.0001\n",
      "Epoch 21, Step: 265, Loss: 0.11223603785037994, Lr:0.0001\n",
      "Epoch 21, Step: 266, Loss: 0.03182027488946915, Lr:0.0001\n",
      "Epoch 21, Step: 267, Loss: 0.005214255303144455, Lr:0.0001\n",
      "Epoch 21, Step: 268, Loss: 0.0027779252268373966, Lr:0.0001\n",
      "Epoch 21, Step: 269, Loss: 0.03663431853055954, Lr:0.0001\n",
      "Epoch 21, Step: 270, Loss: 0.008178014308214188, Lr:0.0001\n",
      "Epoch 21, Step: 271, Loss: 0.024327421560883522, Lr:0.0001\n",
      "Epoch 21, Step: 272, Loss: 0.07401008158922195, Lr:0.0001\n",
      "Epoch 21, Step: 273, Loss: 0.014801468700170517, Lr:0.0001\n",
      "Epoch 21, Step: 274, Loss: 0.03118099831044674, Lr:0.0001\n",
      "Epoch 21, Step: 275, Loss: 0.046451713889837265, Lr:0.0001\n",
      "Epoch 21, Step: 276, Loss: 0.22496190667152405, Lr:0.0001\n",
      "Epoch 21, Step: 277, Loss: 0.020216329023241997, Lr:0.0001\n",
      "Epoch 21, Step: 278, Loss: 0.034969575703144073, Lr:0.0001\n",
      "Epoch 21, Step: 279, Loss: 0.01576288603246212, Lr:0.0001\n",
      "Epoch 21, Step: 280, Loss: 0.08785489946603775, Lr:0.0001\n",
      "Epoch 21, Step: 281, Loss: 0.027851784601807594, Lr:0.0001\n",
      "Epoch 21, Step: 282, Loss: 0.05807249993085861, Lr:0.0001\n",
      "Epoch 21, Step: 283, Loss: 0.7016691565513611, Lr:0.0001\n",
      "Epoch 21, Step: 284, Loss: 0.07544378191232681, Lr:0.0001\n",
      "Epoch 21, Step: 285, Loss: 0.01139907632023096, Lr:0.0001\n",
      "Epoch 21, Step: 286, Loss: 0.1548129916191101, Lr:0.0001\n",
      "Epoch 21, Step: 287, Loss: 0.011226168833673, Lr:0.0001\n",
      "Epoch 21, Step: 288, Loss: 0.0293373204767704, Lr:0.0001\n",
      "Epoch 21, Step: 289, Loss: 0.03328737989068031, Lr:0.0001\n",
      "Epoch 21, Step: 290, Loss: 0.21228405833244324, Lr:0.0001\n",
      "Epoch 21, Step: 291, Loss: 0.11813585460186005, Lr:0.0001\n",
      "Epoch 21, Step: 292, Loss: 0.0024340765085071325, Lr:0.0001\n",
      "Epoch 21, Step: 293, Loss: 0.005842573009431362, Lr:0.0001\n",
      "Epoch 21, Step: 294, Loss: 0.014225556515157223, Lr:0.0001\n",
      "Epoch 21, Step: 295, Loss: 0.04434232413768768, Lr:0.0001\n",
      "Epoch 21, Step: 296, Loss: 0.15816403925418854, Lr:0.0001\n",
      "Epoch 21, Step: 297, Loss: 0.1468777060508728, Lr:0.0001\n",
      "Epoch 21, Step: 298, Loss: 0.00507556926459074, Lr:0.0001\n",
      "Epoch 21, Step: 299, Loss: 0.07202830165624619, Lr:0.0001\n",
      "Epoch 21, Step: 300, Loss: 0.04351438954472542, Lr:0.0001\n",
      "Epoch 21, Step: 301, Loss: 0.026209766045212746, Lr:0.0001\n",
      "Epoch 21, Step: 302, Loss: 0.0571911446750164, Lr:0.0001\n",
      "Epoch 21, Step: 303, Loss: 0.005011554807424545, Lr:0.0001\n",
      "Epoch 21, Step: 304, Loss: 0.011173030361533165, Lr:0.0001\n",
      "Epoch 21, Step: 305, Loss: 0.06349219381809235, Lr:0.0001\n",
      "Epoch 21, Step: 306, Loss: 0.07778248935937881, Lr:0.0001\n",
      "Epoch 21, Step: 307, Loss: 0.0031848475337028503, Lr:0.0001\n",
      "Epoch 21, Step: 308, Loss: 0.0187615305185318, Lr:0.0001\n",
      "Epoch 21, Step: 309, Loss: 0.012271593324840069, Lr:0.0001\n",
      "Epoch 21, Step: 310, Loss: 0.1115294024348259, Lr:0.0001\n",
      "Epoch 21, Step: 311, Loss: 0.22332854568958282, Lr:0.0001\n",
      "Epoch 21, Step: 312, Loss: 0.036907173693180084, Lr:0.0001\n",
      "Epoch 21, Step: 313, Loss: 0.013770988211035728, Lr:0.0001\n",
      "Epoch 21, Step: 314, Loss: 0.09491077810525894, Lr:0.0001\n",
      "Epoch 21, Step: 315, Loss: 0.0018935181433334947, Lr:0.0001\n",
      "Epoch 21, Step: 316, Loss: 0.08157063275575638, Lr:0.0001\n",
      "Epoch 21, Step: 317, Loss: 0.0505424402654171, Lr:0.0001\n",
      "Epoch 21, Step: 318, Loss: 0.015205126255750656, Lr:0.0001\n",
      "Epoch 21, Step: 319, Loss: 0.15283504128456116, Lr:0.0001\n",
      "Epoch 21, Step: 320, Loss: 0.018165141344070435, Lr:0.0001\n",
      "Epoch 21, Step: 321, Loss: 0.05781983211636543, Lr:0.0001\n",
      "Epoch 21, Step: 322, Loss: 0.032450199127197266, Lr:0.0001\n",
      "Epoch 21, Step: 323, Loss: 0.04764758422970772, Lr:0.0001\n",
      "Epoch 21, Step: 324, Loss: 0.01750679314136505, Lr:0.0001\n",
      "Epoch 21, Step: 325, Loss: 0.014920190908014774, Lr:0.0001\n",
      "Epoch 21, Step: 326, Loss: 0.4192626178264618, Lr:0.0001\n",
      "Epoch 21, Step: 327, Loss: 0.2353910654783249, Lr:0.0001\n",
      "Epoch 21, Step: 328, Loss: 0.07396498322486877, Lr:0.0001\n",
      "Epoch 21, Step: 329, Loss: 0.038196712732315063, Lr:0.0001\n",
      "Epoch 21, Step: 330, Loss: 0.3638242483139038, Lr:0.0001\n",
      "Epoch 21, Step: 331, Loss: 0.07108942419290543, Lr:0.0001\n",
      "Epoch 21, Step: 332, Loss: 0.20627516508102417, Lr:0.0001\n",
      "Epoch 21, Step: 333, Loss: 0.0232472475618124, Lr:0.0001\n",
      "Epoch 21, Step: 334, Loss: 0.008589845150709152, Lr:0.0001\n",
      "Epoch 21, Step: 335, Loss: 0.011876864358782768, Lr:0.0001\n",
      "Epoch 21, Step: 336, Loss: 0.017689336091279984, Lr:0.0001\n",
      "Epoch 21, Step: 337, Loss: 0.048298873007297516, Lr:0.0001\n",
      "Epoch 21, Step: 338, Loss: 0.21038204431533813, Lr:0.0001\n",
      "Epoch 21, Step: 339, Loss: 0.1840209662914276, Lr:0.0001\n",
      "Epoch 21, Step: 340, Loss: 0.15516145527362823, Lr:0.0001\n",
      "Epoch 21, Step: 341, Loss: 0.3360070586204529, Lr:0.0001\n",
      "Epoch 21, Step: 342, Loss: 0.0376773402094841, Lr:0.0001\n",
      "Epoch 21, Step: 343, Loss: 0.005565818399190903, Lr:0.0001\n",
      "Epoch 21, Step: 344, Loss: 0.026799097657203674, Lr:0.0001\n",
      "Epoch 21, Step: 345, Loss: 0.05030311271548271, Lr:0.0001\n",
      "Epoch 21, Step: 346, Loss: 0.018510233610868454, Lr:0.0001\n",
      "Epoch 21, Step: 347, Loss: 0.02100369893014431, Lr:0.0001\n",
      "Epoch 21, Step: 348, Loss: 0.14315679669380188, Lr:0.0001\n",
      "Epoch 21, Step: 349, Loss: 0.09977460652589798, Lr:0.0001\n",
      "Epoch 21, Step: 350, Loss: 0.02458932250738144, Lr:0.0001\n",
      "Epoch 21, Step: 351, Loss: 0.04649418964982033, Lr:0.0001\n",
      "Epoch 21, Step: 352, Loss: 0.05712592974305153, Lr:0.0001\n",
      "Epoch 21, Step: 353, Loss: 0.08000603318214417, Lr:0.0001\n",
      "Epoch 21, Step: 354, Loss: 0.030321665108203888, Lr:0.0001\n",
      "Epoch 21, Step: 355, Loss: 0.006107071880251169, Lr:0.0001\n",
      "Epoch 21, Step: 356, Loss: 0.005266956053674221, Lr:0.0001\n",
      "Epoch 21, Step: 357, Loss: 0.011879057623445988, Lr:0.0001\n",
      "Epoch 21, Step: 358, Loss: 0.11276709288358688, Lr:0.0001\n",
      "Epoch 21, Step: 359, Loss: 0.07732802629470825, Lr:0.0001\n",
      "Epoch 21, Step: 360, Loss: 0.009103387594223022, Lr:0.0001\n",
      "Epoch 21, Step: 361, Loss: 0.08737798780202866, Lr:0.0001\n",
      "Epoch 21, Step: 362, Loss: 0.03293497860431671, Lr:0.0001\n",
      "Epoch 21, Step: 363, Loss: 0.1446618288755417, Lr:0.0001\n",
      "Epoch 21, Step: 364, Loss: 0.10001422464847565, Lr:0.0001\n",
      "Epoch 21, Step: 365, Loss: 0.11647047847509384, Lr:0.0001\n",
      "Epoch 21, Step: 366, Loss: 0.1849556863307953, Lr:0.0001\n",
      "Epoch 21, Step: 367, Loss: 0.016800956800580025, Lr:0.0001\n",
      "Epoch 21, Step: 368, Loss: 0.03904785215854645, Lr:0.0001\n",
      "Epoch 21, Step: 369, Loss: 0.20861724019050598, Lr:0.0001\n",
      "Epoch 21, Step: 370, Loss: 0.010393457487225533, Lr:0.0001\n",
      "Epoch 21, Step: 371, Loss: 0.04597693681716919, Lr:0.0001\n",
      "Epoch 21, Step: 372, Loss: 0.04102642089128494, Lr:0.0001\n",
      "Epoch 21, Step: 373, Loss: 0.04279277101159096, Lr:0.0001\n",
      "Epoch 21, Step: 374, Loss: 0.0033147975336760283, Lr:0.0001\n",
      "Epoch 21, Step: 375, Loss: 0.5627419352531433, Lr:0.0001\n",
      "Epoch 21, Step: 376, Loss: 0.05315729230642319, Lr:0.0001\n",
      "Epoch 21, Step: 377, Loss: 0.036750033497810364, Lr:0.0001\n",
      "Epoch 21, Step: 378, Loss: 0.1072760820388794, Lr:0.0001\n",
      "Epoch 21, Step: 379, Loss: 0.02707989141345024, Lr:0.0001\n",
      "Epoch 21, Step: 380, Loss: 0.007125736214220524, Lr:0.0001\n",
      "Epoch 21, Step: 381, Loss: 0.06440526992082596, Lr:0.0001\n",
      "Epoch 21, Step: 382, Loss: 0.03247040510177612, Lr:0.0001\n",
      "Epoch 21, Step: 383, Loss: 0.03044743463397026, Lr:0.0001\n",
      "Epoch 21, Step: 384, Loss: 0.002746476326137781, Lr:0.0001\n",
      "Epoch 21, Step: 385, Loss: 0.01671535335481167, Lr:0.0001\n",
      "Epoch 21, Step: 386, Loss: 0.07671816647052765, Lr:0.0001\n",
      "Epoch 21, Step: 387, Loss: 0.0026635320391505957, Lr:0.0001\n",
      "Epoch 21, Step: 388, Loss: 0.09093762189149857, Lr:0.0001\n",
      "Epoch 21, Step: 389, Loss: 0.0070135993883013725, Lr:0.0001\n",
      "Epoch 21, Step: 390, Loss: 0.02037486620247364, Lr:0.0001\n",
      "Epoch 21, Step: 391, Loss: 0.012796099297702312, Lr:0.0001\n",
      "Epoch 21, Step: 392, Loss: 0.08220701664686203, Lr:0.0001\n",
      "Epoch 21, Step: 393, Loss: 0.061012718826532364, Lr:0.0001\n",
      "Epoch 21, Step: 394, Loss: 0.35930925607681274, Lr:0.0001\n",
      "Epoch 21, Step: 395, Loss: 0.020185545086860657, Lr:0.0001\n",
      "Epoch 21, Step: 396, Loss: 0.07424081116914749, Lr:0.0001\n",
      "Epoch 21, Step: 397, Loss: 0.0027158893644809723, Lr:0.0001\n",
      "Epoch 21, Step: 398, Loss: 0.0662546455860138, Lr:0.0001\n",
      "Epoch 21, Step: 399, Loss: 0.1462695300579071, Lr:0.0001\n",
      "Epoch 21, Step: 400, Loss: 0.27982693910598755, Lr:0.0001\n",
      "Epoch 21, Step: 401, Loss: 0.2327401489019394, Lr:0.0001\n",
      "Epoch 21, Step: 402, Loss: 0.02288334257900715, Lr:0.0001\n",
      "Epoch 21, Step: 403, Loss: 0.006095550488680601, Lr:0.0001\n",
      "Epoch 21, Step: 404, Loss: 0.06844698637723923, Lr:0.0001\n",
      "Epoch 21, Step: 405, Loss: 0.06964191794395447, Lr:0.0001\n",
      "Epoch 21, Step: 406, Loss: 0.041057076305150986, Lr:0.0001\n",
      "Epoch 21, Step: 407, Loss: 0.008275513537228107, Lr:0.0001\n",
      "Epoch 21, Step: 408, Loss: 0.15811774134635925, Lr:0.0001\n",
      "Epoch 21, Step: 409, Loss: 0.05558307468891144, Lr:0.0001\n",
      "Epoch 21, Step: 410, Loss: 0.00201623048633337, Lr:0.0001\n",
      "Epoch 21, Step: 411, Loss: 0.0033475777599960566, Lr:0.0001\n",
      "Epoch 21, Step: 412, Loss: 0.09554583579301834, Lr:0.0001\n",
      "Epoch 21, Step: 413, Loss: 0.011705027893185616, Lr:0.0001\n",
      "Epoch 21, Step: 414, Loss: 0.025470642372965813, Lr:0.0001\n",
      "Epoch 21, Step: 415, Loss: 0.0860353335738182, Lr:0.0001\n",
      "Epoch 21, Step: 416, Loss: 0.009939350187778473, Lr:0.0001\n",
      "Epoch 21, Step: 417, Loss: 0.006846494972705841, Lr:0.0001\n",
      "Epoch 21, Step: 418, Loss: 0.04868306592106819, Lr:0.0001\n",
      "Epoch 21, Step: 419, Loss: 0.15204483270645142, Lr:0.0001\n",
      "Epoch 21, Step: 420, Loss: 0.08406642824411392, Lr:0.0001\n",
      "Epoch 21, Step: 421, Loss: 0.22134339809417725, Lr:0.0001\n",
      "Epoch 21, Step: 422, Loss: 0.11641374230384827, Lr:0.0001\n",
      "Epoch 21, Step: 423, Loss: 0.10540268570184708, Lr:0.0001\n",
      "Epoch 21, Step: 424, Loss: 0.017219897359609604, Lr:0.0001\n",
      "Epoch 21, Step: 425, Loss: 0.0022060058545321226, Lr:0.0001\n",
      "Epoch 21, Step: 426, Loss: 0.008008766919374466, Lr:0.0001\n",
      "Epoch 21, Step: 427, Loss: 0.08649009466171265, Lr:0.0001\n",
      "Epoch 21, Step: 428, Loss: 0.01924632117152214, Lr:0.0001\n",
      "Epoch 21, Step: 429, Loss: 0.1205560639500618, Lr:0.0001\n",
      "Epoch 21, Step: 430, Loss: 0.034636516124010086, Lr:0.0001\n",
      "Epoch 21, Step: 431, Loss: 0.09516581147909164, Lr:0.0001\n",
      "Epoch 21, Step: 432, Loss: 0.012642408721148968, Lr:0.0001\n",
      "Epoch 21, Step: 433, Loss: 0.0035476800985634327, Lr:0.0001\n",
      "Epoch 21, Step: 434, Loss: 0.030035924166440964, Lr:0.0001\n",
      "Epoch 21, Step: 435, Loss: 0.32060980796813965, Lr:0.0001\n",
      "Epoch 21, Step: 436, Loss: 0.11469234526157379, Lr:0.0001\n",
      "Epoch 21, Step: 437, Loss: 0.03998739644885063, Lr:0.0001\n",
      "Epoch 21, Step: 438, Loss: 0.022638602182269096, Lr:0.0001\n",
      "Epoch 21, Step: 439, Loss: 0.08604650944471359, Lr:0.0001\n",
      "Epoch 21, Step: 440, Loss: 0.257038414478302, Lr:0.0001\n",
      "Epoch 21, Step: 441, Loss: 0.197662815451622, Lr:0.0001\n",
      "Epoch 21, Step: 442, Loss: 0.07807261496782303, Lr:0.0001\n",
      "Epoch 21, Step: 443, Loss: 0.2481721043586731, Lr:0.0001\n",
      "Epoch 21, Step: 444, Loss: 0.14094704389572144, Lr:0.0001\n",
      "Epoch 21, Step: 445, Loss: 0.22982095181941986, Lr:0.0001\n",
      "Epoch 21, Step: 446, Loss: 0.018408266827464104, Lr:0.0001\n",
      "Epoch 21, Step: 447, Loss: 0.06870647519826889, Lr:0.0001\n",
      "Epoch 21, Step: 448, Loss: 0.009281455539166927, Lr:0.0001\n",
      "Epoch 21, Step: 449, Loss: 0.01631760597229004, Lr:0.0001\n",
      "Epoch 21, Step: 450, Loss: 0.07949338108301163, Lr:0.0001\n",
      "Epoch 21, Step: 451, Loss: 0.008667336776852608, Lr:0.0001\n",
      "Epoch 21, Step: 452, Loss: 0.1252325028181076, Lr:0.0001\n",
      "Epoch 21, Step: 453, Loss: 0.06964883953332901, Lr:0.0001\n",
      "Epoch 21, Step: 454, Loss: 0.03832614794373512, Lr:0.0001\n",
      "Epoch 21, Step: 455, Loss: 0.006633417680859566, Lr:0.0001\n",
      "Epoch 21, Step: 456, Loss: 0.20293989777565002, Lr:0.0001\n",
      "Epoch 21, Step: 457, Loss: 0.0662020668387413, Lr:0.0001\n",
      "Epoch 21, Step: 458, Loss: 0.16597770154476166, Lr:0.0001\n",
      "Epoch 21, Step: 459, Loss: 0.005327080376446247, Lr:0.0001\n",
      "Epoch 21, Step: 460, Loss: 0.030293148010969162, Lr:0.0001\n",
      "Epoch 21, Step: 461, Loss: 0.13236038386821747, Lr:0.0001\n",
      "Epoch 21, Step: 462, Loss: 0.028999365866184235, Lr:0.0001\n",
      "Epoch 21, Step: 463, Loss: 0.03765951842069626, Lr:0.0001\n",
      "Epoch 21, Step: 464, Loss: 0.034988343715667725, Lr:0.0001\n",
      "Epoch 21, Step: 465, Loss: 0.07967746257781982, Lr:0.0001\n",
      "Epoch 21, Step: 466, Loss: 0.0925440862774849, Lr:0.0001\n",
      "Epoch 21, Step: 467, Loss: 0.0791940838098526, Lr:0.0001\n",
      "Epoch 21, Step: 468, Loss: 0.3391355276107788, Lr:0.0001\n",
      "Epoch 21, Step: 469, Loss: 0.014210164546966553, Lr:0.0001\n",
      "Epoch 21, Step: 470, Loss: 0.04596380516886711, Lr:0.0001\n",
      "Epoch 21, Step: 471, Loss: 0.01402363833039999, Lr:0.0001\n",
      "Epoch 21, Step: 472, Loss: 0.06723755598068237, Lr:0.0001\n",
      "Epoch 21, Step: 473, Loss: 0.050099752843379974, Lr:0.0001\n",
      "Epoch 21, Step: 474, Loss: 0.06525231152772903, Lr:0.0001\n",
      "Epoch 21, Step: 475, Loss: 0.08999699354171753, Lr:0.0001\n",
      "Epoch 21, Step: 476, Loss: 0.2959349453449249, Lr:0.0001\n",
      "Epoch 21, Step: 477, Loss: 0.0039863260462880135, Lr:0.0001\n",
      "Epoch 21, Step: 478, Loss: 0.02801661565899849, Lr:0.0001\n",
      "Epoch 21, Step: 479, Loss: 0.2287197709083557, Lr:0.0001\n",
      "Epoch 21, Step: 480, Loss: 0.034761834889650345, Lr:0.0001\n",
      "Epoch 21, Step: 481, Loss: 0.026026764884591103, Lr:0.0001\n",
      "Epoch 21, Step: 482, Loss: 0.3747364282608032, Lr:0.0001\n",
      "Epoch 21, Step: 483, Loss: 0.03956346958875656, Lr:0.0001\n",
      "Epoch 21, Step: 484, Loss: 0.1007566899061203, Lr:0.0001\n",
      "Epoch 21, Step: 485, Loss: 0.0989883616566658, Lr:0.0001\n",
      "Epoch 21, Step: 486, Loss: 0.20123431086540222, Lr:0.0001\n",
      "Epoch 21, Step: 487, Loss: 0.020840758457779884, Lr:0.0001\n",
      "Epoch 21, Step: 488, Loss: 0.010895609855651855, Lr:0.0001\n",
      "Epoch 21, Step: 489, Loss: 0.1512366533279419, Lr:0.0001\n",
      "Epoch 21, Step: 490, Loss: 0.038765158504247665, Lr:0.0001\n",
      "Epoch 21, Step: 491, Loss: 0.21505305171012878, Lr:0.0001\n",
      "Epoch 21, Step: 492, Loss: 0.2067640721797943, Lr:0.0001\n",
      "Epoch 21, Step: 493, Loss: 0.0554584339261055, Lr:0.0001\n",
      "Epoch 21, Step: 494, Loss: 0.13836784660816193, Lr:0.0001\n",
      "Epoch 21, Step: 495, Loss: 0.20420624315738678, Lr:0.0001\n",
      "Epoch 21, Step: 496, Loss: 0.14153820276260376, Lr:0.0001\n",
      "Epoch 21, Step: 497, Loss: 0.2554522752761841, Lr:0.0001\n",
      "Epoch 21, Step: 498, Loss: 0.061966672539711, Lr:0.0001\n",
      "Epoch 21, Step: 499, Loss: 0.053668320178985596, Lr:0.0001\n",
      "Epoch 21, Step: 500, Loss: 0.05480603873729706, Lr:0.0001\n",
      "Epoch 21, Step: 501, Loss: 0.005641656927764416, Lr:0.0001\n",
      "Epoch 21, Step: 502, Loss: 0.22890961170196533, Lr:0.0001\n",
      "Epoch 21, Step: 503, Loss: 0.09130263328552246, Lr:0.0001\n",
      "Epoch 21, Step: 504, Loss: 0.16261710226535797, Lr:0.0001\n",
      "Epoch 21, Step: 505, Loss: 0.030555063858628273, Lr:0.0001\n",
      "Epoch 21, Step: 506, Loss: 0.008367533795535564, Lr:0.0001\n",
      "Epoch 21, Step: 507, Loss: 0.15871044993400574, Lr:0.0001\n",
      "Epoch 21, Step: 508, Loss: 0.01240394078195095, Lr:0.0001\n",
      "Epoch 21, Step: 509, Loss: 0.07041781395673752, Lr:0.0001\n",
      "Epoch 21, Step: 510, Loss: 0.008665294386446476, Lr:0.0001\n",
      "Epoch 21, Step: 511, Loss: 0.18967010080814362, Lr:0.0001\n",
      "Epoch 21, Step: 512, Loss: 0.08029890060424805, Lr:0.0001\n",
      "Epoch 21, Step: 513, Loss: 0.02298303134739399, Lr:0.0001\n",
      "Epoch 21, Step: 514, Loss: 0.14423394203186035, Lr:0.0001\n",
      "Epoch 21, Step: 515, Loss: 0.02716376632452011, Lr:0.0001\n",
      "Epoch 21, Step: 516, Loss: 0.018285982310771942, Lr:0.0001\n",
      "Epoch 21, Step: 517, Loss: 0.25495871901512146, Lr:0.0001\n",
      "Epoch 21, Step: 518, Loss: 0.0699143037199974, Lr:0.0001\n",
      "Epoch 21, Step: 519, Loss: 0.02619270421564579, Lr:0.0001\n",
      "Epoch 21, Step: 520, Loss: 0.890856921672821, Lr:0.0001\n",
      "Epoch 21, Step: 521, Loss: 0.017811793833971024, Lr:0.0001\n",
      "Epoch 21, Step: 522, Loss: 0.02070659026503563, Lr:0.0001\n",
      "Epoch 21, Step: 523, Loss: 0.011077391915023327, Lr:0.0001\n",
      "Epoch 21, Step: 524, Loss: 0.20165947079658508, Lr:0.0001\n",
      "Epoch 21, Step: 525, Loss: 0.0011517201783135533, Lr:0.0001\n",
      "Epoch 21, Step: 526, Loss: 0.11931746453046799, Lr:0.0001\n",
      "Epoch 21, Step: 527, Loss: 0.23448605835437775, Lr:0.0001\n",
      "Epoch 21, Step: 528, Loss: 0.020202990621328354, Lr:0.0001\n",
      "Epoch 21, Step: 529, Loss: 0.29652687907218933, Lr:0.0001\n",
      "Epoch 21, Step: 530, Loss: 0.03735211864113808, Lr:0.0001\n",
      "Epoch 21, Step: 531, Loss: 0.15329506993293762, Lr:0.0001\n",
      "Epoch 21, Step: 532, Loss: 0.1991380751132965, Lr:0.0001\n",
      "Epoch 21, Step: 533, Loss: 0.0241001658141613, Lr:0.0001\n",
      "Epoch 21, Step: 534, Loss: 0.14694254100322723, Lr:0.0001\n",
      "Epoch 21, Step: 535, Loss: 0.1796443909406662, Lr:0.0001\n",
      "Epoch 21, Step: 536, Loss: 0.008494263514876366, Lr:0.0001\n",
      "Epoch 21, Step: 537, Loss: 0.24482524394989014, Lr:0.0001\n",
      "Epoch 21, Step: 538, Loss: 0.08746112138032913, Lr:0.0001\n",
      "Epoch 21, Step: 539, Loss: 0.08916962891817093, Lr:0.0001\n",
      "Epoch 21, Step: 540, Loss: 0.006446178071200848, Lr:0.0001\n",
      "Epoch 21, Step: 541, Loss: 0.1297174096107483, Lr:0.0001\n",
      "Epoch 21, Step: 542, Loss: 0.07600603997707367, Lr:0.0001\n",
      "Epoch 21, Step: 543, Loss: 0.026898633688688278, Lr:0.0001\n",
      "Epoch 21, Step: 544, Loss: 0.025780918076634407, Lr:0.0001\n",
      "Epoch 21, Step: 545, Loss: 0.033691082149744034, Lr:0.0001\n",
      "Epoch 21, Step: 546, Loss: 0.024220731109380722, Lr:0.0001\n",
      "Epoch 21, Step: 547, Loss: 0.14230291545391083, Lr:0.0001\n",
      "Epoch 21, Step: 548, Loss: 0.02018127404153347, Lr:0.0001\n",
      "Epoch 21, Step: 549, Loss: 0.03188016638159752, Lr:0.0001\n",
      "Epoch 21, Step: 550, Loss: 0.031405746936798096, Lr:0.0001\n",
      "Epoch 21, Step: 551, Loss: 0.35098689794540405, Lr:0.0001\n",
      "Epoch 21, Step: 552, Loss: 0.021662598475813866, Lr:0.0001\n",
      "Epoch 21, Step: 553, Loss: 0.11113449186086655, Lr:0.0001\n",
      "Epoch 21, Step: 554, Loss: 0.2762768566608429, Lr:0.0001\n",
      "Epoch 21, Step: 555, Loss: 0.030356982722878456, Lr:0.0001\n",
      "Epoch 21, Step: 556, Loss: 0.01151614636182785, Lr:0.0001\n",
      "Epoch 21, Step: 557, Loss: 0.016947438940405846, Lr:0.0001\n",
      "Epoch 21, Step: 558, Loss: 0.29767459630966187, Lr:0.0001\n",
      "Epoch 21, Step: 559, Loss: 0.029973667114973068, Lr:0.0001\n",
      "Epoch 21, Step: 560, Loss: 0.08172208070755005, Lr:0.0001\n",
      "Epoch 21, Step: 561, Loss: 0.02657592110335827, Lr:0.0001\n",
      "Epoch 21, Step: 562, Loss: 0.036969151347875595, Lr:0.0001\n",
      "Epoch 21, Step: 563, Loss: 0.04751507192850113, Lr:0.0001\n",
      "Epoch 21, Step: 564, Loss: 0.0017444058321416378, Lr:0.0001\n",
      "Epoch 21, Step: 565, Loss: 0.083791583776474, Lr:0.0001\n",
      "Epoch 21, Step: 566, Loss: 0.010384784080088139, Lr:0.0001\n",
      "Epoch 21, Step: 567, Loss: 0.22533519566059113, Lr:0.0001\n",
      "Epoch 21, Step: 568, Loss: 0.07586158066987991, Lr:0.0001\n",
      "Epoch 21, Step: 569, Loss: 0.06933576613664627, Lr:0.0001\n",
      "Epoch 21, Step: 570, Loss: 0.04638361558318138, Lr:0.0001\n",
      "Epoch 21, Step: 571, Loss: 0.06773695349693298, Lr:0.0001\n",
      "Epoch 21, Step: 572, Loss: 0.03729376569390297, Lr:0.0001\n",
      "Epoch 21, Step: 573, Loss: 0.02170783467590809, Lr:0.0001\n",
      "Epoch 21, Step: 574, Loss: 0.015871752053499222, Lr:0.0001\n",
      "Epoch 21, Step: 575, Loss: 0.007805409841239452, Lr:0.0001\n",
      "Epoch 21, Step: 576, Loss: 0.01283988542854786, Lr:0.0001\n",
      "Epoch 21, Step: 577, Loss: 0.042265962809324265, Lr:0.0001\n",
      "Epoch 21, Step: 578, Loss: 0.13594992458820343, Lr:0.0001\n",
      "Epoch 21, Step: 579, Loss: 0.008199810981750488, Lr:0.0001\n",
      "Epoch 21, Step: 580, Loss: 0.2994499206542969, Lr:0.0001\n",
      "Epoch 21, Step: 581, Loss: 0.04223553091287613, Lr:0.0001\n",
      "Epoch 21, Step: 582, Loss: 0.02458762377500534, Lr:0.0001\n",
      "Epoch 21, Step: 583, Loss: 0.13026063144207, Lr:0.0001\n",
      "Epoch 21, Step: 584, Loss: 0.007570588495582342, Lr:0.0001\n",
      "Epoch 21, Step: 585, Loss: 0.034475795924663544, Lr:0.0001\n",
      "Epoch 21, Step: 586, Loss: 0.010135435499250889, Lr:0.0001\n",
      "Epoch 21, Step: 587, Loss: 0.10232697427272797, Lr:0.0001\n",
      "Epoch 21, Step: 588, Loss: 0.12980474531650543, Lr:0.0001\n",
      "Epoch 21, Step: 589, Loss: 0.17753177881240845, Lr:0.0001\n",
      "Epoch 21, Step: 590, Loss: 0.008184080943465233, Lr:0.0001\n",
      "Epoch 21, Step: 591, Loss: 0.013085723854601383, Lr:0.0001\n",
      "Epoch 21, Step: 592, Loss: 0.09762053936719894, Lr:0.0001\n",
      "Epoch 21, Step: 593, Loss: 0.1276112198829651, Lr:0.0001\n",
      "Epoch 21, Step: 594, Loss: 0.018495075404644012, Lr:0.0001\n",
      "Epoch 21, Step: 595, Loss: 0.06400679796934128, Lr:0.0001\n",
      "Epoch 21, Step: 596, Loss: 0.024079609662294388, Lr:0.0001\n",
      "Epoch 21, Step: 597, Loss: 0.2706805467605591, Lr:0.0001\n",
      "Epoch 21, Step: 598, Loss: 0.015561833046376705, Lr:0.0001\n",
      "Epoch 21, Step: 599, Loss: 0.12466239184141159, Lr:0.0001\n",
      "Epoch 21, Step: 600, Loss: 0.07561057806015015, Lr:0.0001\n",
      "Epoch 21, Step: 601, Loss: 0.00866316631436348, Lr:0.0001\n",
      "Epoch 21, Step: 602, Loss: 0.02415974996984005, Lr:0.0001\n",
      "Epoch 21, Step: 603, Loss: 0.00619513401761651, Lr:0.0001\n",
      "Epoch 21, Step: 604, Loss: 0.05934540554881096, Lr:0.0001\n",
      "Epoch 21, Step: 605, Loss: 0.06551212817430496, Lr:0.0001\n",
      "Epoch 21, Step: 606, Loss: 0.020093630999326706, Lr:0.0001\n",
      "Epoch 21, Step: 607, Loss: 0.007797520607709885, Lr:0.0001\n",
      "Epoch 21, Step: 608, Loss: 0.08006332069635391, Lr:0.0001\n",
      "Epoch 21, Step: 609, Loss: 0.05641550570726395, Lr:0.0001\n",
      "Epoch 21, Step: 610, Loss: 0.00723964674398303, Lr:0.0001\n",
      "Epoch 21, Step: 611, Loss: 0.05613202601671219, Lr:0.0001\n",
      "Epoch 21, Step: 612, Loss: 0.06185861676931381, Lr:0.0001\n",
      "Epoch 21, Step: 613, Loss: 0.38220518827438354, Lr:0.0001\n",
      "Epoch 21, Step: 614, Loss: 0.1784922331571579, Lr:0.0001\n",
      "Epoch 21, Step: 615, Loss: 0.016021983698010445, Lr:0.0001\n",
      "Epoch 21, Step: 616, Loss: 0.1334541290998459, Lr:0.0001\n",
      "Epoch 21, Step: 617, Loss: 0.028208207339048386, Lr:0.0001\n",
      "Epoch 21, Step: 618, Loss: 0.12222870439291, Lr:0.0001\n",
      "Epoch 21, Step: 619, Loss: 0.042227908968925476, Lr:0.0001\n",
      "Epoch 21, Step: 620, Loss: 0.01652895286679268, Lr:0.0001\n",
      "Epoch 21, Step: 621, Loss: 0.12114259600639343, Lr:0.0001\n",
      "Epoch 21, Step: 622, Loss: 0.07984276115894318, Lr:0.0001\n",
      "Epoch 21, Step: 623, Loss: 0.02456752024590969, Lr:0.0001\n",
      "Epoch 21, Step: 624, Loss: 0.07608208805322647, Lr:0.0001\n",
      "Epoch 21, Step: 625, Loss: 0.3418722450733185, Lr:0.0001\n",
      "Epoch 21, Step: 626, Loss: 0.15992459654808044, Lr:0.0001\n",
      "Epoch 21, Step: 627, Loss: 0.03537609055638313, Lr:0.0001\n",
      "Epoch 21, Step: 628, Loss: 0.08498217910528183, Lr:0.0001\n",
      "Epoch 21, Step: 629, Loss: 0.14254407584667206, Lr:0.0001\n",
      "Epoch 21, Step: 630, Loss: 0.0463239960372448, Lr:0.0001\n",
      "Epoch 21, Step: 631, Loss: 0.13033178448677063, Lr:0.0001\n",
      "Epoch 21, Step: 632, Loss: 0.1738809496164322, Lr:0.0001\n",
      "Epoch 21, Step: 633, Loss: 0.1302177757024765, Lr:0.0001\n",
      "Epoch 21, Step: 634, Loss: 0.3488951325416565, Lr:0.0001\n",
      "Epoch 21, Step: 635, Loss: 0.1382458508014679, Lr:0.0001\n",
      "Epoch 21, Step: 636, Loss: 0.2862948775291443, Lr:0.0001\n",
      "Epoch 21, Step: 637, Loss: 0.018254708498716354, Lr:0.0001\n",
      "Epoch 21, Step: 638, Loss: 0.2824738323688507, Lr:0.0001\n",
      "Epoch 21, Step: 639, Loss: 0.12295149266719818, Lr:0.0001\n",
      "Epoch 21, Step: 640, Loss: 0.051599591970443726, Lr:0.0001\n",
      "Epoch 21, Step: 641, Loss: 0.14763867855072021, Lr:0.0001\n",
      "Epoch 21, Step: 642, Loss: 0.06675180792808533, Lr:0.0001\n",
      "Epoch 21, Step: 643, Loss: 0.02206537313759327, Lr:0.0001\n",
      "Epoch 21, Step: 644, Loss: 0.010766001418232918, Lr:0.0001\n",
      "Epoch 21, Step: 645, Loss: 0.2352410852909088, Lr:0.0001\n",
      "Epoch 21, Step: 646, Loss: 0.014121770858764648, Lr:0.0001\n",
      "Epoch 21, Step: 647, Loss: 0.1568467766046524, Lr:0.0001\n",
      "Epoch 21, Step: 648, Loss: 0.01080606784671545, Lr:0.0001\n",
      "Epoch 21, Step: 649, Loss: 0.03166719526052475, Lr:0.0001\n",
      "Epoch 21, Step: 650, Loss: 0.20884554088115692, Lr:0.0001\n",
      "Epoch 21, Step: 651, Loss: 0.08662405610084534, Lr:0.0001\n",
      "Epoch 21, Step: 652, Loss: 0.05937253311276436, Lr:0.0001\n",
      "Epoch 21, Step: 653, Loss: 0.20847995579242706, Lr:0.0001\n",
      "Epoch 21, Step: 654, Loss: 0.0628201961517334, Lr:0.0001\n",
      "Epoch 21, Step: 655, Loss: 0.11415015906095505, Lr:0.0001\n",
      "Epoch 21, Step: 656, Loss: 0.14686532318592072, Lr:0.0001\n",
      "Epoch 21, Step: 657, Loss: 0.12011172622442245, Lr:0.0001\n",
      "Epoch 21, Step: 658, Loss: 0.2144865095615387, Lr:0.0001\n",
      "Epoch 21, Step: 659, Loss: 0.099092997610569, Lr:0.0001\n",
      "Epoch 21, Step: 660, Loss: 0.010507198050618172, Lr:0.0001\n",
      "Epoch 21, Step: 661, Loss: 0.029046596959233284, Lr:0.0001\n",
      "Epoch 21, Step: 662, Loss: 0.16727064549922943, Lr:0.0001\n",
      "Epoch 21, Step: 663, Loss: 0.025683991611003876, Lr:0.0001\n",
      "Epoch 21, Step: 664, Loss: 0.016469357535243034, Lr:0.0001\n",
      "Epoch 21, Step: 665, Loss: 0.1505158543586731, Lr:0.0001\n",
      "Epoch 21, Step: 666, Loss: 0.11377285420894623, Lr:0.0001\n",
      "Epoch 21, Step: 667, Loss: 0.00820607878267765, Lr:0.0001\n",
      "Epoch 21, Step: 668, Loss: 0.12321781367063522, Lr:0.0001\n",
      "Epoch 21, Step: 669, Loss: 0.1021791473031044, Lr:0.0001\n",
      "Epoch 21, Step: 670, Loss: 0.017603447660803795, Lr:0.0001\n",
      "Epoch 21, Step: 671, Loss: 0.010116634890437126, Lr:0.0001\n",
      "Epoch 21, Step: 672, Loss: 0.0547633022069931, Lr:0.0001\n",
      "Epoch 21, Step: 673, Loss: 0.07086262106895447, Lr:0.0001\n",
      "Epoch 21, Step: 674, Loss: 0.17562270164489746, Lr:0.0001\n",
      "Epoch 21, Step: 675, Loss: 0.054349448531866074, Lr:0.0001\n",
      "Epoch 21, Step: 676, Loss: 0.034554075449705124, Lr:0.0001\n",
      "Epoch 21, Step: 677, Loss: 0.02653047814965248, Lr:0.0001\n",
      "Epoch 21, Step: 678, Loss: 0.02101980336010456, Lr:0.0001\n",
      "Epoch 21, Step: 679, Loss: 0.019360389560461044, Lr:0.0001\n",
      "Epoch 21, Step: 680, Loss: 0.037359800189733505, Lr:0.0001\n",
      "Epoch 21, Step: 681, Loss: 0.6197111010551453, Lr:0.0001\n",
      "Epoch 21, Step: 682, Loss: 0.3590666651725769, Lr:0.0001\n",
      "Epoch 21, Step: 683, Loss: 0.03667644038796425, Lr:0.0001\n",
      "Epoch 21, Step: 684, Loss: 0.02805183455348015, Lr:0.0001\n",
      "Epoch 21, Step: 685, Loss: 0.15286210179328918, Lr:0.0001\n",
      "Epoch 21, Step: 686, Loss: 0.07629095762968063, Lr:0.0001\n",
      "Epoch 21, Step: 687, Loss: 0.01699245534837246, Lr:0.0001\n",
      "Epoch 21, Step: 688, Loss: 0.08126876503229141, Lr:0.0001\n",
      "Epoch 21, Step: 689, Loss: 0.07418876141309738, Lr:0.0001\n",
      "Epoch 21, Step: 690, Loss: 0.08313210308551788, Lr:0.0001\n",
      "Epoch 21, Step: 691, Loss: 0.08193473517894745, Lr:0.0001\n",
      "Epoch 21, Step: 692, Loss: 0.009402384050190449, Lr:0.0001\n",
      "Epoch 21, Step: 693, Loss: 0.03832429647445679, Lr:0.0001\n",
      "Epoch 21, Step: 694, Loss: 0.000737567141186446, Lr:0.0001\n",
      "Epoch 21, Step: 695, Loss: 0.03639857843518257, Lr:0.0001\n",
      "Epoch 21, Step: 696, Loss: 0.19933459162712097, Lr:0.0001\n",
      "Epoch 21, Step: 697, Loss: 0.16565106809139252, Lr:0.0001\n",
      "Epoch 21, Step: 698, Loss: 0.023722082376480103, Lr:0.0001\n",
      "Epoch 21, Step: 699, Loss: 0.09217233955860138, Lr:0.0001\n",
      "Epoch 21, Step: 700, Loss: 0.009552594274282455, Lr:0.0001\n",
      "Epoch 21, Step: 701, Loss: 0.030271966010332108, Lr:0.0001\n",
      "Epoch 21, Step: 702, Loss: 0.093865305185318, Lr:0.0001\n",
      "Epoch 21, Step: 703, Loss: 0.13307984173297882, Lr:0.0001\n",
      "Epoch 21, Step: 704, Loss: 0.07932201027870178, Lr:0.0001\n",
      "Epoch 21, Step: 705, Loss: 0.05605369433760643, Lr:0.0001\n",
      "Epoch 21, Step: 706, Loss: 0.004175519570708275, Lr:0.0001\n",
      "Epoch 21, Step: 707, Loss: 0.04628725349903107, Lr:0.0001\n",
      "Epoch 21, Step: 708, Loss: 0.0456901378929615, Lr:0.0001\n",
      "Epoch 21, Step: 709, Loss: 0.01832660287618637, Lr:0.0001\n",
      "Epoch 21, Step: 710, Loss: 0.03313956782221794, Lr:0.0001\n",
      "Epoch 21, Step: 711, Loss: 0.007216067984700203, Lr:0.0001\n",
      "Epoch 21, Step: 712, Loss: 0.4414557218551636, Lr:0.0001\n",
      "Epoch 21, Step: 713, Loss: 0.007384557276964188, Lr:0.0001\n",
      "Epoch 21, Step: 714, Loss: 0.025428075343370438, Lr:0.0001\n",
      "Epoch 21, Step: 715, Loss: 0.038432806730270386, Lr:0.0001\n",
      "Epoch 21, Step: 716, Loss: 0.012442671693861485, Lr:0.0001\n",
      "Epoch 21, Step: 717, Loss: 0.10332717001438141, Lr:0.0001\n",
      "Epoch 21, Step: 718, Loss: 0.0830208882689476, Lr:0.0001\n",
      "Epoch 21, Step: 719, Loss: 0.04415865242481232, Lr:0.0001\n",
      "Epoch 21, Step: 720, Loss: 0.06640299409627914, Lr:0.0001\n",
      "Epoch 21, Step: 721, Loss: 0.11681245267391205, Lr:0.0001\n",
      "Epoch 21, Step: 722, Loss: 0.003267735941335559, Lr:0.0001\n",
      "Epoch 21, Step: 723, Loss: 0.01580839417874813, Lr:0.0001\n",
      "Epoch 21, Step: 724, Loss: 0.025144057348370552, Lr:0.0001\n",
      "Epoch 21, Step: 725, Loss: 0.04979701340198517, Lr:0.0001\n",
      "Epoch 21, Step: 726, Loss: 0.22928130626678467, Lr:0.0001\n",
      "Epoch 21, Step: 727, Loss: 0.06341034919023514, Lr:0.0001\n",
      "Epoch 21, Step: 728, Loss: 0.031791336834430695, Lr:0.0001\n",
      "Epoch 21, Step: 729, Loss: 0.21904629468917847, Lr:0.0001\n",
      "Epoch 21, Step: 730, Loss: 0.2149793803691864, Lr:0.0001\n",
      "Epoch 21, Step: 731, Loss: 0.005626796279102564, Lr:0.0001\n",
      "Epoch 21, Step: 732, Loss: 0.07850857824087143, Lr:0.0001\n",
      "Epoch 21, Step: 733, Loss: 0.06598076224327087, Lr:0.0001\n",
      "Epoch 21, Step: 734, Loss: 0.013542093336582184, Lr:0.0001\n",
      "Epoch 21, Step: 735, Loss: 0.0032381389755755663, Lr:0.0001\n",
      "Epoch 21, Step: 736, Loss: 0.092809297144413, Lr:0.0001\n",
      "Epoch 21, Step: 737, Loss: 0.3080761134624481, Lr:0.0001\n",
      "Epoch 21, Step: 738, Loss: 0.33714455366134644, Lr:0.0001\n",
      "Epoch 21, Step: 739, Loss: 0.010980813764035702, Lr:0.0001\n",
      "Epoch 21, Step: 740, Loss: 0.13934816420078278, Lr:0.0001\n",
      "Epoch 21, Step: 741, Loss: 0.014963007532060146, Lr:0.0001\n",
      "Epoch 21, Step: 742, Loss: 0.06811957061290741, Lr:0.0001\n",
      "Epoch 21, Step: 743, Loss: 0.1165224015712738, Lr:0.0001\n",
      "Epoch 21, Step: 744, Loss: 0.029437469318509102, Lr:0.0001\n",
      "Epoch 21, Step: 745, Loss: 0.08018796145915985, Lr:0.0001\n",
      "Epoch 21, Step: 746, Loss: 0.027741512283682823, Lr:0.0001\n",
      "Epoch 21, Step: 747, Loss: 0.1350882351398468, Lr:0.0001\n",
      "Epoch 21, Step: 748, Loss: 0.05594312772154808, Lr:0.0001\n",
      "Epoch 21, Step: 749, Loss: 0.017407434061169624, Lr:0.0001\n",
      "Epoch 21, Step: 750, Loss: 0.03007839433848858, Lr:0.0001\n",
      "Epoch 21, Step: 751, Loss: 0.08692612498998642, Lr:0.0001\n",
      "Epoch 21, Step: 752, Loss: 0.011833502911031246, Lr:0.0001\n",
      "Epoch 21, Step: 753, Loss: 0.04712296277284622, Lr:0.0001\n",
      "Epoch 21, Step: 754, Loss: 0.05086823180317879, Lr:0.0001\n",
      "Epoch 21, Step: 755, Loss: 0.010210084728896618, Lr:0.0001\n",
      "Epoch 21, Step: 756, Loss: 0.07411888986825943, Lr:0.0001\n",
      "Epoch 21, Step: 757, Loss: 0.16235925257205963, Lr:0.0001\n",
      "Epoch 21, Step: 758, Loss: 0.1825292408466339, Lr:0.0001\n",
      "Epoch 21, Step: 759, Loss: 0.02785787172615528, Lr:0.0001\n",
      "Epoch 21, Step: 760, Loss: 0.011441177688539028, Lr:0.0001\n",
      "Epoch 21, Step: 761, Loss: 0.010147089138627052, Lr:0.0001\n",
      "Epoch 21, Step: 762, Loss: 0.01692185178399086, Lr:0.0001\n",
      "Epoch 21, Step: 763, Loss: 0.004930371418595314, Lr:0.0001\n",
      "Epoch 21, Step: 764, Loss: 0.0510021336376667, Lr:0.0001\n",
      "Epoch 21, Step: 765, Loss: 0.5128440856933594, Lr:0.0001\n",
      "Epoch 21, Step: 766, Loss: 0.025484733283519745, Lr:0.0001\n",
      "Epoch 21, Step: 767, Loss: 0.008943697437644005, Lr:0.0001\n",
      "Epoch 21, Step: 768, Loss: 0.08143304288387299, Lr:0.0001\n",
      "Epoch 21, Step: 769, Loss: 0.07550396025180817, Lr:0.0001\n",
      "Epoch 21, Step: 770, Loss: 0.032452017068862915, Lr:0.0001\n",
      "Epoch 21, Step: 771, Loss: 0.26986807584762573, Lr:0.0001\n",
      "Epoch 21, Step: 772, Loss: 0.2738460898399353, Lr:0.0001\n",
      "Epoch 21, Step: 773, Loss: 0.03914439678192139, Lr:0.0001\n",
      "Epoch 21, Step: 774, Loss: 0.15593385696411133, Lr:0.0001\n",
      "Epoch 21, Step: 775, Loss: 0.048383038491010666, Lr:0.0001\n",
      "Epoch 21, Step: 776, Loss: 0.01393986213952303, Lr:0.0001\n",
      "Epoch 21, Step: 777, Loss: 0.028760099783539772, Lr:0.0001\n",
      "Epoch 21, Step: 778, Loss: 0.13713280856609344, Lr:0.0001\n",
      "Epoch 21, Step: 779, Loss: 0.010725388303399086, Lr:0.0001\n",
      "Epoch 21, Step: 780, Loss: 0.19287599623203278, Lr:0.0001\n",
      "Epoch 21, Step: 781, Loss: 0.21194224059581757, Lr:0.0001\n",
      "Epoch 21, Step: 782, Loss: 0.17819488048553467, Lr:0.0001\n",
      "Epoch 21, Step: 783, Loss: 0.06784036755561829, Lr:0.0001\n",
      "Epoch 21, Step: 784, Loss: 0.017016751691699028, Lr:0.0001\n",
      "Epoch 21, Step: 785, Loss: 0.0357857309281826, Lr:0.0001\n",
      "Epoch 21, Step: 786, Loss: 0.31706371903419495, Lr:0.0001\n",
      "Epoch 21, Step: 787, Loss: 0.07990073412656784, Lr:0.0001\n",
      "Epoch 21, Step: 788, Loss: 0.14365293085575104, Lr:0.0001\n",
      "Epoch 21, Step: 789, Loss: 0.09510249644517899, Lr:0.0001\n",
      "Epoch 21, Step: 790, Loss: 0.0666208267211914, Lr:0.0001\n",
      "Epoch 21, Step: 791, Loss: 0.37054407596588135, Lr:0.0001\n",
      "Epoch 21, Step: 792, Loss: 0.027393918484449387, Lr:0.0001\n",
      "Epoch 21, Step: 793, Loss: 0.05500221997499466, Lr:0.0001\n",
      "Epoch 21, Step: 794, Loss: 0.01738853007555008, Lr:0.0001\n",
      "Epoch 21, Step: 795, Loss: 0.007319089025259018, Lr:0.0001\n",
      "Epoch 21, Step: 796, Loss: 0.002964851912111044, Lr:0.0001\n",
      "Epoch 21, Step: 797, Loss: 0.10724551975727081, Lr:0.0001\n",
      "Epoch 21, Step: 798, Loss: 0.02565036341547966, Lr:0.0001\n",
      "Epoch 21, Step: 799, Loss: 0.009204693138599396, Lr:0.0001\n",
      "Epoch 21, Step: 800, Loss: 0.015032785944640636, Lr:0.0001\n",
      "Epoch 21, Step: 801, Loss: 0.22175613045692444, Lr:0.0001\n",
      "Epoch 21, Step: 802, Loss: 0.018829550594091415, Lr:0.0001\n",
      "Epoch 21, Step: 803, Loss: 0.029633715748786926, Lr:0.0001\n",
      "Epoch 21, Step: 804, Loss: 0.12634997069835663, Lr:0.0001\n",
      "Epoch 21, Step: 805, Loss: 0.043014802038669586, Lr:0.0001\n",
      "Epoch 21, Step: 806, Loss: 0.008281152695417404, Lr:0.0001\n",
      "Epoch 21, Step: 807, Loss: 0.05403878539800644, Lr:0.0001\n",
      "Epoch 21, Step: 808, Loss: 0.02419194020330906, Lr:0.0001\n",
      "Epoch 21, Step: 809, Loss: 0.015335713513195515, Lr:0.0001\n",
      "Epoch 21, Step: 810, Loss: 0.031016841530799866, Lr:0.0001\n",
      "Epoch 21, Step: 811, Loss: 0.03301110118627548, Lr:0.0001\n",
      "Epoch 21, Step: 812, Loss: 0.00024533539544790983, Lr:0.0001\n",
      "Epoch 21, Step: 813, Loss: 0.056003473699092865, Lr:0.0001\n",
      "Epoch 21, Step: 814, Loss: 0.24854712188243866, Lr:0.0001\n",
      "Epoch 21, Step: 815, Loss: 0.024331731721758842, Lr:0.0001\n",
      "Epoch 21, Step: 816, Loss: 0.03324026241898537, Lr:0.0001\n",
      "Epoch 21, Step: 817, Loss: 0.03320476412773132, Lr:0.0001\n",
      "Epoch 21, Step: 818, Loss: 0.006245739292353392, Lr:0.0001\n",
      "Epoch 21, Step: 819, Loss: 0.28361260890960693, Lr:0.0001\n",
      "Epoch 21, Step: 820, Loss: 0.05153030902147293, Lr:0.0001\n",
      "Epoch 21, Step: 821, Loss: 0.1208527535200119, Lr:0.0001\n",
      "Epoch 21, Step: 822, Loss: 0.06584624201059341, Lr:0.0001\n",
      "Epoch 21, Step: 823, Loss: 0.03422507271170616, Lr:0.0001\n",
      "Epoch 21, Step: 824, Loss: 0.042781319469213486, Lr:0.0001\n",
      "Epoch 21, Step: 825, Loss: 0.014655034989118576, Lr:0.0001\n",
      "Epoch 21, Step: 826, Loss: 0.16995148360729218, Lr:0.0001\n",
      "Epoch 21, Step: 827, Loss: 0.004971267189830542, Lr:0.0001\n",
      "Epoch 21, Step: 828, Loss: 0.004401059355586767, Lr:0.0001\n",
      "Epoch 21, Step: 829, Loss: 0.3437010645866394, Lr:0.0001\n",
      "Epoch 21, Step: 830, Loss: 0.0770910456776619, Lr:0.0001\n",
      "Epoch 21, Step: 831, Loss: 0.007893153466284275, Lr:0.0001\n",
      "Epoch 21, Step: 832, Loss: 0.144142746925354, Lr:0.0001\n",
      "Epoch 21, Step: 833, Loss: 0.01645359769463539, Lr:0.0001\n",
      "Epoch 21, Step: 834, Loss: 0.056285273283720016, Lr:0.0001\n",
      "Epoch 21, Step: 835, Loss: 0.039294298738241196, Lr:0.0001\n",
      "Epoch 21, Step: 836, Loss: 0.1528794765472412, Lr:0.0001\n",
      "Epoch 21, Step: 837, Loss: 0.03701357543468475, Lr:0.0001\n",
      "Epoch 21, Step: 838, Loss: 0.030205238610506058, Lr:0.0001\n",
      "Epoch 21, Step: 839, Loss: 0.09148719906806946, Lr:0.0001\n",
      "Epoch 21, Step: 840, Loss: 0.06066949665546417, Lr:0.0001\n",
      "Epoch 21, Step: 841, Loss: 0.01683163456618786, Lr:0.0001\n",
      "Epoch 21, Step: 842, Loss: 0.11312057822942734, Lr:0.0001\n",
      "Epoch 21, Step: 843, Loss: 0.07837608456611633, Lr:0.0001\n",
      "Epoch 21, Step: 844, Loss: 0.25482654571533203, Lr:0.0001\n",
      "Epoch 21, Step: 845, Loss: 0.18071196973323822, Lr:0.0001\n",
      "Epoch 21, Step: 846, Loss: 0.01815347746014595, Lr:0.0001\n",
      "Epoch 21, Step: 847, Loss: 0.1212838739156723, Lr:0.0001\n",
      "Epoch 21, Step: 848, Loss: 0.18245069682598114, Lr:0.0001\n",
      "Epoch 21, Step: 849, Loss: 0.0012861402938142419, Lr:0.0001\n",
      "Epoch 21, Step: 850, Loss: 0.14945831894874573, Lr:0.0001\n",
      "Epoch 21, Step: 851, Loss: 0.14853674173355103, Lr:0.0001\n",
      "Epoch 21, Step: 852, Loss: 0.05388778820633888, Lr:0.0001\n",
      "Epoch 21, Step: 853, Loss: 0.1321653127670288, Lr:0.0001\n",
      "Epoch 21, Step: 854, Loss: 0.036873508244752884, Lr:0.0001\n",
      "Epoch 21, Step: 855, Loss: 0.42407870292663574, Lr:0.0001\n",
      "Epoch 21, Step: 856, Loss: 0.048407573252916336, Lr:0.0001\n",
      "Epoch 21, Step: 857, Loss: 0.1726641058921814, Lr:0.0001\n",
      "Epoch 21, Step: 858, Loss: 0.15451815724372864, Lr:0.0001\n",
      "Epoch 21, Step: 859, Loss: 0.3210127353668213, Lr:0.0001\n",
      "Epoch 21, Step: 860, Loss: 0.17722254991531372, Lr:0.0001\n",
      "Epoch 21, Step: 861, Loss: 0.033422503620386124, Lr:0.0001\n",
      "Epoch 21, Step: 862, Loss: 0.06198219582438469, Lr:0.0001\n",
      "Epoch 21, Step: 863, Loss: 0.1948702037334442, Lr:0.0001\n",
      "Epoch 21, Step: 864, Loss: 0.14971888065338135, Lr:0.0001\n",
      "Epoch 21, Step: 865, Loss: 0.0009649909334257245, Lr:0.0001\n",
      "Epoch 21, Step: 866, Loss: 0.14372427761554718, Lr:0.0001\n",
      "Epoch 21, Step: 867, Loss: 0.02956671267747879, Lr:0.0001\n",
      "Epoch 21, Step: 868, Loss: 0.07564202696084976, Lr:0.0001\n",
      "Epoch 21, Step: 869, Loss: 0.017473379150032997, Lr:0.0001\n",
      "Epoch 21, Step: 870, Loss: 0.15401898324489594, Lr:0.0001\n",
      "Epoch 21, Step: 871, Loss: 0.03698687627911568, Lr:0.0001\n",
      "Epoch 21, Step: 872, Loss: 0.008669490925967693, Lr:0.0001\n",
      "Epoch 21, Step: 873, Loss: 0.09244886040687561, Lr:0.0001\n",
      "Epoch 21, Step: 874, Loss: 0.13504448533058167, Lr:0.0001\n",
      "Epoch 21, Step: 875, Loss: 0.19655224680900574, Lr:0.0001\n",
      "Epoch 21, Step: 876, Loss: 0.03256925567984581, Lr:0.0001\n",
      "Epoch 21, Step: 877, Loss: 0.03003106452524662, Lr:0.0001\n",
      "Epoch 21, Step: 878, Loss: 0.28738945722579956, Lr:0.0001\n",
      "Epoch 21, Step: 879, Loss: 0.20687809586524963, Lr:0.0001\n",
      "Epoch 21, Step: 880, Loss: 0.5193648934364319, Lr:0.0001\n",
      "Epoch 21, Step: 881, Loss: 0.015405750833451748, Lr:0.0001\n",
      "Epoch 21, Step: 882, Loss: 0.006231608334928751, Lr:0.0001\n",
      "Epoch 21, Step: 883, Loss: 0.3481462001800537, Lr:0.0001\n",
      "Epoch 21, Step: 884, Loss: 0.07369299978017807, Lr:0.0001\n",
      "Epoch 21, Step: 885, Loss: 0.11562146246433258, Lr:0.0001\n",
      "Epoch 21, Step: 886, Loss: 0.22321100533008575, Lr:0.0001\n",
      "Epoch 21, Step: 887, Loss: 0.1563306748867035, Lr:0.0001\n",
      "Epoch 21, Step: 888, Loss: 0.17687593400478363, Lr:0.0001\n",
      "Epoch 21, Step: 889, Loss: 0.14829666912555695, Lr:0.0001\n",
      "Epoch 21, Step: 890, Loss: 0.00277182599529624, Lr:0.0001\n",
      "Epoch 21, Step: 891, Loss: 0.031987518072128296, Lr:0.0001\n",
      "Epoch 21, Step: 892, Loss: 0.11292140930891037, Lr:0.0001\n",
      "Epoch 21, Step: 893, Loss: 0.1655241698026657, Lr:0.0001\n",
      "Epoch 21, Step: 894, Loss: 0.10226143896579742, Lr:0.0001\n",
      "Epoch 21, Step: 895, Loss: 0.00696696899831295, Lr:0.0001\n",
      "Epoch 21, Step: 896, Loss: 0.07679416239261627, Lr:0.0001\n",
      "Epoch 21, Step: 897, Loss: 0.4086027443408966, Lr:0.0001\n",
      "Epoch 21, Step: 898, Loss: 0.02330283261835575, Lr:0.0001\n",
      "Epoch 21, Step: 899, Loss: 0.08975960314273834, Lr:0.0001\n",
      "Epoch 21, Step: 900, Loss: 0.02533247321844101, Lr:0.0001\n",
      "Epoch 21, Step: 901, Loss: 0.037199582904577255, Lr:0.0001\n",
      "Epoch 21, Step: 902, Loss: 0.043790411204099655, Lr:0.0001\n",
      "Epoch 21, Step: 903, Loss: 0.19984716176986694, Lr:0.0001\n",
      "Epoch 21, Step: 904, Loss: 0.18280848860740662, Lr:0.0001\n",
      "Epoch 21, Step: 905, Loss: 0.05562656372785568, Lr:0.0001\n",
      "Epoch 21, Step: 906, Loss: 0.03693151846528053, Lr:0.0001\n",
      "Epoch 21, Step: 907, Loss: 0.027323966845870018, Lr:0.0001\n",
      "Epoch 21, Step: 908, Loss: 0.21261243522167206, Lr:0.0001\n",
      "Epoch 21, Step: 909, Loss: 0.04094628989696503, Lr:0.0001\n",
      "Epoch 21, Step: 910, Loss: 0.0732429251074791, Lr:0.0001\n",
      "Epoch 21, Step: 911, Loss: 0.0687422901391983, Lr:0.0001\n",
      "Epoch 21, Step: 912, Loss: 0.09962252527475357, Lr:0.0001\n",
      "Epoch 21, Step: 913, Loss: 0.018171580508351326, Lr:0.0001\n",
      "Epoch 21, Step: 914, Loss: 0.06931110471487045, Lr:0.0001\n",
      "Epoch 21, Step: 915, Loss: 0.13795877993106842, Lr:0.0001\n",
      "Epoch 21, Step: 916, Loss: 0.006853168364614248, Lr:0.0001\n",
      "Epoch 21, Step: 917, Loss: 0.011024195700883865, Lr:0.0001\n",
      "Epoch 21, Step: 918, Loss: 0.013185843825340271, Lr:0.0001\n",
      "Epoch 21, Step: 919, Loss: 0.022750258445739746, Lr:0.0001\n",
      "Epoch 21, Step: 920, Loss: 0.11523064225912094, Lr:0.0001\n",
      "Epoch 21, Step: 921, Loss: 0.15634870529174805, Lr:0.0001\n",
      "Epoch 21, Step: 922, Loss: 0.028314977884292603, Lr:0.0001\n",
      "Epoch 21, Step: 923, Loss: 0.10393780469894409, Lr:0.0001\n",
      "Epoch 21, Step: 924, Loss: 0.038129061460494995, Lr:0.0001\n",
      "Epoch 21, Step: 925, Loss: 0.059232197701931, Lr:0.0001\n",
      "Epoch 21, Step: 926, Loss: 0.10541753470897675, Lr:0.0001\n",
      "Epoch 21, Step: 927, Loss: 0.030106959864497185, Lr:0.0001\n",
      "Epoch 21, Step: 928, Loss: 0.02849314734339714, Lr:0.0001\n",
      "Epoch 21, Step: 929, Loss: 0.0033914088271558285, Lr:0.0001\n",
      "Epoch 21, Step: 930, Loss: 0.00694110756739974, Lr:0.0001\n",
      "Epoch 21, Step: 931, Loss: 0.05627773702144623, Lr:0.0001\n",
      "Epoch 21, Step: 932, Loss: 0.16716629266738892, Lr:0.0001\n",
      "Epoch 21, Step: 933, Loss: 0.0514974519610405, Lr:0.0001\n",
      "Epoch 21, Step: 934, Loss: 0.013913620263338089, Lr:0.0001\n",
      "Epoch 21, Step: 935, Loss: 0.05105471983551979, Lr:0.0001\n",
      "Epoch 21, Step: 936, Loss: 0.050012484192848206, Lr:0.0001\n",
      "Epoch 21, Step: 937, Loss: 0.0022176920901983976, Lr:0.0001\n",
      "Epoch 21, Step: 938, Loss: 0.05945413559675217, Lr:0.0001\n",
      "Epoch 21, Step: 939, Loss: 0.031700558960437775, Lr:0.0001\n",
      "Epoch 21, Step: 940, Loss: 0.27779847383499146, Lr:0.0001\n",
      "Epoch 21, Step: 941, Loss: 0.021138202399015427, Lr:0.0001\n",
      "Epoch 21, Step: 942, Loss: 0.12243874371051788, Lr:0.0001\n",
      "Epoch 21, Step: 943, Loss: 0.14153380692005157, Lr:0.0001\n",
      "Epoch 21, Step: 944, Loss: 0.008453955873847008, Lr:0.0001\n",
      "Epoch 21, Step: 945, Loss: 0.08350026607513428, Lr:0.0001\n",
      "Epoch 21, Step: 946, Loss: 0.12757013738155365, Lr:0.0001\n",
      "Epoch 21, Step: 947, Loss: 0.03415174037218094, Lr:0.0001\n",
      "Epoch 21, Step: 948, Loss: 0.05288989096879959, Lr:0.0001\n",
      "Epoch 21, Step: 949, Loss: 0.01472029834985733, Lr:0.0001\n",
      "Epoch 21, Step: 950, Loss: 0.19027164578437805, Lr:0.0001\n",
      "Epoch 21, Step: 951, Loss: 0.07567555457353592, Lr:0.0001\n",
      "Epoch 21, Step: 952, Loss: 0.08112350106239319, Lr:0.0001\n",
      "Epoch 21, Step: 953, Loss: 0.11087166517972946, Lr:0.0001\n",
      "Epoch 21, Step: 954, Loss: 0.2536782920360565, Lr:0.0001\n",
      "Epoch 21, Step: 955, Loss: 0.06561486423015594, Lr:0.0001\n",
      "Epoch 21, Step: 956, Loss: 0.009503294713795185, Lr:0.0001\n",
      "Epoch 21, Step: 957, Loss: 0.07058519870042801, Lr:0.0001\n",
      "Epoch 21, Step: 958, Loss: 0.02158813737332821, Lr:0.0001\n",
      "Epoch 21, Step: 959, Loss: 0.02250058576464653, Lr:0.0001\n",
      "Epoch 21, Step: 960, Loss: 0.07169990986585617, Lr:0.0001\n",
      "Epoch 21, Step: 961, Loss: 0.009445901960134506, Lr:0.0001\n",
      "Epoch 21, Step: 962, Loss: 0.0690462738275528, Lr:0.0001\n",
      "Epoch 21, Step: 963, Loss: 0.08428898453712463, Lr:0.0001\n",
      "Epoch 21, Step: 964, Loss: 0.014067144133150578, Lr:0.0001\n",
      "Epoch 21, Step: 965, Loss: 0.0403498150408268, Lr:0.0001\n",
      "Epoch 21, Step: 966, Loss: 0.23178255558013916, Lr:0.0001\n",
      "Epoch 21, Step: 967, Loss: 0.0044465092942118645, Lr:0.0001\n",
      "Epoch 21, Step: 968, Loss: 0.03037899360060692, Lr:0.0001\n",
      "Epoch 21, Step: 969, Loss: 0.11094021797180176, Lr:0.0001\n",
      "Epoch 21, Step: 970, Loss: 0.03200116008520126, Lr:0.0001\n",
      "Epoch 21, Step: 971, Loss: 0.044351473450660706, Lr:0.0001\n",
      "Epoch 21, Step: 972, Loss: 0.06365755200386047, Lr:0.0001\n",
      "Epoch 21, Step: 973, Loss: 0.06929370015859604, Lr:0.0001\n",
      "Epoch 21, Step: 974, Loss: 0.0753040686249733, Lr:0.0001\n",
      "Epoch 21, Step: 975, Loss: 0.16842053830623627, Lr:0.0001\n",
      "Epoch 21, Step: 976, Loss: 0.04341352730989456, Lr:0.0001\n",
      "Epoch 21, Step: 977, Loss: 0.1359434425830841, Lr:0.0001\n",
      "Epoch 21, Step: 978, Loss: 0.022825876250863075, Lr:0.0001\n",
      "Epoch 21, Step: 979, Loss: 0.05054950341582298, Lr:0.0001\n",
      "Epoch 21, Step: 980, Loss: 0.008815894834697247, Lr:0.0001\n",
      "Epoch 21, Step: 981, Loss: 0.07181312143802643, Lr:0.0001\n",
      "Epoch 21, Step: 982, Loss: 0.027286134660243988, Lr:0.0001\n",
      "Epoch 21, Step: 983, Loss: 0.22763918340206146, Lr:0.0001\n",
      "Epoch 21, Step: 984, Loss: 0.02116367593407631, Lr:0.0001\n",
      "Epoch 21, Step: 985, Loss: 0.024411719292402267, Lr:0.0001\n",
      "Epoch 21, Step: 986, Loss: 0.05075829476118088, Lr:0.0001\n",
      "Epoch 21, Step: 987, Loss: 0.2598189413547516, Lr:0.0001\n",
      "Epoch 21, Step: 988, Loss: 0.022119125351309776, Lr:0.0001\n",
      "Epoch 21, Step: 989, Loss: 0.11766756325960159, Lr:0.0001\n",
      "Epoch 21, Step: 990, Loss: 0.01277232263237238, Lr:0.0001\n",
      "Epoch 21, Step: 991, Loss: 0.03901941329240799, Lr:0.0001\n",
      "Epoch 21, Step: 992, Loss: 0.002885175868868828, Lr:0.0001\n",
      "Epoch 21, Step: 993, Loss: 0.27321842312812805, Lr:0.0001\n",
      "Epoch 21, Step: 994, Loss: 0.13717570900917053, Lr:0.0001\n",
      "Epoch 21, Step: 995, Loss: 0.00239850883372128, Lr:0.0001\n",
      "Epoch 21, Step: 996, Loss: 0.011246460489928722, Lr:0.0001\n",
      "Epoch 21, Step: 997, Loss: 0.02551504597067833, Lr:0.0001\n",
      "Epoch 21, Step: 998, Loss: 0.11715684831142426, Lr:0.0001\n",
      "Epoch 21, Step: 999, Loss: 0.015069705434143543, Lr:0.0001\n",
      "Epoch 21, Step: 1000, Loss: 0.012346997857093811, Lr:0.0001\n",
      "Epoch 21, Step: 1001, Loss: 0.004850558936595917, Lr:0.0001\n",
      "Epoch 21, Step: 1002, Loss: 0.018386365845799446, Lr:0.0001\n",
      "Epoch 21, Step: 1003, Loss: 0.004836739972233772, Lr:0.0001\n",
      "Epoch 21, Step: 1004, Loss: 0.043941058218479156, Lr:0.0001\n",
      "Epoch 21, Step: 1005, Loss: 0.0014020127709954977, Lr:0.0001\n",
      "Epoch 21, Step: 1006, Loss: 0.062120307236909866, Lr:0.0001\n",
      "Epoch 21, Step: 1007, Loss: 0.06826992332935333, Lr:0.0001\n",
      "Epoch 21, Step: 1008, Loss: 0.05073651298880577, Lr:0.0001\n",
      "Epoch 21, Step: 1009, Loss: 0.16377145051956177, Lr:0.0001\n",
      "Epoch 21, Step: 1010, Loss: 0.01862190291285515, Lr:0.0001\n",
      "Epoch 21, Step: 1011, Loss: 0.04325711354613304, Lr:0.0001\n",
      "Epoch 21, Step: 1012, Loss: 0.0008098591933958232, Lr:0.0001\n",
      "Epoch 21, Step: 1013, Loss: 0.20338915288448334, Lr:0.0001\n",
      "Epoch 21, Step: 1014, Loss: 0.04748809337615967, Lr:0.0001\n",
      "Epoch 21, Step: 1015, Loss: 0.10938360542058945, Lr:0.0001\n",
      "Epoch 21, Step: 1016, Loss: 0.007291051093488932, Lr:0.0001\n",
      "Epoch 21, Step: 1017, Loss: 0.025227323174476624, Lr:0.0001\n",
      "Epoch 21, Step: 1018, Loss: 0.09663214534521103, Lr:0.0001\n",
      "Epoch 21, Step: 1019, Loss: 0.16458703577518463, Lr:0.0001\n",
      "Epoch 21, Step: 1020, Loss: 0.0764707699418068, Lr:0.0001\n",
      "Epoch 21, Step: 1021, Loss: 0.019179992377758026, Lr:0.0001\n",
      "Epoch 21, Step: 1022, Loss: 0.02001778595149517, Lr:0.0001\n",
      "Epoch 21, Step: 1023, Loss: 0.04421309009194374, Lr:0.0001\n",
      "Epoch 21, Step: 1024, Loss: 0.03204219788312912, Lr:0.0001\n",
      "Epoch 21, Step: 1025, Loss: 0.009387687779963017, Lr:0.0001\n",
      "Epoch 21, Step: 1026, Loss: 0.05289468541741371, Lr:0.0001\n",
      "Epoch 21, Step: 1027, Loss: 0.1256439983844757, Lr:0.0001\n",
      "Epoch 21, Step: 1028, Loss: 0.0352654904127121, Lr:0.0001\n",
      "Epoch 21, Step: 1029, Loss: 0.07746081054210663, Lr:0.0001\n",
      "Epoch 21, Step: 1030, Loss: 0.1691821813583374, Lr:0.0001\n",
      "Epoch 21, Step: 1031, Loss: 0.003338468726724386, Lr:0.0001\n",
      "Epoch 21, Step: 1032, Loss: 0.11283446848392487, Lr:0.0001\n",
      "Epoch 21, Step: 1033, Loss: 0.01833989843726158, Lr:0.0001\n",
      "Epoch 21, Step: 1034, Loss: 0.0048783160746097565, Lr:0.0001\n",
      "Epoch 21, Step: 1035, Loss: 0.010521136224269867, Lr:0.0001\n",
      "Epoch 21, Step: 1036, Loss: 0.07238119095563889, Lr:0.0001\n",
      "Epoch 21, Step: 1037, Loss: 0.02707475796341896, Lr:0.0001\n",
      "Epoch 21, Step: 1038, Loss: 0.02359974943101406, Lr:0.0001\n",
      "Epoch 21, Step: 1039, Loss: 0.03514896333217621, Lr:0.0001\n",
      "Epoch 21, Step: 1040, Loss: 0.04300194978713989, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 21\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:18 loss: 0.5733 (0.5733) acc1: 87.5000 (87.5000) acc5: 100.0000 (100.0000) time: 0.3216 data: 0.1200 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:14 loss: 0.0005 (0.0594) acc1: 100.0000 (98.2955) acc5: 100.0000 (100.0000) time: 0.3048 data: 0.1222 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:11 loss: 0.0001 (0.0659) acc1: 100.0000 (98.2143) acc5: 100.0000 (100.0000) time: 0.3180 data: 0.1232 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:08 loss: 0.0595 (0.1481) acc1: 100.0000 (95.7661) acc5: 100.0000 (100.0000) time: 0.3232 data: 0.1213 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:05 loss: 0.2017 (0.1589) acc1: 93.7500 (95.2744) acc5: 100.0000 (100.0000) time: 0.3088 data: 0.1207 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0735 (0.1535) acc1: 93.7500 (94.6078) acc5: 100.0000 (100.0000) time: 0.3083 data: 0.1248 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0655 (0.1555) acc1: 93.7500 (94.6652) acc5: 100.0000 (100.0000) time: 0.2959 data: 0.1201 max mem: 15137\n",
      "Test: Total time: 0:00:17 (0.3082 s / it)\n",
      "* Acc@1 94.665 Acc@5 100.000 loss 0.155\n",
      "Accuracy of the network on the 881 test image: 94.7%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 22, Step: 0, Loss: 0.0935172289609909, Lr:0.0001\n",
      "Epoch 22, Step: 1, Loss: 0.057467807084321976, Lr:0.0001\n",
      "Epoch 22, Step: 2, Loss: 0.02178320661187172, Lr:0.0001\n",
      "Epoch 22, Step: 3, Loss: 0.007192550227046013, Lr:0.0001\n",
      "Epoch 22, Step: 4, Loss: 0.0326041653752327, Lr:0.0001\n",
      "Epoch 22, Step: 5, Loss: 0.07584782689809799, Lr:0.0001\n",
      "Epoch 22, Step: 6, Loss: 0.0009766530711203814, Lr:0.0001\n",
      "Epoch 22, Step: 7, Loss: 0.05434844642877579, Lr:0.0001\n",
      "Epoch 22, Step: 8, Loss: 0.008208554238080978, Lr:0.0001\n",
      "Epoch 22, Step: 9, Loss: 0.022596266120672226, Lr:0.0001\n",
      "Epoch 22, Step: 10, Loss: 0.05709049850702286, Lr:0.0001\n",
      "Epoch 22, Step: 11, Loss: 0.024371866136789322, Lr:0.0001\n",
      "Epoch 22, Step: 12, Loss: 0.061376217752695084, Lr:0.0001\n",
      "Epoch 22, Step: 13, Loss: 0.030788246542215347, Lr:0.0001\n",
      "Epoch 22, Step: 14, Loss: 0.008319269865751266, Lr:0.0001\n",
      "Epoch 22, Step: 15, Loss: 0.0006491953390650451, Lr:0.0001\n",
      "Epoch 22, Step: 16, Loss: 0.022684019058942795, Lr:0.0001\n",
      "Epoch 22, Step: 17, Loss: 0.0038523743860423565, Lr:0.0001\n",
      "Epoch 22, Step: 18, Loss: 0.0022303746081888676, Lr:0.0001\n",
      "Epoch 22, Step: 19, Loss: 0.09698648005723953, Lr:0.0001\n",
      "Epoch 22, Step: 20, Loss: 0.029771985486149788, Lr:0.0001\n",
      "Epoch 22, Step: 21, Loss: 0.0012843383010476828, Lr:0.0001\n",
      "Epoch 22, Step: 22, Loss: 0.0019093529554083943, Lr:0.0001\n",
      "Epoch 22, Step: 23, Loss: 0.03693230077624321, Lr:0.0001\n",
      "Epoch 22, Step: 24, Loss: 0.029788214713335037, Lr:0.0001\n",
      "Epoch 22, Step: 25, Loss: 0.09231186658143997, Lr:0.0001\n",
      "Epoch 22, Step: 26, Loss: 0.006735149305313826, Lr:0.0001\n",
      "Epoch 22, Step: 27, Loss: 0.041547663509845734, Lr:0.0001\n",
      "Epoch 22, Step: 28, Loss: 0.30308592319488525, Lr:0.0001\n",
      "Epoch 22, Step: 29, Loss: 0.0898347944021225, Lr:0.0001\n",
      "Epoch 22, Step: 30, Loss: 0.11211131513118744, Lr:0.0001\n",
      "Epoch 22, Step: 31, Loss: 0.002447203965857625, Lr:0.0001\n",
      "Epoch 22, Step: 32, Loss: 0.011137746274471283, Lr:0.0001\n",
      "Epoch 22, Step: 33, Loss: 0.04073512926697731, Lr:0.0001\n",
      "Epoch 22, Step: 34, Loss: 0.0027747296262532473, Lr:0.0001\n",
      "Epoch 22, Step: 35, Loss: 0.020467836409807205, Lr:0.0001\n",
      "Epoch 22, Step: 36, Loss: 0.04846304655075073, Lr:0.0001\n",
      "Epoch 22, Step: 37, Loss: 0.08117114752531052, Lr:0.0001\n",
      "Epoch 22, Step: 38, Loss: 0.001373660285025835, Lr:0.0001\n",
      "Epoch 22, Step: 39, Loss: 0.00860589649528265, Lr:0.0001\n",
      "Epoch 22, Step: 40, Loss: 0.11337985098361969, Lr:0.0001\n",
      "Epoch 22, Step: 41, Loss: 0.00649508461356163, Lr:0.0001\n",
      "Epoch 22, Step: 42, Loss: 0.0058193751610815525, Lr:0.0001\n",
      "Epoch 22, Step: 43, Loss: 0.19142599403858185, Lr:0.0001\n",
      "Epoch 22, Step: 44, Loss: 0.22353793680667877, Lr:0.0001\n",
      "Epoch 22, Step: 45, Loss: 0.02295982651412487, Lr:0.0001\n",
      "Epoch 22, Step: 46, Loss: 0.07588799297809601, Lr:0.0001\n",
      "Epoch 22, Step: 47, Loss: 0.01892874948680401, Lr:0.0001\n",
      "Epoch 22, Step: 48, Loss: 0.0008109754417091608, Lr:0.0001\n",
      "Epoch 22, Step: 49, Loss: 0.07585551589727402, Lr:0.0001\n",
      "Epoch 22, Step: 50, Loss: 0.052485350519418716, Lr:0.0001\n",
      "Epoch 22, Step: 51, Loss: 0.03362254798412323, Lr:0.0001\n",
      "Epoch 22, Step: 52, Loss: 0.06831832230091095, Lr:0.0001\n",
      "Epoch 22, Step: 53, Loss: 0.050760090351104736, Lr:0.0001\n",
      "Epoch 22, Step: 54, Loss: 0.2033461332321167, Lr:0.0001\n",
      "Epoch 22, Step: 55, Loss: 0.11055345833301544, Lr:0.0001\n",
      "Epoch 22, Step: 56, Loss: 0.33078834414482117, Lr:0.0001\n",
      "Epoch 22, Step: 57, Loss: 0.3639499545097351, Lr:0.0001\n",
      "Epoch 22, Step: 58, Loss: 0.0010462565114721656, Lr:0.0001\n",
      "Epoch 22, Step: 59, Loss: 0.03691873699426651, Lr:0.0001\n",
      "Epoch 22, Step: 60, Loss: 0.03279104456305504, Lr:0.0001\n",
      "Epoch 22, Step: 61, Loss: 0.09915055334568024, Lr:0.0001\n",
      "Epoch 22, Step: 62, Loss: 0.017423801124095917, Lr:0.0001\n",
      "Epoch 22, Step: 63, Loss: 0.12376921623945236, Lr:0.0001\n",
      "Epoch 22, Step: 64, Loss: 0.018815606832504272, Lr:0.0001\n",
      "Epoch 22, Step: 65, Loss: 0.047624338418245316, Lr:0.0001\n",
      "Epoch 22, Step: 66, Loss: 0.058620091527700424, Lr:0.0001\n",
      "Epoch 22, Step: 67, Loss: 0.08196347206830978, Lr:0.0001\n",
      "Epoch 22, Step: 68, Loss: 0.19893775880336761, Lr:0.0001\n",
      "Epoch 22, Step: 69, Loss: 0.04163423925638199, Lr:0.0001\n",
      "Epoch 22, Step: 70, Loss: 0.34537234902381897, Lr:0.0001\n",
      "Epoch 22, Step: 71, Loss: 0.037212468683719635, Lr:0.0001\n",
      "Epoch 22, Step: 72, Loss: 0.03744998574256897, Lr:0.0001\n",
      "Epoch 22, Step: 73, Loss: 0.02609844319522381, Lr:0.0001\n",
      "Epoch 22, Step: 74, Loss: 0.0056011569686234, Lr:0.0001\n",
      "Epoch 22, Step: 75, Loss: 0.042861051857471466, Lr:0.0001\n",
      "Epoch 22, Step: 76, Loss: 0.017446838319301605, Lr:0.0001\n",
      "Epoch 22, Step: 77, Loss: 0.06361249834299088, Lr:0.0001\n",
      "Epoch 22, Step: 78, Loss: 0.005134545266628265, Lr:0.0001\n",
      "Epoch 22, Step: 79, Loss: 0.07257447391748428, Lr:0.0001\n",
      "Epoch 22, Step: 80, Loss: 0.012506088241934776, Lr:0.0001\n",
      "Epoch 22, Step: 81, Loss: 0.15128007531166077, Lr:0.0001\n",
      "Epoch 22, Step: 82, Loss: 0.09226497262716293, Lr:0.0001\n",
      "Epoch 22, Step: 83, Loss: 0.09134707599878311, Lr:0.0001\n",
      "Epoch 22, Step: 84, Loss: 0.03085685335099697, Lr:0.0001\n",
      "Epoch 22, Step: 85, Loss: 0.17948850989341736, Lr:0.0001\n",
      "Epoch 22, Step: 86, Loss: 0.11193473637104034, Lr:0.0001\n",
      "Epoch 22, Step: 87, Loss: 0.16835956275463104, Lr:0.0001\n",
      "Epoch 22, Step: 88, Loss: 0.25803059339523315, Lr:0.0001\n",
      "Epoch 22, Step: 89, Loss: 0.009681444615125656, Lr:0.0001\n",
      "Epoch 22, Step: 90, Loss: 0.013787249103188515, Lr:0.0001\n",
      "Epoch 22, Step: 91, Loss: 0.01713387481868267, Lr:0.0001\n",
      "Epoch 22, Step: 92, Loss: 0.04890101030468941, Lr:0.0001\n",
      "Epoch 22, Step: 93, Loss: 0.02086825482547283, Lr:0.0001\n",
      "Epoch 22, Step: 94, Loss: 0.009055014699697495, Lr:0.0001\n",
      "Epoch 22, Step: 95, Loss: 0.20660452544689178, Lr:0.0001\n",
      "Epoch 22, Step: 96, Loss: 0.015044528059661388, Lr:0.0001\n",
      "Epoch 22, Step: 97, Loss: 0.10255202651023865, Lr:0.0001\n",
      "Epoch 22, Step: 98, Loss: 0.08703271299600601, Lr:0.0001\n",
      "Epoch 22, Step: 99, Loss: 0.025269364938139915, Lr:0.0001\n",
      "Epoch 22, Step: 100, Loss: 0.038364388048648834, Lr:0.0001\n",
      "Epoch 22, Step: 101, Loss: 0.0912180170416832, Lr:0.0001\n",
      "Epoch 22, Step: 102, Loss: 0.041837625205516815, Lr:0.0001\n",
      "Epoch 22, Step: 103, Loss: 0.11451134830713272, Lr:0.0001\n",
      "Epoch 22, Step: 104, Loss: 0.11495109647512436, Lr:0.0001\n",
      "Epoch 22, Step: 105, Loss: 0.010605613701045513, Lr:0.0001\n",
      "Epoch 22, Step: 106, Loss: 0.06268935650587082, Lr:0.0001\n",
      "Epoch 22, Step: 107, Loss: 0.2868909239768982, Lr:0.0001\n",
      "Epoch 22, Step: 108, Loss: 0.03096349537372589, Lr:0.0001\n",
      "Epoch 22, Step: 109, Loss: 0.024961164221167564, Lr:0.0001\n",
      "Epoch 22, Step: 110, Loss: 0.11391807347536087, Lr:0.0001\n",
      "Epoch 22, Step: 111, Loss: 0.11186490207910538, Lr:0.0001\n",
      "Epoch 22, Step: 112, Loss: 0.04507528617978096, Lr:0.0001\n",
      "Epoch 22, Step: 113, Loss: 0.17107796669006348, Lr:0.0001\n",
      "Epoch 22, Step: 114, Loss: 0.062336232513189316, Lr:0.0001\n",
      "Epoch 22, Step: 115, Loss: 0.0242775809019804, Lr:0.0001\n",
      "Epoch 22, Step: 116, Loss: 0.03663729876279831, Lr:0.0001\n",
      "Epoch 22, Step: 117, Loss: 0.3598637580871582, Lr:0.0001\n",
      "Epoch 22, Step: 118, Loss: 0.30106884241104126, Lr:0.0001\n",
      "Epoch 22, Step: 119, Loss: 0.021786311641335487, Lr:0.0001\n",
      "Epoch 22, Step: 120, Loss: 0.009343154728412628, Lr:0.0001\n",
      "Epoch 22, Step: 121, Loss: 0.15005245804786682, Lr:0.0001\n",
      "Epoch 22, Step: 122, Loss: 0.1476454734802246, Lr:0.0001\n",
      "Epoch 22, Step: 123, Loss: 0.008162316866219044, Lr:0.0001\n",
      "Epoch 22, Step: 124, Loss: 0.05397289991378784, Lr:0.0001\n",
      "Epoch 22, Step: 125, Loss: 0.015057310461997986, Lr:0.0001\n",
      "Epoch 22, Step: 126, Loss: 0.06610986590385437, Lr:0.0001\n",
      "Epoch 22, Step: 127, Loss: 0.4537705183029175, Lr:0.0001\n",
      "Epoch 22, Step: 128, Loss: 0.08690857887268066, Lr:0.0001\n",
      "Epoch 22, Step: 129, Loss: 0.07665885984897614, Lr:0.0001\n",
      "Epoch 22, Step: 130, Loss: 0.00984121672809124, Lr:0.0001\n",
      "Epoch 22, Step: 131, Loss: 0.3593619763851166, Lr:0.0001\n",
      "Epoch 22, Step: 132, Loss: 0.008771521039307117, Lr:0.0001\n",
      "Epoch 22, Step: 133, Loss: 0.004624372348189354, Lr:0.0001\n",
      "Epoch 22, Step: 134, Loss: 0.21766158938407898, Lr:0.0001\n",
      "Epoch 22, Step: 135, Loss: 0.010760840959846973, Lr:0.0001\n",
      "Epoch 22, Step: 136, Loss: 0.07084523886442184, Lr:0.0001\n",
      "Epoch 22, Step: 137, Loss: 0.14366599917411804, Lr:0.0001\n",
      "Epoch 22, Step: 138, Loss: 0.025024253875017166, Lr:0.0001\n",
      "Epoch 22, Step: 139, Loss: 0.08137817680835724, Lr:0.0001\n",
      "Epoch 22, Step: 140, Loss: 0.008485483005642891, Lr:0.0001\n",
      "Epoch 22, Step: 141, Loss: 0.004532061982899904, Lr:0.0001\n",
      "Epoch 22, Step: 142, Loss: 0.25404348969459534, Lr:0.0001\n",
      "Epoch 22, Step: 143, Loss: 0.006236468907445669, Lr:0.0001\n",
      "Epoch 22, Step: 144, Loss: 0.02911342680454254, Lr:0.0001\n",
      "Epoch 22, Step: 145, Loss: 0.0030579210724681616, Lr:0.0001\n",
      "Epoch 22, Step: 146, Loss: 0.10553218424320221, Lr:0.0001\n",
      "Epoch 22, Step: 147, Loss: 0.023216500878334045, Lr:0.0001\n",
      "Epoch 22, Step: 148, Loss: 0.039076853543519974, Lr:0.0001\n",
      "Epoch 22, Step: 149, Loss: 0.006040776614099741, Lr:0.0001\n",
      "Epoch 22, Step: 150, Loss: 0.011563192121684551, Lr:0.0001\n",
      "Epoch 22, Step: 151, Loss: 0.015094497241079807, Lr:0.0001\n",
      "Epoch 22, Step: 152, Loss: 0.028569284826517105, Lr:0.0001\n",
      "Epoch 22, Step: 153, Loss: 0.026049379259347916, Lr:0.0001\n",
      "Epoch 22, Step: 154, Loss: 0.03576987609267235, Lr:0.0001\n",
      "Epoch 22, Step: 155, Loss: 0.03514520078897476, Lr:0.0001\n",
      "Epoch 22, Step: 156, Loss: 0.006620458327233791, Lr:0.0001\n",
      "Epoch 22, Step: 157, Loss: 0.0888461321592331, Lr:0.0001\n",
      "Epoch 22, Step: 158, Loss: 0.005014065653085709, Lr:0.0001\n",
      "Epoch 22, Step: 159, Loss: 0.012113369069993496, Lr:0.0001\n",
      "Epoch 22, Step: 160, Loss: 0.2761419117450714, Lr:0.0001\n",
      "Epoch 22, Step: 161, Loss: 0.015944072976708412, Lr:0.0001\n",
      "Epoch 22, Step: 162, Loss: 0.0499730110168457, Lr:0.0001\n",
      "Epoch 22, Step: 163, Loss: 0.15947343409061432, Lr:0.0001\n",
      "Epoch 22, Step: 164, Loss: 0.10230939835309982, Lr:0.0001\n",
      "Epoch 22, Step: 165, Loss: 0.010716574266552925, Lr:0.0001\n",
      "Epoch 22, Step: 166, Loss: 0.007964970543980598, Lr:0.0001\n",
      "Epoch 22, Step: 167, Loss: 0.013710014522075653, Lr:0.0001\n",
      "Epoch 22, Step: 168, Loss: 0.084066241979599, Lr:0.0001\n",
      "Epoch 22, Step: 169, Loss: 0.04192338138818741, Lr:0.0001\n",
      "Epoch 22, Step: 170, Loss: 0.020362067967653275, Lr:0.0001\n",
      "Epoch 22, Step: 171, Loss: 0.18214964866638184, Lr:0.0001\n",
      "Epoch 22, Step: 172, Loss: 0.0165657140314579, Lr:0.0001\n",
      "Epoch 22, Step: 173, Loss: 0.01783658191561699, Lr:0.0001\n",
      "Epoch 22, Step: 174, Loss: 0.011477803811430931, Lr:0.0001\n",
      "Epoch 22, Step: 175, Loss: 0.07288065552711487, Lr:0.0001\n",
      "Epoch 22, Step: 176, Loss: 0.05763188377022743, Lr:0.0001\n",
      "Epoch 22, Step: 177, Loss: 0.028435388579964638, Lr:0.0001\n",
      "Epoch 22, Step: 178, Loss: 0.014336028136312962, Lr:0.0001\n",
      "Epoch 22, Step: 179, Loss: 0.11695358157157898, Lr:0.0001\n",
      "Epoch 22, Step: 180, Loss: 0.050644200295209885, Lr:0.0001\n",
      "Epoch 22, Step: 181, Loss: 0.2227339744567871, Lr:0.0001\n",
      "Epoch 22, Step: 182, Loss: 0.11821504682302475, Lr:0.0001\n",
      "Epoch 22, Step: 183, Loss: 0.12509289383888245, Lr:0.0001\n",
      "Epoch 22, Step: 184, Loss: 0.12615364789962769, Lr:0.0001\n",
      "Epoch 22, Step: 185, Loss: 0.005470162723213434, Lr:0.0001\n",
      "Epoch 22, Step: 186, Loss: 0.00670845340937376, Lr:0.0001\n",
      "Epoch 22, Step: 187, Loss: 0.008879169821739197, Lr:0.0001\n",
      "Epoch 22, Step: 188, Loss: 0.006957496050745249, Lr:0.0001\n",
      "Epoch 22, Step: 189, Loss: 0.0016920482739806175, Lr:0.0001\n",
      "Epoch 22, Step: 190, Loss: 0.14797808229923248, Lr:0.0001\n",
      "Epoch 22, Step: 191, Loss: 0.00757156778126955, Lr:0.0001\n",
      "Epoch 22, Step: 192, Loss: 0.09989698231220245, Lr:0.0001\n",
      "Epoch 22, Step: 193, Loss: 0.20452602207660675, Lr:0.0001\n",
      "Epoch 22, Step: 194, Loss: 0.008865769021213055, Lr:0.0001\n",
      "Epoch 22, Step: 195, Loss: 0.015471038408577442, Lr:0.0001\n",
      "Epoch 22, Step: 196, Loss: 0.057385288178920746, Lr:0.0001\n",
      "Epoch 22, Step: 197, Loss: 0.04104405641555786, Lr:0.0001\n",
      "Epoch 22, Step: 198, Loss: 0.3767379820346832, Lr:0.0001\n",
      "Epoch 22, Step: 199, Loss: 0.005255718715488911, Lr:0.0001\n",
      "Epoch 22, Step: 200, Loss: 0.006147355772554874, Lr:0.0001\n",
      "Epoch 22, Step: 201, Loss: 0.07780276983976364, Lr:0.0001\n",
      "Epoch 22, Step: 202, Loss: 0.03090132400393486, Lr:0.0001\n",
      "Epoch 22, Step: 203, Loss: 0.0043419585563242435, Lr:0.0001\n",
      "Epoch 22, Step: 204, Loss: 0.013264038600027561, Lr:0.0001\n",
      "Epoch 22, Step: 205, Loss: 0.006222534459084272, Lr:0.0001\n",
      "Epoch 22, Step: 206, Loss: 0.2232751101255417, Lr:0.0001\n",
      "Epoch 22, Step: 207, Loss: 0.03016088902950287, Lr:0.0001\n",
      "Epoch 22, Step: 208, Loss: 0.009693343192338943, Lr:0.0001\n",
      "Epoch 22, Step: 209, Loss: 0.23876619338989258, Lr:0.0001\n",
      "Epoch 22, Step: 210, Loss: 0.055034324526786804, Lr:0.0001\n",
      "Epoch 22, Step: 211, Loss: 0.1070178970694542, Lr:0.0001\n",
      "Epoch 22, Step: 212, Loss: 0.005377631168812513, Lr:0.0001\n",
      "Epoch 22, Step: 213, Loss: 0.012827220372855663, Lr:0.0001\n",
      "Epoch 22, Step: 214, Loss: 0.09393668174743652, Lr:0.0001\n",
      "Epoch 22, Step: 215, Loss: 0.0020810209680348635, Lr:0.0001\n",
      "Epoch 22, Step: 216, Loss: 0.21996906399726868, Lr:0.0001\n",
      "Epoch 22, Step: 217, Loss: 0.10742679983377457, Lr:0.0001\n",
      "Epoch 22, Step: 218, Loss: 0.004040977917611599, Lr:0.0001\n",
      "Epoch 22, Step: 219, Loss: 0.032679133117198944, Lr:0.0001\n",
      "Epoch 22, Step: 220, Loss: 0.051065899431705475, Lr:0.0001\n",
      "Epoch 22, Step: 221, Loss: 0.08994446694850922, Lr:0.0001\n",
      "Epoch 22, Step: 222, Loss: 0.015784109011292458, Lr:0.0001\n",
      "Epoch 22, Step: 223, Loss: 0.0776103138923645, Lr:0.0001\n",
      "Epoch 22, Step: 224, Loss: 0.08137793838977814, Lr:0.0001\n",
      "Epoch 22, Step: 225, Loss: 0.034760236740112305, Lr:0.0001\n",
      "Epoch 22, Step: 226, Loss: 0.06789576262235641, Lr:0.0001\n",
      "Epoch 22, Step: 227, Loss: 0.08791707456111908, Lr:0.0001\n",
      "Epoch 22, Step: 228, Loss: 0.18764305114746094, Lr:0.0001\n",
      "Epoch 22, Step: 229, Loss: 0.09016699343919754, Lr:0.0001\n",
      "Epoch 22, Step: 230, Loss: 0.005393875762820244, Lr:0.0001\n",
      "Epoch 22, Step: 231, Loss: 0.09209631383419037, Lr:0.0001\n",
      "Epoch 22, Step: 232, Loss: 0.12815110385417938, Lr:0.0001\n",
      "Epoch 22, Step: 233, Loss: 0.011635808274149895, Lr:0.0001\n",
      "Epoch 22, Step: 234, Loss: 0.0011870686430484056, Lr:0.0001\n",
      "Epoch 22, Step: 235, Loss: 0.01133100874722004, Lr:0.0001\n",
      "Epoch 22, Step: 236, Loss: 0.05610533803701401, Lr:0.0001\n",
      "Epoch 22, Step: 237, Loss: 0.011434619314968586, Lr:0.0001\n",
      "Epoch 22, Step: 238, Loss: 0.002050049602985382, Lr:0.0001\n",
      "Epoch 22, Step: 239, Loss: 0.04953855648636818, Lr:0.0001\n",
      "Epoch 22, Step: 240, Loss: 0.13828027248382568, Lr:0.0001\n",
      "Epoch 22, Step: 241, Loss: 0.008231104351580143, Lr:0.0001\n",
      "Epoch 22, Step: 242, Loss: 0.04987300932407379, Lr:0.0001\n",
      "Epoch 22, Step: 243, Loss: 0.009847264736890793, Lr:0.0001\n",
      "Epoch 22, Step: 244, Loss: 0.04917405545711517, Lr:0.0001\n",
      "Epoch 22, Step: 245, Loss: 0.035834088921546936, Lr:0.0001\n",
      "Epoch 22, Step: 246, Loss: 0.0420069694519043, Lr:0.0001\n",
      "Epoch 22, Step: 247, Loss: 0.06862646341323853, Lr:0.0001\n",
      "Epoch 22, Step: 248, Loss: 0.02262403629720211, Lr:0.0001\n",
      "Epoch 22, Step: 249, Loss: 0.24783170223236084, Lr:0.0001\n",
      "Epoch 22, Step: 250, Loss: 0.029416849836707115, Lr:0.0001\n",
      "Epoch 22, Step: 251, Loss: 0.12062256038188934, Lr:0.0001\n",
      "Epoch 22, Step: 252, Loss: 0.01763373799622059, Lr:0.0001\n",
      "Epoch 22, Step: 253, Loss: 0.012387096881866455, Lr:0.0001\n",
      "Epoch 22, Step: 254, Loss: 0.11194265633821487, Lr:0.0001\n",
      "Epoch 22, Step: 255, Loss: 0.010598943568766117, Lr:0.0001\n",
      "Epoch 22, Step: 256, Loss: 0.06231505051255226, Lr:0.0001\n",
      "Epoch 22, Step: 257, Loss: 0.01744297705590725, Lr:0.0001\n",
      "Epoch 22, Step: 258, Loss: 0.011140504851937294, Lr:0.0001\n",
      "Epoch 22, Step: 259, Loss: 0.013869372196495533, Lr:0.0001\n",
      "Epoch 22, Step: 260, Loss: 0.058136872947216034, Lr:0.0001\n",
      "Epoch 22, Step: 261, Loss: 0.03548811748623848, Lr:0.0001\n",
      "Epoch 22, Step: 262, Loss: 0.01056548859924078, Lr:0.0001\n",
      "Epoch 22, Step: 263, Loss: 0.051242586225271225, Lr:0.0001\n",
      "Epoch 22, Step: 264, Loss: 0.07523445785045624, Lr:0.0001\n",
      "Epoch 22, Step: 265, Loss: 0.019048115238547325, Lr:0.0001\n",
      "Epoch 22, Step: 266, Loss: 0.07863731682300568, Lr:0.0001\n",
      "Epoch 22, Step: 267, Loss: 0.0062223090790212154, Lr:0.0001\n",
      "Epoch 22, Step: 268, Loss: 0.018433183431625366, Lr:0.0001\n",
      "Epoch 22, Step: 269, Loss: 0.1458384245634079, Lr:0.0001\n",
      "Epoch 22, Step: 270, Loss: 0.005102678667753935, Lr:0.0001\n",
      "Epoch 22, Step: 271, Loss: 0.09770293533802032, Lr:0.0001\n",
      "Epoch 22, Step: 272, Loss: 0.18708990514278412, Lr:0.0001\n",
      "Epoch 22, Step: 273, Loss: 0.07754240930080414, Lr:0.0001\n",
      "Epoch 22, Step: 274, Loss: 0.06661293655633926, Lr:0.0001\n",
      "Epoch 22, Step: 275, Loss: 0.06792980432510376, Lr:0.0001\n",
      "Epoch 22, Step: 276, Loss: 0.012279290705919266, Lr:0.0001\n",
      "Epoch 22, Step: 277, Loss: 0.042772505432367325, Lr:0.0001\n",
      "Epoch 22, Step: 278, Loss: 0.017371665686368942, Lr:0.0001\n",
      "Epoch 22, Step: 279, Loss: 0.13163471221923828, Lr:0.0001\n",
      "Epoch 22, Step: 280, Loss: 0.0017201929586008191, Lr:0.0001\n",
      "Epoch 22, Step: 281, Loss: 0.009935294277966022, Lr:0.0001\n",
      "Epoch 22, Step: 282, Loss: 0.009907077997922897, Lr:0.0001\n",
      "Epoch 22, Step: 283, Loss: 0.004796016030013561, Lr:0.0001\n",
      "Epoch 22, Step: 284, Loss: 0.008324088528752327, Lr:0.0001\n",
      "Epoch 22, Step: 285, Loss: 0.00105233711656183, Lr:0.0001\n",
      "Epoch 22, Step: 286, Loss: 0.10551782697439194, Lr:0.0001\n",
      "Epoch 22, Step: 287, Loss: 0.002826286479830742, Lr:0.0001\n",
      "Epoch 22, Step: 288, Loss: 0.008547116070985794, Lr:0.0001\n",
      "Epoch 22, Step: 289, Loss: 0.09076857566833496, Lr:0.0001\n",
      "Epoch 22, Step: 290, Loss: 0.012315449304878712, Lr:0.0001\n",
      "Epoch 22, Step: 291, Loss: 0.009653886780142784, Lr:0.0001\n",
      "Epoch 22, Step: 292, Loss: 0.028273705393075943, Lr:0.0001\n",
      "Epoch 22, Step: 293, Loss: 0.0033605170901864767, Lr:0.0001\n",
      "Epoch 22, Step: 294, Loss: 0.004179266281425953, Lr:0.0001\n",
      "Epoch 22, Step: 295, Loss: 0.10056902468204498, Lr:0.0001\n",
      "Epoch 22, Step: 296, Loss: 0.015191732905805111, Lr:0.0001\n",
      "Epoch 22, Step: 297, Loss: 0.012409151531755924, Lr:0.0001\n",
      "Epoch 22, Step: 298, Loss: 0.18451270461082458, Lr:0.0001\n",
      "Epoch 22, Step: 299, Loss: 0.15443027019500732, Lr:0.0001\n",
      "Epoch 22, Step: 300, Loss: 0.005224101711064577, Lr:0.0001\n",
      "Epoch 22, Step: 301, Loss: 0.006544059608131647, Lr:0.0001\n",
      "Epoch 22, Step: 302, Loss: 0.001520846737548709, Lr:0.0001\n",
      "Epoch 22, Step: 303, Loss: 0.06617027521133423, Lr:0.0001\n",
      "Epoch 22, Step: 304, Loss: 0.008769797161221504, Lr:0.0001\n",
      "Epoch 22, Step: 305, Loss: 0.06717799603939056, Lr:0.0001\n",
      "Epoch 22, Step: 306, Loss: 0.009524033404886723, Lr:0.0001\n",
      "Epoch 22, Step: 307, Loss: 0.15654364228248596, Lr:0.0001\n",
      "Epoch 22, Step: 308, Loss: 0.04239187017083168, Lr:0.0001\n",
      "Epoch 22, Step: 309, Loss: 0.09154810756444931, Lr:0.0001\n",
      "Epoch 22, Step: 310, Loss: 0.14898623526096344, Lr:0.0001\n",
      "Epoch 22, Step: 311, Loss: 0.049755800515413284, Lr:0.0001\n",
      "Epoch 22, Step: 312, Loss: 0.02837873436510563, Lr:0.0001\n",
      "Epoch 22, Step: 313, Loss: 0.002648384775966406, Lr:0.0001\n",
      "Epoch 22, Step: 314, Loss: 0.015719003975391388, Lr:0.0001\n",
      "Epoch 22, Step: 315, Loss: 0.08025969564914703, Lr:0.0001\n",
      "Epoch 22, Step: 316, Loss: 0.39217156171798706, Lr:0.0001\n",
      "Epoch 22, Step: 317, Loss: 0.012245549820363522, Lr:0.0001\n",
      "Epoch 22, Step: 318, Loss: 0.20371027290821075, Lr:0.0001\n",
      "Epoch 22, Step: 319, Loss: 0.05296847224235535, Lr:0.0001\n",
      "Epoch 22, Step: 320, Loss: 0.01499202474951744, Lr:0.0001\n",
      "Epoch 22, Step: 321, Loss: 0.018338901922106743, Lr:0.0001\n",
      "Epoch 22, Step: 322, Loss: 0.04677656292915344, Lr:0.0001\n",
      "Epoch 22, Step: 323, Loss: 0.02924109622836113, Lr:0.0001\n",
      "Epoch 22, Step: 324, Loss: 0.02579093724489212, Lr:0.0001\n",
      "Epoch 22, Step: 325, Loss: 0.003879351308569312, Lr:0.0001\n",
      "Epoch 22, Step: 326, Loss: 0.5550355911254883, Lr:0.0001\n",
      "Epoch 22, Step: 327, Loss: 0.02364564873278141, Lr:0.0001\n",
      "Epoch 22, Step: 328, Loss: 0.12460537999868393, Lr:0.0001\n",
      "Epoch 22, Step: 329, Loss: 0.2153153121471405, Lr:0.0001\n",
      "Epoch 22, Step: 330, Loss: 0.012231665663421154, Lr:0.0001\n",
      "Epoch 22, Step: 331, Loss: 0.018703443929553032, Lr:0.0001\n",
      "Epoch 22, Step: 332, Loss: 0.036950238049030304, Lr:0.0001\n",
      "Epoch 22, Step: 333, Loss: 0.12125566601753235, Lr:0.0001\n",
      "Epoch 22, Step: 334, Loss: 0.020092589780688286, Lr:0.0001\n",
      "Epoch 22, Step: 335, Loss: 0.03183072432875633, Lr:0.0001\n",
      "Epoch 22, Step: 336, Loss: 0.08017108589410782, Lr:0.0001\n",
      "Epoch 22, Step: 337, Loss: 0.16505244374275208, Lr:0.0001\n",
      "Epoch 22, Step: 338, Loss: 0.12234293669462204, Lr:0.0001\n",
      "Epoch 22, Step: 339, Loss: 0.08923159539699554, Lr:0.0001\n",
      "Epoch 22, Step: 340, Loss: 0.08649537712335587, Lr:0.0001\n",
      "Epoch 22, Step: 341, Loss: 0.07983332872390747, Lr:0.0001\n",
      "Epoch 22, Step: 342, Loss: 0.02651328779757023, Lr:0.0001\n",
      "Epoch 22, Step: 343, Loss: 0.09702834486961365, Lr:0.0001\n",
      "Epoch 22, Step: 344, Loss: 0.010540020652115345, Lr:0.0001\n",
      "Epoch 22, Step: 345, Loss: 0.18885137140750885, Lr:0.0001\n",
      "Epoch 22, Step: 346, Loss: 0.10184229165315628, Lr:0.0001\n",
      "Epoch 22, Step: 347, Loss: 0.0005905393627472222, Lr:0.0001\n",
      "Epoch 22, Step: 348, Loss: 0.00628115888684988, Lr:0.0001\n",
      "Epoch 22, Step: 349, Loss: 0.008761027827858925, Lr:0.0001\n",
      "Epoch 22, Step: 350, Loss: 0.049118317663669586, Lr:0.0001\n",
      "Epoch 22, Step: 351, Loss: 0.23973044753074646, Lr:0.0001\n",
      "Epoch 22, Step: 352, Loss: 0.3931695222854614, Lr:0.0001\n",
      "Epoch 22, Step: 353, Loss: 0.06210660934448242, Lr:0.0001\n",
      "Epoch 22, Step: 354, Loss: 0.17789755761623383, Lr:0.0001\n",
      "Epoch 22, Step: 355, Loss: 0.20437105000019073, Lr:0.0001\n",
      "Epoch 22, Step: 356, Loss: 0.01532496977597475, Lr:0.0001\n",
      "Epoch 22, Step: 357, Loss: 0.002047713613137603, Lr:0.0001\n",
      "Epoch 22, Step: 358, Loss: 0.09893224388360977, Lr:0.0001\n",
      "Epoch 22, Step: 359, Loss: 0.03126407042145729, Lr:0.0001\n",
      "Epoch 22, Step: 360, Loss: 0.21667955815792084, Lr:0.0001\n",
      "Epoch 22, Step: 361, Loss: 0.13099513947963715, Lr:0.0001\n",
      "Epoch 22, Step: 362, Loss: 0.5816188454627991, Lr:0.0001\n",
      "Epoch 22, Step: 363, Loss: 0.03206658363342285, Lr:0.0001\n",
      "Epoch 22, Step: 364, Loss: 0.030946942046284676, Lr:0.0001\n",
      "Epoch 22, Step: 365, Loss: 0.00413073506206274, Lr:0.0001\n",
      "Epoch 22, Step: 366, Loss: 0.029508288949728012, Lr:0.0001\n",
      "Epoch 22, Step: 367, Loss: 0.009557734243571758, Lr:0.0001\n",
      "Epoch 22, Step: 368, Loss: 0.010263619013130665, Lr:0.0001\n",
      "Epoch 22, Step: 369, Loss: 0.0987718254327774, Lr:0.0001\n",
      "Epoch 22, Step: 370, Loss: 0.12831903994083405, Lr:0.0001\n",
      "Epoch 22, Step: 371, Loss: 0.02734210714697838, Lr:0.0001\n",
      "Epoch 22, Step: 372, Loss: 0.2632380723953247, Lr:0.0001\n",
      "Epoch 22, Step: 373, Loss: 0.00919406022876501, Lr:0.0001\n",
      "Epoch 22, Step: 374, Loss: 0.18287886679172516, Lr:0.0001\n",
      "Epoch 22, Step: 375, Loss: 0.029502682387828827, Lr:0.0001\n",
      "Epoch 22, Step: 376, Loss: 0.08411846309900284, Lr:0.0001\n",
      "Epoch 22, Step: 377, Loss: 0.10129059106111526, Lr:0.0001\n",
      "Epoch 22, Step: 378, Loss: 0.09836868941783905, Lr:0.0001\n",
      "Epoch 22, Step: 379, Loss: 0.07987547665834427, Lr:0.0001\n",
      "Epoch 22, Step: 380, Loss: 0.060875847935676575, Lr:0.0001\n",
      "Epoch 22, Step: 381, Loss: 0.05497799813747406, Lr:0.0001\n",
      "Epoch 22, Step: 382, Loss: 0.23289158940315247, Lr:0.0001\n",
      "Epoch 22, Step: 383, Loss: 0.07470192015171051, Lr:0.0001\n",
      "Epoch 22, Step: 384, Loss: 0.024196146056056023, Lr:0.0001\n",
      "Epoch 22, Step: 385, Loss: 0.17624810338020325, Lr:0.0001\n",
      "Epoch 22, Step: 386, Loss: 0.039552636444568634, Lr:0.0001\n",
      "Epoch 22, Step: 387, Loss: 0.21122723817825317, Lr:0.0001\n",
      "Epoch 22, Step: 388, Loss: 0.018931377679109573, Lr:0.0001\n",
      "Epoch 22, Step: 389, Loss: 0.11163181811571121, Lr:0.0001\n",
      "Epoch 22, Step: 390, Loss: 0.3243512511253357, Lr:0.0001\n",
      "Epoch 22, Step: 391, Loss: 0.25120997428894043, Lr:0.0001\n",
      "Epoch 22, Step: 392, Loss: 0.004566607531160116, Lr:0.0001\n",
      "Epoch 22, Step: 393, Loss: 0.09525945037603378, Lr:0.0001\n",
      "Epoch 22, Step: 394, Loss: 0.04199482128024101, Lr:0.0001\n",
      "Epoch 22, Step: 395, Loss: 0.001094121253117919, Lr:0.0001\n",
      "Epoch 22, Step: 396, Loss: 0.15628215670585632, Lr:0.0001\n",
      "Epoch 22, Step: 397, Loss: 0.03766247257590294, Lr:0.0001\n",
      "Epoch 22, Step: 398, Loss: 0.027543824166059494, Lr:0.0001\n",
      "Epoch 22, Step: 399, Loss: 0.25625959038734436, Lr:0.0001\n",
      "Epoch 22, Step: 400, Loss: 0.11198887974023819, Lr:0.0001\n",
      "Epoch 22, Step: 401, Loss: 0.01819072850048542, Lr:0.0001\n",
      "Epoch 22, Step: 402, Loss: 0.0013377952855080366, Lr:0.0001\n",
      "Epoch 22, Step: 403, Loss: 0.029557056725025177, Lr:0.0001\n",
      "Epoch 22, Step: 404, Loss: 0.10240644961595535, Lr:0.0001\n",
      "Epoch 22, Step: 405, Loss: 0.26883816719055176, Lr:0.0001\n",
      "Epoch 22, Step: 406, Loss: 0.024852870032191277, Lr:0.0001\n",
      "Epoch 22, Step: 407, Loss: 0.02725256234407425, Lr:0.0001\n",
      "Epoch 22, Step: 408, Loss: 0.0032185229938477278, Lr:0.0001\n",
      "Epoch 22, Step: 409, Loss: 0.22412478923797607, Lr:0.0001\n",
      "Epoch 22, Step: 410, Loss: 0.05417635664343834, Lr:0.0001\n",
      "Epoch 22, Step: 411, Loss: 0.02078244462609291, Lr:0.0001\n",
      "Epoch 22, Step: 412, Loss: 0.07526130974292755, Lr:0.0001\n",
      "Epoch 22, Step: 413, Loss: 0.003488552290946245, Lr:0.0001\n",
      "Epoch 22, Step: 414, Loss: 0.09899596124887466, Lr:0.0001\n",
      "Epoch 22, Step: 415, Loss: 0.016636500135064125, Lr:0.0001\n",
      "Epoch 22, Step: 416, Loss: 0.14037223160266876, Lr:0.0001\n",
      "Epoch 22, Step: 417, Loss: 0.023189380764961243, Lr:0.0001\n",
      "Epoch 22, Step: 418, Loss: 0.11074601858854294, Lr:0.0001\n",
      "Epoch 22, Step: 419, Loss: 0.07347556203603745, Lr:0.0001\n",
      "Epoch 22, Step: 420, Loss: 0.013438988476991653, Lr:0.0001\n",
      "Epoch 22, Step: 421, Loss: 0.03067959100008011, Lr:0.0001\n",
      "Epoch 22, Step: 422, Loss: 0.22280026972293854, Lr:0.0001\n",
      "Epoch 22, Step: 423, Loss: 0.006465143524110317, Lr:0.0001\n",
      "Epoch 22, Step: 424, Loss: 0.003445457201451063, Lr:0.0001\n",
      "Epoch 22, Step: 425, Loss: 0.034088633954524994, Lr:0.0001\n",
      "Epoch 22, Step: 426, Loss: 0.018449919298291206, Lr:0.0001\n",
      "Epoch 22, Step: 427, Loss: 0.01700526475906372, Lr:0.0001\n",
      "Epoch 22, Step: 428, Loss: 0.2523709535598755, Lr:0.0001\n",
      "Epoch 22, Step: 429, Loss: 0.1274210661649704, Lr:0.0001\n",
      "Epoch 22, Step: 430, Loss: 0.1260121464729309, Lr:0.0001\n",
      "Epoch 22, Step: 431, Loss: 0.008436602540314198, Lr:0.0001\n",
      "Epoch 22, Step: 432, Loss: 0.42827826738357544, Lr:0.0001\n",
      "Epoch 22, Step: 433, Loss: 0.009066878817975521, Lr:0.0001\n",
      "Epoch 22, Step: 434, Loss: 0.27893728017807007, Lr:0.0001\n",
      "Epoch 22, Step: 435, Loss: 0.11067909747362137, Lr:0.0001\n",
      "Epoch 22, Step: 436, Loss: 0.2807682752609253, Lr:0.0001\n",
      "Epoch 22, Step: 437, Loss: 0.0037920852191746235, Lr:0.0001\n",
      "Epoch 22, Step: 438, Loss: 0.11349896341562271, Lr:0.0001\n",
      "Epoch 22, Step: 439, Loss: 0.3721100986003876, Lr:0.0001\n",
      "Epoch 22, Step: 440, Loss: 0.10038395971059799, Lr:0.0001\n",
      "Epoch 22, Step: 441, Loss: 0.020084040239453316, Lr:0.0001\n",
      "Epoch 22, Step: 442, Loss: 0.015282656066119671, Lr:0.0001\n",
      "Epoch 22, Step: 443, Loss: 0.28964951634407043, Lr:0.0001\n",
      "Epoch 22, Step: 444, Loss: 0.004230109043419361, Lr:0.0001\n",
      "Epoch 22, Step: 445, Loss: 0.007027345709502697, Lr:0.0001\n",
      "Epoch 22, Step: 446, Loss: 0.021056365221738815, Lr:0.0001\n",
      "Epoch 22, Step: 447, Loss: 0.021069105714559555, Lr:0.0001\n",
      "Epoch 22, Step: 448, Loss: 0.005962302442640066, Lr:0.0001\n",
      "Epoch 22, Step: 449, Loss: 0.04207311198115349, Lr:0.0001\n",
      "Epoch 22, Step: 450, Loss: 0.07197218388319016, Lr:0.0001\n",
      "Epoch 22, Step: 451, Loss: 0.00214554276317358, Lr:0.0001\n",
      "Epoch 22, Step: 452, Loss: 0.024528171867132187, Lr:0.0001\n",
      "Epoch 22, Step: 453, Loss: 0.0951942503452301, Lr:0.0001\n",
      "Epoch 22, Step: 454, Loss: 0.3398759067058563, Lr:0.0001\n",
      "Epoch 22, Step: 455, Loss: 0.019568391144275665, Lr:0.0001\n",
      "Epoch 22, Step: 456, Loss: 0.20018713176250458, Lr:0.0001\n",
      "Epoch 22, Step: 457, Loss: 0.0437261201441288, Lr:0.0001\n",
      "Epoch 22, Step: 458, Loss: 0.0356774628162384, Lr:0.0001\n",
      "Epoch 22, Step: 459, Loss: 0.043343957513570786, Lr:0.0001\n",
      "Epoch 22, Step: 460, Loss: 0.02772405929863453, Lr:0.0001\n",
      "Epoch 22, Step: 461, Loss: 0.09514018148183823, Lr:0.0001\n",
      "Epoch 22, Step: 462, Loss: 0.12761190533638, Lr:0.0001\n",
      "Epoch 22, Step: 463, Loss: 0.02580326609313488, Lr:0.0001\n",
      "Epoch 22, Step: 464, Loss: 0.1026756539940834, Lr:0.0001\n",
      "Epoch 22, Step: 465, Loss: 0.012863251380622387, Lr:0.0001\n",
      "Epoch 22, Step: 466, Loss: 0.04671933129429817, Lr:0.0001\n",
      "Epoch 22, Step: 467, Loss: 0.061512332409620285, Lr:0.0001\n",
      "Epoch 22, Step: 468, Loss: 0.05513005331158638, Lr:0.0001\n",
      "Epoch 22, Step: 469, Loss: 0.0843038558959961, Lr:0.0001\n",
      "Epoch 22, Step: 470, Loss: 0.09225766360759735, Lr:0.0001\n",
      "Epoch 22, Step: 471, Loss: 0.057751141488552094, Lr:0.0001\n",
      "Epoch 22, Step: 472, Loss: 0.062306907027959824, Lr:0.0001\n",
      "Epoch 22, Step: 473, Loss: 0.009673867374658585, Lr:0.0001\n",
      "Epoch 22, Step: 474, Loss: 0.0004715777176897973, Lr:0.0001\n",
      "Epoch 22, Step: 475, Loss: 0.0018533675465732813, Lr:0.0001\n",
      "Epoch 22, Step: 476, Loss: 0.025334352627396584, Lr:0.0001\n",
      "Epoch 22, Step: 477, Loss: 0.015326401218771935, Lr:0.0001\n",
      "Epoch 22, Step: 478, Loss: 0.14157459139823914, Lr:0.0001\n",
      "Epoch 22, Step: 479, Loss: 0.08313716948032379, Lr:0.0001\n",
      "Epoch 22, Step: 480, Loss: 0.20615600049495697, Lr:0.0001\n",
      "Epoch 22, Step: 481, Loss: 0.07070524245500565, Lr:0.0001\n",
      "Epoch 22, Step: 482, Loss: 0.025257356464862823, Lr:0.0001\n",
      "Epoch 22, Step: 483, Loss: 0.10992274433374405, Lr:0.0001\n",
      "Epoch 22, Step: 484, Loss: 0.14573287963867188, Lr:0.0001\n",
      "Epoch 22, Step: 485, Loss: 0.06629925966262817, Lr:0.0001\n",
      "Epoch 22, Step: 486, Loss: 0.0061361221596598625, Lr:0.0001\n",
      "Epoch 22, Step: 487, Loss: 0.42376697063446045, Lr:0.0001\n",
      "Epoch 22, Step: 488, Loss: 0.003927089739590883, Lr:0.0001\n",
      "Epoch 22, Step: 489, Loss: 0.0641779899597168, Lr:0.0001\n",
      "Epoch 22, Step: 490, Loss: 0.09915269166231155, Lr:0.0001\n",
      "Epoch 22, Step: 491, Loss: 0.025871550664305687, Lr:0.0001\n",
      "Epoch 22, Step: 492, Loss: 0.02434302121400833, Lr:0.0001\n",
      "Epoch 22, Step: 493, Loss: 0.030497761443257332, Lr:0.0001\n",
      "Epoch 22, Step: 494, Loss: 0.2533782124519348, Lr:0.0001\n",
      "Epoch 22, Step: 495, Loss: 0.00832928717136383, Lr:0.0001\n",
      "Epoch 22, Step: 496, Loss: 0.019240105524659157, Lr:0.0001\n",
      "Epoch 22, Step: 497, Loss: 0.1812421828508377, Lr:0.0001\n",
      "Epoch 22, Step: 498, Loss: 0.1337519735097885, Lr:0.0001\n",
      "Epoch 22, Step: 499, Loss: 0.08886723965406418, Lr:0.0001\n",
      "Epoch 22, Step: 500, Loss: 0.05594773590564728, Lr:0.0001\n",
      "Epoch 22, Step: 501, Loss: 0.028880655765533447, Lr:0.0001\n",
      "Epoch 22, Step: 502, Loss: 0.04361656308174133, Lr:0.0001\n",
      "Epoch 22, Step: 503, Loss: 0.036380160599946976, Lr:0.0001\n",
      "Epoch 22, Step: 504, Loss: 0.003179702674970031, Lr:0.0001\n",
      "Epoch 22, Step: 505, Loss: 0.05064316838979721, Lr:0.0001\n",
      "Epoch 22, Step: 506, Loss: 0.02011718787252903, Lr:0.0001\n",
      "Epoch 22, Step: 507, Loss: 0.017550572752952576, Lr:0.0001\n",
      "Epoch 22, Step: 508, Loss: 0.22023996710777283, Lr:0.0001\n",
      "Epoch 22, Step: 509, Loss: 0.06823266297578812, Lr:0.0001\n",
      "Epoch 22, Step: 510, Loss: 0.1334736943244934, Lr:0.0001\n",
      "Epoch 22, Step: 511, Loss: 0.0426182858645916, Lr:0.0001\n",
      "Epoch 22, Step: 512, Loss: 0.07747077196836472, Lr:0.0001\n",
      "Epoch 22, Step: 513, Loss: 0.09796126186847687, Lr:0.0001\n",
      "Epoch 22, Step: 514, Loss: 0.01911693997681141, Lr:0.0001\n",
      "Epoch 22, Step: 515, Loss: 0.11717414855957031, Lr:0.0001\n",
      "Epoch 22, Step: 516, Loss: 0.006328909192234278, Lr:0.0001\n",
      "Epoch 22, Step: 517, Loss: 0.03432263061404228, Lr:0.0001\n",
      "Epoch 22, Step: 518, Loss: 0.009974674321711063, Lr:0.0001\n",
      "Epoch 22, Step: 519, Loss: 0.05320382118225098, Lr:0.0001\n",
      "Epoch 22, Step: 520, Loss: 0.05097833648324013, Lr:0.0001\n",
      "Epoch 22, Step: 521, Loss: 0.029260946437716484, Lr:0.0001\n",
      "Epoch 22, Step: 522, Loss: 0.03288673982024193, Lr:0.0001\n",
      "Epoch 22, Step: 523, Loss: 0.02415102906525135, Lr:0.0001\n",
      "Epoch 22, Step: 524, Loss: 0.022484581917524338, Lr:0.0001\n",
      "Epoch 22, Step: 525, Loss: 0.2963591516017914, Lr:0.0001\n",
      "Epoch 22, Step: 526, Loss: 0.004802928306162357, Lr:0.0001\n",
      "Epoch 22, Step: 527, Loss: 0.08931179344654083, Lr:0.0001\n",
      "Epoch 22, Step: 528, Loss: 0.28194019198417664, Lr:0.0001\n",
      "Epoch 22, Step: 529, Loss: 0.035185374319553375, Lr:0.0001\n",
      "Epoch 22, Step: 530, Loss: 0.02781190164387226, Lr:0.0001\n",
      "Epoch 22, Step: 531, Loss: 0.07460310310125351, Lr:0.0001\n",
      "Epoch 22, Step: 532, Loss: 0.11447547376155853, Lr:0.0001\n",
      "Epoch 22, Step: 533, Loss: 0.008486076258122921, Lr:0.0001\n",
      "Epoch 22, Step: 534, Loss: 0.006962681654840708, Lr:0.0001\n",
      "Epoch 22, Step: 535, Loss: 0.18107323348522186, Lr:0.0001\n",
      "Epoch 22, Step: 536, Loss: 0.036546140909194946, Lr:0.0001\n",
      "Epoch 22, Step: 537, Loss: 0.09401015192270279, Lr:0.0001\n",
      "Epoch 22, Step: 538, Loss: 0.046960022300481796, Lr:0.0001\n",
      "Epoch 22, Step: 539, Loss: 0.04143244028091431, Lr:0.0001\n",
      "Epoch 22, Step: 540, Loss: 0.040584348142147064, Lr:0.0001\n",
      "Epoch 22, Step: 541, Loss: 0.0010892562568187714, Lr:0.0001\n",
      "Epoch 22, Step: 542, Loss: 0.33625051379203796, Lr:0.0001\n",
      "Epoch 22, Step: 543, Loss: 0.0717165395617485, Lr:0.0001\n",
      "Epoch 22, Step: 544, Loss: 0.022843284532427788, Lr:0.0001\n",
      "Epoch 22, Step: 545, Loss: 0.018469778820872307, Lr:0.0001\n",
      "Epoch 22, Step: 546, Loss: 0.014982529915869236, Lr:0.0001\n",
      "Epoch 22, Step: 547, Loss: 0.03285073861479759, Lr:0.0001\n",
      "Epoch 22, Step: 548, Loss: 0.05305423587560654, Lr:0.0001\n",
      "Epoch 22, Step: 549, Loss: 0.021861881017684937, Lr:0.0001\n",
      "Epoch 22, Step: 550, Loss: 0.0725240483880043, Lr:0.0001\n",
      "Epoch 22, Step: 551, Loss: 0.06284098327159882, Lr:0.0001\n",
      "Epoch 22, Step: 552, Loss: 0.025799844413995743, Lr:0.0001\n",
      "Epoch 22, Step: 553, Loss: 0.12783652544021606, Lr:0.0001\n",
      "Epoch 22, Step: 554, Loss: 0.07896929979324341, Lr:0.0001\n",
      "Epoch 22, Step: 555, Loss: 0.12482867389917374, Lr:0.0001\n",
      "Epoch 22, Step: 556, Loss: 0.12232047319412231, Lr:0.0001\n",
      "Epoch 22, Step: 557, Loss: 0.0767265185713768, Lr:0.0001\n",
      "Epoch 22, Step: 558, Loss: 0.10054060816764832, Lr:0.0001\n",
      "Epoch 22, Step: 559, Loss: 0.016770025715231895, Lr:0.0001\n",
      "Epoch 22, Step: 560, Loss: 0.07474084198474884, Lr:0.0001\n",
      "Epoch 22, Step: 561, Loss: 0.03624080866575241, Lr:0.0001\n",
      "Epoch 22, Step: 562, Loss: 0.02619175612926483, Lr:0.0001\n",
      "Epoch 22, Step: 563, Loss: 0.06502231955528259, Lr:0.0001\n",
      "Epoch 22, Step: 564, Loss: 0.018020644783973694, Lr:0.0001\n",
      "Epoch 22, Step: 565, Loss: 0.23391234874725342, Lr:0.0001\n",
      "Epoch 22, Step: 566, Loss: 0.09071371704339981, Lr:0.0001\n",
      "Epoch 22, Step: 567, Loss: 0.10943889617919922, Lr:0.0001\n",
      "Epoch 22, Step: 568, Loss: 0.007977230474352837, Lr:0.0001\n",
      "Epoch 22, Step: 569, Loss: 0.052866749465465546, Lr:0.0001\n",
      "Epoch 22, Step: 570, Loss: 0.1262277364730835, Lr:0.0001\n",
      "Epoch 22, Step: 571, Loss: 0.11566907912492752, Lr:0.0001\n",
      "Epoch 22, Step: 572, Loss: 0.004169653169810772, Lr:0.0001\n",
      "Epoch 22, Step: 573, Loss: 0.056724172085523605, Lr:0.0001\n",
      "Epoch 22, Step: 574, Loss: 0.05502406135201454, Lr:0.0001\n",
      "Epoch 22, Step: 575, Loss: 0.3650149405002594, Lr:0.0001\n",
      "Epoch 22, Step: 576, Loss: 0.0608588308095932, Lr:0.0001\n",
      "Epoch 22, Step: 577, Loss: 0.009648230858147144, Lr:0.0001\n",
      "Epoch 22, Step: 578, Loss: 0.04341605305671692, Lr:0.0001\n",
      "Epoch 22, Step: 579, Loss: 0.041079748421907425, Lr:0.0001\n",
      "Epoch 22, Step: 580, Loss: 0.22482113540172577, Lr:0.0001\n",
      "Epoch 22, Step: 581, Loss: 0.06641118973493576, Lr:0.0001\n",
      "Epoch 22, Step: 582, Loss: 0.005536765791475773, Lr:0.0001\n",
      "Epoch 22, Step: 583, Loss: 0.20667292177677155, Lr:0.0001\n",
      "Epoch 22, Step: 584, Loss: 0.1612432599067688, Lr:0.0001\n",
      "Epoch 22, Step: 585, Loss: 0.09179891645908356, Lr:0.0001\n",
      "Epoch 22, Step: 586, Loss: 0.13214553892612457, Lr:0.0001\n",
      "Epoch 22, Step: 587, Loss: 0.14658445119857788, Lr:0.0001\n",
      "Epoch 22, Step: 588, Loss: 0.019151976332068443, Lr:0.0001\n",
      "Epoch 22, Step: 589, Loss: 0.007289445959031582, Lr:0.0001\n",
      "Epoch 22, Step: 590, Loss: 0.34636422991752625, Lr:0.0001\n",
      "Epoch 22, Step: 591, Loss: 0.17486388981342316, Lr:0.0001\n",
      "Epoch 22, Step: 592, Loss: 0.05222634971141815, Lr:0.0001\n",
      "Epoch 22, Step: 593, Loss: 0.28124335408210754, Lr:0.0001\n",
      "Epoch 22, Step: 594, Loss: 0.08917385339736938, Lr:0.0001\n",
      "Epoch 22, Step: 595, Loss: 0.09224075078964233, Lr:0.0001\n",
      "Epoch 22, Step: 596, Loss: 0.07551566511392593, Lr:0.0001\n",
      "Epoch 22, Step: 597, Loss: 0.015949290245771408, Lr:0.0001\n",
      "Epoch 22, Step: 598, Loss: 0.031189436092972755, Lr:0.0001\n",
      "Epoch 22, Step: 599, Loss: 0.02620120346546173, Lr:0.0001\n",
      "Epoch 22, Step: 600, Loss: 0.006210295483469963, Lr:0.0001\n",
      "Epoch 22, Step: 601, Loss: 0.02008736878633499, Lr:0.0001\n",
      "Epoch 22, Step: 602, Loss: 0.06588593125343323, Lr:0.0001\n",
      "Epoch 22, Step: 603, Loss: 0.014126528985798359, Lr:0.0001\n",
      "Epoch 22, Step: 604, Loss: 0.44236984848976135, Lr:0.0001\n",
      "Epoch 22, Step: 605, Loss: 0.012286004610359669, Lr:0.0001\n",
      "Epoch 22, Step: 606, Loss: 0.05164643004536629, Lr:0.0001\n",
      "Epoch 22, Step: 607, Loss: 0.058884087949991226, Lr:0.0001\n",
      "Epoch 22, Step: 608, Loss: 0.018074963241815567, Lr:0.0001\n",
      "Epoch 22, Step: 609, Loss: 0.009862140752375126, Lr:0.0001\n",
      "Epoch 22, Step: 610, Loss: 0.008386035449802876, Lr:0.0001\n",
      "Epoch 22, Step: 611, Loss: 0.12167395651340485, Lr:0.0001\n",
      "Epoch 22, Step: 612, Loss: 0.0339234285056591, Lr:0.0001\n",
      "Epoch 22, Step: 613, Loss: 0.23726211488246918, Lr:0.0001\n",
      "Epoch 22, Step: 614, Loss: 0.04257358983159065, Lr:0.0001\n",
      "Epoch 22, Step: 615, Loss: 0.05524240434169769, Lr:0.0001\n",
      "Epoch 22, Step: 616, Loss: 0.0425187349319458, Lr:0.0001\n",
      "Epoch 22, Step: 617, Loss: 0.0004377572622615844, Lr:0.0001\n",
      "Epoch 22, Step: 618, Loss: 0.021316509693861008, Lr:0.0001\n",
      "Epoch 22, Step: 619, Loss: 0.0703604444861412, Lr:0.0001\n",
      "Epoch 22, Step: 620, Loss: 0.05258231610059738, Lr:0.0001\n",
      "Epoch 22, Step: 621, Loss: 0.204348623752594, Lr:0.0001\n",
      "Epoch 22, Step: 622, Loss: 0.03037422150373459, Lr:0.0001\n",
      "Epoch 22, Step: 623, Loss: 0.13246247172355652, Lr:0.0001\n",
      "Epoch 22, Step: 624, Loss: 0.0941692516207695, Lr:0.0001\n",
      "Epoch 22, Step: 625, Loss: 0.45074474811553955, Lr:0.0001\n",
      "Epoch 22, Step: 626, Loss: 0.28200486302375793, Lr:0.0001\n",
      "Epoch 22, Step: 627, Loss: 0.0393771268427372, Lr:0.0001\n",
      "Epoch 22, Step: 628, Loss: 0.055135373026132584, Lr:0.0001\n",
      "Epoch 22, Step: 629, Loss: 0.1476203054189682, Lr:0.0001\n",
      "Epoch 22, Step: 630, Loss: 0.13614881038665771, Lr:0.0001\n",
      "Epoch 22, Step: 631, Loss: 0.04007633775472641, Lr:0.0001\n",
      "Epoch 22, Step: 632, Loss: 0.010412090457975864, Lr:0.0001\n",
      "Epoch 22, Step: 633, Loss: 0.07063779979944229, Lr:0.0001\n",
      "Epoch 22, Step: 634, Loss: 0.059903834015131, Lr:0.0001\n",
      "Epoch 22, Step: 635, Loss: 0.1438264697790146, Lr:0.0001\n",
      "Epoch 22, Step: 636, Loss: 0.13034828007221222, Lr:0.0001\n",
      "Epoch 22, Step: 637, Loss: 0.01737910509109497, Lr:0.0001\n",
      "Epoch 22, Step: 638, Loss: 0.04503346607089043, Lr:0.0001\n",
      "Epoch 22, Step: 639, Loss: 0.01547095738351345, Lr:0.0001\n",
      "Epoch 22, Step: 640, Loss: 0.5798794031143188, Lr:0.0001\n",
      "Epoch 22, Step: 641, Loss: 0.004577831365168095, Lr:0.0001\n",
      "Epoch 22, Step: 642, Loss: 0.024285148829221725, Lr:0.0001\n",
      "Epoch 22, Step: 643, Loss: 0.0440647155046463, Lr:0.0001\n",
      "Epoch 22, Step: 644, Loss: 0.091777503490448, Lr:0.0001\n",
      "Epoch 22, Step: 645, Loss: 0.12168701738119125, Lr:0.0001\n",
      "Epoch 22, Step: 646, Loss: 0.05072235316038132, Lr:0.0001\n",
      "Epoch 22, Step: 647, Loss: 0.17451350390911102, Lr:0.0001\n",
      "Epoch 22, Step: 648, Loss: 0.0219376590102911, Lr:0.0001\n",
      "Epoch 22, Step: 649, Loss: 0.10144176334142685, Lr:0.0001\n",
      "Epoch 22, Step: 650, Loss: 0.06216547638177872, Lr:0.0001\n",
      "Epoch 22, Step: 651, Loss: 0.07304129004478455, Lr:0.0001\n",
      "Epoch 22, Step: 652, Loss: 0.17922641336917877, Lr:0.0001\n",
      "Epoch 22, Step: 653, Loss: 0.004481514450162649, Lr:0.0001\n",
      "Epoch 22, Step: 654, Loss: 0.22258129715919495, Lr:0.0001\n",
      "Epoch 22, Step: 655, Loss: 0.04969170689582825, Lr:0.0001\n",
      "Epoch 22, Step: 656, Loss: 0.25304630398750305, Lr:0.0001\n",
      "Epoch 22, Step: 657, Loss: 0.052426718175411224, Lr:0.0001\n",
      "Epoch 22, Step: 658, Loss: 0.13216204941272736, Lr:0.0001\n",
      "Epoch 22, Step: 659, Loss: 0.11257188022136688, Lr:0.0001\n",
      "Epoch 22, Step: 660, Loss: 0.0528377890586853, Lr:0.0001\n",
      "Epoch 22, Step: 661, Loss: 0.0018527964130043983, Lr:0.0001\n",
      "Epoch 22, Step: 662, Loss: 0.028198519721627235, Lr:0.0001\n",
      "Epoch 22, Step: 663, Loss: 0.023526595905423164, Lr:0.0001\n",
      "Epoch 22, Step: 664, Loss: 0.38634365797042847, Lr:0.0001\n",
      "Epoch 22, Step: 665, Loss: 0.08683910220861435, Lr:0.0001\n",
      "Epoch 22, Step: 666, Loss: 0.028041880577802658, Lr:0.0001\n",
      "Epoch 22, Step: 667, Loss: 0.0010621527908369899, Lr:0.0001\n",
      "Epoch 22, Step: 668, Loss: 0.009261931292712688, Lr:0.0001\n",
      "Epoch 22, Step: 669, Loss: 0.04776638746261597, Lr:0.0001\n",
      "Epoch 22, Step: 670, Loss: 0.005641957279294729, Lr:0.0001\n",
      "Epoch 22, Step: 671, Loss: 0.006630657706409693, Lr:0.0001\n",
      "Epoch 22, Step: 672, Loss: 0.0619317963719368, Lr:0.0001\n",
      "Epoch 22, Step: 673, Loss: 0.010879544541239738, Lr:0.0001\n",
      "Epoch 22, Step: 674, Loss: 0.05514216050505638, Lr:0.0001\n",
      "Epoch 22, Step: 675, Loss: 0.06300339847803116, Lr:0.0001\n",
      "Epoch 22, Step: 676, Loss: 0.07690531760454178, Lr:0.0001\n",
      "Epoch 22, Step: 677, Loss: 0.13382604718208313, Lr:0.0001\n",
      "Epoch 22, Step: 678, Loss: 0.028629139065742493, Lr:0.0001\n",
      "Epoch 22, Step: 679, Loss: 0.010016901418566704, Lr:0.0001\n",
      "Epoch 22, Step: 680, Loss: 0.058602698147296906, Lr:0.0001\n",
      "Epoch 22, Step: 681, Loss: 0.29317834973335266, Lr:0.0001\n",
      "Epoch 22, Step: 682, Loss: 0.09609149396419525, Lr:0.0001\n",
      "Epoch 22, Step: 683, Loss: 0.12100072205066681, Lr:0.0001\n",
      "Epoch 22, Step: 684, Loss: 0.003654484637081623, Lr:0.0001\n",
      "Epoch 22, Step: 685, Loss: 0.010067138820886612, Lr:0.0001\n",
      "Epoch 22, Step: 686, Loss: 0.025375191122293472, Lr:0.0001\n",
      "Epoch 22, Step: 687, Loss: 0.13452588021755219, Lr:0.0001\n",
      "Epoch 22, Step: 688, Loss: 0.3923285901546478, Lr:0.0001\n",
      "Epoch 22, Step: 689, Loss: 0.13716919720172882, Lr:0.0001\n",
      "Epoch 22, Step: 690, Loss: 0.017820261418819427, Lr:0.0001\n",
      "Epoch 22, Step: 691, Loss: 0.10455643385648727, Lr:0.0001\n",
      "Epoch 22, Step: 692, Loss: 0.02969331480562687, Lr:0.0001\n",
      "Epoch 22, Step: 693, Loss: 0.25221744179725647, Lr:0.0001\n",
      "Epoch 22, Step: 694, Loss: 0.009439421817660332, Lr:0.0001\n",
      "Epoch 22, Step: 695, Loss: 0.010204985737800598, Lr:0.0001\n",
      "Epoch 22, Step: 696, Loss: 0.06500381231307983, Lr:0.0001\n",
      "Epoch 22, Step: 697, Loss: 0.05694400519132614, Lr:0.0001\n",
      "Epoch 22, Step: 698, Loss: 0.15108007192611694, Lr:0.0001\n",
      "Epoch 22, Step: 699, Loss: 0.007442366797477007, Lr:0.0001\n",
      "Epoch 22, Step: 700, Loss: 0.14974436163902283, Lr:0.0001\n",
      "Epoch 22, Step: 701, Loss: 0.11044026911258698, Lr:0.0001\n",
      "Epoch 22, Step: 702, Loss: 0.01075407862663269, Lr:0.0001\n",
      "Epoch 22, Step: 703, Loss: 0.01200507115572691, Lr:0.0001\n",
      "Epoch 22, Step: 704, Loss: 0.11387666314840317, Lr:0.0001\n",
      "Epoch 22, Step: 705, Loss: 0.0822850689291954, Lr:0.0001\n",
      "Epoch 22, Step: 706, Loss: 0.004823867231607437, Lr:0.0001\n",
      "Epoch 22, Step: 707, Loss: 0.025105377659201622, Lr:0.0001\n",
      "Epoch 22, Step: 708, Loss: 0.017511632293462753, Lr:0.0001\n",
      "Epoch 22, Step: 709, Loss: 0.0344996377825737, Lr:0.0001\n",
      "Epoch 22, Step: 710, Loss: 0.15340888500213623, Lr:0.0001\n",
      "Epoch 22, Step: 711, Loss: 0.13954997062683105, Lr:0.0001\n",
      "Epoch 22, Step: 712, Loss: 0.10830298066139221, Lr:0.0001\n",
      "Epoch 22, Step: 713, Loss: 0.15466852486133575, Lr:0.0001\n",
      "Epoch 22, Step: 714, Loss: 0.025085194036364555, Lr:0.0001\n",
      "Epoch 22, Step: 715, Loss: 0.028414366766810417, Lr:0.0001\n",
      "Epoch 22, Step: 716, Loss: 0.0645492672920227, Lr:0.0001\n",
      "Epoch 22, Step: 717, Loss: 0.03759273886680603, Lr:0.0001\n",
      "Epoch 22, Step: 718, Loss: 0.022122742608189583, Lr:0.0001\n",
      "Epoch 22, Step: 719, Loss: 0.04666602984070778, Lr:0.0001\n",
      "Epoch 22, Step: 720, Loss: 0.07192310690879822, Lr:0.0001\n",
      "Epoch 22, Step: 721, Loss: 0.010517768561840057, Lr:0.0001\n",
      "Epoch 22, Step: 722, Loss: 0.07852403074502945, Lr:0.0001\n",
      "Epoch 22, Step: 723, Loss: 0.01343633234500885, Lr:0.0001\n",
      "Epoch 22, Step: 724, Loss: 0.06225469708442688, Lr:0.0001\n",
      "Epoch 22, Step: 725, Loss: 0.008397548459470272, Lr:0.0001\n",
      "Epoch 22, Step: 726, Loss: 0.001914684078656137, Lr:0.0001\n",
      "Epoch 22, Step: 727, Loss: 0.06546653062105179, Lr:0.0001\n",
      "Epoch 22, Step: 728, Loss: 0.04124990105628967, Lr:0.0001\n",
      "Epoch 22, Step: 729, Loss: 0.14152134954929352, Lr:0.0001\n",
      "Epoch 22, Step: 730, Loss: 0.1084059402346611, Lr:0.0001\n",
      "Epoch 22, Step: 731, Loss: 0.03410216048359871, Lr:0.0001\n",
      "Epoch 22, Step: 732, Loss: 0.047878511250019073, Lr:0.0001\n",
      "Epoch 22, Step: 733, Loss: 0.043994683772325516, Lr:0.0001\n",
      "Epoch 22, Step: 734, Loss: 0.08622172474861145, Lr:0.0001\n",
      "Epoch 22, Step: 735, Loss: 0.008467056788504124, Lr:0.0001\n",
      "Epoch 22, Step: 736, Loss: 0.1285141408443451, Lr:0.0001\n",
      "Epoch 22, Step: 737, Loss: 0.10613501816987991, Lr:0.0001\n",
      "Epoch 22, Step: 738, Loss: 0.055651288479566574, Lr:0.0001\n",
      "Epoch 22, Step: 739, Loss: 0.014421855099499226, Lr:0.0001\n",
      "Epoch 22, Step: 740, Loss: 0.01399487815797329, Lr:0.0001\n",
      "Epoch 22, Step: 741, Loss: 0.02387145720422268, Lr:0.0001\n",
      "Epoch 22, Step: 742, Loss: 0.034902174025774, Lr:0.0001\n",
      "Epoch 22, Step: 743, Loss: 0.10527021437883377, Lr:0.0001\n",
      "Epoch 22, Step: 744, Loss: 0.022113295271992683, Lr:0.0001\n",
      "Epoch 22, Step: 745, Loss: 0.0931880846619606, Lr:0.0001\n",
      "Epoch 22, Step: 746, Loss: 0.023386089131236076, Lr:0.0001\n",
      "Epoch 22, Step: 747, Loss: 0.021922247484326363, Lr:0.0001\n",
      "Epoch 22, Step: 748, Loss: 0.02544538490474224, Lr:0.0001\n",
      "Epoch 22, Step: 749, Loss: 0.017977900803089142, Lr:0.0001\n",
      "Epoch 22, Step: 750, Loss: 0.001744515378959477, Lr:0.0001\n",
      "Epoch 22, Step: 751, Loss: 0.012094633653759956, Lr:0.0001\n",
      "Epoch 22, Step: 752, Loss: 0.017413519322872162, Lr:0.0001\n",
      "Epoch 22, Step: 753, Loss: 0.054215025156736374, Lr:0.0001\n",
      "Epoch 22, Step: 754, Loss: 0.1206367164850235, Lr:0.0001\n",
      "Epoch 22, Step: 755, Loss: 0.12359201163053513, Lr:0.0001\n",
      "Epoch 22, Step: 756, Loss: 0.0011015242198482156, Lr:0.0001\n",
      "Epoch 22, Step: 757, Loss: 0.06197629123926163, Lr:0.0001\n",
      "Epoch 22, Step: 758, Loss: 0.017045093700289726, Lr:0.0001\n",
      "Epoch 22, Step: 759, Loss: 0.11857037246227264, Lr:0.0001\n",
      "Epoch 22, Step: 760, Loss: 0.0725879892706871, Lr:0.0001\n",
      "Epoch 22, Step: 761, Loss: 0.22548696398735046, Lr:0.0001\n",
      "Epoch 22, Step: 762, Loss: 0.013243132270872593, Lr:0.0001\n",
      "Epoch 22, Step: 763, Loss: 0.0798993855714798, Lr:0.0001\n",
      "Epoch 22, Step: 764, Loss: 0.15411897003650665, Lr:0.0001\n",
      "Epoch 22, Step: 765, Loss: 0.011703504249453545, Lr:0.0001\n",
      "Epoch 22, Step: 766, Loss: 0.1001352071762085, Lr:0.0001\n",
      "Epoch 22, Step: 767, Loss: 0.010701938532292843, Lr:0.0001\n",
      "Epoch 22, Step: 768, Loss: 0.17056025564670563, Lr:0.0001\n",
      "Epoch 22, Step: 769, Loss: 0.06277573853731155, Lr:0.0001\n",
      "Epoch 22, Step: 770, Loss: 0.01572803221642971, Lr:0.0001\n",
      "Epoch 22, Step: 771, Loss: 0.08530735969543457, Lr:0.0001\n",
      "Epoch 22, Step: 772, Loss: 0.039384931325912476, Lr:0.0001\n",
      "Epoch 22, Step: 773, Loss: 0.028998002409934998, Lr:0.0001\n",
      "Epoch 22, Step: 774, Loss: 0.022016137838363647, Lr:0.0001\n",
      "Epoch 22, Step: 775, Loss: 0.1543153077363968, Lr:0.0001\n",
      "Epoch 22, Step: 776, Loss: 0.25423070788383484, Lr:0.0001\n",
      "Epoch 22, Step: 777, Loss: 0.15991303324699402, Lr:0.0001\n",
      "Epoch 22, Step: 778, Loss: 0.16920578479766846, Lr:0.0001\n",
      "Epoch 22, Step: 779, Loss: 0.06537340581417084, Lr:0.0001\n",
      "Epoch 22, Step: 780, Loss: 0.027180615812540054, Lr:0.0001\n",
      "Epoch 22, Step: 781, Loss: 0.3194732666015625, Lr:0.0001\n",
      "Epoch 22, Step: 782, Loss: 0.2035946398973465, Lr:0.0001\n",
      "Epoch 22, Step: 783, Loss: 0.04086849093437195, Lr:0.0001\n",
      "Epoch 22, Step: 784, Loss: 0.025852693244814873, Lr:0.0001\n",
      "Epoch 22, Step: 785, Loss: 0.008292030543088913, Lr:0.0001\n",
      "Epoch 22, Step: 786, Loss: 0.11269032955169678, Lr:0.0001\n",
      "Epoch 22, Step: 787, Loss: 0.302594393491745, Lr:0.0001\n",
      "Epoch 22, Step: 788, Loss: 0.1417708396911621, Lr:0.0001\n",
      "Epoch 22, Step: 789, Loss: 0.0016353502869606018, Lr:0.0001\n",
      "Epoch 22, Step: 790, Loss: 0.04465098679065704, Lr:0.0001\n",
      "Epoch 22, Step: 791, Loss: 0.28836914896965027, Lr:0.0001\n",
      "Epoch 22, Step: 792, Loss: 0.013530141673982143, Lr:0.0001\n",
      "Epoch 22, Step: 793, Loss: 0.16587741672992706, Lr:0.0001\n",
      "Epoch 22, Step: 794, Loss: 0.004975130315870047, Lr:0.0001\n",
      "Epoch 22, Step: 795, Loss: 0.20539452135562897, Lr:0.0001\n",
      "Epoch 22, Step: 796, Loss: 0.013739343732595444, Lr:0.0001\n",
      "Epoch 22, Step: 797, Loss: 0.13205087184906006, Lr:0.0001\n",
      "Epoch 22, Step: 798, Loss: 0.005697364453226328, Lr:0.0001\n",
      "Epoch 22, Step: 799, Loss: 0.08859925717115402, Lr:0.0001\n",
      "Epoch 22, Step: 800, Loss: 0.02227471023797989, Lr:0.0001\n",
      "Epoch 22, Step: 801, Loss: 0.1699623018503189, Lr:0.0001\n",
      "Epoch 22, Step: 802, Loss: 0.15196967124938965, Lr:0.0001\n",
      "Epoch 22, Step: 803, Loss: 0.09856340289115906, Lr:0.0001\n",
      "Epoch 22, Step: 804, Loss: 0.03432505577802658, Lr:0.0001\n",
      "Epoch 22, Step: 805, Loss: 0.06480512768030167, Lr:0.0001\n",
      "Epoch 22, Step: 806, Loss: 0.03991840034723282, Lr:0.0001\n",
      "Epoch 22, Step: 807, Loss: 0.11112748831510544, Lr:0.0001\n",
      "Epoch 22, Step: 808, Loss: 0.039725206792354584, Lr:0.0001\n",
      "Epoch 22, Step: 809, Loss: 0.08057135343551636, Lr:0.0001\n",
      "Epoch 22, Step: 810, Loss: 0.229430690407753, Lr:0.0001\n",
      "Epoch 22, Step: 811, Loss: 0.03482818603515625, Lr:0.0001\n",
      "Epoch 22, Step: 812, Loss: 0.06854759901762009, Lr:0.0001\n",
      "Epoch 22, Step: 813, Loss: 0.0002985114697366953, Lr:0.0001\n",
      "Epoch 22, Step: 814, Loss: 0.07435695827007294, Lr:0.0001\n",
      "Epoch 22, Step: 815, Loss: 0.07257486879825592, Lr:0.0001\n",
      "Epoch 22, Step: 816, Loss: 0.08788339793682098, Lr:0.0001\n",
      "Epoch 22, Step: 817, Loss: 0.05768965557217598, Lr:0.0001\n",
      "Epoch 22, Step: 818, Loss: 0.18858963251113892, Lr:0.0001\n",
      "Epoch 22, Step: 819, Loss: 0.013441652059555054, Lr:0.0001\n",
      "Epoch 22, Step: 820, Loss: 0.4385761618614197, Lr:0.0001\n",
      "Epoch 22, Step: 821, Loss: 0.008974761702120304, Lr:0.0001\n",
      "Epoch 22, Step: 822, Loss: 0.2447081208229065, Lr:0.0001\n",
      "Epoch 22, Step: 823, Loss: 0.06744208186864853, Lr:0.0001\n",
      "Epoch 22, Step: 824, Loss: 0.17461834847927094, Lr:0.0001\n",
      "Epoch 22, Step: 825, Loss: 0.18917757272720337, Lr:0.0001\n",
      "Epoch 22, Step: 826, Loss: 0.13845442235469818, Lr:0.0001\n",
      "Epoch 22, Step: 827, Loss: 0.06746814399957657, Lr:0.0001\n",
      "Epoch 22, Step: 828, Loss: 0.13118019700050354, Lr:0.0001\n",
      "Epoch 22, Step: 829, Loss: 0.02018306404352188, Lr:0.0001\n",
      "Epoch 22, Step: 830, Loss: 0.12507806718349457, Lr:0.0001\n",
      "Epoch 22, Step: 831, Loss: 0.024718735367059708, Lr:0.0001\n",
      "Epoch 22, Step: 832, Loss: 0.012289972975850105, Lr:0.0001\n",
      "Epoch 22, Step: 833, Loss: 0.197531059384346, Lr:0.0001\n",
      "Epoch 22, Step: 834, Loss: 0.07955393195152283, Lr:0.0001\n",
      "Epoch 22, Step: 835, Loss: 0.058008961379528046, Lr:0.0001\n",
      "Epoch 22, Step: 836, Loss: 0.029180973768234253, Lr:0.0001\n",
      "Epoch 22, Step: 837, Loss: 0.0028842221945524216, Lr:0.0001\n",
      "Epoch 22, Step: 838, Loss: 0.04085231199860573, Lr:0.0001\n",
      "Epoch 22, Step: 839, Loss: 0.09109695255756378, Lr:0.0001\n",
      "Epoch 22, Step: 840, Loss: 0.008784702979028225, Lr:0.0001\n",
      "Epoch 22, Step: 841, Loss: 0.11945760995149612, Lr:0.0001\n",
      "Epoch 22, Step: 842, Loss: 0.12274466454982758, Lr:0.0001\n",
      "Epoch 22, Step: 843, Loss: 0.03250083327293396, Lr:0.0001\n",
      "Epoch 22, Step: 844, Loss: 0.07894332706928253, Lr:0.0001\n",
      "Epoch 22, Step: 845, Loss: 0.11120722442865372, Lr:0.0001\n",
      "Epoch 22, Step: 846, Loss: 0.07772302627563477, Lr:0.0001\n",
      "Epoch 22, Step: 847, Loss: 0.10387512296438217, Lr:0.0001\n",
      "Epoch 22, Step: 848, Loss: 0.0660124123096466, Lr:0.0001\n",
      "Epoch 22, Step: 849, Loss: 0.10062461346387863, Lr:0.0001\n",
      "Epoch 22, Step: 850, Loss: 0.047753725200891495, Lr:0.0001\n",
      "Epoch 22, Step: 851, Loss: 0.030113499611616135, Lr:0.0001\n",
      "Epoch 22, Step: 852, Loss: 0.3081858456134796, Lr:0.0001\n",
      "Epoch 22, Step: 853, Loss: 0.015245837159454823, Lr:0.0001\n",
      "Epoch 22, Step: 854, Loss: 0.0500946119427681, Lr:0.0001\n",
      "Epoch 22, Step: 855, Loss: 0.020609954372048378, Lr:0.0001\n",
      "Epoch 22, Step: 856, Loss: 0.19378942251205444, Lr:0.0001\n",
      "Epoch 22, Step: 857, Loss: 0.012273839674890041, Lr:0.0001\n",
      "Epoch 22, Step: 858, Loss: 0.004110055975615978, Lr:0.0001\n",
      "Epoch 22, Step: 859, Loss: 0.02102949470281601, Lr:0.0001\n",
      "Epoch 22, Step: 860, Loss: 0.12767019867897034, Lr:0.0001\n",
      "Epoch 22, Step: 861, Loss: 0.16736917197704315, Lr:0.0001\n",
      "Epoch 22, Step: 862, Loss: 0.014419253915548325, Lr:0.0001\n",
      "Epoch 22, Step: 863, Loss: 0.04043028876185417, Lr:0.0001\n",
      "Epoch 22, Step: 864, Loss: 0.046238381415605545, Lr:0.0001\n",
      "Epoch 22, Step: 865, Loss: 0.22929608821868896, Lr:0.0001\n",
      "Epoch 22, Step: 866, Loss: 0.11745673418045044, Lr:0.0001\n",
      "Epoch 22, Step: 867, Loss: 0.09418770670890808, Lr:0.0001\n",
      "Epoch 22, Step: 868, Loss: 0.05218268930912018, Lr:0.0001\n",
      "Epoch 22, Step: 869, Loss: 0.165818452835083, Lr:0.0001\n",
      "Epoch 22, Step: 870, Loss: 0.011243415996432304, Lr:0.0001\n",
      "Epoch 22, Step: 871, Loss: 0.12367083877325058, Lr:0.0001\n",
      "Epoch 22, Step: 872, Loss: 0.022050078958272934, Lr:0.0001\n",
      "Epoch 22, Step: 873, Loss: 0.01606644317507744, Lr:0.0001\n",
      "Epoch 22, Step: 874, Loss: 0.02688935026526451, Lr:0.0001\n",
      "Epoch 22, Step: 875, Loss: 0.1596098691225052, Lr:0.0001\n",
      "Epoch 22, Step: 876, Loss: 0.01165068056434393, Lr:0.0001\n",
      "Epoch 22, Step: 877, Loss: 0.041278813034296036, Lr:0.0001\n",
      "Epoch 22, Step: 878, Loss: 0.05881032347679138, Lr:0.0001\n",
      "Epoch 22, Step: 879, Loss: 0.0927157923579216, Lr:0.0001\n",
      "Epoch 22, Step: 880, Loss: 0.07498136162757874, Lr:0.0001\n",
      "Epoch 22, Step: 881, Loss: 0.03693552687764168, Lr:0.0001\n",
      "Epoch 22, Step: 882, Loss: 0.1890309453010559, Lr:0.0001\n",
      "Epoch 22, Step: 883, Loss: 0.10187391936779022, Lr:0.0001\n",
      "Epoch 22, Step: 884, Loss: 0.016957348212599754, Lr:0.0001\n",
      "Epoch 22, Step: 885, Loss: 0.003948696423321962, Lr:0.0001\n",
      "Epoch 22, Step: 886, Loss: 0.016771165654063225, Lr:0.0001\n",
      "Epoch 22, Step: 887, Loss: 0.05998082086443901, Lr:0.0001\n",
      "Epoch 22, Step: 888, Loss: 0.03555741161108017, Lr:0.0001\n",
      "Epoch 22, Step: 889, Loss: 0.008370675146579742, Lr:0.0001\n",
      "Epoch 22, Step: 890, Loss: 0.06180593743920326, Lr:0.0001\n",
      "Epoch 22, Step: 891, Loss: 0.33155351877212524, Lr:0.0001\n",
      "Epoch 22, Step: 892, Loss: 0.23707255721092224, Lr:0.0001\n",
      "Epoch 22, Step: 893, Loss: 0.006043447181582451, Lr:0.0001\n",
      "Epoch 22, Step: 894, Loss: 0.00904458574950695, Lr:0.0001\n",
      "Epoch 22, Step: 895, Loss: 0.008237839676439762, Lr:0.0001\n",
      "Epoch 22, Step: 896, Loss: 0.14848089218139648, Lr:0.0001\n",
      "Epoch 22, Step: 897, Loss: 0.04085833579301834, Lr:0.0001\n",
      "Epoch 22, Step: 898, Loss: 0.004860882647335529, Lr:0.0001\n",
      "Epoch 22, Step: 899, Loss: 0.059238776564598083, Lr:0.0001\n",
      "Epoch 22, Step: 900, Loss: 0.0012362784473225474, Lr:0.0001\n",
      "Epoch 22, Step: 901, Loss: 0.07384540885686874, Lr:0.0001\n",
      "Epoch 22, Step: 902, Loss: 0.03145246580243111, Lr:0.0001\n",
      "Epoch 22, Step: 903, Loss: 0.14631281793117523, Lr:0.0001\n",
      "Epoch 22, Step: 904, Loss: 0.05052725225687027, Lr:0.0001\n",
      "Epoch 22, Step: 905, Loss: 0.011591624468564987, Lr:0.0001\n",
      "Epoch 22, Step: 906, Loss: 0.03087603487074375, Lr:0.0001\n",
      "Epoch 22, Step: 907, Loss: 0.011286160908639431, Lr:0.0001\n",
      "Epoch 22, Step: 908, Loss: 0.060809385031461716, Lr:0.0001\n",
      "Epoch 22, Step: 909, Loss: 0.04785830155014992, Lr:0.0001\n",
      "Epoch 22, Step: 910, Loss: 0.03643682599067688, Lr:0.0001\n",
      "Epoch 22, Step: 911, Loss: 0.02355770952999592, Lr:0.0001\n",
      "Epoch 22, Step: 912, Loss: 0.07310812175273895, Lr:0.0001\n",
      "Epoch 22, Step: 913, Loss: 0.0015521200839430094, Lr:0.0001\n",
      "Epoch 22, Step: 914, Loss: 0.3884412944316864, Lr:0.0001\n",
      "Epoch 22, Step: 915, Loss: 0.04180236905813217, Lr:0.0001\n",
      "Epoch 22, Step: 916, Loss: 0.13403384387493134, Lr:0.0001\n",
      "Epoch 22, Step: 917, Loss: 0.04662209376692772, Lr:0.0001\n",
      "Epoch 22, Step: 918, Loss: 0.0019794648978859186, Lr:0.0001\n",
      "Epoch 22, Step: 919, Loss: 0.07007075846195221, Lr:0.0001\n",
      "Epoch 22, Step: 920, Loss: 0.019806204363703728, Lr:0.0001\n",
      "Epoch 22, Step: 921, Loss: 0.17030756175518036, Lr:0.0001\n",
      "Epoch 22, Step: 922, Loss: 0.17733502388000488, Lr:0.0001\n",
      "Epoch 22, Step: 923, Loss: 0.032009243965148926, Lr:0.0001\n",
      "Epoch 22, Step: 924, Loss: 0.11648862808942795, Lr:0.0001\n",
      "Epoch 22, Step: 925, Loss: 0.011974523775279522, Lr:0.0001\n",
      "Epoch 22, Step: 926, Loss: 0.02253221720457077, Lr:0.0001\n",
      "Epoch 22, Step: 927, Loss: 0.03299924358725548, Lr:0.0001\n",
      "Epoch 22, Step: 928, Loss: 0.007046885322779417, Lr:0.0001\n",
      "Epoch 22, Step: 929, Loss: 0.07093881815671921, Lr:0.0001\n",
      "Epoch 22, Step: 930, Loss: 0.03353584185242653, Lr:0.0001\n",
      "Epoch 22, Step: 931, Loss: 0.02607906609773636, Lr:0.0001\n",
      "Epoch 22, Step: 932, Loss: 0.09087575972080231, Lr:0.0001\n",
      "Epoch 22, Step: 933, Loss: 0.0074284994043409824, Lr:0.0001\n",
      "Epoch 22, Step: 934, Loss: 0.12217849493026733, Lr:0.0001\n",
      "Epoch 22, Step: 935, Loss: 0.014141468331217766, Lr:0.0001\n",
      "Epoch 22, Step: 936, Loss: 0.02883032150566578, Lr:0.0001\n",
      "Epoch 22, Step: 937, Loss: 0.13079434633255005, Lr:0.0001\n",
      "Epoch 22, Step: 938, Loss: 0.02991306595504284, Lr:0.0001\n",
      "Epoch 22, Step: 939, Loss: 0.023258795961737633, Lr:0.0001\n",
      "Epoch 22, Step: 940, Loss: 0.03945350646972656, Lr:0.0001\n",
      "Epoch 22, Step: 941, Loss: 0.06029926985502243, Lr:0.0001\n",
      "Epoch 22, Step: 942, Loss: 0.1616765409708023, Lr:0.0001\n",
      "Epoch 22, Step: 943, Loss: 0.08464910089969635, Lr:0.0001\n",
      "Epoch 22, Step: 944, Loss: 0.033431559801101685, Lr:0.0001\n",
      "Epoch 22, Step: 945, Loss: 0.002967044711112976, Lr:0.0001\n",
      "Epoch 22, Step: 946, Loss: 0.0027960145380347967, Lr:0.0001\n",
      "Epoch 22, Step: 947, Loss: 0.010089392773807049, Lr:0.0001\n",
      "Epoch 22, Step: 948, Loss: 0.10334271937608719, Lr:0.0001\n",
      "Epoch 22, Step: 949, Loss: 0.010546645149588585, Lr:0.0001\n",
      "Epoch 22, Step: 950, Loss: 0.2860810160636902, Lr:0.0001\n",
      "Epoch 22, Step: 951, Loss: 0.14220520853996277, Lr:0.0001\n",
      "Epoch 22, Step: 952, Loss: 0.012870518490672112, Lr:0.0001\n",
      "Epoch 22, Step: 953, Loss: 0.06232784688472748, Lr:0.0001\n",
      "Epoch 22, Step: 954, Loss: 0.0023907884024083614, Lr:0.0001\n",
      "Epoch 22, Step: 955, Loss: 0.01946641132235527, Lr:0.0001\n",
      "Epoch 22, Step: 956, Loss: 0.053905386477708817, Lr:0.0001\n",
      "Epoch 22, Step: 957, Loss: 0.010070599615573883, Lr:0.0001\n",
      "Epoch 22, Step: 958, Loss: 0.008399010635912418, Lr:0.0001\n",
      "Epoch 22, Step: 959, Loss: 0.00958320777863264, Lr:0.0001\n",
      "Epoch 22, Step: 960, Loss: 0.011852673254907131, Lr:0.0001\n",
      "Epoch 22, Step: 961, Loss: 0.03750128298997879, Lr:0.0001\n",
      "Epoch 22, Step: 962, Loss: 0.02326902747154236, Lr:0.0001\n",
      "Epoch 22, Step: 963, Loss: 0.23677422106266022, Lr:0.0001\n",
      "Epoch 22, Step: 964, Loss: 0.008828832767903805, Lr:0.0001\n",
      "Epoch 22, Step: 965, Loss: 0.004703502636402845, Lr:0.0001\n",
      "Epoch 22, Step: 966, Loss: 0.04026375710964203, Lr:0.0001\n",
      "Epoch 22, Step: 967, Loss: 0.17349940538406372, Lr:0.0001\n",
      "Epoch 22, Step: 968, Loss: 0.03656494617462158, Lr:0.0001\n",
      "Epoch 22, Step: 969, Loss: 0.00406633922830224, Lr:0.0001\n",
      "Epoch 22, Step: 970, Loss: 0.0035014168825000525, Lr:0.0001\n",
      "Epoch 22, Step: 971, Loss: 0.003760750638321042, Lr:0.0001\n",
      "Epoch 22, Step: 972, Loss: 0.002464610617607832, Lr:0.0001\n",
      "Epoch 22, Step: 973, Loss: 0.05107433348894119, Lr:0.0001\n",
      "Epoch 22, Step: 974, Loss: 0.0860581323504448, Lr:0.0001\n",
      "Epoch 22, Step: 975, Loss: 0.013846627436578274, Lr:0.0001\n",
      "Epoch 22, Step: 976, Loss: 0.0014231039676815271, Lr:0.0001\n",
      "Epoch 22, Step: 977, Loss: 0.0677700787782669, Lr:0.0001\n",
      "Epoch 22, Step: 978, Loss: 0.0440714955329895, Lr:0.0001\n",
      "Epoch 22, Step: 979, Loss: 0.02254076860845089, Lr:0.0001\n",
      "Epoch 22, Step: 980, Loss: 0.009038467891514301, Lr:0.0001\n",
      "Epoch 22, Step: 981, Loss: 0.02038707211613655, Lr:0.0001\n",
      "Epoch 22, Step: 982, Loss: 0.09091847389936447, Lr:0.0001\n",
      "Epoch 22, Step: 983, Loss: 0.016448501497507095, Lr:0.0001\n",
      "Epoch 22, Step: 984, Loss: 0.07533282786607742, Lr:0.0001\n",
      "Epoch 22, Step: 985, Loss: 0.003911176696419716, Lr:0.0001\n",
      "Epoch 22, Step: 986, Loss: 0.0398457795381546, Lr:0.0001\n",
      "Epoch 22, Step: 987, Loss: 0.025362292304635048, Lr:0.0001\n",
      "Epoch 22, Step: 988, Loss: 0.1067008376121521, Lr:0.0001\n",
      "Epoch 22, Step: 989, Loss: 0.05086766928434372, Lr:0.0001\n",
      "Epoch 22, Step: 990, Loss: 0.06848705559968948, Lr:0.0001\n",
      "Epoch 22, Step: 991, Loss: 0.023441132158041, Lr:0.0001\n",
      "Epoch 22, Step: 992, Loss: 0.026422778144478798, Lr:0.0001\n",
      "Epoch 22, Step: 993, Loss: 0.2472667694091797, Lr:0.0001\n",
      "Epoch 22, Step: 994, Loss: 0.2235318273305893, Lr:0.0001\n",
      "Epoch 22, Step: 995, Loss: 0.034384116530418396, Lr:0.0001\n",
      "Epoch 22, Step: 996, Loss: 0.042763106524944305, Lr:0.0001\n",
      "Epoch 22, Step: 997, Loss: 0.02902771532535553, Lr:0.0001\n",
      "Epoch 22, Step: 998, Loss: 0.22045058012008667, Lr:0.0001\n",
      "Epoch 22, Step: 999, Loss: 0.07897796481847763, Lr:0.0001\n",
      "Epoch 22, Step: 1000, Loss: 0.019401470199227333, Lr:0.0001\n",
      "Epoch 22, Step: 1001, Loss: 0.0393010638654232, Lr:0.0001\n",
      "Epoch 22, Step: 1002, Loss: 0.021381929516792297, Lr:0.0001\n",
      "Epoch 22, Step: 1003, Loss: 0.023356884717941284, Lr:0.0001\n",
      "Epoch 22, Step: 1004, Loss: 0.3089631199836731, Lr:0.0001\n",
      "Epoch 22, Step: 1005, Loss: 0.08239088207483292, Lr:0.0001\n",
      "Epoch 22, Step: 1006, Loss: 0.12107937037944794, Lr:0.0001\n",
      "Epoch 22, Step: 1007, Loss: 0.008304009214043617, Lr:0.0001\n",
      "Epoch 22, Step: 1008, Loss: 0.11059700697660446, Lr:0.0001\n",
      "Epoch 22, Step: 1009, Loss: 0.042061131447553635, Lr:0.0001\n",
      "Epoch 22, Step: 1010, Loss: 0.5291231870651245, Lr:0.0001\n",
      "Epoch 22, Step: 1011, Loss: 0.02528432384133339, Lr:0.0001\n",
      "Epoch 22, Step: 1012, Loss: 0.006345477420836687, Lr:0.0001\n",
      "Epoch 22, Step: 1013, Loss: 0.012678265571594238, Lr:0.0001\n",
      "Epoch 22, Step: 1014, Loss: 0.23046837747097015, Lr:0.0001\n",
      "Epoch 22, Step: 1015, Loss: 0.34719663858413696, Lr:0.0001\n",
      "Epoch 22, Step: 1016, Loss: 0.0829562395811081, Lr:0.0001\n",
      "Epoch 22, Step: 1017, Loss: 0.11278121173381805, Lr:0.0001\n",
      "Epoch 22, Step: 1018, Loss: 0.026739126071333885, Lr:0.0001\n",
      "Epoch 22, Step: 1019, Loss: 0.014953757636249065, Lr:0.0001\n",
      "Epoch 22, Step: 1020, Loss: 0.05080322176218033, Lr:0.0001\n",
      "Epoch 22, Step: 1021, Loss: 0.013557098805904388, Lr:0.0001\n",
      "Epoch 22, Step: 1022, Loss: 0.02836192585527897, Lr:0.0001\n",
      "Epoch 22, Step: 1023, Loss: 0.9270294904708862, Lr:0.0001\n",
      "Epoch 22, Step: 1024, Loss: 0.1716175675392151, Lr:0.0001\n",
      "Epoch 22, Step: 1025, Loss: 0.006437581963837147, Lr:0.0001\n",
      "Epoch 22, Step: 1026, Loss: 0.2454495131969452, Lr:0.0001\n",
      "Epoch 22, Step: 1027, Loss: 0.15834641456604004, Lr:0.0001\n",
      "Epoch 22, Step: 1028, Loss: 0.16647909581661224, Lr:0.0001\n",
      "Epoch 22, Step: 1029, Loss: 0.11654580384492874, Lr:0.0001\n",
      "Epoch 22, Step: 1030, Loss: 0.11151103675365448, Lr:0.0001\n",
      "Epoch 22, Step: 1031, Loss: 0.11038967221975327, Lr:0.0001\n",
      "Epoch 22, Step: 1032, Loss: 0.03588250279426575, Lr:0.0001\n",
      "Epoch 22, Step: 1033, Loss: 0.12657006084918976, Lr:0.0001\n",
      "Epoch 22, Step: 1034, Loss: 0.029376985505223274, Lr:0.0001\n",
      "Epoch 22, Step: 1035, Loss: 0.13895493745803833, Lr:0.0001\n",
      "Epoch 22, Step: 1036, Loss: 0.03037123754620552, Lr:0.0001\n",
      "Epoch 22, Step: 1037, Loss: 0.15219295024871826, Lr:0.0001\n",
      "Epoch 22, Step: 1038, Loss: 0.08388674259185791, Lr:0.0001\n",
      "Epoch 22, Step: 1039, Loss: 0.4682590067386627, Lr:0.0001\n",
      "Epoch 22, Step: 1040, Loss: 0.41135525703430176, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 22\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:16 loss: 0.2223 (0.2223) acc1: 87.5000 (87.5000) acc5: 100.0000 (100.0000) time: 0.2946 data: 0.1166 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.0039 (0.0471) acc1: 100.0000 (97.7273) acc5: 100.0000 (100.0000) time: 0.2947 data: 0.1161 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0031 (0.0641) acc1: 100.0000 (97.3214) acc5: 100.0000 (100.0000) time: 0.3059 data: 0.1195 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.1622 (0.1904) acc1: 93.7500 (92.5403) acc5: 100.0000 (100.0000) time: 0.3074 data: 0.1197 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.3173 (0.2223) acc1: 87.5000 (91.7683) acc5: 100.0000 (100.0000) time: 0.2996 data: 0.1191 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0043 (0.1813) acc1: 100.0000 (93.2598) acc5: 100.0000 (100.0000) time: 0.3145 data: 0.1234 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0043 (0.1942) acc1: 100.0000 (93.3031) acc5: 100.0000 (100.0000) time: 0.3050 data: 0.1179 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.3023 s / it)\n",
      "* Acc@1 93.303 Acc@5 100.000 loss 0.194\n",
      "Accuracy of the network on the 881 test image: 93.3%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 23, Step: 0, Loss: 0.05763918533921242, Lr:0.0001\n",
      "Epoch 23, Step: 1, Loss: 0.014035091735422611, Lr:0.0001\n",
      "Epoch 23, Step: 2, Loss: 0.004435981623828411, Lr:0.0001\n",
      "Epoch 23, Step: 3, Loss: 0.0875168889760971, Lr:0.0001\n",
      "Epoch 23, Step: 4, Loss: 0.016045821830630302, Lr:0.0001\n",
      "Epoch 23, Step: 5, Loss: 0.14489418268203735, Lr:0.0001\n",
      "Epoch 23, Step: 6, Loss: 0.03284559026360512, Lr:0.0001\n",
      "Epoch 23, Step: 7, Loss: 0.19424539804458618, Lr:0.0001\n",
      "Epoch 23, Step: 8, Loss: 0.022029781714081764, Lr:0.0001\n",
      "Epoch 23, Step: 9, Loss: 0.24640697240829468, Lr:0.0001\n",
      "Epoch 23, Step: 10, Loss: 0.012252552434802055, Lr:0.0001\n",
      "Epoch 23, Step: 11, Loss: 2.4040141105651855, Lr:0.0001\n",
      "Epoch 23, Step: 12, Loss: 0.17647752165794373, Lr:0.0001\n",
      "Epoch 23, Step: 13, Loss: 0.025172477588057518, Lr:0.0001\n",
      "Epoch 23, Step: 14, Loss: 0.20272156596183777, Lr:0.0001\n",
      "Epoch 23, Step: 15, Loss: 0.04252556711435318, Lr:0.0001\n",
      "Epoch 23, Step: 16, Loss: 0.025890449061989784, Lr:0.0001\n",
      "Epoch 23, Step: 17, Loss: 0.05638981983065605, Lr:0.0001\n",
      "Epoch 23, Step: 18, Loss: 0.0065389275550842285, Lr:0.0001\n",
      "Epoch 23, Step: 19, Loss: 0.0575653612613678, Lr:0.0001\n",
      "Epoch 23, Step: 20, Loss: 0.0772034227848053, Lr:0.0001\n",
      "Epoch 23, Step: 21, Loss: 0.029691999778151512, Lr:0.0001\n",
      "Epoch 23, Step: 22, Loss: 0.3439908027648926, Lr:0.0001\n",
      "Epoch 23, Step: 23, Loss: 0.11435708403587341, Lr:0.0001\n",
      "Epoch 23, Step: 24, Loss: 0.09346934407949448, Lr:0.0001\n",
      "Epoch 23, Step: 25, Loss: 0.09864027053117752, Lr:0.0001\n",
      "Epoch 23, Step: 26, Loss: 0.1241559311747551, Lr:0.0001\n",
      "Epoch 23, Step: 27, Loss: 0.14532725512981415, Lr:0.0001\n",
      "Epoch 23, Step: 28, Loss: 0.013324247673153877, Lr:0.0001\n",
      "Epoch 23, Step: 29, Loss: 0.1136852577328682, Lr:0.0001\n",
      "Epoch 23, Step: 30, Loss: 0.1595880538225174, Lr:0.0001\n",
      "Epoch 23, Step: 31, Loss: 0.02644416317343712, Lr:0.0001\n",
      "Epoch 23, Step: 32, Loss: 0.02968566119670868, Lr:0.0001\n",
      "Epoch 23, Step: 33, Loss: 0.39056530594825745, Lr:0.0001\n",
      "Epoch 23, Step: 34, Loss: 0.030248966068029404, Lr:0.0001\n",
      "Epoch 23, Step: 35, Loss: 0.023659782484173775, Lr:0.0001\n",
      "Epoch 23, Step: 36, Loss: 0.003520929953083396, Lr:0.0001\n",
      "Epoch 23, Step: 37, Loss: 0.041108500212430954, Lr:0.0001\n",
      "Epoch 23, Step: 38, Loss: 0.005524322856217623, Lr:0.0001\n",
      "Epoch 23, Step: 39, Loss: 0.023735251277685165, Lr:0.0001\n",
      "Epoch 23, Step: 40, Loss: 0.050010159611701965, Lr:0.0001\n",
      "Epoch 23, Step: 41, Loss: 0.2136036455631256, Lr:0.0001\n",
      "Epoch 23, Step: 42, Loss: 0.2544527053833008, Lr:0.0001\n",
      "Epoch 23, Step: 43, Loss: 1.0492238998413086, Lr:0.0001\n",
      "Epoch 23, Step: 44, Loss: 0.05708818510174751, Lr:0.0001\n",
      "Epoch 23, Step: 45, Loss: 0.1249651238322258, Lr:0.0001\n",
      "Epoch 23, Step: 46, Loss: 0.12409252673387527, Lr:0.0001\n",
      "Epoch 23, Step: 47, Loss: 0.2462725043296814, Lr:0.0001\n",
      "Epoch 23, Step: 48, Loss: 0.05404350161552429, Lr:0.0001\n",
      "Epoch 23, Step: 49, Loss: 0.2045595347881317, Lr:0.0001\n",
      "Epoch 23, Step: 50, Loss: 0.005953050218522549, Lr:0.0001\n",
      "Epoch 23, Step: 51, Loss: 0.0015601397026330233, Lr:0.0001\n",
      "Epoch 23, Step: 52, Loss: 0.031045787036418915, Lr:0.0001\n",
      "Epoch 23, Step: 53, Loss: 0.21316762268543243, Lr:0.0001\n",
      "Epoch 23, Step: 54, Loss: 0.2095160037279129, Lr:0.0001\n",
      "Epoch 23, Step: 55, Loss: 0.09387263655662537, Lr:0.0001\n",
      "Epoch 23, Step: 56, Loss: 0.007160488981753588, Lr:0.0001\n",
      "Epoch 23, Step: 57, Loss: 0.33185234665870667, Lr:0.0001\n",
      "Epoch 23, Step: 58, Loss: 0.06749861687421799, Lr:0.0001\n",
      "Epoch 23, Step: 59, Loss: 0.010738312266767025, Lr:0.0001\n",
      "Epoch 23, Step: 60, Loss: 0.005830689799040556, Lr:0.0001\n",
      "Epoch 23, Step: 61, Loss: 0.011162004433572292, Lr:0.0001\n",
      "Epoch 23, Step: 62, Loss: 0.027418876066803932, Lr:0.0001\n",
      "Epoch 23, Step: 63, Loss: 0.3218745291233063, Lr:0.0001\n",
      "Epoch 23, Step: 64, Loss: 0.11947692930698395, Lr:0.0001\n",
      "Epoch 23, Step: 65, Loss: 0.04856798052787781, Lr:0.0001\n",
      "Epoch 23, Step: 66, Loss: 0.031827110797166824, Lr:0.0001\n",
      "Epoch 23, Step: 67, Loss: 0.2531901001930237, Lr:0.0001\n",
      "Epoch 23, Step: 68, Loss: 0.032467134296894073, Lr:0.0001\n",
      "Epoch 23, Step: 69, Loss: 0.01135353371500969, Lr:0.0001\n",
      "Epoch 23, Step: 70, Loss: 0.055036332458257675, Lr:0.0001\n",
      "Epoch 23, Step: 71, Loss: 0.2996012270450592, Lr:0.0001\n",
      "Epoch 23, Step: 72, Loss: 0.4996223747730255, Lr:0.0001\n",
      "Epoch 23, Step: 73, Loss: 0.09109801799058914, Lr:0.0001\n",
      "Epoch 23, Step: 74, Loss: 0.482012003660202, Lr:0.0001\n",
      "Epoch 23, Step: 75, Loss: 0.04628393054008484, Lr:0.0001\n",
      "Epoch 23, Step: 76, Loss: 0.24377340078353882, Lr:0.0001\n",
      "Epoch 23, Step: 77, Loss: 0.11403241008520126, Lr:0.0001\n",
      "Epoch 23, Step: 78, Loss: 0.0008598572458140552, Lr:0.0001\n",
      "Epoch 23, Step: 79, Loss: 0.002905696164816618, Lr:0.0001\n",
      "Epoch 23, Step: 80, Loss: 0.008984632790088654, Lr:0.0001\n",
      "Epoch 23, Step: 81, Loss: 0.13590280711650848, Lr:0.0001\n",
      "Epoch 23, Step: 82, Loss: 0.01930561102926731, Lr:0.0001\n",
      "Epoch 23, Step: 83, Loss: 0.058455027639865875, Lr:0.0001\n",
      "Epoch 23, Step: 84, Loss: 0.08897251635789871, Lr:0.0001\n",
      "Epoch 23, Step: 85, Loss: 0.041039738804101944, Lr:0.0001\n",
      "Epoch 23, Step: 86, Loss: 0.04039366915822029, Lr:0.0001\n",
      "Epoch 23, Step: 87, Loss: 0.10617613047361374, Lr:0.0001\n",
      "Epoch 23, Step: 88, Loss: 0.023339832201600075, Lr:0.0001\n",
      "Epoch 23, Step: 89, Loss: 0.044693153351545334, Lr:0.0001\n",
      "Epoch 23, Step: 90, Loss: 0.029591161757707596, Lr:0.0001\n",
      "Epoch 23, Step: 91, Loss: 0.17955318093299866, Lr:0.0001\n",
      "Epoch 23, Step: 92, Loss: 0.06799755990505219, Lr:0.0001\n",
      "Epoch 23, Step: 93, Loss: 0.01743893139064312, Lr:0.0001\n",
      "Epoch 23, Step: 94, Loss: 0.016731036826968193, Lr:0.0001\n",
      "Epoch 23, Step: 95, Loss: 0.06360884755849838, Lr:0.0001\n",
      "Epoch 23, Step: 96, Loss: 0.08780926465988159, Lr:0.0001\n",
      "Epoch 23, Step: 97, Loss: 0.06028631329536438, Lr:0.0001\n",
      "Epoch 23, Step: 98, Loss: 0.1076916754245758, Lr:0.0001\n",
      "Epoch 23, Step: 99, Loss: 0.03826428949832916, Lr:0.0001\n",
      "Epoch 23, Step: 100, Loss: 0.012080764397978783, Lr:0.0001\n",
      "Epoch 23, Step: 101, Loss: 0.22043882310390472, Lr:0.0001\n",
      "Epoch 23, Step: 102, Loss: 0.1099596917629242, Lr:0.0001\n",
      "Epoch 23, Step: 103, Loss: 0.04599016532301903, Lr:0.0001\n",
      "Epoch 23, Step: 104, Loss: 0.10177600383758545, Lr:0.0001\n",
      "Epoch 23, Step: 105, Loss: 0.04296795278787613, Lr:0.0001\n",
      "Epoch 23, Step: 106, Loss: 0.02883809246122837, Lr:0.0001\n",
      "Epoch 23, Step: 107, Loss: 0.1407511979341507, Lr:0.0001\n",
      "Epoch 23, Step: 108, Loss: 0.007201395928859711, Lr:0.0001\n",
      "Epoch 23, Step: 109, Loss: 0.015385550446808338, Lr:0.0001\n",
      "Epoch 23, Step: 110, Loss: 0.056075356900691986, Lr:0.0001\n",
      "Epoch 23, Step: 111, Loss: 0.12758098542690277, Lr:0.0001\n",
      "Epoch 23, Step: 112, Loss: 0.034398145973682404, Lr:0.0001\n",
      "Epoch 23, Step: 113, Loss: 0.06895283609628677, Lr:0.0001\n",
      "Epoch 23, Step: 114, Loss: 0.013263030909001827, Lr:0.0001\n",
      "Epoch 23, Step: 115, Loss: 0.215683251619339, Lr:0.0001\n",
      "Epoch 23, Step: 116, Loss: 0.025124376639723778, Lr:0.0001\n",
      "Epoch 23, Step: 117, Loss: 0.006065073888748884, Lr:0.0001\n",
      "Epoch 23, Step: 118, Loss: 0.010794640518724918, Lr:0.0001\n",
      "Epoch 23, Step: 119, Loss: 0.022803081199526787, Lr:0.0001\n",
      "Epoch 23, Step: 120, Loss: 0.022829871624708176, Lr:0.0001\n",
      "Epoch 23, Step: 121, Loss: 0.11993397772312164, Lr:0.0001\n",
      "Epoch 23, Step: 122, Loss: 0.030460085719823837, Lr:0.0001\n",
      "Epoch 23, Step: 123, Loss: 0.01645703613758087, Lr:0.0001\n",
      "Epoch 23, Step: 124, Loss: 0.04524584859609604, Lr:0.0001\n",
      "Epoch 23, Step: 125, Loss: 0.036447182297706604, Lr:0.0001\n",
      "Epoch 23, Step: 126, Loss: 0.655305802822113, Lr:0.0001\n",
      "Epoch 23, Step: 127, Loss: 0.03590920567512512, Lr:0.0001\n",
      "Epoch 23, Step: 128, Loss: 0.03304862231016159, Lr:0.0001\n",
      "Epoch 23, Step: 129, Loss: 0.03669806942343712, Lr:0.0001\n",
      "Epoch 23, Step: 130, Loss: 0.1934901475906372, Lr:0.0001\n",
      "Epoch 23, Step: 131, Loss: 0.07753939181566238, Lr:0.0001\n",
      "Epoch 23, Step: 132, Loss: 0.045430637896060944, Lr:0.0001\n",
      "Epoch 23, Step: 133, Loss: 0.03826666995882988, Lr:0.0001\n",
      "Epoch 23, Step: 134, Loss: 0.15573886036872864, Lr:0.0001\n",
      "Epoch 23, Step: 135, Loss: 0.01270222570747137, Lr:0.0001\n",
      "Epoch 23, Step: 136, Loss: 0.0978274941444397, Lr:0.0001\n",
      "Epoch 23, Step: 137, Loss: 0.0630882978439331, Lr:0.0001\n",
      "Epoch 23, Step: 138, Loss: 0.3251997232437134, Lr:0.0001\n",
      "Epoch 23, Step: 139, Loss: 0.06175972521305084, Lr:0.0001\n",
      "Epoch 23, Step: 140, Loss: 0.11671850085258484, Lr:0.0001\n",
      "Epoch 23, Step: 141, Loss: 0.06626945734024048, Lr:0.0001\n",
      "Epoch 23, Step: 142, Loss: 0.15294398367404938, Lr:0.0001\n",
      "Epoch 23, Step: 143, Loss: 0.0200368482619524, Lr:0.0001\n",
      "Epoch 23, Step: 144, Loss: 0.0024632106069475412, Lr:0.0001\n",
      "Epoch 23, Step: 145, Loss: 0.019279561936855316, Lr:0.0001\n",
      "Epoch 23, Step: 146, Loss: 0.03879233077168465, Lr:0.0001\n",
      "Epoch 23, Step: 147, Loss: 0.08827463537454605, Lr:0.0001\n",
      "Epoch 23, Step: 148, Loss: 0.014922885224223137, Lr:0.0001\n",
      "Epoch 23, Step: 149, Loss: 0.07391712069511414, Lr:0.0001\n",
      "Epoch 23, Step: 150, Loss: 0.07317370921373367, Lr:0.0001\n",
      "Epoch 23, Step: 151, Loss: 0.17379581928253174, Lr:0.0001\n",
      "Epoch 23, Step: 152, Loss: 0.13116228580474854, Lr:0.0001\n",
      "Epoch 23, Step: 153, Loss: 0.007021316792815924, Lr:0.0001\n",
      "Epoch 23, Step: 154, Loss: 0.05080990120768547, Lr:0.0001\n",
      "Epoch 23, Step: 155, Loss: 0.07419165223836899, Lr:0.0001\n",
      "Epoch 23, Step: 156, Loss: 0.08378476649522781, Lr:0.0001\n",
      "Epoch 23, Step: 157, Loss: 0.020829295739531517, Lr:0.0001\n",
      "Epoch 23, Step: 158, Loss: 0.060016173869371414, Lr:0.0001\n",
      "Epoch 23, Step: 159, Loss: 0.31397056579589844, Lr:0.0001\n",
      "Epoch 23, Step: 160, Loss: 0.009099920280277729, Lr:0.0001\n",
      "Epoch 23, Step: 161, Loss: 0.06051947548985481, Lr:0.0001\n",
      "Epoch 23, Step: 162, Loss: 0.03815540671348572, Lr:0.0001\n",
      "Epoch 23, Step: 163, Loss: 0.03708431497216225, Lr:0.0001\n",
      "Epoch 23, Step: 164, Loss: 0.04610862210392952, Lr:0.0001\n",
      "Epoch 23, Step: 165, Loss: 0.2792763113975525, Lr:0.0001\n",
      "Epoch 23, Step: 166, Loss: 0.03357682004570961, Lr:0.0001\n",
      "Epoch 23, Step: 167, Loss: 0.013248885981738567, Lr:0.0001\n",
      "Epoch 23, Step: 168, Loss: 0.04483895003795624, Lr:0.0001\n",
      "Epoch 23, Step: 169, Loss: 0.07423187792301178, Lr:0.0001\n",
      "Epoch 23, Step: 170, Loss: 0.04435431584715843, Lr:0.0001\n",
      "Epoch 23, Step: 171, Loss: 0.24807925522327423, Lr:0.0001\n",
      "Epoch 23, Step: 172, Loss: 0.11800327897071838, Lr:0.0001\n",
      "Epoch 23, Step: 173, Loss: 0.028590451925992966, Lr:0.0001\n",
      "Epoch 23, Step: 174, Loss: 0.05858239158987999, Lr:0.0001\n",
      "Epoch 23, Step: 175, Loss: 0.03493291884660721, Lr:0.0001\n",
      "Epoch 23, Step: 176, Loss: 0.09297681599855423, Lr:0.0001\n",
      "Epoch 23, Step: 177, Loss: 0.0779058188199997, Lr:0.0001\n",
      "Epoch 23, Step: 178, Loss: 0.019028112292289734, Lr:0.0001\n",
      "Epoch 23, Step: 179, Loss: 0.0053601996041834354, Lr:0.0001\n",
      "Epoch 23, Step: 180, Loss: 0.021676065400242805, Lr:0.0001\n",
      "Epoch 23, Step: 181, Loss: 0.0317857451736927, Lr:0.0001\n",
      "Epoch 23, Step: 182, Loss: 0.061871059238910675, Lr:0.0001\n",
      "Epoch 23, Step: 183, Loss: 0.24899497628211975, Lr:0.0001\n",
      "Epoch 23, Step: 184, Loss: 0.16713325679302216, Lr:0.0001\n",
      "Epoch 23, Step: 185, Loss: 0.12442716956138611, Lr:0.0001\n",
      "Epoch 23, Step: 186, Loss: 0.3745429515838623, Lr:0.0001\n",
      "Epoch 23, Step: 187, Loss: 0.13282853364944458, Lr:0.0001\n",
      "Epoch 23, Step: 188, Loss: 0.14808736741542816, Lr:0.0001\n",
      "Epoch 23, Step: 189, Loss: 0.04120927304029465, Lr:0.0001\n",
      "Epoch 23, Step: 190, Loss: 0.02614773064851761, Lr:0.0001\n",
      "Epoch 23, Step: 191, Loss: 0.04500283673405647, Lr:0.0001\n",
      "Epoch 23, Step: 192, Loss: 0.18524189293384552, Lr:0.0001\n",
      "Epoch 23, Step: 193, Loss: 0.43682509660720825, Lr:0.0001\n",
      "Epoch 23, Step: 194, Loss: 0.05835005268454552, Lr:0.0001\n",
      "Epoch 23, Step: 195, Loss: 0.011217918246984482, Lr:0.0001\n",
      "Epoch 23, Step: 196, Loss: 0.027948882430791855, Lr:0.0001\n",
      "Epoch 23, Step: 197, Loss: 0.0744348093867302, Lr:0.0001\n",
      "Epoch 23, Step: 198, Loss: 0.07399965822696686, Lr:0.0001\n",
      "Epoch 23, Step: 199, Loss: 0.018907688558101654, Lr:0.0001\n",
      "Epoch 23, Step: 200, Loss: 0.07584702968597412, Lr:0.0001\n",
      "Epoch 23, Step: 201, Loss: 0.04901346191763878, Lr:0.0001\n",
      "Epoch 23, Step: 202, Loss: 0.04596656188368797, Lr:0.0001\n",
      "Epoch 23, Step: 203, Loss: 0.07945986837148666, Lr:0.0001\n",
      "Epoch 23, Step: 204, Loss: 0.012314887717366219, Lr:0.0001\n",
      "Epoch 23, Step: 205, Loss: 0.04704931005835533, Lr:0.0001\n",
      "Epoch 23, Step: 206, Loss: 0.009767476469278336, Lr:0.0001\n",
      "Epoch 23, Step: 207, Loss: 0.1656474620103836, Lr:0.0001\n",
      "Epoch 23, Step: 208, Loss: 0.15501585602760315, Lr:0.0001\n",
      "Epoch 23, Step: 209, Loss: 0.3702867925167084, Lr:0.0001\n",
      "Epoch 23, Step: 210, Loss: 0.004909602925181389, Lr:0.0001\n",
      "Epoch 23, Step: 211, Loss: 0.0788024514913559, Lr:0.0001\n",
      "Epoch 23, Step: 212, Loss: 0.046554964035749435, Lr:0.0001\n",
      "Epoch 23, Step: 213, Loss: 0.061600301414728165, Lr:0.0001\n",
      "Epoch 23, Step: 214, Loss: 0.16171017289161682, Lr:0.0001\n",
      "Epoch 23, Step: 215, Loss: 0.0467282310128212, Lr:0.0001\n",
      "Epoch 23, Step: 216, Loss: 0.06426063179969788, Lr:0.0001\n",
      "Epoch 23, Step: 217, Loss: 0.06351229548454285, Lr:0.0001\n",
      "Epoch 23, Step: 218, Loss: 0.1716839224100113, Lr:0.0001\n",
      "Epoch 23, Step: 219, Loss: 0.004248164594173431, Lr:0.0001\n",
      "Epoch 23, Step: 220, Loss: 0.016194751486182213, Lr:0.0001\n",
      "Epoch 23, Step: 221, Loss: 0.10284297168254852, Lr:0.0001\n",
      "Epoch 23, Step: 222, Loss: 0.002768910024315119, Lr:0.0001\n",
      "Epoch 23, Step: 223, Loss: 0.02826559916138649, Lr:0.0001\n",
      "Epoch 23, Step: 224, Loss: 0.006394353695213795, Lr:0.0001\n",
      "Epoch 23, Step: 225, Loss: 0.39181604981422424, Lr:0.0001\n",
      "Epoch 23, Step: 226, Loss: 0.04745814949274063, Lr:0.0001\n",
      "Epoch 23, Step: 227, Loss: 0.008928532712161541, Lr:0.0001\n",
      "Epoch 23, Step: 228, Loss: 0.10264859348535538, Lr:0.0001\n",
      "Epoch 23, Step: 229, Loss: 0.03948765620589256, Lr:0.0001\n",
      "Epoch 23, Step: 230, Loss: 0.017412880435585976, Lr:0.0001\n",
      "Epoch 23, Step: 231, Loss: 0.01818900927901268, Lr:0.0001\n",
      "Epoch 23, Step: 232, Loss: 0.001719639403745532, Lr:0.0001\n",
      "Epoch 23, Step: 233, Loss: 0.03481772169470787, Lr:0.0001\n",
      "Epoch 23, Step: 234, Loss: 0.03867242857813835, Lr:0.0001\n",
      "Epoch 23, Step: 235, Loss: 0.26726794242858887, Lr:0.0001\n",
      "Epoch 23, Step: 236, Loss: 0.005346904508769512, Lr:0.0001\n",
      "Epoch 23, Step: 237, Loss: 0.061565957963466644, Lr:0.0001\n",
      "Epoch 23, Step: 238, Loss: 0.06825175136327744, Lr:0.0001\n",
      "Epoch 23, Step: 239, Loss: 0.19834133982658386, Lr:0.0001\n",
      "Epoch 23, Step: 240, Loss: 0.4178207814693451, Lr:0.0001\n",
      "Epoch 23, Step: 241, Loss: 0.010502506047487259, Lr:0.0001\n",
      "Epoch 23, Step: 242, Loss: 0.04464399814605713, Lr:0.0001\n",
      "Epoch 23, Step: 243, Loss: 0.0572601743042469, Lr:0.0001\n",
      "Epoch 23, Step: 244, Loss: 0.032965485006570816, Lr:0.0001\n",
      "Epoch 23, Step: 245, Loss: 0.2548109292984009, Lr:0.0001\n",
      "Epoch 23, Step: 246, Loss: 0.025101331993937492, Lr:0.0001\n",
      "Epoch 23, Step: 247, Loss: 0.09837225079536438, Lr:0.0001\n",
      "Epoch 23, Step: 248, Loss: 0.10351387411355972, Lr:0.0001\n",
      "Epoch 23, Step: 249, Loss: 0.009542971849441528, Lr:0.0001\n",
      "Epoch 23, Step: 250, Loss: 0.00848615262657404, Lr:0.0001\n",
      "Epoch 23, Step: 251, Loss: 0.03564049303531647, Lr:0.0001\n",
      "Epoch 23, Step: 252, Loss: 0.024824874475598335, Lr:0.0001\n",
      "Epoch 23, Step: 253, Loss: 0.011194339022040367, Lr:0.0001\n",
      "Epoch 23, Step: 254, Loss: 0.0195771437138319, Lr:0.0001\n",
      "Epoch 23, Step: 255, Loss: 0.02969302050769329, Lr:0.0001\n",
      "Epoch 23, Step: 256, Loss: 0.01470289658755064, Lr:0.0001\n",
      "Epoch 23, Step: 257, Loss: 0.7760608196258545, Lr:0.0001\n",
      "Epoch 23, Step: 258, Loss: 0.11793283373117447, Lr:0.0001\n",
      "Epoch 23, Step: 259, Loss: 0.03258257731795311, Lr:0.0001\n",
      "Epoch 23, Step: 260, Loss: 0.02246641367673874, Lr:0.0001\n",
      "Epoch 23, Step: 261, Loss: 0.005172763951122761, Lr:0.0001\n",
      "Epoch 23, Step: 262, Loss: 0.220511332154274, Lr:0.0001\n",
      "Epoch 23, Step: 263, Loss: 0.04042612016201019, Lr:0.0001\n",
      "Epoch 23, Step: 264, Loss: 0.16582132875919342, Lr:0.0001\n",
      "Epoch 23, Step: 265, Loss: 0.08618823438882828, Lr:0.0001\n",
      "Epoch 23, Step: 266, Loss: 0.022336207330226898, Lr:0.0001\n",
      "Epoch 23, Step: 267, Loss: 0.03025573492050171, Lr:0.0001\n",
      "Epoch 23, Step: 268, Loss: 0.4098604619503021, Lr:0.0001\n",
      "Epoch 23, Step: 269, Loss: 0.07894356548786163, Lr:0.0001\n",
      "Epoch 23, Step: 270, Loss: 0.2011541724205017, Lr:0.0001\n",
      "Epoch 23, Step: 271, Loss: 0.4609623849391937, Lr:0.0001\n",
      "Epoch 23, Step: 272, Loss: 0.0699542686343193, Lr:0.0001\n",
      "Epoch 23, Step: 273, Loss: 0.01189409289509058, Lr:0.0001\n",
      "Epoch 23, Step: 274, Loss: 0.21811647713184357, Lr:0.0001\n",
      "Epoch 23, Step: 275, Loss: 0.10301506519317627, Lr:0.0001\n",
      "Epoch 23, Step: 276, Loss: 0.018969999626278877, Lr:0.0001\n",
      "Epoch 23, Step: 277, Loss: 0.45156389474868774, Lr:0.0001\n",
      "Epoch 23, Step: 278, Loss: 0.20367489755153656, Lr:0.0001\n",
      "Epoch 23, Step: 279, Loss: 0.042430780827999115, Lr:0.0001\n",
      "Epoch 23, Step: 280, Loss: 0.16983701288700104, Lr:0.0001\n",
      "Epoch 23, Step: 281, Loss: 0.0003338757378514856, Lr:0.0001\n",
      "Epoch 23, Step: 282, Loss: 0.05284374579787254, Lr:0.0001\n",
      "Epoch 23, Step: 283, Loss: 0.07944910228252411, Lr:0.0001\n",
      "Epoch 23, Step: 284, Loss: 0.020987922325730324, Lr:0.0001\n",
      "Epoch 23, Step: 285, Loss: 0.11699827015399933, Lr:0.0001\n",
      "Epoch 23, Step: 286, Loss: 0.02052117884159088, Lr:0.0001\n",
      "Epoch 23, Step: 287, Loss: 0.08937404304742813, Lr:0.0001\n",
      "Epoch 23, Step: 288, Loss: 0.08495877683162689, Lr:0.0001\n",
      "Epoch 23, Step: 289, Loss: 0.0692368894815445, Lr:0.0001\n",
      "Epoch 23, Step: 290, Loss: 0.04090108349919319, Lr:0.0001\n",
      "Epoch 23, Step: 291, Loss: 0.034561365842819214, Lr:0.0001\n",
      "Epoch 23, Step: 292, Loss: 0.049029700458049774, Lr:0.0001\n",
      "Epoch 23, Step: 293, Loss: 0.2807832956314087, Lr:0.0001\n",
      "Epoch 23, Step: 294, Loss: 0.019257979467511177, Lr:0.0001\n",
      "Epoch 23, Step: 295, Loss: 0.03657897189259529, Lr:0.0001\n",
      "Epoch 23, Step: 296, Loss: 0.00787574052810669, Lr:0.0001\n",
      "Epoch 23, Step: 297, Loss: 0.011727334931492805, Lr:0.0001\n",
      "Epoch 23, Step: 298, Loss: 0.010456912219524384, Lr:0.0001\n",
      "Epoch 23, Step: 299, Loss: 0.25863850116729736, Lr:0.0001\n",
      "Epoch 23, Step: 300, Loss: 0.02536049485206604, Lr:0.0001\n",
      "Epoch 23, Step: 301, Loss: 0.024318818002939224, Lr:0.0001\n",
      "Epoch 23, Step: 302, Loss: 0.008403603918850422, Lr:0.0001\n",
      "Epoch 23, Step: 303, Loss: 0.008524681441485882, Lr:0.0001\n",
      "Epoch 23, Step: 304, Loss: 0.06436734646558762, Lr:0.0001\n",
      "Epoch 23, Step: 305, Loss: 0.1683819442987442, Lr:0.0001\n",
      "Epoch 23, Step: 306, Loss: 0.01655973680317402, Lr:0.0001\n",
      "Epoch 23, Step: 307, Loss: 0.22587865591049194, Lr:0.0001\n",
      "Epoch 23, Step: 308, Loss: 0.03524596244096756, Lr:0.0001\n",
      "Epoch 23, Step: 309, Loss: 0.01731327548623085, Lr:0.0001\n",
      "Epoch 23, Step: 310, Loss: 0.030194584280252457, Lr:0.0001\n",
      "Epoch 23, Step: 311, Loss: 0.09970906376838684, Lr:0.0001\n",
      "Epoch 23, Step: 312, Loss: 0.006435655523091555, Lr:0.0001\n",
      "Epoch 23, Step: 313, Loss: 0.18720583617687225, Lr:0.0001\n",
      "Epoch 23, Step: 314, Loss: 0.04558463767170906, Lr:0.0001\n",
      "Epoch 23, Step: 315, Loss: 0.08218253403902054, Lr:0.0001\n",
      "Epoch 23, Step: 316, Loss: 0.10661101341247559, Lr:0.0001\n",
      "Epoch 23, Step: 317, Loss: 0.023330580443143845, Lr:0.0001\n",
      "Epoch 23, Step: 318, Loss: 0.5082228779792786, Lr:0.0001\n",
      "Epoch 23, Step: 319, Loss: 0.04753553867340088, Lr:0.0001\n",
      "Epoch 23, Step: 320, Loss: 0.1927158385515213, Lr:0.0001\n",
      "Epoch 23, Step: 321, Loss: 0.03619030863046646, Lr:0.0001\n",
      "Epoch 23, Step: 322, Loss: 0.007969832047820091, Lr:0.0001\n",
      "Epoch 23, Step: 323, Loss: 0.08207817375659943, Lr:0.0001\n",
      "Epoch 23, Step: 324, Loss: 0.056529175490140915, Lr:0.0001\n",
      "Epoch 23, Step: 325, Loss: 0.025416741147637367, Lr:0.0001\n",
      "Epoch 23, Step: 326, Loss: 0.303213894367218, Lr:0.0001\n",
      "Epoch 23, Step: 327, Loss: 0.0493326336145401, Lr:0.0001\n",
      "Epoch 23, Step: 328, Loss: 0.006811183877289295, Lr:0.0001\n",
      "Epoch 23, Step: 329, Loss: 0.06612055748701096, Lr:0.0001\n",
      "Epoch 23, Step: 330, Loss: 0.004745736252516508, Lr:0.0001\n",
      "Epoch 23, Step: 331, Loss: 0.030319154262542725, Lr:0.0001\n",
      "Epoch 23, Step: 332, Loss: 0.02483357861638069, Lr:0.0001\n",
      "Epoch 23, Step: 333, Loss: 0.05777299776673317, Lr:0.0001\n",
      "Epoch 23, Step: 334, Loss: 0.5216807126998901, Lr:0.0001\n",
      "Epoch 23, Step: 335, Loss: 0.017793014645576477, Lr:0.0001\n",
      "Epoch 23, Step: 336, Loss: 0.00683831050992012, Lr:0.0001\n",
      "Epoch 23, Step: 337, Loss: 0.33095869421958923, Lr:0.0001\n",
      "Epoch 23, Step: 338, Loss: 0.008539123460650444, Lr:0.0001\n",
      "Epoch 23, Step: 339, Loss: 0.14273729920387268, Lr:0.0001\n",
      "Epoch 23, Step: 340, Loss: 0.03638230264186859, Lr:0.0001\n",
      "Epoch 23, Step: 341, Loss: 0.0022835584823042154, Lr:0.0001\n",
      "Epoch 23, Step: 342, Loss: 0.052914224565029144, Lr:0.0001\n",
      "Epoch 23, Step: 343, Loss: 0.11234039813280106, Lr:0.0001\n",
      "Epoch 23, Step: 344, Loss: 0.0020912867039442062, Lr:0.0001\n",
      "Epoch 23, Step: 345, Loss: 0.21296380460262299, Lr:0.0001\n",
      "Epoch 23, Step: 346, Loss: 0.021562041714787483, Lr:0.0001\n",
      "Epoch 23, Step: 347, Loss: 0.02928326092660427, Lr:0.0001\n",
      "Epoch 23, Step: 348, Loss: 0.061207763850688934, Lr:0.0001\n",
      "Epoch 23, Step: 349, Loss: 0.07965067774057388, Lr:0.0001\n",
      "Epoch 23, Step: 350, Loss: 0.03231792151927948, Lr:0.0001\n",
      "Epoch 23, Step: 351, Loss: 0.14213217794895172, Lr:0.0001\n",
      "Epoch 23, Step: 352, Loss: 0.005531333386898041, Lr:0.0001\n",
      "Epoch 23, Step: 353, Loss: 0.16354985535144806, Lr:0.0001\n",
      "Epoch 23, Step: 354, Loss: 0.017108676955103874, Lr:0.0001\n",
      "Epoch 23, Step: 355, Loss: 0.08601108193397522, Lr:0.0001\n",
      "Epoch 23, Step: 356, Loss: 0.05650859326124191, Lr:0.0001\n",
      "Epoch 23, Step: 357, Loss: 0.027832163497805595, Lr:0.0001\n",
      "Epoch 23, Step: 358, Loss: 0.11049918830394745, Lr:0.0001\n",
      "Epoch 23, Step: 359, Loss: 0.07612442970275879, Lr:0.0001\n",
      "Epoch 23, Step: 360, Loss: 0.05995459854602814, Lr:0.0001\n",
      "Epoch 23, Step: 361, Loss: 0.110821932554245, Lr:0.0001\n",
      "Epoch 23, Step: 362, Loss: 0.00900933239609003, Lr:0.0001\n",
      "Epoch 23, Step: 363, Loss: 0.10617222636938095, Lr:0.0001\n",
      "Epoch 23, Step: 364, Loss: 0.2792034447193146, Lr:0.0001\n",
      "Epoch 23, Step: 365, Loss: 0.02650272101163864, Lr:0.0001\n",
      "Epoch 23, Step: 366, Loss: 0.07526502013206482, Lr:0.0001\n",
      "Epoch 23, Step: 367, Loss: 0.023221665993332863, Lr:0.0001\n",
      "Epoch 23, Step: 368, Loss: 0.1698152720928192, Lr:0.0001\n",
      "Epoch 23, Step: 369, Loss: 0.004222998861223459, Lr:0.0001\n",
      "Epoch 23, Step: 370, Loss: 0.04108526557683945, Lr:0.0001\n",
      "Epoch 23, Step: 371, Loss: 0.10400357842445374, Lr:0.0001\n",
      "Epoch 23, Step: 372, Loss: 0.006844013929367065, Lr:0.0001\n",
      "Epoch 23, Step: 373, Loss: 0.08725596219301224, Lr:0.0001\n",
      "Epoch 23, Step: 374, Loss: 0.03546641021966934, Lr:0.0001\n",
      "Epoch 23, Step: 375, Loss: 0.06675946712493896, Lr:0.0001\n",
      "Epoch 23, Step: 376, Loss: 0.13786959648132324, Lr:0.0001\n",
      "Epoch 23, Step: 377, Loss: 0.046029362827539444, Lr:0.0001\n",
      "Epoch 23, Step: 378, Loss: 0.0883813351392746, Lr:0.0001\n",
      "Epoch 23, Step: 379, Loss: 0.041218388825654984, Lr:0.0001\n",
      "Epoch 23, Step: 380, Loss: 0.03130357712507248, Lr:0.0001\n",
      "Epoch 23, Step: 381, Loss: 0.004714516922831535, Lr:0.0001\n",
      "Epoch 23, Step: 382, Loss: 0.046800244599580765, Lr:0.0001\n",
      "Epoch 23, Step: 383, Loss: 0.009938396513462067, Lr:0.0001\n",
      "Epoch 23, Step: 384, Loss: 0.006714196410030127, Lr:0.0001\n",
      "Epoch 23, Step: 385, Loss: 0.037477266043424606, Lr:0.0001\n",
      "Epoch 23, Step: 386, Loss: 0.10608761757612228, Lr:0.0001\n",
      "Epoch 23, Step: 387, Loss: 0.016173671931028366, Lr:0.0001\n",
      "Epoch 23, Step: 388, Loss: 0.014395153149962425, Lr:0.0001\n",
      "Epoch 23, Step: 389, Loss: 0.015415888279676437, Lr:0.0001\n",
      "Epoch 23, Step: 390, Loss: 0.04279714077711105, Lr:0.0001\n",
      "Epoch 23, Step: 391, Loss: 0.1638217568397522, Lr:0.0001\n",
      "Epoch 23, Step: 392, Loss: 0.029448848217725754, Lr:0.0001\n",
      "Epoch 23, Step: 393, Loss: 0.09960998594760895, Lr:0.0001\n",
      "Epoch 23, Step: 394, Loss: 0.07667525112628937, Lr:0.0001\n",
      "Epoch 23, Step: 395, Loss: 0.0604972168803215, Lr:0.0001\n",
      "Epoch 23, Step: 396, Loss: 0.10375235229730606, Lr:0.0001\n",
      "Epoch 23, Step: 397, Loss: 0.19095014035701752, Lr:0.0001\n",
      "Epoch 23, Step: 398, Loss: 0.02894028276205063, Lr:0.0001\n",
      "Epoch 23, Step: 399, Loss: 0.028612177819013596, Lr:0.0001\n",
      "Epoch 23, Step: 400, Loss: 0.10836654901504517, Lr:0.0001\n",
      "Epoch 23, Step: 401, Loss: 0.025351837277412415, Lr:0.0001\n",
      "Epoch 23, Step: 402, Loss: 0.2096167355775833, Lr:0.0001\n",
      "Epoch 23, Step: 403, Loss: 0.0572432279586792, Lr:0.0001\n",
      "Epoch 23, Step: 404, Loss: 0.04430457949638367, Lr:0.0001\n",
      "Epoch 23, Step: 405, Loss: 0.0898723378777504, Lr:0.0001\n",
      "Epoch 23, Step: 406, Loss: 0.24580053985118866, Lr:0.0001\n",
      "Epoch 23, Step: 407, Loss: 0.017961839213967323, Lr:0.0001\n",
      "Epoch 23, Step: 408, Loss: 0.022693989798426628, Lr:0.0001\n",
      "Epoch 23, Step: 409, Loss: 0.008044869638979435, Lr:0.0001\n",
      "Epoch 23, Step: 410, Loss: 0.005522534251213074, Lr:0.0001\n",
      "Epoch 23, Step: 411, Loss: 0.014281860552728176, Lr:0.0001\n",
      "Epoch 23, Step: 412, Loss: 0.057890165597200394, Lr:0.0001\n",
      "Epoch 23, Step: 413, Loss: 0.2545042634010315, Lr:0.0001\n",
      "Epoch 23, Step: 414, Loss: 0.11855193972587585, Lr:0.0001\n",
      "Epoch 23, Step: 415, Loss: 0.08221513032913208, Lr:0.0001\n",
      "Epoch 23, Step: 416, Loss: 0.004664197098463774, Lr:0.0001\n",
      "Epoch 23, Step: 417, Loss: 0.21152810752391815, Lr:0.0001\n",
      "Epoch 23, Step: 418, Loss: 0.09153036773204803, Lr:0.0001\n",
      "Epoch 23, Step: 419, Loss: 0.012795521877706051, Lr:0.0001\n",
      "Epoch 23, Step: 420, Loss: 0.02668416127562523, Lr:0.0001\n",
      "Epoch 23, Step: 421, Loss: 0.007175032515078783, Lr:0.0001\n",
      "Epoch 23, Step: 422, Loss: 0.05604377016425133, Lr:0.0001\n",
      "Epoch 23, Step: 423, Loss: 0.0005342791555449367, Lr:0.0001\n",
      "Epoch 23, Step: 424, Loss: 0.12702777981758118, Lr:0.0001\n",
      "Epoch 23, Step: 425, Loss: 0.011243455111980438, Lr:0.0001\n",
      "Epoch 23, Step: 426, Loss: 0.0059189628809690475, Lr:0.0001\n",
      "Epoch 23, Step: 427, Loss: 0.10263438522815704, Lr:0.0001\n",
      "Epoch 23, Step: 428, Loss: 0.060386426746845245, Lr:0.0001\n",
      "Epoch 23, Step: 429, Loss: 0.017857875674962997, Lr:0.0001\n",
      "Epoch 23, Step: 430, Loss: 0.0012622320791706443, Lr:0.0001\n",
      "Epoch 23, Step: 431, Loss: 0.049282293766736984, Lr:0.0001\n",
      "Epoch 23, Step: 432, Loss: 0.038417331874370575, Lr:0.0001\n",
      "Epoch 23, Step: 433, Loss: 0.01293187402188778, Lr:0.0001\n",
      "Epoch 23, Step: 434, Loss: 0.10756295919418335, Lr:0.0001\n",
      "Epoch 23, Step: 435, Loss: 0.028303036466240883, Lr:0.0001\n",
      "Epoch 23, Step: 436, Loss: 0.011612377129495144, Lr:0.0001\n",
      "Epoch 23, Step: 437, Loss: 0.02199827879667282, Lr:0.0001\n",
      "Epoch 23, Step: 438, Loss: 0.24805831909179688, Lr:0.0001\n",
      "Epoch 23, Step: 439, Loss: 0.12896759808063507, Lr:0.0001\n",
      "Epoch 23, Step: 440, Loss: 0.28667858242988586, Lr:0.0001\n",
      "Epoch 23, Step: 441, Loss: 0.09092819690704346, Lr:0.0001\n",
      "Epoch 23, Step: 442, Loss: 0.025282548740506172, Lr:0.0001\n",
      "Epoch 23, Step: 443, Loss: 0.27506065368652344, Lr:0.0001\n",
      "Epoch 23, Step: 444, Loss: 0.12666644155979156, Lr:0.0001\n",
      "Epoch 23, Step: 445, Loss: 0.02122812718153, Lr:0.0001\n",
      "Epoch 23, Step: 446, Loss: 0.42956510186195374, Lr:0.0001\n",
      "Epoch 23, Step: 447, Loss: 0.07176702469587326, Lr:0.0001\n",
      "Epoch 23, Step: 448, Loss: 0.0075913891196250916, Lr:0.0001\n",
      "Epoch 23, Step: 449, Loss: 0.2437179833650589, Lr:0.0001\n",
      "Epoch 23, Step: 450, Loss: 0.07177724689245224, Lr:0.0001\n",
      "Epoch 23, Step: 451, Loss: 0.012803010642528534, Lr:0.0001\n",
      "Epoch 23, Step: 452, Loss: 0.21545372903347015, Lr:0.0001\n",
      "Epoch 23, Step: 453, Loss: 0.02466769516468048, Lr:0.0001\n",
      "Epoch 23, Step: 454, Loss: 0.11166508495807648, Lr:0.0001\n",
      "Epoch 23, Step: 455, Loss: 0.04681840538978577, Lr:0.0001\n",
      "Epoch 23, Step: 456, Loss: 0.030988439917564392, Lr:0.0001\n",
      "Epoch 23, Step: 457, Loss: 0.06261307001113892, Lr:0.0001\n",
      "Epoch 23, Step: 458, Loss: 0.06873559951782227, Lr:0.0001\n",
      "Epoch 23, Step: 459, Loss: 0.041849084198474884, Lr:0.0001\n",
      "Epoch 23, Step: 460, Loss: 0.11292961984872818, Lr:0.0001\n",
      "Epoch 23, Step: 461, Loss: 0.1729784458875656, Lr:0.0001\n",
      "Epoch 23, Step: 462, Loss: 0.1183430477976799, Lr:0.0001\n",
      "Epoch 23, Step: 463, Loss: 0.058373235166072845, Lr:0.0001\n",
      "Epoch 23, Step: 464, Loss: 0.0645279660820961, Lr:0.0001\n",
      "Epoch 23, Step: 465, Loss: 0.0752718523144722, Lr:0.0001\n",
      "Epoch 23, Step: 466, Loss: 0.1898457556962967, Lr:0.0001\n",
      "Epoch 23, Step: 467, Loss: 0.017485443502664566, Lr:0.0001\n",
      "Epoch 23, Step: 468, Loss: 0.042384061962366104, Lr:0.0001\n",
      "Epoch 23, Step: 469, Loss: 0.09793975949287415, Lr:0.0001\n",
      "Epoch 23, Step: 470, Loss: 0.02873747982084751, Lr:0.0001\n",
      "Epoch 23, Step: 471, Loss: 0.03870277851819992, Lr:0.0001\n",
      "Epoch 23, Step: 472, Loss: 0.036143604665994644, Lr:0.0001\n",
      "Epoch 23, Step: 473, Loss: 0.19469107687473297, Lr:0.0001\n",
      "Epoch 23, Step: 474, Loss: 0.17740418016910553, Lr:0.0001\n",
      "Epoch 23, Step: 475, Loss: 0.15810999274253845, Lr:0.0001\n",
      "Epoch 23, Step: 476, Loss: 0.1008865237236023, Lr:0.0001\n",
      "Epoch 23, Step: 477, Loss: 0.09091860800981522, Lr:0.0001\n",
      "Epoch 23, Step: 478, Loss: 0.004636634141206741, Lr:0.0001\n",
      "Epoch 23, Step: 479, Loss: 0.06841091066598892, Lr:0.0001\n",
      "Epoch 23, Step: 480, Loss: 0.028435807675123215, Lr:0.0001\n",
      "Epoch 23, Step: 481, Loss: 0.006243032403290272, Lr:0.0001\n",
      "Epoch 23, Step: 482, Loss: 0.11223433911800385, Lr:0.0001\n",
      "Epoch 23, Step: 483, Loss: 0.03526069596409798, Lr:0.0001\n",
      "Epoch 23, Step: 484, Loss: 0.1535152643918991, Lr:0.0001\n",
      "Epoch 23, Step: 485, Loss: 0.025922652333974838, Lr:0.0001\n",
      "Epoch 23, Step: 486, Loss: 0.13026203215122223, Lr:0.0001\n",
      "Epoch 23, Step: 487, Loss: 0.15435166656970978, Lr:0.0001\n",
      "Epoch 23, Step: 488, Loss: 0.01147396769374609, Lr:0.0001\n",
      "Epoch 23, Step: 489, Loss: 0.02062065526843071, Lr:0.0001\n",
      "Epoch 23, Step: 490, Loss: 0.049761392176151276, Lr:0.0001\n",
      "Epoch 23, Step: 491, Loss: 0.1497270166873932, Lr:0.0001\n",
      "Epoch 23, Step: 492, Loss: 0.04751910641789436, Lr:0.0001\n",
      "Epoch 23, Step: 493, Loss: 0.07959990948438644, Lr:0.0001\n",
      "Epoch 23, Step: 494, Loss: 0.03704339265823364, Lr:0.0001\n",
      "Epoch 23, Step: 495, Loss: 0.00848938338458538, Lr:0.0001\n",
      "Epoch 23, Step: 496, Loss: 0.37232521176338196, Lr:0.0001\n",
      "Epoch 23, Step: 497, Loss: 0.10489547252655029, Lr:0.0001\n",
      "Epoch 23, Step: 498, Loss: 0.011660200543701649, Lr:0.0001\n",
      "Epoch 23, Step: 499, Loss: 0.1989775449037552, Lr:0.0001\n",
      "Epoch 23, Step: 500, Loss: 0.04217643290758133, Lr:0.0001\n",
      "Epoch 23, Step: 501, Loss: 0.0517432764172554, Lr:0.0001\n",
      "Epoch 23, Step: 502, Loss: 0.005560190416872501, Lr:0.0001\n",
      "Epoch 23, Step: 503, Loss: 0.002047817688435316, Lr:0.0001\n",
      "Epoch 23, Step: 504, Loss: 0.02877984195947647, Lr:0.0001\n",
      "Epoch 23, Step: 505, Loss: 0.029285209253430367, Lr:0.0001\n",
      "Epoch 23, Step: 506, Loss: 0.07978921383619308, Lr:0.0001\n",
      "Epoch 23, Step: 507, Loss: 0.18173940479755402, Lr:0.0001\n",
      "Epoch 23, Step: 508, Loss: 0.1867375522851944, Lr:0.0001\n",
      "Epoch 23, Step: 509, Loss: 0.013092752546072006, Lr:0.0001\n",
      "Epoch 23, Step: 510, Loss: 0.02826884761452675, Lr:0.0001\n",
      "Epoch 23, Step: 511, Loss: 0.19552725553512573, Lr:0.0001\n",
      "Epoch 23, Step: 512, Loss: 0.10767101496458054, Lr:0.0001\n",
      "Epoch 23, Step: 513, Loss: 0.02199425734579563, Lr:0.0001\n",
      "Epoch 23, Step: 514, Loss: 0.07624556869268417, Lr:0.0001\n",
      "Epoch 23, Step: 515, Loss: 0.0820700153708458, Lr:0.0001\n",
      "Epoch 23, Step: 516, Loss: 0.007910228334367275, Lr:0.0001\n",
      "Epoch 23, Step: 517, Loss: 0.1061873584985733, Lr:0.0001\n",
      "Epoch 23, Step: 518, Loss: 0.01750246062874794, Lr:0.0001\n",
      "Epoch 23, Step: 519, Loss: 0.0026222108863294125, Lr:0.0001\n",
      "Epoch 23, Step: 520, Loss: 0.01297115720808506, Lr:0.0001\n",
      "Epoch 23, Step: 521, Loss: 0.01822046935558319, Lr:0.0001\n",
      "Epoch 23, Step: 522, Loss: 0.020103247836232185, Lr:0.0001\n",
      "Epoch 23, Step: 523, Loss: 0.04678316041827202, Lr:0.0001\n",
      "Epoch 23, Step: 524, Loss: 0.16498896479606628, Lr:0.0001\n",
      "Epoch 23, Step: 525, Loss: 0.2679069936275482, Lr:0.0001\n",
      "Epoch 23, Step: 526, Loss: 0.044636525213718414, Lr:0.0001\n",
      "Epoch 23, Step: 527, Loss: 0.025119025260210037, Lr:0.0001\n",
      "Epoch 23, Step: 528, Loss: 0.03909437358379364, Lr:0.0001\n",
      "Epoch 23, Step: 529, Loss: 0.09061464667320251, Lr:0.0001\n",
      "Epoch 23, Step: 530, Loss: 0.07520106434822083, Lr:0.0001\n",
      "Epoch 23, Step: 531, Loss: 0.05246352031826973, Lr:0.0001\n",
      "Epoch 23, Step: 532, Loss: 0.033993177115917206, Lr:0.0001\n",
      "Epoch 23, Step: 533, Loss: 0.022637587040662766, Lr:0.0001\n",
      "Epoch 23, Step: 534, Loss: 0.015137547627091408, Lr:0.0001\n",
      "Epoch 23, Step: 535, Loss: 0.009076861664652824, Lr:0.0001\n",
      "Epoch 23, Step: 536, Loss: 0.004718177951872349, Lr:0.0001\n",
      "Epoch 23, Step: 537, Loss: 0.015855835750699043, Lr:0.0001\n",
      "Epoch 23, Step: 538, Loss: 0.14396418631076813, Lr:0.0001\n",
      "Epoch 23, Step: 539, Loss: 0.16960714757442474, Lr:0.0001\n",
      "Epoch 23, Step: 540, Loss: 0.03643829748034477, Lr:0.0001\n",
      "Epoch 23, Step: 541, Loss: 0.10305154323577881, Lr:0.0001\n",
      "Epoch 23, Step: 542, Loss: 0.012105588801205158, Lr:0.0001\n",
      "Epoch 23, Step: 543, Loss: 0.5626301169395447, Lr:0.0001\n",
      "Epoch 23, Step: 544, Loss: 0.0715450868010521, Lr:0.0001\n",
      "Epoch 23, Step: 545, Loss: 0.0534292533993721, Lr:0.0001\n",
      "Epoch 23, Step: 546, Loss: 0.0017282906919717789, Lr:0.0001\n",
      "Epoch 23, Step: 547, Loss: 0.06598245352506638, Lr:0.0001\n",
      "Epoch 23, Step: 548, Loss: 0.008727547712624073, Lr:0.0001\n",
      "Epoch 23, Step: 549, Loss: 0.21172145009040833, Lr:0.0001\n",
      "Epoch 23, Step: 550, Loss: 0.01405977550894022, Lr:0.0001\n",
      "Epoch 23, Step: 551, Loss: 0.03846178948879242, Lr:0.0001\n",
      "Epoch 23, Step: 552, Loss: 0.08353415131568909, Lr:0.0001\n",
      "Epoch 23, Step: 553, Loss: 0.04215100035071373, Lr:0.0001\n",
      "Epoch 23, Step: 554, Loss: 0.25414934754371643, Lr:0.0001\n",
      "Epoch 23, Step: 555, Loss: 0.029795754700899124, Lr:0.0001\n",
      "Epoch 23, Step: 556, Loss: 0.04663090035319328, Lr:0.0001\n",
      "Epoch 23, Step: 557, Loss: 0.0362519845366478, Lr:0.0001\n",
      "Epoch 23, Step: 558, Loss: 0.3057861030101776, Lr:0.0001\n",
      "Epoch 23, Step: 559, Loss: 0.022845039144158363, Lr:0.0001\n",
      "Epoch 23, Step: 560, Loss: 0.04953883960843086, Lr:0.0001\n",
      "Epoch 23, Step: 561, Loss: 0.15310268104076385, Lr:0.0001\n",
      "Epoch 23, Step: 562, Loss: 0.020995376631617546, Lr:0.0001\n",
      "Epoch 23, Step: 563, Loss: 0.01109638623893261, Lr:0.0001\n",
      "Epoch 23, Step: 564, Loss: 0.04576019570231438, Lr:0.0001\n",
      "Epoch 23, Step: 565, Loss: 0.08215995132923126, Lr:0.0001\n",
      "Epoch 23, Step: 566, Loss: 0.08531904965639114, Lr:0.0001\n",
      "Epoch 23, Step: 567, Loss: 0.16457349061965942, Lr:0.0001\n",
      "Epoch 23, Step: 568, Loss: 0.023228030651807785, Lr:0.0001\n",
      "Epoch 23, Step: 569, Loss: 0.012024435214698315, Lr:0.0001\n",
      "Epoch 23, Step: 570, Loss: 0.011651324108242989, Lr:0.0001\n",
      "Epoch 23, Step: 571, Loss: 0.17694920301437378, Lr:0.0001\n",
      "Epoch 23, Step: 572, Loss: 0.055106498301029205, Lr:0.0001\n",
      "Epoch 23, Step: 573, Loss: 0.2513449192047119, Lr:0.0001\n",
      "Epoch 23, Step: 574, Loss: 0.15445195138454437, Lr:0.0001\n",
      "Epoch 23, Step: 575, Loss: 0.14784641563892365, Lr:0.0001\n",
      "Epoch 23, Step: 576, Loss: 0.12615767121315002, Lr:0.0001\n",
      "Epoch 23, Step: 577, Loss: 0.022790024057030678, Lr:0.0001\n",
      "Epoch 23, Step: 578, Loss: 0.07904695719480515, Lr:0.0001\n",
      "Epoch 23, Step: 579, Loss: 0.006923876702785492, Lr:0.0001\n",
      "Epoch 23, Step: 580, Loss: 0.05397624894976616, Lr:0.0001\n",
      "Epoch 23, Step: 581, Loss: 0.1913454532623291, Lr:0.0001\n",
      "Epoch 23, Step: 582, Loss: 0.1981266587972641, Lr:0.0001\n",
      "Epoch 23, Step: 583, Loss: 0.011265837587416172, Lr:0.0001\n",
      "Epoch 23, Step: 584, Loss: 0.008194890804588795, Lr:0.0001\n",
      "Epoch 23, Step: 585, Loss: 0.10516632348299026, Lr:0.0001\n",
      "Epoch 23, Step: 586, Loss: 0.09722822904586792, Lr:0.0001\n",
      "Epoch 23, Step: 587, Loss: 0.2907719016075134, Lr:0.0001\n",
      "Epoch 23, Step: 588, Loss: 0.0411573201417923, Lr:0.0001\n",
      "Epoch 23, Step: 589, Loss: 0.06678323447704315, Lr:0.0001\n",
      "Epoch 23, Step: 590, Loss: 0.024352947250008583, Lr:0.0001\n",
      "Epoch 23, Step: 591, Loss: 0.11695197224617004, Lr:0.0001\n",
      "Epoch 23, Step: 592, Loss: 0.02196354977786541, Lr:0.0001\n",
      "Epoch 23, Step: 593, Loss: 0.2866363227367401, Lr:0.0001\n",
      "Epoch 23, Step: 594, Loss: 0.1812351942062378, Lr:0.0001\n",
      "Epoch 23, Step: 595, Loss: 0.010842559859156609, Lr:0.0001\n",
      "Epoch 23, Step: 596, Loss: 0.061071716248989105, Lr:0.0001\n",
      "Epoch 23, Step: 597, Loss: 0.08232720196247101, Lr:0.0001\n",
      "Epoch 23, Step: 598, Loss: 0.0320127010345459, Lr:0.0001\n",
      "Epoch 23, Step: 599, Loss: 0.06528937071561813, Lr:0.0001\n",
      "Epoch 23, Step: 600, Loss: 0.04860561713576317, Lr:0.0001\n",
      "Epoch 23, Step: 601, Loss: 0.04088957607746124, Lr:0.0001\n",
      "Epoch 23, Step: 602, Loss: 0.10178358852863312, Lr:0.0001\n",
      "Epoch 23, Step: 603, Loss: 0.08236850798130035, Lr:0.0001\n",
      "Epoch 23, Step: 604, Loss: 0.008649595081806183, Lr:0.0001\n",
      "Epoch 23, Step: 605, Loss: 0.10399957001209259, Lr:0.0001\n",
      "Epoch 23, Step: 606, Loss: 0.021274011582136154, Lr:0.0001\n",
      "Epoch 23, Step: 607, Loss: 0.11039470136165619, Lr:0.0001\n",
      "Epoch 23, Step: 608, Loss: 0.1995307356119156, Lr:0.0001\n",
      "Epoch 23, Step: 609, Loss: 0.00031700762338005006, Lr:0.0001\n",
      "Epoch 23, Step: 610, Loss: 0.020936144515872, Lr:0.0001\n",
      "Epoch 23, Step: 611, Loss: 0.013751622289419174, Lr:0.0001\n",
      "Epoch 23, Step: 612, Loss: 0.015326077118515968, Lr:0.0001\n",
      "Epoch 23, Step: 613, Loss: 0.21595653891563416, Lr:0.0001\n",
      "Epoch 23, Step: 614, Loss: 0.2630324363708496, Lr:0.0001\n",
      "Epoch 23, Step: 615, Loss: 0.004473713226616383, Lr:0.0001\n",
      "Epoch 23, Step: 616, Loss: 0.08394008129835129, Lr:0.0001\n",
      "Epoch 23, Step: 617, Loss: 0.07712153345346451, Lr:0.0001\n",
      "Epoch 23, Step: 618, Loss: 0.01579470746219158, Lr:0.0001\n",
      "Epoch 23, Step: 619, Loss: 0.0280833188444376, Lr:0.0001\n",
      "Epoch 23, Step: 620, Loss: 0.008083759807050228, Lr:0.0001\n",
      "Epoch 23, Step: 621, Loss: 0.07820715010166168, Lr:0.0001\n",
      "Epoch 23, Step: 622, Loss: 0.012234955094754696, Lr:0.0001\n",
      "Epoch 23, Step: 623, Loss: 0.11233058571815491, Lr:0.0001\n",
      "Epoch 23, Step: 624, Loss: 0.001930902129970491, Lr:0.0001\n",
      "Epoch 23, Step: 625, Loss: 0.020958539098501205, Lr:0.0001\n",
      "Epoch 23, Step: 626, Loss: 0.006328337360173464, Lr:0.0001\n",
      "Epoch 23, Step: 627, Loss: 0.009284185245633125, Lr:0.0001\n",
      "Epoch 23, Step: 628, Loss: 0.14911824464797974, Lr:0.0001\n",
      "Epoch 23, Step: 629, Loss: 0.09834811091423035, Lr:0.0001\n",
      "Epoch 23, Step: 630, Loss: 0.12916138768196106, Lr:0.0001\n",
      "Epoch 23, Step: 631, Loss: 0.24942828714847565, Lr:0.0001\n",
      "Epoch 23, Step: 632, Loss: 0.14463287591934204, Lr:0.0001\n",
      "Epoch 23, Step: 633, Loss: 0.01184477936476469, Lr:0.0001\n",
      "Epoch 23, Step: 634, Loss: 0.04711764305830002, Lr:0.0001\n",
      "Epoch 23, Step: 635, Loss: 0.07446321099996567, Lr:0.0001\n",
      "Epoch 23, Step: 636, Loss: 0.07314588129520416, Lr:0.0001\n",
      "Epoch 23, Step: 637, Loss: 0.006631849333643913, Lr:0.0001\n",
      "Epoch 23, Step: 638, Loss: 0.0052304742857813835, Lr:0.0001\n",
      "Epoch 23, Step: 639, Loss: 0.00944153219461441, Lr:0.0001\n",
      "Epoch 23, Step: 640, Loss: 0.08150554448366165, Lr:0.0001\n",
      "Epoch 23, Step: 641, Loss: 0.035135917365550995, Lr:0.0001\n",
      "Epoch 23, Step: 642, Loss: 0.15909302234649658, Lr:0.0001\n",
      "Epoch 23, Step: 643, Loss: 0.0958665981888771, Lr:0.0001\n",
      "Epoch 23, Step: 644, Loss: 0.07646799832582474, Lr:0.0001\n",
      "Epoch 23, Step: 645, Loss: 0.037080030888319016, Lr:0.0001\n",
      "Epoch 23, Step: 646, Loss: 0.030919957906007767, Lr:0.0001\n",
      "Epoch 23, Step: 647, Loss: 0.0445740707218647, Lr:0.0001\n",
      "Epoch 23, Step: 648, Loss: 0.4654960036277771, Lr:0.0001\n",
      "Epoch 23, Step: 649, Loss: 0.00549327814951539, Lr:0.0001\n",
      "Epoch 23, Step: 650, Loss: 0.009075834415853024, Lr:0.0001\n",
      "Epoch 23, Step: 651, Loss: 0.012977694161236286, Lr:0.0001\n",
      "Epoch 23, Step: 652, Loss: 0.05829783156514168, Lr:0.0001\n",
      "Epoch 23, Step: 653, Loss: 0.08197008073329926, Lr:0.0001\n",
      "Epoch 23, Step: 654, Loss: 0.011854058131575584, Lr:0.0001\n",
      "Epoch 23, Step: 655, Loss: 0.009147172793745995, Lr:0.0001\n",
      "Epoch 23, Step: 656, Loss: 0.04386502876877785, Lr:0.0001\n",
      "Epoch 23, Step: 657, Loss: 0.01414058730006218, Lr:0.0001\n",
      "Epoch 23, Step: 658, Loss: 0.06906602531671524, Lr:0.0001\n",
      "Epoch 23, Step: 659, Loss: 0.20090457797050476, Lr:0.0001\n",
      "Epoch 23, Step: 660, Loss: 0.032383352518081665, Lr:0.0001\n",
      "Epoch 23, Step: 661, Loss: 0.11488846689462662, Lr:0.0001\n",
      "Epoch 23, Step: 662, Loss: 0.16496600210666656, Lr:0.0001\n",
      "Epoch 23, Step: 663, Loss: 0.007775879930704832, Lr:0.0001\n",
      "Epoch 23, Step: 664, Loss: 0.2076260894536972, Lr:0.0001\n",
      "Epoch 23, Step: 665, Loss: 0.010754636488854885, Lr:0.0001\n",
      "Epoch 23, Step: 666, Loss: 0.12153604626655579, Lr:0.0001\n",
      "Epoch 23, Step: 667, Loss: 0.1103140115737915, Lr:0.0001\n",
      "Epoch 23, Step: 668, Loss: 0.06550806015729904, Lr:0.0001\n",
      "Epoch 23, Step: 669, Loss: 0.04083627834916115, Lr:0.0001\n",
      "Epoch 23, Step: 670, Loss: 0.15260906517505646, Lr:0.0001\n",
      "Epoch 23, Step: 671, Loss: 0.09907489269971848, Lr:0.0001\n",
      "Epoch 23, Step: 672, Loss: 0.007680072914808989, Lr:0.0001\n",
      "Epoch 23, Step: 673, Loss: 0.12423786520957947, Lr:0.0001\n",
      "Epoch 23, Step: 674, Loss: 0.04973338916897774, Lr:0.0001\n",
      "Epoch 23, Step: 675, Loss: 0.2681347727775574, Lr:0.0001\n",
      "Epoch 23, Step: 676, Loss: 0.05309155583381653, Lr:0.0001\n",
      "Epoch 23, Step: 677, Loss: 0.0039880783297121525, Lr:0.0001\n",
      "Epoch 23, Step: 678, Loss: 0.25118955969810486, Lr:0.0001\n",
      "Epoch 23, Step: 679, Loss: 0.1204458698630333, Lr:0.0001\n",
      "Epoch 23, Step: 680, Loss: 0.03237956389784813, Lr:0.0001\n",
      "Epoch 23, Step: 681, Loss: 0.17252689599990845, Lr:0.0001\n",
      "Epoch 23, Step: 682, Loss: 0.09140865504741669, Lr:0.0001\n",
      "Epoch 23, Step: 683, Loss: 0.02347962185740471, Lr:0.0001\n",
      "Epoch 23, Step: 684, Loss: 0.11801254004240036, Lr:0.0001\n",
      "Epoch 23, Step: 685, Loss: 0.008909136056900024, Lr:0.0001\n",
      "Epoch 23, Step: 686, Loss: 0.10974699258804321, Lr:0.0001\n",
      "Epoch 23, Step: 687, Loss: 0.003956549800932407, Lr:0.0001\n",
      "Epoch 23, Step: 688, Loss: 0.07364971190690994, Lr:0.0001\n",
      "Epoch 23, Step: 689, Loss: 0.027489015832543373, Lr:0.0001\n",
      "Epoch 23, Step: 690, Loss: 0.062422364950180054, Lr:0.0001\n",
      "Epoch 23, Step: 691, Loss: 0.02402714639902115, Lr:0.0001\n",
      "Epoch 23, Step: 692, Loss: 0.018327053636312485, Lr:0.0001\n",
      "Epoch 23, Step: 693, Loss: 0.0036213502753525972, Lr:0.0001\n",
      "Epoch 23, Step: 694, Loss: 0.006728137377649546, Lr:0.0001\n",
      "Epoch 23, Step: 695, Loss: 0.05686473101377487, Lr:0.0001\n",
      "Epoch 23, Step: 696, Loss: 0.07515008747577667, Lr:0.0001\n",
      "Epoch 23, Step: 697, Loss: 0.03609549626708031, Lr:0.0001\n",
      "Epoch 23, Step: 698, Loss: 0.10440737009048462, Lr:0.0001\n",
      "Epoch 23, Step: 699, Loss: 0.05560217425227165, Lr:0.0001\n",
      "Epoch 23, Step: 700, Loss: 0.13748109340667725, Lr:0.0001\n",
      "Epoch 23, Step: 701, Loss: 0.05328609421849251, Lr:0.0001\n",
      "Epoch 23, Step: 702, Loss: 0.1206759363412857, Lr:0.0001\n",
      "Epoch 23, Step: 703, Loss: 0.0018660025671124458, Lr:0.0001\n",
      "Epoch 23, Step: 704, Loss: 0.08424900472164154, Lr:0.0001\n",
      "Epoch 23, Step: 705, Loss: 0.0045919762924313545, Lr:0.0001\n",
      "Epoch 23, Step: 706, Loss: 0.01708015613257885, Lr:0.0001\n",
      "Epoch 23, Step: 707, Loss: 0.09283027797937393, Lr:0.0001\n",
      "Epoch 23, Step: 708, Loss: 0.1058582216501236, Lr:0.0001\n",
      "Epoch 23, Step: 709, Loss: 0.05375814065337181, Lr:0.0001\n",
      "Epoch 23, Step: 710, Loss: 0.038530830293893814, Lr:0.0001\n",
      "Epoch 23, Step: 711, Loss: 0.03011813387274742, Lr:0.0001\n",
      "Epoch 23, Step: 712, Loss: 0.038397159427404404, Lr:0.0001\n",
      "Epoch 23, Step: 713, Loss: 0.01534944586455822, Lr:0.0001\n",
      "Epoch 23, Step: 714, Loss: 0.0073079513385891914, Lr:0.0001\n",
      "Epoch 23, Step: 715, Loss: 0.09564968198537827, Lr:0.0001\n",
      "Epoch 23, Step: 716, Loss: 0.04397011920809746, Lr:0.0001\n",
      "Epoch 23, Step: 717, Loss: 0.16904035210609436, Lr:0.0001\n",
      "Epoch 23, Step: 718, Loss: 0.0016324708703905344, Lr:0.0001\n",
      "Epoch 23, Step: 719, Loss: 0.006398564204573631, Lr:0.0001\n",
      "Epoch 23, Step: 720, Loss: 0.010945187881588936, Lr:0.0001\n",
      "Epoch 23, Step: 721, Loss: 0.046964481472969055, Lr:0.0001\n",
      "Epoch 23, Step: 722, Loss: 0.011811589822173119, Lr:0.0001\n",
      "Epoch 23, Step: 723, Loss: 0.020437616854906082, Lr:0.0001\n",
      "Epoch 23, Step: 724, Loss: 0.05362710356712341, Lr:0.0001\n",
      "Epoch 23, Step: 725, Loss: 0.04358356073498726, Lr:0.0001\n",
      "Epoch 23, Step: 726, Loss: 0.0259736068546772, Lr:0.0001\n",
      "Epoch 23, Step: 727, Loss: 0.04160018265247345, Lr:0.0001\n",
      "Epoch 23, Step: 728, Loss: 0.12171881645917892, Lr:0.0001\n",
      "Epoch 23, Step: 729, Loss: 0.004170177038758993, Lr:0.0001\n",
      "Epoch 23, Step: 730, Loss: 0.10537493973970413, Lr:0.0001\n",
      "Epoch 23, Step: 731, Loss: 0.05041974037885666, Lr:0.0001\n",
      "Epoch 23, Step: 732, Loss: 0.0031921451445668936, Lr:0.0001\n",
      "Epoch 23, Step: 733, Loss: 0.09371078759431839, Lr:0.0001\n",
      "Epoch 23, Step: 734, Loss: 0.04656499996781349, Lr:0.0001\n",
      "Epoch 23, Step: 735, Loss: 0.17158161103725433, Lr:0.0001\n",
      "Epoch 23, Step: 736, Loss: 0.002595029305666685, Lr:0.0001\n",
      "Epoch 23, Step: 737, Loss: 0.03261484578251839, Lr:0.0001\n",
      "Epoch 23, Step: 738, Loss: 0.03389032185077667, Lr:0.0001\n",
      "Epoch 23, Step: 739, Loss: 0.02907714433968067, Lr:0.0001\n",
      "Epoch 23, Step: 740, Loss: 0.04676755517721176, Lr:0.0001\n",
      "Epoch 23, Step: 741, Loss: 0.12819282710552216, Lr:0.0001\n",
      "Epoch 23, Step: 742, Loss: 0.01012255996465683, Lr:0.0001\n",
      "Epoch 23, Step: 743, Loss: 0.005260148085653782, Lr:0.0001\n",
      "Epoch 23, Step: 744, Loss: 0.003929946571588516, Lr:0.0001\n",
      "Epoch 23, Step: 745, Loss: 0.20366181433200836, Lr:0.0001\n",
      "Epoch 23, Step: 746, Loss: 0.010381934233009815, Lr:0.0001\n",
      "Epoch 23, Step: 747, Loss: 0.1112772673368454, Lr:0.0001\n",
      "Epoch 23, Step: 748, Loss: 0.22367225587368011, Lr:0.0001\n",
      "Epoch 23, Step: 749, Loss: 0.24922029674053192, Lr:0.0001\n",
      "Epoch 23, Step: 750, Loss: 0.001248594606295228, Lr:0.0001\n",
      "Epoch 23, Step: 751, Loss: 0.03734279051423073, Lr:0.0001\n",
      "Epoch 23, Step: 752, Loss: 0.05198465660214424, Lr:0.0001\n",
      "Epoch 23, Step: 753, Loss: 0.0012329280143603683, Lr:0.0001\n",
      "Epoch 23, Step: 754, Loss: 0.0012747814180329442, Lr:0.0001\n",
      "Epoch 23, Step: 755, Loss: 0.14358671009540558, Lr:0.0001\n",
      "Epoch 23, Step: 756, Loss: 0.12331108003854752, Lr:0.0001\n",
      "Epoch 23, Step: 757, Loss: 0.04917112737894058, Lr:0.0001\n",
      "Epoch 23, Step: 758, Loss: 0.030749192461371422, Lr:0.0001\n",
      "Epoch 23, Step: 759, Loss: 0.02512706257402897, Lr:0.0001\n",
      "Epoch 23, Step: 760, Loss: 0.30948904156684875, Lr:0.0001\n",
      "Epoch 23, Step: 761, Loss: 0.0960286557674408, Lr:0.0001\n",
      "Epoch 23, Step: 762, Loss: 0.08886357396841049, Lr:0.0001\n",
      "Epoch 23, Step: 763, Loss: 0.18394984304904938, Lr:0.0001\n",
      "Epoch 23, Step: 764, Loss: 0.008654844015836716, Lr:0.0001\n",
      "Epoch 23, Step: 765, Loss: 0.04840309917926788, Lr:0.0001\n",
      "Epoch 23, Step: 766, Loss: 0.326084703207016, Lr:0.0001\n",
      "Epoch 23, Step: 767, Loss: 0.17566971480846405, Lr:0.0001\n",
      "Epoch 23, Step: 768, Loss: 0.1891855150461197, Lr:0.0001\n",
      "Epoch 23, Step: 769, Loss: 0.011781706474721432, Lr:0.0001\n",
      "Epoch 23, Step: 770, Loss: 0.00903203897178173, Lr:0.0001\n",
      "Epoch 23, Step: 771, Loss: 0.005681173875927925, Lr:0.0001\n",
      "Epoch 23, Step: 772, Loss: 0.08996656537055969, Lr:0.0001\n",
      "Epoch 23, Step: 773, Loss: 0.07531845569610596, Lr:0.0001\n",
      "Epoch 23, Step: 774, Loss: 0.019222252070903778, Lr:0.0001\n",
      "Epoch 23, Step: 775, Loss: 0.16900037229061127, Lr:0.0001\n",
      "Epoch 23, Step: 776, Loss: 0.3038957118988037, Lr:0.0001\n",
      "Epoch 23, Step: 777, Loss: 0.04055535048246384, Lr:0.0001\n",
      "Epoch 23, Step: 778, Loss: 0.2560391128063202, Lr:0.0001\n",
      "Epoch 23, Step: 779, Loss: 0.05466533079743385, Lr:0.0001\n",
      "Epoch 23, Step: 780, Loss: 0.1947292536497116, Lr:0.0001\n",
      "Epoch 23, Step: 781, Loss: 0.05281487852334976, Lr:0.0001\n",
      "Epoch 23, Step: 782, Loss: 0.04819875955581665, Lr:0.0001\n",
      "Epoch 23, Step: 783, Loss: 0.09437856078147888, Lr:0.0001\n",
      "Epoch 23, Step: 784, Loss: 0.13943998515605927, Lr:0.0001\n",
      "Epoch 23, Step: 785, Loss: 0.0958917886018753, Lr:0.0001\n",
      "Epoch 23, Step: 786, Loss: 0.06588681787252426, Lr:0.0001\n",
      "Epoch 23, Step: 787, Loss: 0.09487506747245789, Lr:0.0001\n",
      "Epoch 23, Step: 788, Loss: 0.03384476900100708, Lr:0.0001\n",
      "Epoch 23, Step: 789, Loss: 0.16806432604789734, Lr:0.0001\n",
      "Epoch 23, Step: 790, Loss: 0.05121423676609993, Lr:0.0001\n",
      "Epoch 23, Step: 791, Loss: 0.024236958473920822, Lr:0.0001\n",
      "Epoch 23, Step: 792, Loss: 0.050680309534072876, Lr:0.0001\n",
      "Epoch 23, Step: 793, Loss: 0.06067302078008652, Lr:0.0001\n",
      "Epoch 23, Step: 794, Loss: 0.04195600003004074, Lr:0.0001\n",
      "Epoch 23, Step: 795, Loss: 0.08944988250732422, Lr:0.0001\n",
      "Epoch 23, Step: 796, Loss: 0.003974584862589836, Lr:0.0001\n",
      "Epoch 23, Step: 797, Loss: 0.019701799377799034, Lr:0.0001\n",
      "Epoch 23, Step: 798, Loss: 0.0753379836678505, Lr:0.0001\n",
      "Epoch 23, Step: 799, Loss: 0.0016642974223941565, Lr:0.0001\n",
      "Epoch 23, Step: 800, Loss: 0.005012291017919779, Lr:0.0001\n",
      "Epoch 23, Step: 801, Loss: 0.0168414618819952, Lr:0.0001\n",
      "Epoch 23, Step: 802, Loss: 0.18890966475009918, Lr:0.0001\n",
      "Epoch 23, Step: 803, Loss: 0.025081774219870567, Lr:0.0001\n",
      "Epoch 23, Step: 804, Loss: 0.0031635367777198553, Lr:0.0001\n",
      "Epoch 23, Step: 805, Loss: 0.06566926836967468, Lr:0.0001\n",
      "Epoch 23, Step: 806, Loss: 0.13015185296535492, Lr:0.0001\n",
      "Epoch 23, Step: 807, Loss: 0.006958003621548414, Lr:0.0001\n",
      "Epoch 23, Step: 808, Loss: 0.056877683848142624, Lr:0.0001\n",
      "Epoch 23, Step: 809, Loss: 0.02286556363105774, Lr:0.0001\n",
      "Epoch 23, Step: 810, Loss: 0.15994632244110107, Lr:0.0001\n",
      "Epoch 23, Step: 811, Loss: 0.2619987428188324, Lr:0.0001\n",
      "Epoch 23, Step: 812, Loss: 0.1774676889181137, Lr:0.0001\n",
      "Epoch 23, Step: 813, Loss: 0.00448359502479434, Lr:0.0001\n",
      "Epoch 23, Step: 814, Loss: 0.10371053218841553, Lr:0.0001\n",
      "Epoch 23, Step: 815, Loss: 0.08407924324274063, Lr:0.0001\n",
      "Epoch 23, Step: 816, Loss: 0.00486147403717041, Lr:0.0001\n",
      "Epoch 23, Step: 817, Loss: 0.015450799837708473, Lr:0.0001\n",
      "Epoch 23, Step: 818, Loss: 0.047859061509370804, Lr:0.0001\n",
      "Epoch 23, Step: 819, Loss: 0.00494750402867794, Lr:0.0001\n",
      "Epoch 23, Step: 820, Loss: 0.03692736104130745, Lr:0.0001\n",
      "Epoch 23, Step: 821, Loss: 0.08133677393198013, Lr:0.0001\n",
      "Epoch 23, Step: 822, Loss: 0.07386080175638199, Lr:0.0001\n",
      "Epoch 23, Step: 823, Loss: 0.06328046321868896, Lr:0.0001\n",
      "Epoch 23, Step: 824, Loss: 0.006930286530405283, Lr:0.0001\n",
      "Epoch 23, Step: 825, Loss: 0.04629720002412796, Lr:0.0001\n",
      "Epoch 23, Step: 826, Loss: 0.012835980392992496, Lr:0.0001\n",
      "Epoch 23, Step: 827, Loss: 0.024981439113616943, Lr:0.0001\n",
      "Epoch 23, Step: 828, Loss: 0.008633498102426529, Lr:0.0001\n",
      "Epoch 23, Step: 829, Loss: 0.20595066249370575, Lr:0.0001\n",
      "Epoch 23, Step: 830, Loss: 0.6106973886489868, Lr:0.0001\n",
      "Epoch 23, Step: 831, Loss: 0.20128990709781647, Lr:0.0001\n",
      "Epoch 23, Step: 832, Loss: 0.061816900968551636, Lr:0.0001\n",
      "Epoch 23, Step: 833, Loss: 0.0875035747885704, Lr:0.0001\n",
      "Epoch 23, Step: 834, Loss: 0.02139582298696041, Lr:0.0001\n",
      "Epoch 23, Step: 835, Loss: 0.14414864778518677, Lr:0.0001\n",
      "Epoch 23, Step: 836, Loss: 0.06743641942739487, Lr:0.0001\n",
      "Epoch 23, Step: 837, Loss: 0.12258206307888031, Lr:0.0001\n",
      "Epoch 23, Step: 838, Loss: 0.1265011727809906, Lr:0.0001\n",
      "Epoch 23, Step: 839, Loss: 0.004973950330168009, Lr:0.0001\n",
      "Epoch 23, Step: 840, Loss: 0.020528560504317284, Lr:0.0001\n",
      "Epoch 23, Step: 841, Loss: 0.03438085690140724, Lr:0.0001\n",
      "Epoch 23, Step: 842, Loss: 0.06491824984550476, Lr:0.0001\n",
      "Epoch 23, Step: 843, Loss: 0.3950880467891693, Lr:0.0001\n",
      "Epoch 23, Step: 844, Loss: 0.03212064877152443, Lr:0.0001\n",
      "Epoch 23, Step: 845, Loss: 0.29760849475860596, Lr:0.0001\n",
      "Epoch 23, Step: 846, Loss: 0.0031738909892737865, Lr:0.0001\n",
      "Epoch 23, Step: 847, Loss: 0.006950789131224155, Lr:0.0001\n",
      "Epoch 23, Step: 848, Loss: 0.0033043764997273684, Lr:0.0001\n",
      "Epoch 23, Step: 849, Loss: 0.11530967801809311, Lr:0.0001\n",
      "Epoch 23, Step: 850, Loss: 0.026592664420604706, Lr:0.0001\n",
      "Epoch 23, Step: 851, Loss: 0.05006309598684311, Lr:0.0001\n",
      "Epoch 23, Step: 852, Loss: 0.01116847898811102, Lr:0.0001\n",
      "Epoch 23, Step: 853, Loss: 0.20571701228618622, Lr:0.0001\n",
      "Epoch 23, Step: 854, Loss: 0.10243366658687592, Lr:0.0001\n",
      "Epoch 23, Step: 855, Loss: 0.38385123014450073, Lr:0.0001\n",
      "Epoch 23, Step: 856, Loss: 0.3899345099925995, Lr:0.0001\n",
      "Epoch 23, Step: 857, Loss: 0.10258542001247406, Lr:0.0001\n",
      "Epoch 23, Step: 858, Loss: 0.221879780292511, Lr:0.0001\n",
      "Epoch 23, Step: 859, Loss: 0.13581562042236328, Lr:0.0001\n",
      "Epoch 23, Step: 860, Loss: 0.10293528437614441, Lr:0.0001\n",
      "Epoch 23, Step: 861, Loss: 0.02566201239824295, Lr:0.0001\n",
      "Epoch 23, Step: 862, Loss: 0.11307813972234726, Lr:0.0001\n",
      "Epoch 23, Step: 863, Loss: 0.021255675703287125, Lr:0.0001\n",
      "Epoch 23, Step: 864, Loss: 0.18185213208198547, Lr:0.0001\n",
      "Epoch 23, Step: 865, Loss: 0.006126623600721359, Lr:0.0001\n",
      "Epoch 23, Step: 866, Loss: 0.00653091911226511, Lr:0.0001\n",
      "Epoch 23, Step: 867, Loss: 0.19511142373085022, Lr:0.0001\n",
      "Epoch 23, Step: 868, Loss: 0.09023991972208023, Lr:0.0001\n",
      "Epoch 23, Step: 869, Loss: 0.019361035898327827, Lr:0.0001\n",
      "Epoch 23, Step: 870, Loss: 0.07042520493268967, Lr:0.0001\n",
      "Epoch 23, Step: 871, Loss: 0.10199534147977829, Lr:0.0001\n",
      "Epoch 23, Step: 872, Loss: 0.2987937331199646, Lr:0.0001\n",
      "Epoch 23, Step: 873, Loss: 0.032682567834854126, Lr:0.0001\n",
      "Epoch 23, Step: 874, Loss: 0.041014283895492554, Lr:0.0001\n",
      "Epoch 23, Step: 875, Loss: 0.08719408512115479, Lr:0.0001\n",
      "Epoch 23, Step: 876, Loss: 0.2417685091495514, Lr:0.0001\n",
      "Epoch 23, Step: 877, Loss: 0.009433632716536522, Lr:0.0001\n",
      "Epoch 23, Step: 878, Loss: 0.09842236340045929, Lr:0.0001\n",
      "Epoch 23, Step: 879, Loss: 0.08211597055196762, Lr:0.0001\n",
      "Epoch 23, Step: 880, Loss: 0.10506293922662735, Lr:0.0001\n",
      "Epoch 23, Step: 881, Loss: 0.021077346056699753, Lr:0.0001\n",
      "Epoch 23, Step: 882, Loss: 0.26586660742759705, Lr:0.0001\n",
      "Epoch 23, Step: 883, Loss: 0.05215388908982277, Lr:0.0001\n",
      "Epoch 23, Step: 884, Loss: 0.06036965548992157, Lr:0.0001\n",
      "Epoch 23, Step: 885, Loss: 0.03872866928577423, Lr:0.0001\n",
      "Epoch 23, Step: 886, Loss: 0.008490992709994316, Lr:0.0001\n",
      "Epoch 23, Step: 887, Loss: 0.020186185836791992, Lr:0.0001\n",
      "Epoch 23, Step: 888, Loss: 0.2182394415140152, Lr:0.0001\n",
      "Epoch 23, Step: 889, Loss: 0.04956935718655586, Lr:0.0001\n",
      "Epoch 23, Step: 890, Loss: 0.021478669717907906, Lr:0.0001\n",
      "Epoch 23, Step: 891, Loss: 0.002733602887019515, Lr:0.0001\n",
      "Epoch 23, Step: 892, Loss: 0.2827334403991699, Lr:0.0001\n",
      "Epoch 23, Step: 893, Loss: 0.03688947856426239, Lr:0.0001\n",
      "Epoch 23, Step: 894, Loss: 0.024606425315141678, Lr:0.0001\n",
      "Epoch 23, Step: 895, Loss: 0.009993034414947033, Lr:0.0001\n",
      "Epoch 23, Step: 896, Loss: 0.22155407071113586, Lr:0.0001\n",
      "Epoch 23, Step: 897, Loss: 0.007461504079401493, Lr:0.0001\n",
      "Epoch 23, Step: 898, Loss: 0.12866538763046265, Lr:0.0001\n",
      "Epoch 23, Step: 899, Loss: 0.14726369082927704, Lr:0.0001\n",
      "Epoch 23, Step: 900, Loss: 0.14081358909606934, Lr:0.0001\n",
      "Epoch 23, Step: 901, Loss: 0.12825873494148254, Lr:0.0001\n",
      "Epoch 23, Step: 902, Loss: 0.002349993446841836, Lr:0.0001\n",
      "Epoch 23, Step: 903, Loss: 0.0035058415960520506, Lr:0.0001\n",
      "Epoch 23, Step: 904, Loss: 0.15035222470760345, Lr:0.0001\n",
      "Epoch 23, Step: 905, Loss: 0.05211034417152405, Lr:0.0001\n",
      "Epoch 23, Step: 906, Loss: 0.010842054150998592, Lr:0.0001\n",
      "Epoch 23, Step: 907, Loss: 0.07234659790992737, Lr:0.0001\n",
      "Epoch 23, Step: 908, Loss: 0.0018542386824265122, Lr:0.0001\n",
      "Epoch 23, Step: 909, Loss: 0.08449156582355499, Lr:0.0001\n",
      "Epoch 23, Step: 910, Loss: 0.07095823436975479, Lr:0.0001\n",
      "Epoch 23, Step: 911, Loss: 0.05311909317970276, Lr:0.0001\n",
      "Epoch 23, Step: 912, Loss: 0.03072010725736618, Lr:0.0001\n",
      "Epoch 23, Step: 913, Loss: 0.11251981556415558, Lr:0.0001\n",
      "Epoch 23, Step: 914, Loss: 0.006403511390089989, Lr:0.0001\n",
      "Epoch 23, Step: 915, Loss: 0.10573915392160416, Lr:0.0001\n",
      "Epoch 23, Step: 916, Loss: 0.1681327223777771, Lr:0.0001\n",
      "Epoch 23, Step: 917, Loss: 0.2960452139377594, Lr:0.0001\n",
      "Epoch 23, Step: 918, Loss: 0.06404222548007965, Lr:0.0001\n",
      "Epoch 23, Step: 919, Loss: 0.03668372333049774, Lr:0.0001\n",
      "Epoch 23, Step: 920, Loss: 0.008260099217295647, Lr:0.0001\n",
      "Epoch 23, Step: 921, Loss: 0.008961346000432968, Lr:0.0001\n",
      "Epoch 23, Step: 922, Loss: 0.08603359013795853, Lr:0.0001\n",
      "Epoch 23, Step: 923, Loss: 0.10511603206396103, Lr:0.0001\n",
      "Epoch 23, Step: 924, Loss: 0.02765110693871975, Lr:0.0001\n",
      "Epoch 23, Step: 925, Loss: 0.009110582992434502, Lr:0.0001\n",
      "Epoch 23, Step: 926, Loss: 0.0467577800154686, Lr:0.0001\n",
      "Epoch 23, Step: 927, Loss: 0.09178987145423889, Lr:0.0001\n",
      "Epoch 23, Step: 928, Loss: 0.014371980912983418, Lr:0.0001\n",
      "Epoch 23, Step: 929, Loss: 0.08792775869369507, Lr:0.0001\n",
      "Epoch 23, Step: 930, Loss: 0.420930951833725, Lr:0.0001\n",
      "Epoch 23, Step: 931, Loss: 0.1931762546300888, Lr:0.0001\n",
      "Epoch 23, Step: 932, Loss: 0.004298686049878597, Lr:0.0001\n",
      "Epoch 23, Step: 933, Loss: 0.021418413147330284, Lr:0.0001\n",
      "Epoch 23, Step: 934, Loss: 0.0471184179186821, Lr:0.0001\n",
      "Epoch 23, Step: 935, Loss: 0.00445724418386817, Lr:0.0001\n",
      "Epoch 23, Step: 936, Loss: 0.020136939361691475, Lr:0.0001\n",
      "Epoch 23, Step: 937, Loss: 0.2984234392642975, Lr:0.0001\n",
      "Epoch 23, Step: 938, Loss: 0.043453529477119446, Lr:0.0001\n",
      "Epoch 23, Step: 939, Loss: 0.027946075424551964, Lr:0.0001\n",
      "Epoch 23, Step: 940, Loss: 0.1243688240647316, Lr:0.0001\n",
      "Epoch 23, Step: 941, Loss: 0.006266787648200989, Lr:0.0001\n",
      "Epoch 23, Step: 942, Loss: 0.04428471252322197, Lr:0.0001\n",
      "Epoch 23, Step: 943, Loss: 0.16776342689990997, Lr:0.0001\n",
      "Epoch 23, Step: 944, Loss: 0.170502170920372, Lr:0.0001\n",
      "Epoch 23, Step: 945, Loss: 0.04792359843850136, Lr:0.0001\n",
      "Epoch 23, Step: 946, Loss: 0.30663394927978516, Lr:0.0001\n",
      "Epoch 23, Step: 947, Loss: 0.011188214644789696, Lr:0.0001\n",
      "Epoch 23, Step: 948, Loss: 0.011117286048829556, Lr:0.0001\n",
      "Epoch 23, Step: 949, Loss: 0.10157112777233124, Lr:0.0001\n",
      "Epoch 23, Step: 950, Loss: 0.0019646380096673965, Lr:0.0001\n",
      "Epoch 23, Step: 951, Loss: 0.02077886462211609, Lr:0.0001\n",
      "Epoch 23, Step: 952, Loss: 0.03534281998872757, Lr:0.0001\n",
      "Epoch 23, Step: 953, Loss: 0.10228174924850464, Lr:0.0001\n",
      "Epoch 23, Step: 954, Loss: 0.08121874928474426, Lr:0.0001\n",
      "Epoch 23, Step: 955, Loss: 0.06915679574012756, Lr:0.0001\n",
      "Epoch 23, Step: 956, Loss: 0.007140766829252243, Lr:0.0001\n",
      "Epoch 23, Step: 957, Loss: 0.018733948469161987, Lr:0.0001\n",
      "Epoch 23, Step: 958, Loss: 0.09951361268758774, Lr:0.0001\n",
      "Epoch 23, Step: 959, Loss: 0.006501335650682449, Lr:0.0001\n",
      "Epoch 23, Step: 960, Loss: 0.01758844219148159, Lr:0.0001\n",
      "Epoch 23, Step: 961, Loss: 0.014911239966750145, Lr:0.0001\n",
      "Epoch 23, Step: 962, Loss: 0.1934157758951187, Lr:0.0001\n",
      "Epoch 23, Step: 963, Loss: 0.01212246809154749, Lr:0.0001\n",
      "Epoch 23, Step: 964, Loss: 0.09505785256624222, Lr:0.0001\n",
      "Epoch 23, Step: 965, Loss: 0.010486983694136143, Lr:0.0001\n",
      "Epoch 23, Step: 966, Loss: 0.04933878779411316, Lr:0.0001\n",
      "Epoch 23, Step: 967, Loss: 0.04698377102613449, Lr:0.0001\n",
      "Epoch 23, Step: 968, Loss: 0.0323370136320591, Lr:0.0001\n",
      "Epoch 23, Step: 969, Loss: 0.008714352734386921, Lr:0.0001\n",
      "Epoch 23, Step: 970, Loss: 0.30038729310035706, Lr:0.0001\n",
      "Epoch 23, Step: 971, Loss: 0.009235301986336708, Lr:0.0001\n",
      "Epoch 23, Step: 972, Loss: 0.10643632709980011, Lr:0.0001\n",
      "Epoch 23, Step: 973, Loss: 0.02300933375954628, Lr:0.0001\n",
      "Epoch 23, Step: 974, Loss: 0.0016545053804293275, Lr:0.0001\n",
      "Epoch 23, Step: 975, Loss: 0.179880753159523, Lr:0.0001\n",
      "Epoch 23, Step: 976, Loss: 0.002473384141921997, Lr:0.0001\n",
      "Epoch 23, Step: 977, Loss: 0.01171373575925827, Lr:0.0001\n",
      "Epoch 23, Step: 978, Loss: 0.2780180275440216, Lr:0.0001\n",
      "Epoch 23, Step: 979, Loss: 0.06606850028038025, Lr:0.0001\n",
      "Epoch 23, Step: 980, Loss: 0.003027484519407153, Lr:0.0001\n",
      "Epoch 23, Step: 981, Loss: 0.014543169178068638, Lr:0.0001\n",
      "Epoch 23, Step: 982, Loss: 0.029831882566213608, Lr:0.0001\n",
      "Epoch 23, Step: 983, Loss: 0.0009467113413847983, Lr:0.0001\n",
      "Epoch 23, Step: 984, Loss: 0.01597275584936142, Lr:0.0001\n",
      "Epoch 23, Step: 985, Loss: 0.13057482242584229, Lr:0.0001\n",
      "Epoch 23, Step: 986, Loss: 0.011436662636697292, Lr:0.0001\n",
      "Epoch 23, Step: 987, Loss: 0.0056541236117482185, Lr:0.0001\n",
      "Epoch 23, Step: 988, Loss: 0.09362931549549103, Lr:0.0001\n",
      "Epoch 23, Step: 989, Loss: 0.16152624785900116, Lr:0.0001\n",
      "Epoch 23, Step: 990, Loss: 0.08233122527599335, Lr:0.0001\n",
      "Epoch 23, Step: 991, Loss: 0.11970409005880356, Lr:0.0001\n",
      "Epoch 23, Step: 992, Loss: 0.04804393649101257, Lr:0.0001\n",
      "Epoch 23, Step: 993, Loss: 0.08271860331296921, Lr:0.0001\n",
      "Epoch 23, Step: 994, Loss: 0.03913196921348572, Lr:0.0001\n",
      "Epoch 23, Step: 995, Loss: 0.12881316244602203, Lr:0.0001\n",
      "Epoch 23, Step: 996, Loss: 0.007938554510474205, Lr:0.0001\n",
      "Epoch 23, Step: 997, Loss: 0.000851508928462863, Lr:0.0001\n",
      "Epoch 23, Step: 998, Loss: 0.13581575453281403, Lr:0.0001\n",
      "Epoch 23, Step: 999, Loss: 0.06385672092437744, Lr:0.0001\n",
      "Epoch 23, Step: 1000, Loss: 0.03884551301598549, Lr:0.0001\n",
      "Epoch 23, Step: 1001, Loss: 0.0303342305123806, Lr:0.0001\n",
      "Epoch 23, Step: 1002, Loss: 0.05151158943772316, Lr:0.0001\n",
      "Epoch 23, Step: 1003, Loss: 0.04991229623556137, Lr:0.0001\n",
      "Epoch 23, Step: 1004, Loss: 0.04723268002271652, Lr:0.0001\n",
      "Epoch 23, Step: 1005, Loss: 0.01107169222086668, Lr:0.0001\n",
      "Epoch 23, Step: 1006, Loss: 0.0010332141537219286, Lr:0.0001\n",
      "Epoch 23, Step: 1007, Loss: 0.004701431840658188, Lr:0.0001\n",
      "Epoch 23, Step: 1008, Loss: 0.1162191703915596, Lr:0.0001\n",
      "Epoch 23, Step: 1009, Loss: 0.016878074035048485, Lr:0.0001\n",
      "Epoch 23, Step: 1010, Loss: 0.011828557588160038, Lr:0.0001\n",
      "Epoch 23, Step: 1011, Loss: 0.13792872428894043, Lr:0.0001\n",
      "Epoch 23, Step: 1012, Loss: 0.03114769607782364, Lr:0.0001\n",
      "Epoch 23, Step: 1013, Loss: 0.057498179376125336, Lr:0.0001\n",
      "Epoch 23, Step: 1014, Loss: 0.15111373364925385, Lr:0.0001\n",
      "Epoch 23, Step: 1015, Loss: 0.010329353623092175, Lr:0.0001\n",
      "Epoch 23, Step: 1016, Loss: 0.044498831033706665, Lr:0.0001\n",
      "Epoch 23, Step: 1017, Loss: 0.061699748039245605, Lr:0.0001\n",
      "Epoch 23, Step: 1018, Loss: 0.00853952206671238, Lr:0.0001\n",
      "Epoch 23, Step: 1019, Loss: 0.02775687351822853, Lr:0.0001\n",
      "Epoch 23, Step: 1020, Loss: 0.17137080430984497, Lr:0.0001\n",
      "Epoch 23, Step: 1021, Loss: 0.010355518199503422, Lr:0.0001\n",
      "Epoch 23, Step: 1022, Loss: 0.013144681230187416, Lr:0.0001\n",
      "Epoch 23, Step: 1023, Loss: 0.014165814965963364, Lr:0.0001\n",
      "Epoch 23, Step: 1024, Loss: 0.05896675959229469, Lr:0.0001\n",
      "Epoch 23, Step: 1025, Loss: 0.09421921521425247, Lr:0.0001\n",
      "Epoch 23, Step: 1026, Loss: 0.07362347096204758, Lr:0.0001\n",
      "Epoch 23, Step: 1027, Loss: 0.03664906322956085, Lr:0.0001\n",
      "Epoch 23, Step: 1028, Loss: 0.007502848282456398, Lr:0.0001\n",
      "Epoch 23, Step: 1029, Loss: 0.13690130412578583, Lr:0.0001\n",
      "Epoch 23, Step: 1030, Loss: 0.06761973351240158, Lr:0.0001\n",
      "Epoch 23, Step: 1031, Loss: 0.021876202896237373, Lr:0.0001\n",
      "Epoch 23, Step: 1032, Loss: 0.0027040119748562574, Lr:0.0001\n",
      "Epoch 23, Step: 1033, Loss: 0.7613188028335571, Lr:0.0001\n",
      "Epoch 23, Step: 1034, Loss: 0.09643350541591644, Lr:0.0001\n",
      "Epoch 23, Step: 1035, Loss: 0.009598973207175732, Lr:0.0001\n",
      "Epoch 23, Step: 1036, Loss: 0.014008811675012112, Lr:0.0001\n",
      "Epoch 23, Step: 1037, Loss: 0.22213062644004822, Lr:0.0001\n",
      "Epoch 23, Step: 1038, Loss: 0.015044868923723698, Lr:0.0001\n",
      "Epoch 23, Step: 1039, Loss: 0.08536523580551147, Lr:0.0001\n",
      "Epoch 23, Step: 1040, Loss: 0.007356926333159208, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 23\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:16 loss: 3.0947 (3.0947) acc1: 68.7500 (68.7500) acc5: 100.0000 (100.0000) time: 0.2946 data: 0.1150 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.9569 (1.3758) acc1: 75.0000 (74.4318) acc5: 100.0000 (100.0000) time: 0.2929 data: 0.1159 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.6872 (1.0489) acc1: 81.2500 (79.1667) acc5: 100.0000 (100.0000) time: 0.3005 data: 0.1181 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.2972 (0.7958) acc1: 87.5000 (83.2661) acc5: 100.0000 (100.0000) time: 0.3051 data: 0.1212 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.0510 (0.6444) acc1: 93.7500 (86.1280) acc5: 100.0000 (100.0000) time: 0.3041 data: 0.1231 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0614 (0.5469) acc1: 93.7500 (87.9902) acc5: 100.0000 (100.0000) time: 0.3200 data: 0.1265 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0121 (0.5139) acc1: 100.0000 (88.4222) acc5: 100.0000 (100.0000) time: 0.3068 data: 0.1193 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.3031 s / it)\n",
      "* Acc@1 88.422 Acc@5 100.000 loss 0.514\n",
      "Accuracy of the network on the 881 test image: 88.4%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 24, Step: 0, Loss: 0.013851189985871315, Lr:0.0001\n",
      "Epoch 24, Step: 1, Loss: 0.03632357344031334, Lr:0.0001\n",
      "Epoch 24, Step: 2, Loss: 0.010312343016266823, Lr:0.0001\n",
      "Epoch 24, Step: 3, Loss: 0.06166044622659683, Lr:0.0001\n",
      "Epoch 24, Step: 4, Loss: 0.051179978996515274, Lr:0.0001\n",
      "Epoch 24, Step: 5, Loss: 0.1735539734363556, Lr:0.0001\n",
      "Epoch 24, Step: 6, Loss: 0.00779705448076129, Lr:0.0001\n",
      "Epoch 24, Step: 7, Loss: 0.030739080160856247, Lr:0.0001\n",
      "Epoch 24, Step: 8, Loss: 0.003455275436863303, Lr:0.0001\n",
      "Epoch 24, Step: 9, Loss: 0.11752846837043762, Lr:0.0001\n",
      "Epoch 24, Step: 10, Loss: 0.6045096516609192, Lr:0.0001\n",
      "Epoch 24, Step: 11, Loss: 0.1003827378153801, Lr:0.0001\n",
      "Epoch 24, Step: 12, Loss: 0.008538180962204933, Lr:0.0001\n",
      "Epoch 24, Step: 13, Loss: 0.10255327820777893, Lr:0.0001\n",
      "Epoch 24, Step: 14, Loss: 0.1307806670665741, Lr:0.0001\n",
      "Epoch 24, Step: 15, Loss: 0.04725154861807823, Lr:0.0001\n",
      "Epoch 24, Step: 16, Loss: 0.019130541011691093, Lr:0.0001\n",
      "Epoch 24, Step: 17, Loss: 0.23295091092586517, Lr:0.0001\n",
      "Epoch 24, Step: 18, Loss: 0.015940293669700623, Lr:0.0001\n",
      "Epoch 24, Step: 19, Loss: 0.05147794634103775, Lr:0.0001\n",
      "Epoch 24, Step: 20, Loss: 0.03585962578654289, Lr:0.0001\n",
      "Epoch 24, Step: 21, Loss: 0.003889391664415598, Lr:0.0001\n",
      "Epoch 24, Step: 22, Loss: 0.014335934072732925, Lr:0.0001\n",
      "Epoch 24, Step: 23, Loss: 0.02612018585205078, Lr:0.0001\n",
      "Epoch 24, Step: 24, Loss: 0.06971284747123718, Lr:0.0001\n",
      "Epoch 24, Step: 25, Loss: 0.13127851486206055, Lr:0.0001\n",
      "Epoch 24, Step: 26, Loss: 0.09901226311922073, Lr:0.0001\n",
      "Epoch 24, Step: 27, Loss: 0.05519552528858185, Lr:0.0001\n",
      "Epoch 24, Step: 28, Loss: 0.02860983833670616, Lr:0.0001\n",
      "Epoch 24, Step: 29, Loss: 0.03816911205649376, Lr:0.0001\n",
      "Epoch 24, Step: 30, Loss: 0.003595793154090643, Lr:0.0001\n",
      "Epoch 24, Step: 31, Loss: 0.008755205199122429, Lr:0.0001\n",
      "Epoch 24, Step: 32, Loss: 0.021747002378106117, Lr:0.0001\n",
      "Epoch 24, Step: 33, Loss: 0.014347238466143608, Lr:0.0001\n",
      "Epoch 24, Step: 34, Loss: 0.06544656306505203, Lr:0.0001\n",
      "Epoch 24, Step: 35, Loss: 0.036039769649505615, Lr:0.0001\n",
      "Epoch 24, Step: 36, Loss: 0.004982145968824625, Lr:0.0001\n",
      "Epoch 24, Step: 37, Loss: 0.006639366038143635, Lr:0.0001\n",
      "Epoch 24, Step: 38, Loss: 0.032226771116256714, Lr:0.0001\n",
      "Epoch 24, Step: 39, Loss: 0.15894024074077606, Lr:0.0001\n",
      "Epoch 24, Step: 40, Loss: 0.01506237592548132, Lr:0.0001\n",
      "Epoch 24, Step: 41, Loss: 0.0037130487617105246, Lr:0.0001\n",
      "Epoch 24, Step: 42, Loss: 0.04515962675213814, Lr:0.0001\n",
      "Epoch 24, Step: 43, Loss: 0.05386962369084358, Lr:0.0001\n",
      "Epoch 24, Step: 44, Loss: 0.005618208087980747, Lr:0.0001\n",
      "Epoch 24, Step: 45, Loss: 0.010461158119142056, Lr:0.0001\n",
      "Epoch 24, Step: 46, Loss: 0.029722824692726135, Lr:0.0001\n",
      "Epoch 24, Step: 47, Loss: 0.042359642684459686, Lr:0.0001\n",
      "Epoch 24, Step: 48, Loss: 0.00530072208493948, Lr:0.0001\n",
      "Epoch 24, Step: 49, Loss: 0.3513135313987732, Lr:0.0001\n",
      "Epoch 24, Step: 50, Loss: 0.049361519515514374, Lr:0.0001\n",
      "Epoch 24, Step: 51, Loss: 0.002102233236655593, Lr:0.0001\n",
      "Epoch 24, Step: 52, Loss: 0.011270148679614067, Lr:0.0001\n",
      "Epoch 24, Step: 53, Loss: 0.07039792090654373, Lr:0.0001\n",
      "Epoch 24, Step: 54, Loss: 0.011962400749325752, Lr:0.0001\n",
      "Epoch 24, Step: 55, Loss: 0.09720245003700256, Lr:0.0001\n",
      "Epoch 24, Step: 56, Loss: 0.22074578702449799, Lr:0.0001\n",
      "Epoch 24, Step: 57, Loss: 0.01271204836666584, Lr:0.0001\n",
      "Epoch 24, Step: 58, Loss: 0.044838786125183105, Lr:0.0001\n",
      "Epoch 24, Step: 59, Loss: 0.06660085916519165, Lr:0.0001\n",
      "Epoch 24, Step: 60, Loss: 0.013133758679032326, Lr:0.0001\n",
      "Epoch 24, Step: 61, Loss: 0.023003466427326202, Lr:0.0001\n",
      "Epoch 24, Step: 62, Loss: 0.03312159329652786, Lr:0.0001\n",
      "Epoch 24, Step: 63, Loss: 0.10382362455129623, Lr:0.0001\n",
      "Epoch 24, Step: 64, Loss: 0.012464875355362892, Lr:0.0001\n",
      "Epoch 24, Step: 65, Loss: 0.01189415529370308, Lr:0.0001\n",
      "Epoch 24, Step: 66, Loss: 0.09568747133016586, Lr:0.0001\n",
      "Epoch 24, Step: 67, Loss: 0.04825013875961304, Lr:0.0001\n",
      "Epoch 24, Step: 68, Loss: 0.18017946183681488, Lr:0.0001\n",
      "Epoch 24, Step: 69, Loss: 0.004848287906497717, Lr:0.0001\n",
      "Epoch 24, Step: 70, Loss: 0.003906839992851019, Lr:0.0001\n",
      "Epoch 24, Step: 71, Loss: 0.1397317349910736, Lr:0.0001\n",
      "Epoch 24, Step: 72, Loss: 0.02417786791920662, Lr:0.0001\n",
      "Epoch 24, Step: 73, Loss: 0.020529985427856445, Lr:0.0001\n",
      "Epoch 24, Step: 74, Loss: 0.02226453274488449, Lr:0.0001\n",
      "Epoch 24, Step: 75, Loss: 0.07397515326738358, Lr:0.0001\n",
      "Epoch 24, Step: 76, Loss: 0.12071120738983154, Lr:0.0001\n",
      "Epoch 24, Step: 77, Loss: 0.003182129468768835, Lr:0.0001\n",
      "Epoch 24, Step: 78, Loss: 0.013908524066209793, Lr:0.0001\n",
      "Epoch 24, Step: 79, Loss: 0.02609327808022499, Lr:0.0001\n",
      "Epoch 24, Step: 80, Loss: 0.04841127246618271, Lr:0.0001\n",
      "Epoch 24, Step: 81, Loss: 0.007030772510915995, Lr:0.0001\n",
      "Epoch 24, Step: 82, Loss: 0.12186551094055176, Lr:0.0001\n",
      "Epoch 24, Step: 83, Loss: 0.046819306910037994, Lr:0.0001\n",
      "Epoch 24, Step: 84, Loss: 0.052199769765138626, Lr:0.0001\n",
      "Epoch 24, Step: 85, Loss: 0.08622150123119354, Lr:0.0001\n",
      "Epoch 24, Step: 86, Loss: 0.010795698501169682, Lr:0.0001\n",
      "Epoch 24, Step: 87, Loss: 0.012895608320832253, Lr:0.0001\n",
      "Epoch 24, Step: 88, Loss: 0.051269352436065674, Lr:0.0001\n",
      "Epoch 24, Step: 89, Loss: 0.0025970800779759884, Lr:0.0001\n",
      "Epoch 24, Step: 90, Loss: 0.08525349944829941, Lr:0.0001\n",
      "Epoch 24, Step: 91, Loss: 0.01946946047246456, Lr:0.0001\n",
      "Epoch 24, Step: 92, Loss: 0.01584184169769287, Lr:0.0001\n",
      "Epoch 24, Step: 93, Loss: 0.050282787531614304, Lr:0.0001\n",
      "Epoch 24, Step: 94, Loss: 0.05934716388583183, Lr:0.0001\n",
      "Epoch 24, Step: 95, Loss: 0.04933442175388336, Lr:0.0001\n",
      "Epoch 24, Step: 96, Loss: 0.020295560359954834, Lr:0.0001\n",
      "Epoch 24, Step: 97, Loss: 0.020835919305682182, Lr:0.0001\n",
      "Epoch 24, Step: 98, Loss: 0.01868383027613163, Lr:0.0001\n",
      "Epoch 24, Step: 99, Loss: 0.014814767986536026, Lr:0.0001\n",
      "Epoch 24, Step: 100, Loss: 0.11335216462612152, Lr:0.0001\n",
      "Epoch 24, Step: 101, Loss: 0.012426517903804779, Lr:0.0001\n",
      "Epoch 24, Step: 102, Loss: 0.1477580964565277, Lr:0.0001\n",
      "Epoch 24, Step: 103, Loss: 0.02743856981396675, Lr:0.0001\n",
      "Epoch 24, Step: 104, Loss: 0.08515457808971405, Lr:0.0001\n",
      "Epoch 24, Step: 105, Loss: 0.00098352727945894, Lr:0.0001\n",
      "Epoch 24, Step: 106, Loss: 0.2741256356239319, Lr:0.0001\n",
      "Epoch 24, Step: 107, Loss: 0.0036135539412498474, Lr:0.0001\n",
      "Epoch 24, Step: 108, Loss: 0.15666897594928741, Lr:0.0001\n",
      "Epoch 24, Step: 109, Loss: 0.044528111815452576, Lr:0.0001\n",
      "Epoch 24, Step: 110, Loss: 0.16565780341625214, Lr:0.0001\n",
      "Epoch 24, Step: 111, Loss: 0.018207330256700516, Lr:0.0001\n",
      "Epoch 24, Step: 112, Loss: 0.005099584814161062, Lr:0.0001\n",
      "Epoch 24, Step: 113, Loss: 0.15454433858394623, Lr:0.0001\n",
      "Epoch 24, Step: 114, Loss: 0.05894766002893448, Lr:0.0001\n",
      "Epoch 24, Step: 115, Loss: 0.012985026463866234, Lr:0.0001\n",
      "Epoch 24, Step: 116, Loss: 0.03140703961253166, Lr:0.0001\n",
      "Epoch 24, Step: 117, Loss: 0.07285021990537643, Lr:0.0001\n",
      "Epoch 24, Step: 118, Loss: 0.2288903146982193, Lr:0.0001\n",
      "Epoch 24, Step: 119, Loss: 0.09219478815793991, Lr:0.0001\n",
      "Epoch 24, Step: 120, Loss: 0.1116131916642189, Lr:0.0001\n",
      "Epoch 24, Step: 121, Loss: 0.08878858387470245, Lr:0.0001\n",
      "Epoch 24, Step: 122, Loss: 0.008335035294294357, Lr:0.0001\n",
      "Epoch 24, Step: 123, Loss: 0.022766824811697006, Lr:0.0001\n",
      "Epoch 24, Step: 124, Loss: 0.009789470583200455, Lr:0.0001\n",
      "Epoch 24, Step: 125, Loss: 0.003413985949009657, Lr:0.0001\n",
      "Epoch 24, Step: 126, Loss: 0.2973267734050751, Lr:0.0001\n",
      "Epoch 24, Step: 127, Loss: 0.04232494533061981, Lr:0.0001\n",
      "Epoch 24, Step: 128, Loss: 0.04224687069654465, Lr:0.0001\n",
      "Epoch 24, Step: 129, Loss: 0.19376324117183685, Lr:0.0001\n",
      "Epoch 24, Step: 130, Loss: 0.005616030190140009, Lr:0.0001\n",
      "Epoch 24, Step: 131, Loss: 0.1291075199842453, Lr:0.0001\n",
      "Epoch 24, Step: 132, Loss: 0.323687344789505, Lr:0.0001\n",
      "Epoch 24, Step: 133, Loss: 0.09127993881702423, Lr:0.0001\n",
      "Epoch 24, Step: 134, Loss: 0.0012247548438608646, Lr:0.0001\n",
      "Epoch 24, Step: 135, Loss: 0.03797656670212746, Lr:0.0001\n",
      "Epoch 24, Step: 136, Loss: 0.36218157410621643, Lr:0.0001\n",
      "Epoch 24, Step: 137, Loss: 0.09470713138580322, Lr:0.0001\n",
      "Epoch 24, Step: 138, Loss: 0.03500639274716377, Lr:0.0001\n",
      "Epoch 24, Step: 139, Loss: 0.04454959183931351, Lr:0.0001\n",
      "Epoch 24, Step: 140, Loss: 0.029258092865347862, Lr:0.0001\n",
      "Epoch 24, Step: 141, Loss: 0.11051438748836517, Lr:0.0001\n",
      "Epoch 24, Step: 142, Loss: 0.049584053456783295, Lr:0.0001\n",
      "Epoch 24, Step: 143, Loss: 0.012704829685389996, Lr:0.0001\n",
      "Epoch 24, Step: 144, Loss: 0.0035059868823736906, Lr:0.0001\n",
      "Epoch 24, Step: 145, Loss: 0.07656051218509674, Lr:0.0001\n",
      "Epoch 24, Step: 146, Loss: 0.0063059390522539616, Lr:0.0001\n",
      "Epoch 24, Step: 147, Loss: 0.0030565240886062384, Lr:0.0001\n",
      "Epoch 24, Step: 148, Loss: 0.08120174705982208, Lr:0.0001\n",
      "Epoch 24, Step: 149, Loss: 0.014459844678640366, Lr:0.0001\n",
      "Epoch 24, Step: 150, Loss: 0.01740831881761551, Lr:0.0001\n",
      "Epoch 24, Step: 151, Loss: 0.006740953307598829, Lr:0.0001\n",
      "Epoch 24, Step: 152, Loss: 0.02280215546488762, Lr:0.0001\n",
      "Epoch 24, Step: 153, Loss: 0.2375091165304184, Lr:0.0001\n",
      "Epoch 24, Step: 154, Loss: 0.04665031656622887, Lr:0.0001\n",
      "Epoch 24, Step: 155, Loss: 0.20447957515716553, Lr:0.0001\n",
      "Epoch 24, Step: 156, Loss: 0.05272364988923073, Lr:0.0001\n",
      "Epoch 24, Step: 157, Loss: 0.2902255058288574, Lr:0.0001\n",
      "Epoch 24, Step: 158, Loss: 0.06365600228309631, Lr:0.0001\n",
      "Epoch 24, Step: 159, Loss: 0.01643303595483303, Lr:0.0001\n",
      "Epoch 24, Step: 160, Loss: 0.041025061160326004, Lr:0.0001\n",
      "Epoch 24, Step: 161, Loss: 0.010488716885447502, Lr:0.0001\n",
      "Epoch 24, Step: 162, Loss: 0.029042115435004234, Lr:0.0001\n",
      "Epoch 24, Step: 163, Loss: 0.039581406861543655, Lr:0.0001\n",
      "Epoch 24, Step: 164, Loss: 0.016389185562729836, Lr:0.0001\n",
      "Epoch 24, Step: 165, Loss: 0.13883133232593536, Lr:0.0001\n",
      "Epoch 24, Step: 166, Loss: 0.002025878755375743, Lr:0.0001\n",
      "Epoch 24, Step: 167, Loss: 0.15920375287532806, Lr:0.0001\n",
      "Epoch 24, Step: 168, Loss: 0.018748847767710686, Lr:0.0001\n",
      "Epoch 24, Step: 169, Loss: 0.052897222340106964, Lr:0.0001\n",
      "Epoch 24, Step: 170, Loss: 0.003373046638444066, Lr:0.0001\n",
      "Epoch 24, Step: 171, Loss: 0.011431857943534851, Lr:0.0001\n",
      "Epoch 24, Step: 172, Loss: 0.14463171362876892, Lr:0.0001\n",
      "Epoch 24, Step: 173, Loss: 0.022412152960896492, Lr:0.0001\n",
      "Epoch 24, Step: 174, Loss: 0.0013180384412407875, Lr:0.0001\n",
      "Epoch 24, Step: 175, Loss: 0.01019488275051117, Lr:0.0001\n",
      "Epoch 24, Step: 176, Loss: 0.16101092100143433, Lr:0.0001\n",
      "Epoch 24, Step: 177, Loss: 0.0725044384598732, Lr:0.0001\n",
      "Epoch 24, Step: 178, Loss: 0.03465808555483818, Lr:0.0001\n",
      "Epoch 24, Step: 179, Loss: 0.008906195871531963, Lr:0.0001\n",
      "Epoch 24, Step: 180, Loss: 0.12043193727731705, Lr:0.0001\n",
      "Epoch 24, Step: 181, Loss: 0.07131493836641312, Lr:0.0001\n",
      "Epoch 24, Step: 182, Loss: 0.009784935973584652, Lr:0.0001\n",
      "Epoch 24, Step: 183, Loss: 0.08450004458427429, Lr:0.0001\n",
      "Epoch 24, Step: 184, Loss: 0.0014129147166386247, Lr:0.0001\n",
      "Epoch 24, Step: 185, Loss: 0.012208831496536732, Lr:0.0001\n",
      "Epoch 24, Step: 186, Loss: 0.06111534684896469, Lr:0.0001\n",
      "Epoch 24, Step: 187, Loss: 0.054478466510772705, Lr:0.0001\n",
      "Epoch 24, Step: 188, Loss: 0.004899540916085243, Lr:0.0001\n",
      "Epoch 24, Step: 189, Loss: 0.0037339674308896065, Lr:0.0001\n",
      "Epoch 24, Step: 190, Loss: 0.003500155871734023, Lr:0.0001\n",
      "Epoch 24, Step: 191, Loss: 0.01009626965969801, Lr:0.0001\n",
      "Epoch 24, Step: 192, Loss: 0.01663532294332981, Lr:0.0001\n",
      "Epoch 24, Step: 193, Loss: 0.024063369259238243, Lr:0.0001\n",
      "Epoch 24, Step: 194, Loss: 0.017317362129688263, Lr:0.0001\n",
      "Epoch 24, Step: 195, Loss: 0.005382748320698738, Lr:0.0001\n",
      "Epoch 24, Step: 196, Loss: 0.0028693457134068012, Lr:0.0001\n",
      "Epoch 24, Step: 197, Loss: 0.05589589104056358, Lr:0.0001\n",
      "Epoch 24, Step: 198, Loss: 0.10113773494958878, Lr:0.0001\n",
      "Epoch 24, Step: 199, Loss: 0.16889360547065735, Lr:0.0001\n",
      "Epoch 24, Step: 200, Loss: 0.007745080161839724, Lr:0.0001\n",
      "Epoch 24, Step: 201, Loss: 0.0587591826915741, Lr:0.0001\n",
      "Epoch 24, Step: 202, Loss: 0.16318604350090027, Lr:0.0001\n",
      "Epoch 24, Step: 203, Loss: 0.04598314315080643, Lr:0.0001\n",
      "Epoch 24, Step: 204, Loss: 0.08178234100341797, Lr:0.0001\n",
      "Epoch 24, Step: 205, Loss: 0.08037048578262329, Lr:0.0001\n",
      "Epoch 24, Step: 206, Loss: 0.25610092282295227, Lr:0.0001\n",
      "Epoch 24, Step: 207, Loss: 0.04765491187572479, Lr:0.0001\n",
      "Epoch 24, Step: 208, Loss: 0.023586474359035492, Lr:0.0001\n",
      "Epoch 24, Step: 209, Loss: 0.011803949251770973, Lr:0.0001\n",
      "Epoch 24, Step: 210, Loss: 0.09602447599172592, Lr:0.0001\n",
      "Epoch 24, Step: 211, Loss: 0.006790494546294212, Lr:0.0001\n",
      "Epoch 24, Step: 212, Loss: 0.10151461511850357, Lr:0.0001\n",
      "Epoch 24, Step: 213, Loss: 0.364103764295578, Lr:0.0001\n",
      "Epoch 24, Step: 214, Loss: 0.0017002393724396825, Lr:0.0001\n",
      "Epoch 24, Step: 215, Loss: 0.004411018453538418, Lr:0.0001\n",
      "Epoch 24, Step: 216, Loss: 0.005927768535912037, Lr:0.0001\n",
      "Epoch 24, Step: 217, Loss: 0.021640149876475334, Lr:0.0001\n",
      "Epoch 24, Step: 218, Loss: 0.2344241887331009, Lr:0.0001\n",
      "Epoch 24, Step: 219, Loss: 0.0044477214105427265, Lr:0.0001\n",
      "Epoch 24, Step: 220, Loss: 0.024593524634838104, Lr:0.0001\n",
      "Epoch 24, Step: 221, Loss: 0.10444313287734985, Lr:0.0001\n",
      "Epoch 24, Step: 222, Loss: 0.029092634096741676, Lr:0.0001\n",
      "Epoch 24, Step: 223, Loss: 0.019891930744051933, Lr:0.0001\n",
      "Epoch 24, Step: 224, Loss: 0.02598375454545021, Lr:0.0001\n",
      "Epoch 24, Step: 225, Loss: 0.07749399542808533, Lr:0.0001\n",
      "Epoch 24, Step: 226, Loss: 0.0033199884928762913, Lr:0.0001\n",
      "Epoch 24, Step: 227, Loss: 0.08364065736532211, Lr:0.0001\n",
      "Epoch 24, Step: 228, Loss: 0.20285926759243011, Lr:0.0001\n",
      "Epoch 24, Step: 229, Loss: 0.022084608674049377, Lr:0.0001\n",
      "Epoch 24, Step: 230, Loss: 0.006801193580031395, Lr:0.0001\n",
      "Epoch 24, Step: 231, Loss: 0.13693076372146606, Lr:0.0001\n",
      "Epoch 24, Step: 232, Loss: 0.002751964842900634, Lr:0.0001\n",
      "Epoch 24, Step: 233, Loss: 0.03032924234867096, Lr:0.0001\n",
      "Epoch 24, Step: 234, Loss: 0.0263488981872797, Lr:0.0001\n",
      "Epoch 24, Step: 235, Loss: 0.007669617887586355, Lr:0.0001\n",
      "Epoch 24, Step: 236, Loss: 0.002128069754689932, Lr:0.0001\n",
      "Epoch 24, Step: 237, Loss: 0.053053926676511765, Lr:0.0001\n",
      "Epoch 24, Step: 238, Loss: 0.07620445638895035, Lr:0.0001\n",
      "Epoch 24, Step: 239, Loss: 0.18504875898361206, Lr:0.0001\n",
      "Epoch 24, Step: 240, Loss: 0.027574658393859863, Lr:0.0001\n",
      "Epoch 24, Step: 241, Loss: 0.1286964863538742, Lr:0.0001\n",
      "Epoch 24, Step: 242, Loss: 0.07125450670719147, Lr:0.0001\n",
      "Epoch 24, Step: 243, Loss: 0.22486598789691925, Lr:0.0001\n",
      "Epoch 24, Step: 244, Loss: 0.003408401506021619, Lr:0.0001\n",
      "Epoch 24, Step: 245, Loss: 0.035573143512010574, Lr:0.0001\n",
      "Epoch 24, Step: 246, Loss: 0.06417607516050339, Lr:0.0001\n",
      "Epoch 24, Step: 247, Loss: 0.0023725214414298534, Lr:0.0001\n",
      "Epoch 24, Step: 248, Loss: 0.06246214359998703, Lr:0.0001\n",
      "Epoch 24, Step: 249, Loss: 0.08465205878019333, Lr:0.0001\n",
      "Epoch 24, Step: 250, Loss: 0.16845689713954926, Lr:0.0001\n",
      "Epoch 24, Step: 251, Loss: 0.16690802574157715, Lr:0.0001\n",
      "Epoch 24, Step: 252, Loss: 0.017296552658081055, Lr:0.0001\n",
      "Epoch 24, Step: 253, Loss: 0.005422394722700119, Lr:0.0001\n",
      "Epoch 24, Step: 254, Loss: 0.047513287514448166, Lr:0.0001\n",
      "Epoch 24, Step: 255, Loss: 0.02450638823211193, Lr:0.0001\n",
      "Epoch 24, Step: 256, Loss: 0.09531796723604202, Lr:0.0001\n",
      "Epoch 24, Step: 257, Loss: 0.01969234272837639, Lr:0.0001\n",
      "Epoch 24, Step: 258, Loss: 0.07402000576257706, Lr:0.0001\n",
      "Epoch 24, Step: 259, Loss: 0.053510747849941254, Lr:0.0001\n",
      "Epoch 24, Step: 260, Loss: 0.004509760998189449, Lr:0.0001\n",
      "Epoch 24, Step: 261, Loss: 0.021662715822458267, Lr:0.0001\n",
      "Epoch 24, Step: 262, Loss: 0.16437381505966187, Lr:0.0001\n",
      "Epoch 24, Step: 263, Loss: 0.091372050344944, Lr:0.0001\n",
      "Epoch 24, Step: 264, Loss: 0.05201268941164017, Lr:0.0001\n",
      "Epoch 24, Step: 265, Loss: 0.0009250666480511427, Lr:0.0001\n",
      "Epoch 24, Step: 266, Loss: 0.07225082069635391, Lr:0.0001\n",
      "Epoch 24, Step: 267, Loss: 0.02721562050282955, Lr:0.0001\n",
      "Epoch 24, Step: 268, Loss: 0.01322617195546627, Lr:0.0001\n",
      "Epoch 24, Step: 269, Loss: 0.03959870710968971, Lr:0.0001\n",
      "Epoch 24, Step: 270, Loss: 0.021590664982795715, Lr:0.0001\n",
      "Epoch 24, Step: 271, Loss: 0.17151185870170593, Lr:0.0001\n",
      "Epoch 24, Step: 272, Loss: 0.1290929913520813, Lr:0.0001\n",
      "Epoch 24, Step: 273, Loss: 0.22698725759983063, Lr:0.0001\n",
      "Epoch 24, Step: 274, Loss: 0.025148184970021248, Lr:0.0001\n",
      "Epoch 24, Step: 275, Loss: 0.07003474235534668, Lr:0.0001\n",
      "Epoch 24, Step: 276, Loss: 0.06101489067077637, Lr:0.0001\n",
      "Epoch 24, Step: 277, Loss: 0.16391439735889435, Lr:0.0001\n",
      "Epoch 24, Step: 278, Loss: 0.038559988141059875, Lr:0.0001\n",
      "Epoch 24, Step: 279, Loss: 0.08383114635944366, Lr:0.0001\n",
      "Epoch 24, Step: 280, Loss: 0.02320231683552265, Lr:0.0001\n",
      "Epoch 24, Step: 281, Loss: 0.006646519526839256, Lr:0.0001\n",
      "Epoch 24, Step: 282, Loss: 0.007658327929675579, Lr:0.0001\n",
      "Epoch 24, Step: 283, Loss: 0.17787010967731476, Lr:0.0001\n",
      "Epoch 24, Step: 284, Loss: 0.17398907244205475, Lr:0.0001\n",
      "Epoch 24, Step: 285, Loss: 0.1237873062491417, Lr:0.0001\n",
      "Epoch 24, Step: 286, Loss: 0.04281298816204071, Lr:0.0001\n",
      "Epoch 24, Step: 287, Loss: 0.04442926123738289, Lr:0.0001\n",
      "Epoch 24, Step: 288, Loss: 0.02611357718706131, Lr:0.0001\n",
      "Epoch 24, Step: 289, Loss: 0.09388948231935501, Lr:0.0001\n",
      "Epoch 24, Step: 290, Loss: 0.0037844281177967787, Lr:0.0001\n",
      "Epoch 24, Step: 291, Loss: 0.023268669843673706, Lr:0.0001\n",
      "Epoch 24, Step: 292, Loss: 0.011008704081177711, Lr:0.0001\n",
      "Epoch 24, Step: 293, Loss: 0.0763370543718338, Lr:0.0001\n",
      "Epoch 24, Step: 294, Loss: 0.02059824950993061, Lr:0.0001\n",
      "Epoch 24, Step: 295, Loss: 0.02042173407971859, Lr:0.0001\n",
      "Epoch 24, Step: 296, Loss: 0.023211341351270676, Lr:0.0001\n",
      "Epoch 24, Step: 297, Loss: 0.03218663111329079, Lr:0.0001\n",
      "Epoch 24, Step: 298, Loss: 0.039038531482219696, Lr:0.0001\n",
      "Epoch 24, Step: 299, Loss: 0.000545424991287291, Lr:0.0001\n",
      "Epoch 24, Step: 300, Loss: 0.010640246793627739, Lr:0.0001\n",
      "Epoch 24, Step: 301, Loss: 0.0021786028519272804, Lr:0.0001\n",
      "Epoch 24, Step: 302, Loss: 0.03902915492653847, Lr:0.0001\n",
      "Epoch 24, Step: 303, Loss: 0.028337299823760986, Lr:0.0001\n",
      "Epoch 24, Step: 304, Loss: 0.1819782555103302, Lr:0.0001\n",
      "Epoch 24, Step: 305, Loss: 0.019023122265934944, Lr:0.0001\n",
      "Epoch 24, Step: 306, Loss: 0.018814656883478165, Lr:0.0001\n",
      "Epoch 24, Step: 307, Loss: 0.027676602825522423, Lr:0.0001\n",
      "Epoch 24, Step: 308, Loss: 0.027414264157414436, Lr:0.0001\n",
      "Epoch 24, Step: 309, Loss: 0.15735498070716858, Lr:0.0001\n",
      "Epoch 24, Step: 310, Loss: 0.2331579476594925, Lr:0.0001\n",
      "Epoch 24, Step: 311, Loss: 0.020130163058638573, Lr:0.0001\n",
      "Epoch 24, Step: 312, Loss: 0.18550418317317963, Lr:0.0001\n",
      "Epoch 24, Step: 313, Loss: 0.004927691072225571, Lr:0.0001\n",
      "Epoch 24, Step: 314, Loss: 0.020033640787005424, Lr:0.0001\n",
      "Epoch 24, Step: 315, Loss: 0.005047876853495836, Lr:0.0001\n",
      "Epoch 24, Step: 316, Loss: 0.24457497894763947, Lr:0.0001\n",
      "Epoch 24, Step: 317, Loss: 0.11801667511463165, Lr:0.0001\n",
      "Epoch 24, Step: 318, Loss: 0.16250742971897125, Lr:0.0001\n",
      "Epoch 24, Step: 319, Loss: 0.04872148111462593, Lr:0.0001\n",
      "Epoch 24, Step: 320, Loss: 0.01896105334162712, Lr:0.0001\n",
      "Epoch 24, Step: 321, Loss: 0.09886026382446289, Lr:0.0001\n",
      "Epoch 24, Step: 322, Loss: 0.028551708906888962, Lr:0.0001\n",
      "Epoch 24, Step: 323, Loss: 0.15602046251296997, Lr:0.0001\n",
      "Epoch 24, Step: 324, Loss: 0.12038101255893707, Lr:0.0001\n",
      "Epoch 24, Step: 325, Loss: 0.17807289958000183, Lr:0.0001\n",
      "Epoch 24, Step: 326, Loss: 0.07762704789638519, Lr:0.0001\n",
      "Epoch 24, Step: 327, Loss: 0.24846433103084564, Lr:0.0001\n",
      "Epoch 24, Step: 328, Loss: 0.0009662781958468258, Lr:0.0001\n",
      "Epoch 24, Step: 329, Loss: 0.09387420117855072, Lr:0.0001\n",
      "Epoch 24, Step: 330, Loss: 0.004587836097925901, Lr:0.0001\n",
      "Epoch 24, Step: 331, Loss: 0.010831117630004883, Lr:0.0001\n",
      "Epoch 24, Step: 332, Loss: 0.03231482207775116, Lr:0.0001\n",
      "Epoch 24, Step: 333, Loss: 0.09959874302148819, Lr:0.0001\n",
      "Epoch 24, Step: 334, Loss: 0.1768231838941574, Lr:0.0001\n",
      "Epoch 24, Step: 335, Loss: 0.05890531465411186, Lr:0.0001\n",
      "Epoch 24, Step: 336, Loss: 0.057757362723350525, Lr:0.0001\n",
      "Epoch 24, Step: 337, Loss: 0.010341768153011799, Lr:0.0001\n",
      "Epoch 24, Step: 338, Loss: 0.11108066141605377, Lr:0.0001\n",
      "Epoch 24, Step: 339, Loss: 0.01312955841422081, Lr:0.0001\n",
      "Epoch 24, Step: 340, Loss: 0.006125675514340401, Lr:0.0001\n",
      "Epoch 24, Step: 341, Loss: 0.009315915405750275, Lr:0.0001\n",
      "Epoch 24, Step: 342, Loss: 0.3265487253665924, Lr:0.0001\n",
      "Epoch 24, Step: 343, Loss: 0.032319433987140656, Lr:0.0001\n",
      "Epoch 24, Step: 344, Loss: 0.007172148209065199, Lr:0.0001\n",
      "Epoch 24, Step: 345, Loss: 0.06873852014541626, Lr:0.0001\n",
      "Epoch 24, Step: 346, Loss: 0.04552033543586731, Lr:0.0001\n",
      "Epoch 24, Step: 347, Loss: 0.07847794145345688, Lr:0.0001\n",
      "Epoch 24, Step: 348, Loss: 0.02899148315191269, Lr:0.0001\n",
      "Epoch 24, Step: 349, Loss: 0.0063211871311068535, Lr:0.0001\n",
      "Epoch 24, Step: 350, Loss: 0.13971690833568573, Lr:0.0001\n",
      "Epoch 24, Step: 351, Loss: 0.20713789761066437, Lr:0.0001\n",
      "Epoch 24, Step: 352, Loss: 0.021164163947105408, Lr:0.0001\n",
      "Epoch 24, Step: 353, Loss: 0.025065531954169273, Lr:0.0001\n",
      "Epoch 24, Step: 354, Loss: 0.0031710469629615545, Lr:0.0001\n",
      "Epoch 24, Step: 355, Loss: 0.03455175459384918, Lr:0.0001\n",
      "Epoch 24, Step: 356, Loss: 0.04335123300552368, Lr:0.0001\n",
      "Epoch 24, Step: 357, Loss: 0.02758558839559555, Lr:0.0001\n",
      "Epoch 24, Step: 358, Loss: 0.04745205119252205, Lr:0.0001\n",
      "Epoch 24, Step: 359, Loss: 0.08464238792657852, Lr:0.0001\n",
      "Epoch 24, Step: 360, Loss: 0.011849777773022652, Lr:0.0001\n",
      "Epoch 24, Step: 361, Loss: 0.04994342103600502, Lr:0.0001\n",
      "Epoch 24, Step: 362, Loss: 0.023816725239157677, Lr:0.0001\n",
      "Epoch 24, Step: 363, Loss: 0.013620172627270222, Lr:0.0001\n",
      "Epoch 24, Step: 364, Loss: 0.29193806648254395, Lr:0.0001\n",
      "Epoch 24, Step: 365, Loss: 0.1311110109090805, Lr:0.0001\n",
      "Epoch 24, Step: 366, Loss: 0.07119131833314896, Lr:0.0001\n",
      "Epoch 24, Step: 367, Loss: 0.04927220568060875, Lr:0.0001\n",
      "Epoch 24, Step: 368, Loss: 0.02170395292341709, Lr:0.0001\n",
      "Epoch 24, Step: 369, Loss: 0.1665332317352295, Lr:0.0001\n",
      "Epoch 24, Step: 370, Loss: 0.005165682639926672, Lr:0.0001\n",
      "Epoch 24, Step: 371, Loss: 0.0007612285553477705, Lr:0.0001\n",
      "Epoch 24, Step: 372, Loss: 0.12390793114900589, Lr:0.0001\n",
      "Epoch 24, Step: 373, Loss: 0.0340275913476944, Lr:0.0001\n",
      "Epoch 24, Step: 374, Loss: 0.03553113341331482, Lr:0.0001\n",
      "Epoch 24, Step: 375, Loss: 0.21204371750354767, Lr:0.0001\n",
      "Epoch 24, Step: 376, Loss: 0.005636362358927727, Lr:0.0001\n",
      "Epoch 24, Step: 377, Loss: 0.06186289340257645, Lr:0.0001\n",
      "Epoch 24, Step: 378, Loss: 0.10185365378856659, Lr:0.0001\n",
      "Epoch 24, Step: 379, Loss: 0.006152971647679806, Lr:0.0001\n",
      "Epoch 24, Step: 380, Loss: 0.037194620817899704, Lr:0.0001\n",
      "Epoch 24, Step: 381, Loss: 0.2582305371761322, Lr:0.0001\n",
      "Epoch 24, Step: 382, Loss: 0.08625642210245132, Lr:0.0001\n",
      "Epoch 24, Step: 383, Loss: 0.1779707968235016, Lr:0.0001\n",
      "Epoch 24, Step: 384, Loss: 0.0346035361289978, Lr:0.0001\n",
      "Epoch 24, Step: 385, Loss: 0.03599797189235687, Lr:0.0001\n",
      "Epoch 24, Step: 386, Loss: 0.01253938116133213, Lr:0.0001\n",
      "Epoch 24, Step: 387, Loss: 0.003869849955663085, Lr:0.0001\n",
      "Epoch 24, Step: 388, Loss: 0.0077368468046188354, Lr:0.0001\n",
      "Epoch 24, Step: 389, Loss: 0.08475880324840546, Lr:0.0001\n",
      "Epoch 24, Step: 390, Loss: 0.2050984501838684, Lr:0.0001\n",
      "Epoch 24, Step: 391, Loss: 0.03457820042967796, Lr:0.0001\n",
      "Epoch 24, Step: 392, Loss: 0.0025522452779114246, Lr:0.0001\n",
      "Epoch 24, Step: 393, Loss: 0.015006677247583866, Lr:0.0001\n",
      "Epoch 24, Step: 394, Loss: 0.008081522770226002, Lr:0.0001\n",
      "Epoch 24, Step: 395, Loss: 0.0907297283411026, Lr:0.0001\n",
      "Epoch 24, Step: 396, Loss: 0.2378033995628357, Lr:0.0001\n",
      "Epoch 24, Step: 397, Loss: 0.10124204307794571, Lr:0.0001\n",
      "Epoch 24, Step: 398, Loss: 0.07657867670059204, Lr:0.0001\n",
      "Epoch 24, Step: 399, Loss: 0.15553592145442963, Lr:0.0001\n",
      "Epoch 24, Step: 400, Loss: 0.09219248592853546, Lr:0.0001\n",
      "Epoch 24, Step: 401, Loss: 0.1720139980316162, Lr:0.0001\n",
      "Epoch 24, Step: 402, Loss: 0.05887990444898605, Lr:0.0001\n",
      "Epoch 24, Step: 403, Loss: 0.02208513393998146, Lr:0.0001\n",
      "Epoch 24, Step: 404, Loss: 0.0006868992932140827, Lr:0.0001\n",
      "Epoch 24, Step: 405, Loss: 0.01704079657793045, Lr:0.0001\n",
      "Epoch 24, Step: 406, Loss: 0.21490561962127686, Lr:0.0001\n",
      "Epoch 24, Step: 407, Loss: 0.016386961564421654, Lr:0.0001\n",
      "Epoch 24, Step: 408, Loss: 0.055088821798563004, Lr:0.0001\n",
      "Epoch 24, Step: 409, Loss: 0.20322971045970917, Lr:0.0001\n",
      "Epoch 24, Step: 410, Loss: 0.0008732679998502135, Lr:0.0001\n",
      "Epoch 24, Step: 411, Loss: 0.01859799586236477, Lr:0.0001\n",
      "Epoch 24, Step: 412, Loss: 0.06722865253686905, Lr:0.0001\n",
      "Epoch 24, Step: 413, Loss: 0.14321036636829376, Lr:0.0001\n",
      "Epoch 24, Step: 414, Loss: 0.1657017469406128, Lr:0.0001\n",
      "Epoch 24, Step: 415, Loss: 0.10933976620435715, Lr:0.0001\n",
      "Epoch 24, Step: 416, Loss: 0.01464727334678173, Lr:0.0001\n",
      "Epoch 24, Step: 417, Loss: 0.01948980800807476, Lr:0.0001\n",
      "Epoch 24, Step: 418, Loss: 0.014936738647520542, Lr:0.0001\n",
      "Epoch 24, Step: 419, Loss: 0.002788987010717392, Lr:0.0001\n",
      "Epoch 24, Step: 420, Loss: 0.1613779217004776, Lr:0.0001\n",
      "Epoch 24, Step: 421, Loss: 0.0578373484313488, Lr:0.0001\n",
      "Epoch 24, Step: 422, Loss: 0.06797941029071808, Lr:0.0001\n",
      "Epoch 24, Step: 423, Loss: 0.008144726976752281, Lr:0.0001\n",
      "Epoch 24, Step: 424, Loss: 0.015439879149198532, Lr:0.0001\n",
      "Epoch 24, Step: 425, Loss: 0.16420555114746094, Lr:0.0001\n",
      "Epoch 24, Step: 426, Loss: 0.05402674525976181, Lr:0.0001\n",
      "Epoch 24, Step: 427, Loss: 0.024596888571977615, Lr:0.0001\n",
      "Epoch 24, Step: 428, Loss: 0.03695562109351158, Lr:0.0001\n",
      "Epoch 24, Step: 429, Loss: 0.06895946711301804, Lr:0.0001\n",
      "Epoch 24, Step: 430, Loss: 0.05370542034506798, Lr:0.0001\n",
      "Epoch 24, Step: 431, Loss: 0.07430582493543625, Lr:0.0001\n",
      "Epoch 24, Step: 432, Loss: 0.26459458470344543, Lr:0.0001\n",
      "Epoch 24, Step: 433, Loss: 0.002706925617530942, Lr:0.0001\n",
      "Epoch 24, Step: 434, Loss: 0.048135772347450256, Lr:0.0001\n",
      "Epoch 24, Step: 435, Loss: 0.019416607916355133, Lr:0.0001\n",
      "Epoch 24, Step: 436, Loss: 0.0011492233024910092, Lr:0.0001\n",
      "Epoch 24, Step: 437, Loss: 0.17391303181648254, Lr:0.0001\n",
      "Epoch 24, Step: 438, Loss: 0.012538526207208633, Lr:0.0001\n",
      "Epoch 24, Step: 439, Loss: 0.008106188848614693, Lr:0.0001\n",
      "Epoch 24, Step: 440, Loss: 0.08414409309625626, Lr:0.0001\n",
      "Epoch 24, Step: 441, Loss: 0.059503551572561264, Lr:0.0001\n",
      "Epoch 24, Step: 442, Loss: 0.0028672043699771166, Lr:0.0001\n",
      "Epoch 24, Step: 443, Loss: 0.026585891842842102, Lr:0.0001\n",
      "Epoch 24, Step: 444, Loss: 0.1492399424314499, Lr:0.0001\n",
      "Epoch 24, Step: 445, Loss: 0.09562721103429794, Lr:0.0001\n",
      "Epoch 24, Step: 446, Loss: 0.047053635120391846, Lr:0.0001\n",
      "Epoch 24, Step: 447, Loss: 0.04918726161122322, Lr:0.0001\n",
      "Epoch 24, Step: 448, Loss: 0.07190960645675659, Lr:0.0001\n",
      "Epoch 24, Step: 449, Loss: 0.012009307742118835, Lr:0.0001\n",
      "Epoch 24, Step: 450, Loss: 0.02839372307062149, Lr:0.0001\n",
      "Epoch 24, Step: 451, Loss: 0.015152432024478912, Lr:0.0001\n",
      "Epoch 24, Step: 452, Loss: 0.06776785850524902, Lr:0.0001\n",
      "Epoch 24, Step: 453, Loss: 0.11807772517204285, Lr:0.0001\n",
      "Epoch 24, Step: 454, Loss: 0.011047529987990856, Lr:0.0001\n",
      "Epoch 24, Step: 455, Loss: 0.0016876996960490942, Lr:0.0001\n",
      "Epoch 24, Step: 456, Loss: 0.009684743359684944, Lr:0.0001\n",
      "Epoch 24, Step: 457, Loss: 0.14482423663139343, Lr:0.0001\n",
      "Epoch 24, Step: 458, Loss: 0.0816282257437706, Lr:0.0001\n",
      "Epoch 24, Step: 459, Loss: 0.008210163563489914, Lr:0.0001\n",
      "Epoch 24, Step: 460, Loss: 0.07175356894731522, Lr:0.0001\n",
      "Epoch 24, Step: 461, Loss: 0.017857342958450317, Lr:0.0001\n",
      "Epoch 24, Step: 462, Loss: 0.007804788649082184, Lr:0.0001\n",
      "Epoch 24, Step: 463, Loss: 0.029523784294724464, Lr:0.0001\n",
      "Epoch 24, Step: 464, Loss: 0.11500022560358047, Lr:0.0001\n",
      "Epoch 24, Step: 465, Loss: 0.03057911992073059, Lr:0.0001\n",
      "Epoch 24, Step: 466, Loss: 0.14135965704917908, Lr:0.0001\n",
      "Epoch 24, Step: 467, Loss: 0.034573834389448166, Lr:0.0001\n",
      "Epoch 24, Step: 468, Loss: 0.010221343487501144, Lr:0.0001\n",
      "Epoch 24, Step: 469, Loss: 0.054972074925899506, Lr:0.0001\n",
      "Epoch 24, Step: 470, Loss: 0.14707937836647034, Lr:0.0001\n",
      "Epoch 24, Step: 471, Loss: 0.07091093808412552, Lr:0.0001\n",
      "Epoch 24, Step: 472, Loss: 0.14421941339969635, Lr:0.0001\n",
      "Epoch 24, Step: 473, Loss: 0.07826162874698639, Lr:0.0001\n",
      "Epoch 24, Step: 474, Loss: 0.0982414036989212, Lr:0.0001\n",
      "Epoch 24, Step: 475, Loss: 0.45428475737571716, Lr:0.0001\n",
      "Epoch 24, Step: 476, Loss: 0.014343209564685822, Lr:0.0001\n",
      "Epoch 24, Step: 477, Loss: 0.0008693141280673444, Lr:0.0001\n",
      "Epoch 24, Step: 478, Loss: 0.3708270490169525, Lr:0.0001\n",
      "Epoch 24, Step: 479, Loss: 0.06883222609758377, Lr:0.0001\n",
      "Epoch 24, Step: 480, Loss: 0.15242552757263184, Lr:0.0001\n",
      "Epoch 24, Step: 481, Loss: 0.1198529377579689, Lr:0.0001\n",
      "Epoch 24, Step: 482, Loss: 0.006157560274004936, Lr:0.0001\n",
      "Epoch 24, Step: 483, Loss: 0.026779111474752426, Lr:0.0001\n",
      "Epoch 24, Step: 484, Loss: 0.0010010011028498411, Lr:0.0001\n",
      "Epoch 24, Step: 485, Loss: 0.010554775595664978, Lr:0.0001\n",
      "Epoch 24, Step: 486, Loss: 0.023536916822195053, Lr:0.0001\n",
      "Epoch 24, Step: 487, Loss: 0.005351561587303877, Lr:0.0001\n",
      "Epoch 24, Step: 488, Loss: 0.07750388234853745, Lr:0.0001\n",
      "Epoch 24, Step: 489, Loss: 0.04013250395655632, Lr:0.0001\n",
      "Epoch 24, Step: 490, Loss: 0.292534738779068, Lr:0.0001\n",
      "Epoch 24, Step: 491, Loss: 0.035070303827524185, Lr:0.0001\n",
      "Epoch 24, Step: 492, Loss: 0.0036037578247487545, Lr:0.0001\n",
      "Epoch 24, Step: 493, Loss: 0.0060054524801671505, Lr:0.0001\n",
      "Epoch 24, Step: 494, Loss: 0.034012120217084885, Lr:0.0001\n",
      "Epoch 24, Step: 495, Loss: 0.3934605121612549, Lr:0.0001\n",
      "Epoch 24, Step: 496, Loss: 0.19530224800109863, Lr:0.0001\n",
      "Epoch 24, Step: 497, Loss: 0.11740338802337646, Lr:0.0001\n",
      "Epoch 24, Step: 498, Loss: 0.17869439721107483, Lr:0.0001\n",
      "Epoch 24, Step: 499, Loss: 0.058936215937137604, Lr:0.0001\n",
      "Epoch 24, Step: 500, Loss: 0.011504900641739368, Lr:0.0001\n",
      "Epoch 24, Step: 501, Loss: 0.10617547482252121, Lr:0.0001\n",
      "Epoch 24, Step: 502, Loss: 0.005409212317317724, Lr:0.0001\n",
      "Epoch 24, Step: 503, Loss: 0.08686841279268265, Lr:0.0001\n",
      "Epoch 24, Step: 504, Loss: 0.040298499166965485, Lr:0.0001\n",
      "Epoch 24, Step: 505, Loss: 0.016435060650110245, Lr:0.0001\n",
      "Epoch 24, Step: 506, Loss: 0.011648164130747318, Lr:0.0001\n",
      "Epoch 24, Step: 507, Loss: 0.017124956473708153, Lr:0.0001\n",
      "Epoch 24, Step: 508, Loss: 0.02195168472826481, Lr:0.0001\n",
      "Epoch 24, Step: 509, Loss: 0.0007349651423282921, Lr:0.0001\n",
      "Epoch 24, Step: 510, Loss: 0.010652333498001099, Lr:0.0001\n",
      "Epoch 24, Step: 511, Loss: 0.39595627784729004, Lr:0.0001\n",
      "Epoch 24, Step: 512, Loss: 0.1947026252746582, Lr:0.0001\n",
      "Epoch 24, Step: 513, Loss: 0.06823086738586426, Lr:0.0001\n",
      "Epoch 24, Step: 514, Loss: 0.0018785340944305062, Lr:0.0001\n",
      "Epoch 24, Step: 515, Loss: 0.210323765873909, Lr:0.0001\n",
      "Epoch 24, Step: 516, Loss: 0.005013215821236372, Lr:0.0001\n",
      "Epoch 24, Step: 517, Loss: 0.015514394268393517, Lr:0.0001\n",
      "Epoch 24, Step: 518, Loss: 0.0259745754301548, Lr:0.0001\n",
      "Epoch 24, Step: 519, Loss: 0.11179633438587189, Lr:0.0001\n",
      "Epoch 24, Step: 520, Loss: 0.1803618222475052, Lr:0.0001\n",
      "Epoch 24, Step: 521, Loss: 0.039941754192113876, Lr:0.0001\n",
      "Epoch 24, Step: 522, Loss: 0.00742474477738142, Lr:0.0001\n",
      "Epoch 24, Step: 523, Loss: 0.44987258315086365, Lr:0.0001\n",
      "Epoch 24, Step: 524, Loss: 0.14840564131736755, Lr:0.0001\n",
      "Epoch 24, Step: 525, Loss: 0.28714510798454285, Lr:0.0001\n",
      "Epoch 24, Step: 526, Loss: 0.1082736998796463, Lr:0.0001\n",
      "Epoch 24, Step: 527, Loss: 0.1466543823480606, Lr:0.0001\n",
      "Epoch 24, Step: 528, Loss: 0.01252303272485733, Lr:0.0001\n",
      "Epoch 24, Step: 529, Loss: 0.056505024433135986, Lr:0.0001\n",
      "Epoch 24, Step: 530, Loss: 0.041954174637794495, Lr:0.0001\n",
      "Epoch 24, Step: 531, Loss: 0.23485067486763, Lr:0.0001\n",
      "Epoch 24, Step: 532, Loss: 0.12643802165985107, Lr:0.0001\n",
      "Epoch 24, Step: 533, Loss: 0.19978024065494537, Lr:0.0001\n",
      "Epoch 24, Step: 534, Loss: 0.0003059105947613716, Lr:0.0001\n",
      "Epoch 24, Step: 535, Loss: 0.011176051571965218, Lr:0.0001\n",
      "Epoch 24, Step: 536, Loss: 0.11141221970319748, Lr:0.0001\n",
      "Epoch 24, Step: 537, Loss: 0.0018810485489666462, Lr:0.0001\n",
      "Epoch 24, Step: 538, Loss: 0.10462652146816254, Lr:0.0001\n",
      "Epoch 24, Step: 539, Loss: 0.12185843288898468, Lr:0.0001\n",
      "Epoch 24, Step: 540, Loss: 0.004542163573205471, Lr:0.0001\n",
      "Epoch 24, Step: 541, Loss: 0.508952796459198, Lr:0.0001\n",
      "Epoch 24, Step: 542, Loss: 0.13084712624549866, Lr:0.0001\n",
      "Epoch 24, Step: 543, Loss: 0.0630800649523735, Lr:0.0001\n",
      "Epoch 24, Step: 544, Loss: 0.03393479809165001, Lr:0.0001\n",
      "Epoch 24, Step: 545, Loss: 0.09554408490657806, Lr:0.0001\n",
      "Epoch 24, Step: 546, Loss: 0.016063963994383812, Lr:0.0001\n",
      "Epoch 24, Step: 547, Loss: 0.02502679079771042, Lr:0.0001\n",
      "Epoch 24, Step: 548, Loss: 0.019450874999165535, Lr:0.0001\n",
      "Epoch 24, Step: 549, Loss: 0.0059288726188242435, Lr:0.0001\n",
      "Epoch 24, Step: 550, Loss: 0.03196161985397339, Lr:0.0001\n",
      "Epoch 24, Step: 551, Loss: 0.016085457056760788, Lr:0.0001\n",
      "Epoch 24, Step: 552, Loss: 0.3761957287788391, Lr:0.0001\n",
      "Epoch 24, Step: 553, Loss: 0.09064167737960815, Lr:0.0001\n",
      "Epoch 24, Step: 554, Loss: 0.03981471806764603, Lr:0.0001\n",
      "Epoch 24, Step: 555, Loss: 0.1342334896326065, Lr:0.0001\n",
      "Epoch 24, Step: 556, Loss: 0.007623985875397921, Lr:0.0001\n",
      "Epoch 24, Step: 557, Loss: 0.022666793316602707, Lr:0.0001\n",
      "Epoch 24, Step: 558, Loss: 0.015027862042188644, Lr:0.0001\n",
      "Epoch 24, Step: 559, Loss: 0.010840381495654583, Lr:0.0001\n",
      "Epoch 24, Step: 560, Loss: 0.1953093409538269, Lr:0.0001\n",
      "Epoch 24, Step: 561, Loss: 0.010678730905056, Lr:0.0001\n",
      "Epoch 24, Step: 562, Loss: 0.057315681129693985, Lr:0.0001\n",
      "Epoch 24, Step: 563, Loss: 0.11502840369939804, Lr:0.0001\n",
      "Epoch 24, Step: 564, Loss: 0.10115103423595428, Lr:0.0001\n",
      "Epoch 24, Step: 565, Loss: 0.006339724175632, Lr:0.0001\n",
      "Epoch 24, Step: 566, Loss: 0.039348896592855453, Lr:0.0001\n",
      "Epoch 24, Step: 567, Loss: 0.043702635914087296, Lr:0.0001\n",
      "Epoch 24, Step: 568, Loss: 0.011637055315077305, Lr:0.0001\n",
      "Epoch 24, Step: 569, Loss: 0.09109021723270416, Lr:0.0001\n",
      "Epoch 24, Step: 570, Loss: 0.10922835767269135, Lr:0.0001\n",
      "Epoch 24, Step: 571, Loss: 0.007152596488595009, Lr:0.0001\n",
      "Epoch 24, Step: 572, Loss: 0.017861993983387947, Lr:0.0001\n",
      "Epoch 24, Step: 573, Loss: 0.03743835911154747, Lr:0.0001\n",
      "Epoch 24, Step: 574, Loss: 0.3571583330631256, Lr:0.0001\n",
      "Epoch 24, Step: 575, Loss: 0.001095325336791575, Lr:0.0001\n",
      "Epoch 24, Step: 576, Loss: 0.10802256315946579, Lr:0.0001\n",
      "Epoch 24, Step: 577, Loss: 0.037753138691186905, Lr:0.0001\n",
      "Epoch 24, Step: 578, Loss: 0.08492772281169891, Lr:0.0001\n",
      "Epoch 24, Step: 579, Loss: 0.012205923907458782, Lr:0.0001\n",
      "Epoch 24, Step: 580, Loss: 0.023655293509364128, Lr:0.0001\n",
      "Epoch 24, Step: 581, Loss: 0.1543537825345993, Lr:0.0001\n",
      "Epoch 24, Step: 582, Loss: 0.015307135879993439, Lr:0.0001\n",
      "Epoch 24, Step: 583, Loss: 0.18462727963924408, Lr:0.0001\n",
      "Epoch 24, Step: 584, Loss: 0.028934622183442116, Lr:0.0001\n",
      "Epoch 24, Step: 585, Loss: 0.051633596420288086, Lr:0.0001\n",
      "Epoch 24, Step: 586, Loss: 0.049194589257240295, Lr:0.0001\n",
      "Epoch 24, Step: 587, Loss: 0.14843545854091644, Lr:0.0001\n",
      "Epoch 24, Step: 588, Loss: 0.15686629712581635, Lr:0.0001\n",
      "Epoch 24, Step: 589, Loss: 0.04101717099547386, Lr:0.0001\n",
      "Epoch 24, Step: 590, Loss: 0.03661661595106125, Lr:0.0001\n",
      "Epoch 24, Step: 591, Loss: 0.016327958554029465, Lr:0.0001\n",
      "Epoch 24, Step: 592, Loss: 0.005513444077223539, Lr:0.0001\n",
      "Epoch 24, Step: 593, Loss: 0.13529197871685028, Lr:0.0001\n",
      "Epoch 24, Step: 594, Loss: 0.006176438648253679, Lr:0.0001\n",
      "Epoch 24, Step: 595, Loss: 0.10451804846525192, Lr:0.0001\n",
      "Epoch 24, Step: 596, Loss: 0.019882014021277428, Lr:0.0001\n",
      "Epoch 24, Step: 597, Loss: 0.02791520394384861, Lr:0.0001\n",
      "Epoch 24, Step: 598, Loss: 0.02155929058790207, Lr:0.0001\n",
      "Epoch 24, Step: 599, Loss: 0.005643563345074654, Lr:0.0001\n",
      "Epoch 24, Step: 600, Loss: 0.00471789576113224, Lr:0.0001\n",
      "Epoch 24, Step: 601, Loss: 0.04737009480595589, Lr:0.0001\n",
      "Epoch 24, Step: 602, Loss: 0.002620312385261059, Lr:0.0001\n",
      "Epoch 24, Step: 603, Loss: 0.0012327420990914106, Lr:0.0001\n",
      "Epoch 24, Step: 604, Loss: 0.03925113007426262, Lr:0.0001\n",
      "Epoch 24, Step: 605, Loss: 0.08232631534337997, Lr:0.0001\n",
      "Epoch 24, Step: 606, Loss: 0.018196670338511467, Lr:0.0001\n",
      "Epoch 24, Step: 607, Loss: 0.006962137296795845, Lr:0.0001\n",
      "Epoch 24, Step: 608, Loss: 0.02170245535671711, Lr:0.0001\n",
      "Epoch 24, Step: 609, Loss: 0.02350040152668953, Lr:0.0001\n",
      "Epoch 24, Step: 610, Loss: 0.05087937414646149, Lr:0.0001\n",
      "Epoch 24, Step: 611, Loss: 0.002161290729418397, Lr:0.0001\n",
      "Epoch 24, Step: 612, Loss: 0.005078501533716917, Lr:0.0001\n",
      "Epoch 24, Step: 613, Loss: 0.060546599328517914, Lr:0.0001\n",
      "Epoch 24, Step: 614, Loss: 0.06762224435806274, Lr:0.0001\n",
      "Epoch 24, Step: 615, Loss: 0.015517272055149078, Lr:0.0001\n",
      "Epoch 24, Step: 616, Loss: 0.04505103826522827, Lr:0.0001\n",
      "Epoch 24, Step: 617, Loss: 0.08413607627153397, Lr:0.0001\n",
      "Epoch 24, Step: 618, Loss: 0.001078184461221099, Lr:0.0001\n",
      "Epoch 24, Step: 619, Loss: 0.07717827707529068, Lr:0.0001\n",
      "Epoch 24, Step: 620, Loss: 0.08645498007535934, Lr:0.0001\n",
      "Epoch 24, Step: 621, Loss: 0.015067685395479202, Lr:0.0001\n",
      "Epoch 24, Step: 622, Loss: 0.005743722897022963, Lr:0.0001\n",
      "Epoch 24, Step: 623, Loss: 0.16974219679832458, Lr:0.0001\n",
      "Epoch 24, Step: 624, Loss: 0.03064166009426117, Lr:0.0001\n",
      "Epoch 24, Step: 625, Loss: 0.02693179063498974, Lr:0.0001\n",
      "Epoch 24, Step: 626, Loss: 0.040487755089998245, Lr:0.0001\n",
      "Epoch 24, Step: 627, Loss: 0.00938462745398283, Lr:0.0001\n",
      "Epoch 24, Step: 628, Loss: 0.006197227165102959, Lr:0.0001\n",
      "Epoch 24, Step: 629, Loss: 0.025038886815309525, Lr:0.0001\n",
      "Epoch 24, Step: 630, Loss: 0.03298109397292137, Lr:0.0001\n",
      "Epoch 24, Step: 631, Loss: 0.08988623321056366, Lr:0.0001\n",
      "Epoch 24, Step: 632, Loss: 0.09241658449172974, Lr:0.0001\n",
      "Epoch 24, Step: 633, Loss: 0.024255868047475815, Lr:0.0001\n",
      "Epoch 24, Step: 634, Loss: 0.012751969508826733, Lr:0.0001\n",
      "Epoch 24, Step: 635, Loss: 0.0009719091467559338, Lr:0.0001\n",
      "Epoch 24, Step: 636, Loss: 0.062206514179706573, Lr:0.0001\n",
      "Epoch 24, Step: 637, Loss: 0.023349281400442123, Lr:0.0001\n",
      "Epoch 24, Step: 638, Loss: 0.015308414585888386, Lr:0.0001\n",
      "Epoch 24, Step: 639, Loss: 0.08199106156826019, Lr:0.0001\n",
      "Epoch 24, Step: 640, Loss: 0.023804016411304474, Lr:0.0001\n",
      "Epoch 24, Step: 641, Loss: 0.012405806221067905, Lr:0.0001\n",
      "Epoch 24, Step: 642, Loss: 0.0004940131329931319, Lr:0.0001\n",
      "Epoch 24, Step: 643, Loss: 0.003741899970918894, Lr:0.0001\n",
      "Epoch 24, Step: 644, Loss: 0.09074869006872177, Lr:0.0001\n",
      "Epoch 24, Step: 645, Loss: 0.009251122362911701, Lr:0.0001\n",
      "Epoch 24, Step: 646, Loss: 0.014661743305623531, Lr:0.0001\n",
      "Epoch 24, Step: 647, Loss: 0.004412883426994085, Lr:0.0001\n",
      "Epoch 24, Step: 648, Loss: 0.037012193351984024, Lr:0.0001\n",
      "Epoch 24, Step: 649, Loss: 0.04860447719693184, Lr:0.0001\n",
      "Epoch 24, Step: 650, Loss: 0.04517500475049019, Lr:0.0001\n",
      "Epoch 24, Step: 651, Loss: 0.03845883533358574, Lr:0.0001\n",
      "Epoch 24, Step: 652, Loss: 0.002161621116101742, Lr:0.0001\n",
      "Epoch 24, Step: 653, Loss: 0.02980443462729454, Lr:0.0001\n",
      "Epoch 24, Step: 654, Loss: 0.037054989486932755, Lr:0.0001\n",
      "Epoch 24, Step: 655, Loss: 0.08902394026517868, Lr:0.0001\n",
      "Epoch 24, Step: 656, Loss: 0.03972168266773224, Lr:0.0001\n",
      "Epoch 24, Step: 657, Loss: 0.05859749764204025, Lr:0.0001\n",
      "Epoch 24, Step: 658, Loss: 0.05102851614356041, Lr:0.0001\n",
      "Epoch 24, Step: 659, Loss: 0.025118110701441765, Lr:0.0001\n",
      "Epoch 24, Step: 660, Loss: 0.08135437965393066, Lr:0.0001\n",
      "Epoch 24, Step: 661, Loss: 0.0292243380099535, Lr:0.0001\n",
      "Epoch 24, Step: 662, Loss: 0.07110530138015747, Lr:0.0001\n",
      "Epoch 24, Step: 663, Loss: 0.005702429451048374, Lr:0.0001\n",
      "Epoch 24, Step: 664, Loss: 0.02867448888719082, Lr:0.0001\n",
      "Epoch 24, Step: 665, Loss: 0.005486378446221352, Lr:0.0001\n",
      "Epoch 24, Step: 666, Loss: 0.019560227170586586, Lr:0.0001\n",
      "Epoch 24, Step: 667, Loss: 0.09411470592021942, Lr:0.0001\n",
      "Epoch 24, Step: 668, Loss: 0.11075460910797119, Lr:0.0001\n",
      "Epoch 24, Step: 669, Loss: 0.1194506585597992, Lr:0.0001\n",
      "Epoch 24, Step: 670, Loss: 0.04728270322084427, Lr:0.0001\n",
      "Epoch 24, Step: 671, Loss: 0.0033785845153033733, Lr:0.0001\n",
      "Epoch 24, Step: 672, Loss: 0.2709229588508606, Lr:0.0001\n",
      "Epoch 24, Step: 673, Loss: 0.005100096110254526, Lr:0.0001\n",
      "Epoch 24, Step: 674, Loss: 0.0071883732452988625, Lr:0.0001\n",
      "Epoch 24, Step: 675, Loss: 0.09778127074241638, Lr:0.0001\n",
      "Epoch 24, Step: 676, Loss: 0.06833488494157791, Lr:0.0001\n",
      "Epoch 24, Step: 677, Loss: 0.010209998115897179, Lr:0.0001\n",
      "Epoch 24, Step: 678, Loss: 0.007197137456387281, Lr:0.0001\n",
      "Epoch 24, Step: 679, Loss: 0.017712295055389404, Lr:0.0001\n",
      "Epoch 24, Step: 680, Loss: 0.00425539817661047, Lr:0.0001\n",
      "Epoch 24, Step: 681, Loss: 0.04726672172546387, Lr:0.0001\n",
      "Epoch 24, Step: 682, Loss: 0.05754512548446655, Lr:0.0001\n",
      "Epoch 24, Step: 683, Loss: 0.0069076926447451115, Lr:0.0001\n",
      "Epoch 24, Step: 684, Loss: 0.02477382868528366, Lr:0.0001\n",
      "Epoch 24, Step: 685, Loss: 0.008657361380755901, Lr:0.0001\n",
      "Epoch 24, Step: 686, Loss: 0.1538783609867096, Lr:0.0001\n",
      "Epoch 24, Step: 687, Loss: 0.018520869314670563, Lr:0.0001\n",
      "Epoch 24, Step: 688, Loss: 0.18484683334827423, Lr:0.0001\n",
      "Epoch 24, Step: 689, Loss: 0.01232481561601162, Lr:0.0001\n",
      "Epoch 24, Step: 690, Loss: 0.010989084839820862, Lr:0.0001\n",
      "Epoch 24, Step: 691, Loss: 0.011262785643339157, Lr:0.0001\n",
      "Epoch 24, Step: 692, Loss: 0.02641645446419716, Lr:0.0001\n",
      "Epoch 24, Step: 693, Loss: 0.005472958087921143, Lr:0.0001\n",
      "Epoch 24, Step: 694, Loss: 0.00506169255822897, Lr:0.0001\n",
      "Epoch 24, Step: 695, Loss: 0.12455348670482635, Lr:0.0001\n",
      "Epoch 24, Step: 696, Loss: 0.02477027103304863, Lr:0.0001\n",
      "Epoch 24, Step: 697, Loss: 0.18312081694602966, Lr:0.0001\n",
      "Epoch 24, Step: 698, Loss: 0.15287210047245026, Lr:0.0001\n",
      "Epoch 24, Step: 699, Loss: 0.013715709559619427, Lr:0.0001\n",
      "Epoch 24, Step: 700, Loss: 0.04368004575371742, Lr:0.0001\n",
      "Epoch 24, Step: 701, Loss: 0.2250491976737976, Lr:0.0001\n",
      "Epoch 24, Step: 702, Loss: 0.014880088157951832, Lr:0.0001\n",
      "Epoch 24, Step: 703, Loss: 0.12513208389282227, Lr:0.0001\n",
      "Epoch 24, Step: 704, Loss: 0.020228562876582146, Lr:0.0001\n",
      "Epoch 24, Step: 705, Loss: 0.012378768995404243, Lr:0.0001\n",
      "Epoch 24, Step: 706, Loss: 0.004173112101852894, Lr:0.0001\n",
      "Epoch 24, Step: 707, Loss: 0.1335316151380539, Lr:0.0001\n",
      "Epoch 24, Step: 708, Loss: 0.006733303889632225, Lr:0.0001\n",
      "Epoch 24, Step: 709, Loss: 0.05824296921491623, Lr:0.0001\n",
      "Epoch 24, Step: 710, Loss: 0.10088366270065308, Lr:0.0001\n",
      "Epoch 24, Step: 711, Loss: 0.007834176532924175, Lr:0.0001\n",
      "Epoch 24, Step: 712, Loss: 0.039742570370435715, Lr:0.0001\n",
      "Epoch 24, Step: 713, Loss: 0.0478207990527153, Lr:0.0001\n",
      "Epoch 24, Step: 714, Loss: 0.010750400833785534, Lr:0.0001\n",
      "Epoch 24, Step: 715, Loss: 0.12172481417655945, Lr:0.0001\n",
      "Epoch 24, Step: 716, Loss: 0.04762740805745125, Lr:0.0001\n",
      "Epoch 24, Step: 717, Loss: 0.16265229880809784, Lr:0.0001\n",
      "Epoch 24, Step: 718, Loss: 0.06527017802000046, Lr:0.0001\n",
      "Epoch 24, Step: 719, Loss: 0.01580248773097992, Lr:0.0001\n",
      "Epoch 24, Step: 720, Loss: 0.006785671692341566, Lr:0.0001\n",
      "Epoch 24, Step: 721, Loss: 0.06074099987745285, Lr:0.0001\n",
      "Epoch 24, Step: 722, Loss: 0.001576496404595673, Lr:0.0001\n",
      "Epoch 24, Step: 723, Loss: 0.01985125243663788, Lr:0.0001\n",
      "Epoch 24, Step: 724, Loss: 0.1264282464981079, Lr:0.0001\n",
      "Epoch 24, Step: 725, Loss: 0.03643546998500824, Lr:0.0001\n",
      "Epoch 24, Step: 726, Loss: 0.005071394145488739, Lr:0.0001\n",
      "Epoch 24, Step: 727, Loss: 0.2677170932292938, Lr:0.0001\n",
      "Epoch 24, Step: 728, Loss: 0.03208007663488388, Lr:0.0001\n",
      "Epoch 24, Step: 729, Loss: 0.010896673426032066, Lr:0.0001\n",
      "Epoch 24, Step: 730, Loss: 0.01134019996970892, Lr:0.0001\n",
      "Epoch 24, Step: 731, Loss: 0.08586080372333527, Lr:0.0001\n",
      "Epoch 24, Step: 732, Loss: 0.13074122369289398, Lr:0.0001\n",
      "Epoch 24, Step: 733, Loss: 0.12367089837789536, Lr:0.0001\n",
      "Epoch 24, Step: 734, Loss: 0.006977301090955734, Lr:0.0001\n",
      "Epoch 24, Step: 735, Loss: 0.023677576333284378, Lr:0.0001\n",
      "Epoch 24, Step: 736, Loss: 0.23392289876937866, Lr:0.0001\n",
      "Epoch 24, Step: 737, Loss: 0.02077731117606163, Lr:0.0001\n",
      "Epoch 24, Step: 738, Loss: 0.0058599235489964485, Lr:0.0001\n",
      "Epoch 24, Step: 739, Loss: 0.044695667922496796, Lr:0.0001\n",
      "Epoch 24, Step: 740, Loss: 0.27668485045433044, Lr:0.0001\n",
      "Epoch 24, Step: 741, Loss: 0.034712061285972595, Lr:0.0001\n",
      "Epoch 24, Step: 742, Loss: 0.05011816695332527, Lr:0.0001\n",
      "Epoch 24, Step: 743, Loss: 0.4457389712333679, Lr:0.0001\n",
      "Epoch 24, Step: 744, Loss: 0.07694196701049805, Lr:0.0001\n",
      "Epoch 24, Step: 745, Loss: 0.1467062085866928, Lr:0.0001\n",
      "Epoch 24, Step: 746, Loss: 0.014157738536596298, Lr:0.0001\n",
      "Epoch 24, Step: 747, Loss: 0.002000058302655816, Lr:0.0001\n",
      "Epoch 24, Step: 748, Loss: 0.04236217960715294, Lr:0.0001\n",
      "Epoch 24, Step: 749, Loss: 0.1128627136349678, Lr:0.0001\n",
      "Epoch 24, Step: 750, Loss: 0.18235157430171967, Lr:0.0001\n",
      "Epoch 24, Step: 751, Loss: 0.054744936525821686, Lr:0.0001\n",
      "Epoch 24, Step: 752, Loss: 0.39386266469955444, Lr:0.0001\n",
      "Epoch 24, Step: 753, Loss: 0.004286500625312328, Lr:0.0001\n",
      "Epoch 24, Step: 754, Loss: 0.026951923966407776, Lr:0.0001\n",
      "Epoch 24, Step: 755, Loss: 0.12338479608297348, Lr:0.0001\n",
      "Epoch 24, Step: 756, Loss: 0.0574655756354332, Lr:0.0001\n",
      "Epoch 24, Step: 757, Loss: 0.012312098406255245, Lr:0.0001\n",
      "Epoch 24, Step: 758, Loss: 0.0171488169580698, Lr:0.0001\n",
      "Epoch 24, Step: 759, Loss: 0.12214589864015579, Lr:0.0001\n",
      "Epoch 24, Step: 760, Loss: 0.031869422644376755, Lr:0.0001\n",
      "Epoch 24, Step: 761, Loss: 0.0723387822508812, Lr:0.0001\n",
      "Epoch 24, Step: 762, Loss: 0.8227341175079346, Lr:0.0001\n",
      "Epoch 24, Step: 763, Loss: 0.049361374229192734, Lr:0.0001\n",
      "Epoch 24, Step: 764, Loss: 0.017464790493249893, Lr:0.0001\n",
      "Epoch 24, Step: 765, Loss: 0.10280993580818176, Lr:0.0001\n",
      "Epoch 24, Step: 766, Loss: 0.07335411757230759, Lr:0.0001\n",
      "Epoch 24, Step: 767, Loss: 0.08074986934661865, Lr:0.0001\n",
      "Epoch 24, Step: 768, Loss: 0.035779017955064774, Lr:0.0001\n",
      "Epoch 24, Step: 769, Loss: 0.006737163290381432, Lr:0.0001\n",
      "Epoch 24, Step: 770, Loss: 0.059464357793331146, Lr:0.0001\n",
      "Epoch 24, Step: 771, Loss: 0.06367658078670502, Lr:0.0001\n",
      "Epoch 24, Step: 772, Loss: 0.18849772214889526, Lr:0.0001\n",
      "Epoch 24, Step: 773, Loss: 0.006040353327989578, Lr:0.0001\n",
      "Epoch 24, Step: 774, Loss: 0.2031683772802353, Lr:0.0001\n",
      "Epoch 24, Step: 775, Loss: 0.027665773406624794, Lr:0.0001\n",
      "Epoch 24, Step: 776, Loss: 0.036137811839580536, Lr:0.0001\n",
      "Epoch 24, Step: 777, Loss: 0.003756151767447591, Lr:0.0001\n",
      "Epoch 24, Step: 778, Loss: 0.03496168553829193, Lr:0.0001\n",
      "Epoch 24, Step: 779, Loss: 0.24692006409168243, Lr:0.0001\n",
      "Epoch 24, Step: 780, Loss: 0.005528542213141918, Lr:0.0001\n",
      "Epoch 24, Step: 781, Loss: 0.01685260981321335, Lr:0.0001\n",
      "Epoch 24, Step: 782, Loss: 0.027238916605710983, Lr:0.0001\n",
      "Epoch 24, Step: 783, Loss: 0.05141314119100571, Lr:0.0001\n",
      "Epoch 24, Step: 784, Loss: 0.018448378890752792, Lr:0.0001\n",
      "Epoch 24, Step: 785, Loss: 0.06486738473176956, Lr:0.0001\n",
      "Epoch 24, Step: 786, Loss: 0.03098520077764988, Lr:0.0001\n",
      "Epoch 24, Step: 787, Loss: 0.015440665185451508, Lr:0.0001\n",
      "Epoch 24, Step: 788, Loss: 0.02938871458172798, Lr:0.0001\n",
      "Epoch 24, Step: 789, Loss: 0.13527143001556396, Lr:0.0001\n",
      "Epoch 24, Step: 790, Loss: 0.21055425703525543, Lr:0.0001\n",
      "Epoch 24, Step: 791, Loss: 0.36115410923957825, Lr:0.0001\n",
      "Epoch 24, Step: 792, Loss: 0.004486470483243465, Lr:0.0001\n",
      "Epoch 24, Step: 793, Loss: 0.005736981052905321, Lr:0.0001\n",
      "Epoch 24, Step: 794, Loss: 0.1952345371246338, Lr:0.0001\n",
      "Epoch 24, Step: 795, Loss: 0.016849474981427193, Lr:0.0001\n",
      "Epoch 24, Step: 796, Loss: 0.014324614778161049, Lr:0.0001\n",
      "Epoch 24, Step: 797, Loss: 0.32734066247940063, Lr:0.0001\n",
      "Epoch 24, Step: 798, Loss: 0.0030434676446020603, Lr:0.0001\n",
      "Epoch 24, Step: 799, Loss: 0.018235525116324425, Lr:0.0001\n",
      "Epoch 24, Step: 800, Loss: 0.01930803246796131, Lr:0.0001\n",
      "Epoch 24, Step: 801, Loss: 0.032138656824827194, Lr:0.0001\n",
      "Epoch 24, Step: 802, Loss: 0.009297563694417477, Lr:0.0001\n",
      "Epoch 24, Step: 803, Loss: 0.19745662808418274, Lr:0.0001\n",
      "Epoch 24, Step: 804, Loss: 0.021595625206828117, Lr:0.0001\n",
      "Epoch 24, Step: 805, Loss: 0.034019097685813904, Lr:0.0001\n",
      "Epoch 24, Step: 806, Loss: 0.1292530596256256, Lr:0.0001\n",
      "Epoch 24, Step: 807, Loss: 0.15273423492908478, Lr:0.0001\n",
      "Epoch 24, Step: 808, Loss: 0.05461353808641434, Lr:0.0001\n",
      "Epoch 24, Step: 809, Loss: 0.031051360070705414, Lr:0.0001\n",
      "Epoch 24, Step: 810, Loss: 0.07314404100179672, Lr:0.0001\n",
      "Epoch 24, Step: 811, Loss: 0.08770168572664261, Lr:0.0001\n",
      "Epoch 24, Step: 812, Loss: 0.1543016880750656, Lr:0.0001\n",
      "Epoch 24, Step: 813, Loss: 0.0024187711533159018, Lr:0.0001\n",
      "Epoch 24, Step: 814, Loss: 0.01613033190369606, Lr:0.0001\n",
      "Epoch 24, Step: 815, Loss: 0.0075536309741437435, Lr:0.0001\n",
      "Epoch 24, Step: 816, Loss: 0.29036104679107666, Lr:0.0001\n",
      "Epoch 24, Step: 817, Loss: 0.04873253405094147, Lr:0.0001\n",
      "Epoch 24, Step: 818, Loss: 0.07781146466732025, Lr:0.0001\n",
      "Epoch 24, Step: 819, Loss: 0.029094841331243515, Lr:0.0001\n",
      "Epoch 24, Step: 820, Loss: 0.07268542796373367, Lr:0.0001\n",
      "Epoch 24, Step: 821, Loss: 0.09934526681900024, Lr:0.0001\n",
      "Epoch 24, Step: 822, Loss: 0.011343955993652344, Lr:0.0001\n",
      "Epoch 24, Step: 823, Loss: 0.016943128779530525, Lr:0.0001\n",
      "Epoch 24, Step: 824, Loss: 0.14334216713905334, Lr:0.0001\n",
      "Epoch 24, Step: 825, Loss: 0.018059158697724342, Lr:0.0001\n",
      "Epoch 24, Step: 826, Loss: 0.20977960526943207, Lr:0.0001\n",
      "Epoch 24, Step: 827, Loss: 0.01355269830673933, Lr:0.0001\n",
      "Epoch 24, Step: 828, Loss: 0.04288100451231003, Lr:0.0001\n",
      "Epoch 24, Step: 829, Loss: 0.0019300638232380152, Lr:0.0001\n",
      "Epoch 24, Step: 830, Loss: 0.004507241304963827, Lr:0.0001\n",
      "Epoch 24, Step: 831, Loss: 0.00879676640033722, Lr:0.0001\n",
      "Epoch 24, Step: 832, Loss: 0.0018732633907347918, Lr:0.0001\n",
      "Epoch 24, Step: 833, Loss: 0.09182241559028625, Lr:0.0001\n",
      "Epoch 24, Step: 834, Loss: 0.028098326176404953, Lr:0.0001\n",
      "Epoch 24, Step: 835, Loss: 0.013658251613378525, Lr:0.0001\n",
      "Epoch 24, Step: 836, Loss: 0.08161625266075134, Lr:0.0001\n",
      "Epoch 24, Step: 837, Loss: 0.0192833561450243, Lr:0.0001\n",
      "Epoch 24, Step: 838, Loss: 0.02698219008743763, Lr:0.0001\n",
      "Epoch 24, Step: 839, Loss: 0.0020021116361021996, Lr:0.0001\n",
      "Epoch 24, Step: 840, Loss: 0.18581779301166534, Lr:0.0001\n",
      "Epoch 24, Step: 841, Loss: 0.02716047689318657, Lr:0.0001\n",
      "Epoch 24, Step: 842, Loss: 0.00421158317476511, Lr:0.0001\n",
      "Epoch 24, Step: 843, Loss: 0.033102210611104965, Lr:0.0001\n",
      "Epoch 24, Step: 844, Loss: 0.13557247817516327, Lr:0.0001\n",
      "Epoch 24, Step: 845, Loss: 0.009902505204081535, Lr:0.0001\n",
      "Epoch 24, Step: 846, Loss: 0.0639730840921402, Lr:0.0001\n",
      "Epoch 24, Step: 847, Loss: 0.005919176619499922, Lr:0.0001\n",
      "Epoch 24, Step: 848, Loss: 0.10514146089553833, Lr:0.0001\n",
      "Epoch 24, Step: 849, Loss: 0.08890478312969208, Lr:0.0001\n",
      "Epoch 24, Step: 850, Loss: 0.07662414014339447, Lr:0.0001\n",
      "Epoch 24, Step: 851, Loss: 0.024636274203658104, Lr:0.0001\n",
      "Epoch 24, Step: 852, Loss: 0.19184063374996185, Lr:0.0001\n",
      "Epoch 24, Step: 853, Loss: 0.01591329649090767, Lr:0.0001\n",
      "Epoch 24, Step: 854, Loss: 0.04229436814785004, Lr:0.0001\n",
      "Epoch 24, Step: 855, Loss: 0.213542178273201, Lr:0.0001\n",
      "Epoch 24, Step: 856, Loss: 0.02616407722234726, Lr:0.0001\n",
      "Epoch 24, Step: 857, Loss: 0.004925812594592571, Lr:0.0001\n",
      "Epoch 24, Step: 858, Loss: 0.13571633398532867, Lr:0.0001\n",
      "Epoch 24, Step: 859, Loss: 0.0089942067861557, Lr:0.0001\n",
      "Epoch 24, Step: 860, Loss: 0.25131744146347046, Lr:0.0001\n",
      "Epoch 24, Step: 861, Loss: 0.11714580655097961, Lr:0.0001\n",
      "Epoch 24, Step: 862, Loss: 0.23215699195861816, Lr:0.0001\n",
      "Epoch 24, Step: 863, Loss: 0.09507105499505997, Lr:0.0001\n",
      "Epoch 24, Step: 864, Loss: 0.005534317810088396, Lr:0.0001\n",
      "Epoch 24, Step: 865, Loss: 0.013798443600535393, Lr:0.0001\n",
      "Epoch 24, Step: 866, Loss: 0.31654590368270874, Lr:0.0001\n",
      "Epoch 24, Step: 867, Loss: 0.08930438756942749, Lr:0.0001\n",
      "Epoch 24, Step: 868, Loss: 0.016097381711006165, Lr:0.0001\n",
      "Epoch 24, Step: 869, Loss: 0.2885880768299103, Lr:0.0001\n",
      "Epoch 24, Step: 870, Loss: 0.27257636189460754, Lr:0.0001\n",
      "Epoch 24, Step: 871, Loss: 0.1462128907442093, Lr:0.0001\n",
      "Epoch 24, Step: 872, Loss: 0.01448060479015112, Lr:0.0001\n",
      "Epoch 24, Step: 873, Loss: 0.015985723584890366, Lr:0.0001\n",
      "Epoch 24, Step: 874, Loss: 0.015817072242498398, Lr:0.0001\n",
      "Epoch 24, Step: 875, Loss: 0.0009783671703189611, Lr:0.0001\n",
      "Epoch 24, Step: 876, Loss: 0.0077601270750164986, Lr:0.0001\n",
      "Epoch 24, Step: 877, Loss: 0.09016872942447662, Lr:0.0001\n",
      "Epoch 24, Step: 878, Loss: 0.1803041696548462, Lr:0.0001\n",
      "Epoch 24, Step: 879, Loss: 0.0705922320485115, Lr:0.0001\n",
      "Epoch 24, Step: 880, Loss: 0.03224103897809982, Lr:0.0001\n",
      "Epoch 24, Step: 881, Loss: 0.005855337250977755, Lr:0.0001\n",
      "Epoch 24, Step: 882, Loss: 0.03862082213163376, Lr:0.0001\n",
      "Epoch 24, Step: 883, Loss: 0.001641564187593758, Lr:0.0001\n",
      "Epoch 24, Step: 884, Loss: 0.0729627013206482, Lr:0.0001\n",
      "Epoch 24, Step: 885, Loss: 0.042735423892736435, Lr:0.0001\n",
      "Epoch 24, Step: 886, Loss: 0.07305051386356354, Lr:0.0001\n",
      "Epoch 24, Step: 887, Loss: 0.21504424512386322, Lr:0.0001\n",
      "Epoch 24, Step: 888, Loss: 0.12648193538188934, Lr:0.0001\n",
      "Epoch 24, Step: 889, Loss: 0.08353088796138763, Lr:0.0001\n",
      "Epoch 24, Step: 890, Loss: 0.06818270683288574, Lr:0.0001\n",
      "Epoch 24, Step: 891, Loss: 0.08078720420598984, Lr:0.0001\n",
      "Epoch 24, Step: 892, Loss: 0.08032098412513733, Lr:0.0001\n",
      "Epoch 24, Step: 893, Loss: 0.029957536607980728, Lr:0.0001\n",
      "Epoch 24, Step: 894, Loss: 0.004247515462338924, Lr:0.0001\n",
      "Epoch 24, Step: 895, Loss: 0.002769238781183958, Lr:0.0001\n",
      "Epoch 24, Step: 896, Loss: 0.005067857913672924, Lr:0.0001\n",
      "Epoch 24, Step: 897, Loss: 0.10801397264003754, Lr:0.0001\n",
      "Epoch 24, Step: 898, Loss: 0.2216235250234604, Lr:0.0001\n",
      "Epoch 24, Step: 899, Loss: 0.11572214215993881, Lr:0.0001\n",
      "Epoch 24, Step: 900, Loss: 0.0009310481837019324, Lr:0.0001\n",
      "Epoch 24, Step: 901, Loss: 0.21140708029270172, Lr:0.0001\n",
      "Epoch 24, Step: 902, Loss: 0.08929827064275742, Lr:0.0001\n",
      "Epoch 24, Step: 903, Loss: 0.028794247657060623, Lr:0.0001\n",
      "Epoch 24, Step: 904, Loss: 0.002567957155406475, Lr:0.0001\n",
      "Epoch 24, Step: 905, Loss: 0.016840914264321327, Lr:0.0001\n",
      "Epoch 24, Step: 906, Loss: 0.11162656545639038, Lr:0.0001\n",
      "Epoch 24, Step: 907, Loss: 0.07096289098262787, Lr:0.0001\n",
      "Epoch 24, Step: 908, Loss: 0.006200804375112057, Lr:0.0001\n",
      "Epoch 24, Step: 909, Loss: 0.06761029362678528, Lr:0.0001\n",
      "Epoch 24, Step: 910, Loss: 0.09596860408782959, Lr:0.0001\n",
      "Epoch 24, Step: 911, Loss: 0.0605909638106823, Lr:0.0001\n",
      "Epoch 24, Step: 912, Loss: 0.1960788071155548, Lr:0.0001\n",
      "Epoch 24, Step: 913, Loss: 0.0010098794009536505, Lr:0.0001\n",
      "Epoch 24, Step: 914, Loss: 0.2339615672826767, Lr:0.0001\n",
      "Epoch 24, Step: 915, Loss: 0.052454493939876556, Lr:0.0001\n",
      "Epoch 24, Step: 916, Loss: 0.024634651839733124, Lr:0.0001\n",
      "Epoch 24, Step: 917, Loss: 0.014833944849669933, Lr:0.0001\n",
      "Epoch 24, Step: 918, Loss: 0.029558520764112473, Lr:0.0001\n",
      "Epoch 24, Step: 919, Loss: 0.011363262310624123, Lr:0.0001\n",
      "Epoch 24, Step: 920, Loss: 0.009270960465073586, Lr:0.0001\n",
      "Epoch 24, Step: 921, Loss: 0.05676041916012764, Lr:0.0001\n",
      "Epoch 24, Step: 922, Loss: 0.04563738778233528, Lr:0.0001\n",
      "Epoch 24, Step: 923, Loss: 0.028788384050130844, Lr:0.0001\n",
      "Epoch 24, Step: 924, Loss: 0.001843832666054368, Lr:0.0001\n",
      "Epoch 24, Step: 925, Loss: 0.011762160807847977, Lr:0.0001\n",
      "Epoch 24, Step: 926, Loss: 0.15522827208042145, Lr:0.0001\n",
      "Epoch 24, Step: 927, Loss: 0.010311521589756012, Lr:0.0001\n",
      "Epoch 24, Step: 928, Loss: 0.13219374418258667, Lr:0.0001\n",
      "Epoch 24, Step: 929, Loss: 0.012721884995698929, Lr:0.0001\n",
      "Epoch 24, Step: 930, Loss: 0.046173933893442154, Lr:0.0001\n",
      "Epoch 24, Step: 931, Loss: 0.00134231336414814, Lr:0.0001\n",
      "Epoch 24, Step: 932, Loss: 0.043999046087265015, Lr:0.0001\n",
      "Epoch 24, Step: 933, Loss: 0.21261367201805115, Lr:0.0001\n",
      "Epoch 24, Step: 934, Loss: 0.08181435614824295, Lr:0.0001\n",
      "Epoch 24, Step: 935, Loss: 0.0011763825314119458, Lr:0.0001\n",
      "Epoch 24, Step: 936, Loss: 0.013111554086208344, Lr:0.0001\n",
      "Epoch 24, Step: 937, Loss: 0.0007958188652992249, Lr:0.0001\n",
      "Epoch 24, Step: 938, Loss: 0.01154516451060772, Lr:0.0001\n",
      "Epoch 24, Step: 939, Loss: 0.07401806861162186, Lr:0.0001\n",
      "Epoch 24, Step: 940, Loss: 0.010693236254155636, Lr:0.0001\n",
      "Epoch 24, Step: 941, Loss: 0.15075218677520752, Lr:0.0001\n",
      "Epoch 24, Step: 942, Loss: 0.06151275709271431, Lr:0.0001\n",
      "Epoch 24, Step: 943, Loss: 0.0008487512241117656, Lr:0.0001\n",
      "Epoch 24, Step: 944, Loss: 0.11034189909696579, Lr:0.0001\n",
      "Epoch 24, Step: 945, Loss: 0.0013233444187790155, Lr:0.0001\n",
      "Epoch 24, Step: 946, Loss: 0.04458171874284744, Lr:0.0001\n",
      "Epoch 24, Step: 947, Loss: 0.04639885574579239, Lr:0.0001\n",
      "Epoch 24, Step: 948, Loss: 0.06167326122522354, Lr:0.0001\n",
      "Epoch 24, Step: 949, Loss: 0.005170734599232674, Lr:0.0001\n",
      "Epoch 24, Step: 950, Loss: 0.019442839547991753, Lr:0.0001\n",
      "Epoch 24, Step: 951, Loss: 0.0815490111708641, Lr:0.0001\n",
      "Epoch 24, Step: 952, Loss: 0.09596338123083115, Lr:0.0001\n",
      "Epoch 24, Step: 953, Loss: 0.015823855996131897, Lr:0.0001\n",
      "Epoch 24, Step: 954, Loss: 0.008588767610490322, Lr:0.0001\n",
      "Epoch 24, Step: 955, Loss: 0.14717483520507812, Lr:0.0001\n",
      "Epoch 24, Step: 956, Loss: 0.26806896924972534, Lr:0.0001\n",
      "Epoch 24, Step: 957, Loss: 0.14676649868488312, Lr:0.0001\n",
      "Epoch 24, Step: 958, Loss: 0.24324674904346466, Lr:0.0001\n",
      "Epoch 24, Step: 959, Loss: 0.042187489569187164, Lr:0.0001\n",
      "Epoch 24, Step: 960, Loss: 0.0167331974953413, Lr:0.0001\n",
      "Epoch 24, Step: 961, Loss: 0.03525472804903984, Lr:0.0001\n",
      "Epoch 24, Step: 962, Loss: 0.116913802921772, Lr:0.0001\n",
      "Epoch 24, Step: 963, Loss: 0.014367060735821724, Lr:0.0001\n",
      "Epoch 24, Step: 964, Loss: 0.00039920624112710357, Lr:0.0001\n",
      "Epoch 24, Step: 965, Loss: 0.024826399981975555, Lr:0.0001\n",
      "Epoch 24, Step: 966, Loss: 0.18718159198760986, Lr:0.0001\n",
      "Epoch 24, Step: 967, Loss: 0.0515841580927372, Lr:0.0001\n",
      "Epoch 24, Step: 968, Loss: 0.024923205375671387, Lr:0.0001\n",
      "Epoch 24, Step: 969, Loss: 0.0027200980111956596, Lr:0.0001\n",
      "Epoch 24, Step: 970, Loss: 0.130856454372406, Lr:0.0001\n",
      "Epoch 24, Step: 971, Loss: 0.01205134391784668, Lr:0.0001\n",
      "Epoch 24, Step: 972, Loss: 0.01059490442276001, Lr:0.0001\n",
      "Epoch 24, Step: 973, Loss: 0.05544179677963257, Lr:0.0001\n",
      "Epoch 24, Step: 974, Loss: 0.012358002364635468, Lr:0.0001\n",
      "Epoch 24, Step: 975, Loss: 0.08587618917226791, Lr:0.0001\n",
      "Epoch 24, Step: 976, Loss: 0.010665563866496086, Lr:0.0001\n",
      "Epoch 24, Step: 977, Loss: 0.04820334538817406, Lr:0.0001\n",
      "Epoch 24, Step: 978, Loss: 0.022445594891905785, Lr:0.0001\n",
      "Epoch 24, Step: 979, Loss: 0.011142626404762268, Lr:0.0001\n",
      "Epoch 24, Step: 980, Loss: 0.019768012687563896, Lr:0.0001\n",
      "Epoch 24, Step: 981, Loss: 0.08655346184968948, Lr:0.0001\n",
      "Epoch 24, Step: 982, Loss: 0.2889966070652008, Lr:0.0001\n",
      "Epoch 24, Step: 983, Loss: 0.0006296549690887332, Lr:0.0001\n",
      "Epoch 24, Step: 984, Loss: 0.23181955516338348, Lr:0.0001\n",
      "Epoch 24, Step: 985, Loss: 0.0015431889332830906, Lr:0.0001\n",
      "Epoch 24, Step: 986, Loss: 0.0250623170286417, Lr:0.0001\n",
      "Epoch 24, Step: 987, Loss: 0.006233180873095989, Lr:0.0001\n",
      "Epoch 24, Step: 988, Loss: 0.05537266284227371, Lr:0.0001\n",
      "Epoch 24, Step: 989, Loss: 0.04125268757343292, Lr:0.0001\n",
      "Epoch 24, Step: 990, Loss: 0.0016889403341338038, Lr:0.0001\n",
      "Epoch 24, Step: 991, Loss: 0.020022492855787277, Lr:0.0001\n",
      "Epoch 24, Step: 992, Loss: 0.015415598638355732, Lr:0.0001\n",
      "Epoch 24, Step: 993, Loss: 0.1265425980091095, Lr:0.0001\n",
      "Epoch 24, Step: 994, Loss: 0.4641364514827728, Lr:0.0001\n",
      "Epoch 24, Step: 995, Loss: 0.0018723245011642575, Lr:0.0001\n",
      "Epoch 24, Step: 996, Loss: 0.19529812037944794, Lr:0.0001\n",
      "Epoch 24, Step: 997, Loss: 0.03180664777755737, Lr:0.0001\n",
      "Epoch 24, Step: 998, Loss: 0.06709383428096771, Lr:0.0001\n",
      "Epoch 24, Step: 999, Loss: 0.053486354649066925, Lr:0.0001\n",
      "Epoch 24, Step: 1000, Loss: 0.20592135190963745, Lr:0.0001\n",
      "Epoch 24, Step: 1001, Loss: 0.22792282700538635, Lr:0.0001\n",
      "Epoch 24, Step: 1002, Loss: 0.0896294042468071, Lr:0.0001\n",
      "Epoch 24, Step: 1003, Loss: 0.04294081777334213, Lr:0.0001\n",
      "Epoch 24, Step: 1004, Loss: 0.27828308939933777, Lr:0.0001\n",
      "Epoch 24, Step: 1005, Loss: 0.024226875975728035, Lr:0.0001\n",
      "Epoch 24, Step: 1006, Loss: 0.2061937004327774, Lr:0.0001\n",
      "Epoch 24, Step: 1007, Loss: 0.06782621145248413, Lr:0.0001\n",
      "Epoch 24, Step: 1008, Loss: 0.0076602306216955185, Lr:0.0001\n",
      "Epoch 24, Step: 1009, Loss: 0.13898015022277832, Lr:0.0001\n",
      "Epoch 24, Step: 1010, Loss: 0.016037775203585625, Lr:0.0001\n",
      "Epoch 24, Step: 1011, Loss: 0.002819832181558013, Lr:0.0001\n",
      "Epoch 24, Step: 1012, Loss: 0.06354929506778717, Lr:0.0001\n",
      "Epoch 24, Step: 1013, Loss: 0.10411711037158966, Lr:0.0001\n",
      "Epoch 24, Step: 1014, Loss: 0.03398757427930832, Lr:0.0001\n",
      "Epoch 24, Step: 1015, Loss: 0.020625991746783257, Lr:0.0001\n",
      "Epoch 24, Step: 1016, Loss: 0.023774953559041023, Lr:0.0001\n",
      "Epoch 24, Step: 1017, Loss: 0.014916064217686653, Lr:0.0001\n",
      "Epoch 24, Step: 1018, Loss: 0.23875200748443604, Lr:0.0001\n",
      "Epoch 24, Step: 1019, Loss: 0.029049238190054893, Lr:0.0001\n",
      "Epoch 24, Step: 1020, Loss: 0.30372917652130127, Lr:0.0001\n",
      "Epoch 24, Step: 1021, Loss: 0.34903377294540405, Lr:0.0001\n",
      "Epoch 24, Step: 1022, Loss: 0.01556683424860239, Lr:0.0001\n",
      "Epoch 24, Step: 1023, Loss: 0.007215552031993866, Lr:0.0001\n",
      "Epoch 24, Step: 1024, Loss: 0.013852456584572792, Lr:0.0001\n",
      "Epoch 24, Step: 1025, Loss: 0.009330976754426956, Lr:0.0001\n",
      "Epoch 24, Step: 1026, Loss: 0.006429893895983696, Lr:0.0001\n",
      "Epoch 24, Step: 1027, Loss: 0.10837850719690323, Lr:0.0001\n",
      "Epoch 24, Step: 1028, Loss: 0.0025715932715684175, Lr:0.0001\n",
      "Epoch 24, Step: 1029, Loss: 0.010418539866805077, Lr:0.0001\n",
      "Epoch 24, Step: 1030, Loss: 0.034896187484264374, Lr:0.0001\n",
      "Epoch 24, Step: 1031, Loss: 0.3517657518386841, Lr:0.0001\n",
      "Epoch 24, Step: 1032, Loss: 0.1479255110025406, Lr:0.0001\n",
      "Epoch 24, Step: 1033, Loss: 0.02455640584230423, Lr:0.0001\n",
      "Epoch 24, Step: 1034, Loss: 0.11148066818714142, Lr:0.0001\n",
      "Epoch 24, Step: 1035, Loss: 0.025837259367108345, Lr:0.0001\n",
      "Epoch 24, Step: 1036, Loss: 0.02817373163998127, Lr:0.0001\n",
      "Epoch 24, Step: 1037, Loss: 0.055404435843229294, Lr:0.0001\n",
      "Epoch 24, Step: 1038, Loss: 0.07298391312360764, Lr:0.0001\n",
      "Epoch 24, Step: 1039, Loss: 0.06749595701694489, Lr:0.0001\n",
      "Epoch 24, Step: 1040, Loss: 0.05808890238404274, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 24\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:17 loss: 1.0823 (1.0823) acc1: 81.2500 (81.2500) acc5: 100.0000 (100.0000) time: 0.3140 data: 0.1203 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:14 loss: 0.0324 (0.1670) acc1: 100.0000 (96.0227) acc5: 100.0000 (100.0000) time: 0.3217 data: 0.1248 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:11 loss: 0.0324 (0.1620) acc1: 100.0000 (96.1310) acc5: 100.0000 (100.0000) time: 0.3129 data: 0.1213 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:08 loss: 0.1235 (0.2843) acc1: 93.7500 (92.9435) acc5: 100.0000 (100.0000) time: 0.3115 data: 0.1212 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:05 loss: 0.1693 (0.3142) acc1: 93.7500 (92.0732) acc5: 100.0000 (100.0000) time: 0.3132 data: 0.1253 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.1198 (0.2778) acc1: 93.7500 (92.8922) acc5: 100.0000 (100.0000) time: 0.3152 data: 0.1272 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0224 (0.2604) acc1: 100.0000 (93.1896) acc5: 100.0000 (100.0000) time: 0.2995 data: 0.1203 max mem: 15137\n",
      "Test: Total time: 0:00:17 (0.3093 s / it)\n",
      "* Acc@1 93.190 Acc@5 100.000 loss 0.260\n",
      "Accuracy of the network on the 881 test image: 93.2%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 25, Step: 0, Loss: 0.008736898191273212, Lr:0.0001\n",
      "Epoch 25, Step: 1, Loss: 0.041253652423620224, Lr:0.0001\n",
      "Epoch 25, Step: 2, Loss: 0.019985971972346306, Lr:0.0001\n",
      "Epoch 25, Step: 3, Loss: 0.06870424002408981, Lr:0.0001\n",
      "Epoch 25, Step: 4, Loss: 0.03853074088692665, Lr:0.0001\n",
      "Epoch 25, Step: 5, Loss: 0.03486378490924835, Lr:0.0001\n",
      "Epoch 25, Step: 6, Loss: 0.05269110947847366, Lr:0.0001\n",
      "Epoch 25, Step: 7, Loss: 0.013939215801656246, Lr:0.0001\n",
      "Epoch 25, Step: 8, Loss: 0.1178802102804184, Lr:0.0001\n",
      "Epoch 25, Step: 9, Loss: 0.02106843888759613, Lr:0.0001\n",
      "Epoch 25, Step: 10, Loss: 0.11475791037082672, Lr:0.0001\n",
      "Epoch 25, Step: 11, Loss: 0.012170623987913132, Lr:0.0001\n",
      "Epoch 25, Step: 12, Loss: 0.00376010499894619, Lr:0.0001\n",
      "Epoch 25, Step: 13, Loss: 0.029844708740711212, Lr:0.0001\n",
      "Epoch 25, Step: 14, Loss: 0.057158585637807846, Lr:0.0001\n",
      "Epoch 25, Step: 15, Loss: 0.09897104650735855, Lr:0.0001\n",
      "Epoch 25, Step: 16, Loss: 0.07595101743936539, Lr:0.0001\n",
      "Epoch 25, Step: 17, Loss: 0.024061817675828934, Lr:0.0001\n",
      "Epoch 25, Step: 18, Loss: 0.02447248250246048, Lr:0.0001\n",
      "Epoch 25, Step: 19, Loss: 0.016428880393505096, Lr:0.0001\n",
      "Epoch 25, Step: 20, Loss: 0.01716477796435356, Lr:0.0001\n",
      "Epoch 25, Step: 21, Loss: 0.0176934115588665, Lr:0.0001\n",
      "Epoch 25, Step: 22, Loss: 0.09953416883945465, Lr:0.0001\n",
      "Epoch 25, Step: 23, Loss: 0.09177924692630768, Lr:0.0001\n",
      "Epoch 25, Step: 24, Loss: 0.011011578142642975, Lr:0.0001\n",
      "Epoch 25, Step: 25, Loss: 0.030021749436855316, Lr:0.0001\n",
      "Epoch 25, Step: 26, Loss: 0.009191718883812428, Lr:0.0001\n",
      "Epoch 25, Step: 27, Loss: 0.0032949582673609257, Lr:0.0001\n",
      "Epoch 25, Step: 28, Loss: 0.004528400022536516, Lr:0.0001\n",
      "Epoch 25, Step: 29, Loss: 0.11598268151283264, Lr:0.0001\n",
      "Epoch 25, Step: 30, Loss: 0.011907344684004784, Lr:0.0001\n",
      "Epoch 25, Step: 31, Loss: 0.0030829377938061953, Lr:0.0001\n",
      "Epoch 25, Step: 32, Loss: 0.011550423689186573, Lr:0.0001\n",
      "Epoch 25, Step: 33, Loss: 0.05453771725296974, Lr:0.0001\n",
      "Epoch 25, Step: 34, Loss: 0.010794275440275669, Lr:0.0001\n",
      "Epoch 25, Step: 35, Loss: 0.01401703804731369, Lr:0.0001\n",
      "Epoch 25, Step: 36, Loss: 0.008645273745059967, Lr:0.0001\n",
      "Epoch 25, Step: 37, Loss: 0.09044577926397324, Lr:0.0001\n",
      "Epoch 25, Step: 38, Loss: 0.019478484988212585, Lr:0.0001\n",
      "Epoch 25, Step: 39, Loss: 0.0061208512634038925, Lr:0.0001\n",
      "Epoch 25, Step: 40, Loss: 0.10662681609392166, Lr:0.0001\n",
      "Epoch 25, Step: 41, Loss: 0.05913872644305229, Lr:0.0001\n",
      "Epoch 25, Step: 42, Loss: 0.003939780406653881, Lr:0.0001\n",
      "Epoch 25, Step: 43, Loss: 0.0004713563248515129, Lr:0.0001\n",
      "Epoch 25, Step: 44, Loss: 0.03455546498298645, Lr:0.0001\n",
      "Epoch 25, Step: 45, Loss: 0.0025401769671589136, Lr:0.0001\n",
      "Epoch 25, Step: 46, Loss: 0.10860877484083176, Lr:0.0001\n",
      "Epoch 25, Step: 47, Loss: 0.010931975208222866, Lr:0.0001\n",
      "Epoch 25, Step: 48, Loss: 0.076724573969841, Lr:0.0001\n",
      "Epoch 25, Step: 49, Loss: 0.27299487590789795, Lr:0.0001\n",
      "Epoch 25, Step: 50, Loss: 0.04679882898926735, Lr:0.0001\n",
      "Epoch 25, Step: 51, Loss: 0.0016118084313347936, Lr:0.0001\n",
      "Epoch 25, Step: 52, Loss: 0.029617996886372566, Lr:0.0001\n",
      "Epoch 25, Step: 53, Loss: 0.029549140483140945, Lr:0.0001\n",
      "Epoch 25, Step: 54, Loss: 0.04813416674733162, Lr:0.0001\n",
      "Epoch 25, Step: 55, Loss: 0.021707842126488686, Lr:0.0001\n",
      "Epoch 25, Step: 56, Loss: 0.07706587761640549, Lr:0.0001\n",
      "Epoch 25, Step: 57, Loss: 0.22673475742340088, Lr:0.0001\n",
      "Epoch 25, Step: 58, Loss: 0.05192488431930542, Lr:0.0001\n",
      "Epoch 25, Step: 59, Loss: 0.622471272945404, Lr:0.0001\n",
      "Epoch 25, Step: 60, Loss: 0.0025631349999457598, Lr:0.0001\n",
      "Epoch 25, Step: 61, Loss: 0.09359842538833618, Lr:0.0001\n",
      "Epoch 25, Step: 62, Loss: 0.005759658757597208, Lr:0.0001\n",
      "Epoch 25, Step: 63, Loss: 0.17628391087055206, Lr:0.0001\n",
      "Epoch 25, Step: 64, Loss: 0.3275757133960724, Lr:0.0001\n",
      "Epoch 25, Step: 65, Loss: 0.04641798138618469, Lr:0.0001\n",
      "Epoch 25, Step: 66, Loss: 0.0784677267074585, Lr:0.0001\n",
      "Epoch 25, Step: 67, Loss: 0.025328747928142548, Lr:0.0001\n",
      "Epoch 25, Step: 68, Loss: 0.14812661707401276, Lr:0.0001\n",
      "Epoch 25, Step: 69, Loss: 0.006623823661357164, Lr:0.0001\n",
      "Epoch 25, Step: 70, Loss: 0.0429254025220871, Lr:0.0001\n",
      "Epoch 25, Step: 71, Loss: 0.00822352897375822, Lr:0.0001\n",
      "Epoch 25, Step: 72, Loss: 0.07191013544797897, Lr:0.0001\n",
      "Epoch 25, Step: 73, Loss: 0.020167553797364235, Lr:0.0001\n",
      "Epoch 25, Step: 74, Loss: 0.03533851355314255, Lr:0.0001\n",
      "Epoch 25, Step: 75, Loss: 0.0075839851051568985, Lr:0.0001\n",
      "Epoch 25, Step: 76, Loss: 0.09421781450510025, Lr:0.0001\n",
      "Epoch 25, Step: 77, Loss: 0.02022978849709034, Lr:0.0001\n",
      "Epoch 25, Step: 78, Loss: 0.019428901374340057, Lr:0.0001\n",
      "Epoch 25, Step: 79, Loss: 0.0805378183722496, Lr:0.0001\n",
      "Epoch 25, Step: 80, Loss: 0.01627790555357933, Lr:0.0001\n",
      "Epoch 25, Step: 81, Loss: 0.2890858054161072, Lr:0.0001\n",
      "Epoch 25, Step: 82, Loss: 0.05995570868253708, Lr:0.0001\n",
      "Epoch 25, Step: 83, Loss: 0.00037020232412032783, Lr:0.0001\n",
      "Epoch 25, Step: 84, Loss: 0.02446090243756771, Lr:0.0001\n",
      "Epoch 25, Step: 85, Loss: 0.1215088739991188, Lr:0.0001\n",
      "Epoch 25, Step: 86, Loss: 0.06258278340101242, Lr:0.0001\n",
      "Epoch 25, Step: 87, Loss: 0.01651095040142536, Lr:0.0001\n",
      "Epoch 25, Step: 88, Loss: 0.19797666370868683, Lr:0.0001\n",
      "Epoch 25, Step: 89, Loss: 0.007656078319996595, Lr:0.0001\n",
      "Epoch 25, Step: 90, Loss: 0.18728190660476685, Lr:0.0001\n",
      "Epoch 25, Step: 91, Loss: 0.14971838891506195, Lr:0.0001\n",
      "Epoch 25, Step: 92, Loss: 0.17836736142635345, Lr:0.0001\n",
      "Epoch 25, Step: 93, Loss: 0.15117135643959045, Lr:0.0001\n",
      "Epoch 25, Step: 94, Loss: 0.09688013046979904, Lr:0.0001\n",
      "Epoch 25, Step: 95, Loss: 0.11438273638486862, Lr:0.0001\n",
      "Epoch 25, Step: 96, Loss: 0.17196860909461975, Lr:0.0001\n",
      "Epoch 25, Step: 97, Loss: 0.07813379913568497, Lr:0.0001\n",
      "Epoch 25, Step: 98, Loss: 0.12407610565423965, Lr:0.0001\n",
      "Epoch 25, Step: 99, Loss: 0.05428963899612427, Lr:0.0001\n",
      "Epoch 25, Step: 100, Loss: 0.08726837486028671, Lr:0.0001\n",
      "Epoch 25, Step: 101, Loss: 0.04037204757332802, Lr:0.0001\n",
      "Epoch 25, Step: 102, Loss: 0.00575849087908864, Lr:0.0001\n",
      "Epoch 25, Step: 103, Loss: 0.09089329838752747, Lr:0.0001\n",
      "Epoch 25, Step: 104, Loss: 0.10041593015193939, Lr:0.0001\n",
      "Epoch 25, Step: 105, Loss: 0.021196143701672554, Lr:0.0001\n",
      "Epoch 25, Step: 106, Loss: 0.03230489045381546, Lr:0.0001\n",
      "Epoch 25, Step: 107, Loss: 0.15942198038101196, Lr:0.0001\n",
      "Epoch 25, Step: 108, Loss: 0.051125138998031616, Lr:0.0001\n",
      "Epoch 25, Step: 109, Loss: 0.02909396030008793, Lr:0.0001\n",
      "Epoch 25, Step: 110, Loss: 0.04903266206383705, Lr:0.0001\n",
      "Epoch 25, Step: 111, Loss: 0.01262825820595026, Lr:0.0001\n",
      "Epoch 25, Step: 112, Loss: 0.003798031248152256, Lr:0.0001\n",
      "Epoch 25, Step: 113, Loss: 0.014538608491420746, Lr:0.0001\n",
      "Epoch 25, Step: 114, Loss: 0.005068451166152954, Lr:0.0001\n",
      "Epoch 25, Step: 115, Loss: 0.018288759514689445, Lr:0.0001\n",
      "Epoch 25, Step: 116, Loss: 0.021420584991574287, Lr:0.0001\n",
      "Epoch 25, Step: 117, Loss: 0.017554996535182, Lr:0.0001\n",
      "Epoch 25, Step: 118, Loss: 0.02120741456747055, Lr:0.0001\n",
      "Epoch 25, Step: 119, Loss: 0.02503734827041626, Lr:0.0001\n",
      "Epoch 25, Step: 120, Loss: 0.05442146211862564, Lr:0.0001\n",
      "Epoch 25, Step: 121, Loss: 0.03389929234981537, Lr:0.0001\n",
      "Epoch 25, Step: 122, Loss: 0.0087576974183321, Lr:0.0001\n",
      "Epoch 25, Step: 123, Loss: 0.01835023984313011, Lr:0.0001\n",
      "Epoch 25, Step: 124, Loss: 0.009334140457212925, Lr:0.0001\n",
      "Epoch 25, Step: 125, Loss: 0.02631322853267193, Lr:0.0001\n",
      "Epoch 25, Step: 126, Loss: 0.04016243666410446, Lr:0.0001\n",
      "Epoch 25, Step: 127, Loss: 0.056912459433078766, Lr:0.0001\n",
      "Epoch 25, Step: 128, Loss: 0.013553307391703129, Lr:0.0001\n",
      "Epoch 25, Step: 129, Loss: 0.12289733439683914, Lr:0.0001\n",
      "Epoch 25, Step: 130, Loss: 0.04154639691114426, Lr:0.0001\n",
      "Epoch 25, Step: 131, Loss: 0.15716470777988434, Lr:0.0001\n",
      "Epoch 25, Step: 132, Loss: 0.009722151793539524, Lr:0.0001\n",
      "Epoch 25, Step: 133, Loss: 0.022080570459365845, Lr:0.0001\n",
      "Epoch 25, Step: 134, Loss: 0.2679462134838104, Lr:0.0001\n",
      "Epoch 25, Step: 135, Loss: 0.008673775009810925, Lr:0.0001\n",
      "Epoch 25, Step: 136, Loss: 0.023559635505080223, Lr:0.0001\n",
      "Epoch 25, Step: 137, Loss: 0.029362469911575317, Lr:0.0001\n",
      "Epoch 25, Step: 138, Loss: 0.015037206001579762, Lr:0.0001\n",
      "Epoch 25, Step: 139, Loss: 0.0237275380641222, Lr:0.0001\n",
      "Epoch 25, Step: 140, Loss: 0.005651670973747969, Lr:0.0001\n",
      "Epoch 25, Step: 141, Loss: 0.07276523113250732, Lr:0.0001\n",
      "Epoch 25, Step: 142, Loss: 0.03349810093641281, Lr:0.0001\n",
      "Epoch 25, Step: 143, Loss: 0.030841179192066193, Lr:0.0001\n",
      "Epoch 25, Step: 144, Loss: 0.12440763413906097, Lr:0.0001\n",
      "Epoch 25, Step: 145, Loss: 0.11373297870159149, Lr:0.0001\n",
      "Epoch 25, Step: 146, Loss: 0.030910247936844826, Lr:0.0001\n",
      "Epoch 25, Step: 147, Loss: 0.023012708872556686, Lr:0.0001\n",
      "Epoch 25, Step: 148, Loss: 0.01624959334731102, Lr:0.0001\n",
      "Epoch 25, Step: 149, Loss: 0.06966820359230042, Lr:0.0001\n",
      "Epoch 25, Step: 150, Loss: 0.25695446133613586, Lr:0.0001\n",
      "Epoch 25, Step: 151, Loss: 0.04836007207632065, Lr:0.0001\n",
      "Epoch 25, Step: 152, Loss: 0.01491626724600792, Lr:0.0001\n",
      "Epoch 25, Step: 153, Loss: 0.1439758837223053, Lr:0.0001\n",
      "Epoch 25, Step: 154, Loss: 0.17610254883766174, Lr:0.0001\n",
      "Epoch 25, Step: 155, Loss: 0.08332985639572144, Lr:0.0001\n",
      "Epoch 25, Step: 156, Loss: 0.05073952674865723, Lr:0.0001\n",
      "Epoch 25, Step: 157, Loss: 0.06899960339069366, Lr:0.0001\n",
      "Epoch 25, Step: 158, Loss: 0.00973402801901102, Lr:0.0001\n",
      "Epoch 25, Step: 159, Loss: 0.0763232558965683, Lr:0.0001\n",
      "Epoch 25, Step: 160, Loss: 0.07597339153289795, Lr:0.0001\n",
      "Epoch 25, Step: 161, Loss: 0.19537462294101715, Lr:0.0001\n",
      "Epoch 25, Step: 162, Loss: 0.24959728121757507, Lr:0.0001\n",
      "Epoch 25, Step: 163, Loss: 0.026933737099170685, Lr:0.0001\n",
      "Epoch 25, Step: 164, Loss: 0.052068933844566345, Lr:0.0001\n",
      "Epoch 25, Step: 165, Loss: 0.013246355578303337, Lr:0.0001\n",
      "Epoch 25, Step: 166, Loss: 0.3346717059612274, Lr:0.0001\n",
      "Epoch 25, Step: 167, Loss: 0.04971307888627052, Lr:0.0001\n",
      "Epoch 25, Step: 168, Loss: 0.027658995240926743, Lr:0.0001\n",
      "Epoch 25, Step: 169, Loss: 0.12243081629276276, Lr:0.0001\n",
      "Epoch 25, Step: 170, Loss: 0.03653048723936081, Lr:0.0001\n",
      "Epoch 25, Step: 171, Loss: 0.18386004865169525, Lr:0.0001\n",
      "Epoch 25, Step: 172, Loss: 0.05122146010398865, Lr:0.0001\n",
      "Epoch 25, Step: 173, Loss: 0.027531376108527184, Lr:0.0001\n",
      "Epoch 25, Step: 174, Loss: 0.05356581136584282, Lr:0.0001\n",
      "Epoch 25, Step: 175, Loss: 0.0019206495489925146, Lr:0.0001\n",
      "Epoch 25, Step: 176, Loss: 0.034372780472040176, Lr:0.0001\n",
      "Epoch 25, Step: 177, Loss: 0.00987992249429226, Lr:0.0001\n",
      "Epoch 25, Step: 178, Loss: 0.4147672653198242, Lr:0.0001\n",
      "Epoch 25, Step: 179, Loss: 0.0428290069103241, Lr:0.0001\n",
      "Epoch 25, Step: 180, Loss: 0.025414710864424706, Lr:0.0001\n",
      "Epoch 25, Step: 181, Loss: 0.45715394616127014, Lr:0.0001\n",
      "Epoch 25, Step: 182, Loss: 0.021109340712428093, Lr:0.0001\n",
      "Epoch 25, Step: 183, Loss: 0.1421850621700287, Lr:0.0001\n",
      "Epoch 25, Step: 184, Loss: 0.040904074907302856, Lr:0.0001\n",
      "Epoch 25, Step: 185, Loss: 0.07169919461011887, Lr:0.0001\n",
      "Epoch 25, Step: 186, Loss: 0.023636920377612114, Lr:0.0001\n",
      "Epoch 25, Step: 187, Loss: 0.008992082439363003, Lr:0.0001\n",
      "Epoch 25, Step: 188, Loss: 0.05233898013830185, Lr:0.0001\n",
      "Epoch 25, Step: 189, Loss: 0.21071498095989227, Lr:0.0001\n",
      "Epoch 25, Step: 190, Loss: 0.00110961077734828, Lr:0.0001\n",
      "Epoch 25, Step: 191, Loss: 0.03623642399907112, Lr:0.0001\n",
      "Epoch 25, Step: 192, Loss: 0.17942239344120026, Lr:0.0001\n",
      "Epoch 25, Step: 193, Loss: 0.06283384561538696, Lr:0.0001\n",
      "Epoch 25, Step: 194, Loss: 0.022773096337914467, Lr:0.0001\n",
      "Epoch 25, Step: 195, Loss: 0.04320196062326431, Lr:0.0001\n",
      "Epoch 25, Step: 196, Loss: 0.224738210439682, Lr:0.0001\n",
      "Epoch 25, Step: 197, Loss: 0.0420183502137661, Lr:0.0001\n",
      "Epoch 25, Step: 198, Loss: 0.08515261113643646, Lr:0.0001\n",
      "Epoch 25, Step: 199, Loss: 0.28631076216697693, Lr:0.0001\n",
      "Epoch 25, Step: 200, Loss: 0.18945230543613434, Lr:0.0001\n",
      "Epoch 25, Step: 201, Loss: 0.014248788356781006, Lr:0.0001\n",
      "Epoch 25, Step: 202, Loss: 0.013841251842677593, Lr:0.0001\n",
      "Epoch 25, Step: 203, Loss: 0.30560359358787537, Lr:0.0001\n",
      "Epoch 25, Step: 204, Loss: 0.06094316393136978, Lr:0.0001\n",
      "Epoch 25, Step: 205, Loss: 0.09589062631130219, Lr:0.0001\n",
      "Epoch 25, Step: 206, Loss: 0.03728963062167168, Lr:0.0001\n",
      "Epoch 25, Step: 207, Loss: 0.008149726316332817, Lr:0.0001\n",
      "Epoch 25, Step: 208, Loss: 0.022149985656142235, Lr:0.0001\n",
      "Epoch 25, Step: 209, Loss: 0.1554991602897644, Lr:0.0001\n",
      "Epoch 25, Step: 210, Loss: 0.011334416456520557, Lr:0.0001\n",
      "Epoch 25, Step: 211, Loss: 0.060317862778902054, Lr:0.0001\n",
      "Epoch 25, Step: 212, Loss: 0.06901185214519501, Lr:0.0001\n",
      "Epoch 25, Step: 213, Loss: 0.0551442913711071, Lr:0.0001\n",
      "Epoch 25, Step: 214, Loss: 0.07128024101257324, Lr:0.0001\n",
      "Epoch 25, Step: 215, Loss: 0.04676005616784096, Lr:0.0001\n",
      "Epoch 25, Step: 216, Loss: 0.004723312333226204, Lr:0.0001\n",
      "Epoch 25, Step: 217, Loss: 0.22517509758472443, Lr:0.0001\n",
      "Epoch 25, Step: 218, Loss: 0.11842168122529984, Lr:0.0001\n",
      "Epoch 25, Step: 219, Loss: 0.0598502978682518, Lr:0.0001\n",
      "Epoch 25, Step: 220, Loss: 0.008909562602639198, Lr:0.0001\n",
      "Epoch 25, Step: 221, Loss: 0.0008406118722632527, Lr:0.0001\n",
      "Epoch 25, Step: 222, Loss: 0.012042020447552204, Lr:0.0001\n",
      "Epoch 25, Step: 223, Loss: 0.008156678639352322, Lr:0.0001\n",
      "Epoch 25, Step: 224, Loss: 0.0338437482714653, Lr:0.0001\n",
      "Epoch 25, Step: 225, Loss: 0.047172799706459045, Lr:0.0001\n",
      "Epoch 25, Step: 226, Loss: 0.023161284625530243, Lr:0.0001\n",
      "Epoch 25, Step: 227, Loss: 0.007315918803215027, Lr:0.0001\n",
      "Epoch 25, Step: 228, Loss: 0.20525412261486053, Lr:0.0001\n",
      "Epoch 25, Step: 229, Loss: 0.08998046070337296, Lr:0.0001\n",
      "Epoch 25, Step: 230, Loss: 0.017340227961540222, Lr:0.0001\n",
      "Epoch 25, Step: 231, Loss: 0.07550101727247238, Lr:0.0001\n",
      "Epoch 25, Step: 232, Loss: 0.03347015753388405, Lr:0.0001\n",
      "Epoch 25, Step: 233, Loss: 0.3493557572364807, Lr:0.0001\n",
      "Epoch 25, Step: 234, Loss: 0.01204580720514059, Lr:0.0001\n",
      "Epoch 25, Step: 235, Loss: 0.01783902198076248, Lr:0.0001\n",
      "Epoch 25, Step: 236, Loss: 0.06699896603822708, Lr:0.0001\n",
      "Epoch 25, Step: 237, Loss: 0.17564964294433594, Lr:0.0001\n",
      "Epoch 25, Step: 238, Loss: 0.0005836483906023204, Lr:0.0001\n",
      "Epoch 25, Step: 239, Loss: 0.06694697588682175, Lr:0.0001\n",
      "Epoch 25, Step: 240, Loss: 0.05409800261259079, Lr:0.0001\n",
      "Epoch 25, Step: 241, Loss: 0.023716283962130547, Lr:0.0001\n",
      "Epoch 25, Step: 242, Loss: 0.07249679416418076, Lr:0.0001\n",
      "Epoch 25, Step: 243, Loss: 0.013293632306158543, Lr:0.0001\n",
      "Epoch 25, Step: 244, Loss: 0.269067645072937, Lr:0.0001\n",
      "Epoch 25, Step: 245, Loss: 0.1307363361120224, Lr:0.0001\n",
      "Epoch 25, Step: 246, Loss: 0.11600086092948914, Lr:0.0001\n",
      "Epoch 25, Step: 247, Loss: 0.0569847896695137, Lr:0.0001\n",
      "Epoch 25, Step: 248, Loss: 0.017669731751084328, Lr:0.0001\n",
      "Epoch 25, Step: 249, Loss: 0.00518912123516202, Lr:0.0001\n",
      "Epoch 25, Step: 250, Loss: 0.008850300684571266, Lr:0.0001\n",
      "Epoch 25, Step: 251, Loss: 0.0037821682635694742, Lr:0.0001\n",
      "Epoch 25, Step: 252, Loss: 0.11963845789432526, Lr:0.0001\n",
      "Epoch 25, Step: 253, Loss: 0.04524395242333412, Lr:0.0001\n",
      "Epoch 25, Step: 254, Loss: 0.00022333409287966788, Lr:0.0001\n",
      "Epoch 25, Step: 255, Loss: 0.04859771579504013, Lr:0.0001\n",
      "Epoch 25, Step: 256, Loss: 0.12842310965061188, Lr:0.0001\n",
      "Epoch 25, Step: 257, Loss: 0.011699889786541462, Lr:0.0001\n",
      "Epoch 25, Step: 258, Loss: 0.010604891926050186, Lr:0.0001\n",
      "Epoch 25, Step: 259, Loss: 0.15039032697677612, Lr:0.0001\n",
      "Epoch 25, Step: 260, Loss: 0.09124769270420074, Lr:0.0001\n",
      "Epoch 25, Step: 261, Loss: 0.10945449769496918, Lr:0.0001\n",
      "Epoch 25, Step: 262, Loss: 0.037473443895578384, Lr:0.0001\n",
      "Epoch 25, Step: 263, Loss: 0.018221663311123848, Lr:0.0001\n",
      "Epoch 25, Step: 264, Loss: 0.08925220370292664, Lr:0.0001\n",
      "Epoch 25, Step: 265, Loss: 0.11398031562566757, Lr:0.0001\n",
      "Epoch 25, Step: 266, Loss: 0.016049541532993317, Lr:0.0001\n",
      "Epoch 25, Step: 267, Loss: 0.16155725717544556, Lr:0.0001\n",
      "Epoch 25, Step: 268, Loss: 0.011826231144368649, Lr:0.0001\n",
      "Epoch 25, Step: 269, Loss: 0.003953485284000635, Lr:0.0001\n",
      "Epoch 25, Step: 270, Loss: 0.04951925948262215, Lr:0.0001\n",
      "Epoch 25, Step: 271, Loss: 0.005975458770990372, Lr:0.0001\n",
      "Epoch 25, Step: 272, Loss: 0.0006982054328545928, Lr:0.0001\n",
      "Epoch 25, Step: 273, Loss: 0.1272444874048233, Lr:0.0001\n",
      "Epoch 25, Step: 274, Loss: 0.020131131634116173, Lr:0.0001\n",
      "Epoch 25, Step: 275, Loss: 0.014862214215099812, Lr:0.0001\n",
      "Epoch 25, Step: 276, Loss: 0.022332951426506042, Lr:0.0001\n",
      "Epoch 25, Step: 277, Loss: 0.09277243167161942, Lr:0.0001\n",
      "Epoch 25, Step: 278, Loss: 0.14569565653800964, Lr:0.0001\n",
      "Epoch 25, Step: 279, Loss: 0.019500216469168663, Lr:0.0001\n",
      "Epoch 25, Step: 280, Loss: 0.01016497053205967, Lr:0.0001\n",
      "Epoch 25, Step: 281, Loss: 0.04499843344092369, Lr:0.0001\n",
      "Epoch 25, Step: 282, Loss: 0.04236272722482681, Lr:0.0001\n",
      "Epoch 25, Step: 283, Loss: 0.1464909315109253, Lr:0.0001\n",
      "Epoch 25, Step: 284, Loss: 0.14058519899845123, Lr:0.0001\n",
      "Epoch 25, Step: 285, Loss: 0.05528493970632553, Lr:0.0001\n",
      "Epoch 25, Step: 286, Loss: 0.03858797252178192, Lr:0.0001\n",
      "Epoch 25, Step: 287, Loss: 0.1568300724029541, Lr:0.0001\n",
      "Epoch 25, Step: 288, Loss: 0.07136885821819305, Lr:0.0001\n",
      "Epoch 25, Step: 289, Loss: 0.004079217556864023, Lr:0.0001\n",
      "Epoch 25, Step: 290, Loss: 0.1142357885837555, Lr:0.0001\n",
      "Epoch 25, Step: 291, Loss: 0.048429954797029495, Lr:0.0001\n",
      "Epoch 25, Step: 292, Loss: 0.09759978950023651, Lr:0.0001\n",
      "Epoch 25, Step: 293, Loss: 0.0872470885515213, Lr:0.0001\n",
      "Epoch 25, Step: 294, Loss: 0.0038596990052610636, Lr:0.0001\n",
      "Epoch 25, Step: 295, Loss: 0.0158347450196743, Lr:0.0001\n",
      "Epoch 25, Step: 296, Loss: 0.4184150695800781, Lr:0.0001\n",
      "Epoch 25, Step: 297, Loss: 0.06128257140517235, Lr:0.0001\n",
      "Epoch 25, Step: 298, Loss: 0.036586035043001175, Lr:0.0001\n",
      "Epoch 25, Step: 299, Loss: 0.01887214183807373, Lr:0.0001\n",
      "Epoch 25, Step: 300, Loss: 0.0010997988283634186, Lr:0.0001\n",
      "Epoch 25, Step: 301, Loss: 0.009975917637348175, Lr:0.0001\n",
      "Epoch 25, Step: 302, Loss: 0.09139905869960785, Lr:0.0001\n",
      "Epoch 25, Step: 303, Loss: 0.01215815544128418, Lr:0.0001\n",
      "Epoch 25, Step: 304, Loss: 0.06752447038888931, Lr:0.0001\n",
      "Epoch 25, Step: 305, Loss: 0.0063814427703619, Lr:0.0001\n",
      "Epoch 25, Step: 306, Loss: 0.09933887422084808, Lr:0.0001\n",
      "Epoch 25, Step: 307, Loss: 0.003809298388659954, Lr:0.0001\n",
      "Epoch 25, Step: 308, Loss: 0.0015473709208890796, Lr:0.0001\n",
      "Epoch 25, Step: 309, Loss: 0.00920927058905363, Lr:0.0001\n",
      "Epoch 25, Step: 310, Loss: 0.1026429608464241, Lr:0.0001\n",
      "Epoch 25, Step: 311, Loss: 0.30571162700653076, Lr:0.0001\n",
      "Epoch 25, Step: 312, Loss: 0.017924640327692032, Lr:0.0001\n",
      "Epoch 25, Step: 313, Loss: 0.011418517678976059, Lr:0.0001\n",
      "Epoch 25, Step: 314, Loss: 0.021732810884714127, Lr:0.0001\n",
      "Epoch 25, Step: 315, Loss: 0.07224252074956894, Lr:0.0001\n",
      "Epoch 25, Step: 316, Loss: 0.0009351576445624232, Lr:0.0001\n",
      "Epoch 25, Step: 317, Loss: 0.04037362337112427, Lr:0.0001\n",
      "Epoch 25, Step: 318, Loss: 0.09531797468662262, Lr:0.0001\n",
      "Epoch 25, Step: 319, Loss: 0.14274318516254425, Lr:0.0001\n",
      "Epoch 25, Step: 320, Loss: 0.1352834850549698, Lr:0.0001\n",
      "Epoch 25, Step: 321, Loss: 0.01562865637242794, Lr:0.0001\n",
      "Epoch 25, Step: 322, Loss: 0.1427721232175827, Lr:0.0001\n",
      "Epoch 25, Step: 323, Loss: 0.1841481477022171, Lr:0.0001\n",
      "Epoch 25, Step: 324, Loss: 0.0260311309248209, Lr:0.0001\n",
      "Epoch 25, Step: 325, Loss: 0.01975846290588379, Lr:0.0001\n",
      "Epoch 25, Step: 326, Loss: 0.1927170753479004, Lr:0.0001\n",
      "Epoch 25, Step: 327, Loss: 0.10817711800336838, Lr:0.0001\n",
      "Epoch 25, Step: 328, Loss: 0.014159156009554863, Lr:0.0001\n",
      "Epoch 25, Step: 329, Loss: 0.03384167701005936, Lr:0.0001\n",
      "Epoch 25, Step: 330, Loss: 0.0736231580376625, Lr:0.0001\n",
      "Epoch 25, Step: 331, Loss: 0.142852783203125, Lr:0.0001\n",
      "Epoch 25, Step: 332, Loss: 0.0038686401676386595, Lr:0.0001\n",
      "Epoch 25, Step: 333, Loss: 0.18722841143608093, Lr:0.0001\n",
      "Epoch 25, Step: 334, Loss: 0.0006908791838213801, Lr:0.0001\n",
      "Epoch 25, Step: 335, Loss: 0.10349826514720917, Lr:0.0001\n",
      "Epoch 25, Step: 336, Loss: 0.1961795836687088, Lr:0.0001\n",
      "Epoch 25, Step: 337, Loss: 0.014328681863844395, Lr:0.0001\n",
      "Epoch 25, Step: 338, Loss: 0.03905694931745529, Lr:0.0001\n",
      "Epoch 25, Step: 339, Loss: 0.2152462750673294, Lr:0.0001\n",
      "Epoch 25, Step: 340, Loss: 0.03445011004805565, Lr:0.0001\n",
      "Epoch 25, Step: 341, Loss: 0.17281921207904816, Lr:0.0001\n",
      "Epoch 25, Step: 342, Loss: 0.033619485795497894, Lr:0.0001\n",
      "Epoch 25, Step: 343, Loss: 0.1214187890291214, Lr:0.0001\n",
      "Epoch 25, Step: 344, Loss: 0.06259764730930328, Lr:0.0001\n",
      "Epoch 25, Step: 345, Loss: 0.04468420147895813, Lr:0.0001\n",
      "Epoch 25, Step: 346, Loss: 0.11542297899723053, Lr:0.0001\n",
      "Epoch 25, Step: 347, Loss: 0.03460628539323807, Lr:0.0001\n",
      "Epoch 25, Step: 348, Loss: 0.3139301836490631, Lr:0.0001\n",
      "Epoch 25, Step: 349, Loss: 0.201859712600708, Lr:0.0001\n",
      "Epoch 25, Step: 350, Loss: 0.03448941931128502, Lr:0.0001\n",
      "Epoch 25, Step: 351, Loss: 0.0007767003844492137, Lr:0.0001\n",
      "Epoch 25, Step: 352, Loss: 0.0054405019618570805, Lr:0.0001\n",
      "Epoch 25, Step: 353, Loss: 0.04483615234494209, Lr:0.0001\n",
      "Epoch 25, Step: 354, Loss: 0.1991456151008606, Lr:0.0001\n",
      "Epoch 25, Step: 355, Loss: 0.1458645761013031, Lr:0.0001\n",
      "Epoch 25, Step: 356, Loss: 0.16501401364803314, Lr:0.0001\n",
      "Epoch 25, Step: 357, Loss: 0.4942661225795746, Lr:0.0001\n",
      "Epoch 25, Step: 358, Loss: 0.05250567942857742, Lr:0.0001\n",
      "Epoch 25, Step: 359, Loss: 0.06883499026298523, Lr:0.0001\n",
      "Epoch 25, Step: 360, Loss: 0.2758261263370514, Lr:0.0001\n",
      "Epoch 25, Step: 361, Loss: 0.11634918302297592, Lr:0.0001\n",
      "Epoch 25, Step: 362, Loss: 0.05640505999326706, Lr:0.0001\n",
      "Epoch 25, Step: 363, Loss: 0.6900521516799927, Lr:0.0001\n",
      "Epoch 25, Step: 364, Loss: 0.06914627552032471, Lr:0.0001\n",
      "Epoch 25, Step: 365, Loss: 0.021037595346570015, Lr:0.0001\n",
      "Epoch 25, Step: 366, Loss: 0.001804049708880484, Lr:0.0001\n",
      "Epoch 25, Step: 367, Loss: 0.026885272935032845, Lr:0.0001\n",
      "Epoch 25, Step: 368, Loss: 0.0009366265730932355, Lr:0.0001\n",
      "Epoch 25, Step: 369, Loss: 0.046559568494558334, Lr:0.0001\n",
      "Epoch 25, Step: 370, Loss: 0.2556599974632263, Lr:0.0001\n",
      "Epoch 25, Step: 371, Loss: 0.06977260112762451, Lr:0.0001\n",
      "Epoch 25, Step: 372, Loss: 0.11348786950111389, Lr:0.0001\n",
      "Epoch 25, Step: 373, Loss: 0.20946577191352844, Lr:0.0001\n",
      "Epoch 25, Step: 374, Loss: 0.039171457290649414, Lr:0.0001\n",
      "Epoch 25, Step: 375, Loss: 0.034253232181072235, Lr:0.0001\n",
      "Epoch 25, Step: 376, Loss: 0.040684618055820465, Lr:0.0001\n",
      "Epoch 25, Step: 377, Loss: 0.06348014622926712, Lr:0.0001\n",
      "Epoch 25, Step: 378, Loss: 0.007836819626390934, Lr:0.0001\n",
      "Epoch 25, Step: 379, Loss: 0.0997767448425293, Lr:0.0001\n",
      "Epoch 25, Step: 380, Loss: 0.13085822761058807, Lr:0.0001\n",
      "Epoch 25, Step: 381, Loss: 0.005958868656307459, Lr:0.0001\n",
      "Epoch 25, Step: 382, Loss: 0.10582735389471054, Lr:0.0001\n",
      "Epoch 25, Step: 383, Loss: 0.02698592282831669, Lr:0.0001\n",
      "Epoch 25, Step: 384, Loss: 0.0022611080203205347, Lr:0.0001\n",
      "Epoch 25, Step: 385, Loss: 0.030815934762358665, Lr:0.0001\n",
      "Epoch 25, Step: 386, Loss: 0.01680639013648033, Lr:0.0001\n",
      "Epoch 25, Step: 387, Loss: 0.012651444412767887, Lr:0.0001\n",
      "Epoch 25, Step: 388, Loss: 0.08951013535261154, Lr:0.0001\n",
      "Epoch 25, Step: 389, Loss: 0.0017960646655410528, Lr:0.0001\n",
      "Epoch 25, Step: 390, Loss: 0.022941917181015015, Lr:0.0001\n",
      "Epoch 25, Step: 391, Loss: 0.0639643445611, Lr:0.0001\n",
      "Epoch 25, Step: 392, Loss: 0.05557485669851303, Lr:0.0001\n",
      "Epoch 25, Step: 393, Loss: 0.014024036936461926, Lr:0.0001\n",
      "Epoch 25, Step: 394, Loss: 0.07370087504386902, Lr:0.0001\n",
      "Epoch 25, Step: 395, Loss: 0.020826170220971107, Lr:0.0001\n",
      "Epoch 25, Step: 396, Loss: 0.22921162843704224, Lr:0.0001\n",
      "Epoch 25, Step: 397, Loss: 0.011879033409059048, Lr:0.0001\n",
      "Epoch 25, Step: 398, Loss: 0.0011739626061171293, Lr:0.0001\n",
      "Epoch 25, Step: 399, Loss: 0.031345028430223465, Lr:0.0001\n",
      "Epoch 25, Step: 400, Loss: 0.003795712487772107, Lr:0.0001\n",
      "Epoch 25, Step: 401, Loss: 0.20665596425533295, Lr:0.0001\n",
      "Epoch 25, Step: 402, Loss: 0.08555994182825089, Lr:0.0001\n",
      "Epoch 25, Step: 403, Loss: 0.4057968556880951, Lr:0.0001\n",
      "Epoch 25, Step: 404, Loss: 0.014845991507172585, Lr:0.0001\n",
      "Epoch 25, Step: 405, Loss: 0.0836091935634613, Lr:0.0001\n",
      "Epoch 25, Step: 406, Loss: 0.09969828277826309, Lr:0.0001\n",
      "Epoch 25, Step: 407, Loss: 0.027433909475803375, Lr:0.0001\n",
      "Epoch 25, Step: 408, Loss: 0.008165869861841202, Lr:0.0001\n",
      "Epoch 25, Step: 409, Loss: 0.017840644344687462, Lr:0.0001\n",
      "Epoch 25, Step: 410, Loss: 0.0003797355748247355, Lr:0.0001\n",
      "Epoch 25, Step: 411, Loss: 0.049983181059360504, Lr:0.0001\n",
      "Epoch 25, Step: 412, Loss: 0.19309255480766296, Lr:0.0001\n",
      "Epoch 25, Step: 413, Loss: 0.04582831636071205, Lr:0.0001\n",
      "Epoch 25, Step: 414, Loss: 0.20048661530017853, Lr:0.0001\n",
      "Epoch 25, Step: 415, Loss: 0.002992180408909917, Lr:0.0001\n",
      "Epoch 25, Step: 416, Loss: 0.056873030960559845, Lr:0.0001\n",
      "Epoch 25, Step: 417, Loss: 0.06802944839000702, Lr:0.0001\n",
      "Epoch 25, Step: 418, Loss: 0.0084376847371459, Lr:0.0001\n",
      "Epoch 25, Step: 419, Loss: 0.3038569986820221, Lr:0.0001\n",
      "Epoch 25, Step: 420, Loss: 0.0046689631417393684, Lr:0.0001\n",
      "Epoch 25, Step: 421, Loss: 0.03206625208258629, Lr:0.0001\n",
      "Epoch 25, Step: 422, Loss: 0.033347200602293015, Lr:0.0001\n",
      "Epoch 25, Step: 423, Loss: 0.004213839303702116, Lr:0.0001\n",
      "Epoch 25, Step: 424, Loss: 0.048736512660980225, Lr:0.0001\n",
      "Epoch 25, Step: 425, Loss: 0.017898760735988617, Lr:0.0001\n",
      "Epoch 25, Step: 426, Loss: 0.0026374305598437786, Lr:0.0001\n",
      "Epoch 25, Step: 427, Loss: 0.02036740630865097, Lr:0.0001\n",
      "Epoch 25, Step: 428, Loss: 0.0626903846859932, Lr:0.0001\n",
      "Epoch 25, Step: 429, Loss: 0.07253963500261307, Lr:0.0001\n",
      "Epoch 25, Step: 430, Loss: 0.1412559449672699, Lr:0.0001\n",
      "Epoch 25, Step: 431, Loss: 0.020086251199245453, Lr:0.0001\n",
      "Epoch 25, Step: 432, Loss: 0.0014684885973110795, Lr:0.0001\n",
      "Epoch 25, Step: 433, Loss: 0.0004931288422085345, Lr:0.0001\n",
      "Epoch 25, Step: 434, Loss: 0.029584256932139397, Lr:0.0001\n",
      "Epoch 25, Step: 435, Loss: 0.008468286134302616, Lr:0.0001\n",
      "Epoch 25, Step: 436, Loss: 0.3253272473812103, Lr:0.0001\n",
      "Epoch 25, Step: 437, Loss: 0.02312786690890789, Lr:0.0001\n",
      "Epoch 25, Step: 438, Loss: 0.13576550781726837, Lr:0.0001\n",
      "Epoch 25, Step: 439, Loss: 0.19982600212097168, Lr:0.0001\n",
      "Epoch 25, Step: 440, Loss: 1.586104393005371, Lr:0.0001\n",
      "Epoch 25, Step: 441, Loss: 0.01943051442503929, Lr:0.0001\n",
      "Epoch 25, Step: 442, Loss: 0.011396808549761772, Lr:0.0001\n",
      "Epoch 25, Step: 443, Loss: 0.012369267642498016, Lr:0.0001\n",
      "Epoch 25, Step: 444, Loss: 0.0643099918961525, Lr:0.0001\n",
      "Epoch 25, Step: 445, Loss: 0.12264490127563477, Lr:0.0001\n",
      "Epoch 25, Step: 446, Loss: 0.048031341284513474, Lr:0.0001\n",
      "Epoch 25, Step: 447, Loss: 0.0984673947095871, Lr:0.0001\n",
      "Epoch 25, Step: 448, Loss: 0.04282401129603386, Lr:0.0001\n",
      "Epoch 25, Step: 449, Loss: 0.01042512059211731, Lr:0.0001\n",
      "Epoch 25, Step: 450, Loss: 0.1622113734483719, Lr:0.0001\n",
      "Epoch 25, Step: 451, Loss: 0.016776854172348976, Lr:0.0001\n",
      "Epoch 25, Step: 452, Loss: 0.008037561550736427, Lr:0.0001\n",
      "Epoch 25, Step: 453, Loss: 0.0061853197403252125, Lr:0.0001\n",
      "Epoch 25, Step: 454, Loss: 0.08260809630155563, Lr:0.0001\n",
      "Epoch 25, Step: 455, Loss: 0.13645566999912262, Lr:0.0001\n",
      "Epoch 25, Step: 456, Loss: 0.2498856484889984, Lr:0.0001\n",
      "Epoch 25, Step: 457, Loss: 0.013447280041873455, Lr:0.0001\n",
      "Epoch 25, Step: 458, Loss: 0.010153758339583874, Lr:0.0001\n",
      "Epoch 25, Step: 459, Loss: 0.019652560353279114, Lr:0.0001\n",
      "Epoch 25, Step: 460, Loss: 0.0918203741312027, Lr:0.0001\n",
      "Epoch 25, Step: 461, Loss: 0.020009612664580345, Lr:0.0001\n",
      "Epoch 25, Step: 462, Loss: 0.5389198660850525, Lr:0.0001\n",
      "Epoch 25, Step: 463, Loss: 0.00214085029438138, Lr:0.0001\n",
      "Epoch 25, Step: 464, Loss: 0.03249051794409752, Lr:0.0001\n",
      "Epoch 25, Step: 465, Loss: 0.23022274672985077, Lr:0.0001\n",
      "Epoch 25, Step: 466, Loss: 0.07428757846355438, Lr:0.0001\n",
      "Epoch 25, Step: 467, Loss: 0.04727288708090782, Lr:0.0001\n",
      "Epoch 25, Step: 468, Loss: 0.24231137335300446, Lr:0.0001\n",
      "Epoch 25, Step: 469, Loss: 0.016823386773467064, Lr:0.0001\n",
      "Epoch 25, Step: 470, Loss: 0.05915357545018196, Lr:0.0001\n",
      "Epoch 25, Step: 471, Loss: 0.15273018181324005, Lr:0.0001\n",
      "Epoch 25, Step: 472, Loss: 0.0034112995490431786, Lr:0.0001\n",
      "Epoch 25, Step: 473, Loss: 0.10888075083494186, Lr:0.0001\n",
      "Epoch 25, Step: 474, Loss: 0.07502657175064087, Lr:0.0001\n",
      "Epoch 25, Step: 475, Loss: 0.24118654429912567, Lr:0.0001\n",
      "Epoch 25, Step: 476, Loss: 0.09362897276878357, Lr:0.0001\n",
      "Epoch 25, Step: 477, Loss: 0.016406290233135223, Lr:0.0001\n",
      "Epoch 25, Step: 478, Loss: 0.03461319953203201, Lr:0.0001\n",
      "Epoch 25, Step: 479, Loss: 0.21165454387664795, Lr:0.0001\n",
      "Epoch 25, Step: 480, Loss: 0.004826508462429047, Lr:0.0001\n",
      "Epoch 25, Step: 481, Loss: 0.0038234780076891184, Lr:0.0001\n",
      "Epoch 25, Step: 482, Loss: 0.02424711175262928, Lr:0.0001\n",
      "Epoch 25, Step: 483, Loss: 0.029127806425094604, Lr:0.0001\n",
      "Epoch 25, Step: 484, Loss: 0.012632432393729687, Lr:0.0001\n",
      "Epoch 25, Step: 485, Loss: 0.0191909559071064, Lr:0.0001\n",
      "Epoch 25, Step: 486, Loss: 0.21671147644519806, Lr:0.0001\n",
      "Epoch 25, Step: 487, Loss: 0.07423066347837448, Lr:0.0001\n",
      "Epoch 25, Step: 488, Loss: 0.007181231863796711, Lr:0.0001\n",
      "Epoch 25, Step: 489, Loss: 0.11484555155038834, Lr:0.0001\n",
      "Epoch 25, Step: 490, Loss: 0.0008783647208474576, Lr:0.0001\n",
      "Epoch 25, Step: 491, Loss: 0.07148164510726929, Lr:0.0001\n",
      "Epoch 25, Step: 492, Loss: 0.12673375010490417, Lr:0.0001\n",
      "Epoch 25, Step: 493, Loss: 0.025955216959118843, Lr:0.0001\n",
      "Epoch 25, Step: 494, Loss: 0.3863298296928406, Lr:0.0001\n",
      "Epoch 25, Step: 495, Loss: 0.0560990609228611, Lr:0.0001\n",
      "Epoch 25, Step: 496, Loss: 0.0815298855304718, Lr:0.0001\n",
      "Epoch 25, Step: 497, Loss: 0.09672389924526215, Lr:0.0001\n",
      "Epoch 25, Step: 498, Loss: 0.13258466124534607, Lr:0.0001\n",
      "Epoch 25, Step: 499, Loss: 0.004116082098335028, Lr:0.0001\n",
      "Epoch 25, Step: 500, Loss: 0.13477058708667755, Lr:0.0001\n",
      "Epoch 25, Step: 501, Loss: 0.07074339687824249, Lr:0.0001\n",
      "Epoch 25, Step: 502, Loss: 0.04819616675376892, Lr:0.0001\n",
      "Epoch 25, Step: 503, Loss: 0.043637096881866455, Lr:0.0001\n",
      "Epoch 25, Step: 504, Loss: 0.17322298884391785, Lr:0.0001\n",
      "Epoch 25, Step: 505, Loss: 0.1830061376094818, Lr:0.0001\n",
      "Epoch 25, Step: 506, Loss: 0.012585384771227837, Lr:0.0001\n",
      "Epoch 25, Step: 507, Loss: 0.07327926903963089, Lr:0.0001\n",
      "Epoch 25, Step: 508, Loss: 0.03396330028772354, Lr:0.0001\n",
      "Epoch 25, Step: 509, Loss: 0.05547895282506943, Lr:0.0001\n",
      "Epoch 25, Step: 510, Loss: 0.02340744435787201, Lr:0.0001\n",
      "Epoch 25, Step: 511, Loss: 0.06976533681154251, Lr:0.0001\n",
      "Epoch 25, Step: 512, Loss: 0.050644032657146454, Lr:0.0001\n",
      "Epoch 25, Step: 513, Loss: 0.14203564822673798, Lr:0.0001\n",
      "Epoch 25, Step: 514, Loss: 0.0025348460767418146, Lr:0.0001\n",
      "Epoch 25, Step: 515, Loss: 0.0013748337514698505, Lr:0.0001\n",
      "Epoch 25, Step: 516, Loss: 0.02758023329079151, Lr:0.0001\n",
      "Epoch 25, Step: 517, Loss: 0.027887187898159027, Lr:0.0001\n",
      "Epoch 25, Step: 518, Loss: 0.1118541806936264, Lr:0.0001\n",
      "Epoch 25, Step: 519, Loss: 0.027341140434145927, Lr:0.0001\n",
      "Epoch 25, Step: 520, Loss: 0.19789785146713257, Lr:0.0001\n",
      "Epoch 25, Step: 521, Loss: 0.16636137664318085, Lr:0.0001\n",
      "Epoch 25, Step: 522, Loss: 0.055848535150289536, Lr:0.0001\n",
      "Epoch 25, Step: 523, Loss: 0.028560979291796684, Lr:0.0001\n",
      "Epoch 25, Step: 524, Loss: 0.05473437160253525, Lr:0.0001\n",
      "Epoch 25, Step: 525, Loss: 0.016733143478631973, Lr:0.0001\n",
      "Epoch 25, Step: 526, Loss: 0.06109010428190231, Lr:0.0001\n",
      "Epoch 25, Step: 527, Loss: 0.017675401642918587, Lr:0.0001\n",
      "Epoch 25, Step: 528, Loss: 0.14400459825992584, Lr:0.0001\n",
      "Epoch 25, Step: 529, Loss: 0.22223420441150665, Lr:0.0001\n",
      "Epoch 25, Step: 530, Loss: 0.057787422090768814, Lr:0.0001\n",
      "Epoch 25, Step: 531, Loss: 0.0033577880822122097, Lr:0.0001\n",
      "Epoch 25, Step: 532, Loss: 0.015677908435463905, Lr:0.0001\n",
      "Epoch 25, Step: 533, Loss: 0.09696069359779358, Lr:0.0001\n",
      "Epoch 25, Step: 534, Loss: 0.0037161388900130987, Lr:0.0001\n",
      "Epoch 25, Step: 535, Loss: 0.015551429241895676, Lr:0.0001\n",
      "Epoch 25, Step: 536, Loss: 0.10891055315732956, Lr:0.0001\n",
      "Epoch 25, Step: 537, Loss: 0.007238574326038361, Lr:0.0001\n",
      "Epoch 25, Step: 538, Loss: 0.2986774742603302, Lr:0.0001\n",
      "Epoch 25, Step: 539, Loss: 0.028397947549819946, Lr:0.0001\n",
      "Epoch 25, Step: 540, Loss: 0.31798720359802246, Lr:0.0001\n",
      "Epoch 25, Step: 541, Loss: 0.03392360359430313, Lr:0.0001\n",
      "Epoch 25, Step: 542, Loss: 0.027637675404548645, Lr:0.0001\n",
      "Epoch 25, Step: 543, Loss: 0.08619657903909683, Lr:0.0001\n",
      "Epoch 25, Step: 544, Loss: 0.01521970797330141, Lr:0.0001\n",
      "Epoch 25, Step: 545, Loss: 0.04589236527681351, Lr:0.0001\n",
      "Epoch 25, Step: 546, Loss: 0.003187658730894327, Lr:0.0001\n",
      "Epoch 25, Step: 547, Loss: 0.03481506556272507, Lr:0.0001\n",
      "Epoch 25, Step: 548, Loss: 0.04691057279706001, Lr:0.0001\n",
      "Epoch 25, Step: 549, Loss: 0.0005765953683294356, Lr:0.0001\n",
      "Epoch 25, Step: 550, Loss: 0.05261116474866867, Lr:0.0001\n",
      "Epoch 25, Step: 551, Loss: 0.2566704750061035, Lr:0.0001\n",
      "Epoch 25, Step: 552, Loss: 0.02674194797873497, Lr:0.0001\n",
      "Epoch 25, Step: 553, Loss: 0.15552833676338196, Lr:0.0001\n",
      "Epoch 25, Step: 554, Loss: 0.023504536598920822, Lr:0.0001\n",
      "Epoch 25, Step: 555, Loss: 0.010183891281485558, Lr:0.0001\n",
      "Epoch 25, Step: 556, Loss: 0.1986004114151001, Lr:0.0001\n",
      "Epoch 25, Step: 557, Loss: 0.08958997577428818, Lr:0.0001\n",
      "Epoch 25, Step: 558, Loss: 0.027775436639785767, Lr:0.0001\n",
      "Epoch 25, Step: 559, Loss: 0.05422472953796387, Lr:0.0001\n",
      "Epoch 25, Step: 560, Loss: 0.6540975570678711, Lr:0.0001\n",
      "Epoch 25, Step: 561, Loss: 0.15607860684394836, Lr:0.0001\n",
      "Epoch 25, Step: 562, Loss: 0.03867100179195404, Lr:0.0001\n",
      "Epoch 25, Step: 563, Loss: 0.44667407870292664, Lr:0.0001\n",
      "Epoch 25, Step: 564, Loss: 0.03199460729956627, Lr:0.0001\n",
      "Epoch 25, Step: 565, Loss: 0.05034636706113815, Lr:0.0001\n",
      "Epoch 25, Step: 566, Loss: 0.04451681300997734, Lr:0.0001\n",
      "Epoch 25, Step: 567, Loss: 0.023296214640140533, Lr:0.0001\n",
      "Epoch 25, Step: 568, Loss: 0.0066442969255149364, Lr:0.0001\n",
      "Epoch 25, Step: 569, Loss: 0.025953104719519615, Lr:0.0001\n",
      "Epoch 25, Step: 570, Loss: 0.03609888255596161, Lr:0.0001\n",
      "Epoch 25, Step: 571, Loss: 0.06223198398947716, Lr:0.0001\n",
      "Epoch 25, Step: 572, Loss: 0.04073064774274826, Lr:0.0001\n",
      "Epoch 25, Step: 573, Loss: 0.21472179889678955, Lr:0.0001\n",
      "Epoch 25, Step: 574, Loss: 0.006023903377354145, Lr:0.0001\n",
      "Epoch 25, Step: 575, Loss: 0.006485674064606428, Lr:0.0001\n",
      "Epoch 25, Step: 576, Loss: 0.029111113399267197, Lr:0.0001\n",
      "Epoch 25, Step: 577, Loss: 0.03807223215699196, Lr:0.0001\n",
      "Epoch 25, Step: 578, Loss: 0.004816471599042416, Lr:0.0001\n",
      "Epoch 25, Step: 579, Loss: 0.034622274339199066, Lr:0.0001\n",
      "Epoch 25, Step: 580, Loss: 0.11181651800870895, Lr:0.0001\n",
      "Epoch 25, Step: 581, Loss: 0.017807234078645706, Lr:0.0001\n",
      "Epoch 25, Step: 582, Loss: 0.08897458016872406, Lr:0.0001\n",
      "Epoch 25, Step: 583, Loss: 0.002098569879308343, Lr:0.0001\n",
      "Epoch 25, Step: 584, Loss: 0.08246011286973953, Lr:0.0001\n",
      "Epoch 25, Step: 585, Loss: 0.23862029612064362, Lr:0.0001\n",
      "Epoch 25, Step: 586, Loss: 0.019523460417985916, Lr:0.0001\n",
      "Epoch 25, Step: 587, Loss: 0.005662849638611078, Lr:0.0001\n",
      "Epoch 25, Step: 588, Loss: 0.005384850315749645, Lr:0.0001\n",
      "Epoch 25, Step: 589, Loss: 0.3585398197174072, Lr:0.0001\n",
      "Epoch 25, Step: 590, Loss: 0.050073668360710144, Lr:0.0001\n",
      "Epoch 25, Step: 591, Loss: 0.04066476225852966, Lr:0.0001\n",
      "Epoch 25, Step: 592, Loss: 0.012143516913056374, Lr:0.0001\n",
      "Epoch 25, Step: 593, Loss: 0.04720412194728851, Lr:0.0001\n",
      "Epoch 25, Step: 594, Loss: 0.1735837161540985, Lr:0.0001\n",
      "Epoch 25, Step: 595, Loss: 0.07246997952461243, Lr:0.0001\n",
      "Epoch 25, Step: 596, Loss: 0.017022470012307167, Lr:0.0001\n",
      "Epoch 25, Step: 597, Loss: 0.03020966798067093, Lr:0.0001\n",
      "Epoch 25, Step: 598, Loss: 0.005751677788794041, Lr:0.0001\n",
      "Epoch 25, Step: 599, Loss: 0.12403692305088043, Lr:0.0001\n",
      "Epoch 25, Step: 600, Loss: 0.15740834176540375, Lr:0.0001\n",
      "Epoch 25, Step: 601, Loss: 0.027288198471069336, Lr:0.0001\n",
      "Epoch 25, Step: 602, Loss: 0.02741949073970318, Lr:0.0001\n",
      "Epoch 25, Step: 603, Loss: 0.017943860962986946, Lr:0.0001\n",
      "Epoch 25, Step: 604, Loss: 0.017953818663954735, Lr:0.0001\n",
      "Epoch 25, Step: 605, Loss: 0.015201004222035408, Lr:0.0001\n",
      "Epoch 25, Step: 606, Loss: 0.10178428888320923, Lr:0.0001\n",
      "Epoch 25, Step: 607, Loss: 0.20904859900474548, Lr:0.0001\n",
      "Epoch 25, Step: 608, Loss: 0.11631613969802856, Lr:0.0001\n",
      "Epoch 25, Step: 609, Loss: 0.012514564208686352, Lr:0.0001\n",
      "Epoch 25, Step: 610, Loss: 0.07957438379526138, Lr:0.0001\n",
      "Epoch 25, Step: 611, Loss: 0.09164036810398102, Lr:0.0001\n",
      "Epoch 25, Step: 612, Loss: 0.004760862328112125, Lr:0.0001\n",
      "Epoch 25, Step: 613, Loss: 0.01230117678642273, Lr:0.0001\n",
      "Epoch 25, Step: 614, Loss: 0.00954518187791109, Lr:0.0001\n",
      "Epoch 25, Step: 615, Loss: 0.09401938319206238, Lr:0.0001\n",
      "Epoch 25, Step: 616, Loss: 0.06055986136198044, Lr:0.0001\n",
      "Epoch 25, Step: 617, Loss: 0.042795635759830475, Lr:0.0001\n",
      "Epoch 25, Step: 618, Loss: 0.01959189958870411, Lr:0.0001\n",
      "Epoch 25, Step: 619, Loss: 0.003507069079205394, Lr:0.0001\n",
      "Epoch 25, Step: 620, Loss: 0.014218953438103199, Lr:0.0001\n",
      "Epoch 25, Step: 621, Loss: 0.033597853034734726, Lr:0.0001\n",
      "Epoch 25, Step: 622, Loss: 0.12049166858196259, Lr:0.0001\n",
      "Epoch 25, Step: 623, Loss: 0.06731541454792023, Lr:0.0001\n",
      "Epoch 25, Step: 624, Loss: 0.01652546413242817, Lr:0.0001\n",
      "Epoch 25, Step: 625, Loss: 0.2059532105922699, Lr:0.0001\n",
      "Epoch 25, Step: 626, Loss: 0.012817679904401302, Lr:0.0001\n",
      "Epoch 25, Step: 627, Loss: 0.1165383979678154, Lr:0.0001\n",
      "Epoch 25, Step: 628, Loss: 0.1508243829011917, Lr:0.0001\n",
      "Epoch 25, Step: 629, Loss: 0.06420216709375381, Lr:0.0001\n",
      "Epoch 25, Step: 630, Loss: 0.008318133652210236, Lr:0.0001\n",
      "Epoch 25, Step: 631, Loss: 0.03283602371811867, Lr:0.0001\n",
      "Epoch 25, Step: 632, Loss: 0.11093167215585709, Lr:0.0001\n",
      "Epoch 25, Step: 633, Loss: 0.018438365310430527, Lr:0.0001\n",
      "Epoch 25, Step: 634, Loss: 0.09716805070638657, Lr:0.0001\n",
      "Epoch 25, Step: 635, Loss: 0.043020572513341904, Lr:0.0001\n",
      "Epoch 25, Step: 636, Loss: 0.0450001060962677, Lr:0.0001\n",
      "Epoch 25, Step: 637, Loss: 0.010686248540878296, Lr:0.0001\n",
      "Epoch 25, Step: 638, Loss: 0.01801672764122486, Lr:0.0001\n",
      "Epoch 25, Step: 639, Loss: 0.016998693346977234, Lr:0.0001\n",
      "Epoch 25, Step: 640, Loss: 0.30326324701309204, Lr:0.0001\n",
      "Epoch 25, Step: 641, Loss: 0.12556937336921692, Lr:0.0001\n",
      "Epoch 25, Step: 642, Loss: 0.04492039605975151, Lr:0.0001\n",
      "Epoch 25, Step: 643, Loss: 0.08632785081863403, Lr:0.0001\n",
      "Epoch 25, Step: 644, Loss: 0.20289868116378784, Lr:0.0001\n",
      "Epoch 25, Step: 645, Loss: 0.014795871451497078, Lr:0.0001\n",
      "Epoch 25, Step: 646, Loss: 0.0028977994807064533, Lr:0.0001\n",
      "Epoch 25, Step: 647, Loss: 0.02613164857029915, Lr:0.0001\n",
      "Epoch 25, Step: 648, Loss: 0.09390518069267273, Lr:0.0001\n",
      "Epoch 25, Step: 649, Loss: 0.06238839402794838, Lr:0.0001\n",
      "Epoch 25, Step: 650, Loss: 0.03850951045751572, Lr:0.0001\n",
      "Epoch 25, Step: 651, Loss: 0.017919320613145828, Lr:0.0001\n",
      "Epoch 25, Step: 652, Loss: 0.0312981978058815, Lr:0.0001\n",
      "Epoch 25, Step: 653, Loss: 0.021113023161888123, Lr:0.0001\n",
      "Epoch 25, Step: 654, Loss: 0.03154974430799484, Lr:0.0001\n",
      "Epoch 25, Step: 655, Loss: 0.1126563623547554, Lr:0.0001\n",
      "Epoch 25, Step: 656, Loss: 0.02944486401975155, Lr:0.0001\n",
      "Epoch 25, Step: 657, Loss: 0.15581326186656952, Lr:0.0001\n",
      "Epoch 25, Step: 658, Loss: 0.05986427515745163, Lr:0.0001\n",
      "Epoch 25, Step: 659, Loss: 0.014272046275436878, Lr:0.0001\n",
      "Epoch 25, Step: 660, Loss: 0.012892918661236763, Lr:0.0001\n",
      "Epoch 25, Step: 661, Loss: 0.026096859946846962, Lr:0.0001\n",
      "Epoch 25, Step: 662, Loss: 0.22745899856090546, Lr:0.0001\n",
      "Epoch 25, Step: 663, Loss: 0.14463751018047333, Lr:0.0001\n",
      "Epoch 25, Step: 664, Loss: 0.058546021580696106, Lr:0.0001\n",
      "Epoch 25, Step: 665, Loss: 0.16311904788017273, Lr:0.0001\n",
      "Epoch 25, Step: 666, Loss: 0.1470857411623001, Lr:0.0001\n",
      "Epoch 25, Step: 667, Loss: 0.01761939749121666, Lr:0.0001\n",
      "Epoch 25, Step: 668, Loss: 0.11321625858545303, Lr:0.0001\n",
      "Epoch 25, Step: 669, Loss: 0.03603065386414528, Lr:0.0001\n",
      "Epoch 25, Step: 670, Loss: 0.009791103191673756, Lr:0.0001\n",
      "Epoch 25, Step: 671, Loss: 0.021323449909687042, Lr:0.0001\n",
      "Epoch 25, Step: 672, Loss: 0.022685015574097633, Lr:0.0001\n",
      "Epoch 25, Step: 673, Loss: 0.10611221194267273, Lr:0.0001\n",
      "Epoch 25, Step: 674, Loss: 0.3061894476413727, Lr:0.0001\n",
      "Epoch 25, Step: 675, Loss: 0.1766720712184906, Lr:0.0001\n",
      "Epoch 25, Step: 676, Loss: 0.026358712464571, Lr:0.0001\n",
      "Epoch 25, Step: 677, Loss: 0.09506217390298843, Lr:0.0001\n",
      "Epoch 25, Step: 678, Loss: 0.014429234899580479, Lr:0.0001\n",
      "Epoch 25, Step: 679, Loss: 0.01035330630838871, Lr:0.0001\n",
      "Epoch 25, Step: 680, Loss: 0.026545759290456772, Lr:0.0001\n",
      "Epoch 25, Step: 681, Loss: 0.0932779461145401, Lr:0.0001\n",
      "Epoch 25, Step: 682, Loss: 0.018194099888205528, Lr:0.0001\n",
      "Epoch 25, Step: 683, Loss: 0.04166996479034424, Lr:0.0001\n",
      "Epoch 25, Step: 684, Loss: 0.08179353177547455, Lr:0.0001\n",
      "Epoch 25, Step: 685, Loss: 0.004667001776397228, Lr:0.0001\n",
      "Epoch 25, Step: 686, Loss: 0.016878768801689148, Lr:0.0001\n",
      "Epoch 25, Step: 687, Loss: 0.003856747644022107, Lr:0.0001\n",
      "Epoch 25, Step: 688, Loss: 0.10090576112270355, Lr:0.0001\n",
      "Epoch 25, Step: 689, Loss: 0.11337403953075409, Lr:0.0001\n",
      "Epoch 25, Step: 690, Loss: 0.023135032504796982, Lr:0.0001\n",
      "Epoch 25, Step: 691, Loss: 0.0014426738489419222, Lr:0.0001\n",
      "Epoch 25, Step: 692, Loss: 0.030903439968824387, Lr:0.0001\n",
      "Epoch 25, Step: 693, Loss: 0.13585613667964935, Lr:0.0001\n",
      "Epoch 25, Step: 694, Loss: 0.25601425766944885, Lr:0.0001\n",
      "Epoch 25, Step: 695, Loss: 0.007892990484833717, Lr:0.0001\n",
      "Epoch 25, Step: 696, Loss: 0.05197823792695999, Lr:0.0001\n",
      "Epoch 25, Step: 697, Loss: 0.01943347044289112, Lr:0.0001\n",
      "Epoch 25, Step: 698, Loss: 0.0642981231212616, Lr:0.0001\n",
      "Epoch 25, Step: 699, Loss: 0.316400945186615, Lr:0.0001\n",
      "Epoch 25, Step: 700, Loss: 0.03691631555557251, Lr:0.0001\n",
      "Epoch 25, Step: 701, Loss: 0.012813434936106205, Lr:0.0001\n",
      "Epoch 25, Step: 702, Loss: 0.09372864663600922, Lr:0.0001\n",
      "Epoch 25, Step: 703, Loss: 0.2666880190372467, Lr:0.0001\n",
      "Epoch 25, Step: 704, Loss: 0.15480394661426544, Lr:0.0001\n",
      "Epoch 25, Step: 705, Loss: 0.0485367551445961, Lr:0.0001\n",
      "Epoch 25, Step: 706, Loss: 0.016195187345147133, Lr:0.0001\n",
      "Epoch 25, Step: 707, Loss: 0.07789240777492523, Lr:0.0001\n",
      "Epoch 25, Step: 708, Loss: 0.09978310763835907, Lr:0.0001\n",
      "Epoch 25, Step: 709, Loss: 0.010573464445769787, Lr:0.0001\n",
      "Epoch 25, Step: 710, Loss: 0.21358934044837952, Lr:0.0001\n",
      "Epoch 25, Step: 711, Loss: 0.06915890425443649, Lr:0.0001\n",
      "Epoch 25, Step: 712, Loss: 0.018152575939893723, Lr:0.0001\n",
      "Epoch 25, Step: 713, Loss: 0.0005819446523673832, Lr:0.0001\n",
      "Epoch 25, Step: 714, Loss: 0.052783332765102386, Lr:0.0001\n",
      "Epoch 25, Step: 715, Loss: 0.1671009510755539, Lr:0.0001\n",
      "Epoch 25, Step: 716, Loss: 0.03222614526748657, Lr:0.0001\n",
      "Epoch 25, Step: 717, Loss: 0.0032700011506676674, Lr:0.0001\n",
      "Epoch 25, Step: 718, Loss: 0.013981426134705544, Lr:0.0001\n",
      "Epoch 25, Step: 719, Loss: 0.016925020143389702, Lr:0.0001\n",
      "Epoch 25, Step: 720, Loss: 0.009229461662471294, Lr:0.0001\n",
      "Epoch 25, Step: 721, Loss: 0.14277631044387817, Lr:0.0001\n",
      "Epoch 25, Step: 722, Loss: 0.022112615406513214, Lr:0.0001\n",
      "Epoch 25, Step: 723, Loss: 0.016808466985821724, Lr:0.0001\n",
      "Epoch 25, Step: 724, Loss: 0.05110128968954086, Lr:0.0001\n",
      "Epoch 25, Step: 725, Loss: 0.0631563663482666, Lr:0.0001\n",
      "Epoch 25, Step: 726, Loss: 0.0035588673781603575, Lr:0.0001\n",
      "Epoch 25, Step: 727, Loss: 0.033183153718709946, Lr:0.0001\n",
      "Epoch 25, Step: 728, Loss: 0.056550391018390656, Lr:0.0001\n",
      "Epoch 25, Step: 729, Loss: 0.01242205873131752, Lr:0.0001\n",
      "Epoch 25, Step: 730, Loss: 0.082966148853302, Lr:0.0001\n",
      "Epoch 25, Step: 731, Loss: 0.0028079398907721043, Lr:0.0001\n",
      "Epoch 25, Step: 732, Loss: 0.002807416021823883, Lr:0.0001\n",
      "Epoch 25, Step: 733, Loss: 0.00747316051274538, Lr:0.0001\n",
      "Epoch 25, Step: 734, Loss: 0.005935543682426214, Lr:0.0001\n",
      "Epoch 25, Step: 735, Loss: 0.2371903508901596, Lr:0.0001\n",
      "Epoch 25, Step: 736, Loss: 0.0002128764899680391, Lr:0.0001\n",
      "Epoch 25, Step: 737, Loss: 0.0039592767134308815, Lr:0.0001\n",
      "Epoch 25, Step: 738, Loss: 0.032272182404994965, Lr:0.0001\n",
      "Epoch 25, Step: 739, Loss: 0.05236764997243881, Lr:0.0001\n",
      "Epoch 25, Step: 740, Loss: 0.0038886815309524536, Lr:0.0001\n",
      "Epoch 25, Step: 741, Loss: 0.01178690791130066, Lr:0.0001\n",
      "Epoch 25, Step: 742, Loss: 0.09958526492118835, Lr:0.0001\n",
      "Epoch 25, Step: 743, Loss: 0.043713219463825226, Lr:0.0001\n",
      "Epoch 25, Step: 744, Loss: 0.022084666416049004, Lr:0.0001\n",
      "Epoch 25, Step: 745, Loss: 0.013529493473470211, Lr:0.0001\n",
      "Epoch 25, Step: 746, Loss: 0.06902129203081131, Lr:0.0001\n",
      "Epoch 25, Step: 747, Loss: 0.0026728357188403606, Lr:0.0001\n",
      "Epoch 25, Step: 748, Loss: 0.062492914497852325, Lr:0.0001\n",
      "Epoch 25, Step: 749, Loss: 0.0012851242208853364, Lr:0.0001\n",
      "Epoch 25, Step: 750, Loss: 0.0636143833398819, Lr:0.0001\n",
      "Epoch 25, Step: 751, Loss: 0.0012171624694019556, Lr:0.0001\n",
      "Epoch 25, Step: 752, Loss: 0.017006732523441315, Lr:0.0001\n",
      "Epoch 25, Step: 753, Loss: 0.054567042738199234, Lr:0.0001\n",
      "Epoch 25, Step: 754, Loss: 0.08389704674482346, Lr:0.0001\n",
      "Epoch 25, Step: 755, Loss: 0.03907278925180435, Lr:0.0001\n",
      "Epoch 25, Step: 756, Loss: 0.0014510626206174493, Lr:0.0001\n",
      "Epoch 25, Step: 757, Loss: 0.04325752332806587, Lr:0.0001\n",
      "Epoch 25, Step: 758, Loss: 0.12883815169334412, Lr:0.0001\n",
      "Epoch 25, Step: 759, Loss: 0.0011753046419471502, Lr:0.0001\n",
      "Epoch 25, Step: 760, Loss: 0.03827560320496559, Lr:0.0001\n",
      "Epoch 25, Step: 761, Loss: 0.0316297747194767, Lr:0.0001\n",
      "Epoch 25, Step: 762, Loss: 0.09872932732105255, Lr:0.0001\n",
      "Epoch 25, Step: 763, Loss: 0.0004446365055628121, Lr:0.0001\n",
      "Epoch 25, Step: 764, Loss: 0.11608555912971497, Lr:0.0001\n",
      "Epoch 25, Step: 765, Loss: 0.00045443515409715474, Lr:0.0001\n",
      "Epoch 25, Step: 766, Loss: 0.004843366798013449, Lr:0.0001\n",
      "Epoch 25, Step: 767, Loss: 0.36832162737846375, Lr:0.0001\n",
      "Epoch 25, Step: 768, Loss: 0.00046802108408883214, Lr:0.0001\n",
      "Epoch 25, Step: 769, Loss: 0.032730430364608765, Lr:0.0001\n",
      "Epoch 25, Step: 770, Loss: 0.009864531457424164, Lr:0.0001\n",
      "Epoch 25, Step: 771, Loss: 0.0262956153601408, Lr:0.0001\n",
      "Epoch 25, Step: 772, Loss: 0.11258548498153687, Lr:0.0001\n",
      "Epoch 25, Step: 773, Loss: 0.03176574036478996, Lr:0.0001\n",
      "Epoch 25, Step: 774, Loss: 0.1672215461730957, Lr:0.0001\n",
      "Epoch 25, Step: 775, Loss: 0.20350109040737152, Lr:0.0001\n",
      "Epoch 25, Step: 776, Loss: 0.034371230751276016, Lr:0.0001\n",
      "Epoch 25, Step: 777, Loss: 0.03465951234102249, Lr:0.0001\n",
      "Epoch 25, Step: 778, Loss: 0.051795005798339844, Lr:0.0001\n",
      "Epoch 25, Step: 779, Loss: 0.01983385533094406, Lr:0.0001\n",
      "Epoch 25, Step: 780, Loss: 0.06889455765485764, Lr:0.0001\n",
      "Epoch 25, Step: 781, Loss: 0.001986452378332615, Lr:0.0001\n",
      "Epoch 25, Step: 782, Loss: 0.060356639325618744, Lr:0.0001\n",
      "Epoch 25, Step: 783, Loss: 0.22414380311965942, Lr:0.0001\n",
      "Epoch 25, Step: 784, Loss: 0.027995489537715912, Lr:0.0001\n",
      "Epoch 25, Step: 785, Loss: 0.0806523859500885, Lr:0.0001\n",
      "Epoch 25, Step: 786, Loss: 0.036155734211206436, Lr:0.0001\n",
      "Epoch 25, Step: 787, Loss: 0.06709663569927216, Lr:0.0001\n",
      "Epoch 25, Step: 788, Loss: 0.07957915216684341, Lr:0.0001\n",
      "Epoch 25, Step: 789, Loss: 0.0075738090090453625, Lr:0.0001\n",
      "Epoch 25, Step: 790, Loss: 0.027883052825927734, Lr:0.0001\n",
      "Epoch 25, Step: 791, Loss: 0.19523601233959198, Lr:0.0001\n",
      "Epoch 25, Step: 792, Loss: 0.004430240485817194, Lr:0.0001\n",
      "Epoch 25, Step: 793, Loss: 0.11967825144529343, Lr:0.0001\n",
      "Epoch 25, Step: 794, Loss: 0.022615358233451843, Lr:0.0001\n",
      "Epoch 25, Step: 795, Loss: 0.4447353184223175, Lr:0.0001\n",
      "Epoch 25, Step: 796, Loss: 0.0011594105744734406, Lr:0.0001\n",
      "Epoch 25, Step: 797, Loss: 0.056563690304756165, Lr:0.0001\n",
      "Epoch 25, Step: 798, Loss: 0.2173691838979721, Lr:0.0001\n",
      "Epoch 25, Step: 799, Loss: 0.1442549079656601, Lr:0.0001\n",
      "Epoch 25, Step: 800, Loss: 0.10940401256084442, Lr:0.0001\n",
      "Epoch 25, Step: 801, Loss: 0.053168267011642456, Lr:0.0001\n",
      "Epoch 25, Step: 802, Loss: 0.00937379989773035, Lr:0.0001\n",
      "Epoch 25, Step: 803, Loss: 0.0026634768582880497, Lr:0.0001\n",
      "Epoch 25, Step: 804, Loss: 0.05854237079620361, Lr:0.0001\n",
      "Epoch 25, Step: 805, Loss: 0.15519404411315918, Lr:0.0001\n",
      "Epoch 25, Step: 806, Loss: 0.3007453680038452, Lr:0.0001\n",
      "Epoch 25, Step: 807, Loss: 0.037239931523799896, Lr:0.0001\n",
      "Epoch 25, Step: 808, Loss: 0.05328578129410744, Lr:0.0001\n",
      "Epoch 25, Step: 809, Loss: 0.0432443767786026, Lr:0.0001\n",
      "Epoch 25, Step: 810, Loss: 0.08762010931968689, Lr:0.0001\n",
      "Epoch 25, Step: 811, Loss: 0.38309165835380554, Lr:0.0001\n",
      "Epoch 25, Step: 812, Loss: 0.31125593185424805, Lr:0.0001\n",
      "Epoch 25, Step: 813, Loss: 0.035237208008766174, Lr:0.0001\n",
      "Epoch 25, Step: 814, Loss: 0.026727471500635147, Lr:0.0001\n",
      "Epoch 25, Step: 815, Loss: 0.013213951140642166, Lr:0.0001\n",
      "Epoch 25, Step: 816, Loss: 0.07742505520582199, Lr:0.0001\n",
      "Epoch 25, Step: 817, Loss: 0.019820956513285637, Lr:0.0001\n",
      "Epoch 25, Step: 818, Loss: 0.0463009774684906, Lr:0.0001\n",
      "Epoch 25, Step: 819, Loss: 0.12119460850954056, Lr:0.0001\n",
      "Epoch 25, Step: 820, Loss: 0.09278589487075806, Lr:0.0001\n",
      "Epoch 25, Step: 821, Loss: 0.04267256706953049, Lr:0.0001\n",
      "Epoch 25, Step: 822, Loss: 0.04697102680802345, Lr:0.0001\n",
      "Epoch 25, Step: 823, Loss: 0.31428471207618713, Lr:0.0001\n",
      "Epoch 25, Step: 824, Loss: 0.035097114741802216, Lr:0.0001\n",
      "Epoch 25, Step: 825, Loss: 0.043973200023174286, Lr:0.0001\n",
      "Epoch 25, Step: 826, Loss: 0.013747891411185265, Lr:0.0001\n",
      "Epoch 25, Step: 827, Loss: 0.057446278631687164, Lr:0.0001\n",
      "Epoch 25, Step: 828, Loss: 0.0661715641617775, Lr:0.0001\n",
      "Epoch 25, Step: 829, Loss: 0.034628912806510925, Lr:0.0001\n",
      "Epoch 25, Step: 830, Loss: 0.18150830268859863, Lr:0.0001\n",
      "Epoch 25, Step: 831, Loss: 0.025057468563318253, Lr:0.0001\n",
      "Epoch 25, Step: 832, Loss: 0.010232813656330109, Lr:0.0001\n",
      "Epoch 25, Step: 833, Loss: 0.12954841554164886, Lr:0.0001\n",
      "Epoch 25, Step: 834, Loss: 0.0187132079154253, Lr:0.0001\n",
      "Epoch 25, Step: 835, Loss: 0.19390366971492767, Lr:0.0001\n",
      "Epoch 25, Step: 836, Loss: 0.04075314849615097, Lr:0.0001\n",
      "Epoch 25, Step: 837, Loss: 0.016667691990733147, Lr:0.0001\n",
      "Epoch 25, Step: 838, Loss: 0.027997732162475586, Lr:0.0001\n",
      "Epoch 25, Step: 839, Loss: 0.03193136677145958, Lr:0.0001\n",
      "Epoch 25, Step: 840, Loss: 0.008938988670706749, Lr:0.0001\n",
      "Epoch 25, Step: 841, Loss: 0.008262942545115948, Lr:0.0001\n",
      "Epoch 25, Step: 842, Loss: 0.03238612040877342, Lr:0.0001\n",
      "Epoch 25, Step: 843, Loss: 0.13176636397838593, Lr:0.0001\n",
      "Epoch 25, Step: 844, Loss: 0.025027673691511154, Lr:0.0001\n",
      "Epoch 25, Step: 845, Loss: 0.0020804237574338913, Lr:0.0001\n",
      "Epoch 25, Step: 846, Loss: 0.18549038469791412, Lr:0.0001\n",
      "Epoch 25, Step: 847, Loss: 0.05962349474430084, Lr:0.0001\n",
      "Epoch 25, Step: 848, Loss: 0.01084245927631855, Lr:0.0001\n",
      "Epoch 25, Step: 849, Loss: 0.3641716241836548, Lr:0.0001\n",
      "Epoch 25, Step: 850, Loss: 0.07998871058225632, Lr:0.0001\n",
      "Epoch 25, Step: 851, Loss: 0.08921784162521362, Lr:0.0001\n",
      "Epoch 25, Step: 852, Loss: 0.004171709530055523, Lr:0.0001\n",
      "Epoch 25, Step: 853, Loss: 0.11194852739572525, Lr:0.0001\n",
      "Epoch 25, Step: 854, Loss: 0.05960945039987564, Lr:0.0001\n",
      "Epoch 25, Step: 855, Loss: 0.08783745020627975, Lr:0.0001\n",
      "Epoch 25, Step: 856, Loss: 0.07649186998605728, Lr:0.0001\n",
      "Epoch 25, Step: 857, Loss: 0.062020327895879745, Lr:0.0001\n",
      "Epoch 25, Step: 858, Loss: 0.04431461915373802, Lr:0.0001\n",
      "Epoch 25, Step: 859, Loss: 0.01106256153434515, Lr:0.0001\n",
      "Epoch 25, Step: 860, Loss: 0.004891326650977135, Lr:0.0001\n",
      "Epoch 25, Step: 861, Loss: 0.04836481809616089, Lr:0.0001\n",
      "Epoch 25, Step: 862, Loss: 0.014797276817262173, Lr:0.0001\n",
      "Epoch 25, Step: 863, Loss: 0.08952398598194122, Lr:0.0001\n",
      "Epoch 25, Step: 864, Loss: 0.0016650852048769593, Lr:0.0001\n",
      "Epoch 25, Step: 865, Loss: 0.14088274538516998, Lr:0.0001\n",
      "Epoch 25, Step: 866, Loss: 0.04738812521100044, Lr:0.0001\n",
      "Epoch 25, Step: 867, Loss: 0.024419650435447693, Lr:0.0001\n",
      "Epoch 25, Step: 868, Loss: 0.001944611663930118, Lr:0.0001\n",
      "Epoch 25, Step: 869, Loss: 0.011255268938839436, Lr:0.0001\n",
      "Epoch 25, Step: 870, Loss: 0.05322760343551636, Lr:0.0001\n",
      "Epoch 25, Step: 871, Loss: 0.15195070207118988, Lr:0.0001\n",
      "Epoch 25, Step: 872, Loss: 0.014346148818731308, Lr:0.0001\n",
      "Epoch 25, Step: 873, Loss: 0.004973582457751036, Lr:0.0001\n",
      "Epoch 25, Step: 874, Loss: 0.008412458933889866, Lr:0.0001\n",
      "Epoch 25, Step: 875, Loss: 0.010234635323286057, Lr:0.0001\n",
      "Epoch 25, Step: 876, Loss: 0.16164104640483856, Lr:0.0001\n",
      "Epoch 25, Step: 877, Loss: 0.037224315106868744, Lr:0.0001\n",
      "Epoch 25, Step: 878, Loss: 0.2008821815252304, Lr:0.0001\n",
      "Epoch 25, Step: 879, Loss: 0.2507826089859009, Lr:0.0001\n",
      "Epoch 25, Step: 880, Loss: 0.022529160603880882, Lr:0.0001\n",
      "Epoch 25, Step: 881, Loss: 0.14530028402805328, Lr:0.0001\n",
      "Epoch 25, Step: 882, Loss: 0.09870631992816925, Lr:0.0001\n",
      "Epoch 25, Step: 883, Loss: 0.08758366107940674, Lr:0.0001\n",
      "Epoch 25, Step: 884, Loss: 0.00518597848713398, Lr:0.0001\n",
      "Epoch 25, Step: 885, Loss: 0.02693292126059532, Lr:0.0001\n",
      "Epoch 25, Step: 886, Loss: 0.01791912503540516, Lr:0.0001\n",
      "Epoch 25, Step: 887, Loss: 0.28531932830810547, Lr:0.0001\n",
      "Epoch 25, Step: 888, Loss: 0.12271729856729507, Lr:0.0001\n",
      "Epoch 25, Step: 889, Loss: 0.1372559368610382, Lr:0.0001\n",
      "Epoch 25, Step: 890, Loss: 0.110625721514225, Lr:0.0001\n",
      "Epoch 25, Step: 891, Loss: 0.11961154639720917, Lr:0.0001\n",
      "Epoch 25, Step: 892, Loss: 0.007376637309789658, Lr:0.0001\n",
      "Epoch 25, Step: 893, Loss: 0.07756339758634567, Lr:0.0001\n",
      "Epoch 25, Step: 894, Loss: 0.020157869905233383, Lr:0.0001\n",
      "Epoch 25, Step: 895, Loss: 0.008934932760894299, Lr:0.0001\n",
      "Epoch 25, Step: 896, Loss: 0.12645255029201508, Lr:0.0001\n",
      "Epoch 25, Step: 897, Loss: 0.09965750575065613, Lr:0.0001\n",
      "Epoch 25, Step: 898, Loss: 0.043712690472602844, Lr:0.0001\n",
      "Epoch 25, Step: 899, Loss: 0.045579683035612106, Lr:0.0001\n",
      "Epoch 25, Step: 900, Loss: 0.025544695556163788, Lr:0.0001\n",
      "Epoch 25, Step: 901, Loss: 0.2907060384750366, Lr:0.0001\n",
      "Epoch 25, Step: 902, Loss: 0.0028260983526706696, Lr:0.0001\n",
      "Epoch 25, Step: 903, Loss: 0.09107360243797302, Lr:0.0001\n",
      "Epoch 25, Step: 904, Loss: 0.01074171718209982, Lr:0.0001\n",
      "Epoch 25, Step: 905, Loss: 0.07361026108264923, Lr:0.0001\n",
      "Epoch 25, Step: 906, Loss: 0.017362629994750023, Lr:0.0001\n",
      "Epoch 25, Step: 907, Loss: 0.010523560456931591, Lr:0.0001\n",
      "Epoch 25, Step: 908, Loss: 0.06294410675764084, Lr:0.0001\n",
      "Epoch 25, Step: 909, Loss: 0.03533533215522766, Lr:0.0001\n",
      "Epoch 25, Step: 910, Loss: 0.08137504011392593, Lr:0.0001\n",
      "Epoch 25, Step: 911, Loss: 0.06907720118761063, Lr:0.0001\n",
      "Epoch 25, Step: 912, Loss: 0.0702889934182167, Lr:0.0001\n",
      "Epoch 25, Step: 913, Loss: 0.1573546826839447, Lr:0.0001\n",
      "Epoch 25, Step: 914, Loss: 0.06708990037441254, Lr:0.0001\n",
      "Epoch 25, Step: 915, Loss: 0.09871970862150192, Lr:0.0001\n",
      "Epoch 25, Step: 916, Loss: 0.014602582901716232, Lr:0.0001\n",
      "Epoch 25, Step: 917, Loss: 0.029661666601896286, Lr:0.0001\n",
      "Epoch 25, Step: 918, Loss: 0.014666108414530754, Lr:0.0001\n",
      "Epoch 25, Step: 919, Loss: 0.006693580653518438, Lr:0.0001\n",
      "Epoch 25, Step: 920, Loss: 0.03466815501451492, Lr:0.0001\n",
      "Epoch 25, Step: 921, Loss: 0.03797929733991623, Lr:0.0001\n",
      "Epoch 25, Step: 922, Loss: 0.2386387288570404, Lr:0.0001\n",
      "Epoch 25, Step: 923, Loss: 0.033578503876924515, Lr:0.0001\n",
      "Epoch 25, Step: 924, Loss: 0.08258993178606033, Lr:0.0001\n",
      "Epoch 25, Step: 925, Loss: 0.052312325686216354, Lr:0.0001\n",
      "Epoch 25, Step: 926, Loss: 0.2326727658510208, Lr:0.0001\n",
      "Epoch 25, Step: 927, Loss: 0.03343426436185837, Lr:0.0001\n",
      "Epoch 25, Step: 928, Loss: 0.08843252807855606, Lr:0.0001\n",
      "Epoch 25, Step: 929, Loss: 0.03209295496344566, Lr:0.0001\n",
      "Epoch 25, Step: 930, Loss: 0.04912117123603821, Lr:0.0001\n",
      "Epoch 25, Step: 931, Loss: 0.016893986612558365, Lr:0.0001\n",
      "Epoch 25, Step: 932, Loss: 0.009129629470407963, Lr:0.0001\n",
      "Epoch 25, Step: 933, Loss: 0.008799571543931961, Lr:0.0001\n",
      "Epoch 25, Step: 934, Loss: 0.006244199350476265, Lr:0.0001\n",
      "Epoch 25, Step: 935, Loss: 0.10780483484268188, Lr:0.0001\n",
      "Epoch 25, Step: 936, Loss: 0.007403620518743992, Lr:0.0001\n",
      "Epoch 25, Step: 937, Loss: 0.05747363716363907, Lr:0.0001\n",
      "Epoch 25, Step: 938, Loss: 0.02177012898027897, Lr:0.0001\n",
      "Epoch 25, Step: 939, Loss: 0.05762337148189545, Lr:0.0001\n",
      "Epoch 25, Step: 940, Loss: 0.019470514729619026, Lr:0.0001\n",
      "Epoch 25, Step: 941, Loss: 0.06765685230493546, Lr:0.0001\n",
      "Epoch 25, Step: 942, Loss: 0.1912248581647873, Lr:0.0001\n",
      "Epoch 25, Step: 943, Loss: 0.0382697768509388, Lr:0.0001\n",
      "Epoch 25, Step: 944, Loss: 0.005047368351370096, Lr:0.0001\n",
      "Epoch 25, Step: 945, Loss: 0.29867446422576904, Lr:0.0001\n",
      "Epoch 25, Step: 946, Loss: 0.09308454394340515, Lr:0.0001\n",
      "Epoch 25, Step: 947, Loss: 0.20652198791503906, Lr:0.0001\n",
      "Epoch 25, Step: 948, Loss: 0.03585520014166832, Lr:0.0001\n",
      "Epoch 25, Step: 949, Loss: 0.09333673119544983, Lr:0.0001\n",
      "Epoch 25, Step: 950, Loss: 0.012384921312332153, Lr:0.0001\n",
      "Epoch 25, Step: 951, Loss: 0.025585345923900604, Lr:0.0001\n",
      "Epoch 25, Step: 952, Loss: 0.011368640698492527, Lr:0.0001\n",
      "Epoch 25, Step: 953, Loss: 0.003417115192860365, Lr:0.0001\n",
      "Epoch 25, Step: 954, Loss: 0.0052576931193470955, Lr:0.0001\n",
      "Epoch 25, Step: 955, Loss: 0.06425683200359344, Lr:0.0001\n",
      "Epoch 25, Step: 956, Loss: 0.08196017891168594, Lr:0.0001\n",
      "Epoch 25, Step: 957, Loss: 0.001208200235851109, Lr:0.0001\n",
      "Epoch 25, Step: 958, Loss: 1.2056596279144287, Lr:0.0001\n",
      "Epoch 25, Step: 959, Loss: 0.014487359672784805, Lr:0.0001\n",
      "Epoch 25, Step: 960, Loss: 0.015341397374868393, Lr:0.0001\n",
      "Epoch 25, Step: 961, Loss: 0.00556139973923564, Lr:0.0001\n",
      "Epoch 25, Step: 962, Loss: 0.016611309722065926, Lr:0.0001\n",
      "Epoch 25, Step: 963, Loss: 0.016424883157014847, Lr:0.0001\n",
      "Epoch 25, Step: 964, Loss: 0.004794153850525618, Lr:0.0001\n",
      "Epoch 25, Step: 965, Loss: 0.06926992535591125, Lr:0.0001\n",
      "Epoch 25, Step: 966, Loss: 0.042015086859464645, Lr:0.0001\n",
      "Epoch 25, Step: 967, Loss: 0.06896549463272095, Lr:0.0001\n",
      "Epoch 25, Step: 968, Loss: 0.01209994126111269, Lr:0.0001\n",
      "Epoch 25, Step: 969, Loss: 0.007981711067259312, Lr:0.0001\n",
      "Epoch 25, Step: 970, Loss: 0.1027047336101532, Lr:0.0001\n",
      "Epoch 25, Step: 971, Loss: 0.42323821783065796, Lr:0.0001\n",
      "Epoch 25, Step: 972, Loss: 0.007393619976937771, Lr:0.0001\n",
      "Epoch 25, Step: 973, Loss: 0.7755923867225647, Lr:0.0001\n",
      "Epoch 25, Step: 974, Loss: 0.06803519278764725, Lr:0.0001\n",
      "Epoch 25, Step: 975, Loss: 0.1243111789226532, Lr:0.0001\n",
      "Epoch 25, Step: 976, Loss: 0.11548350751399994, Lr:0.0001\n",
      "Epoch 25, Step: 977, Loss: 0.014260259456932545, Lr:0.0001\n",
      "Epoch 25, Step: 978, Loss: 0.0229103434830904, Lr:0.0001\n",
      "Epoch 25, Step: 979, Loss: 0.013298533856868744, Lr:0.0001\n",
      "Epoch 25, Step: 980, Loss: 0.022048069164156914, Lr:0.0001\n",
      "Epoch 25, Step: 981, Loss: 0.02418758161365986, Lr:0.0001\n",
      "Epoch 25, Step: 982, Loss: 0.1544678509235382, Lr:0.0001\n",
      "Epoch 25, Step: 983, Loss: 0.010119874961674213, Lr:0.0001\n",
      "Epoch 25, Step: 984, Loss: 0.031899016350507736, Lr:0.0001\n",
      "Epoch 25, Step: 985, Loss: 0.24985311925411224, Lr:0.0001\n",
      "Epoch 25, Step: 986, Loss: 0.01868690922856331, Lr:0.0001\n",
      "Epoch 25, Step: 987, Loss: 0.0570831261575222, Lr:0.0001\n",
      "Epoch 25, Step: 988, Loss: 0.026544667780399323, Lr:0.0001\n",
      "Epoch 25, Step: 989, Loss: 0.0068565839901566505, Lr:0.0001\n",
      "Epoch 25, Step: 990, Loss: 0.008486361242830753, Lr:0.0001\n",
      "Epoch 25, Step: 991, Loss: 0.06835193932056427, Lr:0.0001\n",
      "Epoch 25, Step: 992, Loss: 0.0533054955303669, Lr:0.0001\n",
      "Epoch 25, Step: 993, Loss: 0.0034779002889990807, Lr:0.0001\n",
      "Epoch 25, Step: 994, Loss: 0.032984063029289246, Lr:0.0001\n",
      "Epoch 25, Step: 995, Loss: 0.1446778029203415, Lr:0.0001\n",
      "Epoch 25, Step: 996, Loss: 0.019382918253540993, Lr:0.0001\n",
      "Epoch 25, Step: 997, Loss: 0.06005682423710823, Lr:0.0001\n",
      "Epoch 25, Step: 998, Loss: 0.6597298979759216, Lr:0.0001\n",
      "Epoch 25, Step: 999, Loss: 0.0005821353406645358, Lr:0.0001\n",
      "Epoch 25, Step: 1000, Loss: 0.004292996600270271, Lr:0.0001\n",
      "Epoch 25, Step: 1001, Loss: 0.10158541053533554, Lr:0.0001\n",
      "Epoch 25, Step: 1002, Loss: 0.015451496466994286, Lr:0.0001\n",
      "Epoch 25, Step: 1003, Loss: 0.06836391985416412, Lr:0.0001\n",
      "Epoch 25, Step: 1004, Loss: 0.008360636420547962, Lr:0.0001\n",
      "Epoch 25, Step: 1005, Loss: 0.0371522381901741, Lr:0.0001\n",
      "Epoch 25, Step: 1006, Loss: 0.00421731173992157, Lr:0.0001\n",
      "Epoch 25, Step: 1007, Loss: 0.004737202078104019, Lr:0.0001\n",
      "Epoch 25, Step: 1008, Loss: 0.003909907769411802, Lr:0.0001\n",
      "Epoch 25, Step: 1009, Loss: 0.015474287793040276, Lr:0.0001\n",
      "Epoch 25, Step: 1010, Loss: 0.028784500434994698, Lr:0.0001\n",
      "Epoch 25, Step: 1011, Loss: 0.07566917687654495, Lr:0.0001\n",
      "Epoch 25, Step: 1012, Loss: 0.017194487154483795, Lr:0.0001\n",
      "Epoch 25, Step: 1013, Loss: 0.07181830704212189, Lr:0.0001\n",
      "Epoch 25, Step: 1014, Loss: 0.002233195584267378, Lr:0.0001\n",
      "Epoch 25, Step: 1015, Loss: 0.2139187902212143, Lr:0.0001\n",
      "Epoch 25, Step: 1016, Loss: 0.04631548002362251, Lr:0.0001\n",
      "Epoch 25, Step: 1017, Loss: 0.09584170579910278, Lr:0.0001\n",
      "Epoch 25, Step: 1018, Loss: 0.04704872518777847, Lr:0.0001\n",
      "Epoch 25, Step: 1019, Loss: 0.04608321189880371, Lr:0.0001\n",
      "Epoch 25, Step: 1020, Loss: 0.18514366447925568, Lr:0.0001\n",
      "Epoch 25, Step: 1021, Loss: 0.011427566409111023, Lr:0.0001\n",
      "Epoch 25, Step: 1022, Loss: 0.04092523455619812, Lr:0.0001\n",
      "Epoch 25, Step: 1023, Loss: 0.004758275113999844, Lr:0.0001\n",
      "Epoch 25, Step: 1024, Loss: 0.01761529967188835, Lr:0.0001\n",
      "Epoch 25, Step: 1025, Loss: 0.24634714424610138, Lr:0.0001\n",
      "Epoch 25, Step: 1026, Loss: 0.009622312150895596, Lr:0.0001\n",
      "Epoch 25, Step: 1027, Loss: 0.00987277366220951, Lr:0.0001\n",
      "Epoch 25, Step: 1028, Loss: 0.014258172363042831, Lr:0.0001\n",
      "Epoch 25, Step: 1029, Loss: 0.0109312254935503, Lr:0.0001\n",
      "Epoch 25, Step: 1030, Loss: 0.026009460911154747, Lr:0.0001\n",
      "Epoch 25, Step: 1031, Loss: 0.010354733094573021, Lr:0.0001\n",
      "Epoch 25, Step: 1032, Loss: 0.047355055809020996, Lr:0.0001\n",
      "Epoch 25, Step: 1033, Loss: 0.02435101941227913, Lr:0.0001\n",
      "Epoch 25, Step: 1034, Loss: 0.053430214524269104, Lr:0.0001\n",
      "Epoch 25, Step: 1035, Loss: 0.09466370195150375, Lr:0.0001\n",
      "Epoch 25, Step: 1036, Loss: 0.008600397035479546, Lr:0.0001\n",
      "Epoch 25, Step: 1037, Loss: 0.1731659471988678, Lr:0.0001\n",
      "Epoch 25, Step: 1038, Loss: 0.0019599157385528088, Lr:0.0001\n",
      "Epoch 25, Step: 1039, Loss: 0.005166496615856886, Lr:0.0001\n",
      "Epoch 25, Step: 1040, Loss: 0.008174227550625801, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 25\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:15 loss: 0.0360 (0.0360) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.2850 data: 0.1170 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.0013 (0.0187) acc1: 100.0000 (99.4318) acc5: 100.0000 (100.0000) time: 0.2908 data: 0.1144 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0012 (0.0520) acc1: 100.0000 (98.5119) acc5: 100.0000 (100.0000) time: 0.2962 data: 0.1158 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.1399 (0.2242) acc1: 93.7500 (93.1452) acc5: 100.0000 (100.0000) time: 0.3114 data: 0.1194 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.2497 (0.2234) acc1: 93.7500 (93.4451) acc5: 100.0000 (100.0000) time: 0.3148 data: 0.1225 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.2039 (0.2602) acc1: 93.7500 (92.5245) acc5: 100.0000 (100.0000) time: 0.3071 data: 0.1236 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.1615 (0.2731) acc1: 93.7500 (92.2815) acc5: 100.0000 (100.0000) time: 0.2907 data: 0.1174 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.2994 s / it)\n",
      "* Acc@1 92.281 Acc@5 100.000 loss 0.273\n",
      "Accuracy of the network on the 881 test image: 92.3%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 26, Step: 0, Loss: 0.06413452327251434, Lr:0.0001\n",
      "Epoch 26, Step: 1, Loss: 0.012862319126725197, Lr:0.0001\n",
      "Epoch 26, Step: 2, Loss: 0.022159932181239128, Lr:0.0001\n",
      "Epoch 26, Step: 3, Loss: 0.028429612517356873, Lr:0.0001\n",
      "Epoch 26, Step: 4, Loss: 0.06593544036149979, Lr:0.0001\n",
      "Epoch 26, Step: 5, Loss: 0.02111218310892582, Lr:0.0001\n",
      "Epoch 26, Step: 6, Loss: 0.2196645885705948, Lr:0.0001\n",
      "Epoch 26, Step: 7, Loss: 0.09147052466869354, Lr:0.0001\n",
      "Epoch 26, Step: 8, Loss: 0.06652417778968811, Lr:0.0001\n",
      "Epoch 26, Step: 9, Loss: 0.05117261782288551, Lr:0.0001\n",
      "Epoch 26, Step: 10, Loss: 0.08200202137231827, Lr:0.0001\n",
      "Epoch 26, Step: 11, Loss: 0.049489449709653854, Lr:0.0001\n",
      "Epoch 26, Step: 12, Loss: 0.006087617017328739, Lr:0.0001\n",
      "Epoch 26, Step: 13, Loss: 0.008948699571192265, Lr:0.0001\n",
      "Epoch 26, Step: 14, Loss: 0.002841202076524496, Lr:0.0001\n",
      "Epoch 26, Step: 15, Loss: 0.0035651884973049164, Lr:0.0001\n",
      "Epoch 26, Step: 16, Loss: 0.007557970006018877, Lr:0.0001\n",
      "Epoch 26, Step: 17, Loss: 0.10106360912322998, Lr:0.0001\n",
      "Epoch 26, Step: 18, Loss: 0.004429659806191921, Lr:0.0001\n",
      "Epoch 26, Step: 19, Loss: 0.1860477179288864, Lr:0.0001\n",
      "Epoch 26, Step: 20, Loss: 0.0728398784995079, Lr:0.0001\n",
      "Epoch 26, Step: 21, Loss: 0.010166032239794731, Lr:0.0001\n",
      "Epoch 26, Step: 22, Loss: 0.18661203980445862, Lr:0.0001\n",
      "Epoch 26, Step: 23, Loss: 0.023304950445890427, Lr:0.0001\n",
      "Epoch 26, Step: 24, Loss: 0.018936073407530785, Lr:0.0001\n",
      "Epoch 26, Step: 25, Loss: 0.03086497262120247, Lr:0.0001\n",
      "Epoch 26, Step: 26, Loss: 0.0017169980565086007, Lr:0.0001\n",
      "Epoch 26, Step: 27, Loss: 0.08583572506904602, Lr:0.0001\n",
      "Epoch 26, Step: 28, Loss: 0.07887936383485794, Lr:0.0001\n",
      "Epoch 26, Step: 29, Loss: 0.002989551518112421, Lr:0.0001\n",
      "Epoch 26, Step: 30, Loss: 0.013921271078288555, Lr:0.0001\n",
      "Epoch 26, Step: 31, Loss: 0.026653487235307693, Lr:0.0001\n",
      "Epoch 26, Step: 32, Loss: 0.009302661754190922, Lr:0.0001\n",
      "Epoch 26, Step: 33, Loss: 0.36132365465164185, Lr:0.0001\n",
      "Epoch 26, Step: 34, Loss: 0.06503084301948547, Lr:0.0001\n",
      "Epoch 26, Step: 35, Loss: 0.0068041738122701645, Lr:0.0001\n",
      "Epoch 26, Step: 36, Loss: 0.03283844143152237, Lr:0.0001\n",
      "Epoch 26, Step: 37, Loss: 0.01170271821320057, Lr:0.0001\n",
      "Epoch 26, Step: 38, Loss: 0.014823968522250652, Lr:0.0001\n",
      "Epoch 26, Step: 39, Loss: 0.3926587700843811, Lr:0.0001\n",
      "Epoch 26, Step: 40, Loss: 0.012604176066815853, Lr:0.0001\n",
      "Epoch 26, Step: 41, Loss: 0.003338611451908946, Lr:0.0001\n",
      "Epoch 26, Step: 42, Loss: 0.2184627205133438, Lr:0.0001\n",
      "Epoch 26, Step: 43, Loss: 0.09772459417581558, Lr:0.0001\n",
      "Epoch 26, Step: 44, Loss: 0.012183822691440582, Lr:0.0001\n",
      "Epoch 26, Step: 45, Loss: 0.20017610490322113, Lr:0.0001\n",
      "Epoch 26, Step: 46, Loss: 0.049124762415885925, Lr:0.0001\n",
      "Epoch 26, Step: 47, Loss: 0.004489237442612648, Lr:0.0001\n",
      "Epoch 26, Step: 48, Loss: 0.06866693496704102, Lr:0.0001\n",
      "Epoch 26, Step: 49, Loss: 0.002890611533075571, Lr:0.0001\n",
      "Epoch 26, Step: 50, Loss: 0.06512536108493805, Lr:0.0001\n",
      "Epoch 26, Step: 51, Loss: 0.2470887154340744, Lr:0.0001\n",
      "Epoch 26, Step: 52, Loss: 0.009265120141208172, Lr:0.0001\n",
      "Epoch 26, Step: 53, Loss: 0.2129100263118744, Lr:0.0001\n",
      "Epoch 26, Step: 54, Loss: 0.054071590304374695, Lr:0.0001\n",
      "Epoch 26, Step: 55, Loss: 0.03681093826889992, Lr:0.0001\n",
      "Epoch 26, Step: 56, Loss: 0.007695427630096674, Lr:0.0001\n",
      "Epoch 26, Step: 57, Loss: 0.05213426053524017, Lr:0.0001\n",
      "Epoch 26, Step: 58, Loss: 0.008206301368772984, Lr:0.0001\n",
      "Epoch 26, Step: 59, Loss: 0.3423340320587158, Lr:0.0001\n",
      "Epoch 26, Step: 60, Loss: 0.06062862649559975, Lr:0.0001\n",
      "Epoch 26, Step: 61, Loss: 0.1193232610821724, Lr:0.0001\n",
      "Epoch 26, Step: 62, Loss: 0.009741772897541523, Lr:0.0001\n",
      "Epoch 26, Step: 63, Loss: 0.019677476957440376, Lr:0.0001\n",
      "Epoch 26, Step: 64, Loss: 0.33267906308174133, Lr:0.0001\n",
      "Epoch 26, Step: 65, Loss: 0.03304335102438927, Lr:0.0001\n",
      "Epoch 26, Step: 66, Loss: 0.11386274546384811, Lr:0.0001\n",
      "Epoch 26, Step: 67, Loss: 0.003080905182287097, Lr:0.0001\n",
      "Epoch 26, Step: 68, Loss: 0.00877620093524456, Lr:0.0001\n",
      "Epoch 26, Step: 69, Loss: 0.02452816255390644, Lr:0.0001\n",
      "Epoch 26, Step: 70, Loss: 0.3322756588459015, Lr:0.0001\n",
      "Epoch 26, Step: 71, Loss: 0.1052277460694313, Lr:0.0001\n",
      "Epoch 26, Step: 72, Loss: 0.04408412426710129, Lr:0.0001\n",
      "Epoch 26, Step: 73, Loss: 0.1075909435749054, Lr:0.0001\n",
      "Epoch 26, Step: 74, Loss: 0.03257573023438454, Lr:0.0001\n",
      "Epoch 26, Step: 75, Loss: 0.04428333044052124, Lr:0.0001\n",
      "Epoch 26, Step: 76, Loss: 0.2038683444261551, Lr:0.0001\n",
      "Epoch 26, Step: 77, Loss: 0.01819048821926117, Lr:0.0001\n",
      "Epoch 26, Step: 78, Loss: 0.06593477725982666, Lr:0.0001\n",
      "Epoch 26, Step: 79, Loss: 0.021429328247904778, Lr:0.0001\n",
      "Epoch 26, Step: 80, Loss: 0.06623784452676773, Lr:0.0001\n",
      "Epoch 26, Step: 81, Loss: 0.06048297882080078, Lr:0.0001\n",
      "Epoch 26, Step: 82, Loss: 0.06907492130994797, Lr:0.0001\n",
      "Epoch 26, Step: 83, Loss: 0.0037882972974330187, Lr:0.0001\n",
      "Epoch 26, Step: 84, Loss: 0.01755286194384098, Lr:0.0001\n",
      "Epoch 26, Step: 85, Loss: 0.000991633627563715, Lr:0.0001\n",
      "Epoch 26, Step: 86, Loss: 0.09184890240430832, Lr:0.0001\n",
      "Epoch 26, Step: 87, Loss: 0.012776807881891727, Lr:0.0001\n",
      "Epoch 26, Step: 88, Loss: 0.03351015970110893, Lr:0.0001\n",
      "Epoch 26, Step: 89, Loss: 0.1842210739850998, Lr:0.0001\n",
      "Epoch 26, Step: 90, Loss: 0.008123780600726604, Lr:0.0001\n",
      "Epoch 26, Step: 91, Loss: 0.047443687915802, Lr:0.0001\n",
      "Epoch 26, Step: 92, Loss: 0.240439772605896, Lr:0.0001\n",
      "Epoch 26, Step: 93, Loss: 0.03889269009232521, Lr:0.0001\n",
      "Epoch 26, Step: 94, Loss: 0.01589333824813366, Lr:0.0001\n",
      "Epoch 26, Step: 95, Loss: 0.19797861576080322, Lr:0.0001\n",
      "Epoch 26, Step: 96, Loss: 0.0937739834189415, Lr:0.0001\n",
      "Epoch 26, Step: 97, Loss: 0.04300330951809883, Lr:0.0001\n",
      "Epoch 26, Step: 98, Loss: 0.015929000452160835, Lr:0.0001\n",
      "Epoch 26, Step: 99, Loss: 0.016315601766109467, Lr:0.0001\n",
      "Epoch 26, Step: 100, Loss: 0.09249192476272583, Lr:0.0001\n",
      "Epoch 26, Step: 101, Loss: 0.02597886323928833, Lr:0.0001\n",
      "Epoch 26, Step: 102, Loss: 0.20973916351795197, Lr:0.0001\n",
      "Epoch 26, Step: 103, Loss: 0.23399300873279572, Lr:0.0001\n",
      "Epoch 26, Step: 104, Loss: 0.010760361328721046, Lr:0.0001\n",
      "Epoch 26, Step: 105, Loss: 0.04537414386868477, Lr:0.0001\n",
      "Epoch 26, Step: 106, Loss: 0.07369393855333328, Lr:0.0001\n",
      "Epoch 26, Step: 107, Loss: 0.05449635162949562, Lr:0.0001\n",
      "Epoch 26, Step: 108, Loss: 0.07420270889997482, Lr:0.0001\n",
      "Epoch 26, Step: 109, Loss: 0.11956195533275604, Lr:0.0001\n",
      "Epoch 26, Step: 110, Loss: 0.07138371467590332, Lr:0.0001\n",
      "Epoch 26, Step: 111, Loss: 0.009235614910721779, Lr:0.0001\n",
      "Epoch 26, Step: 112, Loss: 0.1959114372730255, Lr:0.0001\n",
      "Epoch 26, Step: 113, Loss: 0.07077720761299133, Lr:0.0001\n",
      "Epoch 26, Step: 114, Loss: 0.07030735909938812, Lr:0.0001\n",
      "Epoch 26, Step: 115, Loss: 0.016856899484992027, Lr:0.0001\n",
      "Epoch 26, Step: 116, Loss: 0.020977990701794624, Lr:0.0001\n",
      "Epoch 26, Step: 117, Loss: 0.23712998628616333, Lr:0.0001\n",
      "Epoch 26, Step: 118, Loss: 0.06844823062419891, Lr:0.0001\n",
      "Epoch 26, Step: 119, Loss: 0.1606893390417099, Lr:0.0001\n",
      "Epoch 26, Step: 120, Loss: 0.02247568964958191, Lr:0.0001\n",
      "Epoch 26, Step: 121, Loss: 0.034292660653591156, Lr:0.0001\n",
      "Epoch 26, Step: 122, Loss: 0.11022474616765976, Lr:0.0001\n",
      "Epoch 26, Step: 123, Loss: 0.08790083229541779, Lr:0.0001\n",
      "Epoch 26, Step: 124, Loss: 0.023734336718916893, Lr:0.0001\n",
      "Epoch 26, Step: 125, Loss: 0.04923639073967934, Lr:0.0001\n",
      "Epoch 26, Step: 126, Loss: 0.015689637511968613, Lr:0.0001\n",
      "Epoch 26, Step: 127, Loss: 0.00887550413608551, Lr:0.0001\n",
      "Epoch 26, Step: 128, Loss: 0.23364146053791046, Lr:0.0001\n",
      "Epoch 26, Step: 129, Loss: 0.04341058060526848, Lr:0.0001\n",
      "Epoch 26, Step: 130, Loss: 0.032412923872470856, Lr:0.0001\n",
      "Epoch 26, Step: 131, Loss: 0.0004905834211967885, Lr:0.0001\n",
      "Epoch 26, Step: 132, Loss: 0.09200024604797363, Lr:0.0001\n",
      "Epoch 26, Step: 133, Loss: 0.31047937273979187, Lr:0.0001\n",
      "Epoch 26, Step: 134, Loss: 0.011126506142318249, Lr:0.0001\n",
      "Epoch 26, Step: 135, Loss: 0.14631927013397217, Lr:0.0001\n",
      "Epoch 26, Step: 136, Loss: 0.0024065831676125526, Lr:0.0001\n",
      "Epoch 26, Step: 137, Loss: 0.0020779231563210487, Lr:0.0001\n",
      "Epoch 26, Step: 138, Loss: 0.033356744796037674, Lr:0.0001\n",
      "Epoch 26, Step: 139, Loss: 0.014522779732942581, Lr:0.0001\n",
      "Epoch 26, Step: 140, Loss: 0.142219677567482, Lr:0.0001\n",
      "Epoch 26, Step: 141, Loss: 0.013767500407993793, Lr:0.0001\n",
      "Epoch 26, Step: 142, Loss: 0.3609399199485779, Lr:0.0001\n",
      "Epoch 26, Step: 143, Loss: 0.03327742964029312, Lr:0.0001\n",
      "Epoch 26, Step: 144, Loss: 0.05187535658478737, Lr:0.0001\n",
      "Epoch 26, Step: 145, Loss: 0.036567870527505875, Lr:0.0001\n",
      "Epoch 26, Step: 146, Loss: 0.02138410694897175, Lr:0.0001\n",
      "Epoch 26, Step: 147, Loss: 0.004199542570859194, Lr:0.0001\n",
      "Epoch 26, Step: 148, Loss: 0.07841584086418152, Lr:0.0001\n",
      "Epoch 26, Step: 149, Loss: 0.031368304044008255, Lr:0.0001\n",
      "Epoch 26, Step: 150, Loss: 0.007640707306563854, Lr:0.0001\n",
      "Epoch 26, Step: 151, Loss: 0.2213502824306488, Lr:0.0001\n",
      "Epoch 26, Step: 152, Loss: 0.0247721616178751, Lr:0.0001\n",
      "Epoch 26, Step: 153, Loss: 0.08008038997650146, Lr:0.0001\n",
      "Epoch 26, Step: 154, Loss: 0.0035254252143204212, Lr:0.0001\n",
      "Epoch 26, Step: 155, Loss: 0.09543436020612717, Lr:0.0001\n",
      "Epoch 26, Step: 156, Loss: 0.07434798777103424, Lr:0.0001\n",
      "Epoch 26, Step: 157, Loss: 0.11305966228246689, Lr:0.0001\n",
      "Epoch 26, Step: 158, Loss: 0.005228123161941767, Lr:0.0001\n",
      "Epoch 26, Step: 159, Loss: 0.0168186966329813, Lr:0.0001\n",
      "Epoch 26, Step: 160, Loss: 0.11419954150915146, Lr:0.0001\n",
      "Epoch 26, Step: 161, Loss: 0.056641459465026855, Lr:0.0001\n",
      "Epoch 26, Step: 162, Loss: 0.04615834727883339, Lr:0.0001\n",
      "Epoch 26, Step: 163, Loss: 0.05430377274751663, Lr:0.0001\n",
      "Epoch 26, Step: 164, Loss: 0.22059638798236847, Lr:0.0001\n",
      "Epoch 26, Step: 165, Loss: 0.017767226323485374, Lr:0.0001\n",
      "Epoch 26, Step: 166, Loss: 0.09965499490499496, Lr:0.0001\n",
      "Epoch 26, Step: 167, Loss: 0.03611951693892479, Lr:0.0001\n",
      "Epoch 26, Step: 168, Loss: 0.018773842602968216, Lr:0.0001\n",
      "Epoch 26, Step: 169, Loss: 0.06925691664218903, Lr:0.0001\n",
      "Epoch 26, Step: 170, Loss: 0.10277889668941498, Lr:0.0001\n",
      "Epoch 26, Step: 171, Loss: 0.06642233580350876, Lr:0.0001\n",
      "Epoch 26, Step: 172, Loss: 0.012730374000966549, Lr:0.0001\n",
      "Epoch 26, Step: 173, Loss: 0.006710808724164963, Lr:0.0001\n",
      "Epoch 26, Step: 174, Loss: 0.20995783805847168, Lr:0.0001\n",
      "Epoch 26, Step: 175, Loss: 0.14958906173706055, Lr:0.0001\n",
      "Epoch 26, Step: 176, Loss: 0.010153403505682945, Lr:0.0001\n",
      "Epoch 26, Step: 177, Loss: 0.016775790601968765, Lr:0.0001\n",
      "Epoch 26, Step: 178, Loss: 0.2010728120803833, Lr:0.0001\n",
      "Epoch 26, Step: 179, Loss: 0.2592628598213196, Lr:0.0001\n",
      "Epoch 26, Step: 180, Loss: 0.046974338591098785, Lr:0.0001\n",
      "Epoch 26, Step: 181, Loss: 0.03860992565751076, Lr:0.0001\n",
      "Epoch 26, Step: 182, Loss: 0.053989626467227936, Lr:0.0001\n",
      "Epoch 26, Step: 183, Loss: 0.011501338332891464, Lr:0.0001\n",
      "Epoch 26, Step: 184, Loss: 0.03520932048559189, Lr:0.0001\n",
      "Epoch 26, Step: 185, Loss: 0.039207037538290024, Lr:0.0001\n",
      "Epoch 26, Step: 186, Loss: 0.36373573541641235, Lr:0.0001\n",
      "Epoch 26, Step: 187, Loss: 0.003943741787225008, Lr:0.0001\n",
      "Epoch 26, Step: 188, Loss: 0.009838861413300037, Lr:0.0001\n",
      "Epoch 26, Step: 189, Loss: 0.14867465198040009, Lr:0.0001\n",
      "Epoch 26, Step: 190, Loss: 0.3597375750541687, Lr:0.0001\n",
      "Epoch 26, Step: 191, Loss: 0.008095718920230865, Lr:0.0001\n",
      "Epoch 26, Step: 192, Loss: 0.02241721749305725, Lr:0.0001\n",
      "Epoch 26, Step: 193, Loss: 0.005142847076058388, Lr:0.0001\n",
      "Epoch 26, Step: 194, Loss: 0.17621538043022156, Lr:0.0001\n",
      "Epoch 26, Step: 195, Loss: 0.05625516176223755, Lr:0.0001\n",
      "Epoch 26, Step: 196, Loss: 0.031053487211465836, Lr:0.0001\n",
      "Epoch 26, Step: 197, Loss: 0.23193217813968658, Lr:0.0001\n",
      "Epoch 26, Step: 198, Loss: 0.013880571350455284, Lr:0.0001\n",
      "Epoch 26, Step: 199, Loss: 0.0031258619856089354, Lr:0.0001\n",
      "Epoch 26, Step: 200, Loss: 0.11082509905099869, Lr:0.0001\n",
      "Epoch 26, Step: 201, Loss: 0.0062326230108737946, Lr:0.0001\n",
      "Epoch 26, Step: 202, Loss: 0.05628056079149246, Lr:0.0001\n",
      "Epoch 26, Step: 203, Loss: 0.03458409011363983, Lr:0.0001\n",
      "Epoch 26, Step: 204, Loss: 0.05437741428613663, Lr:0.0001\n",
      "Epoch 26, Step: 205, Loss: 0.07320380955934525, Lr:0.0001\n",
      "Epoch 26, Step: 206, Loss: 0.0415346622467041, Lr:0.0001\n",
      "Epoch 26, Step: 207, Loss: 0.06457255780696869, Lr:0.0001\n",
      "Epoch 26, Step: 208, Loss: 0.06310439854860306, Lr:0.0001\n",
      "Epoch 26, Step: 209, Loss: 0.0005425270646810532, Lr:0.0001\n",
      "Epoch 26, Step: 210, Loss: 0.09507305175065994, Lr:0.0001\n",
      "Epoch 26, Step: 211, Loss: 0.003537321463227272, Lr:0.0001\n",
      "Epoch 26, Step: 212, Loss: 0.01611553691327572, Lr:0.0001\n",
      "Epoch 26, Step: 213, Loss: 0.0718313604593277, Lr:0.0001\n",
      "Epoch 26, Step: 214, Loss: 0.012195722199976444, Lr:0.0001\n",
      "Epoch 26, Step: 215, Loss: 0.09219703078269958, Lr:0.0001\n",
      "Epoch 26, Step: 216, Loss: 0.06791599094867706, Lr:0.0001\n",
      "Epoch 26, Step: 217, Loss: 0.0818130373954773, Lr:0.0001\n",
      "Epoch 26, Step: 218, Loss: 0.0013126212870702147, Lr:0.0001\n",
      "Epoch 26, Step: 219, Loss: 0.014930939301848412, Lr:0.0001\n",
      "Epoch 26, Step: 220, Loss: 0.1265927255153656, Lr:0.0001\n",
      "Epoch 26, Step: 221, Loss: 0.08158236742019653, Lr:0.0001\n",
      "Epoch 26, Step: 222, Loss: 0.07023078203201294, Lr:0.0001\n",
      "Epoch 26, Step: 223, Loss: 0.060574792325496674, Lr:0.0001\n",
      "Epoch 26, Step: 224, Loss: 0.01724562607705593, Lr:0.0001\n",
      "Epoch 26, Step: 225, Loss: 0.10236012190580368, Lr:0.0001\n",
      "Epoch 26, Step: 226, Loss: 0.0013823779299855232, Lr:0.0001\n",
      "Epoch 26, Step: 227, Loss: 0.07695215195417404, Lr:0.0001\n",
      "Epoch 26, Step: 228, Loss: 0.025031941011548042, Lr:0.0001\n",
      "Epoch 26, Step: 229, Loss: 0.0071060978807508945, Lr:0.0001\n",
      "Epoch 26, Step: 230, Loss: 0.03104252554476261, Lr:0.0001\n",
      "Epoch 26, Step: 231, Loss: 0.06977003067731857, Lr:0.0001\n",
      "Epoch 26, Step: 232, Loss: 0.041505008935928345, Lr:0.0001\n",
      "Epoch 26, Step: 233, Loss: 0.27226102352142334, Lr:0.0001\n",
      "Epoch 26, Step: 234, Loss: 0.028125829994678497, Lr:0.0001\n",
      "Epoch 26, Step: 235, Loss: 0.0028386167250573635, Lr:0.0001\n",
      "Epoch 26, Step: 236, Loss: 0.004646196495741606, Lr:0.0001\n",
      "Epoch 26, Step: 237, Loss: 0.031092258170247078, Lr:0.0001\n",
      "Epoch 26, Step: 238, Loss: 0.004490410443395376, Lr:0.0001\n",
      "Epoch 26, Step: 239, Loss: 0.028788790106773376, Lr:0.0001\n",
      "Epoch 26, Step: 240, Loss: 0.742622971534729, Lr:0.0001\n",
      "Epoch 26, Step: 241, Loss: 0.0006433496018871665, Lr:0.0001\n",
      "Epoch 26, Step: 242, Loss: 0.04765750840306282, Lr:0.0001\n",
      "Epoch 26, Step: 243, Loss: 0.009579703211784363, Lr:0.0001\n",
      "Epoch 26, Step: 244, Loss: 0.0020017470233142376, Lr:0.0001\n",
      "Epoch 26, Step: 245, Loss: 0.013879440724849701, Lr:0.0001\n",
      "Epoch 26, Step: 246, Loss: 0.005588173866271973, Lr:0.0001\n",
      "Epoch 26, Step: 247, Loss: 0.0037935785949230194, Lr:0.0001\n",
      "Epoch 26, Step: 248, Loss: 0.27923843264579773, Lr:0.0001\n",
      "Epoch 26, Step: 249, Loss: 0.010942243039608002, Lr:0.0001\n",
      "Epoch 26, Step: 250, Loss: 0.006723308935761452, Lr:0.0001\n",
      "Epoch 26, Step: 251, Loss: 0.016776878386735916, Lr:0.0001\n",
      "Epoch 26, Step: 252, Loss: 0.20062516629695892, Lr:0.0001\n",
      "Epoch 26, Step: 253, Loss: 0.008977783843874931, Lr:0.0001\n",
      "Epoch 26, Step: 254, Loss: 0.001118284068070352, Lr:0.0001\n",
      "Epoch 26, Step: 255, Loss: 0.008050301112234592, Lr:0.0001\n",
      "Epoch 26, Step: 256, Loss: 0.012847796082496643, Lr:0.0001\n",
      "Epoch 26, Step: 257, Loss: 0.04895472526550293, Lr:0.0001\n",
      "Epoch 26, Step: 258, Loss: 0.0131449606269598, Lr:0.0001\n",
      "Epoch 26, Step: 259, Loss: 0.037897977977991104, Lr:0.0001\n",
      "Epoch 26, Step: 260, Loss: 0.006934550125151873, Lr:0.0001\n",
      "Epoch 26, Step: 261, Loss: 0.036209721118211746, Lr:0.0001\n",
      "Epoch 26, Step: 262, Loss: 0.24053242802619934, Lr:0.0001\n",
      "Epoch 26, Step: 263, Loss: 0.02531725913286209, Lr:0.0001\n",
      "Epoch 26, Step: 264, Loss: 0.011479543522000313, Lr:0.0001\n",
      "Epoch 26, Step: 265, Loss: 0.3662784695625305, Lr:0.0001\n",
      "Epoch 26, Step: 266, Loss: 0.0003929292142856866, Lr:0.0001\n",
      "Epoch 26, Step: 267, Loss: 0.0018829678883776069, Lr:0.0001\n",
      "Epoch 26, Step: 268, Loss: 0.010262256488204002, Lr:0.0001\n",
      "Epoch 26, Step: 269, Loss: 0.11297953128814697, Lr:0.0001\n",
      "Epoch 26, Step: 270, Loss: 0.016767896711826324, Lr:0.0001\n",
      "Epoch 26, Step: 271, Loss: 0.06847567111253738, Lr:0.0001\n",
      "Epoch 26, Step: 272, Loss: 0.01732313632965088, Lr:0.0001\n",
      "Epoch 26, Step: 273, Loss: 0.05438634380698204, Lr:0.0001\n",
      "Epoch 26, Step: 274, Loss: 0.08140028268098831, Lr:0.0001\n",
      "Epoch 26, Step: 275, Loss: 0.08583662658929825, Lr:0.0001\n",
      "Epoch 26, Step: 276, Loss: 0.020392194390296936, Lr:0.0001\n",
      "Epoch 26, Step: 277, Loss: 0.22752992808818817, Lr:0.0001\n",
      "Epoch 26, Step: 278, Loss: 0.027476968243718147, Lr:0.0001\n",
      "Epoch 26, Step: 279, Loss: 0.004198986571282148, Lr:0.0001\n",
      "Epoch 26, Step: 280, Loss: 0.04439598321914673, Lr:0.0001\n",
      "Epoch 26, Step: 281, Loss: 0.041173312813043594, Lr:0.0001\n",
      "Epoch 26, Step: 282, Loss: 0.1798153966665268, Lr:0.0001\n",
      "Epoch 26, Step: 283, Loss: 0.005765794776380062, Lr:0.0001\n",
      "Epoch 26, Step: 284, Loss: 0.015994813293218613, Lr:0.0001\n",
      "Epoch 26, Step: 285, Loss: 0.26644834876060486, Lr:0.0001\n",
      "Epoch 26, Step: 286, Loss: 0.0025368062779307365, Lr:0.0001\n",
      "Epoch 26, Step: 287, Loss: 0.22579450905323029, Lr:0.0001\n",
      "Epoch 26, Step: 288, Loss: 0.20306813716888428, Lr:0.0001\n",
      "Epoch 26, Step: 289, Loss: 0.0245673805475235, Lr:0.0001\n",
      "Epoch 26, Step: 290, Loss: 0.17817892134189606, Lr:0.0001\n",
      "Epoch 26, Step: 291, Loss: 0.05477966368198395, Lr:0.0001\n",
      "Epoch 26, Step: 292, Loss: 0.08938020467758179, Lr:0.0001\n",
      "Epoch 26, Step: 293, Loss: 0.10632657259702682, Lr:0.0001\n",
      "Epoch 26, Step: 294, Loss: 0.007582622580230236, Lr:0.0001\n",
      "Epoch 26, Step: 295, Loss: 0.015604064799845219, Lr:0.0001\n",
      "Epoch 26, Step: 296, Loss: 0.04034644365310669, Lr:0.0001\n",
      "Epoch 26, Step: 297, Loss: 0.20278123021125793, Lr:0.0001\n",
      "Epoch 26, Step: 298, Loss: 0.012820839881896973, Lr:0.0001\n",
      "Epoch 26, Step: 299, Loss: 0.12114756554365158, Lr:0.0001\n",
      "Epoch 26, Step: 300, Loss: 0.011637270450592041, Lr:0.0001\n",
      "Epoch 26, Step: 301, Loss: 0.06443478912115097, Lr:0.0001\n",
      "Epoch 26, Step: 302, Loss: 0.045729752629995346, Lr:0.0001\n",
      "Epoch 26, Step: 303, Loss: 0.011015066877007484, Lr:0.0001\n",
      "Epoch 26, Step: 304, Loss: 0.03755577653646469, Lr:0.0001\n",
      "Epoch 26, Step: 305, Loss: 0.04243750870227814, Lr:0.0001\n",
      "Epoch 26, Step: 306, Loss: 0.015717793256044388, Lr:0.0001\n",
      "Epoch 26, Step: 307, Loss: 0.08223171532154083, Lr:0.0001\n",
      "Epoch 26, Step: 308, Loss: 0.052653152495622635, Lr:0.0001\n",
      "Epoch 26, Step: 309, Loss: 0.3572479784488678, Lr:0.0001\n",
      "Epoch 26, Step: 310, Loss: 0.05381486564874649, Lr:0.0001\n",
      "Epoch 26, Step: 311, Loss: 0.008118577301502228, Lr:0.0001\n",
      "Epoch 26, Step: 312, Loss: 0.0068558985367417336, Lr:0.0001\n",
      "Epoch 26, Step: 313, Loss: 0.027897503226995468, Lr:0.0001\n",
      "Epoch 26, Step: 314, Loss: 0.08488360792398453, Lr:0.0001\n",
      "Epoch 26, Step: 315, Loss: 0.17692774534225464, Lr:0.0001\n",
      "Epoch 26, Step: 316, Loss: 0.05690114200115204, Lr:0.0001\n",
      "Epoch 26, Step: 317, Loss: 0.0009357515373267233, Lr:0.0001\n",
      "Epoch 26, Step: 318, Loss: 0.06648575514554977, Lr:0.0001\n",
      "Epoch 26, Step: 319, Loss: 0.01243352796882391, Lr:0.0001\n",
      "Epoch 26, Step: 320, Loss: 0.012224327772855759, Lr:0.0001\n",
      "Epoch 26, Step: 321, Loss: 0.019458914175629616, Lr:0.0001\n",
      "Epoch 26, Step: 322, Loss: 0.0021124687045812607, Lr:0.0001\n",
      "Epoch 26, Step: 323, Loss: 0.02520229108631611, Lr:0.0001\n",
      "Epoch 26, Step: 324, Loss: 0.01585157960653305, Lr:0.0001\n",
      "Epoch 26, Step: 325, Loss: 0.09878727793693542, Lr:0.0001\n",
      "Epoch 26, Step: 326, Loss: 0.03720942512154579, Lr:0.0001\n",
      "Epoch 26, Step: 327, Loss: 0.09042011946439743, Lr:0.0001\n",
      "Epoch 26, Step: 328, Loss: 0.03281044960021973, Lr:0.0001\n",
      "Epoch 26, Step: 329, Loss: 0.025357341393828392, Lr:0.0001\n",
      "Epoch 26, Step: 330, Loss: 0.033092595636844635, Lr:0.0001\n",
      "Epoch 26, Step: 331, Loss: 0.043052349239587784, Lr:0.0001\n",
      "Epoch 26, Step: 332, Loss: 0.3811747133731842, Lr:0.0001\n",
      "Epoch 26, Step: 333, Loss: 0.08029977232217789, Lr:0.0001\n",
      "Epoch 26, Step: 334, Loss: 0.05929939076304436, Lr:0.0001\n",
      "Epoch 26, Step: 335, Loss: 0.2594241797924042, Lr:0.0001\n",
      "Epoch 26, Step: 336, Loss: 0.22197067737579346, Lr:0.0001\n",
      "Epoch 26, Step: 337, Loss: 0.11286012828350067, Lr:0.0001\n",
      "Epoch 26, Step: 338, Loss: 0.03206605836749077, Lr:0.0001\n",
      "Epoch 26, Step: 339, Loss: 0.02889849990606308, Lr:0.0001\n",
      "Epoch 26, Step: 340, Loss: 0.16088174283504486, Lr:0.0001\n",
      "Epoch 26, Step: 341, Loss: 0.03737470880150795, Lr:0.0001\n",
      "Epoch 26, Step: 342, Loss: 0.42272430658340454, Lr:0.0001\n",
      "Epoch 26, Step: 343, Loss: 0.1547449231147766, Lr:0.0001\n",
      "Epoch 26, Step: 344, Loss: 0.01784740760922432, Lr:0.0001\n",
      "Epoch 26, Step: 345, Loss: 0.07398577034473419, Lr:0.0001\n",
      "Epoch 26, Step: 346, Loss: 0.01944250613451004, Lr:0.0001\n",
      "Epoch 26, Step: 347, Loss: 0.01931201107800007, Lr:0.0001\n",
      "Epoch 26, Step: 348, Loss: 0.14180096983909607, Lr:0.0001\n",
      "Epoch 26, Step: 349, Loss: 0.054073940962553024, Lr:0.0001\n",
      "Epoch 26, Step: 350, Loss: 0.06191414222121239, Lr:0.0001\n",
      "Epoch 26, Step: 351, Loss: 0.0737033560872078, Lr:0.0001\n",
      "Epoch 26, Step: 352, Loss: 0.021879110485315323, Lr:0.0001\n",
      "Epoch 26, Step: 353, Loss: 0.03962934389710426, Lr:0.0001\n",
      "Epoch 26, Step: 354, Loss: 0.1598295271396637, Lr:0.0001\n",
      "Epoch 26, Step: 355, Loss: 0.2456587255001068, Lr:0.0001\n",
      "Epoch 26, Step: 356, Loss: 0.010110737755894661, Lr:0.0001\n",
      "Epoch 26, Step: 357, Loss: 0.01562667451798916, Lr:0.0001\n",
      "Epoch 26, Step: 358, Loss: 0.0031841814052313566, Lr:0.0001\n",
      "Epoch 26, Step: 359, Loss: 0.006189021281898022, Lr:0.0001\n",
      "Epoch 26, Step: 360, Loss: 0.15801118314266205, Lr:0.0001\n",
      "Epoch 26, Step: 361, Loss: 0.016017276793718338, Lr:0.0001\n",
      "Epoch 26, Step: 362, Loss: 0.019770421087741852, Lr:0.0001\n",
      "Epoch 26, Step: 363, Loss: 0.020176315680146217, Lr:0.0001\n",
      "Epoch 26, Step: 364, Loss: 0.009386657737195492, Lr:0.0001\n",
      "Epoch 26, Step: 365, Loss: 0.010934261605143547, Lr:0.0001\n",
      "Epoch 26, Step: 366, Loss: 0.0804009959101677, Lr:0.0001\n",
      "Epoch 26, Step: 367, Loss: 0.046669360250234604, Lr:0.0001\n",
      "Epoch 26, Step: 368, Loss: 0.021068371832370758, Lr:0.0001\n",
      "Epoch 26, Step: 369, Loss: 0.01880040019750595, Lr:0.0001\n",
      "Epoch 26, Step: 370, Loss: 0.4251338839530945, Lr:0.0001\n",
      "Epoch 26, Step: 371, Loss: 0.08505580574274063, Lr:0.0001\n",
      "Epoch 26, Step: 372, Loss: 0.06859041005373001, Lr:0.0001\n",
      "Epoch 26, Step: 373, Loss: 0.06360630691051483, Lr:0.0001\n",
      "Epoch 26, Step: 374, Loss: 0.00545930489897728, Lr:0.0001\n",
      "Epoch 26, Step: 375, Loss: 0.014397522434592247, Lr:0.0001\n",
      "Epoch 26, Step: 376, Loss: 0.0124509921297431, Lr:0.0001\n",
      "Epoch 26, Step: 377, Loss: 0.0020599900744855404, Lr:0.0001\n",
      "Epoch 26, Step: 378, Loss: 0.010252445936203003, Lr:0.0001\n",
      "Epoch 26, Step: 379, Loss: 0.008852907456457615, Lr:0.0001\n",
      "Epoch 26, Step: 380, Loss: 0.02522585168480873, Lr:0.0001\n",
      "Epoch 26, Step: 381, Loss: 0.04003109782934189, Lr:0.0001\n",
      "Epoch 26, Step: 382, Loss: 0.016049541532993317, Lr:0.0001\n",
      "Epoch 26, Step: 383, Loss: 0.14266639947891235, Lr:0.0001\n",
      "Epoch 26, Step: 384, Loss: 0.06746838986873627, Lr:0.0001\n",
      "Epoch 26, Step: 385, Loss: 0.038120441138744354, Lr:0.0001\n",
      "Epoch 26, Step: 386, Loss: 0.055341847240924835, Lr:0.0001\n",
      "Epoch 26, Step: 387, Loss: 0.2583376169204712, Lr:0.0001\n",
      "Epoch 26, Step: 388, Loss: 0.047729525715112686, Lr:0.0001\n",
      "Epoch 26, Step: 389, Loss: 0.11283830553293228, Lr:0.0001\n",
      "Epoch 26, Step: 390, Loss: 0.030344516038894653, Lr:0.0001\n",
      "Epoch 26, Step: 391, Loss: 0.11733509600162506, Lr:0.0001\n",
      "Epoch 26, Step: 392, Loss: 0.08692557364702225, Lr:0.0001\n",
      "Epoch 26, Step: 393, Loss: 0.1658744364976883, Lr:0.0001\n",
      "Epoch 26, Step: 394, Loss: 0.06529650837182999, Lr:0.0001\n",
      "Epoch 26, Step: 395, Loss: 0.06717759370803833, Lr:0.0001\n",
      "Epoch 26, Step: 396, Loss: 0.014160986989736557, Lr:0.0001\n",
      "Epoch 26, Step: 397, Loss: 0.03473237529397011, Lr:0.0001\n",
      "Epoch 26, Step: 398, Loss: 0.02166302315890789, Lr:0.0001\n",
      "Epoch 26, Step: 399, Loss: 0.007258031517267227, Lr:0.0001\n",
      "Epoch 26, Step: 400, Loss: 0.32731160521507263, Lr:0.0001\n",
      "Epoch 26, Step: 401, Loss: 0.04812213033437729, Lr:0.0001\n",
      "Epoch 26, Step: 402, Loss: 0.019061556085944176, Lr:0.0001\n",
      "Epoch 26, Step: 403, Loss: 0.01265627145767212, Lr:0.0001\n",
      "Epoch 26, Step: 404, Loss: 0.17710140347480774, Lr:0.0001\n",
      "Epoch 26, Step: 405, Loss: 0.04851032793521881, Lr:0.0001\n",
      "Epoch 26, Step: 406, Loss: 0.003827366279438138, Lr:0.0001\n",
      "Epoch 26, Step: 407, Loss: 0.028003470972180367, Lr:0.0001\n",
      "Epoch 26, Step: 408, Loss: 0.01338888518512249, Lr:0.0001\n",
      "Epoch 26, Step: 409, Loss: 0.04462744668126106, Lr:0.0001\n",
      "Epoch 26, Step: 410, Loss: 0.005948321893811226, Lr:0.0001\n",
      "Epoch 26, Step: 411, Loss: 0.024238429963588715, Lr:0.0001\n",
      "Epoch 26, Step: 412, Loss: 0.060120243579149246, Lr:0.0001\n",
      "Epoch 26, Step: 413, Loss: 0.0062400600872933865, Lr:0.0001\n",
      "Epoch 26, Step: 414, Loss: 0.06698761880397797, Lr:0.0001\n",
      "Epoch 26, Step: 415, Loss: 0.12765592336654663, Lr:0.0001\n",
      "Epoch 26, Step: 416, Loss: 0.0027567758224904537, Lr:0.0001\n",
      "Epoch 26, Step: 417, Loss: 0.00419512577354908, Lr:0.0001\n",
      "Epoch 26, Step: 418, Loss: 0.07194385677576065, Lr:0.0001\n",
      "Epoch 26, Step: 419, Loss: 0.024042977020144463, Lr:0.0001\n",
      "Epoch 26, Step: 420, Loss: 0.021653566509485245, Lr:0.0001\n",
      "Epoch 26, Step: 421, Loss: 0.008390044793486595, Lr:0.0001\n",
      "Epoch 26, Step: 422, Loss: 0.052290093153715134, Lr:0.0001\n",
      "Epoch 26, Step: 423, Loss: 0.00024834854411892593, Lr:0.0001\n",
      "Epoch 26, Step: 424, Loss: 0.09089723229408264, Lr:0.0001\n",
      "Epoch 26, Step: 425, Loss: 0.03997457027435303, Lr:0.0001\n",
      "Epoch 26, Step: 426, Loss: 0.22274178266525269, Lr:0.0001\n",
      "Epoch 26, Step: 427, Loss: 0.10283194482326508, Lr:0.0001\n",
      "Epoch 26, Step: 428, Loss: 0.016039831563830376, Lr:0.0001\n",
      "Epoch 26, Step: 429, Loss: 0.002055597957223654, Lr:0.0001\n",
      "Epoch 26, Step: 430, Loss: 0.0031271493062376976, Lr:0.0001\n",
      "Epoch 26, Step: 431, Loss: 0.005758807994425297, Lr:0.0001\n",
      "Epoch 26, Step: 432, Loss: 0.0021583654452115297, Lr:0.0001\n",
      "Epoch 26, Step: 433, Loss: 0.017049681395292282, Lr:0.0001\n",
      "Epoch 26, Step: 434, Loss: 0.024103686213493347, Lr:0.0001\n",
      "Epoch 26, Step: 435, Loss: 0.005370496306568384, Lr:0.0001\n",
      "Epoch 26, Step: 436, Loss: 0.0061077093705534935, Lr:0.0001\n",
      "Epoch 26, Step: 437, Loss: 0.008357631042599678, Lr:0.0001\n",
      "Epoch 26, Step: 438, Loss: 0.14614054560661316, Lr:0.0001\n",
      "Epoch 26, Step: 439, Loss: 0.01625080034136772, Lr:0.0001\n",
      "Epoch 26, Step: 440, Loss: 0.0034895397257059813, Lr:0.0001\n",
      "Epoch 26, Step: 441, Loss: 0.0030261657666414976, Lr:0.0001\n",
      "Epoch 26, Step: 442, Loss: 0.0011684841010719538, Lr:0.0001\n",
      "Epoch 26, Step: 443, Loss: 0.11327854543924332, Lr:0.0001\n",
      "Epoch 26, Step: 444, Loss: 0.03250527381896973, Lr:0.0001\n",
      "Epoch 26, Step: 445, Loss: 0.24976971745491028, Lr:0.0001\n",
      "Epoch 26, Step: 446, Loss: 0.036936499178409576, Lr:0.0001\n",
      "Epoch 26, Step: 447, Loss: 0.0092909662052989, Lr:0.0001\n",
      "Epoch 26, Step: 448, Loss: 0.018196268007159233, Lr:0.0001\n",
      "Epoch 26, Step: 449, Loss: 0.031013669446110725, Lr:0.0001\n",
      "Epoch 26, Step: 450, Loss: 0.008821687661111355, Lr:0.0001\n",
      "Epoch 26, Step: 451, Loss: 0.017982242628932, Lr:0.0001\n",
      "Epoch 26, Step: 452, Loss: 0.10055218636989594, Lr:0.0001\n",
      "Epoch 26, Step: 453, Loss: 0.0061686355620622635, Lr:0.0001\n",
      "Epoch 26, Step: 454, Loss: 0.0012681529624387622, Lr:0.0001\n",
      "Epoch 26, Step: 455, Loss: 0.005401973612606525, Lr:0.0001\n",
      "Epoch 26, Step: 456, Loss: 0.016137301921844482, Lr:0.0001\n",
      "Epoch 26, Step: 457, Loss: 0.007255585398525, Lr:0.0001\n",
      "Epoch 26, Step: 458, Loss: 0.05649850517511368, Lr:0.0001\n",
      "Epoch 26, Step: 459, Loss: 0.04296073317527771, Lr:0.0001\n",
      "Epoch 26, Step: 460, Loss: 0.006722392980009317, Lr:0.0001\n",
      "Epoch 26, Step: 461, Loss: 0.028034310787916183, Lr:0.0001\n",
      "Epoch 26, Step: 462, Loss: 0.0065718223340809345, Lr:0.0001\n",
      "Epoch 26, Step: 463, Loss: 0.24306759238243103, Lr:0.0001\n",
      "Epoch 26, Step: 464, Loss: 0.145302876830101, Lr:0.0001\n",
      "Epoch 26, Step: 465, Loss: 0.1417286992073059, Lr:0.0001\n",
      "Epoch 26, Step: 466, Loss: 0.02695520408451557, Lr:0.0001\n",
      "Epoch 26, Step: 467, Loss: 0.02285938709974289, Lr:0.0001\n",
      "Epoch 26, Step: 468, Loss: 0.00862482376396656, Lr:0.0001\n",
      "Epoch 26, Step: 469, Loss: 0.03148167207837105, Lr:0.0001\n",
      "Epoch 26, Step: 470, Loss: 0.02799011953175068, Lr:0.0001\n",
      "Epoch 26, Step: 471, Loss: 0.008216227404773235, Lr:0.0001\n",
      "Epoch 26, Step: 472, Loss: 0.022534215822815895, Lr:0.0001\n",
      "Epoch 26, Step: 473, Loss: 0.07579614967107773, Lr:0.0001\n",
      "Epoch 26, Step: 474, Loss: 0.0062849554233253, Lr:0.0001\n",
      "Epoch 26, Step: 475, Loss: 0.2500877380371094, Lr:0.0001\n",
      "Epoch 26, Step: 476, Loss: 0.040481578558683395, Lr:0.0001\n",
      "Epoch 26, Step: 477, Loss: 0.15742331743240356, Lr:0.0001\n",
      "Epoch 26, Step: 478, Loss: 0.020631669089198112, Lr:0.0001\n",
      "Epoch 26, Step: 479, Loss: 0.05398810654878616, Lr:0.0001\n",
      "Epoch 26, Step: 480, Loss: 0.01388804242014885, Lr:0.0001\n",
      "Epoch 26, Step: 481, Loss: 0.0022660151589661837, Lr:0.0001\n",
      "Epoch 26, Step: 482, Loss: 0.0072316559962928295, Lr:0.0001\n",
      "Epoch 26, Step: 483, Loss: 0.004686963744461536, Lr:0.0001\n",
      "Epoch 26, Step: 484, Loss: 0.006919481325894594, Lr:0.0001\n",
      "Epoch 26, Step: 485, Loss: 0.06887964904308319, Lr:0.0001\n",
      "Epoch 26, Step: 486, Loss: 0.11794759333133698, Lr:0.0001\n",
      "Epoch 26, Step: 487, Loss: 0.05784805864095688, Lr:0.0001\n",
      "Epoch 26, Step: 488, Loss: 0.18267124891281128, Lr:0.0001\n",
      "Epoch 26, Step: 489, Loss: 0.01768852211534977, Lr:0.0001\n",
      "Epoch 26, Step: 490, Loss: 0.056979574263095856, Lr:0.0001\n",
      "Epoch 26, Step: 491, Loss: 0.0581660233438015, Lr:0.0001\n",
      "Epoch 26, Step: 492, Loss: 0.011593411676585674, Lr:0.0001\n",
      "Epoch 26, Step: 493, Loss: 0.011643257923424244, Lr:0.0001\n",
      "Epoch 26, Step: 494, Loss: 0.016168871894478798, Lr:0.0001\n",
      "Epoch 26, Step: 495, Loss: 0.013465779833495617, Lr:0.0001\n",
      "Epoch 26, Step: 496, Loss: 0.039365172386169434, Lr:0.0001\n",
      "Epoch 26, Step: 497, Loss: 0.002525264397263527, Lr:0.0001\n",
      "Epoch 26, Step: 498, Loss: 0.034419916570186615, Lr:0.0001\n",
      "Epoch 26, Step: 499, Loss: 0.021955180913209915, Lr:0.0001\n",
      "Epoch 26, Step: 500, Loss: 0.0015187168028205633, Lr:0.0001\n",
      "Epoch 26, Step: 501, Loss: 0.01890162192285061, Lr:0.0001\n",
      "Epoch 26, Step: 502, Loss: 0.014637378975749016, Lr:0.0001\n",
      "Epoch 26, Step: 503, Loss: 0.017838042229413986, Lr:0.0001\n",
      "Epoch 26, Step: 504, Loss: 0.0038398089818656445, Lr:0.0001\n",
      "Epoch 26, Step: 505, Loss: 0.026460226625204086, Lr:0.0001\n",
      "Epoch 26, Step: 506, Loss: 0.013575653545558453, Lr:0.0001\n",
      "Epoch 26, Step: 507, Loss: 0.005262445658445358, Lr:0.0001\n",
      "Epoch 26, Step: 508, Loss: 0.030074704438447952, Lr:0.0001\n",
      "Epoch 26, Step: 509, Loss: 0.02006503753364086, Lr:0.0001\n",
      "Epoch 26, Step: 510, Loss: 0.0801171213388443, Lr:0.0001\n",
      "Epoch 26, Step: 511, Loss: 0.031688135117292404, Lr:0.0001\n",
      "Epoch 26, Step: 512, Loss: 0.036620113998651505, Lr:0.0001\n",
      "Epoch 26, Step: 513, Loss: 0.009771421551704407, Lr:0.0001\n",
      "Epoch 26, Step: 514, Loss: 0.001421226654201746, Lr:0.0001\n",
      "Epoch 26, Step: 515, Loss: 0.046877190470695496, Lr:0.0001\n",
      "Epoch 26, Step: 516, Loss: 0.01271651778370142, Lr:0.0001\n",
      "Epoch 26, Step: 517, Loss: 0.015091887675225735, Lr:0.0001\n",
      "Epoch 26, Step: 518, Loss: 0.05178830400109291, Lr:0.0001\n",
      "Epoch 26, Step: 519, Loss: 0.2671494483947754, Lr:0.0001\n",
      "Epoch 26, Step: 520, Loss: 0.5462380051612854, Lr:0.0001\n",
      "Epoch 26, Step: 521, Loss: 0.03848489373922348, Lr:0.0001\n",
      "Epoch 26, Step: 522, Loss: 0.0042348019778728485, Lr:0.0001\n",
      "Epoch 26, Step: 523, Loss: 0.09786438941955566, Lr:0.0001\n",
      "Epoch 26, Step: 524, Loss: 0.008000672794878483, Lr:0.0001\n",
      "Epoch 26, Step: 525, Loss: 0.017342982813715935, Lr:0.0001\n",
      "Epoch 26, Step: 526, Loss: 0.03266200050711632, Lr:0.0001\n",
      "Epoch 26, Step: 527, Loss: 0.05403207242488861, Lr:0.0001\n",
      "Epoch 26, Step: 528, Loss: 0.03497680649161339, Lr:0.0001\n",
      "Epoch 26, Step: 529, Loss: 0.45661014318466187, Lr:0.0001\n",
      "Epoch 26, Step: 530, Loss: 0.08538500219583511, Lr:0.0001\n",
      "Epoch 26, Step: 531, Loss: 0.10542943328619003, Lr:0.0001\n",
      "Epoch 26, Step: 532, Loss: 0.0494086779654026, Lr:0.0001\n",
      "Epoch 26, Step: 533, Loss: 0.0033583776094019413, Lr:0.0001\n",
      "Epoch 26, Step: 534, Loss: 0.0631340891122818, Lr:0.0001\n",
      "Epoch 26, Step: 535, Loss: 0.03257647901773453, Lr:0.0001\n",
      "Epoch 26, Step: 536, Loss: 0.13729166984558105, Lr:0.0001\n",
      "Epoch 26, Step: 537, Loss: 0.007703326176851988, Lr:0.0001\n",
      "Epoch 26, Step: 538, Loss: 0.013646199367940426, Lr:0.0001\n",
      "Epoch 26, Step: 539, Loss: 0.008252738043665886, Lr:0.0001\n",
      "Epoch 26, Step: 540, Loss: 0.009801426902413368, Lr:0.0001\n",
      "Epoch 26, Step: 541, Loss: 0.12719464302062988, Lr:0.0001\n",
      "Epoch 26, Step: 542, Loss: 0.019488170742988586, Lr:0.0001\n",
      "Epoch 26, Step: 543, Loss: 0.03491894528269768, Lr:0.0001\n",
      "Epoch 26, Step: 544, Loss: 0.003812083974480629, Lr:0.0001\n",
      "Epoch 26, Step: 545, Loss: 0.06283526122570038, Lr:0.0001\n",
      "Epoch 26, Step: 546, Loss: 0.004034119658172131, Lr:0.0001\n",
      "Epoch 26, Step: 547, Loss: 0.03149349242448807, Lr:0.0001\n",
      "Epoch 26, Step: 548, Loss: 0.00595248444005847, Lr:0.0001\n",
      "Epoch 26, Step: 549, Loss: 0.042404282838106155, Lr:0.0001\n",
      "Epoch 26, Step: 550, Loss: 0.08599922060966492, Lr:0.0001\n",
      "Epoch 26, Step: 551, Loss: 0.005041625816375017, Lr:0.0001\n",
      "Epoch 26, Step: 552, Loss: 0.11563669890165329, Lr:0.0001\n",
      "Epoch 26, Step: 553, Loss: 0.24756568670272827, Lr:0.0001\n",
      "Epoch 26, Step: 554, Loss: 0.013863550499081612, Lr:0.0001\n",
      "Epoch 26, Step: 555, Loss: 0.012468334287405014, Lr:0.0001\n",
      "Epoch 26, Step: 556, Loss: 0.30306077003479004, Lr:0.0001\n",
      "Epoch 26, Step: 557, Loss: 0.06054111570119858, Lr:0.0001\n",
      "Epoch 26, Step: 558, Loss: 0.03991754353046417, Lr:0.0001\n",
      "Epoch 26, Step: 559, Loss: 0.00661577470600605, Lr:0.0001\n",
      "Epoch 26, Step: 560, Loss: 0.025832267478108406, Lr:0.0001\n",
      "Epoch 26, Step: 561, Loss: 0.007565488573163748, Lr:0.0001\n",
      "Epoch 26, Step: 562, Loss: 0.03480103239417076, Lr:0.0001\n",
      "Epoch 26, Step: 563, Loss: 0.017049480229616165, Lr:0.0001\n",
      "Epoch 26, Step: 564, Loss: 0.3273340165615082, Lr:0.0001\n",
      "Epoch 26, Step: 565, Loss: 0.03439481928944588, Lr:0.0001\n",
      "Epoch 26, Step: 566, Loss: 0.0006614464800804853, Lr:0.0001\n",
      "Epoch 26, Step: 567, Loss: 0.03801214322447777, Lr:0.0001\n",
      "Epoch 26, Step: 568, Loss: 0.01931283064186573, Lr:0.0001\n",
      "Epoch 26, Step: 569, Loss: 0.024314969778060913, Lr:0.0001\n",
      "Epoch 26, Step: 570, Loss: 0.01780587062239647, Lr:0.0001\n",
      "Epoch 26, Step: 571, Loss: 0.007490821182727814, Lr:0.0001\n",
      "Epoch 26, Step: 572, Loss: 0.02782418765127659, Lr:0.0001\n",
      "Epoch 26, Step: 573, Loss: 0.594539999961853, Lr:0.0001\n",
      "Epoch 26, Step: 574, Loss: 0.0020325351506471634, Lr:0.0001\n",
      "Epoch 26, Step: 575, Loss: 0.18735292553901672, Lr:0.0001\n",
      "Epoch 26, Step: 576, Loss: 0.07304824143648148, Lr:0.0001\n",
      "Epoch 26, Step: 577, Loss: 0.036930203437805176, Lr:0.0001\n",
      "Epoch 26, Step: 578, Loss: 0.041743673384189606, Lr:0.0001\n",
      "Epoch 26, Step: 579, Loss: 0.010820379480719566, Lr:0.0001\n",
      "Epoch 26, Step: 580, Loss: 0.000989934429526329, Lr:0.0001\n",
      "Epoch 26, Step: 581, Loss: 0.09521264582872391, Lr:0.0001\n",
      "Epoch 26, Step: 582, Loss: 0.03040613979101181, Lr:0.0001\n",
      "Epoch 26, Step: 583, Loss: 0.007213631644845009, Lr:0.0001\n",
      "Epoch 26, Step: 584, Loss: 0.008825057186186314, Lr:0.0001\n",
      "Epoch 26, Step: 585, Loss: 0.15471424162387848, Lr:0.0001\n",
      "Epoch 26, Step: 586, Loss: 0.015404202975332737, Lr:0.0001\n",
      "Epoch 26, Step: 587, Loss: 0.4715382754802704, Lr:0.0001\n",
      "Epoch 26, Step: 588, Loss: 0.06162584573030472, Lr:0.0001\n",
      "Epoch 26, Step: 589, Loss: 0.2473292052745819, Lr:0.0001\n",
      "Epoch 26, Step: 590, Loss: 0.04129204899072647, Lr:0.0001\n",
      "Epoch 26, Step: 591, Loss: 0.0010676828678697348, Lr:0.0001\n",
      "Epoch 26, Step: 592, Loss: 0.12590087950229645, Lr:0.0001\n",
      "Epoch 26, Step: 593, Loss: 0.16222867369651794, Lr:0.0001\n",
      "Epoch 26, Step: 594, Loss: 0.029114730656147003, Lr:0.0001\n",
      "Epoch 26, Step: 595, Loss: 0.11426884680986404, Lr:0.0001\n",
      "Epoch 26, Step: 596, Loss: 0.03954898566007614, Lr:0.0001\n",
      "Epoch 26, Step: 597, Loss: 0.02023758925497532, Lr:0.0001\n",
      "Epoch 26, Step: 598, Loss: 0.007518265396356583, Lr:0.0001\n",
      "Epoch 26, Step: 599, Loss: 0.06136467680335045, Lr:0.0001\n",
      "Epoch 26, Step: 600, Loss: 0.0037229314912110567, Lr:0.0001\n",
      "Epoch 26, Step: 601, Loss: 0.02372625842690468, Lr:0.0001\n",
      "Epoch 26, Step: 602, Loss: 0.024620790034532547, Lr:0.0001\n",
      "Epoch 26, Step: 603, Loss: 0.006163449492305517, Lr:0.0001\n",
      "Epoch 26, Step: 604, Loss: 0.10138777643442154, Lr:0.0001\n",
      "Epoch 26, Step: 605, Loss: 0.39052754640579224, Lr:0.0001\n",
      "Epoch 26, Step: 606, Loss: 0.12042376399040222, Lr:0.0001\n",
      "Epoch 26, Step: 607, Loss: 0.05666986480355263, Lr:0.0001\n",
      "Epoch 26, Step: 608, Loss: 0.001376652391627431, Lr:0.0001\n",
      "Epoch 26, Step: 609, Loss: 0.01750493422150612, Lr:0.0001\n",
      "Epoch 26, Step: 610, Loss: 0.1797846257686615, Lr:0.0001\n",
      "Epoch 26, Step: 611, Loss: 0.03919583559036255, Lr:0.0001\n",
      "Epoch 26, Step: 612, Loss: 0.2066548764705658, Lr:0.0001\n",
      "Epoch 26, Step: 613, Loss: 0.026485053822398186, Lr:0.0001\n",
      "Epoch 26, Step: 614, Loss: 0.0033233321737498045, Lr:0.0001\n",
      "Epoch 26, Step: 615, Loss: 0.10583466291427612, Lr:0.0001\n",
      "Epoch 26, Step: 616, Loss: 0.43790990114212036, Lr:0.0001\n",
      "Epoch 26, Step: 617, Loss: 0.10315307974815369, Lr:0.0001\n",
      "Epoch 26, Step: 618, Loss: 0.02252941206097603, Lr:0.0001\n",
      "Epoch 26, Step: 619, Loss: 0.12346536666154861, Lr:0.0001\n",
      "Epoch 26, Step: 620, Loss: 0.033177684992551804, Lr:0.0001\n",
      "Epoch 26, Step: 621, Loss: 0.09509645402431488, Lr:0.0001\n",
      "Epoch 26, Step: 622, Loss: 0.01491648517549038, Lr:0.0001\n",
      "Epoch 26, Step: 623, Loss: 0.03991865739226341, Lr:0.0001\n",
      "Epoch 26, Step: 624, Loss: 0.09925397485494614, Lr:0.0001\n",
      "Epoch 26, Step: 625, Loss: 0.014610623940825462, Lr:0.0001\n",
      "Epoch 26, Step: 626, Loss: 0.33483070135116577, Lr:0.0001\n",
      "Epoch 26, Step: 627, Loss: 0.021558478474617004, Lr:0.0001\n",
      "Epoch 26, Step: 628, Loss: 0.03953943029046059, Lr:0.0001\n",
      "Epoch 26, Step: 629, Loss: 0.0063821421936154366, Lr:0.0001\n",
      "Epoch 26, Step: 630, Loss: 0.039891134947538376, Lr:0.0001\n",
      "Epoch 26, Step: 631, Loss: 0.04819021746516228, Lr:0.0001\n",
      "Epoch 26, Step: 632, Loss: 0.007020719815045595, Lr:0.0001\n",
      "Epoch 26, Step: 633, Loss: 0.10961485654115677, Lr:0.0001\n",
      "Epoch 26, Step: 634, Loss: 0.06815191358327866, Lr:0.0001\n",
      "Epoch 26, Step: 635, Loss: 0.099738210439682, Lr:0.0001\n",
      "Epoch 26, Step: 636, Loss: 0.03952794149518013, Lr:0.0001\n",
      "Epoch 26, Step: 637, Loss: 0.09375301003456116, Lr:0.0001\n",
      "Epoch 26, Step: 638, Loss: 0.07337263226509094, Lr:0.0001\n",
      "Epoch 26, Step: 639, Loss: 0.03676624968647957, Lr:0.0001\n",
      "Epoch 26, Step: 640, Loss: 0.12458794564008713, Lr:0.0001\n",
      "Epoch 26, Step: 641, Loss: 0.052801307290792465, Lr:0.0001\n",
      "Epoch 26, Step: 642, Loss: 0.09506837278604507, Lr:0.0001\n",
      "Epoch 26, Step: 643, Loss: 0.04972517490386963, Lr:0.0001\n",
      "Epoch 26, Step: 644, Loss: 0.11998054385185242, Lr:0.0001\n",
      "Epoch 26, Step: 645, Loss: 0.13461953401565552, Lr:0.0001\n",
      "Epoch 26, Step: 646, Loss: 0.019240379333496094, Lr:0.0001\n",
      "Epoch 26, Step: 647, Loss: 0.00722805829718709, Lr:0.0001\n",
      "Epoch 26, Step: 648, Loss: 0.18674445152282715, Lr:0.0001\n",
      "Epoch 26, Step: 649, Loss: 0.021921465173363686, Lr:0.0001\n",
      "Epoch 26, Step: 650, Loss: 0.0006994153372943401, Lr:0.0001\n",
      "Epoch 26, Step: 651, Loss: 0.01646255888044834, Lr:0.0001\n",
      "Epoch 26, Step: 652, Loss: 0.015118742361664772, Lr:0.0001\n",
      "Epoch 26, Step: 653, Loss: 0.006484596990048885, Lr:0.0001\n",
      "Epoch 26, Step: 654, Loss: 0.0005553329829126596, Lr:0.0001\n",
      "Epoch 26, Step: 655, Loss: 0.05835200846195221, Lr:0.0001\n",
      "Epoch 26, Step: 656, Loss: 0.0540001206099987, Lr:0.0001\n",
      "Epoch 26, Step: 657, Loss: 0.006101692095398903, Lr:0.0001\n",
      "Epoch 26, Step: 658, Loss: 0.032035715878009796, Lr:0.0001\n",
      "Epoch 26, Step: 659, Loss: 0.011304250918328762, Lr:0.0001\n",
      "Epoch 26, Step: 660, Loss: 0.04031936079263687, Lr:0.0001\n",
      "Epoch 26, Step: 661, Loss: 0.02365810051560402, Lr:0.0001\n",
      "Epoch 26, Step: 662, Loss: 0.09392700344324112, Lr:0.0001\n",
      "Epoch 26, Step: 663, Loss: 0.2136147916316986, Lr:0.0001\n",
      "Epoch 26, Step: 664, Loss: 0.006990819238126278, Lr:0.0001\n",
      "Epoch 26, Step: 665, Loss: 0.11839841306209564, Lr:0.0001\n",
      "Epoch 26, Step: 666, Loss: 0.09348485618829727, Lr:0.0001\n",
      "Epoch 26, Step: 667, Loss: 0.03310268744826317, Lr:0.0001\n",
      "Epoch 26, Step: 668, Loss: 0.020782411098480225, Lr:0.0001\n",
      "Epoch 26, Step: 669, Loss: 0.08904749900102615, Lr:0.0001\n",
      "Epoch 26, Step: 670, Loss: 0.00041505316039547324, Lr:0.0001\n",
      "Epoch 26, Step: 671, Loss: 0.07594668120145798, Lr:0.0001\n",
      "Epoch 26, Step: 672, Loss: 0.011890373192727566, Lr:0.0001\n",
      "Epoch 26, Step: 673, Loss: 0.07411250472068787, Lr:0.0001\n",
      "Epoch 26, Step: 674, Loss: 0.02198825776576996, Lr:0.0001\n",
      "Epoch 26, Step: 675, Loss: 0.003267283085733652, Lr:0.0001\n",
      "Epoch 26, Step: 676, Loss: 0.0019870935939252377, Lr:0.0001\n",
      "Epoch 26, Step: 677, Loss: 0.04459017515182495, Lr:0.0001\n",
      "Epoch 26, Step: 678, Loss: 0.027370205149054527, Lr:0.0001\n",
      "Epoch 26, Step: 679, Loss: 0.043306753039360046, Lr:0.0001\n",
      "Epoch 26, Step: 680, Loss: 0.1813991218805313, Lr:0.0001\n",
      "Epoch 26, Step: 681, Loss: 0.02648179605603218, Lr:0.0001\n",
      "Epoch 26, Step: 682, Loss: 0.06672997772693634, Lr:0.0001\n",
      "Epoch 26, Step: 683, Loss: 0.07184255123138428, Lr:0.0001\n",
      "Epoch 26, Step: 684, Loss: 0.0009795407531782985, Lr:0.0001\n",
      "Epoch 26, Step: 685, Loss: 0.22779273986816406, Lr:0.0001\n",
      "Epoch 26, Step: 686, Loss: 0.00913627166301012, Lr:0.0001\n",
      "Epoch 26, Step: 687, Loss: 0.005343022756278515, Lr:0.0001\n",
      "Epoch 26, Step: 688, Loss: 0.0015679672360420227, Lr:0.0001\n",
      "Epoch 26, Step: 689, Loss: 0.0023613348603248596, Lr:0.0001\n",
      "Epoch 26, Step: 690, Loss: 0.004106609616428614, Lr:0.0001\n",
      "Epoch 26, Step: 691, Loss: 0.007632245775312185, Lr:0.0001\n",
      "Epoch 26, Step: 692, Loss: 0.01352914609014988, Lr:0.0001\n",
      "Epoch 26, Step: 693, Loss: 0.09249674528837204, Lr:0.0001\n",
      "Epoch 26, Step: 694, Loss: 0.009085133671760559, Lr:0.0001\n",
      "Epoch 26, Step: 695, Loss: 0.0017065254505723715, Lr:0.0001\n",
      "Epoch 26, Step: 696, Loss: 0.06271294504404068, Lr:0.0001\n",
      "Epoch 26, Step: 697, Loss: 0.08724119514226913, Lr:0.0001\n",
      "Epoch 26, Step: 698, Loss: 0.00172163057141006, Lr:0.0001\n",
      "Epoch 26, Step: 699, Loss: 0.009395203553140163, Lr:0.0001\n",
      "Epoch 26, Step: 700, Loss: 0.05911249294877052, Lr:0.0001\n",
      "Epoch 26, Step: 701, Loss: 0.13883984088897705, Lr:0.0001\n",
      "Epoch 26, Step: 702, Loss: 0.04291929304599762, Lr:0.0001\n",
      "Epoch 26, Step: 703, Loss: 0.007162640802562237, Lr:0.0001\n",
      "Epoch 26, Step: 704, Loss: 0.037910014390945435, Lr:0.0001\n",
      "Epoch 26, Step: 705, Loss: 0.010087013244628906, Lr:0.0001\n",
      "Epoch 26, Step: 706, Loss: 0.13510704040527344, Lr:0.0001\n",
      "Epoch 26, Step: 707, Loss: 0.20107927918434143, Lr:0.0001\n",
      "Epoch 26, Step: 708, Loss: 0.008169388398528099, Lr:0.0001\n",
      "Epoch 26, Step: 709, Loss: 0.016783585771918297, Lr:0.0001\n",
      "Epoch 26, Step: 710, Loss: 0.0011538995895534754, Lr:0.0001\n",
      "Epoch 26, Step: 711, Loss: 0.009085296653211117, Lr:0.0001\n",
      "Epoch 26, Step: 712, Loss: 0.026045167818665504, Lr:0.0001\n",
      "Epoch 26, Step: 713, Loss: 0.23009784519672394, Lr:0.0001\n",
      "Epoch 26, Step: 714, Loss: 0.14096617698669434, Lr:0.0001\n",
      "Epoch 26, Step: 715, Loss: 0.230741947889328, Lr:0.0001\n",
      "Epoch 26, Step: 716, Loss: 0.0783737301826477, Lr:0.0001\n",
      "Epoch 26, Step: 717, Loss: 0.01053757406771183, Lr:0.0001\n",
      "Epoch 26, Step: 718, Loss: 0.005486579146236181, Lr:0.0001\n",
      "Epoch 26, Step: 719, Loss: 0.022552497684955597, Lr:0.0001\n",
      "Epoch 26, Step: 720, Loss: 0.014183521270751953, Lr:0.0001\n",
      "Epoch 26, Step: 721, Loss: 0.008235892280936241, Lr:0.0001\n",
      "Epoch 26, Step: 722, Loss: 0.27203235030174255, Lr:0.0001\n",
      "Epoch 26, Step: 723, Loss: 0.06263241916894913, Lr:0.0001\n",
      "Epoch 26, Step: 724, Loss: 0.0018285108963027596, Lr:0.0001\n",
      "Epoch 26, Step: 725, Loss: 0.007402690127491951, Lr:0.0001\n",
      "Epoch 26, Step: 726, Loss: 0.03551802039146423, Lr:0.0001\n",
      "Epoch 26, Step: 727, Loss: 0.11436090618371964, Lr:0.0001\n",
      "Epoch 26, Step: 728, Loss: 0.011630082502961159, Lr:0.0001\n",
      "Epoch 26, Step: 729, Loss: 0.13981673121452332, Lr:0.0001\n",
      "Epoch 26, Step: 730, Loss: 0.007767498027533293, Lr:0.0001\n",
      "Epoch 26, Step: 731, Loss: 0.02663695439696312, Lr:0.0001\n",
      "Epoch 26, Step: 732, Loss: 0.009140941314399242, Lr:0.0001\n",
      "Epoch 26, Step: 733, Loss: 0.03844548016786575, Lr:0.0001\n",
      "Epoch 26, Step: 734, Loss: 0.004419599659740925, Lr:0.0001\n",
      "Epoch 26, Step: 735, Loss: 0.18524038791656494, Lr:0.0001\n",
      "Epoch 26, Step: 736, Loss: 0.01247413456439972, Lr:0.0001\n",
      "Epoch 26, Step: 737, Loss: 0.0028767993208020926, Lr:0.0001\n",
      "Epoch 26, Step: 738, Loss: 0.13774888217449188, Lr:0.0001\n",
      "Epoch 26, Step: 739, Loss: 0.21473102271556854, Lr:0.0001\n",
      "Epoch 26, Step: 740, Loss: 0.05875945836305618, Lr:0.0001\n",
      "Epoch 26, Step: 741, Loss: 0.07718606293201447, Lr:0.0001\n",
      "Epoch 26, Step: 742, Loss: 0.0994533896446228, Lr:0.0001\n",
      "Epoch 26, Step: 743, Loss: 0.00022440095199272037, Lr:0.0001\n",
      "Epoch 26, Step: 744, Loss: 0.001791607472114265, Lr:0.0001\n",
      "Epoch 26, Step: 745, Loss: 0.06518092006444931, Lr:0.0001\n",
      "Epoch 26, Step: 746, Loss: 0.15671801567077637, Lr:0.0001\n",
      "Epoch 26, Step: 747, Loss: 0.12356502562761307, Lr:0.0001\n",
      "Epoch 26, Step: 748, Loss: 0.0914410948753357, Lr:0.0001\n",
      "Epoch 26, Step: 749, Loss: 0.018574636429548264, Lr:0.0001\n",
      "Epoch 26, Step: 750, Loss: 0.03747202083468437, Lr:0.0001\n",
      "Epoch 26, Step: 751, Loss: 0.008606208488345146, Lr:0.0001\n",
      "Epoch 26, Step: 752, Loss: 0.04023722559213638, Lr:0.0001\n",
      "Epoch 26, Step: 753, Loss: 0.1969117671251297, Lr:0.0001\n",
      "Epoch 26, Step: 754, Loss: 0.1608845293521881, Lr:0.0001\n",
      "Epoch 26, Step: 755, Loss: 0.02844434417784214, Lr:0.0001\n",
      "Epoch 26, Step: 756, Loss: 0.017113998532295227, Lr:0.0001\n",
      "Epoch 26, Step: 757, Loss: 0.0500052385032177, Lr:0.0001\n",
      "Epoch 26, Step: 758, Loss: 0.029761888086795807, Lr:0.0001\n",
      "Epoch 26, Step: 759, Loss: 0.35580408573150635, Lr:0.0001\n",
      "Epoch 26, Step: 760, Loss: 0.0016946651739999652, Lr:0.0001\n",
      "Epoch 26, Step: 761, Loss: 0.01987692341208458, Lr:0.0001\n",
      "Epoch 26, Step: 762, Loss: 0.02115941420197487, Lr:0.0001\n",
      "Epoch 26, Step: 763, Loss: 0.10195519775152206, Lr:0.0001\n",
      "Epoch 26, Step: 764, Loss: 0.02715413086116314, Lr:0.0001\n",
      "Epoch 26, Step: 765, Loss: 0.032754454761743546, Lr:0.0001\n",
      "Epoch 26, Step: 766, Loss: 0.02315966784954071, Lr:0.0001\n",
      "Epoch 26, Step: 767, Loss: 0.0019165294943377376, Lr:0.0001\n",
      "Epoch 26, Step: 768, Loss: 0.07065971940755844, Lr:0.0001\n",
      "Epoch 26, Step: 769, Loss: 0.036920588463544846, Lr:0.0001\n",
      "Epoch 26, Step: 770, Loss: 0.15881434082984924, Lr:0.0001\n",
      "Epoch 26, Step: 771, Loss: 0.055453669279813766, Lr:0.0001\n",
      "Epoch 26, Step: 772, Loss: 0.00189900491386652, Lr:0.0001\n",
      "Epoch 26, Step: 773, Loss: 0.007918352261185646, Lr:0.0001\n",
      "Epoch 26, Step: 774, Loss: 0.3629205822944641, Lr:0.0001\n",
      "Epoch 26, Step: 775, Loss: 0.06434300541877747, Lr:0.0001\n",
      "Epoch 26, Step: 776, Loss: 0.01763223670423031, Lr:0.0001\n",
      "Epoch 26, Step: 777, Loss: 0.016290267929434776, Lr:0.0001\n",
      "Epoch 26, Step: 778, Loss: 0.0306845810264349, Lr:0.0001\n",
      "Epoch 26, Step: 779, Loss: 0.05051679536700249, Lr:0.0001\n",
      "Epoch 26, Step: 780, Loss: 0.13358275592327118, Lr:0.0001\n",
      "Epoch 26, Step: 781, Loss: 0.08033162355422974, Lr:0.0001\n",
      "Epoch 26, Step: 782, Loss: 0.045240215957164764, Lr:0.0001\n",
      "Epoch 26, Step: 783, Loss: 0.09508077800273895, Lr:0.0001\n",
      "Epoch 26, Step: 784, Loss: 0.36764830350875854, Lr:0.0001\n",
      "Epoch 26, Step: 785, Loss: 0.03159346804022789, Lr:0.0001\n",
      "Epoch 26, Step: 786, Loss: 0.0419156551361084, Lr:0.0001\n",
      "Epoch 26, Step: 787, Loss: 0.35529211163520813, Lr:0.0001\n",
      "Epoch 26, Step: 788, Loss: 0.08627243340015411, Lr:0.0001\n",
      "Epoch 26, Step: 789, Loss: 0.1511610448360443, Lr:0.0001\n",
      "Epoch 26, Step: 790, Loss: 0.10052737593650818, Lr:0.0001\n",
      "Epoch 26, Step: 791, Loss: 0.05565705522894859, Lr:0.0001\n",
      "Epoch 26, Step: 792, Loss: 0.12952229380607605, Lr:0.0001\n",
      "Epoch 26, Step: 793, Loss: 0.033794526010751724, Lr:0.0001\n",
      "Epoch 26, Step: 794, Loss: 0.14784403145313263, Lr:0.0001\n",
      "Epoch 26, Step: 795, Loss: 0.003926160279661417, Lr:0.0001\n",
      "Epoch 26, Step: 796, Loss: 0.003805575892329216, Lr:0.0001\n",
      "Epoch 26, Step: 797, Loss: 0.2582915425300598, Lr:0.0001\n",
      "Epoch 26, Step: 798, Loss: 0.005233848933130503, Lr:0.0001\n",
      "Epoch 26, Step: 799, Loss: 0.000751974293962121, Lr:0.0001\n",
      "Epoch 26, Step: 800, Loss: 0.05227474123239517, Lr:0.0001\n",
      "Epoch 26, Step: 801, Loss: 0.06409596651792526, Lr:0.0001\n",
      "Epoch 26, Step: 802, Loss: 0.05860020965337753, Lr:0.0001\n",
      "Epoch 26, Step: 803, Loss: 0.037863217294216156, Lr:0.0001\n",
      "Epoch 26, Step: 804, Loss: 0.09598812460899353, Lr:0.0001\n",
      "Epoch 26, Step: 805, Loss: 0.045045532286167145, Lr:0.0001\n",
      "Epoch 26, Step: 806, Loss: 0.019617481157183647, Lr:0.0001\n",
      "Epoch 26, Step: 807, Loss: 0.046547066420316696, Lr:0.0001\n",
      "Epoch 26, Step: 808, Loss: 0.04263202100992203, Lr:0.0001\n",
      "Epoch 26, Step: 809, Loss: 0.0060250600799918175, Lr:0.0001\n",
      "Epoch 26, Step: 810, Loss: 0.007634283043444157, Lr:0.0001\n",
      "Epoch 26, Step: 811, Loss: 0.05094962939620018, Lr:0.0001\n",
      "Epoch 26, Step: 812, Loss: 0.032587453722953796, Lr:0.0001\n",
      "Epoch 26, Step: 813, Loss: 0.03978564962744713, Lr:0.0001\n",
      "Epoch 26, Step: 814, Loss: 0.00864690076559782, Lr:0.0001\n",
      "Epoch 26, Step: 815, Loss: 0.05993956699967384, Lr:0.0001\n",
      "Epoch 26, Step: 816, Loss: 0.3300996422767639, Lr:0.0001\n",
      "Epoch 26, Step: 817, Loss: 0.021859126165509224, Lr:0.0001\n",
      "Epoch 26, Step: 818, Loss: 0.022953270003199577, Lr:0.0001\n",
      "Epoch 26, Step: 819, Loss: 0.025505147874355316, Lr:0.0001\n",
      "Epoch 26, Step: 820, Loss: 0.07518305629491806, Lr:0.0001\n",
      "Epoch 26, Step: 821, Loss: 0.018484963104128838, Lr:0.0001\n",
      "Epoch 26, Step: 822, Loss: 0.26289957761764526, Lr:0.0001\n",
      "Epoch 26, Step: 823, Loss: 0.19129981100559235, Lr:0.0001\n",
      "Epoch 26, Step: 824, Loss: 0.10304906219244003, Lr:0.0001\n",
      "Epoch 26, Step: 825, Loss: 0.18032197654247284, Lr:0.0001\n",
      "Epoch 26, Step: 826, Loss: 0.02745707891881466, Lr:0.0001\n",
      "Epoch 26, Step: 827, Loss: 0.01553274691104889, Lr:0.0001\n",
      "Epoch 26, Step: 828, Loss: 0.04359626770019531, Lr:0.0001\n",
      "Epoch 26, Step: 829, Loss: 0.03147818148136139, Lr:0.0001\n",
      "Epoch 26, Step: 830, Loss: 0.026832984760403633, Lr:0.0001\n",
      "Epoch 26, Step: 831, Loss: 0.08896691352128983, Lr:0.0001\n",
      "Epoch 26, Step: 832, Loss: 0.019816292449831963, Lr:0.0001\n",
      "Epoch 26, Step: 833, Loss: 0.04777953028678894, Lr:0.0001\n",
      "Epoch 26, Step: 834, Loss: 0.0015943837352097034, Lr:0.0001\n",
      "Epoch 26, Step: 835, Loss: 0.2580905258655548, Lr:0.0001\n",
      "Epoch 26, Step: 836, Loss: 0.01397018227726221, Lr:0.0001\n",
      "Epoch 26, Step: 837, Loss: 0.00999043881893158, Lr:0.0001\n",
      "Epoch 26, Step: 838, Loss: 0.07702507823705673, Lr:0.0001\n",
      "Epoch 26, Step: 839, Loss: 0.10539939999580383, Lr:0.0001\n",
      "Epoch 26, Step: 840, Loss: 0.04042930155992508, Lr:0.0001\n",
      "Epoch 26, Step: 841, Loss: 0.032836250960826874, Lr:0.0001\n",
      "Epoch 26, Step: 842, Loss: 0.05960586294531822, Lr:0.0001\n",
      "Epoch 26, Step: 843, Loss: 0.058182328939437866, Lr:0.0001\n",
      "Epoch 26, Step: 844, Loss: 0.006821808870881796, Lr:0.0001\n",
      "Epoch 26, Step: 845, Loss: 0.09078556299209595, Lr:0.0001\n",
      "Epoch 26, Step: 846, Loss: 0.015537437982857227, Lr:0.0001\n",
      "Epoch 26, Step: 847, Loss: 0.08656012266874313, Lr:0.0001\n",
      "Epoch 26, Step: 848, Loss: 0.004683787934482098, Lr:0.0001\n",
      "Epoch 26, Step: 849, Loss: 0.0021476787514984608, Lr:0.0001\n",
      "Epoch 26, Step: 850, Loss: 0.015563287772238255, Lr:0.0001\n",
      "Epoch 26, Step: 851, Loss: 0.22823719680309296, Lr:0.0001\n",
      "Epoch 26, Step: 852, Loss: 0.0029861119110137224, Lr:0.0001\n",
      "Epoch 26, Step: 853, Loss: 0.0975622609257698, Lr:0.0001\n",
      "Epoch 26, Step: 854, Loss: 0.012939788401126862, Lr:0.0001\n",
      "Epoch 26, Step: 855, Loss: 0.032840829342603683, Lr:0.0001\n",
      "Epoch 26, Step: 856, Loss: 0.06780891865491867, Lr:0.0001\n",
      "Epoch 26, Step: 857, Loss: 0.01794951781630516, Lr:0.0001\n",
      "Epoch 26, Step: 858, Loss: 0.0018635541200637817, Lr:0.0001\n",
      "Epoch 26, Step: 859, Loss: 0.0035398269537836313, Lr:0.0001\n",
      "Epoch 26, Step: 860, Loss: 0.010049667209386826, Lr:0.0001\n",
      "Epoch 26, Step: 861, Loss: 0.261535108089447, Lr:0.0001\n",
      "Epoch 26, Step: 862, Loss: 0.007934147492051125, Lr:0.0001\n",
      "Epoch 26, Step: 863, Loss: 0.07848311215639114, Lr:0.0001\n",
      "Epoch 26, Step: 864, Loss: 0.09325996786355972, Lr:0.0001\n",
      "Epoch 26, Step: 865, Loss: 0.014473481103777885, Lr:0.0001\n",
      "Epoch 26, Step: 866, Loss: 0.027689654380083084, Lr:0.0001\n",
      "Epoch 26, Step: 867, Loss: 0.03607991337776184, Lr:0.0001\n",
      "Epoch 26, Step: 868, Loss: 0.02871399186551571, Lr:0.0001\n",
      "Epoch 26, Step: 869, Loss: 0.028869101777672768, Lr:0.0001\n",
      "Epoch 26, Step: 870, Loss: 0.31688186526298523, Lr:0.0001\n",
      "Epoch 26, Step: 871, Loss: 0.0026742680929601192, Lr:0.0001\n",
      "Epoch 26, Step: 872, Loss: 0.09620509296655655, Lr:0.0001\n",
      "Epoch 26, Step: 873, Loss: 0.03470595180988312, Lr:0.0001\n",
      "Epoch 26, Step: 874, Loss: 0.0005771633004769683, Lr:0.0001\n",
      "Epoch 26, Step: 875, Loss: 0.008200934156775475, Lr:0.0001\n",
      "Epoch 26, Step: 876, Loss: 0.3804249167442322, Lr:0.0001\n",
      "Epoch 26, Step: 877, Loss: 0.003354117041453719, Lr:0.0001\n",
      "Epoch 26, Step: 878, Loss: 0.01546387281268835, Lr:0.0001\n",
      "Epoch 26, Step: 879, Loss: 0.0006585230003111064, Lr:0.0001\n",
      "Epoch 26, Step: 880, Loss: 0.07687658816576004, Lr:0.0001\n",
      "Epoch 26, Step: 881, Loss: 0.002285404596477747, Lr:0.0001\n",
      "Epoch 26, Step: 882, Loss: 0.02403745986521244, Lr:0.0001\n",
      "Epoch 26, Step: 883, Loss: 0.0029227780178189278, Lr:0.0001\n",
      "Epoch 26, Step: 884, Loss: 0.012596660293638706, Lr:0.0001\n",
      "Epoch 26, Step: 885, Loss: 0.005047546233981848, Lr:0.0001\n",
      "Epoch 26, Step: 886, Loss: 0.055133573710918427, Lr:0.0001\n",
      "Epoch 26, Step: 887, Loss: 0.03973236680030823, Lr:0.0001\n",
      "Epoch 26, Step: 888, Loss: 0.11245772242546082, Lr:0.0001\n",
      "Epoch 26, Step: 889, Loss: 0.3822921812534332, Lr:0.0001\n",
      "Epoch 26, Step: 890, Loss: 0.062227874994277954, Lr:0.0001\n",
      "Epoch 26, Step: 891, Loss: 0.3830719590187073, Lr:0.0001\n",
      "Epoch 26, Step: 892, Loss: 0.031130224466323853, Lr:0.0001\n",
      "Epoch 26, Step: 893, Loss: 0.05114132538437843, Lr:0.0001\n",
      "Epoch 26, Step: 894, Loss: 0.06088177487254143, Lr:0.0001\n",
      "Epoch 26, Step: 895, Loss: 0.023050174117088318, Lr:0.0001\n",
      "Epoch 26, Step: 896, Loss: 0.32855167984962463, Lr:0.0001\n",
      "Epoch 26, Step: 897, Loss: 0.24887444078922272, Lr:0.0001\n",
      "Epoch 26, Step: 898, Loss: 0.39917901158332825, Lr:0.0001\n",
      "Epoch 26, Step: 899, Loss: 0.04469869285821915, Lr:0.0001\n",
      "Epoch 26, Step: 900, Loss: 0.05092388764023781, Lr:0.0001\n",
      "Epoch 26, Step: 901, Loss: 0.02762102149426937, Lr:0.0001\n",
      "Epoch 26, Step: 902, Loss: 0.015043865889310837, Lr:0.0001\n",
      "Epoch 26, Step: 903, Loss: 0.12817776203155518, Lr:0.0001\n",
      "Epoch 26, Step: 904, Loss: 0.012661831453442574, Lr:0.0001\n",
      "Epoch 26, Step: 905, Loss: 0.025157812982797623, Lr:0.0001\n",
      "Epoch 26, Step: 906, Loss: 0.010911615565419197, Lr:0.0001\n",
      "Epoch 26, Step: 907, Loss: 0.04816475510597229, Lr:0.0001\n",
      "Epoch 26, Step: 908, Loss: 0.013693301007151604, Lr:0.0001\n",
      "Epoch 26, Step: 909, Loss: 0.005188613198697567, Lr:0.0001\n",
      "Epoch 26, Step: 910, Loss: 0.18310366570949554, Lr:0.0001\n",
      "Epoch 26, Step: 911, Loss: 0.01192467100918293, Lr:0.0001\n",
      "Epoch 26, Step: 912, Loss: 0.030661556869745255, Lr:0.0001\n",
      "Epoch 26, Step: 913, Loss: 0.06021938845515251, Lr:0.0001\n",
      "Epoch 26, Step: 914, Loss: 0.045975133776664734, Lr:0.0001\n",
      "Epoch 26, Step: 915, Loss: 0.21850833296775818, Lr:0.0001\n",
      "Epoch 26, Step: 916, Loss: 0.23424364626407623, Lr:0.0001\n",
      "Epoch 26, Step: 917, Loss: 0.006771366577595472, Lr:0.0001\n",
      "Epoch 26, Step: 918, Loss: 0.027684655040502548, Lr:0.0001\n",
      "Epoch 26, Step: 919, Loss: 0.10368750989437103, Lr:0.0001\n",
      "Epoch 26, Step: 920, Loss: 0.043133970350027084, Lr:0.0001\n",
      "Epoch 26, Step: 921, Loss: 0.10377687960863113, Lr:0.0001\n",
      "Epoch 26, Step: 922, Loss: 0.011586243286728859, Lr:0.0001\n",
      "Epoch 26, Step: 923, Loss: 0.0262138694524765, Lr:0.0001\n",
      "Epoch 26, Step: 924, Loss: 0.0530509427189827, Lr:0.0001\n",
      "Epoch 26, Step: 925, Loss: 0.03460068255662918, Lr:0.0001\n",
      "Epoch 26, Step: 926, Loss: 0.08187191188335419, Lr:0.0001\n",
      "Epoch 26, Step: 927, Loss: 0.013555643148720264, Lr:0.0001\n",
      "Epoch 26, Step: 928, Loss: 0.0030968226492404938, Lr:0.0001\n",
      "Epoch 26, Step: 929, Loss: 0.010234519839286804, Lr:0.0001\n",
      "Epoch 26, Step: 930, Loss: 0.20768265426158905, Lr:0.0001\n",
      "Epoch 26, Step: 931, Loss: 0.009767776355147362, Lr:0.0001\n",
      "Epoch 26, Step: 932, Loss: 0.10328133404254913, Lr:0.0001\n",
      "Epoch 26, Step: 933, Loss: 0.0870448425412178, Lr:0.0001\n",
      "Epoch 26, Step: 934, Loss: 0.010282891802489758, Lr:0.0001\n",
      "Epoch 26, Step: 935, Loss: 0.003328291466459632, Lr:0.0001\n",
      "Epoch 26, Step: 936, Loss: 0.2789164185523987, Lr:0.0001\n",
      "Epoch 26, Step: 937, Loss: 0.0328657403588295, Lr:0.0001\n",
      "Epoch 26, Step: 938, Loss: 0.08210369199514389, Lr:0.0001\n",
      "Epoch 26, Step: 939, Loss: 0.014016754925251007, Lr:0.0001\n",
      "Epoch 26, Step: 940, Loss: 0.02254243940114975, Lr:0.0001\n",
      "Epoch 26, Step: 941, Loss: 0.002096673008054495, Lr:0.0001\n",
      "Epoch 26, Step: 942, Loss: 0.02047882042825222, Lr:0.0001\n",
      "Epoch 26, Step: 943, Loss: 0.014453805051743984, Lr:0.0001\n",
      "Epoch 26, Step: 944, Loss: 0.0036541838198900223, Lr:0.0001\n",
      "Epoch 26, Step: 945, Loss: 0.05805918574333191, Lr:0.0001\n",
      "Epoch 26, Step: 946, Loss: 0.08876122534275055, Lr:0.0001\n",
      "Epoch 26, Step: 947, Loss: 0.2520102560520172, Lr:0.0001\n",
      "Epoch 26, Step: 948, Loss: 0.045264992862939835, Lr:0.0001\n",
      "Epoch 26, Step: 949, Loss: 0.028965191915631294, Lr:0.0001\n",
      "Epoch 26, Step: 950, Loss: 0.008885106071829796, Lr:0.0001\n",
      "Epoch 26, Step: 951, Loss: 0.16380596160888672, Lr:0.0001\n",
      "Epoch 26, Step: 952, Loss: 0.012227370403707027, Lr:0.0001\n",
      "Epoch 26, Step: 953, Loss: 0.009761017747223377, Lr:0.0001\n",
      "Epoch 26, Step: 954, Loss: 0.02130282297730446, Lr:0.0001\n",
      "Epoch 26, Step: 955, Loss: 0.21960365772247314, Lr:0.0001\n",
      "Epoch 26, Step: 956, Loss: 0.001766783301718533, Lr:0.0001\n",
      "Epoch 26, Step: 957, Loss: 0.027232395485043526, Lr:0.0001\n",
      "Epoch 26, Step: 958, Loss: 0.04651862755417824, Lr:0.0001\n",
      "Epoch 26, Step: 959, Loss: 0.02789386361837387, Lr:0.0001\n",
      "Epoch 26, Step: 960, Loss: 0.0574127733707428, Lr:0.0001\n",
      "Epoch 26, Step: 961, Loss: 0.13812865316867828, Lr:0.0001\n",
      "Epoch 26, Step: 962, Loss: 0.004601847380399704, Lr:0.0001\n",
      "Epoch 26, Step: 963, Loss: 0.00675131194293499, Lr:0.0001\n",
      "Epoch 26, Step: 964, Loss: 0.028590213507413864, Lr:0.0001\n",
      "Epoch 26, Step: 965, Loss: 0.22810736298561096, Lr:0.0001\n",
      "Epoch 26, Step: 966, Loss: 0.0076486654579639435, Lr:0.0001\n",
      "Epoch 26, Step: 967, Loss: 0.1213252991437912, Lr:0.0001\n",
      "Epoch 26, Step: 968, Loss: 0.010587138123810291, Lr:0.0001\n",
      "Epoch 26, Step: 969, Loss: 0.07103754580020905, Lr:0.0001\n",
      "Epoch 26, Step: 970, Loss: 0.008308552205562592, Lr:0.0001\n",
      "Epoch 26, Step: 971, Loss: 0.03632739186286926, Lr:0.0001\n",
      "Epoch 26, Step: 972, Loss: 0.06530550122261047, Lr:0.0001\n",
      "Epoch 26, Step: 973, Loss: 0.01847071759402752, Lr:0.0001\n",
      "Epoch 26, Step: 974, Loss: 0.010014579631388187, Lr:0.0001\n",
      "Epoch 26, Step: 975, Loss: 0.0030524071771651506, Lr:0.0001\n",
      "Epoch 26, Step: 976, Loss: 0.16854293644428253, Lr:0.0001\n",
      "Epoch 26, Step: 977, Loss: 0.008125806227326393, Lr:0.0001\n",
      "Epoch 26, Step: 978, Loss: 0.2574390172958374, Lr:0.0001\n",
      "Epoch 26, Step: 979, Loss: 0.08634592592716217, Lr:0.0001\n",
      "Epoch 26, Step: 980, Loss: 0.08993809670209885, Lr:0.0001\n",
      "Epoch 26, Step: 981, Loss: 0.0014694727724418044, Lr:0.0001\n",
      "Epoch 26, Step: 982, Loss: 0.04509881138801575, Lr:0.0001\n",
      "Epoch 26, Step: 983, Loss: 0.0556219220161438, Lr:0.0001\n",
      "Epoch 26, Step: 984, Loss: 0.007814429700374603, Lr:0.0001\n",
      "Epoch 26, Step: 985, Loss: 0.05037247762084007, Lr:0.0001\n",
      "Epoch 26, Step: 986, Loss: 0.004501168616116047, Lr:0.0001\n",
      "Epoch 26, Step: 987, Loss: 0.060062941163778305, Lr:0.0001\n",
      "Epoch 26, Step: 988, Loss: 0.11153879761695862, Lr:0.0001\n",
      "Epoch 26, Step: 989, Loss: 0.01009497418999672, Lr:0.0001\n",
      "Epoch 26, Step: 990, Loss: 0.08693143725395203, Lr:0.0001\n",
      "Epoch 26, Step: 991, Loss: 0.025867700576782227, Lr:0.0001\n",
      "Epoch 26, Step: 992, Loss: 0.1345929652452469, Lr:0.0001\n",
      "Epoch 26, Step: 993, Loss: 0.10504695773124695, Lr:0.0001\n",
      "Epoch 26, Step: 994, Loss: 0.017068825662136078, Lr:0.0001\n",
      "Epoch 26, Step: 995, Loss: 0.17739391326904297, Lr:0.0001\n",
      "Epoch 26, Step: 996, Loss: 0.0849219486117363, Lr:0.0001\n",
      "Epoch 26, Step: 997, Loss: 0.003688517492264509, Lr:0.0001\n",
      "Epoch 26, Step: 998, Loss: 0.0015294280601665378, Lr:0.0001\n",
      "Epoch 26, Step: 999, Loss: 0.00429331511259079, Lr:0.0001\n",
      "Epoch 26, Step: 1000, Loss: 0.06917953491210938, Lr:0.0001\n",
      "Epoch 26, Step: 1001, Loss: 0.006053246557712555, Lr:0.0001\n",
      "Epoch 26, Step: 1002, Loss: 0.02170761115849018, Lr:0.0001\n",
      "Epoch 26, Step: 1003, Loss: 0.0009597683092579246, Lr:0.0001\n",
      "Epoch 26, Step: 1004, Loss: 0.08487699925899506, Lr:0.0001\n",
      "Epoch 26, Step: 1005, Loss: 0.024979684501886368, Lr:0.0001\n",
      "Epoch 26, Step: 1006, Loss: 0.052081722766160965, Lr:0.0001\n",
      "Epoch 26, Step: 1007, Loss: 0.008614487946033478, Lr:0.0001\n",
      "Epoch 26, Step: 1008, Loss: 0.058975912630558014, Lr:0.0001\n",
      "Epoch 26, Step: 1009, Loss: 0.025759601965546608, Lr:0.0001\n",
      "Epoch 26, Step: 1010, Loss: 0.0011110794730484486, Lr:0.0001\n",
      "Epoch 26, Step: 1011, Loss: 0.0041438136249780655, Lr:0.0001\n",
      "Epoch 26, Step: 1012, Loss: 0.0022160708904266357, Lr:0.0001\n",
      "Epoch 26, Step: 1013, Loss: 0.01187305897474289, Lr:0.0001\n",
      "Epoch 26, Step: 1014, Loss: 0.026119237765669823, Lr:0.0001\n",
      "Epoch 26, Step: 1015, Loss: 0.07893682271242142, Lr:0.0001\n",
      "Epoch 26, Step: 1016, Loss: 0.23826096951961517, Lr:0.0001\n",
      "Epoch 26, Step: 1017, Loss: 0.05906422436237335, Lr:0.0001\n",
      "Epoch 26, Step: 1018, Loss: 0.11552659422159195, Lr:0.0001\n",
      "Epoch 26, Step: 1019, Loss: 0.08931377530097961, Lr:0.0001\n",
      "Epoch 26, Step: 1020, Loss: 0.05548911169171333, Lr:0.0001\n",
      "Epoch 26, Step: 1021, Loss: 0.03945883363485336, Lr:0.0001\n",
      "Epoch 26, Step: 1022, Loss: 0.031558651477098465, Lr:0.0001\n",
      "Epoch 26, Step: 1023, Loss: 0.00535600446164608, Lr:0.0001\n",
      "Epoch 26, Step: 1024, Loss: 0.01637374982237816, Lr:0.0001\n",
      "Epoch 26, Step: 1025, Loss: 0.011641018092632294, Lr:0.0001\n",
      "Epoch 26, Step: 1026, Loss: 0.02767137810587883, Lr:0.0001\n",
      "Epoch 26, Step: 1027, Loss: 0.06684395670890808, Lr:0.0001\n",
      "Epoch 26, Step: 1028, Loss: 0.26084914803504944, Lr:0.0001\n",
      "Epoch 26, Step: 1029, Loss: 0.12415997684001923, Lr:0.0001\n",
      "Epoch 26, Step: 1030, Loss: 0.04595629870891571, Lr:0.0001\n",
      "Epoch 26, Step: 1031, Loss: 0.13925281167030334, Lr:0.0001\n",
      "Epoch 26, Step: 1032, Loss: 0.03327798843383789, Lr:0.0001\n",
      "Epoch 26, Step: 1033, Loss: 0.0024514170363545418, Lr:0.0001\n",
      "Epoch 26, Step: 1034, Loss: 0.10507655143737793, Lr:0.0001\n",
      "Epoch 26, Step: 1035, Loss: 0.01383991539478302, Lr:0.0001\n",
      "Epoch 26, Step: 1036, Loss: 0.015580760315060616, Lr:0.0001\n",
      "Epoch 26, Step: 1037, Loss: 0.0029906462877988815, Lr:0.0001\n",
      "Epoch 26, Step: 1038, Loss: 0.025667725130915642, Lr:0.0001\n",
      "Epoch 26, Step: 1039, Loss: 0.21360839903354645, Lr:0.0001\n",
      "Epoch 26, Step: 1040, Loss: 0.016354037448763847, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 26\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:16 loss: 0.0003 (0.0003) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.2930 data: 0.1140 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.0001 (0.0002) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.2875 data: 0.1137 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0001 (0.1034) acc1: 100.0000 (97.3214) acc5: 100.0000 (100.0000) time: 0.2879 data: 0.1143 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.2012 (0.2401) acc1: 87.5000 (93.3468) acc5: 100.0000 (100.0000) time: 0.2928 data: 0.1181 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.2012 (0.2222) acc1: 93.7500 (94.0549) acc5: 100.0000 (100.0000) time: 0.2993 data: 0.1221 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0088 (0.1991) acc1: 100.0000 (94.3627) acc5: 100.0000 (100.0000) time: 0.3042 data: 0.1235 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0009 (0.1989) acc1: 100.0000 (94.2111) acc5: 100.0000 (100.0000) time: 0.2925 data: 0.1174 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.2926 s / it)\n",
      "* Acc@1 94.211 Acc@5 100.000 loss 0.199\n",
      "Accuracy of the network on the 881 test image: 94.2%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 27, Step: 0, Loss: 0.08316740393638611, Lr:0.0001\n",
      "Epoch 27, Step: 1, Loss: 0.10895366966724396, Lr:0.0001\n",
      "Epoch 27, Step: 2, Loss: 0.03574275225400925, Lr:0.0001\n",
      "Epoch 27, Step: 3, Loss: 0.04177995026111603, Lr:0.0001\n",
      "Epoch 27, Step: 4, Loss: 0.0023097596131265163, Lr:0.0001\n",
      "Epoch 27, Step: 5, Loss: 0.004858830478042364, Lr:0.0001\n",
      "Epoch 27, Step: 6, Loss: 0.004470794461667538, Lr:0.0001\n",
      "Epoch 27, Step: 7, Loss: 0.1224636659026146, Lr:0.0001\n",
      "Epoch 27, Step: 8, Loss: 0.0009146965458057821, Lr:0.0001\n",
      "Epoch 27, Step: 9, Loss: 0.006642815191298723, Lr:0.0001\n",
      "Epoch 27, Step: 10, Loss: 0.02462688274681568, Lr:0.0001\n",
      "Epoch 27, Step: 11, Loss: 0.011917962692677975, Lr:0.0001\n",
      "Epoch 27, Step: 12, Loss: 0.044670864939689636, Lr:0.0001\n",
      "Epoch 27, Step: 13, Loss: 0.014189710840582848, Lr:0.0001\n",
      "Epoch 27, Step: 14, Loss: 0.009169517084956169, Lr:0.0001\n",
      "Epoch 27, Step: 15, Loss: 0.03630748391151428, Lr:0.0001\n",
      "Epoch 27, Step: 16, Loss: 0.007310459390282631, Lr:0.0001\n",
      "Epoch 27, Step: 17, Loss: 0.38811492919921875, Lr:0.0001\n",
      "Epoch 27, Step: 18, Loss: 0.01236672606319189, Lr:0.0001\n",
      "Epoch 27, Step: 19, Loss: 0.0820816233754158, Lr:0.0001\n",
      "Epoch 27, Step: 20, Loss: 0.0674312487244606, Lr:0.0001\n",
      "Epoch 27, Step: 21, Loss: 0.0381668396294117, Lr:0.0001\n",
      "Epoch 27, Step: 22, Loss: 0.0639900416135788, Lr:0.0001\n",
      "Epoch 27, Step: 23, Loss: 0.028361797332763672, Lr:0.0001\n",
      "Epoch 27, Step: 24, Loss: 0.03815581277012825, Lr:0.0001\n",
      "Epoch 27, Step: 25, Loss: 0.0007835659198462963, Lr:0.0001\n",
      "Epoch 27, Step: 26, Loss: 0.13453717529773712, Lr:0.0001\n",
      "Epoch 27, Step: 27, Loss: 0.08494816720485687, Lr:0.0001\n",
      "Epoch 27, Step: 28, Loss: 0.0039895325899124146, Lr:0.0001\n",
      "Epoch 27, Step: 29, Loss: 0.38160911202430725, Lr:0.0001\n",
      "Epoch 27, Step: 30, Loss: 0.09019860625267029, Lr:0.0001\n",
      "Epoch 27, Step: 31, Loss: 0.008107023313641548, Lr:0.0001\n",
      "Epoch 27, Step: 32, Loss: 0.017378339543938637, Lr:0.0001\n",
      "Epoch 27, Step: 33, Loss: 0.0022529775742441416, Lr:0.0001\n",
      "Epoch 27, Step: 34, Loss: 0.19531568884849548, Lr:0.0001\n",
      "Epoch 27, Step: 35, Loss: 0.020897312089800835, Lr:0.0001\n",
      "Epoch 27, Step: 36, Loss: 0.05930987745523453, Lr:0.0001\n",
      "Epoch 27, Step: 37, Loss: 0.009583259001374245, Lr:0.0001\n",
      "Epoch 27, Step: 38, Loss: 0.0020392215810716152, Lr:0.0001\n",
      "Epoch 27, Step: 39, Loss: 0.015421702526509762, Lr:0.0001\n",
      "Epoch 27, Step: 40, Loss: 0.24321691691875458, Lr:0.0001\n",
      "Epoch 27, Step: 41, Loss: 0.01911242865025997, Lr:0.0001\n",
      "Epoch 27, Step: 42, Loss: 0.03191681578755379, Lr:0.0001\n",
      "Epoch 27, Step: 43, Loss: 0.013649160973727703, Lr:0.0001\n",
      "Epoch 27, Step: 44, Loss: 0.05209711939096451, Lr:0.0001\n",
      "Epoch 27, Step: 45, Loss: 0.04251072555780411, Lr:0.0001\n",
      "Epoch 27, Step: 46, Loss: 0.017291966825723648, Lr:0.0001\n",
      "Epoch 27, Step: 47, Loss: 0.12777531147003174, Lr:0.0001\n",
      "Epoch 27, Step: 48, Loss: 0.024237001314759254, Lr:0.0001\n",
      "Epoch 27, Step: 49, Loss: 0.031926531344652176, Lr:0.0001\n",
      "Epoch 27, Step: 50, Loss: 0.11046550422906876, Lr:0.0001\n",
      "Epoch 27, Step: 51, Loss: 0.02420702576637268, Lr:0.0001\n",
      "Epoch 27, Step: 52, Loss: 0.011180885136127472, Lr:0.0001\n",
      "Epoch 27, Step: 53, Loss: 0.00556773180142045, Lr:0.0001\n",
      "Epoch 27, Step: 54, Loss: 0.12923263013362885, Lr:0.0001\n",
      "Epoch 27, Step: 55, Loss: 0.038428641855716705, Lr:0.0001\n",
      "Epoch 27, Step: 56, Loss: 0.008359079249203205, Lr:0.0001\n",
      "Epoch 27, Step: 57, Loss: 0.08318164944648743, Lr:0.0001\n",
      "Epoch 27, Step: 58, Loss: 0.14464648067951202, Lr:0.0001\n",
      "Epoch 27, Step: 59, Loss: 0.020369119942188263, Lr:0.0001\n",
      "Epoch 27, Step: 60, Loss: 0.040889672935009, Lr:0.0001\n",
      "Epoch 27, Step: 61, Loss: 0.0007019736221991479, Lr:0.0001\n",
      "Epoch 27, Step: 62, Loss: 0.03155868127942085, Lr:0.0001\n",
      "Epoch 27, Step: 63, Loss: 0.0679701492190361, Lr:0.0001\n",
      "Epoch 27, Step: 64, Loss: 0.011390378698706627, Lr:0.0001\n",
      "Epoch 27, Step: 65, Loss: 0.14563095569610596, Lr:0.0001\n",
      "Epoch 27, Step: 66, Loss: 0.028879588469862938, Lr:0.0001\n",
      "Epoch 27, Step: 67, Loss: 0.007039443589746952, Lr:0.0001\n",
      "Epoch 27, Step: 68, Loss: 0.025675320997834206, Lr:0.0001\n",
      "Epoch 27, Step: 69, Loss: 0.031517140567302704, Lr:0.0001\n",
      "Epoch 27, Step: 70, Loss: 0.01743742823600769, Lr:0.0001\n",
      "Epoch 27, Step: 71, Loss: 0.016646163538098335, Lr:0.0001\n",
      "Epoch 27, Step: 72, Loss: 0.0067777084186673164, Lr:0.0001\n",
      "Epoch 27, Step: 73, Loss: 0.010471896268427372, Lr:0.0001\n",
      "Epoch 27, Step: 74, Loss: 0.09987544268369675, Lr:0.0001\n",
      "Epoch 27, Step: 75, Loss: 0.06234843656420708, Lr:0.0001\n",
      "Epoch 27, Step: 76, Loss: 0.2841034233570099, Lr:0.0001\n",
      "Epoch 27, Step: 77, Loss: 0.1376466602087021, Lr:0.0001\n",
      "Epoch 27, Step: 78, Loss: 0.014587118290364742, Lr:0.0001\n",
      "Epoch 27, Step: 79, Loss: 0.00702088326215744, Lr:0.0001\n",
      "Epoch 27, Step: 80, Loss: 0.002243678318336606, Lr:0.0001\n",
      "Epoch 27, Step: 81, Loss: 0.03024228848516941, Lr:0.0001\n",
      "Epoch 27, Step: 82, Loss: 0.1246584802865982, Lr:0.0001\n",
      "Epoch 27, Step: 83, Loss: 0.09903819113969803, Lr:0.0001\n",
      "Epoch 27, Step: 84, Loss: 0.0036109189968556166, Lr:0.0001\n",
      "Epoch 27, Step: 85, Loss: 0.012427568435668945, Lr:0.0001\n",
      "Epoch 27, Step: 86, Loss: 0.003623258089646697, Lr:0.0001\n",
      "Epoch 27, Step: 87, Loss: 0.12666292488574982, Lr:0.0001\n",
      "Epoch 27, Step: 88, Loss: 0.00785811711102724, Lr:0.0001\n",
      "Epoch 27, Step: 89, Loss: 0.025995861738920212, Lr:0.0001\n",
      "Epoch 27, Step: 90, Loss: 0.018395300954580307, Lr:0.0001\n",
      "Epoch 27, Step: 91, Loss: 0.15204118192195892, Lr:0.0001\n",
      "Epoch 27, Step: 92, Loss: 0.00043610119610093534, Lr:0.0001\n",
      "Epoch 27, Step: 93, Loss: 0.007322484161704779, Lr:0.0001\n",
      "Epoch 27, Step: 94, Loss: 0.19031895697116852, Lr:0.0001\n",
      "Epoch 27, Step: 95, Loss: 0.018809882923960686, Lr:0.0001\n",
      "Epoch 27, Step: 96, Loss: 0.040003396570682526, Lr:0.0001\n",
      "Epoch 27, Step: 97, Loss: 0.0081724151968956, Lr:0.0001\n",
      "Epoch 27, Step: 98, Loss: 0.18125540018081665, Lr:0.0001\n",
      "Epoch 27, Step: 99, Loss: 0.12112347036600113, Lr:0.0001\n",
      "Epoch 27, Step: 100, Loss: 0.02511759288609028, Lr:0.0001\n",
      "Epoch 27, Step: 101, Loss: 0.027775853872299194, Lr:0.0001\n",
      "Epoch 27, Step: 102, Loss: 0.0017099834512919188, Lr:0.0001\n",
      "Epoch 27, Step: 103, Loss: 0.07275067269802094, Lr:0.0001\n",
      "Epoch 27, Step: 104, Loss: 0.0005057246307842433, Lr:0.0001\n",
      "Epoch 27, Step: 105, Loss: 0.017744053155183792, Lr:0.0001\n",
      "Epoch 27, Step: 106, Loss: 0.025031527504324913, Lr:0.0001\n",
      "Epoch 27, Step: 107, Loss: 0.06335469335317612, Lr:0.0001\n",
      "Epoch 27, Step: 108, Loss: 0.004653210286051035, Lr:0.0001\n",
      "Epoch 27, Step: 109, Loss: 0.2270529419183731, Lr:0.0001\n",
      "Epoch 27, Step: 110, Loss: 0.015823600813746452, Lr:0.0001\n",
      "Epoch 27, Step: 111, Loss: 0.01027756743133068, Lr:0.0001\n",
      "Epoch 27, Step: 112, Loss: 0.05594312772154808, Lr:0.0001\n",
      "Epoch 27, Step: 113, Loss: 0.2072029411792755, Lr:0.0001\n",
      "Epoch 27, Step: 114, Loss: 0.025690926238894463, Lr:0.0001\n",
      "Epoch 27, Step: 115, Loss: 0.08251100778579712, Lr:0.0001\n",
      "Epoch 27, Step: 116, Loss: 0.12496592849493027, Lr:0.0001\n",
      "Epoch 27, Step: 117, Loss: 0.12117359787225723, Lr:0.0001\n",
      "Epoch 27, Step: 118, Loss: 0.12004639208316803, Lr:0.0001\n",
      "Epoch 27, Step: 119, Loss: 0.013432376086711884, Lr:0.0001\n",
      "Epoch 27, Step: 120, Loss: 0.008452648296952248, Lr:0.0001\n",
      "Epoch 27, Step: 121, Loss: 0.2281600534915924, Lr:0.0001\n",
      "Epoch 27, Step: 122, Loss: 0.007062352728098631, Lr:0.0001\n",
      "Epoch 27, Step: 123, Loss: 0.22832633554935455, Lr:0.0001\n",
      "Epoch 27, Step: 124, Loss: 0.13019409775733948, Lr:0.0001\n",
      "Epoch 27, Step: 125, Loss: 0.005308081395924091, Lr:0.0001\n",
      "Epoch 27, Step: 126, Loss: 0.04798659682273865, Lr:0.0001\n",
      "Epoch 27, Step: 127, Loss: 0.07948855310678482, Lr:0.0001\n",
      "Epoch 27, Step: 128, Loss: 0.014490009285509586, Lr:0.0001\n",
      "Epoch 27, Step: 129, Loss: 0.17010335624217987, Lr:0.0001\n",
      "Epoch 27, Step: 130, Loss: 0.08154615014791489, Lr:0.0001\n",
      "Epoch 27, Step: 131, Loss: 0.05041314288973808, Lr:0.0001\n",
      "Epoch 27, Step: 132, Loss: 0.13120408356189728, Lr:0.0001\n",
      "Epoch 27, Step: 133, Loss: 0.5103009343147278, Lr:0.0001\n",
      "Epoch 27, Step: 134, Loss: 0.06981617212295532, Lr:0.0001\n",
      "Epoch 27, Step: 135, Loss: 0.13995936512947083, Lr:0.0001\n",
      "Epoch 27, Step: 136, Loss: 0.052928756922483444, Lr:0.0001\n",
      "Epoch 27, Step: 137, Loss: 0.12113931775093079, Lr:0.0001\n",
      "Epoch 27, Step: 138, Loss: 0.02828799933195114, Lr:0.0001\n",
      "Epoch 27, Step: 139, Loss: 0.013317856006324291, Lr:0.0001\n",
      "Epoch 27, Step: 140, Loss: 0.005799849517643452, Lr:0.0001\n",
      "Epoch 27, Step: 141, Loss: 0.003582842880859971, Lr:0.0001\n",
      "Epoch 27, Step: 142, Loss: 0.013645580969750881, Lr:0.0001\n",
      "Epoch 27, Step: 143, Loss: 0.06509777158498764, Lr:0.0001\n",
      "Epoch 27, Step: 144, Loss: 0.10744482278823853, Lr:0.0001\n",
      "Epoch 27, Step: 145, Loss: 0.04431900754570961, Lr:0.0001\n",
      "Epoch 27, Step: 146, Loss: 0.03190113604068756, Lr:0.0001\n",
      "Epoch 27, Step: 147, Loss: 0.03073284402489662, Lr:0.0001\n",
      "Epoch 27, Step: 148, Loss: 0.018624883145093918, Lr:0.0001\n",
      "Epoch 27, Step: 149, Loss: 0.04800264537334442, Lr:0.0001\n",
      "Epoch 27, Step: 150, Loss: 0.006973851937800646, Lr:0.0001\n",
      "Epoch 27, Step: 151, Loss: 0.0036787986755371094, Lr:0.0001\n",
      "Epoch 27, Step: 152, Loss: 0.007977699860930443, Lr:0.0001\n",
      "Epoch 27, Step: 153, Loss: 0.011712992563843727, Lr:0.0001\n",
      "Epoch 27, Step: 154, Loss: 0.0008268127567134798, Lr:0.0001\n",
      "Epoch 27, Step: 155, Loss: 0.09611104428768158, Lr:0.0001\n",
      "Epoch 27, Step: 156, Loss: 0.20548059046268463, Lr:0.0001\n",
      "Epoch 27, Step: 157, Loss: 0.001213038805872202, Lr:0.0001\n",
      "Epoch 27, Step: 158, Loss: 0.04709220677614212, Lr:0.0001\n",
      "Epoch 27, Step: 159, Loss: 0.08438480645418167, Lr:0.0001\n",
      "Epoch 27, Step: 160, Loss: 0.007963630370795727, Lr:0.0001\n",
      "Epoch 27, Step: 161, Loss: 0.01592068560421467, Lr:0.0001\n",
      "Epoch 27, Step: 162, Loss: 0.042502980679273605, Lr:0.0001\n",
      "Epoch 27, Step: 163, Loss: 0.05799638479948044, Lr:0.0001\n",
      "Epoch 27, Step: 164, Loss: 0.09034700691699982, Lr:0.0001\n",
      "Epoch 27, Step: 165, Loss: 0.06190509349107742, Lr:0.0001\n",
      "Epoch 27, Step: 166, Loss: 0.01707274653017521, Lr:0.0001\n",
      "Epoch 27, Step: 167, Loss: 0.27957916259765625, Lr:0.0001\n",
      "Epoch 27, Step: 168, Loss: 0.164975106716156, Lr:0.0001\n",
      "Epoch 27, Step: 169, Loss: 0.00509954197332263, Lr:0.0001\n",
      "Epoch 27, Step: 170, Loss: 0.053922757506370544, Lr:0.0001\n",
      "Epoch 27, Step: 171, Loss: 0.007991296239197254, Lr:0.0001\n",
      "Epoch 27, Step: 172, Loss: 0.00034865725319832563, Lr:0.0001\n",
      "Epoch 27, Step: 173, Loss: 0.011127060279250145, Lr:0.0001\n",
      "Epoch 27, Step: 174, Loss: 0.06774336844682693, Lr:0.0001\n",
      "Epoch 27, Step: 175, Loss: 0.17495711147785187, Lr:0.0001\n",
      "Epoch 27, Step: 176, Loss: 0.035791896283626556, Lr:0.0001\n",
      "Epoch 27, Step: 177, Loss: 0.03195196017622948, Lr:0.0001\n",
      "Epoch 27, Step: 178, Loss: 0.003907560836523771, Lr:0.0001\n",
      "Epoch 27, Step: 179, Loss: 0.06200158968567848, Lr:0.0001\n",
      "Epoch 27, Step: 180, Loss: 0.016719883307814598, Lr:0.0001\n",
      "Epoch 27, Step: 181, Loss: 0.025808509439229965, Lr:0.0001\n",
      "Epoch 27, Step: 182, Loss: 0.07879618555307388, Lr:0.0001\n",
      "Epoch 27, Step: 183, Loss: 0.02665705606341362, Lr:0.0001\n",
      "Epoch 27, Step: 184, Loss: 0.23909242451190948, Lr:0.0001\n",
      "Epoch 27, Step: 185, Loss: 0.036440666764974594, Lr:0.0001\n",
      "Epoch 27, Step: 186, Loss: 0.07135327160358429, Lr:0.0001\n",
      "Epoch 27, Step: 187, Loss: 0.020729802548885345, Lr:0.0001\n",
      "Epoch 27, Step: 188, Loss: 0.018046962097287178, Lr:0.0001\n",
      "Epoch 27, Step: 189, Loss: 0.0269033070653677, Lr:0.0001\n",
      "Epoch 27, Step: 190, Loss: 0.04409201070666313, Lr:0.0001\n",
      "Epoch 27, Step: 191, Loss: 0.0058949850499629974, Lr:0.0001\n",
      "Epoch 27, Step: 192, Loss: 0.009064643643796444, Lr:0.0001\n",
      "Epoch 27, Step: 193, Loss: 0.0585830993950367, Lr:0.0001\n",
      "Epoch 27, Step: 194, Loss: 0.007970331236720085, Lr:0.0001\n",
      "Epoch 27, Step: 195, Loss: 0.09682147204875946, Lr:0.0001\n",
      "Epoch 27, Step: 196, Loss: 0.02621273510158062, Lr:0.0001\n",
      "Epoch 27, Step: 197, Loss: 0.0064837937243282795, Lr:0.0001\n",
      "Epoch 27, Step: 198, Loss: 0.16092520952224731, Lr:0.0001\n",
      "Epoch 27, Step: 199, Loss: 0.01620284654200077, Lr:0.0001\n",
      "Epoch 27, Step: 200, Loss: 0.03572078421711922, Lr:0.0001\n",
      "Epoch 27, Step: 201, Loss: 0.002892951015383005, Lr:0.0001\n",
      "Epoch 27, Step: 202, Loss: 0.01269529014825821, Lr:0.0001\n",
      "Epoch 27, Step: 203, Loss: 0.09692343324422836, Lr:0.0001\n",
      "Epoch 27, Step: 204, Loss: 0.06409914791584015, Lr:0.0001\n",
      "Epoch 27, Step: 205, Loss: 0.0030632682610303164, Lr:0.0001\n",
      "Epoch 27, Step: 206, Loss: 0.0018663869705051184, Lr:0.0001\n",
      "Epoch 27, Step: 207, Loss: 0.03239953890442848, Lr:0.0001\n",
      "Epoch 27, Step: 208, Loss: 0.005054593551903963, Lr:0.0001\n",
      "Epoch 27, Step: 209, Loss: 0.2359297126531601, Lr:0.0001\n",
      "Epoch 27, Step: 210, Loss: 0.09488258510828018, Lr:0.0001\n",
      "Epoch 27, Step: 211, Loss: 0.050210434943437576, Lr:0.0001\n",
      "Epoch 27, Step: 212, Loss: 0.007567205466330051, Lr:0.0001\n",
      "Epoch 27, Step: 213, Loss: 0.09857507795095444, Lr:0.0001\n",
      "Epoch 27, Step: 214, Loss: 0.005522174760699272, Lr:0.0001\n",
      "Epoch 27, Step: 215, Loss: 0.009474686346948147, Lr:0.0001\n",
      "Epoch 27, Step: 216, Loss: 0.0063633122481405735, Lr:0.0001\n",
      "Epoch 27, Step: 217, Loss: 0.1246475875377655, Lr:0.0001\n",
      "Epoch 27, Step: 218, Loss: 0.0017889027949422598, Lr:0.0001\n",
      "Epoch 27, Step: 219, Loss: 0.007720159366726875, Lr:0.0001\n",
      "Epoch 27, Step: 220, Loss: 0.12144404649734497, Lr:0.0001\n",
      "Epoch 27, Step: 221, Loss: 0.04421032592654228, Lr:0.0001\n",
      "Epoch 27, Step: 222, Loss: 0.0398762971162796, Lr:0.0001\n",
      "Epoch 27, Step: 223, Loss: 0.004942215513437986, Lr:0.0001\n",
      "Epoch 27, Step: 224, Loss: 0.008835028856992722, Lr:0.0001\n",
      "Epoch 27, Step: 225, Loss: 0.004776991903781891, Lr:0.0001\n",
      "Epoch 27, Step: 226, Loss: 0.006042633671313524, Lr:0.0001\n",
      "Epoch 27, Step: 227, Loss: 0.09461762011051178, Lr:0.0001\n",
      "Epoch 27, Step: 228, Loss: 0.03285539150238037, Lr:0.0001\n",
      "Epoch 27, Step: 229, Loss: 0.029440589249134064, Lr:0.0001\n",
      "Epoch 27, Step: 230, Loss: 0.005841549951583147, Lr:0.0001\n",
      "Epoch 27, Step: 231, Loss: 0.08382154256105423, Lr:0.0001\n",
      "Epoch 27, Step: 232, Loss: 0.005426405929028988, Lr:0.0001\n",
      "Epoch 27, Step: 233, Loss: 0.008599160239100456, Lr:0.0001\n",
      "Epoch 27, Step: 234, Loss: 0.02985212579369545, Lr:0.0001\n",
      "Epoch 27, Step: 235, Loss: 0.0013340224977582693, Lr:0.0001\n",
      "Epoch 27, Step: 236, Loss: 0.005601507145911455, Lr:0.0001\n",
      "Epoch 27, Step: 237, Loss: 0.1906692385673523, Lr:0.0001\n",
      "Epoch 27, Step: 238, Loss: 0.009335028938949108, Lr:0.0001\n",
      "Epoch 27, Step: 239, Loss: 0.014295611530542374, Lr:0.0001\n",
      "Epoch 27, Step: 240, Loss: 0.01445419155061245, Lr:0.0001\n",
      "Epoch 27, Step: 241, Loss: 0.08599452674388885, Lr:0.0001\n",
      "Epoch 27, Step: 242, Loss: 0.007919696159660816, Lr:0.0001\n",
      "Epoch 27, Step: 243, Loss: 0.02841869369149208, Lr:0.0001\n",
      "Epoch 27, Step: 244, Loss: 0.04211650788784027, Lr:0.0001\n",
      "Epoch 27, Step: 245, Loss: 0.029456544667482376, Lr:0.0001\n",
      "Epoch 27, Step: 246, Loss: 0.23466752469539642, Lr:0.0001\n",
      "Epoch 27, Step: 247, Loss: 0.006106036249548197, Lr:0.0001\n",
      "Epoch 27, Step: 248, Loss: 0.08682690560817719, Lr:0.0001\n",
      "Epoch 27, Step: 249, Loss: 0.029208984225988388, Lr:0.0001\n",
      "Epoch 27, Step: 250, Loss: 0.05463682860136032, Lr:0.0001\n",
      "Epoch 27, Step: 251, Loss: 0.009714515879750252, Lr:0.0001\n",
      "Epoch 27, Step: 252, Loss: 0.0196889266371727, Lr:0.0001\n",
      "Epoch 27, Step: 253, Loss: 0.01270487904548645, Lr:0.0001\n",
      "Epoch 27, Step: 254, Loss: 0.05993214249610901, Lr:0.0001\n",
      "Epoch 27, Step: 255, Loss: 0.05133097618818283, Lr:0.0001\n",
      "Epoch 27, Step: 256, Loss: 0.0012924934271723032, Lr:0.0001\n",
      "Epoch 27, Step: 257, Loss: 0.020327003672719002, Lr:0.0001\n",
      "Epoch 27, Step: 258, Loss: 0.12286718934774399, Lr:0.0001\n",
      "Epoch 27, Step: 259, Loss: 0.005594717804342508, Lr:0.0001\n",
      "Epoch 27, Step: 260, Loss: 0.04353371635079384, Lr:0.0001\n",
      "Epoch 27, Step: 261, Loss: 0.02545977756381035, Lr:0.0001\n",
      "Epoch 27, Step: 262, Loss: 0.002897989936172962, Lr:0.0001\n",
      "Epoch 27, Step: 263, Loss: 0.03758005425333977, Lr:0.0001\n",
      "Epoch 27, Step: 264, Loss: 0.008235354907810688, Lr:0.0001\n",
      "Epoch 27, Step: 265, Loss: 0.0032098612282425165, Lr:0.0001\n",
      "Epoch 27, Step: 266, Loss: 0.043068110942840576, Lr:0.0001\n",
      "Epoch 27, Step: 267, Loss: 0.036242496222257614, Lr:0.0001\n",
      "Epoch 27, Step: 268, Loss: 0.007792593911290169, Lr:0.0001\n",
      "Epoch 27, Step: 269, Loss: 0.0018903000745922327, Lr:0.0001\n",
      "Epoch 27, Step: 270, Loss: 0.0614948570728302, Lr:0.0001\n",
      "Epoch 27, Step: 271, Loss: 0.03007398173213005, Lr:0.0001\n",
      "Epoch 27, Step: 272, Loss: 0.017395757138729095, Lr:0.0001\n",
      "Epoch 27, Step: 273, Loss: 0.009666956029832363, Lr:0.0001\n",
      "Epoch 27, Step: 274, Loss: 0.05996590480208397, Lr:0.0001\n",
      "Epoch 27, Step: 275, Loss: 0.0023104872088879347, Lr:0.0001\n",
      "Epoch 27, Step: 276, Loss: 0.006052869372069836, Lr:0.0001\n",
      "Epoch 27, Step: 277, Loss: 0.25985077023506165, Lr:0.0001\n",
      "Epoch 27, Step: 278, Loss: 0.0413961336016655, Lr:0.0001\n",
      "Epoch 27, Step: 279, Loss: 0.0012939670123159885, Lr:0.0001\n",
      "Epoch 27, Step: 280, Loss: 0.07076741009950638, Lr:0.0001\n",
      "Epoch 27, Step: 281, Loss: 0.01098629366606474, Lr:0.0001\n",
      "Epoch 27, Step: 282, Loss: 0.011395684443414211, Lr:0.0001\n",
      "Epoch 27, Step: 283, Loss: 0.031109031289815903, Lr:0.0001\n",
      "Epoch 27, Step: 284, Loss: 0.16527311503887177, Lr:0.0001\n",
      "Epoch 27, Step: 285, Loss: 0.0036252206191420555, Lr:0.0001\n",
      "Epoch 27, Step: 286, Loss: 0.0013498200569301844, Lr:0.0001\n",
      "Epoch 27, Step: 287, Loss: 0.05501275137066841, Lr:0.0001\n",
      "Epoch 27, Step: 288, Loss: 0.0007277994882315397, Lr:0.0001\n",
      "Epoch 27, Step: 289, Loss: 0.0015425110468640924, Lr:0.0001\n",
      "Epoch 27, Step: 290, Loss: 0.002025899477303028, Lr:0.0001\n",
      "Epoch 27, Step: 291, Loss: 0.010295032523572445, Lr:0.0001\n",
      "Epoch 27, Step: 292, Loss: 0.01960192807018757, Lr:0.0001\n",
      "Epoch 27, Step: 293, Loss: 0.005006714258342981, Lr:0.0001\n",
      "Epoch 27, Step: 294, Loss: 0.448024719953537, Lr:0.0001\n",
      "Epoch 27, Step: 295, Loss: 0.0035146193113178015, Lr:0.0001\n",
      "Epoch 27, Step: 296, Loss: 0.08060053735971451, Lr:0.0001\n",
      "Epoch 27, Step: 297, Loss: 0.031775858253240585, Lr:0.0001\n",
      "Epoch 27, Step: 298, Loss: 0.09571357816457748, Lr:0.0001\n",
      "Epoch 27, Step: 299, Loss: 0.023609386757016182, Lr:0.0001\n",
      "Epoch 27, Step: 300, Loss: 0.02252892404794693, Lr:0.0001\n",
      "Epoch 27, Step: 301, Loss: 0.04281936213374138, Lr:0.0001\n",
      "Epoch 27, Step: 302, Loss: 0.045642755925655365, Lr:0.0001\n",
      "Epoch 27, Step: 303, Loss: 0.058537568897008896, Lr:0.0001\n",
      "Epoch 27, Step: 304, Loss: 0.14508572220802307, Lr:0.0001\n",
      "Epoch 27, Step: 305, Loss: 0.0010144615080207586, Lr:0.0001\n",
      "Epoch 27, Step: 306, Loss: 0.027879362925887108, Lr:0.0001\n",
      "Epoch 27, Step: 307, Loss: 0.003714798018336296, Lr:0.0001\n",
      "Epoch 27, Step: 308, Loss: 0.16381455957889557, Lr:0.0001\n",
      "Epoch 27, Step: 309, Loss: 0.09897469729185104, Lr:0.0001\n",
      "Epoch 27, Step: 310, Loss: 0.0017832107841968536, Lr:0.0001\n",
      "Epoch 27, Step: 311, Loss: 0.004545093514025211, Lr:0.0001\n",
      "Epoch 27, Step: 312, Loss: 0.12070317566394806, Lr:0.0001\n",
      "Epoch 27, Step: 313, Loss: 0.08583581447601318, Lr:0.0001\n",
      "Epoch 27, Step: 314, Loss: 0.05471239984035492, Lr:0.0001\n",
      "Epoch 27, Step: 315, Loss: 0.09661827981472015, Lr:0.0001\n",
      "Epoch 27, Step: 316, Loss: 0.04791418835520744, Lr:0.0001\n",
      "Epoch 27, Step: 317, Loss: 0.1142621859908104, Lr:0.0001\n",
      "Epoch 27, Step: 318, Loss: 0.002971743233501911, Lr:0.0001\n",
      "Epoch 27, Step: 319, Loss: 0.4119199514389038, Lr:0.0001\n",
      "Epoch 27, Step: 320, Loss: 0.0686039850115776, Lr:0.0001\n",
      "Epoch 27, Step: 321, Loss: 0.026121411472558975, Lr:0.0001\n",
      "Epoch 27, Step: 322, Loss: 0.21531789004802704, Lr:0.0001\n",
      "Epoch 27, Step: 323, Loss: 0.003985957708209753, Lr:0.0001\n",
      "Epoch 27, Step: 324, Loss: 0.007460093125700951, Lr:0.0001\n",
      "Epoch 27, Step: 325, Loss: 0.0021709036082029343, Lr:0.0001\n",
      "Epoch 27, Step: 326, Loss: 0.028247475624084473, Lr:0.0001\n",
      "Epoch 27, Step: 327, Loss: 0.0005136819672770798, Lr:0.0001\n",
      "Epoch 27, Step: 328, Loss: 0.0848618596792221, Lr:0.0001\n",
      "Epoch 27, Step: 329, Loss: 0.006419622339308262, Lr:0.0001\n",
      "Epoch 27, Step: 330, Loss: 0.0949322059750557, Lr:0.0001\n",
      "Epoch 27, Step: 331, Loss: 0.030950108543038368, Lr:0.0001\n",
      "Epoch 27, Step: 332, Loss: 0.030773788690567017, Lr:0.0001\n",
      "Epoch 27, Step: 333, Loss: 0.08469764143228531, Lr:0.0001\n",
      "Epoch 27, Step: 334, Loss: 0.07552830129861832, Lr:0.0001\n",
      "Epoch 27, Step: 335, Loss: 0.006261720322072506, Lr:0.0001\n",
      "Epoch 27, Step: 336, Loss: 0.1354900300502777, Lr:0.0001\n",
      "Epoch 27, Step: 337, Loss: 0.0035061805974692106, Lr:0.0001\n",
      "Epoch 27, Step: 338, Loss: 0.03628072515130043, Lr:0.0001\n",
      "Epoch 27, Step: 339, Loss: 0.11582034081220627, Lr:0.0001\n",
      "Epoch 27, Step: 340, Loss: 0.07551697641611099, Lr:0.0001\n",
      "Epoch 27, Step: 341, Loss: 0.09007981419563293, Lr:0.0001\n",
      "Epoch 27, Step: 342, Loss: 0.32933756709098816, Lr:0.0001\n",
      "Epoch 27, Step: 343, Loss: 0.09973006695508957, Lr:0.0001\n",
      "Epoch 27, Step: 344, Loss: 0.003016057889908552, Lr:0.0001\n",
      "Epoch 27, Step: 345, Loss: 0.11183923482894897, Lr:0.0001\n",
      "Epoch 27, Step: 346, Loss: 0.14571064710617065, Lr:0.0001\n",
      "Epoch 27, Step: 347, Loss: 0.029004473239183426, Lr:0.0001\n",
      "Epoch 27, Step: 348, Loss: 0.23750115931034088, Lr:0.0001\n",
      "Epoch 27, Step: 349, Loss: 0.02094408869743347, Lr:0.0001\n",
      "Epoch 27, Step: 350, Loss: 0.040758416056632996, Lr:0.0001\n",
      "Epoch 27, Step: 351, Loss: 0.2022262066602707, Lr:0.0001\n",
      "Epoch 27, Step: 352, Loss: 0.012382029555737972, Lr:0.0001\n",
      "Epoch 27, Step: 353, Loss: 0.006338798440992832, Lr:0.0001\n",
      "Epoch 27, Step: 354, Loss: 0.0032675722613930702, Lr:0.0001\n",
      "Epoch 27, Step: 355, Loss: 0.036186400800943375, Lr:0.0001\n",
      "Epoch 27, Step: 356, Loss: 0.07233499735593796, Lr:0.0001\n",
      "Epoch 27, Step: 357, Loss: 0.021859508007764816, Lr:0.0001\n",
      "Epoch 27, Step: 358, Loss: 0.010228832252323627, Lr:0.0001\n",
      "Epoch 27, Step: 359, Loss: 0.04581505432724953, Lr:0.0001\n",
      "Epoch 27, Step: 360, Loss: 0.020473429933190346, Lr:0.0001\n",
      "Epoch 27, Step: 361, Loss: 0.03073490411043167, Lr:0.0001\n",
      "Epoch 27, Step: 362, Loss: 0.017652615904808044, Lr:0.0001\n",
      "Epoch 27, Step: 363, Loss: 0.06290531158447266, Lr:0.0001\n",
      "Epoch 27, Step: 364, Loss: 0.08763096481561661, Lr:0.0001\n",
      "Epoch 27, Step: 365, Loss: 0.015194427222013474, Lr:0.0001\n",
      "Epoch 27, Step: 366, Loss: 0.053839508444070816, Lr:0.0001\n",
      "Epoch 27, Step: 367, Loss: 0.058400142937898636, Lr:0.0001\n",
      "Epoch 27, Step: 368, Loss: 0.03393103927373886, Lr:0.0001\n",
      "Epoch 27, Step: 369, Loss: 0.011179045774042606, Lr:0.0001\n",
      "Epoch 27, Step: 370, Loss: 0.007261909544467926, Lr:0.0001\n",
      "Epoch 27, Step: 371, Loss: 0.057966820895671844, Lr:0.0001\n",
      "Epoch 27, Step: 372, Loss: 0.006909017916768789, Lr:0.0001\n",
      "Epoch 27, Step: 373, Loss: 0.004204356111586094, Lr:0.0001\n",
      "Epoch 27, Step: 374, Loss: 0.030339984223246574, Lr:0.0001\n",
      "Epoch 27, Step: 375, Loss: 0.0003219103964511305, Lr:0.0001\n",
      "Epoch 27, Step: 376, Loss: 0.07567007094621658, Lr:0.0001\n",
      "Epoch 27, Step: 377, Loss: 0.03134290128946304, Lr:0.0001\n",
      "Epoch 27, Step: 378, Loss: 0.02155924402177334, Lr:0.0001\n",
      "Epoch 27, Step: 379, Loss: 0.01639544405043125, Lr:0.0001\n",
      "Epoch 27, Step: 380, Loss: 0.02853628247976303, Lr:0.0001\n",
      "Epoch 27, Step: 381, Loss: 0.018953872844576836, Lr:0.0001\n",
      "Epoch 27, Step: 382, Loss: 0.005206948146224022, Lr:0.0001\n",
      "Epoch 27, Step: 383, Loss: 0.2788304090499878, Lr:0.0001\n",
      "Epoch 27, Step: 384, Loss: 0.013788549229502678, Lr:0.0001\n",
      "Epoch 27, Step: 385, Loss: 0.2942446768283844, Lr:0.0001\n",
      "Epoch 27, Step: 386, Loss: 0.013174193911254406, Lr:0.0001\n",
      "Epoch 27, Step: 387, Loss: 0.025405114516615868, Lr:0.0001\n",
      "Epoch 27, Step: 388, Loss: 0.003836651798337698, Lr:0.0001\n",
      "Epoch 27, Step: 389, Loss: 0.010323701426386833, Lr:0.0001\n",
      "Epoch 27, Step: 390, Loss: 0.03330859914422035, Lr:0.0001\n",
      "Epoch 27, Step: 391, Loss: 0.1381227970123291, Lr:0.0001\n",
      "Epoch 27, Step: 392, Loss: 0.024423103779554367, Lr:0.0001\n",
      "Epoch 27, Step: 393, Loss: 0.040260184556245804, Lr:0.0001\n",
      "Epoch 27, Step: 394, Loss: 0.0033723467495292425, Lr:0.0001\n",
      "Epoch 27, Step: 395, Loss: 0.012396140024065971, Lr:0.0001\n",
      "Epoch 27, Step: 396, Loss: 0.040030136704444885, Lr:0.0001\n",
      "Epoch 27, Step: 397, Loss: 0.0030365516431629658, Lr:0.0001\n",
      "Epoch 27, Step: 398, Loss: 0.059244491159915924, Lr:0.0001\n",
      "Epoch 27, Step: 399, Loss: 0.01878999173641205, Lr:0.0001\n",
      "Epoch 27, Step: 400, Loss: 0.02131067030131817, Lr:0.0001\n",
      "Epoch 27, Step: 401, Loss: 0.002391746500506997, Lr:0.0001\n",
      "Epoch 27, Step: 402, Loss: 0.012835249304771423, Lr:0.0001\n",
      "Epoch 27, Step: 403, Loss: 0.0053159757517278194, Lr:0.0001\n",
      "Epoch 27, Step: 404, Loss: 0.010952825658023357, Lr:0.0001\n",
      "Epoch 27, Step: 405, Loss: 0.002857350278645754, Lr:0.0001\n",
      "Epoch 27, Step: 406, Loss: 0.19245077669620514, Lr:0.0001\n",
      "Epoch 27, Step: 407, Loss: 0.005442420486360788, Lr:0.0001\n",
      "Epoch 27, Step: 408, Loss: 0.026520125567913055, Lr:0.0001\n",
      "Epoch 27, Step: 409, Loss: 0.031089946627616882, Lr:0.0001\n",
      "Epoch 27, Step: 410, Loss: 0.008391188457608223, Lr:0.0001\n",
      "Epoch 27, Step: 411, Loss: 0.042091306298971176, Lr:0.0001\n",
      "Epoch 27, Step: 412, Loss: 0.015406600199639797, Lr:0.0001\n",
      "Epoch 27, Step: 413, Loss: 0.011025442741811275, Lr:0.0001\n",
      "Epoch 27, Step: 414, Loss: 0.003444697940722108, Lr:0.0001\n",
      "Epoch 27, Step: 415, Loss: 0.05120285600423813, Lr:0.0001\n",
      "Epoch 27, Step: 416, Loss: 0.0741892158985138, Lr:0.0001\n",
      "Epoch 27, Step: 417, Loss: 0.12718285620212555, Lr:0.0001\n",
      "Epoch 27, Step: 418, Loss: 0.027110572904348373, Lr:0.0001\n",
      "Epoch 27, Step: 419, Loss: 0.003029875922948122, Lr:0.0001\n",
      "Epoch 27, Step: 420, Loss: 0.02472558803856373, Lr:0.0001\n",
      "Epoch 27, Step: 421, Loss: 0.051777854561805725, Lr:0.0001\n",
      "Epoch 27, Step: 422, Loss: 0.01994767226278782, Lr:0.0001\n",
      "Epoch 27, Step: 423, Loss: 0.07061078399419785, Lr:0.0001\n",
      "Epoch 27, Step: 424, Loss: 0.0050420197658240795, Lr:0.0001\n",
      "Epoch 27, Step: 425, Loss: 0.03394106775522232, Lr:0.0001\n",
      "Epoch 27, Step: 426, Loss: 0.06931126862764359, Lr:0.0001\n",
      "Epoch 27, Step: 427, Loss: 0.0015791031764820218, Lr:0.0001\n",
      "Epoch 27, Step: 428, Loss: 0.01154036819934845, Lr:0.0001\n",
      "Epoch 27, Step: 429, Loss: 0.010464103892445564, Lr:0.0001\n",
      "Epoch 27, Step: 430, Loss: 0.10259676724672318, Lr:0.0001\n",
      "Epoch 27, Step: 431, Loss: 0.014345225878059864, Lr:0.0001\n",
      "Epoch 27, Step: 432, Loss: 0.028232749551534653, Lr:0.0001\n",
      "Epoch 27, Step: 433, Loss: 0.03179849684238434, Lr:0.0001\n",
      "Epoch 27, Step: 434, Loss: 0.017072202637791634, Lr:0.0001\n",
      "Epoch 27, Step: 435, Loss: 0.0038145105354487896, Lr:0.0001\n",
      "Epoch 27, Step: 436, Loss: 0.030040929093956947, Lr:0.0001\n",
      "Epoch 27, Step: 437, Loss: 0.01762271113693714, Lr:0.0001\n",
      "Epoch 27, Step: 438, Loss: 0.0012689303839579225, Lr:0.0001\n",
      "Epoch 27, Step: 439, Loss: 0.1424042284488678, Lr:0.0001\n",
      "Epoch 27, Step: 440, Loss: 0.09129329770803452, Lr:0.0001\n",
      "Epoch 27, Step: 441, Loss: 0.020989947021007538, Lr:0.0001\n",
      "Epoch 27, Step: 442, Loss: 0.00731390155851841, Lr:0.0001\n",
      "Epoch 27, Step: 443, Loss: 0.011447235010564327, Lr:0.0001\n",
      "Epoch 27, Step: 444, Loss: 0.001015441375784576, Lr:0.0001\n",
      "Epoch 27, Step: 445, Loss: 0.061148010194301605, Lr:0.0001\n",
      "Epoch 27, Step: 446, Loss: 0.004523733630776405, Lr:0.0001\n",
      "Epoch 27, Step: 447, Loss: 0.09215933829545975, Lr:0.0001\n",
      "Epoch 27, Step: 448, Loss: 0.009525837376713753, Lr:0.0001\n",
      "Epoch 27, Step: 449, Loss: 0.14532223343849182, Lr:0.0001\n",
      "Epoch 27, Step: 450, Loss: 0.002870798110961914, Lr:0.0001\n",
      "Epoch 27, Step: 451, Loss: 0.013302754610776901, Lr:0.0001\n",
      "Epoch 27, Step: 452, Loss: 0.02035004273056984, Lr:0.0001\n",
      "Epoch 27, Step: 453, Loss: 0.005396486725658178, Lr:0.0001\n",
      "Epoch 27, Step: 454, Loss: 0.033543020486831665, Lr:0.0001\n",
      "Epoch 27, Step: 455, Loss: 0.15530425310134888, Lr:0.0001\n",
      "Epoch 27, Step: 456, Loss: 0.008270605467259884, Lr:0.0001\n",
      "Epoch 27, Step: 457, Loss: 0.0777142345905304, Lr:0.0001\n",
      "Epoch 27, Step: 458, Loss: 0.024666743353009224, Lr:0.0001\n",
      "Epoch 27, Step: 459, Loss: 0.008827193640172482, Lr:0.0001\n",
      "Epoch 27, Step: 460, Loss: 0.004725220613181591, Lr:0.0001\n",
      "Epoch 27, Step: 461, Loss: 0.00038040769868530333, Lr:0.0001\n",
      "Epoch 27, Step: 462, Loss: 0.15654915571212769, Lr:0.0001\n",
      "Epoch 27, Step: 463, Loss: 0.001129510928876698, Lr:0.0001\n",
      "Epoch 27, Step: 464, Loss: 0.09775513410568237, Lr:0.0001\n",
      "Epoch 27, Step: 465, Loss: 1.1385979652404785, Lr:0.0001\n",
      "Epoch 27, Step: 466, Loss: 0.11084471642971039, Lr:0.0001\n",
      "Epoch 27, Step: 467, Loss: 0.17262467741966248, Lr:0.0001\n",
      "Epoch 27, Step: 468, Loss: 0.1352234035730362, Lr:0.0001\n",
      "Epoch 27, Step: 469, Loss: 0.07759632170200348, Lr:0.0001\n",
      "Epoch 27, Step: 470, Loss: 0.24391555786132812, Lr:0.0001\n",
      "Epoch 27, Step: 471, Loss: 0.08518374711275101, Lr:0.0001\n",
      "Epoch 27, Step: 472, Loss: 0.131363645195961, Lr:0.0001\n",
      "Epoch 27, Step: 473, Loss: 0.05560395494103432, Lr:0.0001\n",
      "Epoch 27, Step: 474, Loss: 0.01722688414156437, Lr:0.0001\n",
      "Epoch 27, Step: 475, Loss: 0.060580864548683167, Lr:0.0001\n",
      "Epoch 27, Step: 476, Loss: 0.017141779884696007, Lr:0.0001\n",
      "Epoch 27, Step: 477, Loss: 0.26438093185424805, Lr:0.0001\n",
      "Epoch 27, Step: 478, Loss: 0.005614414811134338, Lr:0.0001\n",
      "Epoch 27, Step: 479, Loss: 0.09577977657318115, Lr:0.0001\n",
      "Epoch 27, Step: 480, Loss: 0.061300598084926605, Lr:0.0001\n",
      "Epoch 27, Step: 481, Loss: 0.021437784656882286, Lr:0.0001\n",
      "Epoch 27, Step: 482, Loss: 0.1904137134552002, Lr:0.0001\n",
      "Epoch 27, Step: 483, Loss: 0.012832505628466606, Lr:0.0001\n",
      "Epoch 27, Step: 484, Loss: 0.1634824126958847, Lr:0.0001\n",
      "Epoch 27, Step: 485, Loss: 0.14886769652366638, Lr:0.0001\n",
      "Epoch 27, Step: 486, Loss: 0.2202434539794922, Lr:0.0001\n",
      "Epoch 27, Step: 487, Loss: 0.1332097351551056, Lr:0.0001\n",
      "Epoch 27, Step: 488, Loss: 0.00861329399049282, Lr:0.0001\n",
      "Epoch 27, Step: 489, Loss: 0.2030782699584961, Lr:0.0001\n",
      "Epoch 27, Step: 490, Loss: 0.015659010037779808, Lr:0.0001\n",
      "Epoch 27, Step: 491, Loss: 0.012582935392856598, Lr:0.0001\n",
      "Epoch 27, Step: 492, Loss: 0.09853415936231613, Lr:0.0001\n",
      "Epoch 27, Step: 493, Loss: 0.023826418444514275, Lr:0.0001\n",
      "Epoch 27, Step: 494, Loss: 0.02491043508052826, Lr:0.0001\n",
      "Epoch 27, Step: 495, Loss: 0.14266934990882874, Lr:0.0001\n",
      "Epoch 27, Step: 496, Loss: 0.2709145247936249, Lr:0.0001\n",
      "Epoch 27, Step: 497, Loss: 0.13332943618297577, Lr:0.0001\n",
      "Epoch 27, Step: 498, Loss: 0.1199871227145195, Lr:0.0001\n",
      "Epoch 27, Step: 499, Loss: 0.0031067640520632267, Lr:0.0001\n",
      "Epoch 27, Step: 500, Loss: 0.034935951232910156, Lr:0.0001\n",
      "Epoch 27, Step: 501, Loss: 0.2855606973171234, Lr:0.0001\n",
      "Epoch 27, Step: 502, Loss: 0.1574358493089676, Lr:0.0001\n",
      "Epoch 27, Step: 503, Loss: 0.1807302087545395, Lr:0.0001\n",
      "Epoch 27, Step: 504, Loss: 0.16423946619033813, Lr:0.0001\n",
      "Epoch 27, Step: 505, Loss: 0.3192170560359955, Lr:0.0001\n",
      "Epoch 27, Step: 506, Loss: 0.00973390694707632, Lr:0.0001\n",
      "Epoch 27, Step: 507, Loss: 0.0710376426577568, Lr:0.0001\n",
      "Epoch 27, Step: 508, Loss: 0.29237085580825806, Lr:0.0001\n",
      "Epoch 27, Step: 509, Loss: 0.06848237663507462, Lr:0.0001\n",
      "Epoch 27, Step: 510, Loss: 0.09982877969741821, Lr:0.0001\n",
      "Epoch 27, Step: 511, Loss: 0.18559212982654572, Lr:0.0001\n",
      "Epoch 27, Step: 512, Loss: 0.009181644767522812, Lr:0.0001\n",
      "Epoch 27, Step: 513, Loss: 0.023551560938358307, Lr:0.0001\n",
      "Epoch 27, Step: 514, Loss: 0.28651320934295654, Lr:0.0001\n",
      "Epoch 27, Step: 515, Loss: 0.03695761412382126, Lr:0.0001\n",
      "Epoch 27, Step: 516, Loss: 0.017223989591002464, Lr:0.0001\n",
      "Epoch 27, Step: 517, Loss: 0.08223812282085419, Lr:0.0001\n",
      "Epoch 27, Step: 518, Loss: 0.03825605288147926, Lr:0.0001\n",
      "Epoch 27, Step: 519, Loss: 0.002633002121001482, Lr:0.0001\n",
      "Epoch 27, Step: 520, Loss: 0.2017567902803421, Lr:0.0001\n",
      "Epoch 27, Step: 521, Loss: 0.15867774188518524, Lr:0.0001\n",
      "Epoch 27, Step: 522, Loss: 0.08565634489059448, Lr:0.0001\n",
      "Epoch 27, Step: 523, Loss: 0.02621041238307953, Lr:0.0001\n",
      "Epoch 27, Step: 524, Loss: 0.0418153777718544, Lr:0.0001\n",
      "Epoch 27, Step: 525, Loss: 9.909571235766634e-05, Lr:0.0001\n",
      "Epoch 27, Step: 526, Loss: 0.1501452922821045, Lr:0.0001\n",
      "Epoch 27, Step: 527, Loss: 0.008148694410920143, Lr:0.0001\n",
      "Epoch 27, Step: 528, Loss: 0.04004520922899246, Lr:0.0001\n",
      "Epoch 27, Step: 529, Loss: 0.176774799823761, Lr:0.0001\n",
      "Epoch 27, Step: 530, Loss: 0.06789273768663406, Lr:0.0001\n",
      "Epoch 27, Step: 531, Loss: 0.00040778814582154155, Lr:0.0001\n",
      "Epoch 27, Step: 532, Loss: 0.2110617458820343, Lr:0.0001\n",
      "Epoch 27, Step: 533, Loss: 0.022492486983537674, Lr:0.0001\n",
      "Epoch 27, Step: 534, Loss: 0.061331164091825485, Lr:0.0001\n",
      "Epoch 27, Step: 535, Loss: 0.06352498382329941, Lr:0.0001\n",
      "Epoch 27, Step: 536, Loss: 0.15445220470428467, Lr:0.0001\n",
      "Epoch 27, Step: 537, Loss: 0.08173833787441254, Lr:0.0001\n",
      "Epoch 27, Step: 538, Loss: 0.042744845151901245, Lr:0.0001\n",
      "Epoch 27, Step: 539, Loss: 0.14711511135101318, Lr:0.0001\n",
      "Epoch 27, Step: 540, Loss: 0.04192378744482994, Lr:0.0001\n",
      "Epoch 27, Step: 541, Loss: 0.050677359104156494, Lr:0.0001\n",
      "Epoch 27, Step: 542, Loss: 0.07405503839254379, Lr:0.0001\n",
      "Epoch 27, Step: 543, Loss: 0.32383543252944946, Lr:0.0001\n",
      "Epoch 27, Step: 544, Loss: 0.0009819846600294113, Lr:0.0001\n",
      "Epoch 27, Step: 545, Loss: 0.1573133021593094, Lr:0.0001\n",
      "Epoch 27, Step: 546, Loss: 0.028146615251898766, Lr:0.0001\n",
      "Epoch 27, Step: 547, Loss: 0.08701088279485703, Lr:0.0001\n",
      "Epoch 27, Step: 548, Loss: 0.0008517592796124518, Lr:0.0001\n",
      "Epoch 27, Step: 549, Loss: 0.016438627615571022, Lr:0.0001\n",
      "Epoch 27, Step: 550, Loss: 0.06903639435768127, Lr:0.0001\n",
      "Epoch 27, Step: 551, Loss: 0.040296901017427444, Lr:0.0001\n",
      "Epoch 27, Step: 552, Loss: 0.07336815446615219, Lr:0.0001\n",
      "Epoch 27, Step: 553, Loss: 0.010120272636413574, Lr:0.0001\n",
      "Epoch 27, Step: 554, Loss: 0.10295328497886658, Lr:0.0001\n",
      "Epoch 27, Step: 555, Loss: 0.0036761772353202105, Lr:0.0001\n",
      "Epoch 27, Step: 556, Loss: 0.007427709177136421, Lr:0.0001\n",
      "Epoch 27, Step: 557, Loss: 0.015880651772022247, Lr:0.0001\n",
      "Epoch 27, Step: 558, Loss: 0.0025375434197485447, Lr:0.0001\n",
      "Epoch 27, Step: 559, Loss: 0.2168373167514801, Lr:0.0001\n",
      "Epoch 27, Step: 560, Loss: 0.01090592984110117, Lr:0.0001\n",
      "Epoch 27, Step: 561, Loss: 0.0009172656573355198, Lr:0.0001\n",
      "Epoch 27, Step: 562, Loss: 0.07783712446689606, Lr:0.0001\n",
      "Epoch 27, Step: 563, Loss: 0.13644559681415558, Lr:0.0001\n",
      "Epoch 27, Step: 564, Loss: 0.06780510395765305, Lr:0.0001\n",
      "Epoch 27, Step: 565, Loss: 0.024125996977090836, Lr:0.0001\n",
      "Epoch 27, Step: 566, Loss: 0.008569360710680485, Lr:0.0001\n",
      "Epoch 27, Step: 567, Loss: 0.1183452308177948, Lr:0.0001\n",
      "Epoch 27, Step: 568, Loss: 0.003787500783801079, Lr:0.0001\n",
      "Epoch 27, Step: 569, Loss: 0.12370122224092484, Lr:0.0001\n",
      "Epoch 27, Step: 570, Loss: 0.03786875680088997, Lr:0.0001\n",
      "Epoch 27, Step: 571, Loss: 0.0004943350213579834, Lr:0.0001\n",
      "Epoch 27, Step: 572, Loss: 0.05124087631702423, Lr:0.0001\n",
      "Epoch 27, Step: 573, Loss: 0.018171017989516258, Lr:0.0001\n",
      "Epoch 27, Step: 574, Loss: 0.0317254364490509, Lr:0.0001\n",
      "Epoch 27, Step: 575, Loss: 0.02098403126001358, Lr:0.0001\n",
      "Epoch 27, Step: 576, Loss: 0.5526812672615051, Lr:0.0001\n",
      "Epoch 27, Step: 577, Loss: 0.06279099732637405, Lr:0.0001\n",
      "Epoch 27, Step: 578, Loss: 0.016286741942167282, Lr:0.0001\n",
      "Epoch 27, Step: 579, Loss: 0.18953995406627655, Lr:0.0001\n",
      "Epoch 27, Step: 580, Loss: 0.01358090527355671, Lr:0.0001\n",
      "Epoch 27, Step: 581, Loss: 0.030669404193758965, Lr:0.0001\n",
      "Epoch 27, Step: 582, Loss: 0.23084765672683716, Lr:0.0001\n",
      "Epoch 27, Step: 583, Loss: 0.020913753658533096, Lr:0.0001\n",
      "Epoch 27, Step: 584, Loss: 0.0072588687762618065, Lr:0.0001\n",
      "Epoch 27, Step: 585, Loss: 0.06580305099487305, Lr:0.0001\n",
      "Epoch 27, Step: 586, Loss: 0.018094388768076897, Lr:0.0001\n",
      "Epoch 27, Step: 587, Loss: 0.35999006032943726, Lr:0.0001\n",
      "Epoch 27, Step: 588, Loss: 0.132395938038826, Lr:0.0001\n",
      "Epoch 27, Step: 589, Loss: 0.0986177921295166, Lr:0.0001\n",
      "Epoch 27, Step: 590, Loss: 0.036169543862342834, Lr:0.0001\n",
      "Epoch 27, Step: 591, Loss: 0.04690849781036377, Lr:0.0001\n",
      "Epoch 27, Step: 592, Loss: 0.009408419951796532, Lr:0.0001\n",
      "Epoch 27, Step: 593, Loss: 0.00792165007442236, Lr:0.0001\n",
      "Epoch 27, Step: 594, Loss: 0.0072367568500339985, Lr:0.0001\n",
      "Epoch 27, Step: 595, Loss: 0.017653776332736015, Lr:0.0001\n",
      "Epoch 27, Step: 596, Loss: 0.11874188482761383, Lr:0.0001\n",
      "Epoch 27, Step: 597, Loss: 0.007610027678310871, Lr:0.0001\n",
      "Epoch 27, Step: 598, Loss: 0.03985365852713585, Lr:0.0001\n",
      "Epoch 27, Step: 599, Loss: 0.033486392349004745, Lr:0.0001\n",
      "Epoch 27, Step: 600, Loss: 0.28264787793159485, Lr:0.0001\n",
      "Epoch 27, Step: 601, Loss: 0.03984416276216507, Lr:0.0001\n",
      "Epoch 27, Step: 602, Loss: 0.0012222882360219955, Lr:0.0001\n",
      "Epoch 27, Step: 603, Loss: 0.012072175741195679, Lr:0.0001\n",
      "Epoch 27, Step: 604, Loss: 0.01659935526549816, Lr:0.0001\n",
      "Epoch 27, Step: 605, Loss: 0.02660430409014225, Lr:0.0001\n",
      "Epoch 27, Step: 606, Loss: 0.015106990933418274, Lr:0.0001\n",
      "Epoch 27, Step: 607, Loss: 0.004097346682101488, Lr:0.0001\n",
      "Epoch 27, Step: 608, Loss: 0.033993013203144073, Lr:0.0001\n",
      "Epoch 27, Step: 609, Loss: 0.0728815570473671, Lr:0.0001\n",
      "Epoch 27, Step: 610, Loss: 0.019084325060248375, Lr:0.0001\n",
      "Epoch 27, Step: 611, Loss: 0.07465561479330063, Lr:0.0001\n",
      "Epoch 27, Step: 612, Loss: 0.006054659374058247, Lr:0.0001\n",
      "Epoch 27, Step: 613, Loss: 0.0297089796513319, Lr:0.0001\n",
      "Epoch 27, Step: 614, Loss: 0.21773914992809296, Lr:0.0001\n",
      "Epoch 27, Step: 615, Loss: 0.029900552704930305, Lr:0.0001\n",
      "Epoch 27, Step: 616, Loss: 0.008448509499430656, Lr:0.0001\n",
      "Epoch 27, Step: 617, Loss: 0.0025437662843614817, Lr:0.0001\n",
      "Epoch 27, Step: 618, Loss: 0.14190466701984406, Lr:0.0001\n",
      "Epoch 27, Step: 619, Loss: 0.027830002829432487, Lr:0.0001\n",
      "Epoch 27, Step: 620, Loss: 0.027292193844914436, Lr:0.0001\n",
      "Epoch 27, Step: 621, Loss: 0.0871947631239891, Lr:0.0001\n",
      "Epoch 27, Step: 622, Loss: 0.026917658746242523, Lr:0.0001\n",
      "Epoch 27, Step: 623, Loss: 0.016253335401415825, Lr:0.0001\n",
      "Epoch 27, Step: 624, Loss: 0.14011450111865997, Lr:0.0001\n",
      "Epoch 27, Step: 625, Loss: 0.18400929868221283, Lr:0.0001\n",
      "Epoch 27, Step: 626, Loss: 0.12399096041917801, Lr:0.0001\n",
      "Epoch 27, Step: 627, Loss: 0.04233546182513237, Lr:0.0001\n",
      "Epoch 27, Step: 628, Loss: 0.11027158051729202, Lr:0.0001\n",
      "Epoch 27, Step: 629, Loss: 0.018336214125156403, Lr:0.0001\n",
      "Epoch 27, Step: 630, Loss: 0.2125924825668335, Lr:0.0001\n",
      "Epoch 27, Step: 631, Loss: 0.056590259075164795, Lr:0.0001\n",
      "Epoch 27, Step: 632, Loss: 0.03977109491825104, Lr:0.0001\n",
      "Epoch 27, Step: 633, Loss: 0.05757758393883705, Lr:0.0001\n",
      "Epoch 27, Step: 634, Loss: 0.01859118789434433, Lr:0.0001\n",
      "Epoch 27, Step: 635, Loss: 0.17866326868534088, Lr:0.0001\n",
      "Epoch 27, Step: 636, Loss: 0.05166848376393318, Lr:0.0001\n",
      "Epoch 27, Step: 637, Loss: 0.06238700449466705, Lr:0.0001\n",
      "Epoch 27, Step: 638, Loss: 0.06267809122800827, Lr:0.0001\n",
      "Epoch 27, Step: 639, Loss: 0.006252375431358814, Lr:0.0001\n",
      "Epoch 27, Step: 640, Loss: 0.07095266878604889, Lr:0.0001\n",
      "Epoch 27, Step: 641, Loss: 0.02680552564561367, Lr:0.0001\n",
      "Epoch 27, Step: 642, Loss: 0.06294544041156769, Lr:0.0001\n",
      "Epoch 27, Step: 643, Loss: 0.016302544623613358, Lr:0.0001\n",
      "Epoch 27, Step: 644, Loss: 0.23650790750980377, Lr:0.0001\n",
      "Epoch 27, Step: 645, Loss: 0.018932154402136803, Lr:0.0001\n",
      "Epoch 27, Step: 646, Loss: 0.06524801254272461, Lr:0.0001\n",
      "Epoch 27, Step: 647, Loss: 0.1459321677684784, Lr:0.0001\n",
      "Epoch 27, Step: 648, Loss: 0.1986134946346283, Lr:0.0001\n",
      "Epoch 27, Step: 649, Loss: 0.006033134646713734, Lr:0.0001\n",
      "Epoch 27, Step: 650, Loss: 0.0159434974193573, Lr:0.0001\n",
      "Epoch 27, Step: 651, Loss: 0.0023955742362886667, Lr:0.0001\n",
      "Epoch 27, Step: 652, Loss: 0.012080969288945198, Lr:0.0001\n",
      "Epoch 27, Step: 653, Loss: 0.033139340579509735, Lr:0.0001\n",
      "Epoch 27, Step: 654, Loss: 0.08700128644704819, Lr:0.0001\n",
      "Epoch 27, Step: 655, Loss: 0.11647117882966995, Lr:0.0001\n",
      "Epoch 27, Step: 656, Loss: 0.1464025229215622, Lr:0.0001\n",
      "Epoch 27, Step: 657, Loss: 0.028648659586906433, Lr:0.0001\n",
      "Epoch 27, Step: 658, Loss: 0.010167590342462063, Lr:0.0001\n",
      "Epoch 27, Step: 659, Loss: 0.04073828458786011, Lr:0.0001\n",
      "Epoch 27, Step: 660, Loss: 0.010117629542946815, Lr:0.0001\n",
      "Epoch 27, Step: 661, Loss: 0.0025707168970257044, Lr:0.0001\n",
      "Epoch 27, Step: 662, Loss: 0.002874093595892191, Lr:0.0001\n",
      "Epoch 27, Step: 663, Loss: 0.028758911415934563, Lr:0.0001\n",
      "Epoch 27, Step: 664, Loss: 0.09157007187604904, Lr:0.0001\n",
      "Epoch 27, Step: 665, Loss: 0.005276955664157867, Lr:0.0001\n",
      "Epoch 27, Step: 666, Loss: 0.007577111944556236, Lr:0.0001\n",
      "Epoch 27, Step: 667, Loss: 0.008770432323217392, Lr:0.0001\n",
      "Epoch 27, Step: 668, Loss: 0.07509123533964157, Lr:0.0001\n",
      "Epoch 27, Step: 669, Loss: 0.032192621380090714, Lr:0.0001\n",
      "Epoch 27, Step: 670, Loss: 0.00928060058504343, Lr:0.0001\n",
      "Epoch 27, Step: 671, Loss: 0.003953869920223951, Lr:0.0001\n",
      "Epoch 27, Step: 672, Loss: 0.007526103872805834, Lr:0.0001\n",
      "Epoch 27, Step: 673, Loss: 0.03674289211630821, Lr:0.0001\n",
      "Epoch 27, Step: 674, Loss: 0.01162363588809967, Lr:0.0001\n",
      "Epoch 27, Step: 675, Loss: 0.1182250902056694, Lr:0.0001\n",
      "Epoch 27, Step: 676, Loss: 0.013560475781559944, Lr:0.0001\n",
      "Epoch 27, Step: 677, Loss: 0.0008665641071274877, Lr:0.0001\n",
      "Epoch 27, Step: 678, Loss: 0.0682302936911583, Lr:0.0001\n",
      "Epoch 27, Step: 679, Loss: 0.001698820386081934, Lr:0.0001\n",
      "Epoch 27, Step: 680, Loss: 0.010942590422928333, Lr:0.0001\n",
      "Epoch 27, Step: 681, Loss: 0.010344495996832848, Lr:0.0001\n",
      "Epoch 27, Step: 682, Loss: 0.009800121188163757, Lr:0.0001\n",
      "Epoch 27, Step: 683, Loss: 0.15142422914505005, Lr:0.0001\n",
      "Epoch 27, Step: 684, Loss: 0.031226161867380142, Lr:0.0001\n",
      "Epoch 27, Step: 685, Loss: 0.015155190601944923, Lr:0.0001\n",
      "Epoch 27, Step: 686, Loss: 0.04484226182103157, Lr:0.0001\n",
      "Epoch 27, Step: 687, Loss: 0.034887973219156265, Lr:0.0001\n",
      "Epoch 27, Step: 688, Loss: 0.006030071526765823, Lr:0.0001\n",
      "Epoch 27, Step: 689, Loss: 0.10963727533817291, Lr:0.0001\n",
      "Epoch 27, Step: 690, Loss: 0.11223958432674408, Lr:0.0001\n",
      "Epoch 27, Step: 691, Loss: 0.04215742275118828, Lr:0.0001\n",
      "Epoch 27, Step: 692, Loss: 0.018432533368468285, Lr:0.0001\n",
      "Epoch 27, Step: 693, Loss: 0.04181041568517685, Lr:0.0001\n",
      "Epoch 27, Step: 694, Loss: 0.1913793385028839, Lr:0.0001\n",
      "Epoch 27, Step: 695, Loss: 0.015095466747879982, Lr:0.0001\n",
      "Epoch 27, Step: 696, Loss: 0.05411937087774277, Lr:0.0001\n",
      "Epoch 27, Step: 697, Loss: 0.0026677490677684546, Lr:0.0001\n",
      "Epoch 27, Step: 698, Loss: 0.30487120151519775, Lr:0.0001\n",
      "Epoch 27, Step: 699, Loss: 0.009431432001292706, Lr:0.0001\n",
      "Epoch 27, Step: 700, Loss: 0.0030186022631824017, Lr:0.0001\n",
      "Epoch 27, Step: 701, Loss: 0.0050397892482578754, Lr:0.0001\n",
      "Epoch 27, Step: 702, Loss: 0.0581572987139225, Lr:0.0001\n",
      "Epoch 27, Step: 703, Loss: 0.005968036130070686, Lr:0.0001\n",
      "Epoch 27, Step: 704, Loss: 0.07660054415464401, Lr:0.0001\n",
      "Epoch 27, Step: 705, Loss: 0.06581087410449982, Lr:0.0001\n",
      "Epoch 27, Step: 706, Loss: 0.20450526475906372, Lr:0.0001\n",
      "Epoch 27, Step: 707, Loss: 0.2962321937084198, Lr:0.0001\n",
      "Epoch 27, Step: 708, Loss: 0.2049650102853775, Lr:0.0001\n",
      "Epoch 27, Step: 709, Loss: 0.006985727231949568, Lr:0.0001\n",
      "Epoch 27, Step: 710, Loss: 0.1248934417963028, Lr:0.0001\n",
      "Epoch 27, Step: 711, Loss: 0.0845174714922905, Lr:0.0001\n",
      "Epoch 27, Step: 712, Loss: 0.03337422013282776, Lr:0.0001\n",
      "Epoch 27, Step: 713, Loss: 0.008362431079149246, Lr:0.0001\n",
      "Epoch 27, Step: 714, Loss: 0.03010951355099678, Lr:0.0001\n",
      "Epoch 27, Step: 715, Loss: 0.06601759046316147, Lr:0.0001\n",
      "Epoch 27, Step: 716, Loss: 0.006974952295422554, Lr:0.0001\n",
      "Epoch 27, Step: 717, Loss: 0.07273509353399277, Lr:0.0001\n",
      "Epoch 27, Step: 718, Loss: 0.08681967109441757, Lr:0.0001\n",
      "Epoch 27, Step: 719, Loss: 0.054958950728178024, Lr:0.0001\n",
      "Epoch 27, Step: 720, Loss: 0.04071424901485443, Lr:0.0001\n",
      "Epoch 27, Step: 721, Loss: 0.04181823134422302, Lr:0.0001\n",
      "Epoch 27, Step: 722, Loss: 0.025257952511310577, Lr:0.0001\n",
      "Epoch 27, Step: 723, Loss: 0.008659442886710167, Lr:0.0001\n",
      "Epoch 27, Step: 724, Loss: 0.1430269479751587, Lr:0.0001\n",
      "Epoch 27, Step: 725, Loss: 0.002406354295089841, Lr:0.0001\n",
      "Epoch 27, Step: 726, Loss: 0.008045096881687641, Lr:0.0001\n",
      "Epoch 27, Step: 727, Loss: 0.029594257473945618, Lr:0.0001\n",
      "Epoch 27, Step: 728, Loss: 0.03894932195544243, Lr:0.0001\n",
      "Epoch 27, Step: 729, Loss: 0.00984465703368187, Lr:0.0001\n",
      "Epoch 27, Step: 730, Loss: 0.04107975959777832, Lr:0.0001\n",
      "Epoch 27, Step: 731, Loss: 0.00925806351006031, Lr:0.0001\n",
      "Epoch 27, Step: 732, Loss: 0.20237630605697632, Lr:0.0001\n",
      "Epoch 27, Step: 733, Loss: 0.012759148143231869, Lr:0.0001\n",
      "Epoch 27, Step: 734, Loss: 0.03611614182591438, Lr:0.0001\n",
      "Epoch 27, Step: 735, Loss: 0.005709453485906124, Lr:0.0001\n",
      "Epoch 27, Step: 736, Loss: 0.07201402634382248, Lr:0.0001\n",
      "Epoch 27, Step: 737, Loss: 0.04509503394365311, Lr:0.0001\n",
      "Epoch 27, Step: 738, Loss: 0.1814912110567093, Lr:0.0001\n",
      "Epoch 27, Step: 739, Loss: 0.0026596728712320328, Lr:0.0001\n",
      "Epoch 27, Step: 740, Loss: 0.04617845267057419, Lr:0.0001\n",
      "Epoch 27, Step: 741, Loss: 0.0012173195136711001, Lr:0.0001\n",
      "Epoch 27, Step: 742, Loss: 0.14896681904792786, Lr:0.0001\n",
      "Epoch 27, Step: 743, Loss: 0.08072729408740997, Lr:0.0001\n",
      "Epoch 27, Step: 744, Loss: 0.0013663304271176457, Lr:0.0001\n",
      "Epoch 27, Step: 745, Loss: 0.01293732225894928, Lr:0.0001\n",
      "Epoch 27, Step: 746, Loss: 0.006476139649748802, Lr:0.0001\n",
      "Epoch 27, Step: 747, Loss: 0.026858258992433548, Lr:0.0001\n",
      "Epoch 27, Step: 748, Loss: 0.06395582854747772, Lr:0.0001\n",
      "Epoch 27, Step: 749, Loss: 0.17104856669902802, Lr:0.0001\n",
      "Epoch 27, Step: 750, Loss: 0.03279190883040428, Lr:0.0001\n",
      "Epoch 27, Step: 751, Loss: 0.08569474518299103, Lr:0.0001\n",
      "Epoch 27, Step: 752, Loss: 0.02560233883559704, Lr:0.0001\n",
      "Epoch 27, Step: 753, Loss: 0.004682278260588646, Lr:0.0001\n",
      "Epoch 27, Step: 754, Loss: 0.02475014142692089, Lr:0.0001\n",
      "Epoch 27, Step: 755, Loss: 0.0031202577520161867, Lr:0.0001\n",
      "Epoch 27, Step: 756, Loss: 0.03294207155704498, Lr:0.0001\n",
      "Epoch 27, Step: 757, Loss: 0.02970239147543907, Lr:0.0001\n",
      "Epoch 27, Step: 758, Loss: 0.023270748555660248, Lr:0.0001\n",
      "Epoch 27, Step: 759, Loss: 0.2389872521162033, Lr:0.0001\n",
      "Epoch 27, Step: 760, Loss: 0.018634462729096413, Lr:0.0001\n",
      "Epoch 27, Step: 761, Loss: 0.031098615378141403, Lr:0.0001\n",
      "Epoch 27, Step: 762, Loss: 0.05679107457399368, Lr:0.0001\n",
      "Epoch 27, Step: 763, Loss: 0.45204269886016846, Lr:0.0001\n",
      "Epoch 27, Step: 764, Loss: 0.17227217555046082, Lr:0.0001\n",
      "Epoch 27, Step: 765, Loss: 0.36238375306129456, Lr:0.0001\n",
      "Epoch 27, Step: 766, Loss: 0.015196165069937706, Lr:0.0001\n",
      "Epoch 27, Step: 767, Loss: 0.0014540764968842268, Lr:0.0001\n",
      "Epoch 27, Step: 768, Loss: 0.013942131772637367, Lr:0.0001\n",
      "Epoch 27, Step: 769, Loss: 0.31756356358528137, Lr:0.0001\n",
      "Epoch 27, Step: 770, Loss: 0.37658679485321045, Lr:0.0001\n",
      "Epoch 27, Step: 771, Loss: 0.06426887214183807, Lr:0.0001\n",
      "Epoch 27, Step: 772, Loss: 0.004831716418266296, Lr:0.0001\n",
      "Epoch 27, Step: 773, Loss: 0.09054003655910492, Lr:0.0001\n",
      "Epoch 27, Step: 774, Loss: 0.004936252720654011, Lr:0.0001\n",
      "Epoch 27, Step: 775, Loss: 0.05062223970890045, Lr:0.0001\n",
      "Epoch 27, Step: 776, Loss: 0.011781774461269379, Lr:0.0001\n",
      "Epoch 27, Step: 777, Loss: 0.048476725816726685, Lr:0.0001\n",
      "Epoch 27, Step: 778, Loss: 0.1789270043373108, Lr:0.0001\n",
      "Epoch 27, Step: 779, Loss: 0.2787071466445923, Lr:0.0001\n",
      "Epoch 27, Step: 780, Loss: 0.05486341565847397, Lr:0.0001\n",
      "Epoch 27, Step: 781, Loss: 0.03937789425253868, Lr:0.0001\n",
      "Epoch 27, Step: 782, Loss: 0.031152566894888878, Lr:0.0001\n",
      "Epoch 27, Step: 783, Loss: 0.06064470484852791, Lr:0.0001\n",
      "Epoch 27, Step: 784, Loss: 0.003248326014727354, Lr:0.0001\n",
      "Epoch 27, Step: 785, Loss: 0.01361307967454195, Lr:0.0001\n",
      "Epoch 27, Step: 786, Loss: 0.005786591209471226, Lr:0.0001\n",
      "Epoch 27, Step: 787, Loss: 0.01312639843672514, Lr:0.0001\n",
      "Epoch 27, Step: 788, Loss: 0.011047517880797386, Lr:0.0001\n",
      "Epoch 27, Step: 789, Loss: 0.08374905586242676, Lr:0.0001\n",
      "Epoch 27, Step: 790, Loss: 0.3471149504184723, Lr:0.0001\n",
      "Epoch 27, Step: 791, Loss: 0.041531700640916824, Lr:0.0001\n",
      "Epoch 27, Step: 792, Loss: 0.05950272083282471, Lr:0.0001\n",
      "Epoch 27, Step: 793, Loss: 0.11990311741828918, Lr:0.0001\n",
      "Epoch 27, Step: 794, Loss: 0.0037166443653404713, Lr:0.0001\n",
      "Epoch 27, Step: 795, Loss: 0.028476489707827568, Lr:0.0001\n",
      "Epoch 27, Step: 796, Loss: 0.0009346173028461635, Lr:0.0001\n",
      "Epoch 27, Step: 797, Loss: 0.002869930351153016, Lr:0.0001\n",
      "Epoch 27, Step: 798, Loss: 0.11361121386289597, Lr:0.0001\n",
      "Epoch 27, Step: 799, Loss: 0.005160302855074406, Lr:0.0001\n",
      "Epoch 27, Step: 800, Loss: 0.01807864010334015, Lr:0.0001\n",
      "Epoch 27, Step: 801, Loss: 0.19298525154590607, Lr:0.0001\n",
      "Epoch 27, Step: 802, Loss: 0.034359198063611984, Lr:0.0001\n",
      "Epoch 27, Step: 803, Loss: 0.005579684861004353, Lr:0.0001\n",
      "Epoch 27, Step: 804, Loss: 0.04676489159464836, Lr:0.0001\n",
      "Epoch 27, Step: 805, Loss: 0.014512244611978531, Lr:0.0001\n",
      "Epoch 27, Step: 806, Loss: 0.0030197256710380316, Lr:0.0001\n",
      "Epoch 27, Step: 807, Loss: 0.056395646184682846, Lr:0.0001\n",
      "Epoch 27, Step: 808, Loss: 0.01068622525781393, Lr:0.0001\n",
      "Epoch 27, Step: 809, Loss: 0.05306083336472511, Lr:0.0001\n",
      "Epoch 27, Step: 810, Loss: 0.0008439763332717121, Lr:0.0001\n",
      "Epoch 27, Step: 811, Loss: 0.05886704847216606, Lr:0.0001\n",
      "Epoch 27, Step: 812, Loss: 0.014838200062513351, Lr:0.0001\n",
      "Epoch 27, Step: 813, Loss: 0.03171735629439354, Lr:0.0001\n",
      "Epoch 27, Step: 814, Loss: 0.012989182025194168, Lr:0.0001\n",
      "Epoch 27, Step: 815, Loss: 0.020020082592964172, Lr:0.0001\n",
      "Epoch 27, Step: 816, Loss: 0.23283922672271729, Lr:0.0001\n",
      "Epoch 27, Step: 817, Loss: 0.22094060480594635, Lr:0.0001\n",
      "Epoch 27, Step: 818, Loss: 0.043921008706092834, Lr:0.0001\n",
      "Epoch 27, Step: 819, Loss: 0.092155821621418, Lr:0.0001\n",
      "Epoch 27, Step: 820, Loss: 0.17810772359371185, Lr:0.0001\n",
      "Epoch 27, Step: 821, Loss: 0.012837635353207588, Lr:0.0001\n",
      "Epoch 27, Step: 822, Loss: 0.024517305195331573, Lr:0.0001\n",
      "Epoch 27, Step: 823, Loss: 0.003870987333357334, Lr:0.0001\n",
      "Epoch 27, Step: 824, Loss: 0.26217949390411377, Lr:0.0001\n",
      "Epoch 27, Step: 825, Loss: 0.005183277651667595, Lr:0.0001\n",
      "Epoch 27, Step: 826, Loss: 0.009772306308150291, Lr:0.0001\n",
      "Epoch 27, Step: 827, Loss: 0.015713777393102646, Lr:0.0001\n",
      "Epoch 27, Step: 828, Loss: 0.05186958611011505, Lr:0.0001\n",
      "Epoch 27, Step: 829, Loss: 0.1636577993631363, Lr:0.0001\n",
      "Epoch 27, Step: 830, Loss: 0.01611490175127983, Lr:0.0001\n",
      "Epoch 27, Step: 831, Loss: 0.023219622671604156, Lr:0.0001\n",
      "Epoch 27, Step: 832, Loss: 0.05293632298707962, Lr:0.0001\n",
      "Epoch 27, Step: 833, Loss: 0.10404432564973831, Lr:0.0001\n",
      "Epoch 27, Step: 834, Loss: 0.012362931855022907, Lr:0.0001\n",
      "Epoch 27, Step: 835, Loss: 0.0132253123447299, Lr:0.0001\n",
      "Epoch 27, Step: 836, Loss: 0.08357936143875122, Lr:0.0001\n",
      "Epoch 27, Step: 837, Loss: 0.04414801672101021, Lr:0.0001\n",
      "Epoch 27, Step: 838, Loss: 0.031776029616594315, Lr:0.0001\n",
      "Epoch 27, Step: 839, Loss: 0.13060182332992554, Lr:0.0001\n",
      "Epoch 27, Step: 840, Loss: 0.049555424600839615, Lr:0.0001\n",
      "Epoch 27, Step: 841, Loss: 0.0256015844643116, Lr:0.0001\n",
      "Epoch 27, Step: 842, Loss: 0.060047220438718796, Lr:0.0001\n",
      "Epoch 27, Step: 843, Loss: 0.09467513114213943, Lr:0.0001\n",
      "Epoch 27, Step: 844, Loss: 0.17887352406978607, Lr:0.0001\n",
      "Epoch 27, Step: 845, Loss: 0.022395841777324677, Lr:0.0001\n",
      "Epoch 27, Step: 846, Loss: 0.22183966636657715, Lr:0.0001\n",
      "Epoch 27, Step: 847, Loss: 0.19361338019371033, Lr:0.0001\n",
      "Epoch 27, Step: 848, Loss: 0.07861112058162689, Lr:0.0001\n",
      "Epoch 27, Step: 849, Loss: 0.04069599509239197, Lr:0.0001\n",
      "Epoch 27, Step: 850, Loss: 0.04093090444803238, Lr:0.0001\n",
      "Epoch 27, Step: 851, Loss: 0.031407274305820465, Lr:0.0001\n",
      "Epoch 27, Step: 852, Loss: 0.15683498978614807, Lr:0.0001\n",
      "Epoch 27, Step: 853, Loss: 0.0436699353158474, Lr:0.0001\n",
      "Epoch 27, Step: 854, Loss: 0.08711070567369461, Lr:0.0001\n",
      "Epoch 27, Step: 855, Loss: 0.015219137072563171, Lr:0.0001\n",
      "Epoch 27, Step: 856, Loss: 0.10162647813558578, Lr:0.0001\n",
      "Epoch 27, Step: 857, Loss: 0.011681358329951763, Lr:0.0001\n",
      "Epoch 27, Step: 858, Loss: 0.003594758687540889, Lr:0.0001\n",
      "Epoch 27, Step: 859, Loss: 0.035678546875715256, Lr:0.0001\n",
      "Epoch 27, Step: 860, Loss: 0.00012866528413724154, Lr:0.0001\n",
      "Epoch 27, Step: 861, Loss: 0.049817584455013275, Lr:0.0001\n",
      "Epoch 27, Step: 862, Loss: 0.031362779438495636, Lr:0.0001\n",
      "Epoch 27, Step: 863, Loss: 0.024139404296875, Lr:0.0001\n",
      "Epoch 27, Step: 864, Loss: 0.25308072566986084, Lr:0.0001\n",
      "Epoch 27, Step: 865, Loss: 0.0064656101167202, Lr:0.0001\n",
      "Epoch 27, Step: 866, Loss: 0.006475495174527168, Lr:0.0001\n",
      "Epoch 27, Step: 867, Loss: 0.03549792245030403, Lr:0.0001\n",
      "Epoch 27, Step: 868, Loss: 0.1881166249513626, Lr:0.0001\n",
      "Epoch 27, Step: 869, Loss: 0.10530790686607361, Lr:0.0001\n",
      "Epoch 27, Step: 870, Loss: 0.017515474930405617, Lr:0.0001\n",
      "Epoch 27, Step: 871, Loss: 0.010793673805892467, Lr:0.0001\n",
      "Epoch 27, Step: 872, Loss: 0.03293148800730705, Lr:0.0001\n",
      "Epoch 27, Step: 873, Loss: 0.029666351154446602, Lr:0.0001\n",
      "Epoch 27, Step: 874, Loss: 0.0012471572263166308, Lr:0.0001\n",
      "Epoch 27, Step: 875, Loss: 0.04159366711974144, Lr:0.0001\n",
      "Epoch 27, Step: 876, Loss: 0.15160435438156128, Lr:0.0001\n",
      "Epoch 27, Step: 877, Loss: 0.04671604931354523, Lr:0.0001\n",
      "Epoch 27, Step: 878, Loss: 0.08338534832000732, Lr:0.0001\n",
      "Epoch 27, Step: 879, Loss: 0.06821853667497635, Lr:0.0001\n",
      "Epoch 27, Step: 880, Loss: 0.03395606204867363, Lr:0.0001\n",
      "Epoch 27, Step: 881, Loss: 0.07183360308408737, Lr:0.0001\n",
      "Epoch 27, Step: 882, Loss: 0.0067460499703884125, Lr:0.0001\n",
      "Epoch 27, Step: 883, Loss: 0.05162738636136055, Lr:0.0001\n",
      "Epoch 27, Step: 884, Loss: 0.0018117163563147187, Lr:0.0001\n",
      "Epoch 27, Step: 885, Loss: 0.0967613160610199, Lr:0.0001\n",
      "Epoch 27, Step: 886, Loss: 0.006582295522093773, Lr:0.0001\n",
      "Epoch 27, Step: 887, Loss: 0.002980973804369569, Lr:0.0001\n",
      "Epoch 27, Step: 888, Loss: 0.33242738246917725, Lr:0.0001\n",
      "Epoch 27, Step: 889, Loss: 0.07791993021965027, Lr:0.0001\n",
      "Epoch 27, Step: 890, Loss: 0.026911277323961258, Lr:0.0001\n",
      "Epoch 27, Step: 891, Loss: 0.07057911902666092, Lr:0.0001\n",
      "Epoch 27, Step: 892, Loss: 0.25670063495635986, Lr:0.0001\n",
      "Epoch 27, Step: 893, Loss: 0.042656805366277695, Lr:0.0001\n",
      "Epoch 27, Step: 894, Loss: 0.011157515458762646, Lr:0.0001\n",
      "Epoch 27, Step: 895, Loss: 0.004236864857375622, Lr:0.0001\n",
      "Epoch 27, Step: 896, Loss: 0.010228472761809826, Lr:0.0001\n",
      "Epoch 27, Step: 897, Loss: 0.2657648026943207, Lr:0.0001\n",
      "Epoch 27, Step: 898, Loss: 0.1933465600013733, Lr:0.0001\n",
      "Epoch 27, Step: 899, Loss: 0.11418387293815613, Lr:0.0001\n",
      "Epoch 27, Step: 900, Loss: 0.03460720553994179, Lr:0.0001\n",
      "Epoch 27, Step: 901, Loss: 0.030974511057138443, Lr:0.0001\n",
      "Epoch 27, Step: 902, Loss: 0.0036673275753855705, Lr:0.0001\n",
      "Epoch 27, Step: 903, Loss: 0.022575918585062027, Lr:0.0001\n",
      "Epoch 27, Step: 904, Loss: 0.026038451120257378, Lr:0.0001\n",
      "Epoch 27, Step: 905, Loss: 0.0030620472971349955, Lr:0.0001\n",
      "Epoch 27, Step: 906, Loss: 0.017756232991814613, Lr:0.0001\n",
      "Epoch 27, Step: 907, Loss: 0.04512893781065941, Lr:0.0001\n",
      "Epoch 27, Step: 908, Loss: 0.008708334527909756, Lr:0.0001\n",
      "Epoch 27, Step: 909, Loss: 0.1710372418165207, Lr:0.0001\n",
      "Epoch 27, Step: 910, Loss: 0.01575237326323986, Lr:0.0001\n",
      "Epoch 27, Step: 911, Loss: 0.0017043872503563762, Lr:0.0001\n",
      "Epoch 27, Step: 912, Loss: 0.21109125018119812, Lr:0.0001\n",
      "Epoch 27, Step: 913, Loss: 0.012434336356818676, Lr:0.0001\n",
      "Epoch 27, Step: 914, Loss: 0.024326829239726067, Lr:0.0001\n",
      "Epoch 27, Step: 915, Loss: 0.009505072608590126, Lr:0.0001\n",
      "Epoch 27, Step: 916, Loss: 0.002535619307309389, Lr:0.0001\n",
      "Epoch 27, Step: 917, Loss: 0.006558756809681654, Lr:0.0001\n",
      "Epoch 27, Step: 918, Loss: 0.009801712818443775, Lr:0.0001\n",
      "Epoch 27, Step: 919, Loss: 0.05686293914914131, Lr:0.0001\n",
      "Epoch 27, Step: 920, Loss: 0.04257110133767128, Lr:0.0001\n",
      "Epoch 27, Step: 921, Loss: 0.006948912050575018, Lr:0.0001\n",
      "Epoch 27, Step: 922, Loss: 0.1623051017522812, Lr:0.0001\n",
      "Epoch 27, Step: 923, Loss: 0.025982458144426346, Lr:0.0001\n",
      "Epoch 27, Step: 924, Loss: 0.002715465845540166, Lr:0.0001\n",
      "Epoch 27, Step: 925, Loss: 0.07283931225538254, Lr:0.0001\n",
      "Epoch 27, Step: 926, Loss: 0.021435072645545006, Lr:0.0001\n",
      "Epoch 27, Step: 927, Loss: 0.04299458488821983, Lr:0.0001\n",
      "Epoch 27, Step: 928, Loss: 0.3705528676509857, Lr:0.0001\n",
      "Epoch 27, Step: 929, Loss: 0.002434931928291917, Lr:0.0001\n",
      "Epoch 27, Step: 930, Loss: 0.07176781445741653, Lr:0.0001\n",
      "Epoch 27, Step: 931, Loss: 0.003861082950606942, Lr:0.0001\n",
      "Epoch 27, Step: 932, Loss: 0.031279630959033966, Lr:0.0001\n",
      "Epoch 27, Step: 933, Loss: 0.17203254997730255, Lr:0.0001\n",
      "Epoch 27, Step: 934, Loss: 0.029824232682585716, Lr:0.0001\n",
      "Epoch 27, Step: 935, Loss: 0.01650836504995823, Lr:0.0001\n",
      "Epoch 27, Step: 936, Loss: 0.12746673822402954, Lr:0.0001\n",
      "Epoch 27, Step: 937, Loss: 0.058428969234228134, Lr:0.0001\n",
      "Epoch 27, Step: 938, Loss: 0.12134593725204468, Lr:0.0001\n",
      "Epoch 27, Step: 939, Loss: 0.024650122970342636, Lr:0.0001\n",
      "Epoch 27, Step: 940, Loss: 0.2017493098974228, Lr:0.0001\n",
      "Epoch 27, Step: 941, Loss: 0.15524117648601532, Lr:0.0001\n",
      "Epoch 27, Step: 942, Loss: 0.03108033910393715, Lr:0.0001\n",
      "Epoch 27, Step: 943, Loss: 0.02058158814907074, Lr:0.0001\n",
      "Epoch 27, Step: 944, Loss: 0.29318973422050476, Lr:0.0001\n",
      "Epoch 27, Step: 945, Loss: 0.17295433580875397, Lr:0.0001\n",
      "Epoch 27, Step: 946, Loss: 0.036747146397829056, Lr:0.0001\n",
      "Epoch 27, Step: 947, Loss: 0.04500662535429001, Lr:0.0001\n",
      "Epoch 27, Step: 948, Loss: 0.1224493756890297, Lr:0.0001\n",
      "Epoch 27, Step: 949, Loss: 0.041667066514492035, Lr:0.0001\n",
      "Epoch 27, Step: 950, Loss: 0.29616183042526245, Lr:0.0001\n",
      "Epoch 27, Step: 951, Loss: 0.06417521089315414, Lr:0.0001\n",
      "Epoch 27, Step: 952, Loss: 0.16846832633018494, Lr:0.0001\n",
      "Epoch 27, Step: 953, Loss: 0.06832091510295868, Lr:0.0001\n",
      "Epoch 27, Step: 954, Loss: 0.2978367805480957, Lr:0.0001\n",
      "Epoch 27, Step: 955, Loss: 0.019552966579794884, Lr:0.0001\n",
      "Epoch 27, Step: 956, Loss: 0.0633934885263443, Lr:0.0001\n",
      "Epoch 27, Step: 957, Loss: 0.04657727852463722, Lr:0.0001\n",
      "Epoch 27, Step: 958, Loss: 0.006983842700719833, Lr:0.0001\n",
      "Epoch 27, Step: 959, Loss: 0.09807998687028885, Lr:0.0001\n",
      "Epoch 27, Step: 960, Loss: 0.09574177861213684, Lr:0.0001\n",
      "Epoch 27, Step: 961, Loss: 0.08221197873353958, Lr:0.0001\n",
      "Epoch 27, Step: 962, Loss: 0.060214050114154816, Lr:0.0001\n",
      "Epoch 27, Step: 963, Loss: 0.004123833030462265, Lr:0.0001\n",
      "Epoch 27, Step: 964, Loss: 0.09592439979314804, Lr:0.0001\n",
      "Epoch 27, Step: 965, Loss: 0.16822467744350433, Lr:0.0001\n",
      "Epoch 27, Step: 966, Loss: 0.1414899230003357, Lr:0.0001\n",
      "Epoch 27, Step: 967, Loss: 0.11384132504463196, Lr:0.0001\n",
      "Epoch 27, Step: 968, Loss: 0.058951485902071, Lr:0.0001\n",
      "Epoch 27, Step: 969, Loss: 0.036464281380176544, Lr:0.0001\n",
      "Epoch 27, Step: 970, Loss: 0.21641242504119873, Lr:0.0001\n",
      "Epoch 27, Step: 971, Loss: 0.018549520522356033, Lr:0.0001\n",
      "Epoch 27, Step: 972, Loss: 0.005948063917458057, Lr:0.0001\n",
      "Epoch 27, Step: 973, Loss: 0.18334409594535828, Lr:0.0001\n",
      "Epoch 27, Step: 974, Loss: 0.014344614930450916, Lr:0.0001\n",
      "Epoch 27, Step: 975, Loss: 0.08772217482328415, Lr:0.0001\n",
      "Epoch 27, Step: 976, Loss: 0.024608101695775986, Lr:0.0001\n",
      "Epoch 27, Step: 977, Loss: 0.004245581571012735, Lr:0.0001\n",
      "Epoch 27, Step: 978, Loss: 0.05082754045724869, Lr:0.0001\n",
      "Epoch 27, Step: 979, Loss: 0.02492288313806057, Lr:0.0001\n",
      "Epoch 27, Step: 980, Loss: 0.06731598824262619, Lr:0.0001\n",
      "Epoch 27, Step: 981, Loss: 0.006448281463235617, Lr:0.0001\n",
      "Epoch 27, Step: 982, Loss: 0.1611187607049942, Lr:0.0001\n",
      "Epoch 27, Step: 983, Loss: 0.10232111811637878, Lr:0.0001\n",
      "Epoch 27, Step: 984, Loss: 0.09362184256315231, Lr:0.0001\n",
      "Epoch 27, Step: 985, Loss: 0.001953359693288803, Lr:0.0001\n",
      "Epoch 27, Step: 986, Loss: 0.0625450611114502, Lr:0.0001\n",
      "Epoch 27, Step: 987, Loss: 0.007994886487722397, Lr:0.0001\n",
      "Epoch 27, Step: 988, Loss: 0.03258347138762474, Lr:0.0001\n",
      "Epoch 27, Step: 989, Loss: 0.14986570179462433, Lr:0.0001\n",
      "Epoch 27, Step: 990, Loss: 0.14042627811431885, Lr:0.0001\n",
      "Epoch 27, Step: 991, Loss: 0.03276580944657326, Lr:0.0001\n",
      "Epoch 27, Step: 992, Loss: 0.14248357713222504, Lr:0.0001\n",
      "Epoch 27, Step: 993, Loss: 0.15997952222824097, Lr:0.0001\n",
      "Epoch 27, Step: 994, Loss: 0.049140918999910355, Lr:0.0001\n",
      "Epoch 27, Step: 995, Loss: 0.006168642081320286, Lr:0.0001\n",
      "Epoch 27, Step: 996, Loss: 0.036921072751283646, Lr:0.0001\n",
      "Epoch 27, Step: 997, Loss: 0.18914955854415894, Lr:0.0001\n",
      "Epoch 27, Step: 998, Loss: 0.022250615060329437, Lr:0.0001\n",
      "Epoch 27, Step: 999, Loss: 0.006191418971866369, Lr:0.0001\n",
      "Epoch 27, Step: 1000, Loss: 0.004035436548292637, Lr:0.0001\n",
      "Epoch 27, Step: 1001, Loss: 0.05349412187933922, Lr:0.0001\n",
      "Epoch 27, Step: 1002, Loss: 0.05146859213709831, Lr:0.0001\n",
      "Epoch 27, Step: 1003, Loss: 0.03285115957260132, Lr:0.0001\n",
      "Epoch 27, Step: 1004, Loss: 0.015953753143548965, Lr:0.0001\n",
      "Epoch 27, Step: 1005, Loss: 0.07098668813705444, Lr:0.0001\n",
      "Epoch 27, Step: 1006, Loss: 0.0018644920783117414, Lr:0.0001\n",
      "Epoch 27, Step: 1007, Loss: 0.02360694669187069, Lr:0.0001\n",
      "Epoch 27, Step: 1008, Loss: 0.012663766741752625, Lr:0.0001\n",
      "Epoch 27, Step: 1009, Loss: 0.055229440331459045, Lr:0.0001\n",
      "Epoch 27, Step: 1010, Loss: 0.02044716663658619, Lr:0.0001\n",
      "Epoch 27, Step: 1011, Loss: 0.01943846233189106, Lr:0.0001\n",
      "Epoch 27, Step: 1012, Loss: 0.09051715582609177, Lr:0.0001\n",
      "Epoch 27, Step: 1013, Loss: 0.004484797362238169, Lr:0.0001\n",
      "Epoch 27, Step: 1014, Loss: 0.15897059440612793, Lr:0.0001\n",
      "Epoch 27, Step: 1015, Loss: 0.04701422527432442, Lr:0.0001\n",
      "Epoch 27, Step: 1016, Loss: 0.028743568807840347, Lr:0.0001\n",
      "Epoch 27, Step: 1017, Loss: 0.030401481315493584, Lr:0.0001\n",
      "Epoch 27, Step: 1018, Loss: 0.02258155308663845, Lr:0.0001\n",
      "Epoch 27, Step: 1019, Loss: 0.001775053795427084, Lr:0.0001\n",
      "Epoch 27, Step: 1020, Loss: 0.004197658505290747, Lr:0.0001\n",
      "Epoch 27, Step: 1021, Loss: 0.0037229745648801327, Lr:0.0001\n",
      "Epoch 27, Step: 1022, Loss: 0.07459507137537003, Lr:0.0001\n",
      "Epoch 27, Step: 1023, Loss: 0.01314549334347248, Lr:0.0001\n",
      "Epoch 27, Step: 1024, Loss: 0.1804898977279663, Lr:0.0001\n",
      "Epoch 27, Step: 1025, Loss: 0.04304121062159538, Lr:0.0001\n",
      "Epoch 27, Step: 1026, Loss: 0.0044250888749957085, Lr:0.0001\n",
      "Epoch 27, Step: 1027, Loss: 0.06322398781776428, Lr:0.0001\n",
      "Epoch 27, Step: 1028, Loss: 0.004263317212462425, Lr:0.0001\n",
      "Epoch 27, Step: 1029, Loss: 0.054441310465335846, Lr:0.0001\n",
      "Epoch 27, Step: 1030, Loss: 0.009073680266737938, Lr:0.0001\n",
      "Epoch 27, Step: 1031, Loss: 0.018178580328822136, Lr:0.0001\n",
      "Epoch 27, Step: 1032, Loss: 0.06740228086709976, Lr:0.0001\n",
      "Epoch 27, Step: 1033, Loss: 0.020074358209967613, Lr:0.0001\n",
      "Epoch 27, Step: 1034, Loss: 0.0012050126679241657, Lr:0.0001\n",
      "Epoch 27, Step: 1035, Loss: 0.001979316119104624, Lr:0.0001\n",
      "Epoch 27, Step: 1036, Loss: 0.09771709889173508, Lr:0.0001\n",
      "Epoch 27, Step: 1037, Loss: 0.05456509068608284, Lr:0.0001\n",
      "Epoch 27, Step: 1038, Loss: 0.1255517303943634, Lr:0.0001\n",
      "Epoch 27, Step: 1039, Loss: 0.01663990505039692, Lr:0.0001\n",
      "Epoch 27, Step: 1040, Loss: 0.14336779713630676, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 27\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:16 loss: 0.0123 (0.0123) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.2946 data: 0.1166 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:14 loss: 0.0006 (0.0114) acc1: 100.0000 (99.4318) acc5: 100.0000 (100.0000) time: 0.3053 data: 0.1188 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:11 loss: 0.0006 (0.0193) acc1: 100.0000 (99.1071) acc5: 100.0000 (100.0000) time: 0.3123 data: 0.1199 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:08 loss: 0.0251 (0.0694) acc1: 100.0000 (97.1774) acc5: 100.0000 (100.0000) time: 0.3122 data: 0.1203 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.1762 (0.1115) acc1: 93.7500 (96.6463) acc5: 100.0000 (100.0000) time: 0.3057 data: 0.1226 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0912 (0.1130) acc1: 93.7500 (96.4461) acc5: 100.0000 (100.0000) time: 0.3112 data: 0.1263 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0103 (0.1154) acc1: 100.0000 (96.1407) acc5: 100.0000 (100.0000) time: 0.2971 data: 0.1212 max mem: 15137\n",
      "Test: Total time: 0:00:17 (0.3053 s / it)\n",
      "* Acc@1 96.141 Acc@5 100.000 loss 0.115\n",
      "Accuracy of the network on the 881 test image: 96.1%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 28, Step: 0, Loss: 0.029923278838396072, Lr:0.0001\n",
      "Epoch 28, Step: 1, Loss: 0.020109277218580246, Lr:0.0001\n",
      "Epoch 28, Step: 2, Loss: 0.0761270523071289, Lr:0.0001\n",
      "Epoch 28, Step: 3, Loss: 0.0034252889454364777, Lr:0.0001\n",
      "Epoch 28, Step: 4, Loss: 0.1246526688337326, Lr:0.0001\n",
      "Epoch 28, Step: 5, Loss: 0.026255793869495392, Lr:0.0001\n",
      "Epoch 28, Step: 6, Loss: 0.003047470236197114, Lr:0.0001\n",
      "Epoch 28, Step: 7, Loss: 0.0008639573352411389, Lr:0.0001\n",
      "Epoch 28, Step: 8, Loss: 0.12088184058666229, Lr:0.0001\n",
      "Epoch 28, Step: 9, Loss: 0.196170836687088, Lr:0.0001\n",
      "Epoch 28, Step: 10, Loss: 0.0009333543130196631, Lr:0.0001\n",
      "Epoch 28, Step: 11, Loss: 0.02050570212304592, Lr:0.0001\n",
      "Epoch 28, Step: 12, Loss: 0.13332821428775787, Lr:0.0001\n",
      "Epoch 28, Step: 13, Loss: 0.010276636108756065, Lr:0.0001\n",
      "Epoch 28, Step: 14, Loss: 0.08460380882024765, Lr:0.0001\n",
      "Epoch 28, Step: 15, Loss: 0.001994046848267317, Lr:0.0001\n",
      "Epoch 28, Step: 16, Loss: 0.12265558540821075, Lr:0.0001\n",
      "Epoch 28, Step: 17, Loss: 0.18177688121795654, Lr:0.0001\n",
      "Epoch 28, Step: 18, Loss: 0.19540292024612427, Lr:0.0001\n",
      "Epoch 28, Step: 19, Loss: 0.31090232729911804, Lr:0.0001\n",
      "Epoch 28, Step: 20, Loss: 0.12055490165948868, Lr:0.0001\n",
      "Epoch 28, Step: 21, Loss: 0.009171733632683754, Lr:0.0001\n",
      "Epoch 28, Step: 22, Loss: 0.09666077047586441, Lr:0.0001\n",
      "Epoch 28, Step: 23, Loss: 0.08613452315330505, Lr:0.0001\n",
      "Epoch 28, Step: 24, Loss: 0.0022468704264611006, Lr:0.0001\n",
      "Epoch 28, Step: 25, Loss: 0.013248366303741932, Lr:0.0001\n",
      "Epoch 28, Step: 26, Loss: 0.0467984601855278, Lr:0.0001\n",
      "Epoch 28, Step: 27, Loss: 0.011345462873578072, Lr:0.0001\n",
      "Epoch 28, Step: 28, Loss: 0.015218392945826054, Lr:0.0001\n",
      "Epoch 28, Step: 29, Loss: 0.08656080812215805, Lr:0.0001\n",
      "Epoch 28, Step: 30, Loss: 0.03362505882978439, Lr:0.0001\n",
      "Epoch 28, Step: 31, Loss: 0.0004609388706739992, Lr:0.0001\n",
      "Epoch 28, Step: 32, Loss: 0.042631808668375015, Lr:0.0001\n",
      "Epoch 28, Step: 33, Loss: 0.025751130655407906, Lr:0.0001\n",
      "Epoch 28, Step: 34, Loss: 0.17596302926540375, Lr:0.0001\n",
      "Epoch 28, Step: 35, Loss: 0.09871521592140198, Lr:0.0001\n",
      "Epoch 28, Step: 36, Loss: 0.3340297043323517, Lr:0.0001\n",
      "Epoch 28, Step: 37, Loss: 0.07654977589845657, Lr:0.0001\n",
      "Epoch 28, Step: 38, Loss: 0.005418015643954277, Lr:0.0001\n",
      "Epoch 28, Step: 39, Loss: 0.02519204095005989, Lr:0.0001\n",
      "Epoch 28, Step: 40, Loss: 0.07254970818758011, Lr:0.0001\n",
      "Epoch 28, Step: 41, Loss: 0.18832287192344666, Lr:0.0001\n",
      "Epoch 28, Step: 42, Loss: 0.0032206373289227486, Lr:0.0001\n",
      "Epoch 28, Step: 43, Loss: 0.01662334054708481, Lr:0.0001\n",
      "Epoch 28, Step: 44, Loss: 0.019682785496115685, Lr:0.0001\n",
      "Epoch 28, Step: 45, Loss: 0.04240283742547035, Lr:0.0001\n",
      "Epoch 28, Step: 46, Loss: 0.12331899255514145, Lr:0.0001\n",
      "Epoch 28, Step: 47, Loss: 0.011426279321312904, Lr:0.0001\n",
      "Epoch 28, Step: 48, Loss: 0.05383234843611717, Lr:0.0001\n",
      "Epoch 28, Step: 49, Loss: 0.0009424422169104218, Lr:0.0001\n",
      "Epoch 28, Step: 50, Loss: 0.05196426063776016, Lr:0.0001\n",
      "Epoch 28, Step: 51, Loss: 0.049121491611003876, Lr:0.0001\n",
      "Epoch 28, Step: 52, Loss: 0.005638452246785164, Lr:0.0001\n",
      "Epoch 28, Step: 53, Loss: 0.1453671008348465, Lr:0.0001\n",
      "Epoch 28, Step: 54, Loss: 0.002884950954467058, Lr:0.0001\n",
      "Epoch 28, Step: 55, Loss: 0.04771720618009567, Lr:0.0001\n",
      "Epoch 28, Step: 56, Loss: 0.001246945234015584, Lr:0.0001\n",
      "Epoch 28, Step: 57, Loss: 0.00199254066683352, Lr:0.0001\n",
      "Epoch 28, Step: 58, Loss: 0.1468159258365631, Lr:0.0001\n",
      "Epoch 28, Step: 59, Loss: 0.01373139675706625, Lr:0.0001\n",
      "Epoch 28, Step: 60, Loss: 0.014803579077124596, Lr:0.0001\n",
      "Epoch 28, Step: 61, Loss: 0.015748243778944016, Lr:0.0001\n",
      "Epoch 28, Step: 62, Loss: 0.3363511562347412, Lr:0.0001\n",
      "Epoch 28, Step: 63, Loss: 0.003472674870863557, Lr:0.0001\n",
      "Epoch 28, Step: 64, Loss: 0.02588053233921528, Lr:0.0001\n",
      "Epoch 28, Step: 65, Loss: 0.0066898176446557045, Lr:0.0001\n",
      "Epoch 28, Step: 66, Loss: 0.09184291958808899, Lr:0.0001\n",
      "Epoch 28, Step: 67, Loss: 0.00027217608294449747, Lr:0.0001\n",
      "Epoch 28, Step: 68, Loss: 0.012501135468482971, Lr:0.0001\n",
      "Epoch 28, Step: 69, Loss: 0.007133204955607653, Lr:0.0001\n",
      "Epoch 28, Step: 70, Loss: 0.03469400480389595, Lr:0.0001\n",
      "Epoch 28, Step: 71, Loss: 0.0487699918448925, Lr:0.0001\n",
      "Epoch 28, Step: 72, Loss: 0.15229623019695282, Lr:0.0001\n",
      "Epoch 28, Step: 73, Loss: 0.13930636644363403, Lr:0.0001\n",
      "Epoch 28, Step: 74, Loss: 0.18814557790756226, Lr:0.0001\n",
      "Epoch 28, Step: 75, Loss: 0.049039747565984726, Lr:0.0001\n",
      "Epoch 28, Step: 76, Loss: 0.041943490505218506, Lr:0.0001\n",
      "Epoch 28, Step: 77, Loss: 0.06187709793448448, Lr:0.0001\n",
      "Epoch 28, Step: 78, Loss: 0.003136970568448305, Lr:0.0001\n",
      "Epoch 28, Step: 79, Loss: 0.023051276803016663, Lr:0.0001\n",
      "Epoch 28, Step: 80, Loss: 0.28162524104118347, Lr:0.0001\n",
      "Epoch 28, Step: 81, Loss: 0.19210973381996155, Lr:0.0001\n",
      "Epoch 28, Step: 82, Loss: 0.027228685095906258, Lr:0.0001\n",
      "Epoch 28, Step: 83, Loss: 0.015639031305909157, Lr:0.0001\n",
      "Epoch 28, Step: 84, Loss: 0.05381342023611069, Lr:0.0001\n",
      "Epoch 28, Step: 85, Loss: 0.020864110440015793, Lr:0.0001\n",
      "Epoch 28, Step: 86, Loss: 0.1398661881685257, Lr:0.0001\n",
      "Epoch 28, Step: 87, Loss: 0.05452137067914009, Lr:0.0001\n",
      "Epoch 28, Step: 88, Loss: 0.07956431061029434, Lr:0.0001\n",
      "Epoch 28, Step: 89, Loss: 0.13266333937644958, Lr:0.0001\n",
      "Epoch 28, Step: 90, Loss: 0.38850829005241394, Lr:0.0001\n",
      "Epoch 28, Step: 91, Loss: 0.03765790909528732, Lr:0.0001\n",
      "Epoch 28, Step: 92, Loss: 0.2594439685344696, Lr:0.0001\n",
      "Epoch 28, Step: 93, Loss: 0.07702426612377167, Lr:0.0001\n",
      "Epoch 28, Step: 94, Loss: 0.14142373204231262, Lr:0.0001\n",
      "Epoch 28, Step: 95, Loss: 0.02905425988137722, Lr:0.0001\n",
      "Epoch 28, Step: 96, Loss: 0.10851520299911499, Lr:0.0001\n",
      "Epoch 28, Step: 97, Loss: 0.0981869325041771, Lr:0.0001\n",
      "Epoch 28, Step: 98, Loss: 0.03855137899518013, Lr:0.0001\n",
      "Epoch 28, Step: 99, Loss: 0.009354871697723866, Lr:0.0001\n",
      "Epoch 28, Step: 100, Loss: 0.0038009220734238625, Lr:0.0001\n",
      "Epoch 28, Step: 101, Loss: 0.05332350730895996, Lr:0.0001\n",
      "Epoch 28, Step: 102, Loss: 0.005839396268129349, Lr:0.0001\n",
      "Epoch 28, Step: 103, Loss: 0.01832784339785576, Lr:0.0001\n",
      "Epoch 28, Step: 104, Loss: 0.023702843114733696, Lr:0.0001\n",
      "Epoch 28, Step: 105, Loss: 0.04959270358085632, Lr:0.0001\n",
      "Epoch 28, Step: 106, Loss: 0.05492502078413963, Lr:0.0001\n",
      "Epoch 28, Step: 107, Loss: 0.047171298414468765, Lr:0.0001\n",
      "Epoch 28, Step: 108, Loss: 0.05805783346295357, Lr:0.0001\n",
      "Epoch 28, Step: 109, Loss: 0.04019201174378395, Lr:0.0001\n",
      "Epoch 28, Step: 110, Loss: 0.047948237508535385, Lr:0.0001\n",
      "Epoch 28, Step: 111, Loss: 0.005531892646104097, Lr:0.0001\n",
      "Epoch 28, Step: 112, Loss: 0.014100891537964344, Lr:0.0001\n",
      "Epoch 28, Step: 113, Loss: 0.1191508024930954, Lr:0.0001\n",
      "Epoch 28, Step: 114, Loss: 0.04956008866429329, Lr:0.0001\n",
      "Epoch 28, Step: 115, Loss: 0.03302842006087303, Lr:0.0001\n",
      "Epoch 28, Step: 116, Loss: 0.0775475725531578, Lr:0.0001\n",
      "Epoch 28, Step: 117, Loss: 0.11157823354005814, Lr:0.0001\n",
      "Epoch 28, Step: 118, Loss: 0.10824766755104065, Lr:0.0001\n",
      "Epoch 28, Step: 119, Loss: 0.03556937351822853, Lr:0.0001\n",
      "Epoch 28, Step: 120, Loss: 0.0004233072977513075, Lr:0.0001\n",
      "Epoch 28, Step: 121, Loss: 0.054227542132139206, Lr:0.0001\n",
      "Epoch 28, Step: 122, Loss: 0.03696414828300476, Lr:0.0001\n",
      "Epoch 28, Step: 123, Loss: 0.010223275981843472, Lr:0.0001\n",
      "Epoch 28, Step: 124, Loss: 0.05021679773926735, Lr:0.0001\n",
      "Epoch 28, Step: 125, Loss: 0.09746169298887253, Lr:0.0001\n",
      "Epoch 28, Step: 126, Loss: 0.022840918973088264, Lr:0.0001\n",
      "Epoch 28, Step: 127, Loss: 0.0008975480450317264, Lr:0.0001\n",
      "Epoch 28, Step: 128, Loss: 0.0015333257615566254, Lr:0.0001\n",
      "Epoch 28, Step: 129, Loss: 0.00828447937965393, Lr:0.0001\n",
      "Epoch 28, Step: 130, Loss: 0.010119354352355003, Lr:0.0001\n",
      "Epoch 28, Step: 131, Loss: 0.0005165329785086215, Lr:0.0001\n",
      "Epoch 28, Step: 132, Loss: 0.031718600541353226, Lr:0.0001\n",
      "Epoch 28, Step: 133, Loss: 0.055414486676454544, Lr:0.0001\n",
      "Epoch 28, Step: 134, Loss: 0.0549502819776535, Lr:0.0001\n",
      "Epoch 28, Step: 135, Loss: 0.014577856287360191, Lr:0.0001\n",
      "Epoch 28, Step: 136, Loss: 0.00719742476940155, Lr:0.0001\n",
      "Epoch 28, Step: 137, Loss: 0.09984103590250015, Lr:0.0001\n",
      "Epoch 28, Step: 138, Loss: 0.00488663325086236, Lr:0.0001\n",
      "Epoch 28, Step: 139, Loss: 0.04139333963394165, Lr:0.0001\n",
      "Epoch 28, Step: 140, Loss: 0.0008848414872772992, Lr:0.0001\n",
      "Epoch 28, Step: 141, Loss: 0.13977128267288208, Lr:0.0001\n",
      "Epoch 28, Step: 142, Loss: 0.012283951975405216, Lr:0.0001\n",
      "Epoch 28, Step: 143, Loss: 0.15357159078121185, Lr:0.0001\n",
      "Epoch 28, Step: 144, Loss: 0.03062431700527668, Lr:0.0001\n",
      "Epoch 28, Step: 145, Loss: 0.03863942250609398, Lr:0.0001\n",
      "Epoch 28, Step: 146, Loss: 0.002913301344960928, Lr:0.0001\n",
      "Epoch 28, Step: 147, Loss: 0.14945663511753082, Lr:0.0001\n",
      "Epoch 28, Step: 148, Loss: 0.15281492471694946, Lr:0.0001\n",
      "Epoch 28, Step: 149, Loss: 0.13735263049602509, Lr:0.0001\n",
      "Epoch 28, Step: 150, Loss: 0.008878787979483604, Lr:0.0001\n",
      "Epoch 28, Step: 151, Loss: 0.03194927051663399, Lr:0.0001\n",
      "Epoch 28, Step: 152, Loss: 0.08651741594076157, Lr:0.0001\n",
      "Epoch 28, Step: 153, Loss: 0.005485350266098976, Lr:0.0001\n",
      "Epoch 28, Step: 154, Loss: 0.017919108271598816, Lr:0.0001\n",
      "Epoch 28, Step: 155, Loss: 0.0071125999093055725, Lr:0.0001\n",
      "Epoch 28, Step: 156, Loss: 0.0396805964410305, Lr:0.0001\n",
      "Epoch 28, Step: 157, Loss: 0.029248017817735672, Lr:0.0001\n",
      "Epoch 28, Step: 158, Loss: 0.007842679508030415, Lr:0.0001\n",
      "Epoch 28, Step: 159, Loss: 0.03228411823511124, Lr:0.0001\n",
      "Epoch 28, Step: 160, Loss: 0.012394120916724205, Lr:0.0001\n",
      "Epoch 28, Step: 161, Loss: 0.03186692297458649, Lr:0.0001\n",
      "Epoch 28, Step: 162, Loss: 0.03274567052721977, Lr:0.0001\n",
      "Epoch 28, Step: 163, Loss: 0.006793351843953133, Lr:0.0001\n",
      "Epoch 28, Step: 164, Loss: 0.1551866978406906, Lr:0.0001\n",
      "Epoch 28, Step: 165, Loss: 0.005411731544882059, Lr:0.0001\n",
      "Epoch 28, Step: 166, Loss: 0.023911744356155396, Lr:0.0001\n",
      "Epoch 28, Step: 167, Loss: 0.0241473987698555, Lr:0.0001\n",
      "Epoch 28, Step: 168, Loss: 0.0610048733651638, Lr:0.0001\n",
      "Epoch 28, Step: 169, Loss: 0.012348429299890995, Lr:0.0001\n",
      "Epoch 28, Step: 170, Loss: 0.062759630382061, Lr:0.0001\n",
      "Epoch 28, Step: 171, Loss: 0.03931455314159393, Lr:0.0001\n",
      "Epoch 28, Step: 172, Loss: 0.005364457610994577, Lr:0.0001\n",
      "Epoch 28, Step: 173, Loss: 0.024639494717121124, Lr:0.0001\n",
      "Epoch 28, Step: 174, Loss: 0.04965861141681671, Lr:0.0001\n",
      "Epoch 28, Step: 175, Loss: 0.021257441490888596, Lr:0.0001\n",
      "Epoch 28, Step: 176, Loss: 0.005151108372956514, Lr:0.0001\n",
      "Epoch 28, Step: 177, Loss: 0.007880192250013351, Lr:0.0001\n",
      "Epoch 28, Step: 178, Loss: 0.042475949972867966, Lr:0.0001\n",
      "Epoch 28, Step: 179, Loss: 0.026609424501657486, Lr:0.0001\n",
      "Epoch 28, Step: 180, Loss: 0.03507443144917488, Lr:0.0001\n",
      "Epoch 28, Step: 181, Loss: 0.00813274271786213, Lr:0.0001\n",
      "Epoch 28, Step: 182, Loss: 0.032211434096097946, Lr:0.0001\n",
      "Epoch 28, Step: 183, Loss: 0.029650770127773285, Lr:0.0001\n",
      "Epoch 28, Step: 184, Loss: 0.04958637058734894, Lr:0.0001\n",
      "Epoch 28, Step: 185, Loss: 0.0015705167315900326, Lr:0.0001\n",
      "Epoch 28, Step: 186, Loss: 0.0100012281909585, Lr:0.0001\n",
      "Epoch 28, Step: 187, Loss: 0.10751878470182419, Lr:0.0001\n",
      "Epoch 28, Step: 188, Loss: 0.005919803865253925, Lr:0.0001\n",
      "Epoch 28, Step: 189, Loss: 0.11058243364095688, Lr:0.0001\n",
      "Epoch 28, Step: 190, Loss: 0.052316777408123016, Lr:0.0001\n",
      "Epoch 28, Step: 191, Loss: 0.030728954821825027, Lr:0.0001\n",
      "Epoch 28, Step: 192, Loss: 0.11832810938358307, Lr:0.0001\n",
      "Epoch 28, Step: 193, Loss: 0.0007606122526340187, Lr:0.0001\n",
      "Epoch 28, Step: 194, Loss: 0.17391136288642883, Lr:0.0001\n",
      "Epoch 28, Step: 195, Loss: 0.19741617143154144, Lr:0.0001\n",
      "Epoch 28, Step: 196, Loss: 0.004355957265943289, Lr:0.0001\n",
      "Epoch 28, Step: 197, Loss: 0.008438227698206902, Lr:0.0001\n",
      "Epoch 28, Step: 198, Loss: 0.0220651738345623, Lr:0.0001\n",
      "Epoch 28, Step: 199, Loss: 0.2545950710773468, Lr:0.0001\n",
      "Epoch 28, Step: 200, Loss: 0.11221875995397568, Lr:0.0001\n",
      "Epoch 28, Step: 201, Loss: 0.007011223118752241, Lr:0.0001\n",
      "Epoch 28, Step: 202, Loss: 0.01848154515028, Lr:0.0001\n",
      "Epoch 28, Step: 203, Loss: 0.010798785835504532, Lr:0.0001\n",
      "Epoch 28, Step: 204, Loss: 0.013574832119047642, Lr:0.0001\n",
      "Epoch 28, Step: 205, Loss: 0.007706240750849247, Lr:0.0001\n",
      "Epoch 28, Step: 206, Loss: 0.014145598746836185, Lr:0.0001\n",
      "Epoch 28, Step: 207, Loss: 0.11378267407417297, Lr:0.0001\n",
      "Epoch 28, Step: 208, Loss: 0.00020871195010840893, Lr:0.0001\n",
      "Epoch 28, Step: 209, Loss: 0.006464188918471336, Lr:0.0001\n",
      "Epoch 28, Step: 210, Loss: 0.009679536335170269, Lr:0.0001\n",
      "Epoch 28, Step: 211, Loss: 0.0030508670024573803, Lr:0.0001\n",
      "Epoch 28, Step: 212, Loss: 0.0702485665678978, Lr:0.0001\n",
      "Epoch 28, Step: 213, Loss: 0.11757918447256088, Lr:0.0001\n",
      "Epoch 28, Step: 214, Loss: 0.009319639764726162, Lr:0.0001\n",
      "Epoch 28, Step: 215, Loss: 0.00842707883566618, Lr:0.0001\n",
      "Epoch 28, Step: 216, Loss: 0.6807915568351746, Lr:0.0001\n",
      "Epoch 28, Step: 217, Loss: 0.0013556211488321424, Lr:0.0001\n",
      "Epoch 28, Step: 218, Loss: 0.16597579419612885, Lr:0.0001\n",
      "Epoch 28, Step: 219, Loss: 0.004862082656472921, Lr:0.0001\n",
      "Epoch 28, Step: 220, Loss: 0.0035119650419801474, Lr:0.0001\n",
      "Epoch 28, Step: 221, Loss: 0.009349703788757324, Lr:0.0001\n",
      "Epoch 28, Step: 222, Loss: 0.061174847185611725, Lr:0.0001\n",
      "Epoch 28, Step: 223, Loss: 0.0011105636367574334, Lr:0.0001\n",
      "Epoch 28, Step: 224, Loss: 0.008809218183159828, Lr:0.0001\n",
      "Epoch 28, Step: 225, Loss: 0.013965463265776634, Lr:0.0001\n",
      "Epoch 28, Step: 226, Loss: 0.06315930932760239, Lr:0.0001\n",
      "Epoch 28, Step: 227, Loss: 0.02576223388314247, Lr:0.0001\n",
      "Epoch 28, Step: 228, Loss: 0.0030106897465884686, Lr:0.0001\n",
      "Epoch 28, Step: 229, Loss: 0.008460505865514278, Lr:0.0001\n",
      "Epoch 28, Step: 230, Loss: 0.0030795896891504526, Lr:0.0001\n",
      "Epoch 28, Step: 231, Loss: 0.0005914904177188873, Lr:0.0001\n",
      "Epoch 28, Step: 232, Loss: 0.011347521096467972, Lr:0.0001\n",
      "Epoch 28, Step: 233, Loss: 0.14261378347873688, Lr:0.0001\n",
      "Epoch 28, Step: 234, Loss: 0.1507798582315445, Lr:0.0001\n",
      "Epoch 28, Step: 235, Loss: 0.32538092136383057, Lr:0.0001\n",
      "Epoch 28, Step: 236, Loss: 0.021952083334326744, Lr:0.0001\n",
      "Epoch 28, Step: 237, Loss: 0.10382825881242752, Lr:0.0001\n",
      "Epoch 28, Step: 238, Loss: 0.360888808965683, Lr:0.0001\n",
      "Epoch 28, Step: 239, Loss: 0.10342434048652649, Lr:0.0001\n",
      "Epoch 28, Step: 240, Loss: 0.03743267059326172, Lr:0.0001\n",
      "Epoch 28, Step: 241, Loss: 0.4975541830062866, Lr:0.0001\n",
      "Epoch 28, Step: 242, Loss: 0.019429650157690048, Lr:0.0001\n",
      "Epoch 28, Step: 243, Loss: 0.06075451523065567, Lr:0.0001\n",
      "Epoch 28, Step: 244, Loss: 0.03235733509063721, Lr:0.0001\n",
      "Epoch 28, Step: 245, Loss: 0.02300744317471981, Lr:0.0001\n",
      "Epoch 28, Step: 246, Loss: 0.006117893382906914, Lr:0.0001\n",
      "Epoch 28, Step: 247, Loss: 0.025481311604380608, Lr:0.0001\n",
      "Epoch 28, Step: 248, Loss: 0.2928636074066162, Lr:0.0001\n",
      "Epoch 28, Step: 249, Loss: 0.04386608302593231, Lr:0.0001\n",
      "Epoch 28, Step: 250, Loss: 0.19014067947864532, Lr:0.0001\n",
      "Epoch 28, Step: 251, Loss: 0.028432246297597885, Lr:0.0001\n",
      "Epoch 28, Step: 252, Loss: 0.07717019319534302, Lr:0.0001\n",
      "Epoch 28, Step: 253, Loss: 0.1501542329788208, Lr:0.0001\n",
      "Epoch 28, Step: 254, Loss: 0.06641006469726562, Lr:0.0001\n",
      "Epoch 28, Step: 255, Loss: 0.538432776927948, Lr:0.0001\n",
      "Epoch 28, Step: 256, Loss: 0.004971192684024572, Lr:0.0001\n",
      "Epoch 28, Step: 257, Loss: 0.0012695833574980497, Lr:0.0001\n",
      "Epoch 28, Step: 258, Loss: 0.008610987104475498, Lr:0.0001\n",
      "Epoch 28, Step: 259, Loss: 0.01258103922009468, Lr:0.0001\n",
      "Epoch 28, Step: 260, Loss: 0.017840534448623657, Lr:0.0001\n",
      "Epoch 28, Step: 261, Loss: 0.08980163186788559, Lr:0.0001\n",
      "Epoch 28, Step: 262, Loss: 0.06828591972589493, Lr:0.0001\n",
      "Epoch 28, Step: 263, Loss: 0.08342047780752182, Lr:0.0001\n",
      "Epoch 28, Step: 264, Loss: 0.11538180708885193, Lr:0.0001\n",
      "Epoch 28, Step: 265, Loss: 0.0005797412595711648, Lr:0.0001\n",
      "Epoch 28, Step: 266, Loss: 0.03875055909156799, Lr:0.0001\n",
      "Epoch 28, Step: 267, Loss: 0.18817327916622162, Lr:0.0001\n",
      "Epoch 28, Step: 268, Loss: 0.0795273706316948, Lr:0.0001\n",
      "Epoch 28, Step: 269, Loss: 0.024856027215719223, Lr:0.0001\n",
      "Epoch 28, Step: 270, Loss: 0.03659755364060402, Lr:0.0001\n",
      "Epoch 28, Step: 271, Loss: 0.0066604758612811565, Lr:0.0001\n",
      "Epoch 28, Step: 272, Loss: 0.002556063001975417, Lr:0.0001\n",
      "Epoch 28, Step: 273, Loss: 0.07596796005964279, Lr:0.0001\n",
      "Epoch 28, Step: 274, Loss: 0.008797365240752697, Lr:0.0001\n",
      "Epoch 28, Step: 275, Loss: 0.022681571543216705, Lr:0.0001\n",
      "Epoch 28, Step: 276, Loss: 0.001370880869217217, Lr:0.0001\n",
      "Epoch 28, Step: 277, Loss: 0.0456257089972496, Lr:0.0001\n",
      "Epoch 28, Step: 278, Loss: 0.04978981986641884, Lr:0.0001\n",
      "Epoch 28, Step: 279, Loss: 0.043660301715135574, Lr:0.0001\n",
      "Epoch 28, Step: 280, Loss: 0.0314921997487545, Lr:0.0001\n",
      "Epoch 28, Step: 281, Loss: 0.023600121960043907, Lr:0.0001\n",
      "Epoch 28, Step: 282, Loss: 0.1197281926870346, Lr:0.0001\n",
      "Epoch 28, Step: 283, Loss: 0.10868058353662491, Lr:0.0001\n",
      "Epoch 28, Step: 284, Loss: 0.08187531679868698, Lr:0.0001\n",
      "Epoch 28, Step: 285, Loss: 0.03654610365629196, Lr:0.0001\n",
      "Epoch 28, Step: 286, Loss: 0.01577540673315525, Lr:0.0001\n",
      "Epoch 28, Step: 287, Loss: 0.035428017377853394, Lr:0.0001\n",
      "Epoch 28, Step: 288, Loss: 0.34606000781059265, Lr:0.0001\n",
      "Epoch 28, Step: 289, Loss: 0.036509957164525986, Lr:0.0001\n",
      "Epoch 28, Step: 290, Loss: 0.057615455240011215, Lr:0.0001\n",
      "Epoch 28, Step: 291, Loss: 0.02780553512275219, Lr:0.0001\n",
      "Epoch 28, Step: 292, Loss: 0.00030474382219836116, Lr:0.0001\n",
      "Epoch 28, Step: 293, Loss: 0.016994658857584, Lr:0.0001\n",
      "Epoch 28, Step: 294, Loss: 0.025474995374679565, Lr:0.0001\n",
      "Epoch 28, Step: 295, Loss: 0.024902071803808212, Lr:0.0001\n",
      "Epoch 28, Step: 296, Loss: 0.014341020956635475, Lr:0.0001\n",
      "Epoch 28, Step: 297, Loss: 0.015721961855888367, Lr:0.0001\n",
      "Epoch 28, Step: 298, Loss: 0.08261532336473465, Lr:0.0001\n",
      "Epoch 28, Step: 299, Loss: 0.001640420057810843, Lr:0.0001\n",
      "Epoch 28, Step: 300, Loss: 0.1571062058210373, Lr:0.0001\n",
      "Epoch 28, Step: 301, Loss: 0.07337897270917892, Lr:0.0001\n",
      "Epoch 28, Step: 302, Loss: 0.018366888165473938, Lr:0.0001\n",
      "Epoch 28, Step: 303, Loss: 0.07004284113645554, Lr:0.0001\n",
      "Epoch 28, Step: 304, Loss: 0.029929939657449722, Lr:0.0001\n",
      "Epoch 28, Step: 305, Loss: 0.0027144646737724543, Lr:0.0001\n",
      "Epoch 28, Step: 306, Loss: 0.00318178185261786, Lr:0.0001\n",
      "Epoch 28, Step: 307, Loss: 0.031176865100860596, Lr:0.0001\n",
      "Epoch 28, Step: 308, Loss: 0.09915488213300705, Lr:0.0001\n",
      "Epoch 28, Step: 309, Loss: 0.13722895085811615, Lr:0.0001\n",
      "Epoch 28, Step: 310, Loss: 0.03515457361936569, Lr:0.0001\n",
      "Epoch 28, Step: 311, Loss: 0.008633827790617943, Lr:0.0001\n",
      "Epoch 28, Step: 312, Loss: 0.03891447186470032, Lr:0.0001\n",
      "Epoch 28, Step: 313, Loss: 0.04667363315820694, Lr:0.0001\n",
      "Epoch 28, Step: 314, Loss: 0.0139884939417243, Lr:0.0001\n",
      "Epoch 28, Step: 315, Loss: 0.041820358484983444, Lr:0.0001\n",
      "Epoch 28, Step: 316, Loss: 0.025413915514945984, Lr:0.0001\n",
      "Epoch 28, Step: 317, Loss: 0.20437468588352203, Lr:0.0001\n",
      "Epoch 28, Step: 318, Loss: 0.008150420151650906, Lr:0.0001\n",
      "Epoch 28, Step: 319, Loss: 0.10691709071397781, Lr:0.0001\n",
      "Epoch 28, Step: 320, Loss: 0.015966376289725304, Lr:0.0001\n",
      "Epoch 28, Step: 321, Loss: 0.0026385223027318716, Lr:0.0001\n",
      "Epoch 28, Step: 322, Loss: 0.02034752443432808, Lr:0.0001\n",
      "Epoch 28, Step: 323, Loss: 0.19038698077201843, Lr:0.0001\n",
      "Epoch 28, Step: 324, Loss: 0.01179213635623455, Lr:0.0001\n",
      "Epoch 28, Step: 325, Loss: 0.05048567056655884, Lr:0.0001\n",
      "Epoch 28, Step: 326, Loss: 0.013275067321956158, Lr:0.0001\n",
      "Epoch 28, Step: 327, Loss: 0.5036064386367798, Lr:0.0001\n",
      "Epoch 28, Step: 328, Loss: 0.0042645931243896484, Lr:0.0001\n",
      "Epoch 28, Step: 329, Loss: 0.007293905131518841, Lr:0.0001\n",
      "Epoch 28, Step: 330, Loss: 0.16891363263130188, Lr:0.0001\n",
      "Epoch 28, Step: 331, Loss: 0.04415416717529297, Lr:0.0001\n",
      "Epoch 28, Step: 332, Loss: 0.1259511411190033, Lr:0.0001\n",
      "Epoch 28, Step: 333, Loss: 0.011309651657938957, Lr:0.0001\n",
      "Epoch 28, Step: 334, Loss: 0.012688984163105488, Lr:0.0001\n",
      "Epoch 28, Step: 335, Loss: 0.021413249894976616, Lr:0.0001\n",
      "Epoch 28, Step: 336, Loss: 0.027161773294210434, Lr:0.0001\n",
      "Epoch 28, Step: 337, Loss: 0.14650776982307434, Lr:0.0001\n",
      "Epoch 28, Step: 338, Loss: 0.27173879742622375, Lr:0.0001\n",
      "Epoch 28, Step: 339, Loss: 0.04812072589993477, Lr:0.0001\n",
      "Epoch 28, Step: 340, Loss: 0.08812166005373001, Lr:0.0001\n",
      "Epoch 28, Step: 341, Loss: 0.002549156080931425, Lr:0.0001\n",
      "Epoch 28, Step: 342, Loss: 0.020187554880976677, Lr:0.0001\n",
      "Epoch 28, Step: 343, Loss: 0.1811186522245407, Lr:0.0001\n",
      "Epoch 28, Step: 344, Loss: 0.3493695855140686, Lr:0.0001\n",
      "Epoch 28, Step: 345, Loss: 0.02811426855623722, Lr:0.0001\n",
      "Epoch 28, Step: 346, Loss: 0.15087012946605682, Lr:0.0001\n",
      "Epoch 28, Step: 347, Loss: 0.0006473622051998973, Lr:0.0001\n",
      "Epoch 28, Step: 348, Loss: 0.011492286808788776, Lr:0.0001\n",
      "Epoch 28, Step: 349, Loss: 0.12634886801242828, Lr:0.0001\n",
      "Epoch 28, Step: 350, Loss: 0.022341985255479813, Lr:0.0001\n",
      "Epoch 28, Step: 351, Loss: 0.011326196603477001, Lr:0.0001\n",
      "Epoch 28, Step: 352, Loss: 0.01037684641778469, Lr:0.0001\n",
      "Epoch 28, Step: 353, Loss: 0.12692366540431976, Lr:0.0001\n",
      "Epoch 28, Step: 354, Loss: 0.009296695701777935, Lr:0.0001\n",
      "Epoch 28, Step: 355, Loss: 0.01098223589360714, Lr:0.0001\n",
      "Epoch 28, Step: 356, Loss: 0.0594780296087265, Lr:0.0001\n",
      "Epoch 28, Step: 357, Loss: 0.03058822825551033, Lr:0.0001\n",
      "Epoch 28, Step: 358, Loss: 0.19105225801467896, Lr:0.0001\n",
      "Epoch 28, Step: 359, Loss: 0.03588851913809776, Lr:0.0001\n",
      "Epoch 28, Step: 360, Loss: 0.13160932064056396, Lr:0.0001\n",
      "Epoch 28, Step: 361, Loss: 0.02455066703259945, Lr:0.0001\n",
      "Epoch 28, Step: 362, Loss: 0.014215735718607903, Lr:0.0001\n",
      "Epoch 28, Step: 363, Loss: 0.03326363116502762, Lr:0.0001\n",
      "Epoch 28, Step: 364, Loss: 0.005096876993775368, Lr:0.0001\n",
      "Epoch 28, Step: 365, Loss: 0.0961238369345665, Lr:0.0001\n",
      "Epoch 28, Step: 366, Loss: 0.07837463915348053, Lr:0.0001\n",
      "Epoch 28, Step: 367, Loss: 0.013447560369968414, Lr:0.0001\n",
      "Epoch 28, Step: 368, Loss: 0.02296128310263157, Lr:0.0001\n",
      "Epoch 28, Step: 369, Loss: 0.10910322517156601, Lr:0.0001\n",
      "Epoch 28, Step: 370, Loss: 0.007479123771190643, Lr:0.0001\n",
      "Epoch 28, Step: 371, Loss: 0.04222721979022026, Lr:0.0001\n",
      "Epoch 28, Step: 372, Loss: 0.07596421986818314, Lr:0.0001\n",
      "Epoch 28, Step: 373, Loss: 0.07926871627569199, Lr:0.0001\n",
      "Epoch 28, Step: 374, Loss: 0.0040470631793141365, Lr:0.0001\n",
      "Epoch 28, Step: 375, Loss: 0.020768530666828156, Lr:0.0001\n",
      "Epoch 28, Step: 376, Loss: 0.08546990901231766, Lr:0.0001\n",
      "Epoch 28, Step: 377, Loss: 0.00358741101808846, Lr:0.0001\n",
      "Epoch 28, Step: 378, Loss: 0.02362978644669056, Lr:0.0001\n",
      "Epoch 28, Step: 379, Loss: 0.365165114402771, Lr:0.0001\n",
      "Epoch 28, Step: 380, Loss: 0.001772989984601736, Lr:0.0001\n",
      "Epoch 28, Step: 381, Loss: 0.006215653847903013, Lr:0.0001\n",
      "Epoch 28, Step: 382, Loss: 0.030462348833680153, Lr:0.0001\n",
      "Epoch 28, Step: 383, Loss: 0.032206080853939056, Lr:0.0001\n",
      "Epoch 28, Step: 384, Loss: 0.005931953899562359, Lr:0.0001\n",
      "Epoch 28, Step: 385, Loss: 0.04461224749684334, Lr:0.0001\n",
      "Epoch 28, Step: 386, Loss: 0.09687425941228867, Lr:0.0001\n",
      "Epoch 28, Step: 387, Loss: 0.09675922244787216, Lr:0.0001\n",
      "Epoch 28, Step: 388, Loss: 0.10609713941812515, Lr:0.0001\n",
      "Epoch 28, Step: 389, Loss: 0.10053430497646332, Lr:0.0001\n",
      "Epoch 28, Step: 390, Loss: 0.010296283289790154, Lr:0.0001\n",
      "Epoch 28, Step: 391, Loss: 0.017618678510189056, Lr:0.0001\n",
      "Epoch 28, Step: 392, Loss: 0.011191547848284245, Lr:0.0001\n",
      "Epoch 28, Step: 393, Loss: 0.07074093073606491, Lr:0.0001\n",
      "Epoch 28, Step: 394, Loss: 0.1680602729320526, Lr:0.0001\n",
      "Epoch 28, Step: 395, Loss: 0.17553195357322693, Lr:0.0001\n",
      "Epoch 28, Step: 396, Loss: 0.06459765881299973, Lr:0.0001\n",
      "Epoch 28, Step: 397, Loss: 0.07449017465114594, Lr:0.0001\n",
      "Epoch 28, Step: 398, Loss: 0.0332767590880394, Lr:0.0001\n",
      "Epoch 28, Step: 399, Loss: 0.1041053757071495, Lr:0.0001\n",
      "Epoch 28, Step: 400, Loss: 0.017436694353818893, Lr:0.0001\n",
      "Epoch 28, Step: 401, Loss: 0.040389284491539, Lr:0.0001\n",
      "Epoch 28, Step: 402, Loss: 0.01030871830880642, Lr:0.0001\n",
      "Epoch 28, Step: 403, Loss: 0.028446931391954422, Lr:0.0001\n",
      "Epoch 28, Step: 404, Loss: 0.16845053434371948, Lr:0.0001\n",
      "Epoch 28, Step: 405, Loss: 0.02645125240087509, Lr:0.0001\n",
      "Epoch 28, Step: 406, Loss: 0.1000746563076973, Lr:0.0001\n",
      "Epoch 28, Step: 407, Loss: 0.10342273116111755, Lr:0.0001\n",
      "Epoch 28, Step: 408, Loss: 0.058390356600284576, Lr:0.0001\n",
      "Epoch 28, Step: 409, Loss: 0.022849630564451218, Lr:0.0001\n",
      "Epoch 28, Step: 410, Loss: 0.004798544570803642, Lr:0.0001\n",
      "Epoch 28, Step: 411, Loss: 0.15432262420654297, Lr:0.0001\n",
      "Epoch 28, Step: 412, Loss: 0.016869839280843735, Lr:0.0001\n",
      "Epoch 28, Step: 413, Loss: 0.0028509816620498896, Lr:0.0001\n",
      "Epoch 28, Step: 414, Loss: 0.001273224363103509, Lr:0.0001\n",
      "Epoch 28, Step: 415, Loss: 0.11181554943323135, Lr:0.0001\n",
      "Epoch 28, Step: 416, Loss: 0.001952923252247274, Lr:0.0001\n",
      "Epoch 28, Step: 417, Loss: 0.003822760656476021, Lr:0.0001\n",
      "Epoch 28, Step: 418, Loss: 0.022686900570988655, Lr:0.0001\n",
      "Epoch 28, Step: 419, Loss: 0.0019476874731481075, Lr:0.0001\n",
      "Epoch 28, Step: 420, Loss: 0.014636904932558537, Lr:0.0001\n",
      "Epoch 28, Step: 421, Loss: 0.02170489728450775, Lr:0.0001\n",
      "Epoch 28, Step: 422, Loss: 0.18679939210414886, Lr:0.0001\n",
      "Epoch 28, Step: 423, Loss: 0.006219199392944574, Lr:0.0001\n",
      "Epoch 28, Step: 424, Loss: 0.08331217616796494, Lr:0.0001\n",
      "Epoch 28, Step: 425, Loss: 0.026404868811368942, Lr:0.0001\n",
      "Epoch 28, Step: 426, Loss: 0.18274039030075073, Lr:0.0001\n",
      "Epoch 28, Step: 427, Loss: 0.0016038342146202922, Lr:0.0001\n",
      "Epoch 28, Step: 428, Loss: 0.05199620500206947, Lr:0.0001\n",
      "Epoch 28, Step: 429, Loss: 0.08061898499727249, Lr:0.0001\n",
      "Epoch 28, Step: 430, Loss: 0.08286865055561066, Lr:0.0001\n",
      "Epoch 28, Step: 431, Loss: 0.06838716566562653, Lr:0.0001\n",
      "Epoch 28, Step: 432, Loss: 0.011657404713332653, Lr:0.0001\n",
      "Epoch 28, Step: 433, Loss: 0.030236195772886276, Lr:0.0001\n",
      "Epoch 28, Step: 434, Loss: 0.04529179260134697, Lr:0.0001\n",
      "Epoch 28, Step: 435, Loss: 0.037713177502155304, Lr:0.0001\n",
      "Epoch 28, Step: 436, Loss: 0.0028599021025002003, Lr:0.0001\n",
      "Epoch 28, Step: 437, Loss: 0.054329048842191696, Lr:0.0001\n",
      "Epoch 28, Step: 438, Loss: 0.0631365031003952, Lr:0.0001\n",
      "Epoch 28, Step: 439, Loss: 0.02724360302090645, Lr:0.0001\n",
      "Epoch 28, Step: 440, Loss: 0.0772312805056572, Lr:0.0001\n",
      "Epoch 28, Step: 441, Loss: 0.0011627695057541132, Lr:0.0001\n",
      "Epoch 28, Step: 442, Loss: 0.10308746248483658, Lr:0.0001\n",
      "Epoch 28, Step: 443, Loss: 0.0018518741708248854, Lr:0.0001\n",
      "Epoch 28, Step: 444, Loss: 0.08871401846408844, Lr:0.0001\n",
      "Epoch 28, Step: 445, Loss: 0.003030180698260665, Lr:0.0001\n",
      "Epoch 28, Step: 446, Loss: 0.14949002861976624, Lr:0.0001\n",
      "Epoch 28, Step: 447, Loss: 0.0033822807017713785, Lr:0.0001\n",
      "Epoch 28, Step: 448, Loss: 0.008618808351457119, Lr:0.0001\n",
      "Epoch 28, Step: 449, Loss: 0.031031256541609764, Lr:0.0001\n",
      "Epoch 28, Step: 450, Loss: 0.014113662764430046, Lr:0.0001\n",
      "Epoch 28, Step: 451, Loss: 0.3985351622104645, Lr:0.0001\n",
      "Epoch 28, Step: 452, Loss: 0.2210986614227295, Lr:0.0001\n",
      "Epoch 28, Step: 453, Loss: 0.4762386977672577, Lr:0.0001\n",
      "Epoch 28, Step: 454, Loss: 0.05926715210080147, Lr:0.0001\n",
      "Epoch 28, Step: 455, Loss: 0.004624512512236834, Lr:0.0001\n",
      "Epoch 28, Step: 456, Loss: 0.09976107627153397, Lr:0.0001\n",
      "Epoch 28, Step: 457, Loss: 0.014319833368062973, Lr:0.0001\n",
      "Epoch 28, Step: 458, Loss: 0.0012587429955601692, Lr:0.0001\n",
      "Epoch 28, Step: 459, Loss: 0.012130911462008953, Lr:0.0001\n",
      "Epoch 28, Step: 460, Loss: 0.10627564787864685, Lr:0.0001\n",
      "Epoch 28, Step: 461, Loss: 0.052930012345314026, Lr:0.0001\n",
      "Epoch 28, Step: 462, Loss: 0.07713685929775238, Lr:0.0001\n",
      "Epoch 28, Step: 463, Loss: 0.01014892477542162, Lr:0.0001\n",
      "Epoch 28, Step: 464, Loss: 0.038643110543489456, Lr:0.0001\n",
      "Epoch 28, Step: 465, Loss: 0.0553007572889328, Lr:0.0001\n",
      "Epoch 28, Step: 466, Loss: 0.04505230858922005, Lr:0.0001\n",
      "Epoch 28, Step: 467, Loss: 0.2664966583251953, Lr:0.0001\n",
      "Epoch 28, Step: 468, Loss: 0.509475827217102, Lr:0.0001\n",
      "Epoch 28, Step: 469, Loss: 0.004821116104722023, Lr:0.0001\n",
      "Epoch 28, Step: 470, Loss: 0.00724525423720479, Lr:0.0001\n",
      "Epoch 28, Step: 471, Loss: 0.0014772546710446477, Lr:0.0001\n",
      "Epoch 28, Step: 472, Loss: 0.04732149466872215, Lr:0.0001\n",
      "Epoch 28, Step: 473, Loss: 0.023377658799290657, Lr:0.0001\n",
      "Epoch 28, Step: 474, Loss: 0.20122025907039642, Lr:0.0001\n",
      "Epoch 28, Step: 475, Loss: 0.0030591588001698256, Lr:0.0001\n",
      "Epoch 28, Step: 476, Loss: 0.053786229342222214, Lr:0.0001\n",
      "Epoch 28, Step: 477, Loss: 0.15316523611545563, Lr:0.0001\n",
      "Epoch 28, Step: 478, Loss: 0.008281799964606762, Lr:0.0001\n",
      "Epoch 28, Step: 479, Loss: 0.07813747972249985, Lr:0.0001\n",
      "Epoch 28, Step: 480, Loss: 0.025192204862833023, Lr:0.0001\n",
      "Epoch 28, Step: 481, Loss: 0.0778077244758606, Lr:0.0001\n",
      "Epoch 28, Step: 482, Loss: 0.051919709891080856, Lr:0.0001\n",
      "Epoch 28, Step: 483, Loss: 0.021877145394682884, Lr:0.0001\n",
      "Epoch 28, Step: 484, Loss: 0.06783610582351685, Lr:0.0001\n",
      "Epoch 28, Step: 485, Loss: 0.009101997129619122, Lr:0.0001\n",
      "Epoch 28, Step: 486, Loss: 0.049367476254701614, Lr:0.0001\n",
      "Epoch 28, Step: 487, Loss: 0.01786162704229355, Lr:0.0001\n",
      "Epoch 28, Step: 488, Loss: 0.25273072719573975, Lr:0.0001\n",
      "Epoch 28, Step: 489, Loss: 0.0217524953186512, Lr:0.0001\n",
      "Epoch 28, Step: 490, Loss: 0.02725398726761341, Lr:0.0001\n",
      "Epoch 28, Step: 491, Loss: 0.334682822227478, Lr:0.0001\n",
      "Epoch 28, Step: 492, Loss: 0.00494767539203167, Lr:0.0001\n",
      "Epoch 28, Step: 493, Loss: 0.15284664928913116, Lr:0.0001\n",
      "Epoch 28, Step: 494, Loss: 0.02281029522418976, Lr:0.0001\n",
      "Epoch 28, Step: 495, Loss: 0.12914863228797913, Lr:0.0001\n",
      "Epoch 28, Step: 496, Loss: 0.07299776375293732, Lr:0.0001\n",
      "Epoch 28, Step: 497, Loss: 0.0028236000798642635, Lr:0.0001\n",
      "Epoch 28, Step: 498, Loss: 0.1757255494594574, Lr:0.0001\n",
      "Epoch 28, Step: 499, Loss: 0.11562088876962662, Lr:0.0001\n",
      "Epoch 28, Step: 500, Loss: 0.013595148921012878, Lr:0.0001\n",
      "Epoch 28, Step: 501, Loss: 0.044686101377010345, Lr:0.0001\n",
      "Epoch 28, Step: 502, Loss: 0.0045975446701049805, Lr:0.0001\n",
      "Epoch 28, Step: 503, Loss: 0.024325642734766006, Lr:0.0001\n",
      "Epoch 28, Step: 504, Loss: 0.060352880507707596, Lr:0.0001\n",
      "Epoch 28, Step: 505, Loss: 0.01593966782093048, Lr:0.0001\n",
      "Epoch 28, Step: 506, Loss: 0.04424077644944191, Lr:0.0001\n",
      "Epoch 28, Step: 507, Loss: 0.018211258575320244, Lr:0.0001\n",
      "Epoch 28, Step: 508, Loss: 0.012416915036737919, Lr:0.0001\n",
      "Epoch 28, Step: 509, Loss: 0.02325250580906868, Lr:0.0001\n",
      "Epoch 28, Step: 510, Loss: 0.044207535684108734, Lr:0.0001\n",
      "Epoch 28, Step: 511, Loss: 0.19915995001792908, Lr:0.0001\n",
      "Epoch 28, Step: 512, Loss: 0.0769813060760498, Lr:0.0001\n",
      "Epoch 28, Step: 513, Loss: 0.16161960363388062, Lr:0.0001\n",
      "Epoch 28, Step: 514, Loss: 0.010269236750900745, Lr:0.0001\n",
      "Epoch 28, Step: 515, Loss: 0.08144103735685349, Lr:0.0001\n",
      "Epoch 28, Step: 516, Loss: 0.09750362485647202, Lr:0.0001\n",
      "Epoch 28, Step: 517, Loss: 0.0601828433573246, Lr:0.0001\n",
      "Epoch 28, Step: 518, Loss: 0.020818935707211494, Lr:0.0001\n",
      "Epoch 28, Step: 519, Loss: 0.013101821765303612, Lr:0.0001\n",
      "Epoch 28, Step: 520, Loss: 0.011475172825157642, Lr:0.0001\n",
      "Epoch 28, Step: 521, Loss: 0.14121443033218384, Lr:0.0001\n",
      "Epoch 28, Step: 522, Loss: 0.1040993183851242, Lr:0.0001\n",
      "Epoch 28, Step: 523, Loss: 0.010314525105059147, Lr:0.0001\n",
      "Epoch 28, Step: 524, Loss: 0.0003709368174895644, Lr:0.0001\n",
      "Epoch 28, Step: 525, Loss: 0.008690733462572098, Lr:0.0001\n",
      "Epoch 28, Step: 526, Loss: 0.2737542986869812, Lr:0.0001\n",
      "Epoch 28, Step: 527, Loss: 0.0026187116745859385, Lr:0.0001\n",
      "Epoch 28, Step: 528, Loss: 0.09935339540243149, Lr:0.0001\n",
      "Epoch 28, Step: 529, Loss: 0.005481955129653215, Lr:0.0001\n",
      "Epoch 28, Step: 530, Loss: 0.012895818799734116, Lr:0.0001\n",
      "Epoch 28, Step: 531, Loss: 0.024229388684034348, Lr:0.0001\n",
      "Epoch 28, Step: 532, Loss: 0.12365579605102539, Lr:0.0001\n",
      "Epoch 28, Step: 533, Loss: 0.003257822012528777, Lr:0.0001\n",
      "Epoch 28, Step: 534, Loss: 0.03852170333266258, Lr:0.0001\n",
      "Epoch 28, Step: 535, Loss: 0.04342753440141678, Lr:0.0001\n",
      "Epoch 28, Step: 536, Loss: 0.047851089388132095, Lr:0.0001\n",
      "Epoch 28, Step: 537, Loss: 0.13635466992855072, Lr:0.0001\n",
      "Epoch 28, Step: 538, Loss: 0.011908729560673237, Lr:0.0001\n",
      "Epoch 28, Step: 539, Loss: 0.14775818586349487, Lr:0.0001\n",
      "Epoch 28, Step: 540, Loss: 0.00536278635263443, Lr:0.0001\n",
      "Epoch 28, Step: 541, Loss: 0.0147917615249753, Lr:0.0001\n",
      "Epoch 28, Step: 542, Loss: 0.03255268186330795, Lr:0.0001\n",
      "Epoch 28, Step: 543, Loss: 0.045385271310806274, Lr:0.0001\n",
      "Epoch 28, Step: 544, Loss: 0.004020748194307089, Lr:0.0001\n",
      "Epoch 28, Step: 545, Loss: 0.0015273287426680326, Lr:0.0001\n",
      "Epoch 28, Step: 546, Loss: 0.01724611595273018, Lr:0.0001\n",
      "Epoch 28, Step: 547, Loss: 0.020572355017066002, Lr:0.0001\n",
      "Epoch 28, Step: 548, Loss: 0.07550160586833954, Lr:0.0001\n",
      "Epoch 28, Step: 549, Loss: 0.3774677813053131, Lr:0.0001\n",
      "Epoch 28, Step: 550, Loss: 0.04956018552184105, Lr:0.0001\n",
      "Epoch 28, Step: 551, Loss: 0.08967629820108414, Lr:0.0001\n",
      "Epoch 28, Step: 552, Loss: 0.04543968290090561, Lr:0.0001\n",
      "Epoch 28, Step: 553, Loss: 0.05577411875128746, Lr:0.0001\n",
      "Epoch 28, Step: 554, Loss: 0.024245435371994972, Lr:0.0001\n",
      "Epoch 28, Step: 555, Loss: 0.013960516080260277, Lr:0.0001\n",
      "Epoch 28, Step: 556, Loss: 0.08466903865337372, Lr:0.0001\n",
      "Epoch 28, Step: 557, Loss: 0.04266340658068657, Lr:0.0001\n",
      "Epoch 28, Step: 558, Loss: 0.017574306577444077, Lr:0.0001\n",
      "Epoch 28, Step: 559, Loss: 0.0981433168053627, Lr:0.0001\n",
      "Epoch 28, Step: 560, Loss: 0.0012120665051043034, Lr:0.0001\n",
      "Epoch 28, Step: 561, Loss: 0.016603771597146988, Lr:0.0001\n",
      "Epoch 28, Step: 562, Loss: 0.03147544711828232, Lr:0.0001\n",
      "Epoch 28, Step: 563, Loss: 0.008277727290987968, Lr:0.0001\n",
      "Epoch 28, Step: 564, Loss: 0.04299677535891533, Lr:0.0001\n",
      "Epoch 28, Step: 565, Loss: 0.009075023233890533, Lr:0.0001\n",
      "Epoch 28, Step: 566, Loss: 0.10760913044214249, Lr:0.0001\n",
      "Epoch 28, Step: 567, Loss: 0.0080647524446249, Lr:0.0001\n",
      "Epoch 28, Step: 568, Loss: 0.009060010313987732, Lr:0.0001\n",
      "Epoch 28, Step: 569, Loss: 0.0023472527973353863, Lr:0.0001\n",
      "Epoch 28, Step: 570, Loss: 0.17175604403018951, Lr:0.0001\n",
      "Epoch 28, Step: 571, Loss: 0.03938927501440048, Lr:0.0001\n",
      "Epoch 28, Step: 572, Loss: 0.01420303899794817, Lr:0.0001\n",
      "Epoch 28, Step: 573, Loss: 0.011226681992411613, Lr:0.0001\n",
      "Epoch 28, Step: 574, Loss: 0.011838085018098354, Lr:0.0001\n",
      "Epoch 28, Step: 575, Loss: 0.020931344479322433, Lr:0.0001\n",
      "Epoch 28, Step: 576, Loss: 0.0010783057659864426, Lr:0.0001\n",
      "Epoch 28, Step: 577, Loss: 0.012715935707092285, Lr:0.0001\n",
      "Epoch 28, Step: 578, Loss: 0.005790764931589365, Lr:0.0001\n",
      "Epoch 28, Step: 579, Loss: 0.05633261054754257, Lr:0.0001\n",
      "Epoch 28, Step: 580, Loss: 0.009263772517442703, Lr:0.0001\n",
      "Epoch 28, Step: 581, Loss: 0.03550682216882706, Lr:0.0001\n",
      "Epoch 28, Step: 582, Loss: 0.007091354578733444, Lr:0.0001\n",
      "Epoch 28, Step: 583, Loss: 0.09836125373840332, Lr:0.0001\n",
      "Epoch 28, Step: 584, Loss: 0.021056385710835457, Lr:0.0001\n",
      "Epoch 28, Step: 585, Loss: 0.02341165952384472, Lr:0.0001\n",
      "Epoch 28, Step: 586, Loss: 0.0033481221180409193, Lr:0.0001\n",
      "Epoch 28, Step: 587, Loss: 0.010278315283358097, Lr:0.0001\n",
      "Epoch 28, Step: 588, Loss: 0.05511292815208435, Lr:0.0001\n",
      "Epoch 28, Step: 589, Loss: 0.17104145884513855, Lr:0.0001\n",
      "Epoch 28, Step: 590, Loss: 0.001035703462548554, Lr:0.0001\n",
      "Epoch 28, Step: 591, Loss: 0.08170309662818909, Lr:0.0001\n",
      "Epoch 28, Step: 592, Loss: 0.006793663837015629, Lr:0.0001\n",
      "Epoch 28, Step: 593, Loss: 0.00576894823461771, Lr:0.0001\n",
      "Epoch 28, Step: 594, Loss: 0.009739384055137634, Lr:0.0001\n",
      "Epoch 28, Step: 595, Loss: 0.07369061559438705, Lr:0.0001\n",
      "Epoch 28, Step: 596, Loss: 0.002984525403007865, Lr:0.0001\n",
      "Epoch 28, Step: 597, Loss: 0.6352315545082092, Lr:0.0001\n",
      "Epoch 28, Step: 598, Loss: 0.0008521769777871668, Lr:0.0001\n",
      "Epoch 28, Step: 599, Loss: 0.10644987225532532, Lr:0.0001\n",
      "Epoch 28, Step: 600, Loss: 0.11716736853122711, Lr:0.0001\n",
      "Epoch 28, Step: 601, Loss: 0.04519357532262802, Lr:0.0001\n",
      "Epoch 28, Step: 602, Loss: 0.026468981057405472, Lr:0.0001\n",
      "Epoch 28, Step: 603, Loss: 0.006834547501057386, Lr:0.0001\n",
      "Epoch 28, Step: 604, Loss: 0.002814671490341425, Lr:0.0001\n",
      "Epoch 28, Step: 605, Loss: 0.04794187843799591, Lr:0.0001\n",
      "Epoch 28, Step: 606, Loss: 0.23326261341571808, Lr:0.0001\n",
      "Epoch 28, Step: 607, Loss: 0.07208016514778137, Lr:0.0001\n",
      "Epoch 28, Step: 608, Loss: 0.026077277958393097, Lr:0.0001\n",
      "Epoch 28, Step: 609, Loss: 0.03540259599685669, Lr:0.0001\n",
      "Epoch 28, Step: 610, Loss: 0.04727878049015999, Lr:0.0001\n",
      "Epoch 28, Step: 611, Loss: 0.09411026537418365, Lr:0.0001\n",
      "Epoch 28, Step: 612, Loss: 0.12311843037605286, Lr:0.0001\n",
      "Epoch 28, Step: 613, Loss: 0.006821874994784594, Lr:0.0001\n",
      "Epoch 28, Step: 614, Loss: 0.06050588935613632, Lr:0.0001\n",
      "Epoch 28, Step: 615, Loss: 0.04345836117863655, Lr:0.0001\n",
      "Epoch 28, Step: 616, Loss: 0.011628678068518639, Lr:0.0001\n",
      "Epoch 28, Step: 617, Loss: 0.05779590085148811, Lr:0.0001\n",
      "Epoch 28, Step: 618, Loss: 0.0012105664936825633, Lr:0.0001\n",
      "Epoch 28, Step: 619, Loss: 0.1382235437631607, Lr:0.0001\n",
      "Epoch 28, Step: 620, Loss: 0.09654875844717026, Lr:0.0001\n",
      "Epoch 28, Step: 621, Loss: 0.012472525238990784, Lr:0.0001\n",
      "Epoch 28, Step: 622, Loss: 0.00012962569599039853, Lr:0.0001\n",
      "Epoch 28, Step: 623, Loss: 0.02798427827656269, Lr:0.0001\n",
      "Epoch 28, Step: 624, Loss: 0.04460509493947029, Lr:0.0001\n",
      "Epoch 28, Step: 625, Loss: 0.08541330695152283, Lr:0.0001\n",
      "Epoch 28, Step: 626, Loss: 0.06995939463376999, Lr:0.0001\n",
      "Epoch 28, Step: 627, Loss: 0.34505027532577515, Lr:0.0001\n",
      "Epoch 28, Step: 628, Loss: 0.010283468291163445, Lr:0.0001\n",
      "Epoch 28, Step: 629, Loss: 0.003907783422619104, Lr:0.0001\n",
      "Epoch 28, Step: 630, Loss: 0.004241487011313438, Lr:0.0001\n",
      "Epoch 28, Step: 631, Loss: 0.045769158750772476, Lr:0.0001\n",
      "Epoch 28, Step: 632, Loss: 0.005267757922410965, Lr:0.0001\n",
      "Epoch 28, Step: 633, Loss: 0.13410164415836334, Lr:0.0001\n",
      "Epoch 28, Step: 634, Loss: 0.08982864022254944, Lr:0.0001\n",
      "Epoch 28, Step: 635, Loss: 0.171988382935524, Lr:0.0001\n",
      "Epoch 28, Step: 636, Loss: 0.011298367753624916, Lr:0.0001\n",
      "Epoch 28, Step: 637, Loss: 0.05156724527478218, Lr:0.0001\n",
      "Epoch 28, Step: 638, Loss: 0.14385512471199036, Lr:0.0001\n",
      "Epoch 28, Step: 639, Loss: 0.35767319798469543, Lr:0.0001\n",
      "Epoch 28, Step: 640, Loss: 0.08808483928442001, Lr:0.0001\n",
      "Epoch 28, Step: 641, Loss: 0.07894186675548553, Lr:0.0001\n",
      "Epoch 28, Step: 642, Loss: 0.068459153175354, Lr:0.0001\n",
      "Epoch 28, Step: 643, Loss: 0.0831378847360611, Lr:0.0001\n",
      "Epoch 28, Step: 644, Loss: 0.08435630053281784, Lr:0.0001\n",
      "Epoch 28, Step: 645, Loss: 0.07302960008382797, Lr:0.0001\n",
      "Epoch 28, Step: 646, Loss: 0.026400327682495117, Lr:0.0001\n",
      "Epoch 28, Step: 647, Loss: 0.038626909255981445, Lr:0.0001\n",
      "Epoch 28, Step: 648, Loss: 0.03316802158951759, Lr:0.0001\n",
      "Epoch 28, Step: 649, Loss: 0.03376197814941406, Lr:0.0001\n",
      "Epoch 28, Step: 650, Loss: 0.008611130528151989, Lr:0.0001\n",
      "Epoch 28, Step: 651, Loss: 0.13092462718486786, Lr:0.0001\n",
      "Epoch 28, Step: 652, Loss: 0.01402365043759346, Lr:0.0001\n",
      "Epoch 28, Step: 653, Loss: 0.006028084084391594, Lr:0.0001\n",
      "Epoch 28, Step: 654, Loss: 0.031142044812440872, Lr:0.0001\n",
      "Epoch 28, Step: 655, Loss: 0.009013431146740913, Lr:0.0001\n",
      "Epoch 28, Step: 656, Loss: 0.16415783762931824, Lr:0.0001\n",
      "Epoch 28, Step: 657, Loss: 0.0173310749232769, Lr:0.0001\n",
      "Epoch 28, Step: 658, Loss: 0.060734618455171585, Lr:0.0001\n",
      "Epoch 28, Step: 659, Loss: 0.015128012746572495, Lr:0.0001\n",
      "Epoch 28, Step: 660, Loss: 0.10384725034236908, Lr:0.0001\n",
      "Epoch 28, Step: 661, Loss: 0.07784958183765411, Lr:0.0001\n",
      "Epoch 28, Step: 662, Loss: 0.017034020274877548, Lr:0.0001\n",
      "Epoch 28, Step: 663, Loss: 0.0018109155353158712, Lr:0.0001\n",
      "Epoch 28, Step: 664, Loss: 0.038875024765729904, Lr:0.0001\n",
      "Epoch 28, Step: 665, Loss: 0.17406585812568665, Lr:0.0001\n",
      "Epoch 28, Step: 666, Loss: 0.022641312330961227, Lr:0.0001\n",
      "Epoch 28, Step: 667, Loss: 0.03637515380978584, Lr:0.0001\n",
      "Epoch 28, Step: 668, Loss: 0.0028107326943427324, Lr:0.0001\n",
      "Epoch 28, Step: 669, Loss: 0.035497263073921204, Lr:0.0001\n",
      "Epoch 28, Step: 670, Loss: 0.024871263653039932, Lr:0.0001\n",
      "Epoch 28, Step: 671, Loss: 0.026083506643772125, Lr:0.0001\n",
      "Epoch 28, Step: 672, Loss: 0.09575984627008438, Lr:0.0001\n",
      "Epoch 28, Step: 673, Loss: 0.07131067663431168, Lr:0.0001\n",
      "Epoch 28, Step: 674, Loss: 0.08053304255008698, Lr:0.0001\n",
      "Epoch 28, Step: 675, Loss: 0.004171513020992279, Lr:0.0001\n",
      "Epoch 28, Step: 676, Loss: 0.09193892776966095, Lr:0.0001\n",
      "Epoch 28, Step: 677, Loss: 0.06461537629365921, Lr:0.0001\n",
      "Epoch 28, Step: 678, Loss: 0.03644163906574249, Lr:0.0001\n",
      "Epoch 28, Step: 679, Loss: 0.0540585070848465, Lr:0.0001\n",
      "Epoch 28, Step: 680, Loss: 0.0078028179705142975, Lr:0.0001\n",
      "Epoch 28, Step: 681, Loss: 0.017362669110298157, Lr:0.0001\n",
      "Epoch 28, Step: 682, Loss: 0.05009562894701958, Lr:0.0001\n",
      "Epoch 28, Step: 683, Loss: 0.038737960159778595, Lr:0.0001\n",
      "Epoch 28, Step: 684, Loss: 0.01618731953203678, Lr:0.0001\n",
      "Epoch 28, Step: 685, Loss: 0.03865199536085129, Lr:0.0001\n",
      "Epoch 28, Step: 686, Loss: 0.06658559292554855, Lr:0.0001\n",
      "Epoch 28, Step: 687, Loss: 0.000837583327665925, Lr:0.0001\n",
      "Epoch 28, Step: 688, Loss: 0.007187594659626484, Lr:0.0001\n",
      "Epoch 28, Step: 689, Loss: 0.002785462886095047, Lr:0.0001\n",
      "Epoch 28, Step: 690, Loss: 0.07148956507444382, Lr:0.0001\n",
      "Epoch 28, Step: 691, Loss: 0.17831945419311523, Lr:0.0001\n",
      "Epoch 28, Step: 692, Loss: 0.1225588470697403, Lr:0.0001\n",
      "Epoch 28, Step: 693, Loss: 0.02996020019054413, Lr:0.0001\n",
      "Epoch 28, Step: 694, Loss: 0.051834993064403534, Lr:0.0001\n",
      "Epoch 28, Step: 695, Loss: 0.2287805825471878, Lr:0.0001\n",
      "Epoch 28, Step: 696, Loss: 0.0859755277633667, Lr:0.0001\n",
      "Epoch 28, Step: 697, Loss: 0.002405416453257203, Lr:0.0001\n",
      "Epoch 28, Step: 698, Loss: 0.07084840536117554, Lr:0.0001\n",
      "Epoch 28, Step: 699, Loss: 0.07662992924451828, Lr:0.0001\n",
      "Epoch 28, Step: 700, Loss: 0.0022186818532645702, Lr:0.0001\n",
      "Epoch 28, Step: 701, Loss: 0.04538493603467941, Lr:0.0001\n",
      "Epoch 28, Step: 702, Loss: 0.18183499574661255, Lr:0.0001\n",
      "Epoch 28, Step: 703, Loss: 0.033474452793598175, Lr:0.0001\n",
      "Epoch 28, Step: 704, Loss: 0.08053182810544968, Lr:0.0001\n",
      "Epoch 28, Step: 705, Loss: 0.07616481184959412, Lr:0.0001\n",
      "Epoch 28, Step: 706, Loss: 0.003881053300574422, Lr:0.0001\n",
      "Epoch 28, Step: 707, Loss: 0.15027184784412384, Lr:0.0001\n",
      "Epoch 28, Step: 708, Loss: 0.004764118697494268, Lr:0.0001\n",
      "Epoch 28, Step: 709, Loss: 0.072095587849617, Lr:0.0001\n",
      "Epoch 28, Step: 710, Loss: 0.016880471259355545, Lr:0.0001\n",
      "Epoch 28, Step: 711, Loss: 0.01954435370862484, Lr:0.0001\n",
      "Epoch 28, Step: 712, Loss: 0.00897806417196989, Lr:0.0001\n",
      "Epoch 28, Step: 713, Loss: 0.3747125566005707, Lr:0.0001\n",
      "Epoch 28, Step: 714, Loss: 0.010254722088575363, Lr:0.0001\n",
      "Epoch 28, Step: 715, Loss: 0.2688467502593994, Lr:0.0001\n",
      "Epoch 28, Step: 716, Loss: 0.12599289417266846, Lr:0.0001\n",
      "Epoch 28, Step: 717, Loss: 0.00902276486158371, Lr:0.0001\n",
      "Epoch 28, Step: 718, Loss: 0.038199279457330704, Lr:0.0001\n",
      "Epoch 28, Step: 719, Loss: 0.012913388200104237, Lr:0.0001\n",
      "Epoch 28, Step: 720, Loss: 0.0036973142996430397, Lr:0.0001\n",
      "Epoch 28, Step: 721, Loss: 0.038216788321733475, Lr:0.0001\n",
      "Epoch 28, Step: 722, Loss: 0.08355803787708282, Lr:0.0001\n",
      "Epoch 28, Step: 723, Loss: 0.4432808756828308, Lr:0.0001\n",
      "Epoch 28, Step: 724, Loss: 0.0028521795757114887, Lr:0.0001\n",
      "Epoch 28, Step: 725, Loss: 0.08881141990423203, Lr:0.0001\n",
      "Epoch 28, Step: 726, Loss: 0.0019257542444393039, Lr:0.0001\n",
      "Epoch 28, Step: 727, Loss: 0.013189964927732944, Lr:0.0001\n",
      "Epoch 28, Step: 728, Loss: 0.0018912366358563304, Lr:0.0001\n",
      "Epoch 28, Step: 729, Loss: 0.033144064247608185, Lr:0.0001\n",
      "Epoch 28, Step: 730, Loss: 0.005347273778170347, Lr:0.0001\n",
      "Epoch 28, Step: 731, Loss: 0.26783260703086853, Lr:0.0001\n",
      "Epoch 28, Step: 732, Loss: 0.02112765610218048, Lr:0.0001\n",
      "Epoch 28, Step: 733, Loss: 0.04971325397491455, Lr:0.0001\n",
      "Epoch 28, Step: 734, Loss: 0.00021881418069824576, Lr:0.0001\n",
      "Epoch 28, Step: 735, Loss: 0.008431581780314445, Lr:0.0001\n",
      "Epoch 28, Step: 736, Loss: 0.10582489520311356, Lr:0.0001\n",
      "Epoch 28, Step: 737, Loss: 0.0036140105221420527, Lr:0.0001\n",
      "Epoch 28, Step: 738, Loss: 0.07447901368141174, Lr:0.0001\n",
      "Epoch 28, Step: 739, Loss: 0.03427799418568611, Lr:0.0001\n",
      "Epoch 28, Step: 740, Loss: 0.03183629736304283, Lr:0.0001\n",
      "Epoch 28, Step: 741, Loss: 0.05924685671925545, Lr:0.0001\n",
      "Epoch 28, Step: 742, Loss: 0.047457899898290634, Lr:0.0001\n",
      "Epoch 28, Step: 743, Loss: 0.004896717611700296, Lr:0.0001\n",
      "Epoch 28, Step: 744, Loss: 0.006887046154588461, Lr:0.0001\n",
      "Epoch 28, Step: 745, Loss: 0.0028144659008830786, Lr:0.0001\n",
      "Epoch 28, Step: 746, Loss: 0.025645647197961807, Lr:0.0001\n",
      "Epoch 28, Step: 747, Loss: 0.041468072682619095, Lr:0.0001\n",
      "Epoch 28, Step: 748, Loss: 0.05837612599134445, Lr:0.0001\n",
      "Epoch 28, Step: 749, Loss: 0.08259440958499908, Lr:0.0001\n",
      "Epoch 28, Step: 750, Loss: 0.0034351989161223173, Lr:0.0001\n",
      "Epoch 28, Step: 751, Loss: 0.023192327469587326, Lr:0.0001\n",
      "Epoch 28, Step: 752, Loss: 0.024506984278559685, Lr:0.0001\n",
      "Epoch 28, Step: 753, Loss: 0.055777452886104584, Lr:0.0001\n",
      "Epoch 28, Step: 754, Loss: 0.003686400828883052, Lr:0.0001\n",
      "Epoch 28, Step: 755, Loss: 0.00499146431684494, Lr:0.0001\n",
      "Epoch 28, Step: 756, Loss: 0.004227555822581053, Lr:0.0001\n",
      "Epoch 28, Step: 757, Loss: 0.04449281468987465, Lr:0.0001\n",
      "Epoch 28, Step: 758, Loss: 0.01461030077189207, Lr:0.0001\n",
      "Epoch 28, Step: 759, Loss: 0.024716664105653763, Lr:0.0001\n",
      "Epoch 28, Step: 760, Loss: 0.056039657443761826, Lr:0.0001\n",
      "Epoch 28, Step: 761, Loss: 0.011096352711319923, Lr:0.0001\n",
      "Epoch 28, Step: 762, Loss: 0.08819150179624557, Lr:0.0001\n",
      "Epoch 28, Step: 763, Loss: 0.026730390265583992, Lr:0.0001\n",
      "Epoch 28, Step: 764, Loss: 0.03326163813471794, Lr:0.0001\n",
      "Epoch 28, Step: 765, Loss: 0.07718833535909653, Lr:0.0001\n",
      "Epoch 28, Step: 766, Loss: 0.02433815412223339, Lr:0.0001\n",
      "Epoch 28, Step: 767, Loss: 0.06991272419691086, Lr:0.0001\n",
      "Epoch 28, Step: 768, Loss: 0.1212601289153099, Lr:0.0001\n",
      "Epoch 28, Step: 769, Loss: 0.08342942595481873, Lr:0.0001\n",
      "Epoch 28, Step: 770, Loss: 0.05935505032539368, Lr:0.0001\n",
      "Epoch 28, Step: 771, Loss: 0.019479798153042793, Lr:0.0001\n",
      "Epoch 28, Step: 772, Loss: 0.012078240513801575, Lr:0.0001\n",
      "Epoch 28, Step: 773, Loss: 0.02981891855597496, Lr:0.0001\n",
      "Epoch 28, Step: 774, Loss: 0.0040083336643874645, Lr:0.0001\n",
      "Epoch 28, Step: 775, Loss: 0.10344579815864563, Lr:0.0001\n",
      "Epoch 28, Step: 776, Loss: 0.08110547810792923, Lr:0.0001\n",
      "Epoch 28, Step: 777, Loss: 0.16752322018146515, Lr:0.0001\n",
      "Epoch 28, Step: 778, Loss: 0.07569638639688492, Lr:0.0001\n",
      "Epoch 28, Step: 779, Loss: 0.024530917406082153, Lr:0.0001\n",
      "Epoch 28, Step: 780, Loss: 0.1558636873960495, Lr:0.0001\n",
      "Epoch 28, Step: 781, Loss: 0.2997114062309265, Lr:0.0001\n",
      "Epoch 28, Step: 782, Loss: 0.025323819369077682, Lr:0.0001\n",
      "Epoch 28, Step: 783, Loss: 0.055043552070856094, Lr:0.0001\n",
      "Epoch 28, Step: 784, Loss: 0.06808622926473618, Lr:0.0001\n",
      "Epoch 28, Step: 785, Loss: 0.04240553453564644, Lr:0.0001\n",
      "Epoch 28, Step: 786, Loss: 0.002784925978630781, Lr:0.0001\n",
      "Epoch 28, Step: 787, Loss: 0.0006017081323079765, Lr:0.0001\n",
      "Epoch 28, Step: 788, Loss: 0.008679482154548168, Lr:0.0001\n",
      "Epoch 28, Step: 789, Loss: 0.009079298935830593, Lr:0.0001\n",
      "Epoch 28, Step: 790, Loss: 0.005533269606530666, Lr:0.0001\n",
      "Epoch 28, Step: 791, Loss: 0.0821651741862297, Lr:0.0001\n",
      "Epoch 28, Step: 792, Loss: 0.03870941326022148, Lr:0.0001\n",
      "Epoch 28, Step: 793, Loss: 0.008478274568915367, Lr:0.0001\n",
      "Epoch 28, Step: 794, Loss: 0.004234593827277422, Lr:0.0001\n",
      "Epoch 28, Step: 795, Loss: 0.1550358235836029, Lr:0.0001\n",
      "Epoch 28, Step: 796, Loss: 0.19556039571762085, Lr:0.0001\n",
      "Epoch 28, Step: 797, Loss: 0.001041180919855833, Lr:0.0001\n",
      "Epoch 28, Step: 798, Loss: 0.018788674846291542, Lr:0.0001\n",
      "Epoch 28, Step: 799, Loss: 0.025513824075460434, Lr:0.0001\n",
      "Epoch 28, Step: 800, Loss: 0.06694718450307846, Lr:0.0001\n",
      "Epoch 28, Step: 801, Loss: 0.30696168541908264, Lr:0.0001\n",
      "Epoch 28, Step: 802, Loss: 0.021353429183363914, Lr:0.0001\n",
      "Epoch 28, Step: 803, Loss: 0.002438680035993457, Lr:0.0001\n",
      "Epoch 28, Step: 804, Loss: 0.0030303248204290867, Lr:0.0001\n",
      "Epoch 28, Step: 805, Loss: 0.0030011176131665707, Lr:0.0001\n",
      "Epoch 28, Step: 806, Loss: 0.03778073936700821, Lr:0.0001\n",
      "Epoch 28, Step: 807, Loss: 0.06137455627322197, Lr:0.0001\n",
      "Epoch 28, Step: 808, Loss: 0.00033173212432302535, Lr:0.0001\n",
      "Epoch 28, Step: 809, Loss: 0.12674233317375183, Lr:0.0001\n",
      "Epoch 28, Step: 810, Loss: 0.1495991051197052, Lr:0.0001\n",
      "Epoch 28, Step: 811, Loss: 0.039706263691186905, Lr:0.0001\n",
      "Epoch 28, Step: 812, Loss: 0.09299254417419434, Lr:0.0001\n",
      "Epoch 28, Step: 813, Loss: 0.0001412874407833442, Lr:0.0001\n",
      "Epoch 28, Step: 814, Loss: 0.030030569061636925, Lr:0.0001\n",
      "Epoch 28, Step: 815, Loss: 0.046141721308231354, Lr:0.0001\n",
      "Epoch 28, Step: 816, Loss: 0.09054840356111526, Lr:0.0001\n",
      "Epoch 28, Step: 817, Loss: 0.08529642224311829, Lr:0.0001\n",
      "Epoch 28, Step: 818, Loss: 0.3199589252471924, Lr:0.0001\n",
      "Epoch 28, Step: 819, Loss: 0.03212301433086395, Lr:0.0001\n",
      "Epoch 28, Step: 820, Loss: 0.06835773587226868, Lr:0.0001\n",
      "Epoch 28, Step: 821, Loss: 0.006180666387081146, Lr:0.0001\n",
      "Epoch 28, Step: 822, Loss: 0.004561066161841154, Lr:0.0001\n",
      "Epoch 28, Step: 823, Loss: 0.11640691757202148, Lr:0.0001\n",
      "Epoch 28, Step: 824, Loss: 0.06788744777441025, Lr:0.0001\n",
      "Epoch 28, Step: 825, Loss: 0.03615193068981171, Lr:0.0001\n",
      "Epoch 28, Step: 826, Loss: 0.026549873873591423, Lr:0.0001\n",
      "Epoch 28, Step: 827, Loss: 0.11998732388019562, Lr:0.0001\n",
      "Epoch 28, Step: 828, Loss: 0.06510598957538605, Lr:0.0001\n",
      "Epoch 28, Step: 829, Loss: 0.019098909571766853, Lr:0.0001\n",
      "Epoch 28, Step: 830, Loss: 0.06762408465147018, Lr:0.0001\n",
      "Epoch 28, Step: 831, Loss: 0.006751847453415394, Lr:0.0001\n",
      "Epoch 28, Step: 832, Loss: 0.002219757530838251, Lr:0.0001\n",
      "Epoch 28, Step: 833, Loss: 0.021782301366329193, Lr:0.0001\n",
      "Epoch 28, Step: 834, Loss: 0.005982927046716213, Lr:0.0001\n",
      "Epoch 28, Step: 835, Loss: 0.03480624780058861, Lr:0.0001\n",
      "Epoch 28, Step: 836, Loss: 0.006306113675236702, Lr:0.0001\n",
      "Epoch 28, Step: 837, Loss: 0.01654024049639702, Lr:0.0001\n",
      "Epoch 28, Step: 838, Loss: 0.039823438972234726, Lr:0.0001\n",
      "Epoch 28, Step: 839, Loss: 0.17624066770076752, Lr:0.0001\n",
      "Epoch 28, Step: 840, Loss: 0.002470173640176654, Lr:0.0001\n",
      "Epoch 28, Step: 841, Loss: 0.037254128605127335, Lr:0.0001\n",
      "Epoch 28, Step: 842, Loss: 0.010223270393908024, Lr:0.0001\n",
      "Epoch 28, Step: 843, Loss: 0.17074279487133026, Lr:0.0001\n",
      "Epoch 28, Step: 844, Loss: 0.03660360723733902, Lr:0.0001\n",
      "Epoch 28, Step: 845, Loss: 0.036157798022031784, Lr:0.0001\n",
      "Epoch 28, Step: 846, Loss: 0.08516673743724823, Lr:0.0001\n",
      "Epoch 28, Step: 847, Loss: 0.2508019506931305, Lr:0.0001\n",
      "Epoch 28, Step: 848, Loss: 0.35782644152641296, Lr:0.0001\n",
      "Epoch 28, Step: 849, Loss: 0.07332758605480194, Lr:0.0001\n",
      "Epoch 28, Step: 850, Loss: 0.014391065575182438, Lr:0.0001\n",
      "Epoch 28, Step: 851, Loss: 0.00949628185480833, Lr:0.0001\n",
      "Epoch 28, Step: 852, Loss: 0.005921483971178532, Lr:0.0001\n",
      "Epoch 28, Step: 853, Loss: 0.008669937960803509, Lr:0.0001\n",
      "Epoch 28, Step: 854, Loss: 0.01915033347904682, Lr:0.0001\n",
      "Epoch 28, Step: 855, Loss: 0.004811899736523628, Lr:0.0001\n",
      "Epoch 28, Step: 856, Loss: 0.19140596687793732, Lr:0.0001\n",
      "Epoch 28, Step: 857, Loss: 0.015071810223162174, Lr:0.0001\n",
      "Epoch 28, Step: 858, Loss: 0.10052444040775299, Lr:0.0001\n",
      "Epoch 28, Step: 859, Loss: 0.023553380742669106, Lr:0.0001\n",
      "Epoch 28, Step: 860, Loss: 0.05345156788825989, Lr:0.0001\n",
      "Epoch 28, Step: 861, Loss: 0.02373756468296051, Lr:0.0001\n",
      "Epoch 28, Step: 862, Loss: 0.24672743678092957, Lr:0.0001\n",
      "Epoch 28, Step: 863, Loss: 0.24290645122528076, Lr:0.0001\n",
      "Epoch 28, Step: 864, Loss: 0.0348794125020504, Lr:0.0001\n",
      "Epoch 28, Step: 865, Loss: 0.018429720774292946, Lr:0.0001\n",
      "Epoch 28, Step: 866, Loss: 0.0889696329832077, Lr:0.0001\n",
      "Epoch 28, Step: 867, Loss: 0.3336469829082489, Lr:0.0001\n",
      "Epoch 28, Step: 868, Loss: 0.05612571910023689, Lr:0.0001\n",
      "Epoch 28, Step: 869, Loss: 0.0006927637150511146, Lr:0.0001\n",
      "Epoch 28, Step: 870, Loss: 0.3328043520450592, Lr:0.0001\n",
      "Epoch 28, Step: 871, Loss: 0.18940392136573792, Lr:0.0001\n",
      "Epoch 28, Step: 872, Loss: 0.007284377235919237, Lr:0.0001\n",
      "Epoch 28, Step: 873, Loss: 0.012347903102636337, Lr:0.0001\n",
      "Epoch 28, Step: 874, Loss: 0.06180817633867264, Lr:0.0001\n",
      "Epoch 28, Step: 875, Loss: 0.02852517180144787, Lr:0.0001\n",
      "Epoch 28, Step: 876, Loss: 0.05649547278881073, Lr:0.0001\n",
      "Epoch 28, Step: 877, Loss: 0.054331447929143906, Lr:0.0001\n",
      "Epoch 28, Step: 878, Loss: 0.15543776750564575, Lr:0.0001\n",
      "Epoch 28, Step: 879, Loss: 0.014204301871359348, Lr:0.0001\n",
      "Epoch 28, Step: 880, Loss: 0.09096880257129669, Lr:0.0001\n",
      "Epoch 28, Step: 881, Loss: 0.019160719588398933, Lr:0.0001\n",
      "Epoch 28, Step: 882, Loss: 0.0809980183839798, Lr:0.0001\n",
      "Epoch 28, Step: 883, Loss: 0.0020807930268347263, Lr:0.0001\n",
      "Epoch 28, Step: 884, Loss: 0.2994813024997711, Lr:0.0001\n",
      "Epoch 28, Step: 885, Loss: 0.19755315780639648, Lr:0.0001\n",
      "Epoch 28, Step: 886, Loss: 0.0024718730710446835, Lr:0.0001\n",
      "Epoch 28, Step: 887, Loss: 0.0017024235567077994, Lr:0.0001\n",
      "Epoch 28, Step: 888, Loss: 0.012028631754219532, Lr:0.0001\n",
      "Epoch 28, Step: 889, Loss: 0.31678539514541626, Lr:0.0001\n",
      "Epoch 28, Step: 890, Loss: 0.022565219551324844, Lr:0.0001\n",
      "Epoch 28, Step: 891, Loss: 0.03990227356553078, Lr:0.0001\n",
      "Epoch 28, Step: 892, Loss: 0.01547914743423462, Lr:0.0001\n",
      "Epoch 28, Step: 893, Loss: 0.03529486432671547, Lr:0.0001\n",
      "Epoch 28, Step: 894, Loss: 0.06112735718488693, Lr:0.0001\n",
      "Epoch 28, Step: 895, Loss: 0.02641480602324009, Lr:0.0001\n",
      "Epoch 28, Step: 896, Loss: 0.1290721446275711, Lr:0.0001\n",
      "Epoch 28, Step: 897, Loss: 0.2893347144126892, Lr:0.0001\n",
      "Epoch 28, Step: 898, Loss: 0.13802513480186462, Lr:0.0001\n",
      "Epoch 28, Step: 899, Loss: 0.10934897512197495, Lr:0.0001\n",
      "Epoch 28, Step: 900, Loss: 0.02725929766893387, Lr:0.0001\n",
      "Epoch 28, Step: 901, Loss: 0.4600480794906616, Lr:0.0001\n",
      "Epoch 28, Step: 902, Loss: 0.06377553939819336, Lr:0.0001\n",
      "Epoch 28, Step: 903, Loss: 0.04707205295562744, Lr:0.0001\n",
      "Epoch 28, Step: 904, Loss: 0.0072420258074998856, Lr:0.0001\n",
      "Epoch 28, Step: 905, Loss: 0.11691548675298691, Lr:0.0001\n",
      "Epoch 28, Step: 906, Loss: 0.019127553328871727, Lr:0.0001\n",
      "Epoch 28, Step: 907, Loss: 0.00761036854237318, Lr:0.0001\n",
      "Epoch 28, Step: 908, Loss: 0.10596632957458496, Lr:0.0001\n",
      "Epoch 28, Step: 909, Loss: 0.02044811099767685, Lr:0.0001\n",
      "Epoch 28, Step: 910, Loss: 0.00900371465831995, Lr:0.0001\n",
      "Epoch 28, Step: 911, Loss: 0.002898600185289979, Lr:0.0001\n",
      "Epoch 28, Step: 912, Loss: 0.02279769256711006, Lr:0.0001\n",
      "Epoch 28, Step: 913, Loss: 0.07149884104728699, Lr:0.0001\n",
      "Epoch 28, Step: 914, Loss: 0.027740158140659332, Lr:0.0001\n",
      "Epoch 28, Step: 915, Loss: 0.0144954277202487, Lr:0.0001\n",
      "Epoch 28, Step: 916, Loss: 0.1109706237912178, Lr:0.0001\n",
      "Epoch 28, Step: 917, Loss: 0.026424843817949295, Lr:0.0001\n",
      "Epoch 28, Step: 918, Loss: 0.07403886318206787, Lr:0.0001\n",
      "Epoch 28, Step: 919, Loss: 0.016234073787927628, Lr:0.0001\n",
      "Epoch 28, Step: 920, Loss: 0.002668695757165551, Lr:0.0001\n",
      "Epoch 28, Step: 921, Loss: 0.28791990876197815, Lr:0.0001\n",
      "Epoch 28, Step: 922, Loss: 0.00898036826401949, Lr:0.0001\n",
      "Epoch 28, Step: 923, Loss: 0.009332666173577309, Lr:0.0001\n",
      "Epoch 28, Step: 924, Loss: 0.08903543651103973, Lr:0.0001\n",
      "Epoch 28, Step: 925, Loss: 0.05611271783709526, Lr:0.0001\n",
      "Epoch 28, Step: 926, Loss: 0.17387434840202332, Lr:0.0001\n",
      "Epoch 28, Step: 927, Loss: 0.03333451226353645, Lr:0.0001\n",
      "Epoch 28, Step: 928, Loss: 0.01599711924791336, Lr:0.0001\n",
      "Epoch 28, Step: 929, Loss: 0.062166571617126465, Lr:0.0001\n",
      "Epoch 28, Step: 930, Loss: 0.1723315268754959, Lr:0.0001\n",
      "Epoch 28, Step: 931, Loss: 0.029959531500935555, Lr:0.0001\n",
      "Epoch 28, Step: 932, Loss: 0.03704776614904404, Lr:0.0001\n",
      "Epoch 28, Step: 933, Loss: 0.3266388773918152, Lr:0.0001\n",
      "Epoch 28, Step: 934, Loss: 0.07178576290607452, Lr:0.0001\n",
      "Epoch 28, Step: 935, Loss: 0.007617553696036339, Lr:0.0001\n",
      "Epoch 28, Step: 936, Loss: 0.08573495596647263, Lr:0.0001\n",
      "Epoch 28, Step: 937, Loss: 0.01292092353105545, Lr:0.0001\n",
      "Epoch 28, Step: 938, Loss: 0.03376111015677452, Lr:0.0001\n",
      "Epoch 28, Step: 939, Loss: 0.36850330233573914, Lr:0.0001\n",
      "Epoch 28, Step: 940, Loss: 0.010479029268026352, Lr:0.0001\n",
      "Epoch 28, Step: 941, Loss: 0.08397942781448364, Lr:0.0001\n",
      "Epoch 28, Step: 942, Loss: 0.01030515506863594, Lr:0.0001\n",
      "Epoch 28, Step: 943, Loss: 0.024901116266846657, Lr:0.0001\n",
      "Epoch 28, Step: 944, Loss: 0.02059321105480194, Lr:0.0001\n",
      "Epoch 28, Step: 945, Loss: 0.06080624461174011, Lr:0.0001\n",
      "Epoch 28, Step: 946, Loss: 0.01586778461933136, Lr:0.0001\n",
      "Epoch 28, Step: 947, Loss: 0.20440100133419037, Lr:0.0001\n",
      "Epoch 28, Step: 948, Loss: 0.10917066037654877, Lr:0.0001\n",
      "Epoch 28, Step: 949, Loss: 0.05145983397960663, Lr:0.0001\n",
      "Epoch 28, Step: 950, Loss: 0.013056457042694092, Lr:0.0001\n",
      "Epoch 28, Step: 951, Loss: 0.011844328604638577, Lr:0.0001\n",
      "Epoch 28, Step: 952, Loss: 0.01431711670011282, Lr:0.0001\n",
      "Epoch 28, Step: 953, Loss: 0.030487051233649254, Lr:0.0001\n",
      "Epoch 28, Step: 954, Loss: 0.010269276797771454, Lr:0.0001\n",
      "Epoch 28, Step: 955, Loss: 0.013856254518032074, Lr:0.0001\n",
      "Epoch 28, Step: 956, Loss: 0.00704475212842226, Lr:0.0001\n",
      "Epoch 28, Step: 957, Loss: 0.0173269584774971, Lr:0.0001\n",
      "Epoch 28, Step: 958, Loss: 0.009639890864491463, Lr:0.0001\n",
      "Epoch 28, Step: 959, Loss: 0.05265558138489723, Lr:0.0001\n",
      "Epoch 28, Step: 960, Loss: 0.015926804393529892, Lr:0.0001\n",
      "Epoch 28, Step: 961, Loss: 0.00940412376075983, Lr:0.0001\n",
      "Epoch 28, Step: 962, Loss: 0.04391922801733017, Lr:0.0001\n",
      "Epoch 28, Step: 963, Loss: 0.1406000405550003, Lr:0.0001\n",
      "Epoch 28, Step: 964, Loss: 0.16279137134552002, Lr:0.0001\n",
      "Epoch 28, Step: 965, Loss: 0.022957295179367065, Lr:0.0001\n",
      "Epoch 28, Step: 966, Loss: 0.0005754199810326099, Lr:0.0001\n",
      "Epoch 28, Step: 967, Loss: 0.009230053052306175, Lr:0.0001\n",
      "Epoch 28, Step: 968, Loss: 0.008321011438965797, Lr:0.0001\n",
      "Epoch 28, Step: 969, Loss: 0.13033127784729004, Lr:0.0001\n",
      "Epoch 28, Step: 970, Loss: 0.0006462744204327464, Lr:0.0001\n",
      "Epoch 28, Step: 971, Loss: 0.002142383949831128, Lr:0.0001\n",
      "Epoch 28, Step: 972, Loss: 0.04136162996292114, Lr:0.0001\n",
      "Epoch 28, Step: 973, Loss: 0.010505515150725842, Lr:0.0001\n",
      "Epoch 28, Step: 974, Loss: 0.04196985810995102, Lr:0.0001\n",
      "Epoch 28, Step: 975, Loss: 0.0058190361596643925, Lr:0.0001\n",
      "Epoch 28, Step: 976, Loss: 0.0040306271985173225, Lr:0.0001\n",
      "Epoch 28, Step: 977, Loss: 0.09035273641347885, Lr:0.0001\n",
      "Epoch 28, Step: 978, Loss: 0.01579905115067959, Lr:0.0001\n",
      "Epoch 28, Step: 979, Loss: 0.024904247373342514, Lr:0.0001\n",
      "Epoch 28, Step: 980, Loss: 0.18295100331306458, Lr:0.0001\n",
      "Epoch 28, Step: 981, Loss: 0.014576327987015247, Lr:0.0001\n",
      "Epoch 28, Step: 982, Loss: 0.008003843948245049, Lr:0.0001\n",
      "Epoch 28, Step: 983, Loss: 0.02993038296699524, Lr:0.0001\n",
      "Epoch 28, Step: 984, Loss: 0.06141025573015213, Lr:0.0001\n",
      "Epoch 28, Step: 985, Loss: 0.025373674929142, Lr:0.0001\n",
      "Epoch 28, Step: 986, Loss: 0.01257026381790638, Lr:0.0001\n",
      "Epoch 28, Step: 987, Loss: 0.01085752621293068, Lr:0.0001\n",
      "Epoch 28, Step: 988, Loss: 0.07032426446676254, Lr:0.0001\n",
      "Epoch 28, Step: 989, Loss: 0.006506187841296196, Lr:0.0001\n",
      "Epoch 28, Step: 990, Loss: 0.00940360315144062, Lr:0.0001\n",
      "Epoch 28, Step: 991, Loss: 0.006083711050450802, Lr:0.0001\n",
      "Epoch 28, Step: 992, Loss: 0.0116944694891572, Lr:0.0001\n",
      "Epoch 28, Step: 993, Loss: 0.0054193721152842045, Lr:0.0001\n",
      "Epoch 28, Step: 994, Loss: 0.2039581686258316, Lr:0.0001\n",
      "Epoch 28, Step: 995, Loss: 0.054425206035375595, Lr:0.0001\n",
      "Epoch 28, Step: 996, Loss: 0.03867824003100395, Lr:0.0001\n",
      "Epoch 28, Step: 997, Loss: 0.007477746345102787, Lr:0.0001\n",
      "Epoch 28, Step: 998, Loss: 0.009461402893066406, Lr:0.0001\n",
      "Epoch 28, Step: 999, Loss: 0.09800802916288376, Lr:0.0001\n",
      "Epoch 28, Step: 1000, Loss: 0.008850584737956524, Lr:0.0001\n",
      "Epoch 28, Step: 1001, Loss: 0.005177057348191738, Lr:0.0001\n",
      "Epoch 28, Step: 1002, Loss: 0.01271117851138115, Lr:0.0001\n",
      "Epoch 28, Step: 1003, Loss: 0.08678431808948517, Lr:0.0001\n",
      "Epoch 28, Step: 1004, Loss: 0.025950752198696136, Lr:0.0001\n",
      "Epoch 28, Step: 1005, Loss: 0.014145998284220695, Lr:0.0001\n",
      "Epoch 28, Step: 1006, Loss: 0.038647331297397614, Lr:0.0001\n",
      "Epoch 28, Step: 1007, Loss: 0.24528056383132935, Lr:0.0001\n",
      "Epoch 28, Step: 1008, Loss: 0.008683441206812859, Lr:0.0001\n",
      "Epoch 28, Step: 1009, Loss: 0.04892200231552124, Lr:0.0001\n",
      "Epoch 28, Step: 1010, Loss: 0.12283410131931305, Lr:0.0001\n",
      "Epoch 28, Step: 1011, Loss: 0.03656657040119171, Lr:0.0001\n",
      "Epoch 28, Step: 1012, Loss: 0.12683463096618652, Lr:0.0001\n",
      "Epoch 28, Step: 1013, Loss: 0.11087125539779663, Lr:0.0001\n",
      "Epoch 28, Step: 1014, Loss: 0.011783251538872719, Lr:0.0001\n",
      "Epoch 28, Step: 1015, Loss: 0.025062575936317444, Lr:0.0001\n",
      "Epoch 28, Step: 1016, Loss: 0.017124144360423088, Lr:0.0001\n",
      "Epoch 28, Step: 1017, Loss: 0.0014082345878705382, Lr:0.0001\n",
      "Epoch 28, Step: 1018, Loss: 0.07015995681285858, Lr:0.0001\n",
      "Epoch 28, Step: 1019, Loss: 0.005580235738307238, Lr:0.0001\n",
      "Epoch 28, Step: 1020, Loss: 0.10320594161748886, Lr:0.0001\n",
      "Epoch 28, Step: 1021, Loss: 0.012049967423081398, Lr:0.0001\n",
      "Epoch 28, Step: 1022, Loss: 0.10007347166538239, Lr:0.0001\n",
      "Epoch 28, Step: 1023, Loss: 0.006753000430762768, Lr:0.0001\n",
      "Epoch 28, Step: 1024, Loss: 0.12508833408355713, Lr:0.0001\n",
      "Epoch 28, Step: 1025, Loss: 0.007387431338429451, Lr:0.0001\n",
      "Epoch 28, Step: 1026, Loss: 0.16305957734584808, Lr:0.0001\n",
      "Epoch 28, Step: 1027, Loss: 0.09946734458208084, Lr:0.0001\n",
      "Epoch 28, Step: 1028, Loss: 0.14503800868988037, Lr:0.0001\n",
      "Epoch 28, Step: 1029, Loss: 0.00869053415954113, Lr:0.0001\n",
      "Epoch 28, Step: 1030, Loss: 0.10330895334482193, Lr:0.0001\n",
      "Epoch 28, Step: 1031, Loss: 0.05223068222403526, Lr:0.0001\n",
      "Epoch 28, Step: 1032, Loss: 0.030300423502922058, Lr:0.0001\n",
      "Epoch 28, Step: 1033, Loss: 0.04565763100981712, Lr:0.0001\n",
      "Epoch 28, Step: 1034, Loss: 0.03766453638672829, Lr:0.0001\n",
      "Epoch 28, Step: 1035, Loss: 0.0032793465070426464, Lr:0.0001\n",
      "Epoch 28, Step: 1036, Loss: 0.005059327930212021, Lr:0.0001\n",
      "Epoch 28, Step: 1037, Loss: 0.07188628613948822, Lr:0.0001\n",
      "Epoch 28, Step: 1038, Loss: 0.021410422399640083, Lr:0.0001\n",
      "Epoch 28, Step: 1039, Loss: 0.00914886686950922, Lr:0.0001\n",
      "Epoch 28, Step: 1040, Loss: 0.035034310072660446, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 28\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:16 loss: 0.1554 (0.1554) acc1: 87.5000 (87.5000) acc5: 100.0000 (100.0000) time: 0.2905 data: 0.1235 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.0085 (0.0719) acc1: 100.0000 (97.7273) acc5: 100.0000 (100.0000) time: 0.2998 data: 0.1192 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0040 (0.0907) acc1: 100.0000 (97.6190) acc5: 100.0000 (100.0000) time: 0.2959 data: 0.1170 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.0516 (0.1463) acc1: 93.7500 (95.3629) acc5: 100.0000 (100.0000) time: 0.3107 data: 0.1200 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.1026 (0.1753) acc1: 93.7500 (95.2744) acc5: 100.0000 (100.0000) time: 0.3228 data: 0.1250 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0218 (0.1536) acc1: 100.0000 (95.7108) acc5: 100.0000 (100.0000) time: 0.3094 data: 0.1255 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0218 (0.1842) acc1: 100.0000 (95.0057) acc5: 100.0000 (100.0000) time: 0.2943 data: 0.1199 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.3023 s / it)\n",
      "* Acc@1 95.006 Acc@5 100.000 loss 0.184\n",
      "Accuracy of the network on the 881 test image: 95.0%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 29, Step: 0, Loss: 0.03411726653575897, Lr:0.0001\n",
      "Epoch 29, Step: 1, Loss: 0.021224455907940865, Lr:0.0001\n",
      "Epoch 29, Step: 2, Loss: 0.3284214735031128, Lr:0.0001\n",
      "Epoch 29, Step: 3, Loss: 0.004760596435517073, Lr:0.0001\n",
      "Epoch 29, Step: 4, Loss: 0.020348578691482544, Lr:0.0001\n",
      "Epoch 29, Step: 5, Loss: 0.00249530840665102, Lr:0.0001\n",
      "Epoch 29, Step: 6, Loss: 0.012874320149421692, Lr:0.0001\n",
      "Epoch 29, Step: 7, Loss: 0.05190582573413849, Lr:0.0001\n",
      "Epoch 29, Step: 8, Loss: 0.01754140481352806, Lr:0.0001\n",
      "Epoch 29, Step: 9, Loss: 0.3409329056739807, Lr:0.0001\n",
      "Epoch 29, Step: 10, Loss: 0.012103565968573093, Lr:0.0001\n",
      "Epoch 29, Step: 11, Loss: 0.0007528180722147226, Lr:0.0001\n",
      "Epoch 29, Step: 12, Loss: 0.05408327654004097, Lr:0.0001\n",
      "Epoch 29, Step: 13, Loss: 0.1748812198638916, Lr:0.0001\n",
      "Epoch 29, Step: 14, Loss: 0.0027508949860930443, Lr:0.0001\n",
      "Epoch 29, Step: 15, Loss: 0.0003230294387321919, Lr:0.0001\n",
      "Epoch 29, Step: 16, Loss: 0.02207890897989273, Lr:0.0001\n",
      "Epoch 29, Step: 17, Loss: 0.023192252963781357, Lr:0.0001\n",
      "Epoch 29, Step: 18, Loss: 0.014195863157510757, Lr:0.0001\n",
      "Epoch 29, Step: 19, Loss: 0.0010644159046933055, Lr:0.0001\n",
      "Epoch 29, Step: 20, Loss: 0.05567053705453873, Lr:0.0001\n",
      "Epoch 29, Step: 21, Loss: 0.09081890434026718, Lr:0.0001\n",
      "Epoch 29, Step: 22, Loss: 0.09192199259996414, Lr:0.0001\n",
      "Epoch 29, Step: 23, Loss: 0.03545625880360603, Lr:0.0001\n",
      "Epoch 29, Step: 24, Loss: 0.05413452908396721, Lr:0.0001\n",
      "Epoch 29, Step: 25, Loss: 0.008149257861077785, Lr:0.0001\n",
      "Epoch 29, Step: 26, Loss: 0.023606162518262863, Lr:0.0001\n",
      "Epoch 29, Step: 27, Loss: 0.05340435355901718, Lr:0.0001\n",
      "Epoch 29, Step: 28, Loss: 0.026073724031448364, Lr:0.0001\n",
      "Epoch 29, Step: 29, Loss: 0.006961470004171133, Lr:0.0001\n",
      "Epoch 29, Step: 30, Loss: 0.12079215049743652, Lr:0.0001\n",
      "Epoch 29, Step: 31, Loss: 0.026303153485059738, Lr:0.0001\n",
      "Epoch 29, Step: 32, Loss: 0.014816511422395706, Lr:0.0001\n",
      "Epoch 29, Step: 33, Loss: 0.03683862462639809, Lr:0.0001\n",
      "Epoch 29, Step: 34, Loss: 0.005085983779281378, Lr:0.0001\n",
      "Epoch 29, Step: 35, Loss: 0.02295159362256527, Lr:0.0001\n",
      "Epoch 29, Step: 36, Loss: 0.08835956454277039, Lr:0.0001\n",
      "Epoch 29, Step: 37, Loss: 0.06776167452335358, Lr:0.0001\n",
      "Epoch 29, Step: 38, Loss: 0.01174827292561531, Lr:0.0001\n",
      "Epoch 29, Step: 39, Loss: 0.0009334417409263551, Lr:0.0001\n",
      "Epoch 29, Step: 40, Loss: 0.06809284538030624, Lr:0.0001\n",
      "Epoch 29, Step: 41, Loss: 0.05701414868235588, Lr:0.0001\n",
      "Epoch 29, Step: 42, Loss: 0.024223707616329193, Lr:0.0001\n",
      "Epoch 29, Step: 43, Loss: 0.02176228165626526, Lr:0.0001\n",
      "Epoch 29, Step: 44, Loss: 0.033604852855205536, Lr:0.0001\n",
      "Epoch 29, Step: 45, Loss: 0.09314051270484924, Lr:0.0001\n",
      "Epoch 29, Step: 46, Loss: 0.02290596067905426, Lr:0.0001\n",
      "Epoch 29, Step: 47, Loss: 0.013998772017657757, Lr:0.0001\n",
      "Epoch 29, Step: 48, Loss: 0.09362179785966873, Lr:0.0001\n",
      "Epoch 29, Step: 49, Loss: 0.019845521077513695, Lr:0.0001\n",
      "Epoch 29, Step: 50, Loss: 0.005707886535674334, Lr:0.0001\n",
      "Epoch 29, Step: 51, Loss: 0.03356890380382538, Lr:0.0001\n",
      "Epoch 29, Step: 52, Loss: 0.0161959920078516, Lr:0.0001\n",
      "Epoch 29, Step: 53, Loss: 0.0046482086181640625, Lr:0.0001\n",
      "Epoch 29, Step: 54, Loss: 0.00822916254401207, Lr:0.0001\n",
      "Epoch 29, Step: 55, Loss: 0.03201231360435486, Lr:0.0001\n",
      "Epoch 29, Step: 56, Loss: 0.015447104349732399, Lr:0.0001\n",
      "Epoch 29, Step: 57, Loss: 0.04993834346532822, Lr:0.0001\n",
      "Epoch 29, Step: 58, Loss: 0.04608730971813202, Lr:0.0001\n",
      "Epoch 29, Step: 59, Loss: 0.012791885063052177, Lr:0.0001\n",
      "Epoch 29, Step: 60, Loss: 0.000667716667521745, Lr:0.0001\n",
      "Epoch 29, Step: 61, Loss: 0.007615083362907171, Lr:0.0001\n",
      "Epoch 29, Step: 62, Loss: 0.08934647589921951, Lr:0.0001\n",
      "Epoch 29, Step: 63, Loss: 0.03480544686317444, Lr:0.0001\n",
      "Epoch 29, Step: 64, Loss: 0.005498491693288088, Lr:0.0001\n",
      "Epoch 29, Step: 65, Loss: 0.09772730618715286, Lr:0.0001\n",
      "Epoch 29, Step: 66, Loss: 0.067689910531044, Lr:0.0001\n",
      "Epoch 29, Step: 67, Loss: 0.0875866711139679, Lr:0.0001\n",
      "Epoch 29, Step: 68, Loss: 0.004007197916507721, Lr:0.0001\n",
      "Epoch 29, Step: 69, Loss: 0.013627382926642895, Lr:0.0001\n",
      "Epoch 29, Step: 70, Loss: 0.02307480201125145, Lr:0.0001\n",
      "Epoch 29, Step: 71, Loss: 0.1857144683599472, Lr:0.0001\n",
      "Epoch 29, Step: 72, Loss: 0.03429924696683884, Lr:0.0001\n",
      "Epoch 29, Step: 73, Loss: 0.030591098591685295, Lr:0.0001\n",
      "Epoch 29, Step: 74, Loss: 0.02062259614467621, Lr:0.0001\n",
      "Epoch 29, Step: 75, Loss: 0.0573914498090744, Lr:0.0001\n",
      "Epoch 29, Step: 76, Loss: 0.003137862542644143, Lr:0.0001\n",
      "Epoch 29, Step: 77, Loss: 0.012903951108455658, Lr:0.0001\n",
      "Epoch 29, Step: 78, Loss: 0.07535245269536972, Lr:0.0001\n",
      "Epoch 29, Step: 79, Loss: 0.3929360508918762, Lr:0.0001\n",
      "Epoch 29, Step: 80, Loss: 0.10668604075908661, Lr:0.0001\n",
      "Epoch 29, Step: 81, Loss: 0.04215891286730766, Lr:0.0001\n",
      "Epoch 29, Step: 82, Loss: 0.016660422086715698, Lr:0.0001\n",
      "Epoch 29, Step: 83, Loss: 0.011406932957470417, Lr:0.0001\n",
      "Epoch 29, Step: 84, Loss: 0.14776955544948578, Lr:0.0001\n",
      "Epoch 29, Step: 85, Loss: 0.09038471430540085, Lr:0.0001\n",
      "Epoch 29, Step: 86, Loss: 0.06948724389076233, Lr:0.0001\n",
      "Epoch 29, Step: 87, Loss: 0.024621054530143738, Lr:0.0001\n",
      "Epoch 29, Step: 88, Loss: 0.1792578101158142, Lr:0.0001\n",
      "Epoch 29, Step: 89, Loss: 0.05710230767726898, Lr:0.0001\n",
      "Epoch 29, Step: 90, Loss: 0.24201034009456635, Lr:0.0001\n",
      "Epoch 29, Step: 91, Loss: 0.2667488157749176, Lr:0.0001\n",
      "Epoch 29, Step: 92, Loss: 0.019195863977074623, Lr:0.0001\n",
      "Epoch 29, Step: 93, Loss: 0.12467513233423233, Lr:0.0001\n",
      "Epoch 29, Step: 94, Loss: 0.21098317205905914, Lr:0.0001\n",
      "Epoch 29, Step: 95, Loss: 0.03215297311544418, Lr:0.0001\n",
      "Epoch 29, Step: 96, Loss: 0.12249954044818878, Lr:0.0001\n",
      "Epoch 29, Step: 97, Loss: 0.03221188858151436, Lr:0.0001\n",
      "Epoch 29, Step: 98, Loss: 0.10696129500865936, Lr:0.0001\n",
      "Epoch 29, Step: 99, Loss: 0.010796346701681614, Lr:0.0001\n",
      "Epoch 29, Step: 100, Loss: 0.07913900911808014, Lr:0.0001\n",
      "Epoch 29, Step: 101, Loss: 0.02021322399377823, Lr:0.0001\n",
      "Epoch 29, Step: 102, Loss: 0.02621307782828808, Lr:0.0001\n",
      "Epoch 29, Step: 103, Loss: 0.012770080007612705, Lr:0.0001\n",
      "Epoch 29, Step: 104, Loss: 0.0022987257689237595, Lr:0.0001\n",
      "Epoch 29, Step: 105, Loss: 0.1956099569797516, Lr:0.0001\n",
      "Epoch 29, Step: 106, Loss: 0.020635226741433144, Lr:0.0001\n",
      "Epoch 29, Step: 107, Loss: 0.06231146678328514, Lr:0.0001\n",
      "Epoch 29, Step: 108, Loss: 0.06187671795487404, Lr:0.0001\n",
      "Epoch 29, Step: 109, Loss: 0.0743621215224266, Lr:0.0001\n",
      "Epoch 29, Step: 110, Loss: 0.006010847166180611, Lr:0.0001\n",
      "Epoch 29, Step: 111, Loss: 0.009901878423988819, Lr:0.0001\n",
      "Epoch 29, Step: 112, Loss: 0.016027305275201797, Lr:0.0001\n",
      "Epoch 29, Step: 113, Loss: 0.002322335261851549, Lr:0.0001\n",
      "Epoch 29, Step: 114, Loss: 0.10189789533615112, Lr:0.0001\n",
      "Epoch 29, Step: 115, Loss: 0.2485676258802414, Lr:0.0001\n",
      "Epoch 29, Step: 116, Loss: 0.29719239473342896, Lr:0.0001\n",
      "Epoch 29, Step: 117, Loss: 0.07421323657035828, Lr:0.0001\n",
      "Epoch 29, Step: 118, Loss: 0.01785637065768242, Lr:0.0001\n",
      "Epoch 29, Step: 119, Loss: 0.01682775653898716, Lr:0.0001\n",
      "Epoch 29, Step: 120, Loss: 0.0019180021481588483, Lr:0.0001\n",
      "Epoch 29, Step: 121, Loss: 0.0026467645075172186, Lr:0.0001\n",
      "Epoch 29, Step: 122, Loss: 0.07061628997325897, Lr:0.0001\n",
      "Epoch 29, Step: 123, Loss: 0.16403523087501526, Lr:0.0001\n",
      "Epoch 29, Step: 124, Loss: 0.04422079399228096, Lr:0.0001\n",
      "Epoch 29, Step: 125, Loss: 0.0030434690415859222, Lr:0.0001\n",
      "Epoch 29, Step: 126, Loss: 0.004575429949909449, Lr:0.0001\n",
      "Epoch 29, Step: 127, Loss: 0.22662901878356934, Lr:0.0001\n",
      "Epoch 29, Step: 128, Loss: 0.1689339131116867, Lr:0.0001\n",
      "Epoch 29, Step: 129, Loss: 0.03673878312110901, Lr:0.0001\n",
      "Epoch 29, Step: 130, Loss: 0.035129670053720474, Lr:0.0001\n",
      "Epoch 29, Step: 131, Loss: 0.12735477089881897, Lr:0.0001\n",
      "Epoch 29, Step: 132, Loss: 0.11912886798381805, Lr:0.0001\n",
      "Epoch 29, Step: 133, Loss: 0.41121241450309753, Lr:0.0001\n",
      "Epoch 29, Step: 134, Loss: 0.09520060569047928, Lr:0.0001\n",
      "Epoch 29, Step: 135, Loss: 0.0886005237698555, Lr:0.0001\n",
      "Epoch 29, Step: 136, Loss: 0.11739236861467361, Lr:0.0001\n",
      "Epoch 29, Step: 137, Loss: 0.10692308098077774, Lr:0.0001\n",
      "Epoch 29, Step: 138, Loss: 0.005438061896711588, Lr:0.0001\n",
      "Epoch 29, Step: 139, Loss: 0.02810331992805004, Lr:0.0001\n",
      "Epoch 29, Step: 140, Loss: 0.02133255824446678, Lr:0.0001\n",
      "Epoch 29, Step: 141, Loss: 0.03373604267835617, Lr:0.0001\n",
      "Epoch 29, Step: 142, Loss: 0.020377516746520996, Lr:0.0001\n",
      "Epoch 29, Step: 143, Loss: 0.11639199405908585, Lr:0.0001\n",
      "Epoch 29, Step: 144, Loss: 0.03067326731979847, Lr:0.0001\n",
      "Epoch 29, Step: 145, Loss: 0.026824088767170906, Lr:0.0001\n",
      "Epoch 29, Step: 146, Loss: 0.05520061403512955, Lr:0.0001\n",
      "Epoch 29, Step: 147, Loss: 0.02549954131245613, Lr:0.0001\n",
      "Epoch 29, Step: 148, Loss: 0.021720970049500465, Lr:0.0001\n",
      "Epoch 29, Step: 149, Loss: 0.018044862896203995, Lr:0.0001\n",
      "Epoch 29, Step: 150, Loss: 0.014136982150375843, Lr:0.0001\n",
      "Epoch 29, Step: 151, Loss: 0.23969805240631104, Lr:0.0001\n",
      "Epoch 29, Step: 152, Loss: 0.0008324305526912212, Lr:0.0001\n",
      "Epoch 29, Step: 153, Loss: 0.12460024654865265, Lr:0.0001\n",
      "Epoch 29, Step: 154, Loss: 0.006180891301482916, Lr:0.0001\n",
      "Epoch 29, Step: 155, Loss: 0.09099696576595306, Lr:0.0001\n",
      "Epoch 29, Step: 156, Loss: 0.007171242497861385, Lr:0.0001\n",
      "Epoch 29, Step: 157, Loss: 0.01367224846035242, Lr:0.0001\n",
      "Epoch 29, Step: 158, Loss: 0.007160615175962448, Lr:0.0001\n",
      "Epoch 29, Step: 159, Loss: 0.14055921137332916, Lr:0.0001\n",
      "Epoch 29, Step: 160, Loss: 0.0349174402654171, Lr:0.0001\n",
      "Epoch 29, Step: 161, Loss: 0.0034995684400200844, Lr:0.0001\n",
      "Epoch 29, Step: 162, Loss: 0.21462474763393402, Lr:0.0001\n",
      "Epoch 29, Step: 163, Loss: 0.10061429440975189, Lr:0.0001\n",
      "Epoch 29, Step: 164, Loss: 0.000913683557882905, Lr:0.0001\n",
      "Epoch 29, Step: 165, Loss: 0.06715131551027298, Lr:0.0001\n",
      "Epoch 29, Step: 166, Loss: 0.15645647048950195, Lr:0.0001\n",
      "Epoch 29, Step: 167, Loss: 0.1434902399778366, Lr:0.0001\n",
      "Epoch 29, Step: 168, Loss: 0.02179032936692238, Lr:0.0001\n",
      "Epoch 29, Step: 169, Loss: 0.0015604167710989714, Lr:0.0001\n",
      "Epoch 29, Step: 170, Loss: 0.04460957646369934, Lr:0.0001\n",
      "Epoch 29, Step: 171, Loss: 0.013128530234098434, Lr:0.0001\n",
      "Epoch 29, Step: 172, Loss: 0.03753591701388359, Lr:0.0001\n",
      "Epoch 29, Step: 173, Loss: 0.006668253801763058, Lr:0.0001\n",
      "Epoch 29, Step: 174, Loss: 0.003631753148511052, Lr:0.0001\n",
      "Epoch 29, Step: 175, Loss: 0.008170678280293941, Lr:0.0001\n",
      "Epoch 29, Step: 176, Loss: 0.017916442826390266, Lr:0.0001\n",
      "Epoch 29, Step: 177, Loss: 0.03235457465052605, Lr:0.0001\n",
      "Epoch 29, Step: 178, Loss: 0.16076581180095673, Lr:0.0001\n",
      "Epoch 29, Step: 179, Loss: 0.00349123845808208, Lr:0.0001\n",
      "Epoch 29, Step: 180, Loss: 0.0953395664691925, Lr:0.0001\n",
      "Epoch 29, Step: 181, Loss: 0.23853139579296112, Lr:0.0001\n",
      "Epoch 29, Step: 182, Loss: 0.035383183509111404, Lr:0.0001\n",
      "Epoch 29, Step: 183, Loss: 0.17650721967220306, Lr:0.0001\n",
      "Epoch 29, Step: 184, Loss: 0.0219294261187315, Lr:0.0001\n",
      "Epoch 29, Step: 185, Loss: 0.01484445109963417, Lr:0.0001\n",
      "Epoch 29, Step: 186, Loss: 0.013896595686674118, Lr:0.0001\n",
      "Epoch 29, Step: 187, Loss: 0.025142140686511993, Lr:0.0001\n",
      "Epoch 29, Step: 188, Loss: 0.09316503256559372, Lr:0.0001\n",
      "Epoch 29, Step: 189, Loss: 0.014860275201499462, Lr:0.0001\n",
      "Epoch 29, Step: 190, Loss: 0.02089214324951172, Lr:0.0001\n",
      "Epoch 29, Step: 191, Loss: 0.012441307306289673, Lr:0.0001\n",
      "Epoch 29, Step: 192, Loss: 0.11253003031015396, Lr:0.0001\n",
      "Epoch 29, Step: 193, Loss: 0.019582461565732956, Lr:0.0001\n",
      "Epoch 29, Step: 194, Loss: 0.002147124847397208, Lr:0.0001\n",
      "Epoch 29, Step: 195, Loss: 0.00335977622307837, Lr:0.0001\n",
      "Epoch 29, Step: 196, Loss: 0.019805502146482468, Lr:0.0001\n",
      "Epoch 29, Step: 197, Loss: 0.12845788896083832, Lr:0.0001\n",
      "Epoch 29, Step: 198, Loss: 0.019300973042845726, Lr:0.0001\n",
      "Epoch 29, Step: 199, Loss: 0.017407363280653954, Lr:0.0001\n",
      "Epoch 29, Step: 200, Loss: 0.02734604850411415, Lr:0.0001\n",
      "Epoch 29, Step: 201, Loss: 0.0032982423435896635, Lr:0.0001\n",
      "Epoch 29, Step: 202, Loss: 0.03576261177659035, Lr:0.0001\n",
      "Epoch 29, Step: 203, Loss: 0.030335279181599617, Lr:0.0001\n",
      "Epoch 29, Step: 204, Loss: 0.028522152453660965, Lr:0.0001\n",
      "Epoch 29, Step: 205, Loss: 0.10116197913885117, Lr:0.0001\n",
      "Epoch 29, Step: 206, Loss: 0.04047258943319321, Lr:0.0001\n",
      "Epoch 29, Step: 207, Loss: 0.003644918091595173, Lr:0.0001\n",
      "Epoch 29, Step: 208, Loss: 0.021168509498238564, Lr:0.0001\n",
      "Epoch 29, Step: 209, Loss: 0.0004524549876805395, Lr:0.0001\n",
      "Epoch 29, Step: 210, Loss: 0.012998913414776325, Lr:0.0001\n",
      "Epoch 29, Step: 211, Loss: 0.06923564523458481, Lr:0.0001\n",
      "Epoch 29, Step: 212, Loss: 0.003962280694395304, Lr:0.0001\n",
      "Epoch 29, Step: 213, Loss: 0.01581648364663124, Lr:0.0001\n",
      "Epoch 29, Step: 214, Loss: 0.0053664459846913815, Lr:0.0001\n",
      "Epoch 29, Step: 215, Loss: 0.0894608125090599, Lr:0.0001\n",
      "Epoch 29, Step: 216, Loss: 0.009582172147929668, Lr:0.0001\n",
      "Epoch 29, Step: 217, Loss: 0.12174347788095474, Lr:0.0001\n",
      "Epoch 29, Step: 218, Loss: 0.06430651247501373, Lr:0.0001\n",
      "Epoch 29, Step: 219, Loss: 0.01882081851363182, Lr:0.0001\n",
      "Epoch 29, Step: 220, Loss: 0.025938890874385834, Lr:0.0001\n",
      "Epoch 29, Step: 221, Loss: 0.016829419881105423, Lr:0.0001\n",
      "Epoch 29, Step: 222, Loss: 0.004611899144947529, Lr:0.0001\n",
      "Epoch 29, Step: 223, Loss: 0.03454258292913437, Lr:0.0001\n",
      "Epoch 29, Step: 224, Loss: 0.14267762005329132, Lr:0.0001\n",
      "Epoch 29, Step: 225, Loss: 0.03815847635269165, Lr:0.0001\n",
      "Epoch 29, Step: 226, Loss: 0.0008829344878904521, Lr:0.0001\n",
      "Epoch 29, Step: 227, Loss: 0.08907091617584229, Lr:0.0001\n",
      "Epoch 29, Step: 228, Loss: 0.04232295602560043, Lr:0.0001\n",
      "Epoch 29, Step: 229, Loss: 0.001127893920056522, Lr:0.0001\n",
      "Epoch 29, Step: 230, Loss: 0.0072410497814416885, Lr:0.0001\n",
      "Epoch 29, Step: 231, Loss: 0.004023419227451086, Lr:0.0001\n",
      "Epoch 29, Step: 232, Loss: 0.008644252084195614, Lr:0.0001\n",
      "Epoch 29, Step: 233, Loss: 0.1665809601545334, Lr:0.0001\n",
      "Epoch 29, Step: 234, Loss: 0.057552583515644073, Lr:0.0001\n",
      "Epoch 29, Step: 235, Loss: 0.08541909605264664, Lr:0.0001\n",
      "Epoch 29, Step: 236, Loss: 0.003226525615900755, Lr:0.0001\n",
      "Epoch 29, Step: 237, Loss: 0.09138142317533493, Lr:0.0001\n",
      "Epoch 29, Step: 238, Loss: 0.10296254605054855, Lr:0.0001\n",
      "Epoch 29, Step: 239, Loss: 0.019219743087887764, Lr:0.0001\n",
      "Epoch 29, Step: 240, Loss: 0.009043784812092781, Lr:0.0001\n",
      "Epoch 29, Step: 241, Loss: 0.2461046725511551, Lr:0.0001\n",
      "Epoch 29, Step: 242, Loss: 0.003963046241551638, Lr:0.0001\n",
      "Epoch 29, Step: 243, Loss: 0.030089376494288445, Lr:0.0001\n",
      "Epoch 29, Step: 244, Loss: 0.05665396526455879, Lr:0.0001\n",
      "Epoch 29, Step: 245, Loss: 0.3130834698677063, Lr:0.0001\n",
      "Epoch 29, Step: 246, Loss: 0.00227579427883029, Lr:0.0001\n",
      "Epoch 29, Step: 247, Loss: 0.003694382729008794, Lr:0.0001\n",
      "Epoch 29, Step: 248, Loss: 0.02171199768781662, Lr:0.0001\n",
      "Epoch 29, Step: 249, Loss: 0.07929659634828568, Lr:0.0001\n",
      "Epoch 29, Step: 250, Loss: 0.043211452662944794, Lr:0.0001\n",
      "Epoch 29, Step: 251, Loss: 0.03612341731786728, Lr:0.0001\n",
      "Epoch 29, Step: 252, Loss: 0.07195308804512024, Lr:0.0001\n",
      "Epoch 29, Step: 253, Loss: 0.04318736866116524, Lr:0.0001\n",
      "Epoch 29, Step: 254, Loss: 0.06892653554677963, Lr:0.0001\n",
      "Epoch 29, Step: 255, Loss: 0.18419428169727325, Lr:0.0001\n",
      "Epoch 29, Step: 256, Loss: 0.005937470123171806, Lr:0.0001\n",
      "Epoch 29, Step: 257, Loss: 0.15016110241413116, Lr:0.0001\n",
      "Epoch 29, Step: 258, Loss: 0.2922409176826477, Lr:0.0001\n",
      "Epoch 29, Step: 259, Loss: 0.0008210442611016333, Lr:0.0001\n",
      "Epoch 29, Step: 260, Loss: 0.018480706959962845, Lr:0.0001\n",
      "Epoch 29, Step: 261, Loss: 0.2036590725183487, Lr:0.0001\n",
      "Epoch 29, Step: 262, Loss: 0.011765090748667717, Lr:0.0001\n",
      "Epoch 29, Step: 263, Loss: 0.10472322255373001, Lr:0.0001\n",
      "Epoch 29, Step: 264, Loss: 0.0877608060836792, Lr:0.0001\n",
      "Epoch 29, Step: 265, Loss: 0.10188519209623337, Lr:0.0001\n",
      "Epoch 29, Step: 266, Loss: 0.06752987951040268, Lr:0.0001\n",
      "Epoch 29, Step: 267, Loss: 0.02323014661669731, Lr:0.0001\n",
      "Epoch 29, Step: 268, Loss: 0.012828842736780643, Lr:0.0001\n",
      "Epoch 29, Step: 269, Loss: 0.179108127951622, Lr:0.0001\n",
      "Epoch 29, Step: 270, Loss: 0.013130436651408672, Lr:0.0001\n",
      "Epoch 29, Step: 271, Loss: 0.016480641439557076, Lr:0.0001\n",
      "Epoch 29, Step: 272, Loss: 0.012254903092980385, Lr:0.0001\n",
      "Epoch 29, Step: 273, Loss: 0.09125674515962601, Lr:0.0001\n",
      "Epoch 29, Step: 274, Loss: 0.001072772778570652, Lr:0.0001\n",
      "Epoch 29, Step: 275, Loss: 0.008410054259002209, Lr:0.0001\n",
      "Epoch 29, Step: 276, Loss: 0.06990402936935425, Lr:0.0001\n",
      "Epoch 29, Step: 277, Loss: 0.005277856718748808, Lr:0.0001\n",
      "Epoch 29, Step: 278, Loss: 0.290176659822464, Lr:0.0001\n",
      "Epoch 29, Step: 279, Loss: 0.09616418182849884, Lr:0.0001\n",
      "Epoch 29, Step: 280, Loss: 0.02085094153881073, Lr:0.0001\n",
      "Epoch 29, Step: 281, Loss: 0.011421697214245796, Lr:0.0001\n",
      "Epoch 29, Step: 282, Loss: 0.08646498620510101, Lr:0.0001\n",
      "Epoch 29, Step: 283, Loss: 0.0018824447179213166, Lr:0.0001\n",
      "Epoch 29, Step: 284, Loss: 0.023228170350193977, Lr:0.0001\n",
      "Epoch 29, Step: 285, Loss: 0.01289430446922779, Lr:0.0001\n",
      "Epoch 29, Step: 286, Loss: 0.013013249263167381, Lr:0.0001\n",
      "Epoch 29, Step: 287, Loss: 0.018347416073083878, Lr:0.0001\n",
      "Epoch 29, Step: 288, Loss: 0.002191883511841297, Lr:0.0001\n",
      "Epoch 29, Step: 289, Loss: 0.14647656679153442, Lr:0.0001\n",
      "Epoch 29, Step: 290, Loss: 0.007303208112716675, Lr:0.0001\n",
      "Epoch 29, Step: 291, Loss: 0.008491484448313713, Lr:0.0001\n",
      "Epoch 29, Step: 292, Loss: 0.018177710473537445, Lr:0.0001\n",
      "Epoch 29, Step: 293, Loss: 0.06144978106021881, Lr:0.0001\n",
      "Epoch 29, Step: 294, Loss: 0.12349899113178253, Lr:0.0001\n",
      "Epoch 29, Step: 295, Loss: 0.0016772360540926456, Lr:0.0001\n",
      "Epoch 29, Step: 296, Loss: 0.009231731295585632, Lr:0.0001\n",
      "Epoch 29, Step: 297, Loss: 0.0016593675827607512, Lr:0.0001\n",
      "Epoch 29, Step: 298, Loss: 0.12939107418060303, Lr:0.0001\n",
      "Epoch 29, Step: 299, Loss: 0.0038287865463644266, Lr:0.0001\n",
      "Epoch 29, Step: 300, Loss: 0.011596477590501308, Lr:0.0001\n",
      "Epoch 29, Step: 301, Loss: 0.003729073330760002, Lr:0.0001\n",
      "Epoch 29, Step: 302, Loss: 0.19907668232917786, Lr:0.0001\n",
      "Epoch 29, Step: 303, Loss: 0.00130370631814003, Lr:0.0001\n",
      "Epoch 29, Step: 304, Loss: 0.0050524333491921425, Lr:0.0001\n",
      "Epoch 29, Step: 305, Loss: 0.02508232183754444, Lr:0.0001\n",
      "Epoch 29, Step: 306, Loss: 0.021676132455468178, Lr:0.0001\n",
      "Epoch 29, Step: 307, Loss: 0.0027687891852110624, Lr:0.0001\n",
      "Epoch 29, Step: 308, Loss: 0.1090410053730011, Lr:0.0001\n",
      "Epoch 29, Step: 309, Loss: 0.06953857094049454, Lr:0.0001\n",
      "Epoch 29, Step: 310, Loss: 0.003189536975696683, Lr:0.0001\n",
      "Epoch 29, Step: 311, Loss: 0.03558190539479256, Lr:0.0001\n",
      "Epoch 29, Step: 312, Loss: 0.4474644064903259, Lr:0.0001\n",
      "Epoch 29, Step: 313, Loss: 0.02848145179450512, Lr:0.0001\n",
      "Epoch 29, Step: 314, Loss: 0.03176392242312431, Lr:0.0001\n",
      "Epoch 29, Step: 315, Loss: 0.0834149569272995, Lr:0.0001\n",
      "Epoch 29, Step: 316, Loss: 0.5382850766181946, Lr:0.0001\n",
      "Epoch 29, Step: 317, Loss: 0.002688963897526264, Lr:0.0001\n",
      "Epoch 29, Step: 318, Loss: 0.004181717988103628, Lr:0.0001\n",
      "Epoch 29, Step: 319, Loss: 0.014649976044893265, Lr:0.0001\n",
      "Epoch 29, Step: 320, Loss: 0.012795863673090935, Lr:0.0001\n",
      "Epoch 29, Step: 321, Loss: 0.00645213108509779, Lr:0.0001\n",
      "Epoch 29, Step: 322, Loss: 0.0258265882730484, Lr:0.0001\n",
      "Epoch 29, Step: 323, Loss: 0.0246745515614748, Lr:0.0001\n",
      "Epoch 29, Step: 324, Loss: 0.05764133855700493, Lr:0.0001\n",
      "Epoch 29, Step: 325, Loss: 0.004083412233740091, Lr:0.0001\n",
      "Epoch 29, Step: 326, Loss: 0.009573572315275669, Lr:0.0001\n",
      "Epoch 29, Step: 327, Loss: 0.07838056981563568, Lr:0.0001\n",
      "Epoch 29, Step: 328, Loss: 0.00697498070076108, Lr:0.0001\n",
      "Epoch 29, Step: 329, Loss: 0.06543402373790741, Lr:0.0001\n",
      "Epoch 29, Step: 330, Loss: 0.004504124168306589, Lr:0.0001\n",
      "Epoch 29, Step: 331, Loss: 0.01986280269920826, Lr:0.0001\n",
      "Epoch 29, Step: 332, Loss: 0.01622013747692108, Lr:0.0001\n",
      "Epoch 29, Step: 333, Loss: 0.01907842792570591, Lr:0.0001\n",
      "Epoch 29, Step: 334, Loss: 0.06730059534311295, Lr:0.0001\n",
      "Epoch 29, Step: 335, Loss: 0.01691303588449955, Lr:0.0001\n",
      "Epoch 29, Step: 336, Loss: 0.012908495031297207, Lr:0.0001\n",
      "Epoch 29, Step: 337, Loss: 0.09714072942733765, Lr:0.0001\n",
      "Epoch 29, Step: 338, Loss: 0.05382448434829712, Lr:0.0001\n",
      "Epoch 29, Step: 339, Loss: 0.00930364802479744, Lr:0.0001\n",
      "Epoch 29, Step: 340, Loss: 0.04537879303097725, Lr:0.0001\n",
      "Epoch 29, Step: 341, Loss: 0.034659646451473236, Lr:0.0001\n",
      "Epoch 29, Step: 342, Loss: 0.003880856093019247, Lr:0.0001\n",
      "Epoch 29, Step: 343, Loss: 0.008646298199892044, Lr:0.0001\n",
      "Epoch 29, Step: 344, Loss: 0.0030744243413209915, Lr:0.0001\n",
      "Epoch 29, Step: 345, Loss: 0.004050096962600946, Lr:0.0001\n",
      "Epoch 29, Step: 346, Loss: 0.1500730812549591, Lr:0.0001\n",
      "Epoch 29, Step: 347, Loss: 0.06329070031642914, Lr:0.0001\n",
      "Epoch 29, Step: 348, Loss: 0.11955267190933228, Lr:0.0001\n",
      "Epoch 29, Step: 349, Loss: 0.0967223048210144, Lr:0.0001\n",
      "Epoch 29, Step: 350, Loss: 0.003634142689406872, Lr:0.0001\n",
      "Epoch 29, Step: 351, Loss: 0.0544104166328907, Lr:0.0001\n",
      "Epoch 29, Step: 352, Loss: 0.2026546597480774, Lr:0.0001\n",
      "Epoch 29, Step: 353, Loss: 0.011161922477185726, Lr:0.0001\n",
      "Epoch 29, Step: 354, Loss: 0.06959068775177002, Lr:0.0001\n",
      "Epoch 29, Step: 355, Loss: 0.02311065047979355, Lr:0.0001\n",
      "Epoch 29, Step: 356, Loss: 0.013105712831020355, Lr:0.0001\n",
      "Epoch 29, Step: 357, Loss: 0.008255204185843468, Lr:0.0001\n",
      "Epoch 29, Step: 358, Loss: 0.01814417541027069, Lr:0.0001\n",
      "Epoch 29, Step: 359, Loss: 0.12363988906145096, Lr:0.0001\n",
      "Epoch 29, Step: 360, Loss: 0.08676814287900925, Lr:0.0001\n",
      "Epoch 29, Step: 361, Loss: 0.3112407326698303, Lr:0.0001\n",
      "Epoch 29, Step: 362, Loss: 0.12690295279026031, Lr:0.0001\n",
      "Epoch 29, Step: 363, Loss: 0.0036506783217191696, Lr:0.0001\n",
      "Epoch 29, Step: 364, Loss: 0.017772510647773743, Lr:0.0001\n",
      "Epoch 29, Step: 365, Loss: 0.013064456172287464, Lr:0.0001\n",
      "Epoch 29, Step: 366, Loss: 0.1309843510389328, Lr:0.0001\n",
      "Epoch 29, Step: 367, Loss: 0.028879817575216293, Lr:0.0001\n",
      "Epoch 29, Step: 368, Loss: 0.06412944197654724, Lr:0.0001\n",
      "Epoch 29, Step: 369, Loss: 0.027027254924178123, Lr:0.0001\n",
      "Epoch 29, Step: 370, Loss: 0.2730105519294739, Lr:0.0001\n",
      "Epoch 29, Step: 371, Loss: 0.08744513243436813, Lr:0.0001\n",
      "Epoch 29, Step: 372, Loss: 0.020749859511852264, Lr:0.0001\n",
      "Epoch 29, Step: 373, Loss: 0.21302108466625214, Lr:0.0001\n",
      "Epoch 29, Step: 374, Loss: 0.0633254274725914, Lr:0.0001\n",
      "Epoch 29, Step: 375, Loss: 0.005218793172389269, Lr:0.0001\n",
      "Epoch 29, Step: 376, Loss: 0.10750330984592438, Lr:0.0001\n",
      "Epoch 29, Step: 377, Loss: 0.028127452358603477, Lr:0.0001\n",
      "Epoch 29, Step: 378, Loss: 0.11716797202825546, Lr:0.0001\n",
      "Epoch 29, Step: 379, Loss: 0.08585058897733688, Lr:0.0001\n",
      "Epoch 29, Step: 380, Loss: 0.09289665520191193, Lr:0.0001\n",
      "Epoch 29, Step: 381, Loss: 0.010925286449491978, Lr:0.0001\n",
      "Epoch 29, Step: 382, Loss: 0.10238684713840485, Lr:0.0001\n",
      "Epoch 29, Step: 383, Loss: 0.08929222822189331, Lr:0.0001\n",
      "Epoch 29, Step: 384, Loss: 0.09487536549568176, Lr:0.0001\n",
      "Epoch 29, Step: 385, Loss: 0.2158268243074417, Lr:0.0001\n",
      "Epoch 29, Step: 386, Loss: 0.49127647280693054, Lr:0.0001\n",
      "Epoch 29, Step: 387, Loss: 0.03027527406811714, Lr:0.0001\n",
      "Epoch 29, Step: 388, Loss: 0.009187852032482624, Lr:0.0001\n",
      "Epoch 29, Step: 389, Loss: 0.06836160272359848, Lr:0.0001\n",
      "Epoch 29, Step: 390, Loss: 0.022246763110160828, Lr:0.0001\n",
      "Epoch 29, Step: 391, Loss: 0.012356763705611229, Lr:0.0001\n",
      "Epoch 29, Step: 392, Loss: 0.20870263874530792, Lr:0.0001\n",
      "Epoch 29, Step: 393, Loss: 0.19340574741363525, Lr:0.0001\n",
      "Epoch 29, Step: 394, Loss: 0.02770921215415001, Lr:0.0001\n",
      "Epoch 29, Step: 395, Loss: 0.2373412698507309, Lr:0.0001\n",
      "Epoch 29, Step: 396, Loss: 0.027964545413851738, Lr:0.0001\n",
      "Epoch 29, Step: 397, Loss: 0.01990286447107792, Lr:0.0001\n",
      "Epoch 29, Step: 398, Loss: 0.005408060736954212, Lr:0.0001\n",
      "Epoch 29, Step: 399, Loss: 0.07279889285564423, Lr:0.0001\n",
      "Epoch 29, Step: 400, Loss: 0.030376087874174118, Lr:0.0001\n",
      "Epoch 29, Step: 401, Loss: 0.07872006297111511, Lr:0.0001\n",
      "Epoch 29, Step: 402, Loss: 0.006856793072074652, Lr:0.0001\n",
      "Epoch 29, Step: 403, Loss: 0.013488245196640491, Lr:0.0001\n",
      "Epoch 29, Step: 404, Loss: 0.04695245251059532, Lr:0.0001\n",
      "Epoch 29, Step: 405, Loss: 0.006083623971790075, Lr:0.0001\n",
      "Epoch 29, Step: 406, Loss: 0.09334603697061539, Lr:0.0001\n",
      "Epoch 29, Step: 407, Loss: 0.08267441391944885, Lr:0.0001\n",
      "Epoch 29, Step: 408, Loss: 0.1519111543893814, Lr:0.0001\n",
      "Epoch 29, Step: 409, Loss: 0.16784177720546722, Lr:0.0001\n",
      "Epoch 29, Step: 410, Loss: 0.0077148801647126675, Lr:0.0001\n",
      "Epoch 29, Step: 411, Loss: 0.13560597598552704, Lr:0.0001\n",
      "Epoch 29, Step: 412, Loss: 0.06813494116067886, Lr:0.0001\n",
      "Epoch 29, Step: 413, Loss: 0.015152543783187866, Lr:0.0001\n",
      "Epoch 29, Step: 414, Loss: 0.010042795911431313, Lr:0.0001\n",
      "Epoch 29, Step: 415, Loss: 0.014728662557899952, Lr:0.0001\n",
      "Epoch 29, Step: 416, Loss: 0.0786091759800911, Lr:0.0001\n",
      "Epoch 29, Step: 417, Loss: 0.018240680918097496, Lr:0.0001\n",
      "Epoch 29, Step: 418, Loss: 0.018955951556563377, Lr:0.0001\n",
      "Epoch 29, Step: 419, Loss: 0.002457314869388938, Lr:0.0001\n",
      "Epoch 29, Step: 420, Loss: 0.004105343483388424, Lr:0.0001\n",
      "Epoch 29, Step: 421, Loss: 0.05207913741469383, Lr:0.0001\n",
      "Epoch 29, Step: 422, Loss: 0.029051922261714935, Lr:0.0001\n",
      "Epoch 29, Step: 423, Loss: 0.20183038711547852, Lr:0.0001\n",
      "Epoch 29, Step: 424, Loss: 0.340819776058197, Lr:0.0001\n",
      "Epoch 29, Step: 425, Loss: 0.24135325849056244, Lr:0.0001\n",
      "Epoch 29, Step: 426, Loss: 0.031732216477394104, Lr:0.0001\n",
      "Epoch 29, Step: 427, Loss: 0.018817011266946793, Lr:0.0001\n",
      "Epoch 29, Step: 428, Loss: 0.11878044158220291, Lr:0.0001\n",
      "Epoch 29, Step: 429, Loss: 0.0813189223408699, Lr:0.0001\n",
      "Epoch 29, Step: 430, Loss: 0.013686680234968662, Lr:0.0001\n",
      "Epoch 29, Step: 431, Loss: 0.009197908453643322, Lr:0.0001\n",
      "Epoch 29, Step: 432, Loss: 0.034508850425481796, Lr:0.0001\n",
      "Epoch 29, Step: 433, Loss: 0.01818319968879223, Lr:0.0001\n",
      "Epoch 29, Step: 434, Loss: 0.08695139735937119, Lr:0.0001\n",
      "Epoch 29, Step: 435, Loss: 0.1061759889125824, Lr:0.0001\n",
      "Epoch 29, Step: 436, Loss: 0.002307572402060032, Lr:0.0001\n",
      "Epoch 29, Step: 437, Loss: 0.013872427865862846, Lr:0.0001\n",
      "Epoch 29, Step: 438, Loss: 0.20197232067584991, Lr:0.0001\n",
      "Epoch 29, Step: 439, Loss: 0.036783359944820404, Lr:0.0001\n",
      "Epoch 29, Step: 440, Loss: 0.15046803653240204, Lr:0.0001\n",
      "Epoch 29, Step: 441, Loss: 0.01625748910009861, Lr:0.0001\n",
      "Epoch 29, Step: 442, Loss: 0.034097764641046524, Lr:0.0001\n",
      "Epoch 29, Step: 443, Loss: 0.09250396490097046, Lr:0.0001\n",
      "Epoch 29, Step: 444, Loss: 0.057065363973379135, Lr:0.0001\n",
      "Epoch 29, Step: 445, Loss: 0.006402311380952597, Lr:0.0001\n",
      "Epoch 29, Step: 446, Loss: 0.08627717196941376, Lr:0.0001\n",
      "Epoch 29, Step: 447, Loss: 0.18124566972255707, Lr:0.0001\n",
      "Epoch 29, Step: 448, Loss: 0.07525185495615005, Lr:0.0001\n",
      "Epoch 29, Step: 449, Loss: 0.1535273939371109, Lr:0.0001\n",
      "Epoch 29, Step: 450, Loss: 0.0301543939858675, Lr:0.0001\n",
      "Epoch 29, Step: 451, Loss: 0.2091047763824463, Lr:0.0001\n",
      "Epoch 29, Step: 452, Loss: 0.0015434839297086, Lr:0.0001\n",
      "Epoch 29, Step: 453, Loss: 0.09123855084180832, Lr:0.0001\n",
      "Epoch 29, Step: 454, Loss: 0.0044052256271243095, Lr:0.0001\n",
      "Epoch 29, Step: 455, Loss: 0.0023112930357456207, Lr:0.0001\n",
      "Epoch 29, Step: 456, Loss: 0.0419403500854969, Lr:0.0001\n",
      "Epoch 29, Step: 457, Loss: 0.0005129673518240452, Lr:0.0001\n",
      "Epoch 29, Step: 458, Loss: 0.0018934953259304166, Lr:0.0001\n",
      "Epoch 29, Step: 459, Loss: 0.010616596788167953, Lr:0.0001\n",
      "Epoch 29, Step: 460, Loss: 0.011577372439205647, Lr:0.0001\n",
      "Epoch 29, Step: 461, Loss: 0.025205859914422035, Lr:0.0001\n",
      "Epoch 29, Step: 462, Loss: 0.008241756819188595, Lr:0.0001\n",
      "Epoch 29, Step: 463, Loss: 0.20831143856048584, Lr:0.0001\n",
      "Epoch 29, Step: 464, Loss: 0.0015894713578745723, Lr:0.0001\n",
      "Epoch 29, Step: 465, Loss: 0.1273326873779297, Lr:0.0001\n",
      "Epoch 29, Step: 466, Loss: 0.0020354485604912043, Lr:0.0001\n",
      "Epoch 29, Step: 467, Loss: 0.4146229922771454, Lr:0.0001\n",
      "Epoch 29, Step: 468, Loss: 0.024998601526021957, Lr:0.0001\n",
      "Epoch 29, Step: 469, Loss: 0.005569377914071083, Lr:0.0001\n",
      "Epoch 29, Step: 470, Loss: 0.04886002466082573, Lr:0.0001\n",
      "Epoch 29, Step: 471, Loss: 0.07765911519527435, Lr:0.0001\n",
      "Epoch 29, Step: 472, Loss: 0.1134573295712471, Lr:0.0001\n",
      "Epoch 29, Step: 473, Loss: 0.18986749649047852, Lr:0.0001\n",
      "Epoch 29, Step: 474, Loss: 0.23827122151851654, Lr:0.0001\n",
      "Epoch 29, Step: 475, Loss: 0.010663903318345547, Lr:0.0001\n",
      "Epoch 29, Step: 476, Loss: 0.04381764680147171, Lr:0.0001\n",
      "Epoch 29, Step: 477, Loss: 0.021997224539518356, Lr:0.0001\n",
      "Epoch 29, Step: 478, Loss: 0.023768529295921326, Lr:0.0001\n",
      "Epoch 29, Step: 479, Loss: 0.025305142626166344, Lr:0.0001\n",
      "Epoch 29, Step: 480, Loss: 0.12064233422279358, Lr:0.0001\n",
      "Epoch 29, Step: 481, Loss: 0.12254095822572708, Lr:0.0001\n",
      "Epoch 29, Step: 482, Loss: 0.0003760744584724307, Lr:0.0001\n",
      "Epoch 29, Step: 483, Loss: 0.015991786494851112, Lr:0.0001\n",
      "Epoch 29, Step: 484, Loss: 0.06687819212675095, Lr:0.0001\n",
      "Epoch 29, Step: 485, Loss: 0.03395144268870354, Lr:0.0001\n",
      "Epoch 29, Step: 486, Loss: 0.05772574245929718, Lr:0.0001\n",
      "Epoch 29, Step: 487, Loss: 0.06879682838916779, Lr:0.0001\n",
      "Epoch 29, Step: 488, Loss: 0.014956782571971416, Lr:0.0001\n",
      "Epoch 29, Step: 489, Loss: 0.06963586807250977, Lr:0.0001\n",
      "Epoch 29, Step: 490, Loss: 0.014453578740358353, Lr:0.0001\n",
      "Epoch 29, Step: 491, Loss: 0.025875503197312355, Lr:0.0001\n",
      "Epoch 29, Step: 492, Loss: 0.042671363800764084, Lr:0.0001\n",
      "Epoch 29, Step: 493, Loss: 0.10311354696750641, Lr:0.0001\n",
      "Epoch 29, Step: 494, Loss: 0.09182007610797882, Lr:0.0001\n",
      "Epoch 29, Step: 495, Loss: 0.09156203269958496, Lr:0.0001\n",
      "Epoch 29, Step: 496, Loss: 0.005546598695218563, Lr:0.0001\n",
      "Epoch 29, Step: 497, Loss: 0.06770671904087067, Lr:0.0001\n",
      "Epoch 29, Step: 498, Loss: 0.010744496248662472, Lr:0.0001\n",
      "Epoch 29, Step: 499, Loss: 0.00017950727487914264, Lr:0.0001\n",
      "Epoch 29, Step: 500, Loss: 0.05387500673532486, Lr:0.0001\n",
      "Epoch 29, Step: 501, Loss: 0.040442392230033875, Lr:0.0001\n",
      "Epoch 29, Step: 502, Loss: 0.03217896819114685, Lr:0.0001\n",
      "Epoch 29, Step: 503, Loss: 0.00953640602529049, Lr:0.0001\n",
      "Epoch 29, Step: 504, Loss: 0.003014384536072612, Lr:0.0001\n",
      "Epoch 29, Step: 505, Loss: 0.052557412534952164, Lr:0.0001\n",
      "Epoch 29, Step: 506, Loss: 0.0543086864054203, Lr:0.0001\n",
      "Epoch 29, Step: 507, Loss: 0.05965627729892731, Lr:0.0001\n",
      "Epoch 29, Step: 508, Loss: 0.03187241777777672, Lr:0.0001\n",
      "Epoch 29, Step: 509, Loss: 0.11439479142427444, Lr:0.0001\n",
      "Epoch 29, Step: 510, Loss: 0.0033514888491481543, Lr:0.0001\n",
      "Epoch 29, Step: 511, Loss: 0.03568343073129654, Lr:0.0001\n",
      "Epoch 29, Step: 512, Loss: 0.0035965610295534134, Lr:0.0001\n",
      "Epoch 29, Step: 513, Loss: 0.013799457810819149, Lr:0.0001\n",
      "Epoch 29, Step: 514, Loss: 0.020255008712410927, Lr:0.0001\n",
      "Epoch 29, Step: 515, Loss: 0.0017063884297385812, Lr:0.0001\n",
      "Epoch 29, Step: 516, Loss: 0.008163055405020714, Lr:0.0001\n",
      "Epoch 29, Step: 517, Loss: 0.2882503867149353, Lr:0.0001\n",
      "Epoch 29, Step: 518, Loss: 0.061559729278087616, Lr:0.0001\n",
      "Epoch 29, Step: 519, Loss: 0.07448020577430725, Lr:0.0001\n",
      "Epoch 29, Step: 520, Loss: 0.12218637764453888, Lr:0.0001\n",
      "Epoch 29, Step: 521, Loss: 0.008503002114593983, Lr:0.0001\n",
      "Epoch 29, Step: 522, Loss: 0.07708265632390976, Lr:0.0001\n",
      "Epoch 29, Step: 523, Loss: 0.006227673497051001, Lr:0.0001\n",
      "Epoch 29, Step: 524, Loss: 0.03176584839820862, Lr:0.0001\n",
      "Epoch 29, Step: 525, Loss: 0.00664266524836421, Lr:0.0001\n",
      "Epoch 29, Step: 526, Loss: 0.0005881433025933802, Lr:0.0001\n",
      "Epoch 29, Step: 527, Loss: 0.005690880585461855, Lr:0.0001\n",
      "Epoch 29, Step: 528, Loss: 0.03282758593559265, Lr:0.0001\n",
      "Epoch 29, Step: 529, Loss: 0.05870804563164711, Lr:0.0001\n",
      "Epoch 29, Step: 530, Loss: 0.003979386296123266, Lr:0.0001\n",
      "Epoch 29, Step: 531, Loss: 0.03211626783013344, Lr:0.0001\n",
      "Epoch 29, Step: 532, Loss: 0.09997766464948654, Lr:0.0001\n",
      "Epoch 29, Step: 533, Loss: 0.004223884083330631, Lr:0.0001\n",
      "Epoch 29, Step: 534, Loss: 0.024645142257213593, Lr:0.0001\n",
      "Epoch 29, Step: 535, Loss: 0.00897129438817501, Lr:0.0001\n",
      "Epoch 29, Step: 536, Loss: 0.004522266332060099, Lr:0.0001\n",
      "Epoch 29, Step: 537, Loss: 0.13419441878795624, Lr:0.0001\n",
      "Epoch 29, Step: 538, Loss: 0.006202140357345343, Lr:0.0001\n",
      "Epoch 29, Step: 539, Loss: 0.06351112574338913, Lr:0.0001\n",
      "Epoch 29, Step: 540, Loss: 0.009176037274301052, Lr:0.0001\n",
      "Epoch 29, Step: 541, Loss: 0.02774006500840187, Lr:0.0001\n",
      "Epoch 29, Step: 542, Loss: 0.06233038008213043, Lr:0.0001\n",
      "Epoch 29, Step: 543, Loss: 0.020941991358995438, Lr:0.0001\n",
      "Epoch 29, Step: 544, Loss: 0.00731997936964035, Lr:0.0001\n",
      "Epoch 29, Step: 545, Loss: 0.03241531923413277, Lr:0.0001\n",
      "Epoch 29, Step: 546, Loss: 0.08540092408657074, Lr:0.0001\n",
      "Epoch 29, Step: 547, Loss: 0.03082033060491085, Lr:0.0001\n",
      "Epoch 29, Step: 548, Loss: 0.07471229881048203, Lr:0.0001\n",
      "Epoch 29, Step: 549, Loss: 0.07202962040901184, Lr:0.0001\n",
      "Epoch 29, Step: 550, Loss: 0.02395716868340969, Lr:0.0001\n",
      "Epoch 29, Step: 551, Loss: 0.12525281310081482, Lr:0.0001\n",
      "Epoch 29, Step: 552, Loss: 0.0014551772037521005, Lr:0.0001\n",
      "Epoch 29, Step: 553, Loss: 0.03602743148803711, Lr:0.0001\n",
      "Epoch 29, Step: 554, Loss: 0.14096422493457794, Lr:0.0001\n",
      "Epoch 29, Step: 555, Loss: 0.0011768131516873837, Lr:0.0001\n",
      "Epoch 29, Step: 556, Loss: 0.003067177487537265, Lr:0.0001\n",
      "Epoch 29, Step: 557, Loss: 0.005892443470656872, Lr:0.0001\n",
      "Epoch 29, Step: 558, Loss: 0.0029993082862347364, Lr:0.0001\n",
      "Epoch 29, Step: 559, Loss: 0.0022405353374779224, Lr:0.0001\n",
      "Epoch 29, Step: 560, Loss: 0.0052064210176467896, Lr:0.0001\n",
      "Epoch 29, Step: 561, Loss: 0.11082317680120468, Lr:0.0001\n",
      "Epoch 29, Step: 562, Loss: 0.1519131064414978, Lr:0.0001\n",
      "Epoch 29, Step: 563, Loss: 0.006758417002856731, Lr:0.0001\n",
      "Epoch 29, Step: 564, Loss: 0.10543415695428848, Lr:0.0001\n",
      "Epoch 29, Step: 565, Loss: 0.050976455211639404, Lr:0.0001\n",
      "Epoch 29, Step: 566, Loss: 0.08735454827547073, Lr:0.0001\n",
      "Epoch 29, Step: 567, Loss: 0.04148458316922188, Lr:0.0001\n",
      "Epoch 29, Step: 568, Loss: 0.07102121412754059, Lr:0.0001\n",
      "Epoch 29, Step: 569, Loss: 0.24295318126678467, Lr:0.0001\n",
      "Epoch 29, Step: 570, Loss: 0.059742264449596405, Lr:0.0001\n",
      "Epoch 29, Step: 571, Loss: 0.09607721865177155, Lr:0.0001\n",
      "Epoch 29, Step: 572, Loss: 0.008064416237175465, Lr:0.0001\n",
      "Epoch 29, Step: 573, Loss: 0.12134896963834763, Lr:0.0001\n",
      "Epoch 29, Step: 574, Loss: 0.036591604351997375, Lr:0.0001\n",
      "Epoch 29, Step: 575, Loss: 0.06341740489006042, Lr:0.0001\n",
      "Epoch 29, Step: 576, Loss: 0.003430185606703162, Lr:0.0001\n",
      "Epoch 29, Step: 577, Loss: 0.06214255839586258, Lr:0.0001\n",
      "Epoch 29, Step: 578, Loss: 0.2235509157180786, Lr:0.0001\n",
      "Epoch 29, Step: 579, Loss: 0.1320355385541916, Lr:0.0001\n",
      "Epoch 29, Step: 580, Loss: 0.006835418287664652, Lr:0.0001\n",
      "Epoch 29, Step: 581, Loss: 0.011306807398796082, Lr:0.0001\n",
      "Epoch 29, Step: 582, Loss: 0.003388752928003669, Lr:0.0001\n",
      "Epoch 29, Step: 583, Loss: 0.10552075505256653, Lr:0.0001\n",
      "Epoch 29, Step: 584, Loss: 0.29325324296951294, Lr:0.0001\n",
      "Epoch 29, Step: 585, Loss: 0.18339820206165314, Lr:0.0001\n",
      "Epoch 29, Step: 586, Loss: 0.2747724652290344, Lr:0.0001\n",
      "Epoch 29, Step: 587, Loss: 0.014192766509950161, Lr:0.0001\n",
      "Epoch 29, Step: 588, Loss: 0.0019647630397230387, Lr:0.0001\n",
      "Epoch 29, Step: 589, Loss: 0.004943440202623606, Lr:0.0001\n",
      "Epoch 29, Step: 590, Loss: 0.04857247695326805, Lr:0.0001\n",
      "Epoch 29, Step: 591, Loss: 0.008225438185036182, Lr:0.0001\n",
      "Epoch 29, Step: 592, Loss: 0.025785677134990692, Lr:0.0001\n",
      "Epoch 29, Step: 593, Loss: 0.002914705080911517, Lr:0.0001\n",
      "Epoch 29, Step: 594, Loss: 0.01740310527384281, Lr:0.0001\n",
      "Epoch 29, Step: 595, Loss: 0.025761840865015984, Lr:0.0001\n",
      "Epoch 29, Step: 596, Loss: 0.15427225828170776, Lr:0.0001\n",
      "Epoch 29, Step: 597, Loss: 0.02601091004908085, Lr:0.0001\n",
      "Epoch 29, Step: 598, Loss: 0.026653841137886047, Lr:0.0001\n",
      "Epoch 29, Step: 599, Loss: 0.07558426260948181, Lr:0.0001\n",
      "Epoch 29, Step: 600, Loss: 0.0801227018237114, Lr:0.0001\n",
      "Epoch 29, Step: 601, Loss: 0.0002453571942169219, Lr:0.0001\n",
      "Epoch 29, Step: 602, Loss: 0.004318455699831247, Lr:0.0001\n",
      "Epoch 29, Step: 603, Loss: 0.0068047745153307915, Lr:0.0001\n",
      "Epoch 29, Step: 604, Loss: 0.022202838212251663, Lr:0.0001\n",
      "Epoch 29, Step: 605, Loss: 0.05622429400682449, Lr:0.0001\n",
      "Epoch 29, Step: 606, Loss: 0.000581858737859875, Lr:0.0001\n",
      "Epoch 29, Step: 607, Loss: 0.06776031106710434, Lr:0.0001\n",
      "Epoch 29, Step: 608, Loss: 0.0019779973663389683, Lr:0.0001\n",
      "Epoch 29, Step: 609, Loss: 0.21979829668998718, Lr:0.0001\n",
      "Epoch 29, Step: 610, Loss: 0.020143773406744003, Lr:0.0001\n",
      "Epoch 29, Step: 611, Loss: 0.029146788641810417, Lr:0.0001\n",
      "Epoch 29, Step: 612, Loss: 0.039843570441007614, Lr:0.0001\n",
      "Epoch 29, Step: 613, Loss: 0.07799316197633743, Lr:0.0001\n",
      "Epoch 29, Step: 614, Loss: 0.0031669060699641705, Lr:0.0001\n",
      "Epoch 29, Step: 615, Loss: 0.014319480396807194, Lr:0.0001\n",
      "Epoch 29, Step: 616, Loss: 0.01495499350130558, Lr:0.0001\n",
      "Epoch 29, Step: 617, Loss: 0.2015475183725357, Lr:0.0001\n",
      "Epoch 29, Step: 618, Loss: 0.07167580723762512, Lr:0.0001\n",
      "Epoch 29, Step: 619, Loss: 0.019484395161271095, Lr:0.0001\n",
      "Epoch 29, Step: 620, Loss: 0.17280369997024536, Lr:0.0001\n",
      "Epoch 29, Step: 621, Loss: 0.013737265951931477, Lr:0.0001\n",
      "Epoch 29, Step: 622, Loss: 0.06917356699705124, Lr:0.0001\n",
      "Epoch 29, Step: 623, Loss: 0.0907512977719307, Lr:0.0001\n",
      "Epoch 29, Step: 624, Loss: 0.02776006981730461, Lr:0.0001\n",
      "Epoch 29, Step: 625, Loss: 0.02565956301987171, Lr:0.0001\n",
      "Epoch 29, Step: 626, Loss: 0.018039876595139503, Lr:0.0001\n",
      "Epoch 29, Step: 627, Loss: 0.01842586323618889, Lr:0.0001\n",
      "Epoch 29, Step: 628, Loss: 0.015386794693768024, Lr:0.0001\n",
      "Epoch 29, Step: 629, Loss: 0.01586047001183033, Lr:0.0001\n",
      "Epoch 29, Step: 630, Loss: 0.0010553626343607903, Lr:0.0001\n",
      "Epoch 29, Step: 631, Loss: 0.11096899211406708, Lr:0.0001\n",
      "Epoch 29, Step: 632, Loss: 0.003229175927117467, Lr:0.0001\n",
      "Epoch 29, Step: 633, Loss: 0.040505439043045044, Lr:0.0001\n",
      "Epoch 29, Step: 634, Loss: 0.02574734576046467, Lr:0.0001\n",
      "Epoch 29, Step: 635, Loss: 0.0031472938135266304, Lr:0.0001\n",
      "Epoch 29, Step: 636, Loss: 0.06933683156967163, Lr:0.0001\n",
      "Epoch 29, Step: 637, Loss: 0.07613582909107208, Lr:0.0001\n",
      "Epoch 29, Step: 638, Loss: 0.0010252379579469562, Lr:0.0001\n",
      "Epoch 29, Step: 639, Loss: 0.24263472855091095, Lr:0.0001\n",
      "Epoch 29, Step: 640, Loss: 0.28430476784706116, Lr:0.0001\n",
      "Epoch 29, Step: 641, Loss: 0.0345810241997242, Lr:0.0001\n",
      "Epoch 29, Step: 642, Loss: 0.013457916676998138, Lr:0.0001\n",
      "Epoch 29, Step: 643, Loss: 0.0014566532336175442, Lr:0.0001\n",
      "Epoch 29, Step: 644, Loss: 0.029932290315628052, Lr:0.0001\n",
      "Epoch 29, Step: 645, Loss: 0.11588078737258911, Lr:0.0001\n",
      "Epoch 29, Step: 646, Loss: 0.025330716744065285, Lr:0.0001\n",
      "Epoch 29, Step: 647, Loss: 0.017432525753974915, Lr:0.0001\n",
      "Epoch 29, Step: 648, Loss: 0.057438574731349945, Lr:0.0001\n",
      "Epoch 29, Step: 649, Loss: 0.006044117733836174, Lr:0.0001\n",
      "Epoch 29, Step: 650, Loss: 0.1137860119342804, Lr:0.0001\n",
      "Epoch 29, Step: 651, Loss: 0.1029430478811264, Lr:0.0001\n",
      "Epoch 29, Step: 652, Loss: 0.019744135439395905, Lr:0.0001\n",
      "Epoch 29, Step: 653, Loss: 0.06586779654026031, Lr:0.0001\n",
      "Epoch 29, Step: 654, Loss: 0.1521541327238083, Lr:0.0001\n",
      "Epoch 29, Step: 655, Loss: 0.004833353217691183, Lr:0.0001\n",
      "Epoch 29, Step: 656, Loss: 0.057129867374897, Lr:0.0001\n",
      "Epoch 29, Step: 657, Loss: 0.0008139120764099061, Lr:0.0001\n",
      "Epoch 29, Step: 658, Loss: 0.1337287575006485, Lr:0.0001\n",
      "Epoch 29, Step: 659, Loss: 0.17140723764896393, Lr:0.0001\n",
      "Epoch 29, Step: 660, Loss: 0.003951920662075281, Lr:0.0001\n",
      "Epoch 29, Step: 661, Loss: 0.02355205826461315, Lr:0.0001\n",
      "Epoch 29, Step: 662, Loss: 0.1557025909423828, Lr:0.0001\n",
      "Epoch 29, Step: 663, Loss: 0.012716767378151417, Lr:0.0001\n",
      "Epoch 29, Step: 664, Loss: 0.030517779290676117, Lr:0.0001\n",
      "Epoch 29, Step: 665, Loss: 0.18255257606506348, Lr:0.0001\n",
      "Epoch 29, Step: 666, Loss: 0.07325108349323273, Lr:0.0001\n",
      "Epoch 29, Step: 667, Loss: 0.013222014531493187, Lr:0.0001\n",
      "Epoch 29, Step: 668, Loss: 0.1287953108549118, Lr:0.0001\n",
      "Epoch 29, Step: 669, Loss: 0.00371801876462996, Lr:0.0001\n",
      "Epoch 29, Step: 670, Loss: 0.01665910892188549, Lr:0.0001\n",
      "Epoch 29, Step: 671, Loss: 0.019611816853284836, Lr:0.0001\n",
      "Epoch 29, Step: 672, Loss: 0.05104286968708038, Lr:0.0001\n",
      "Epoch 29, Step: 673, Loss: 0.15390653908252716, Lr:0.0001\n",
      "Epoch 29, Step: 674, Loss: 0.002913878997787833, Lr:0.0001\n",
      "Epoch 29, Step: 675, Loss: 0.011230776086449623, Lr:0.0001\n",
      "Epoch 29, Step: 676, Loss: 0.02555590122938156, Lr:0.0001\n",
      "Epoch 29, Step: 677, Loss: 0.2261146754026413, Lr:0.0001\n",
      "Epoch 29, Step: 678, Loss: 0.03209689259529114, Lr:0.0001\n",
      "Epoch 29, Step: 679, Loss: 0.008075420744717121, Lr:0.0001\n",
      "Epoch 29, Step: 680, Loss: 0.03637520223855972, Lr:0.0001\n",
      "Epoch 29, Step: 681, Loss: 0.10580523312091827, Lr:0.0001\n",
      "Epoch 29, Step: 682, Loss: 0.07213424891233444, Lr:0.0001\n",
      "Epoch 29, Step: 683, Loss: 0.05028746277093887, Lr:0.0001\n",
      "Epoch 29, Step: 684, Loss: 0.013241659849882126, Lr:0.0001\n",
      "Epoch 29, Step: 685, Loss: 0.008469334803521633, Lr:0.0001\n",
      "Epoch 29, Step: 686, Loss: 0.06506718695163727, Lr:0.0001\n",
      "Epoch 29, Step: 687, Loss: 0.14546822011470795, Lr:0.0001\n",
      "Epoch 29, Step: 688, Loss: 0.05193540081381798, Lr:0.0001\n",
      "Epoch 29, Step: 689, Loss: 0.026685284450650215, Lr:0.0001\n",
      "Epoch 29, Step: 690, Loss: 0.024925781413912773, Lr:0.0001\n",
      "Epoch 29, Step: 691, Loss: 0.09719958156347275, Lr:0.0001\n",
      "Epoch 29, Step: 692, Loss: 0.008363722823560238, Lr:0.0001\n",
      "Epoch 29, Step: 693, Loss: 0.02251092717051506, Lr:0.0001\n",
      "Epoch 29, Step: 694, Loss: 0.05092804506421089, Lr:0.0001\n",
      "Epoch 29, Step: 695, Loss: 0.13198867440223694, Lr:0.0001\n",
      "Epoch 29, Step: 696, Loss: 0.14636947214603424, Lr:0.0001\n",
      "Epoch 29, Step: 697, Loss: 0.01675863191485405, Lr:0.0001\n",
      "Epoch 29, Step: 698, Loss: 0.008262211456894875, Lr:0.0001\n",
      "Epoch 29, Step: 699, Loss: 0.010696928948163986, Lr:0.0001\n",
      "Epoch 29, Step: 700, Loss: 0.09409013390541077, Lr:0.0001\n",
      "Epoch 29, Step: 701, Loss: 0.019029976800084114, Lr:0.0001\n",
      "Epoch 29, Step: 702, Loss: 0.007286054082214832, Lr:0.0001\n",
      "Epoch 29, Step: 703, Loss: 0.018107755109667778, Lr:0.0001\n",
      "Epoch 29, Step: 704, Loss: 0.01263433787971735, Lr:0.0001\n",
      "Epoch 29, Step: 705, Loss: 0.025329913944005966, Lr:0.0001\n",
      "Epoch 29, Step: 706, Loss: 0.00256851757876575, Lr:0.0001\n",
      "Epoch 29, Step: 707, Loss: 0.022938743233680725, Lr:0.0001\n",
      "Epoch 29, Step: 708, Loss: 0.04840923100709915, Lr:0.0001\n",
      "Epoch 29, Step: 709, Loss: 0.11987768113613129, Lr:0.0001\n",
      "Epoch 29, Step: 710, Loss: 0.13720610737800598, Lr:0.0001\n",
      "Epoch 29, Step: 711, Loss: 0.0268253181129694, Lr:0.0001\n",
      "Epoch 29, Step: 712, Loss: 0.004844551905989647, Lr:0.0001\n",
      "Epoch 29, Step: 713, Loss: 0.012779682874679565, Lr:0.0001\n",
      "Epoch 29, Step: 714, Loss: 0.004654115065932274, Lr:0.0001\n",
      "Epoch 29, Step: 715, Loss: 0.07538764923810959, Lr:0.0001\n",
      "Epoch 29, Step: 716, Loss: 0.014470016583800316, Lr:0.0001\n",
      "Epoch 29, Step: 717, Loss: 0.11772063374519348, Lr:0.0001\n",
      "Epoch 29, Step: 718, Loss: 0.004403483122587204, Lr:0.0001\n",
      "Epoch 29, Step: 719, Loss: 0.008757958188652992, Lr:0.0001\n",
      "Epoch 29, Step: 720, Loss: 0.027765775099396706, Lr:0.0001\n",
      "Epoch 29, Step: 721, Loss: 0.011280876584351063, Lr:0.0001\n",
      "Epoch 29, Step: 722, Loss: 0.02297123521566391, Lr:0.0001\n",
      "Epoch 29, Step: 723, Loss: 0.009154440835118294, Lr:0.0001\n",
      "Epoch 29, Step: 724, Loss: 0.061821866780519485, Lr:0.0001\n",
      "Epoch 29, Step: 725, Loss: 0.005863096099346876, Lr:0.0001\n",
      "Epoch 29, Step: 726, Loss: 0.04068699851632118, Lr:0.0001\n",
      "Epoch 29, Step: 727, Loss: 0.017089052125811577, Lr:0.0001\n",
      "Epoch 29, Step: 728, Loss: 0.002711640438064933, Lr:0.0001\n",
      "Epoch 29, Step: 729, Loss: 0.053065743297338486, Lr:0.0001\n",
      "Epoch 29, Step: 730, Loss: 0.12041006982326508, Lr:0.0001\n",
      "Epoch 29, Step: 731, Loss: 0.022241173312067986, Lr:0.0001\n",
      "Epoch 29, Step: 732, Loss: 0.038182493299245834, Lr:0.0001\n",
      "Epoch 29, Step: 733, Loss: 0.028226252645254135, Lr:0.0001\n",
      "Epoch 29, Step: 734, Loss: 0.04410378262400627, Lr:0.0001\n",
      "Epoch 29, Step: 735, Loss: 0.061686355620622635, Lr:0.0001\n",
      "Epoch 29, Step: 736, Loss: 0.023380737751722336, Lr:0.0001\n",
      "Epoch 29, Step: 737, Loss: 0.004820047412067652, Lr:0.0001\n",
      "Epoch 29, Step: 738, Loss: 0.025871489197015762, Lr:0.0001\n",
      "Epoch 29, Step: 739, Loss: 0.018927520141005516, Lr:0.0001\n",
      "Epoch 29, Step: 740, Loss: 0.00400865264236927, Lr:0.0001\n",
      "Epoch 29, Step: 741, Loss: 0.05309199541807175, Lr:0.0001\n",
      "Epoch 29, Step: 742, Loss: 0.10429709404706955, Lr:0.0001\n",
      "Epoch 29, Step: 743, Loss: 0.026599695906043053, Lr:0.0001\n",
      "Epoch 29, Step: 744, Loss: 0.027793841436505318, Lr:0.0001\n",
      "Epoch 29, Step: 745, Loss: 0.01814597100019455, Lr:0.0001\n",
      "Epoch 29, Step: 746, Loss: 0.0816124752163887, Lr:0.0001\n",
      "Epoch 29, Step: 747, Loss: 0.0003776814555749297, Lr:0.0001\n",
      "Epoch 29, Step: 748, Loss: 0.013040339574217796, Lr:0.0001\n",
      "Epoch 29, Step: 749, Loss: 0.004530683625489473, Lr:0.0001\n",
      "Epoch 29, Step: 750, Loss: 0.07649627327919006, Lr:0.0001\n",
      "Epoch 29, Step: 751, Loss: 0.044631227850914, Lr:0.0001\n",
      "Epoch 29, Step: 752, Loss: 0.06625315546989441, Lr:0.0001\n",
      "Epoch 29, Step: 753, Loss: 0.045396335422992706, Lr:0.0001\n",
      "Epoch 29, Step: 754, Loss: 0.009778851643204689, Lr:0.0001\n",
      "Epoch 29, Step: 755, Loss: 0.004916614852845669, Lr:0.0001\n",
      "Epoch 29, Step: 756, Loss: 0.07871069759130478, Lr:0.0001\n",
      "Epoch 29, Step: 757, Loss: 0.10392738878726959, Lr:0.0001\n",
      "Epoch 29, Step: 758, Loss: 0.626266598701477, Lr:0.0001\n",
      "Epoch 29, Step: 759, Loss: 0.004508324433118105, Lr:0.0001\n",
      "Epoch 29, Step: 760, Loss: 0.0321560762822628, Lr:0.0001\n",
      "Epoch 29, Step: 761, Loss: 0.005152278579771519, Lr:0.0001\n",
      "Epoch 29, Step: 762, Loss: 0.013839242048561573, Lr:0.0001\n",
      "Epoch 29, Step: 763, Loss: 0.06103408336639404, Lr:0.0001\n",
      "Epoch 29, Step: 764, Loss: 0.002430410822853446, Lr:0.0001\n",
      "Epoch 29, Step: 765, Loss: 0.005159955471754074, Lr:0.0001\n",
      "Epoch 29, Step: 766, Loss: 0.060293979942798615, Lr:0.0001\n",
      "Epoch 29, Step: 767, Loss: 0.1671762615442276, Lr:0.0001\n",
      "Epoch 29, Step: 768, Loss: 0.0025507532991468906, Lr:0.0001\n",
      "Epoch 29, Step: 769, Loss: 0.03875376284122467, Lr:0.0001\n",
      "Epoch 29, Step: 770, Loss: 0.009424380026757717, Lr:0.0001\n",
      "Epoch 29, Step: 771, Loss: 0.038698647171258926, Lr:0.0001\n",
      "Epoch 29, Step: 772, Loss: 0.0020097214728593826, Lr:0.0001\n",
      "Epoch 29, Step: 773, Loss: 0.010980424471199512, Lr:0.0001\n",
      "Epoch 29, Step: 774, Loss: 0.003289883490651846, Lr:0.0001\n",
      "Epoch 29, Step: 775, Loss: 0.0032788936514407396, Lr:0.0001\n",
      "Epoch 29, Step: 776, Loss: 0.0068552568554878235, Lr:0.0001\n",
      "Epoch 29, Step: 777, Loss: 0.008084498345851898, Lr:0.0001\n",
      "Epoch 29, Step: 778, Loss: 0.01999550499022007, Lr:0.0001\n",
      "Epoch 29, Step: 779, Loss: 0.06971271336078644, Lr:0.0001\n",
      "Epoch 29, Step: 780, Loss: 0.13740232586860657, Lr:0.0001\n",
      "Epoch 29, Step: 781, Loss: 0.05523880943655968, Lr:0.0001\n",
      "Epoch 29, Step: 782, Loss: 0.002169327111914754, Lr:0.0001\n",
      "Epoch 29, Step: 783, Loss: 0.2143198698759079, Lr:0.0001\n",
      "Epoch 29, Step: 784, Loss: 0.007593038026243448, Lr:0.0001\n",
      "Epoch 29, Step: 785, Loss: 0.019010018557310104, Lr:0.0001\n",
      "Epoch 29, Step: 786, Loss: 0.010595528408885002, Lr:0.0001\n",
      "Epoch 29, Step: 787, Loss: 0.0608472004532814, Lr:0.0001\n",
      "Epoch 29, Step: 788, Loss: 0.005061757750809193, Lr:0.0001\n",
      "Epoch 29, Step: 789, Loss: 0.04467315599322319, Lr:0.0001\n",
      "Epoch 29, Step: 790, Loss: 0.1408504694700241, Lr:0.0001\n",
      "Epoch 29, Step: 791, Loss: 0.009264128282666206, Lr:0.0001\n",
      "Epoch 29, Step: 792, Loss: 0.008505732752382755, Lr:0.0001\n",
      "Epoch 29, Step: 793, Loss: 0.04814549535512924, Lr:0.0001\n",
      "Epoch 29, Step: 794, Loss: 0.004364928230643272, Lr:0.0001\n",
      "Epoch 29, Step: 795, Loss: 0.004725099075585604, Lr:0.0001\n",
      "Epoch 29, Step: 796, Loss: 0.02308015711605549, Lr:0.0001\n",
      "Epoch 29, Step: 797, Loss: 0.0027533930260688066, Lr:0.0001\n",
      "Epoch 29, Step: 798, Loss: 0.03909396007657051, Lr:0.0001\n",
      "Epoch 29, Step: 799, Loss: 0.12969748675823212, Lr:0.0001\n",
      "Epoch 29, Step: 800, Loss: 0.20541919767856598, Lr:0.0001\n",
      "Epoch 29, Step: 801, Loss: 0.0034636755008250475, Lr:0.0001\n",
      "Epoch 29, Step: 802, Loss: 0.02217124216258526, Lr:0.0001\n",
      "Epoch 29, Step: 803, Loss: 0.0023375260643661022, Lr:0.0001\n",
      "Epoch 29, Step: 804, Loss: 0.03913282975554466, Lr:0.0001\n",
      "Epoch 29, Step: 805, Loss: 0.0012359924148768187, Lr:0.0001\n",
      "Epoch 29, Step: 806, Loss: 0.28035351634025574, Lr:0.0001\n",
      "Epoch 29, Step: 807, Loss: 0.05126023665070534, Lr:0.0001\n",
      "Epoch 29, Step: 808, Loss: 0.011837356723845005, Lr:0.0001\n",
      "Epoch 29, Step: 809, Loss: 0.029835153371095657, Lr:0.0001\n",
      "Epoch 29, Step: 810, Loss: 0.3090199828147888, Lr:0.0001\n",
      "Epoch 29, Step: 811, Loss: 0.02430008351802826, Lr:0.0001\n",
      "Epoch 29, Step: 812, Loss: 0.03305310383439064, Lr:0.0001\n",
      "Epoch 29, Step: 813, Loss: 0.13463325798511505, Lr:0.0001\n",
      "Epoch 29, Step: 814, Loss: 0.019325092434883118, Lr:0.0001\n",
      "Epoch 29, Step: 815, Loss: 0.03320561721920967, Lr:0.0001\n",
      "Epoch 29, Step: 816, Loss: 0.011305192485451698, Lr:0.0001\n",
      "Epoch 29, Step: 817, Loss: 0.0022621529642492533, Lr:0.0001\n",
      "Epoch 29, Step: 818, Loss: 0.056865107268095016, Lr:0.0001\n",
      "Epoch 29, Step: 819, Loss: 0.01725880242884159, Lr:0.0001\n",
      "Epoch 29, Step: 820, Loss: 0.016409965232014656, Lr:0.0001\n",
      "Epoch 29, Step: 821, Loss: 0.08034101873636246, Lr:0.0001\n",
      "Epoch 29, Step: 822, Loss: 0.21993011236190796, Lr:0.0001\n",
      "Epoch 29, Step: 823, Loss: 0.22568143904209137, Lr:0.0001\n",
      "Epoch 29, Step: 824, Loss: 0.22971080243587494, Lr:0.0001\n",
      "Epoch 29, Step: 825, Loss: 0.010085046291351318, Lr:0.0001\n",
      "Epoch 29, Step: 826, Loss: 0.011873742565512657, Lr:0.0001\n",
      "Epoch 29, Step: 827, Loss: 0.007963219657540321, Lr:0.0001\n",
      "Epoch 29, Step: 828, Loss: 0.009014954790472984, Lr:0.0001\n",
      "Epoch 29, Step: 829, Loss: 0.028520485386252403, Lr:0.0001\n",
      "Epoch 29, Step: 830, Loss: 0.00034807182964868844, Lr:0.0001\n",
      "Epoch 29, Step: 831, Loss: 0.0005501668783836067, Lr:0.0001\n",
      "Epoch 29, Step: 832, Loss: 0.14750519394874573, Lr:0.0001\n",
      "Epoch 29, Step: 833, Loss: 0.002184865763410926, Lr:0.0001\n",
      "Epoch 29, Step: 834, Loss: 0.16398081183433533, Lr:0.0001\n",
      "Epoch 29, Step: 835, Loss: 0.07726848870515823, Lr:0.0001\n",
      "Epoch 29, Step: 836, Loss: 0.07696233689785004, Lr:0.0001\n",
      "Epoch 29, Step: 837, Loss: 0.032910626381635666, Lr:0.0001\n",
      "Epoch 29, Step: 838, Loss: 0.02122746780514717, Lr:0.0001\n",
      "Epoch 29, Step: 839, Loss: 0.2574223577976227, Lr:0.0001\n",
      "Epoch 29, Step: 840, Loss: 0.012722058221697807, Lr:0.0001\n",
      "Epoch 29, Step: 841, Loss: 0.021160591393709183, Lr:0.0001\n",
      "Epoch 29, Step: 842, Loss: 0.11104372888803482, Lr:0.0001\n",
      "Epoch 29, Step: 843, Loss: 0.02840288169682026, Lr:0.0001\n",
      "Epoch 29, Step: 844, Loss: 0.006405785214155912, Lr:0.0001\n",
      "Epoch 29, Step: 845, Loss: 0.06211394816637039, Lr:0.0001\n",
      "Epoch 29, Step: 846, Loss: 0.006100649945437908, Lr:0.0001\n",
      "Epoch 29, Step: 847, Loss: 0.2069694697856903, Lr:0.0001\n",
      "Epoch 29, Step: 848, Loss: 0.07103171944618225, Lr:0.0001\n",
      "Epoch 29, Step: 849, Loss: 0.0431310273706913, Lr:0.0001\n",
      "Epoch 29, Step: 850, Loss: 0.039340902119874954, Lr:0.0001\n",
      "Epoch 29, Step: 851, Loss: 0.19157856702804565, Lr:0.0001\n",
      "Epoch 29, Step: 852, Loss: 0.0025240108370780945, Lr:0.0001\n",
      "Epoch 29, Step: 853, Loss: 0.024123836308717728, Lr:0.0001\n",
      "Epoch 29, Step: 854, Loss: 0.09272454679012299, Lr:0.0001\n",
      "Epoch 29, Step: 855, Loss: 0.19327527284622192, Lr:0.0001\n",
      "Epoch 29, Step: 856, Loss: 0.011461989022791386, Lr:0.0001\n",
      "Epoch 29, Step: 857, Loss: 0.13714464008808136, Lr:0.0001\n",
      "Epoch 29, Step: 858, Loss: 0.0004533971950877458, Lr:0.0001\n",
      "Epoch 29, Step: 859, Loss: 0.07198118418455124, Lr:0.0001\n",
      "Epoch 29, Step: 860, Loss: 0.0014021217357367277, Lr:0.0001\n",
      "Epoch 29, Step: 861, Loss: 0.017100276425480843, Lr:0.0001\n",
      "Epoch 29, Step: 862, Loss: 0.002999406075105071, Lr:0.0001\n",
      "Epoch 29, Step: 863, Loss: 0.11252089589834213, Lr:0.0001\n",
      "Epoch 29, Step: 864, Loss: 0.008157873526215553, Lr:0.0001\n",
      "Epoch 29, Step: 865, Loss: 0.010142907500267029, Lr:0.0001\n",
      "Epoch 29, Step: 866, Loss: 0.5328484177589417, Lr:0.0001\n",
      "Epoch 29, Step: 867, Loss: 0.0025485106743872166, Lr:0.0001\n",
      "Epoch 29, Step: 868, Loss: 0.011797584593296051, Lr:0.0001\n",
      "Epoch 29, Step: 869, Loss: 0.02927078679203987, Lr:0.0001\n",
      "Epoch 29, Step: 870, Loss: 0.004548477940261364, Lr:0.0001\n",
      "Epoch 29, Step: 871, Loss: 0.010018711909651756, Lr:0.0001\n",
      "Epoch 29, Step: 872, Loss: 0.038352541625499725, Lr:0.0001\n",
      "Epoch 29, Step: 873, Loss: 0.0011316948803141713, Lr:0.0001\n",
      "Epoch 29, Step: 874, Loss: 0.04182923585176468, Lr:0.0001\n",
      "Epoch 29, Step: 875, Loss: 0.04033976048231125, Lr:0.0001\n",
      "Epoch 29, Step: 876, Loss: 0.1113118827342987, Lr:0.0001\n",
      "Epoch 29, Step: 877, Loss: 0.00044322595931589603, Lr:0.0001\n",
      "Epoch 29, Step: 878, Loss: 0.13540828227996826, Lr:0.0001\n",
      "Epoch 29, Step: 879, Loss: 0.009389267303049564, Lr:0.0001\n",
      "Epoch 29, Step: 880, Loss: 0.1997746378183365, Lr:0.0001\n",
      "Epoch 29, Step: 881, Loss: 0.1302553117275238, Lr:0.0001\n",
      "Epoch 29, Step: 882, Loss: 0.0017196228727698326, Lr:0.0001\n",
      "Epoch 29, Step: 883, Loss: 0.06463222205638885, Lr:0.0001\n",
      "Epoch 29, Step: 884, Loss: 0.035099953413009644, Lr:0.0001\n",
      "Epoch 29, Step: 885, Loss: 0.028838708996772766, Lr:0.0001\n",
      "Epoch 29, Step: 886, Loss: 0.0009655040921643376, Lr:0.0001\n",
      "Epoch 29, Step: 887, Loss: 0.002944455947726965, Lr:0.0001\n",
      "Epoch 29, Step: 888, Loss: 0.020789416506886482, Lr:0.0001\n",
      "Epoch 29, Step: 889, Loss: 0.02135121263563633, Lr:0.0001\n",
      "Epoch 29, Step: 890, Loss: 0.1561644971370697, Lr:0.0001\n",
      "Epoch 29, Step: 891, Loss: 0.12865090370178223, Lr:0.0001\n",
      "Epoch 29, Step: 892, Loss: 0.05695135146379471, Lr:0.0001\n",
      "Epoch 29, Step: 893, Loss: 0.06905808299779892, Lr:0.0001\n",
      "Epoch 29, Step: 894, Loss: 0.2930834889411926, Lr:0.0001\n",
      "Epoch 29, Step: 895, Loss: 0.01283516176044941, Lr:0.0001\n",
      "Epoch 29, Step: 896, Loss: 0.01332828588783741, Lr:0.0001\n",
      "Epoch 29, Step: 897, Loss: 0.005525170359760523, Lr:0.0001\n",
      "Epoch 29, Step: 898, Loss: 0.04719875007867813, Lr:0.0001\n",
      "Epoch 29, Step: 899, Loss: 0.01846121810376644, Lr:0.0001\n",
      "Epoch 29, Step: 900, Loss: 0.06448686122894287, Lr:0.0001\n",
      "Epoch 29, Step: 901, Loss: 0.0532834455370903, Lr:0.0001\n",
      "Epoch 29, Step: 902, Loss: 0.00903721246868372, Lr:0.0001\n",
      "Epoch 29, Step: 903, Loss: 0.017427364364266396, Lr:0.0001\n",
      "Epoch 29, Step: 904, Loss: 0.04287341982126236, Lr:0.0001\n",
      "Epoch 29, Step: 905, Loss: 0.16211335361003876, Lr:0.0001\n",
      "Epoch 29, Step: 906, Loss: 0.0502564013004303, Lr:0.0001\n",
      "Epoch 29, Step: 907, Loss: 0.04077138751745224, Lr:0.0001\n",
      "Epoch 29, Step: 908, Loss: 0.0973658561706543, Lr:0.0001\n",
      "Epoch 29, Step: 909, Loss: 0.041264865547418594, Lr:0.0001\n",
      "Epoch 29, Step: 910, Loss: 0.15295414626598358, Lr:0.0001\n",
      "Epoch 29, Step: 911, Loss: 0.0145373260602355, Lr:0.0001\n",
      "Epoch 29, Step: 912, Loss: 0.01129981316626072, Lr:0.0001\n",
      "Epoch 29, Step: 913, Loss: 0.030276158824563026, Lr:0.0001\n",
      "Epoch 29, Step: 914, Loss: 0.04695416986942291, Lr:0.0001\n",
      "Epoch 29, Step: 915, Loss: 0.02851090021431446, Lr:0.0001\n",
      "Epoch 29, Step: 916, Loss: 0.001350219827145338, Lr:0.0001\n",
      "Epoch 29, Step: 917, Loss: 0.033709075301885605, Lr:0.0001\n",
      "Epoch 29, Step: 918, Loss: 0.001593811553902924, Lr:0.0001\n",
      "Epoch 29, Step: 919, Loss: 0.015395645052194595, Lr:0.0001\n",
      "Epoch 29, Step: 920, Loss: 0.11616381257772446, Lr:0.0001\n",
      "Epoch 29, Step: 921, Loss: 0.003778717014938593, Lr:0.0001\n",
      "Epoch 29, Step: 922, Loss: 0.011680793948471546, Lr:0.0001\n",
      "Epoch 29, Step: 923, Loss: 0.00422650296241045, Lr:0.0001\n",
      "Epoch 29, Step: 924, Loss: 0.21660912036895752, Lr:0.0001\n",
      "Epoch 29, Step: 925, Loss: 0.30385807156562805, Lr:0.0001\n",
      "Epoch 29, Step: 926, Loss: 0.017251938581466675, Lr:0.0001\n",
      "Epoch 29, Step: 927, Loss: 0.06704939156770706, Lr:0.0001\n",
      "Epoch 29, Step: 928, Loss: 0.07898138463497162, Lr:0.0001\n",
      "Epoch 29, Step: 929, Loss: 0.1353759467601776, Lr:0.0001\n",
      "Epoch 29, Step: 930, Loss: 0.001121154404245317, Lr:0.0001\n",
      "Epoch 29, Step: 931, Loss: 0.018526297062635422, Lr:0.0001\n",
      "Epoch 29, Step: 932, Loss: 0.034877073019742966, Lr:0.0001\n",
      "Epoch 29, Step: 933, Loss: 0.000407883373554796, Lr:0.0001\n",
      "Epoch 29, Step: 934, Loss: 0.004288668744266033, Lr:0.0001\n",
      "Epoch 29, Step: 935, Loss: 0.0066440817900002, Lr:0.0001\n",
      "Epoch 29, Step: 936, Loss: 0.04124508425593376, Lr:0.0001\n",
      "Epoch 29, Step: 937, Loss: 0.11606762558221817, Lr:0.0001\n",
      "Epoch 29, Step: 938, Loss: 0.01003320887684822, Lr:0.0001\n",
      "Epoch 29, Step: 939, Loss: 0.0032758861780166626, Lr:0.0001\n",
      "Epoch 29, Step: 940, Loss: 0.20934033393859863, Lr:0.0001\n",
      "Epoch 29, Step: 941, Loss: 0.048330944031476974, Lr:0.0001\n",
      "Epoch 29, Step: 942, Loss: 0.055169954895973206, Lr:0.0001\n",
      "Epoch 29, Step: 943, Loss: 0.00215034163556993, Lr:0.0001\n",
      "Epoch 29, Step: 944, Loss: 0.005386166740208864, Lr:0.0001\n",
      "Epoch 29, Step: 945, Loss: 0.0029180243145674467, Lr:0.0001\n",
      "Epoch 29, Step: 946, Loss: 0.0008341602515429258, Lr:0.0001\n",
      "Epoch 29, Step: 947, Loss: 0.16108642518520355, Lr:0.0001\n",
      "Epoch 29, Step: 948, Loss: 0.009675872512161732, Lr:0.0001\n",
      "Epoch 29, Step: 949, Loss: 0.003247481305152178, Lr:0.0001\n",
      "Epoch 29, Step: 950, Loss: 0.0032046972773969173, Lr:0.0001\n",
      "Epoch 29, Step: 951, Loss: 0.07849899679422379, Lr:0.0001\n",
      "Epoch 29, Step: 952, Loss: 0.002182342577725649, Lr:0.0001\n",
      "Epoch 29, Step: 953, Loss: 0.004836241248995066, Lr:0.0001\n",
      "Epoch 29, Step: 954, Loss: 0.13117218017578125, Lr:0.0001\n",
      "Epoch 29, Step: 955, Loss: 0.05584877356886864, Lr:0.0001\n",
      "Epoch 29, Step: 956, Loss: 0.002084979321807623, Lr:0.0001\n",
      "Epoch 29, Step: 957, Loss: 0.0004433050053194165, Lr:0.0001\n",
      "Epoch 29, Step: 958, Loss: 0.011083880439400673, Lr:0.0001\n",
      "Epoch 29, Step: 959, Loss: 0.03092036023736, Lr:0.0001\n",
      "Epoch 29, Step: 960, Loss: 0.0011735789012163877, Lr:0.0001\n",
      "Epoch 29, Step: 961, Loss: 0.021972263231873512, Lr:0.0001\n",
      "Epoch 29, Step: 962, Loss: 0.09556782990694046, Lr:0.0001\n",
      "Epoch 29, Step: 963, Loss: 0.05076856166124344, Lr:0.0001\n",
      "Epoch 29, Step: 964, Loss: 0.024544106796383858, Lr:0.0001\n",
      "Epoch 29, Step: 965, Loss: 0.06949225813150406, Lr:0.0001\n",
      "Epoch 29, Step: 966, Loss: 0.000540219887625426, Lr:0.0001\n",
      "Epoch 29, Step: 967, Loss: 0.09257663786411285, Lr:0.0001\n",
      "Epoch 29, Step: 968, Loss: 0.040327802300453186, Lr:0.0001\n",
      "Epoch 29, Step: 969, Loss: 0.007189759984612465, Lr:0.0001\n",
      "Epoch 29, Step: 970, Loss: 0.0012012200895696878, Lr:0.0001\n",
      "Epoch 29, Step: 971, Loss: 0.12835006415843964, Lr:0.0001\n",
      "Epoch 29, Step: 972, Loss: 0.03370467945933342, Lr:0.0001\n",
      "Epoch 29, Step: 973, Loss: 0.1750393658876419, Lr:0.0001\n",
      "Epoch 29, Step: 974, Loss: 0.0126471146941185, Lr:0.0001\n",
      "Epoch 29, Step: 975, Loss: 0.009520763531327248, Lr:0.0001\n",
      "Epoch 29, Step: 976, Loss: 0.008341552689671516, Lr:0.0001\n",
      "Epoch 29, Step: 977, Loss: 0.15802158415317535, Lr:0.0001\n",
      "Epoch 29, Step: 978, Loss: 0.03698745369911194, Lr:0.0001\n",
      "Epoch 29, Step: 979, Loss: 0.16205069422721863, Lr:0.0001\n",
      "Epoch 29, Step: 980, Loss: 0.003069598926231265, Lr:0.0001\n",
      "Epoch 29, Step: 981, Loss: 0.2015191614627838, Lr:0.0001\n",
      "Epoch 29, Step: 982, Loss: 0.017394760623574257, Lr:0.0001\n",
      "Epoch 29, Step: 983, Loss: 0.05251535028219223, Lr:0.0001\n",
      "Epoch 29, Step: 984, Loss: 0.038022927939891815, Lr:0.0001\n",
      "Epoch 29, Step: 985, Loss: 0.00582505576312542, Lr:0.0001\n",
      "Epoch 29, Step: 986, Loss: 0.0006896931445226073, Lr:0.0001\n",
      "Epoch 29, Step: 987, Loss: 0.0002685845538508147, Lr:0.0001\n",
      "Epoch 29, Step: 988, Loss: 0.009346803650259972, Lr:0.0001\n",
      "Epoch 29, Step: 989, Loss: 0.000739624781999737, Lr:0.0001\n",
      "Epoch 29, Step: 990, Loss: 0.02996956743299961, Lr:0.0001\n",
      "Epoch 29, Step: 991, Loss: 0.0017918621888384223, Lr:0.0001\n",
      "Epoch 29, Step: 992, Loss: 0.13070864975452423, Lr:0.0001\n",
      "Epoch 29, Step: 993, Loss: 0.05562775582075119, Lr:0.0001\n",
      "Epoch 29, Step: 994, Loss: 0.004502451978623867, Lr:0.0001\n",
      "Epoch 29, Step: 995, Loss: 0.008877397514879704, Lr:0.0001\n",
      "Epoch 29, Step: 996, Loss: 0.033800214529037476, Lr:0.0001\n",
      "Epoch 29, Step: 997, Loss: 0.00034040596801787615, Lr:0.0001\n",
      "Epoch 29, Step: 998, Loss: 0.03137398511171341, Lr:0.0001\n",
      "Epoch 29, Step: 999, Loss: 0.29003649950027466, Lr:0.0001\n",
      "Epoch 29, Step: 1000, Loss: 0.002773280255496502, Lr:0.0001\n",
      "Epoch 29, Step: 1001, Loss: 0.003226472297683358, Lr:0.0001\n",
      "Epoch 29, Step: 1002, Loss: 0.10137971490621567, Lr:0.0001\n",
      "Epoch 29, Step: 1003, Loss: 0.014126335270702839, Lr:0.0001\n",
      "Epoch 29, Step: 1004, Loss: 0.0020612101070582867, Lr:0.0001\n",
      "Epoch 29, Step: 1005, Loss: 0.031859491020441055, Lr:0.0001\n",
      "Epoch 29, Step: 1006, Loss: 0.003152994206175208, Lr:0.0001\n",
      "Epoch 29, Step: 1007, Loss: 0.0808386504650116, Lr:0.0001\n",
      "Epoch 29, Step: 1008, Loss: 0.07923397421836853, Lr:0.0001\n",
      "Epoch 29, Step: 1009, Loss: 0.0021846166346222162, Lr:0.0001\n",
      "Epoch 29, Step: 1010, Loss: 0.03812691196799278, Lr:0.0001\n",
      "Epoch 29, Step: 1011, Loss: 0.11463643610477448, Lr:0.0001\n",
      "Epoch 29, Step: 1012, Loss: 0.00045076722744852304, Lr:0.0001\n",
      "Epoch 29, Step: 1013, Loss: 0.0034560884814709425, Lr:0.0001\n",
      "Epoch 29, Step: 1014, Loss: 0.23144476115703583, Lr:0.0001\n",
      "Epoch 29, Step: 1015, Loss: 0.06492605805397034, Lr:0.0001\n",
      "Epoch 29, Step: 1016, Loss: 0.19520780444145203, Lr:0.0001\n",
      "Epoch 29, Step: 1017, Loss: 0.018710197880864143, Lr:0.0001\n",
      "Epoch 29, Step: 1018, Loss: 0.012626188807189465, Lr:0.0001\n",
      "Epoch 29, Step: 1019, Loss: 0.04737599566578865, Lr:0.0001\n",
      "Epoch 29, Step: 1020, Loss: 0.18379564583301544, Lr:0.0001\n",
      "Epoch 29, Step: 1021, Loss: 0.01904948242008686, Lr:0.0001\n",
      "Epoch 29, Step: 1022, Loss: 0.30610543489456177, Lr:0.0001\n",
      "Epoch 29, Step: 1023, Loss: 0.027231743559241295, Lr:0.0001\n",
      "Epoch 29, Step: 1024, Loss: 0.0009053023532032967, Lr:0.0001\n",
      "Epoch 29, Step: 1025, Loss: 0.009070237167179585, Lr:0.0001\n",
      "Epoch 29, Step: 1026, Loss: 0.04991995170712471, Lr:0.0001\n",
      "Epoch 29, Step: 1027, Loss: 0.0011621068697422743, Lr:0.0001\n",
      "Epoch 29, Step: 1028, Loss: 0.002796974964439869, Lr:0.0001\n",
      "Epoch 29, Step: 1029, Loss: 0.1718541979789734, Lr:0.0001\n",
      "Epoch 29, Step: 1030, Loss: 0.042668092995882034, Lr:0.0001\n",
      "Epoch 29, Step: 1031, Loss: 0.2096792459487915, Lr:0.0001\n",
      "Epoch 29, Step: 1032, Loss: 0.034038618206977844, Lr:0.0001\n",
      "Epoch 29, Step: 1033, Loss: 0.15685604512691498, Lr:0.0001\n",
      "Epoch 29, Step: 1034, Loss: 0.026080185547471046, Lr:0.0001\n",
      "Epoch 29, Step: 1035, Loss: 0.05820160731673241, Lr:0.0001\n",
      "Epoch 29, Step: 1036, Loss: 0.04950757697224617, Lr:0.0001\n",
      "Epoch 29, Step: 1037, Loss: 0.03480628877878189, Lr:0.0001\n",
      "Epoch 29, Step: 1038, Loss: 0.005060840863734484, Lr:0.0001\n",
      "Epoch 29, Step: 1039, Loss: 0.0474829375743866, Lr:0.0001\n",
      "Epoch 29, Step: 1040, Loss: 0.030871225520968437, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 29\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:16 loss: 0.0064 (0.0064) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.2970 data: 0.1180 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.0000 (0.0011) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.2940 data: 0.1172 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0000 (0.0204) acc1: 100.0000 (99.4048) acc5: 100.0000 (100.0000) time: 0.2960 data: 0.1192 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.0614 (0.1492) acc1: 93.7500 (95.9677) acc5: 100.0000 (100.0000) time: 0.2987 data: 0.1215 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.1836 (0.2027) acc1: 87.5000 (94.3598) acc5: 100.0000 (100.0000) time: 0.3031 data: 0.1270 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0156 (0.1812) acc1: 100.0000 (94.7304) acc5: 100.0000 (100.0000) time: 0.3165 data: 0.1376 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0107 (0.1846) acc1: 100.0000 (94.5516) acc5: 100.0000 (100.0000) time: 0.3012 data: 0.1309 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.2995 s / it)\n",
      "* Acc@1 94.552 Acc@5 100.000 loss 0.185\n",
      "Accuracy of the network on the 881 test image: 94.6%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 30, Step: 0, Loss: 0.019459979608654976, Lr:0.0001\n",
      "Epoch 30, Step: 1, Loss: 0.03759860247373581, Lr:0.0001\n",
      "Epoch 30, Step: 2, Loss: 0.09884124994277954, Lr:0.0001\n",
      "Epoch 30, Step: 3, Loss: 0.009183364920318127, Lr:0.0001\n",
      "Epoch 30, Step: 4, Loss: 0.04010752588510513, Lr:0.0001\n",
      "Epoch 30, Step: 5, Loss: 0.15996383130550385, Lr:0.0001\n",
      "Epoch 30, Step: 6, Loss: 0.0759713351726532, Lr:0.0001\n",
      "Epoch 30, Step: 7, Loss: 0.07792028039693832, Lr:0.0001\n",
      "Epoch 30, Step: 8, Loss: 0.0010915203019976616, Lr:0.0001\n",
      "Epoch 30, Step: 9, Loss: 0.021442199125885963, Lr:0.0001\n",
      "Epoch 30, Step: 10, Loss: 0.06304846704006195, Lr:0.0001\n",
      "Epoch 30, Step: 11, Loss: 0.06628375500440598, Lr:0.0001\n",
      "Epoch 30, Step: 12, Loss: 0.05196981132030487, Lr:0.0001\n",
      "Epoch 30, Step: 13, Loss: 0.021566202864050865, Lr:0.0001\n",
      "Epoch 30, Step: 14, Loss: 0.04622604697942734, Lr:0.0001\n",
      "Epoch 30, Step: 15, Loss: 0.0007503379019908607, Lr:0.0001\n",
      "Epoch 30, Step: 16, Loss: 0.08224482089281082, Lr:0.0001\n",
      "Epoch 30, Step: 17, Loss: 0.01164016593247652, Lr:0.0001\n",
      "Epoch 30, Step: 18, Loss: 0.0734088346362114, Lr:0.0001\n",
      "Epoch 30, Step: 19, Loss: 0.06973940879106522, Lr:0.0001\n",
      "Epoch 30, Step: 20, Loss: 0.1447102427482605, Lr:0.0001\n",
      "Epoch 30, Step: 21, Loss: 0.181224063038826, Lr:0.0001\n",
      "Epoch 30, Step: 22, Loss: 0.013507599011063576, Lr:0.0001\n",
      "Epoch 30, Step: 23, Loss: 0.030536912381649017, Lr:0.0001\n",
      "Epoch 30, Step: 24, Loss: 0.10929936915636063, Lr:0.0001\n",
      "Epoch 30, Step: 25, Loss: 0.19598065316677094, Lr:0.0001\n",
      "Epoch 30, Step: 26, Loss: 0.010376703925430775, Lr:0.0001\n",
      "Epoch 30, Step: 27, Loss: 0.008707885630428791, Lr:0.0001\n",
      "Epoch 30, Step: 28, Loss: 0.032749243080616, Lr:0.0001\n",
      "Epoch 30, Step: 29, Loss: 0.03277885168790817, Lr:0.0001\n",
      "Epoch 30, Step: 30, Loss: 0.22283504903316498, Lr:0.0001\n",
      "Epoch 30, Step: 31, Loss: 0.006913698278367519, Lr:0.0001\n",
      "Epoch 30, Step: 32, Loss: 0.01711384952068329, Lr:0.0001\n",
      "Epoch 30, Step: 33, Loss: 0.009086797945201397, Lr:0.0001\n",
      "Epoch 30, Step: 34, Loss: 0.24700741469860077, Lr:0.0001\n",
      "Epoch 30, Step: 35, Loss: 0.019195329397916794, Lr:0.0001\n",
      "Epoch 30, Step: 36, Loss: 0.00955029297620058, Lr:0.0001\n",
      "Epoch 30, Step: 37, Loss: 0.007266112603247166, Lr:0.0001\n",
      "Epoch 30, Step: 38, Loss: 0.03510313108563423, Lr:0.0001\n",
      "Epoch 30, Step: 39, Loss: 0.12111254781484604, Lr:0.0001\n",
      "Epoch 30, Step: 40, Loss: 0.09920242428779602, Lr:0.0001\n",
      "Epoch 30, Step: 41, Loss: 0.009420458227396011, Lr:0.0001\n",
      "Epoch 30, Step: 42, Loss: 0.02137802354991436, Lr:0.0001\n",
      "Epoch 30, Step: 43, Loss: 0.038024164736270905, Lr:0.0001\n",
      "Epoch 30, Step: 44, Loss: 0.17938925325870514, Lr:0.0001\n",
      "Epoch 30, Step: 45, Loss: 0.06254814565181732, Lr:0.0001\n",
      "Epoch 30, Step: 46, Loss: 0.012737768702208996, Lr:0.0001\n",
      "Epoch 30, Step: 47, Loss: 0.0032544275745749474, Lr:0.0001\n",
      "Epoch 30, Step: 48, Loss: 0.03531869500875473, Lr:0.0001\n",
      "Epoch 30, Step: 49, Loss: 0.12591400742530823, Lr:0.0001\n",
      "Epoch 30, Step: 50, Loss: 0.038963526487350464, Lr:0.0001\n",
      "Epoch 30, Step: 51, Loss: 0.048380445688962936, Lr:0.0001\n",
      "Epoch 30, Step: 52, Loss: 0.11093568056821823, Lr:0.0001\n",
      "Epoch 30, Step: 53, Loss: 0.05320194736123085, Lr:0.0001\n",
      "Epoch 30, Step: 54, Loss: 0.009141754359006882, Lr:0.0001\n",
      "Epoch 30, Step: 55, Loss: 0.024518374353647232, Lr:0.0001\n",
      "Epoch 30, Step: 56, Loss: 0.033780016005039215, Lr:0.0001\n",
      "Epoch 30, Step: 57, Loss: 0.04005303606390953, Lr:0.0001\n",
      "Epoch 30, Step: 58, Loss: 0.09873643517494202, Lr:0.0001\n",
      "Epoch 30, Step: 59, Loss: 0.0024535120464861393, Lr:0.0001\n",
      "Epoch 30, Step: 60, Loss: 0.004488652106374502, Lr:0.0001\n",
      "Epoch 30, Step: 61, Loss: 0.06957831978797913, Lr:0.0001\n",
      "Epoch 30, Step: 62, Loss: 0.13290518522262573, Lr:0.0001\n",
      "Epoch 30, Step: 63, Loss: 0.020501378923654556, Lr:0.0001\n",
      "Epoch 30, Step: 64, Loss: 0.010597377084195614, Lr:0.0001\n",
      "Epoch 30, Step: 65, Loss: 0.15832656621932983, Lr:0.0001\n",
      "Epoch 30, Step: 66, Loss: 0.06946568191051483, Lr:0.0001\n",
      "Epoch 30, Step: 67, Loss: 0.018525505438447, Lr:0.0001\n",
      "Epoch 30, Step: 68, Loss: 0.045690812170505524, Lr:0.0001\n",
      "Epoch 30, Step: 69, Loss: 0.06672658026218414, Lr:0.0001\n",
      "Epoch 30, Step: 70, Loss: 0.2046811729669571, Lr:0.0001\n",
      "Epoch 30, Step: 71, Loss: 0.10270185023546219, Lr:0.0001\n",
      "Epoch 30, Step: 72, Loss: 0.02025780640542507, Lr:0.0001\n",
      "Epoch 30, Step: 73, Loss: 0.016116447746753693, Lr:0.0001\n",
      "Epoch 30, Step: 74, Loss: 0.00410740589722991, Lr:0.0001\n",
      "Epoch 30, Step: 75, Loss: 0.11651662737131119, Lr:0.0001\n",
      "Epoch 30, Step: 76, Loss: 0.005892396904528141, Lr:0.0001\n",
      "Epoch 30, Step: 77, Loss: 0.03741929307579994, Lr:0.0001\n",
      "Epoch 30, Step: 78, Loss: 0.25262805819511414, Lr:0.0001\n",
      "Epoch 30, Step: 79, Loss: 0.020496796816587448, Lr:0.0001\n",
      "Epoch 30, Step: 80, Loss: 0.001896008150652051, Lr:0.0001\n",
      "Epoch 30, Step: 81, Loss: 0.0014176539843901992, Lr:0.0001\n",
      "Epoch 30, Step: 82, Loss: 0.0031027088407427073, Lr:0.0001\n",
      "Epoch 30, Step: 83, Loss: 0.00493667321279645, Lr:0.0001\n",
      "Epoch 30, Step: 84, Loss: 0.02574378065764904, Lr:0.0001\n",
      "Epoch 30, Step: 85, Loss: 0.06317048519849777, Lr:0.0001\n",
      "Epoch 30, Step: 86, Loss: 0.005532102659344673, Lr:0.0001\n",
      "Epoch 30, Step: 87, Loss: 0.019171012565493584, Lr:0.0001\n",
      "Epoch 30, Step: 88, Loss: 0.004537506029009819, Lr:0.0001\n",
      "Epoch 30, Step: 89, Loss: 0.01412620022892952, Lr:0.0001\n",
      "Epoch 30, Step: 90, Loss: 0.010242106392979622, Lr:0.0001\n",
      "Epoch 30, Step: 91, Loss: 0.024553479626774788, Lr:0.0001\n",
      "Epoch 30, Step: 92, Loss: 0.020438604056835175, Lr:0.0001\n",
      "Epoch 30, Step: 93, Loss: 0.04153476655483246, Lr:0.0001\n",
      "Epoch 30, Step: 94, Loss: 0.034635089337825775, Lr:0.0001\n",
      "Epoch 30, Step: 95, Loss: 0.2617332339286804, Lr:0.0001\n",
      "Epoch 30, Step: 96, Loss: 0.056885726749897, Lr:0.0001\n",
      "Epoch 30, Step: 97, Loss: 0.021226899698376656, Lr:0.0001\n",
      "Epoch 30, Step: 98, Loss: 0.018362654373049736, Lr:0.0001\n",
      "Epoch 30, Step: 99, Loss: 0.045549098402261734, Lr:0.0001\n",
      "Epoch 30, Step: 100, Loss: 0.04417705535888672, Lr:0.0001\n",
      "Epoch 30, Step: 101, Loss: 0.004155735485255718, Lr:0.0001\n",
      "Epoch 30, Step: 102, Loss: 0.004378859419375658, Lr:0.0001\n",
      "Epoch 30, Step: 103, Loss: 0.010722010396420956, Lr:0.0001\n",
      "Epoch 30, Step: 104, Loss: 0.013951726257801056, Lr:0.0001\n",
      "Epoch 30, Step: 105, Loss: 0.005620659328997135, Lr:0.0001\n",
      "Epoch 30, Step: 106, Loss: 0.007823278196156025, Lr:0.0001\n",
      "Epoch 30, Step: 107, Loss: 0.04634140059351921, Lr:0.0001\n",
      "Epoch 30, Step: 108, Loss: 0.014443334192037582, Lr:0.0001\n",
      "Epoch 30, Step: 109, Loss: 0.2117537558078766, Lr:0.0001\n",
      "Epoch 30, Step: 110, Loss: 0.14410044252872467, Lr:0.0001\n",
      "Epoch 30, Step: 111, Loss: 0.008926705457270145, Lr:0.0001\n",
      "Epoch 30, Step: 112, Loss: 0.05391545593738556, Lr:0.0001\n",
      "Epoch 30, Step: 113, Loss: 0.0801224634051323, Lr:0.0001\n",
      "Epoch 30, Step: 114, Loss: 0.04607503116130829, Lr:0.0001\n",
      "Epoch 30, Step: 115, Loss: 0.10501658916473389, Lr:0.0001\n",
      "Epoch 30, Step: 116, Loss: 0.11903416365385056, Lr:0.0001\n",
      "Epoch 30, Step: 117, Loss: 0.012356860563158989, Lr:0.0001\n",
      "Epoch 30, Step: 118, Loss: 0.06457706540822983, Lr:0.0001\n",
      "Epoch 30, Step: 119, Loss: 0.020668013021349907, Lr:0.0001\n",
      "Epoch 30, Step: 120, Loss: 0.04005984216928482, Lr:0.0001\n",
      "Epoch 30, Step: 121, Loss: 0.07594563066959381, Lr:0.0001\n",
      "Epoch 30, Step: 122, Loss: 0.009372488595545292, Lr:0.0001\n",
      "Epoch 30, Step: 123, Loss: 0.04018619656562805, Lr:0.0001\n",
      "Epoch 30, Step: 124, Loss: 0.009143492206931114, Lr:0.0001\n",
      "Epoch 30, Step: 125, Loss: 0.03636058419942856, Lr:0.0001\n",
      "Epoch 30, Step: 126, Loss: 0.012081975117325783, Lr:0.0001\n",
      "Epoch 30, Step: 127, Loss: 0.08526065945625305, Lr:0.0001\n",
      "Epoch 30, Step: 128, Loss: 0.011946815997362137, Lr:0.0001\n",
      "Epoch 30, Step: 129, Loss: 0.00814401637762785, Lr:0.0001\n",
      "Epoch 30, Step: 130, Loss: 0.0019570752047002316, Lr:0.0001\n",
      "Epoch 30, Step: 131, Loss: 0.005020910874009132, Lr:0.0001\n",
      "Epoch 30, Step: 132, Loss: 0.07263564318418503, Lr:0.0001\n",
      "Epoch 30, Step: 133, Loss: 0.19832809269428253, Lr:0.0001\n",
      "Epoch 30, Step: 134, Loss: 0.008793188259005547, Lr:0.0001\n",
      "Epoch 30, Step: 135, Loss: 0.17137344181537628, Lr:0.0001\n",
      "Epoch 30, Step: 136, Loss: 0.0218788031488657, Lr:0.0001\n",
      "Epoch 30, Step: 137, Loss: 0.05701833963394165, Lr:0.0001\n",
      "Epoch 30, Step: 138, Loss: 0.0051190610975027084, Lr:0.0001\n",
      "Epoch 30, Step: 139, Loss: 0.0011096668895334005, Lr:0.0001\n",
      "Epoch 30, Step: 140, Loss: 0.07203294336795807, Lr:0.0001\n",
      "Epoch 30, Step: 141, Loss: 0.010237058624625206, Lr:0.0001\n",
      "Epoch 30, Step: 142, Loss: 0.011102774180471897, Lr:0.0001\n",
      "Epoch 30, Step: 143, Loss: 0.04699338227510452, Lr:0.0001\n",
      "Epoch 30, Step: 144, Loss: 0.09099921584129333, Lr:0.0001\n",
      "Epoch 30, Step: 145, Loss: 0.014143472537398338, Lr:0.0001\n",
      "Epoch 30, Step: 146, Loss: 0.0969884842634201, Lr:0.0001\n",
      "Epoch 30, Step: 147, Loss: 0.021650973707437515, Lr:0.0001\n",
      "Epoch 30, Step: 148, Loss: 0.00902750063687563, Lr:0.0001\n",
      "Epoch 30, Step: 149, Loss: 0.0035396411549299955, Lr:0.0001\n",
      "Epoch 30, Step: 150, Loss: 0.12734603881835938, Lr:0.0001\n",
      "Epoch 30, Step: 151, Loss: 0.03121260739862919, Lr:0.0001\n",
      "Epoch 30, Step: 152, Loss: 0.11604423820972443, Lr:0.0001\n",
      "Epoch 30, Step: 153, Loss: 0.023992417380213737, Lr:0.0001\n",
      "Epoch 30, Step: 154, Loss: 0.0748414471745491, Lr:0.0001\n",
      "Epoch 30, Step: 155, Loss: 0.016966870054602623, Lr:0.0001\n",
      "Epoch 30, Step: 156, Loss: 0.0269688218832016, Lr:0.0001\n",
      "Epoch 30, Step: 157, Loss: 0.10939640551805496, Lr:0.0001\n",
      "Epoch 30, Step: 158, Loss: 0.0009010759531520307, Lr:0.0001\n",
      "Epoch 30, Step: 159, Loss: 0.04180484637618065, Lr:0.0001\n",
      "Epoch 30, Step: 160, Loss: 0.014061030931770802, Lr:0.0001\n",
      "Epoch 30, Step: 161, Loss: 0.03236428648233414, Lr:0.0001\n",
      "Epoch 30, Step: 162, Loss: 0.0389055535197258, Lr:0.0001\n",
      "Epoch 30, Step: 163, Loss: 0.017058581113815308, Lr:0.0001\n",
      "Epoch 30, Step: 164, Loss: 0.003942472860217094, Lr:0.0001\n",
      "Epoch 30, Step: 165, Loss: 0.012170123867690563, Lr:0.0001\n",
      "Epoch 30, Step: 166, Loss: 0.012727783992886543, Lr:0.0001\n",
      "Epoch 30, Step: 167, Loss: 0.04263686016201973, Lr:0.0001\n",
      "Epoch 30, Step: 168, Loss: 0.004922444000840187, Lr:0.0001\n",
      "Epoch 30, Step: 169, Loss: 0.0004780555027537048, Lr:0.0001\n",
      "Epoch 30, Step: 170, Loss: 0.10166153311729431, Lr:0.0001\n",
      "Epoch 30, Step: 171, Loss: 0.08175648003816605, Lr:0.0001\n",
      "Epoch 30, Step: 172, Loss: 0.0442689023911953, Lr:0.0001\n",
      "Epoch 30, Step: 173, Loss: 0.0187852643430233, Lr:0.0001\n",
      "Epoch 30, Step: 174, Loss: 0.004137287847697735, Lr:0.0001\n",
      "Epoch 30, Step: 175, Loss: 0.023639723658561707, Lr:0.0001\n",
      "Epoch 30, Step: 176, Loss: 0.11654982715845108, Lr:0.0001\n",
      "Epoch 30, Step: 177, Loss: 0.0027873751241713762, Lr:0.0001\n",
      "Epoch 30, Step: 178, Loss: 0.017524782568216324, Lr:0.0001\n",
      "Epoch 30, Step: 179, Loss: 0.23296429216861725, Lr:0.0001\n",
      "Epoch 30, Step: 180, Loss: 0.21600548923015594, Lr:0.0001\n",
      "Epoch 30, Step: 181, Loss: 0.2125438004732132, Lr:0.0001\n",
      "Epoch 30, Step: 182, Loss: 0.0030787091236561537, Lr:0.0001\n",
      "Epoch 30, Step: 183, Loss: 0.010460111312568188, Lr:0.0001\n",
      "Epoch 30, Step: 184, Loss: 0.006918800994753838, Lr:0.0001\n",
      "Epoch 30, Step: 185, Loss: 0.04633957892656326, Lr:0.0001\n",
      "Epoch 30, Step: 186, Loss: 0.060955535620450974, Lr:0.0001\n",
      "Epoch 30, Step: 187, Loss: 0.09531858563423157, Lr:0.0001\n",
      "Epoch 30, Step: 188, Loss: 0.025098882615566254, Lr:0.0001\n",
      "Epoch 30, Step: 189, Loss: 0.022680826485157013, Lr:0.0001\n",
      "Epoch 30, Step: 190, Loss: 0.21413825452327728, Lr:0.0001\n",
      "Epoch 30, Step: 191, Loss: 0.009538579732179642, Lr:0.0001\n",
      "Epoch 30, Step: 192, Loss: 0.015410348773002625, Lr:0.0001\n",
      "Epoch 30, Step: 193, Loss: 0.018715307116508484, Lr:0.0001\n",
      "Epoch 30, Step: 194, Loss: 0.06401510536670685, Lr:0.0001\n",
      "Epoch 30, Step: 195, Loss: 0.1614188253879547, Lr:0.0001\n",
      "Epoch 30, Step: 196, Loss: 0.008853831328451633, Lr:0.0001\n",
      "Epoch 30, Step: 197, Loss: 0.007288546767085791, Lr:0.0001\n",
      "Epoch 30, Step: 198, Loss: 0.07577047497034073, Lr:0.0001\n",
      "Epoch 30, Step: 199, Loss: 0.0057444279082119465, Lr:0.0001\n",
      "Epoch 30, Step: 200, Loss: 0.10036348551511765, Lr:0.0001\n",
      "Epoch 30, Step: 201, Loss: 0.058672837913036346, Lr:0.0001\n",
      "Epoch 30, Step: 202, Loss: 0.00882352888584137, Lr:0.0001\n",
      "Epoch 30, Step: 203, Loss: 0.037367455661296844, Lr:0.0001\n",
      "Epoch 30, Step: 204, Loss: 0.08759596943855286, Lr:0.0001\n",
      "Epoch 30, Step: 205, Loss: 0.16537372767925262, Lr:0.0001\n",
      "Epoch 30, Step: 206, Loss: 0.025980299338698387, Lr:0.0001\n",
      "Epoch 30, Step: 207, Loss: 0.0935482606291771, Lr:0.0001\n",
      "Epoch 30, Step: 208, Loss: 0.034654777497053146, Lr:0.0001\n",
      "Epoch 30, Step: 209, Loss: 0.007676487788558006, Lr:0.0001\n",
      "Epoch 30, Step: 210, Loss: 0.00497022457420826, Lr:0.0001\n",
      "Epoch 30, Step: 211, Loss: 0.02183951437473297, Lr:0.0001\n",
      "Epoch 30, Step: 212, Loss: 0.010850222781300545, Lr:0.0001\n",
      "Epoch 30, Step: 213, Loss: 0.008873840793967247, Lr:0.0001\n",
      "Epoch 30, Step: 214, Loss: 0.0055427527986466885, Lr:0.0001\n",
      "Epoch 30, Step: 215, Loss: 0.09091589599847794, Lr:0.0001\n",
      "Epoch 30, Step: 216, Loss: 0.009289389476180077, Lr:0.0001\n",
      "Epoch 30, Step: 217, Loss: 0.02199574187397957, Lr:0.0001\n",
      "Epoch 30, Step: 218, Loss: 0.040569890290498734, Lr:0.0001\n",
      "Epoch 30, Step: 219, Loss: 0.09121382981538773, Lr:0.0001\n",
      "Epoch 30, Step: 220, Loss: 0.041689433157444, Lr:0.0001\n",
      "Epoch 30, Step: 221, Loss: 0.0030985150951892138, Lr:0.0001\n",
      "Epoch 30, Step: 222, Loss: 0.012122937478125095, Lr:0.0001\n",
      "Epoch 30, Step: 223, Loss: 0.024802235886454582, Lr:0.0001\n",
      "Epoch 30, Step: 224, Loss: 0.06847488880157471, Lr:0.0001\n",
      "Epoch 30, Step: 225, Loss: 0.27570056915283203, Lr:0.0001\n",
      "Epoch 30, Step: 226, Loss: 0.24128524959087372, Lr:0.0001\n",
      "Epoch 30, Step: 227, Loss: 0.019910242408514023, Lr:0.0001\n",
      "Epoch 30, Step: 228, Loss: 0.02403954416513443, Lr:0.0001\n",
      "Epoch 30, Step: 229, Loss: 0.1480794996023178, Lr:0.0001\n",
      "Epoch 30, Step: 230, Loss: 0.008347328752279282, Lr:0.0001\n",
      "Epoch 30, Step: 231, Loss: 0.0696658343076706, Lr:0.0001\n",
      "Epoch 30, Step: 232, Loss: 0.017029620707035065, Lr:0.0001\n",
      "Epoch 30, Step: 233, Loss: 0.031602222472429276, Lr:0.0001\n",
      "Epoch 30, Step: 234, Loss: 0.011652379296720028, Lr:0.0001\n",
      "Epoch 30, Step: 235, Loss: 0.16180749237537384, Lr:0.0001\n",
      "Epoch 30, Step: 236, Loss: 0.08726031333208084, Lr:0.0001\n",
      "Epoch 30, Step: 237, Loss: 0.0513760969042778, Lr:0.0001\n",
      "Epoch 30, Step: 238, Loss: 0.13285917043685913, Lr:0.0001\n",
      "Epoch 30, Step: 239, Loss: 0.01976904645562172, Lr:0.0001\n",
      "Epoch 30, Step: 240, Loss: 0.06161021441221237, Lr:0.0001\n",
      "Epoch 30, Step: 241, Loss: 0.06530946493148804, Lr:0.0001\n",
      "Epoch 30, Step: 242, Loss: 0.047147613018751144, Lr:0.0001\n",
      "Epoch 30, Step: 243, Loss: 0.0017504002898931503, Lr:0.0001\n",
      "Epoch 30, Step: 244, Loss: 0.030789026990532875, Lr:0.0001\n",
      "Epoch 30, Step: 245, Loss: 0.03725748136639595, Lr:0.0001\n",
      "Epoch 30, Step: 246, Loss: 0.022617045789957047, Lr:0.0001\n",
      "Epoch 30, Step: 247, Loss: 0.09801525622606277, Lr:0.0001\n",
      "Epoch 30, Step: 248, Loss: 0.022305108606815338, Lr:0.0001\n",
      "Epoch 30, Step: 249, Loss: 0.017527639865875244, Lr:0.0001\n",
      "Epoch 30, Step: 250, Loss: 0.03687804564833641, Lr:0.0001\n",
      "Epoch 30, Step: 251, Loss: 0.2708646357059479, Lr:0.0001\n",
      "Epoch 30, Step: 252, Loss: 0.016417507082223892, Lr:0.0001\n",
      "Epoch 30, Step: 253, Loss: 0.007543663494288921, Lr:0.0001\n",
      "Epoch 30, Step: 254, Loss: 0.028213730081915855, Lr:0.0001\n",
      "Epoch 30, Step: 255, Loss: 0.0011605783365666866, Lr:0.0001\n",
      "Epoch 30, Step: 256, Loss: 0.05461793392896652, Lr:0.0001\n",
      "Epoch 30, Step: 257, Loss: 0.01300214696675539, Lr:0.0001\n",
      "Epoch 30, Step: 258, Loss: 0.09374161809682846, Lr:0.0001\n",
      "Epoch 30, Step: 259, Loss: 0.044726282358169556, Lr:0.0001\n",
      "Epoch 30, Step: 260, Loss: 0.6456207633018494, Lr:0.0001\n",
      "Epoch 30, Step: 261, Loss: 0.03421452268958092, Lr:0.0001\n",
      "Epoch 30, Step: 262, Loss: 0.30293452739715576, Lr:0.0001\n",
      "Epoch 30, Step: 263, Loss: 0.06044342368841171, Lr:0.0001\n",
      "Epoch 30, Step: 264, Loss: 0.38846537470817566, Lr:0.0001\n",
      "Epoch 30, Step: 265, Loss: 0.05544601380825043, Lr:0.0001\n",
      "Epoch 30, Step: 266, Loss: 0.00022602023091167212, Lr:0.0001\n",
      "Epoch 30, Step: 267, Loss: 0.00829993560910225, Lr:0.0001\n",
      "Epoch 30, Step: 268, Loss: 0.014840472489595413, Lr:0.0001\n",
      "Epoch 30, Step: 269, Loss: 0.21551193296909332, Lr:0.0001\n",
      "Epoch 30, Step: 270, Loss: 0.05188596993684769, Lr:0.0001\n",
      "Epoch 30, Step: 271, Loss: 0.06621336936950684, Lr:0.0001\n",
      "Epoch 30, Step: 272, Loss: 0.015955010429024696, Lr:0.0001\n",
      "Epoch 30, Step: 273, Loss: 0.01858999952673912, Lr:0.0001\n",
      "Epoch 30, Step: 274, Loss: 0.027265068143606186, Lr:0.0001\n",
      "Epoch 30, Step: 275, Loss: 0.0061015114188194275, Lr:0.0001\n",
      "Epoch 30, Step: 276, Loss: 0.0006310406024567783, Lr:0.0001\n",
      "Epoch 30, Step: 277, Loss: 0.015141497366130352, Lr:0.0001\n",
      "Epoch 30, Step: 278, Loss: 0.03675836697220802, Lr:0.0001\n",
      "Epoch 30, Step: 279, Loss: 0.02477184496819973, Lr:0.0001\n",
      "Epoch 30, Step: 280, Loss: 0.15408605337142944, Lr:0.0001\n",
      "Epoch 30, Step: 281, Loss: 0.08575724810361862, Lr:0.0001\n",
      "Epoch 30, Step: 282, Loss: 0.0054227085784077644, Lr:0.0001\n",
      "Epoch 30, Step: 283, Loss: 0.11084266752004623, Lr:0.0001\n",
      "Epoch 30, Step: 284, Loss: 0.2455725371837616, Lr:0.0001\n",
      "Epoch 30, Step: 285, Loss: 0.03841644152998924, Lr:0.0001\n",
      "Epoch 30, Step: 286, Loss: 0.4517853260040283, Lr:0.0001\n",
      "Epoch 30, Step: 287, Loss: 0.0312536284327507, Lr:0.0001\n",
      "Epoch 30, Step: 288, Loss: 0.014854440465569496, Lr:0.0001\n",
      "Epoch 30, Step: 289, Loss: 0.21699869632720947, Lr:0.0001\n",
      "Epoch 30, Step: 290, Loss: 0.016880802810192108, Lr:0.0001\n",
      "Epoch 30, Step: 291, Loss: 0.0037178616039454937, Lr:0.0001\n",
      "Epoch 30, Step: 292, Loss: 0.00441391859203577, Lr:0.0001\n",
      "Epoch 30, Step: 293, Loss: 0.2562545835971832, Lr:0.0001\n",
      "Epoch 30, Step: 294, Loss: 0.0015824270667508245, Lr:0.0001\n",
      "Epoch 30, Step: 295, Loss: 0.032112568616867065, Lr:0.0001\n",
      "Epoch 30, Step: 296, Loss: 0.02405836619436741, Lr:0.0001\n",
      "Epoch 30, Step: 297, Loss: 0.06607240438461304, Lr:0.0001\n",
      "Epoch 30, Step: 298, Loss: 0.07500192523002625, Lr:0.0001\n",
      "Epoch 30, Step: 299, Loss: 0.13062164187431335, Lr:0.0001\n",
      "Epoch 30, Step: 300, Loss: 0.016256246715784073, Lr:0.0001\n",
      "Epoch 30, Step: 301, Loss: 0.009596260264515877, Lr:0.0001\n",
      "Epoch 30, Step: 302, Loss: 0.012753323651850224, Lr:0.0001\n",
      "Epoch 30, Step: 303, Loss: 0.0062978616915643215, Lr:0.0001\n",
      "Epoch 30, Step: 304, Loss: 0.10207562893629074, Lr:0.0001\n",
      "Epoch 30, Step: 305, Loss: 0.13788193464279175, Lr:0.0001\n",
      "Epoch 30, Step: 306, Loss: 0.11548780649900436, Lr:0.0001\n",
      "Epoch 30, Step: 307, Loss: 0.005791832227259874, Lr:0.0001\n",
      "Epoch 30, Step: 308, Loss: 0.03129342570900917, Lr:0.0001\n",
      "Epoch 30, Step: 309, Loss: 0.011926321312785149, Lr:0.0001\n",
      "Epoch 30, Step: 310, Loss: 0.0033277578186243773, Lr:0.0001\n",
      "Epoch 30, Step: 311, Loss: 0.01517510786652565, Lr:0.0001\n",
      "Epoch 30, Step: 312, Loss: 0.09730052202939987, Lr:0.0001\n",
      "Epoch 30, Step: 313, Loss: 0.04845598712563515, Lr:0.0001\n",
      "Epoch 30, Step: 314, Loss: 0.08948313444852829, Lr:0.0001\n",
      "Epoch 30, Step: 315, Loss: 0.030568303540349007, Lr:0.0001\n",
      "Epoch 30, Step: 316, Loss: 0.007425743620842695, Lr:0.0001\n",
      "Epoch 30, Step: 317, Loss: 0.1231171041727066, Lr:0.0001\n",
      "Epoch 30, Step: 318, Loss: 0.15010744333267212, Lr:0.0001\n",
      "Epoch 30, Step: 319, Loss: 0.011040451005101204, Lr:0.0001\n",
      "Epoch 30, Step: 320, Loss: 0.02087046578526497, Lr:0.0001\n",
      "Epoch 30, Step: 321, Loss: 0.16605834662914276, Lr:0.0001\n",
      "Epoch 30, Step: 322, Loss: 0.0021193295251578093, Lr:0.0001\n",
      "Epoch 30, Step: 323, Loss: 0.13925676047801971, Lr:0.0001\n",
      "Epoch 30, Step: 324, Loss: 0.03089118003845215, Lr:0.0001\n",
      "Epoch 30, Step: 325, Loss: 0.1652911752462387, Lr:0.0001\n",
      "Epoch 30, Step: 326, Loss: 0.024755354970693588, Lr:0.0001\n",
      "Epoch 30, Step: 327, Loss: 0.026481103152036667, Lr:0.0001\n",
      "Epoch 30, Step: 328, Loss: 0.015372242778539658, Lr:0.0001\n",
      "Epoch 30, Step: 329, Loss: 0.0064154393039643764, Lr:0.0001\n",
      "Epoch 30, Step: 330, Loss: 0.0006266377167776227, Lr:0.0001\n",
      "Epoch 30, Step: 331, Loss: 0.02638690546154976, Lr:0.0001\n",
      "Epoch 30, Step: 332, Loss: 0.0032000341452658176, Lr:0.0001\n",
      "Epoch 30, Step: 333, Loss: 0.010715305805206299, Lr:0.0001\n",
      "Epoch 30, Step: 334, Loss: 0.03160916268825531, Lr:0.0001\n",
      "Epoch 30, Step: 335, Loss: 0.03380533307790756, Lr:0.0001\n",
      "Epoch 30, Step: 336, Loss: 0.0062283785082399845, Lr:0.0001\n",
      "Epoch 30, Step: 337, Loss: 0.0109684057533741, Lr:0.0001\n",
      "Epoch 30, Step: 338, Loss: 0.012328900396823883, Lr:0.0001\n",
      "Epoch 30, Step: 339, Loss: 0.005402933806180954, Lr:0.0001\n",
      "Epoch 30, Step: 340, Loss: 0.2197645753622055, Lr:0.0001\n",
      "Epoch 30, Step: 341, Loss: 0.0213017500936985, Lr:0.0001\n",
      "Epoch 30, Step: 342, Loss: 0.04641243815422058, Lr:0.0001\n",
      "Epoch 30, Step: 343, Loss: 0.008076931349933147, Lr:0.0001\n",
      "Epoch 30, Step: 344, Loss: 0.04001917690038681, Lr:0.0001\n",
      "Epoch 30, Step: 345, Loss: 0.036340974271297455, Lr:0.0001\n",
      "Epoch 30, Step: 346, Loss: 0.008179131895303726, Lr:0.0001\n",
      "Epoch 30, Step: 347, Loss: 0.03412365913391113, Lr:0.0001\n",
      "Epoch 30, Step: 348, Loss: 0.008924394845962524, Lr:0.0001\n",
      "Epoch 30, Step: 349, Loss: 0.055100515484809875, Lr:0.0001\n",
      "Epoch 30, Step: 350, Loss: 0.006867199204862118, Lr:0.0001\n",
      "Epoch 30, Step: 351, Loss: 0.04141345992684364, Lr:0.0001\n",
      "Epoch 30, Step: 352, Loss: 0.01568043977022171, Lr:0.0001\n",
      "Epoch 30, Step: 353, Loss: 0.1876000165939331, Lr:0.0001\n",
      "Epoch 30, Step: 354, Loss: 0.2954580783843994, Lr:0.0001\n",
      "Epoch 30, Step: 355, Loss: 0.21662239730358124, Lr:0.0001\n",
      "Epoch 30, Step: 356, Loss: 0.8022245168685913, Lr:0.0001\n",
      "Epoch 30, Step: 357, Loss: 0.0013123919488862157, Lr:0.0001\n",
      "Epoch 30, Step: 358, Loss: 0.021835943683981895, Lr:0.0001\n",
      "Epoch 30, Step: 359, Loss: 0.024739278480410576, Lr:0.0001\n",
      "Epoch 30, Step: 360, Loss: 0.013287477195262909, Lr:0.0001\n",
      "Epoch 30, Step: 361, Loss: 0.006718648597598076, Lr:0.0001\n",
      "Epoch 30, Step: 362, Loss: 0.07365142554044724, Lr:0.0001\n",
      "Epoch 30, Step: 363, Loss: 0.05247907713055611, Lr:0.0001\n",
      "Epoch 30, Step: 364, Loss: 0.21722692251205444, Lr:0.0001\n",
      "Epoch 30, Step: 365, Loss: 0.0733669325709343, Lr:0.0001\n",
      "Epoch 30, Step: 366, Loss: 0.0035054085310548544, Lr:0.0001\n",
      "Epoch 30, Step: 367, Loss: 0.1146673932671547, Lr:0.0001\n",
      "Epoch 30, Step: 368, Loss: 0.013331986032426357, Lr:0.0001\n",
      "Epoch 30, Step: 369, Loss: 0.011651337146759033, Lr:0.0001\n",
      "Epoch 30, Step: 370, Loss: 0.02120707370340824, Lr:0.0001\n",
      "Epoch 30, Step: 371, Loss: 0.005436264909803867, Lr:0.0001\n",
      "Epoch 30, Step: 372, Loss: 0.04099418595433235, Lr:0.0001\n",
      "Epoch 30, Step: 373, Loss: 0.04993640258908272, Lr:0.0001\n",
      "Epoch 30, Step: 374, Loss: 0.003532047150656581, Lr:0.0001\n",
      "Epoch 30, Step: 375, Loss: 0.2175709307193756, Lr:0.0001\n",
      "Epoch 30, Step: 376, Loss: 0.058379463851451874, Lr:0.0001\n",
      "Epoch 30, Step: 377, Loss: 0.05442897602915764, Lr:0.0001\n",
      "Epoch 30, Step: 378, Loss: 0.007991727441549301, Lr:0.0001\n",
      "Epoch 30, Step: 379, Loss: 0.6876469254493713, Lr:0.0001\n",
      "Epoch 30, Step: 380, Loss: 0.018826980143785477, Lr:0.0001\n",
      "Epoch 30, Step: 381, Loss: 0.08141050487756729, Lr:0.0001\n",
      "Epoch 30, Step: 382, Loss: 0.05694074183702469, Lr:0.0001\n",
      "Epoch 30, Step: 383, Loss: 0.008219038136303425, Lr:0.0001\n",
      "Epoch 30, Step: 384, Loss: 0.15105865895748138, Lr:0.0001\n",
      "Epoch 30, Step: 385, Loss: 0.22736655175685883, Lr:0.0001\n",
      "Epoch 30, Step: 386, Loss: 0.01812887378036976, Lr:0.0001\n",
      "Epoch 30, Step: 387, Loss: 0.18083184957504272, Lr:0.0001\n",
      "Epoch 30, Step: 388, Loss: 0.21319228410720825, Lr:0.0001\n",
      "Epoch 30, Step: 389, Loss: 0.3921873867511749, Lr:0.0001\n",
      "Epoch 30, Step: 390, Loss: 0.15424354374408722, Lr:0.0001\n",
      "Epoch 30, Step: 391, Loss: 0.17828933894634247, Lr:0.0001\n",
      "Epoch 30, Step: 392, Loss: 0.0208278875797987, Lr:0.0001\n",
      "Epoch 30, Step: 393, Loss: 0.20875424146652222, Lr:0.0001\n",
      "Epoch 30, Step: 394, Loss: 0.01311427541077137, Lr:0.0001\n",
      "Epoch 30, Step: 395, Loss: 0.0175968948751688, Lr:0.0001\n",
      "Epoch 30, Step: 396, Loss: 0.050183262676000595, Lr:0.0001\n",
      "Epoch 30, Step: 397, Loss: 0.013905029743909836, Lr:0.0001\n",
      "Epoch 30, Step: 398, Loss: 0.0015179471811279655, Lr:0.0001\n",
      "Epoch 30, Step: 399, Loss: 0.023788917809724808, Lr:0.0001\n",
      "Epoch 30, Step: 400, Loss: 0.0018395750084891915, Lr:0.0001\n",
      "Epoch 30, Step: 401, Loss: 0.02746158093214035, Lr:0.0001\n",
      "Epoch 30, Step: 402, Loss: 0.070233054459095, Lr:0.0001\n",
      "Epoch 30, Step: 403, Loss: 0.03403907269239426, Lr:0.0001\n",
      "Epoch 30, Step: 404, Loss: 0.22952565550804138, Lr:0.0001\n",
      "Epoch 30, Step: 405, Loss: 0.1509675234556198, Lr:0.0001\n",
      "Epoch 30, Step: 406, Loss: 0.020795127376914024, Lr:0.0001\n",
      "Epoch 30, Step: 407, Loss: 0.006729143671691418, Lr:0.0001\n",
      "Epoch 30, Step: 408, Loss: 0.001192411407828331, Lr:0.0001\n",
      "Epoch 30, Step: 409, Loss: 0.00944752898067236, Lr:0.0001\n",
      "Epoch 30, Step: 410, Loss: 0.023470979183912277, Lr:0.0001\n",
      "Epoch 30, Step: 411, Loss: 0.155088871717453, Lr:0.0001\n",
      "Epoch 30, Step: 412, Loss: 0.03251807764172554, Lr:0.0001\n",
      "Epoch 30, Step: 413, Loss: 0.05972837656736374, Lr:0.0001\n",
      "Epoch 30, Step: 414, Loss: 0.056766387075185776, Lr:0.0001\n",
      "Epoch 30, Step: 415, Loss: 0.052411243319511414, Lr:0.0001\n",
      "Epoch 30, Step: 416, Loss: 0.0014927429147064686, Lr:0.0001\n",
      "Epoch 30, Step: 417, Loss: 0.017178848385810852, Lr:0.0001\n",
      "Epoch 30, Step: 418, Loss: 0.09686824679374695, Lr:0.0001\n",
      "Epoch 30, Step: 419, Loss: 0.04405141994357109, Lr:0.0001\n",
      "Epoch 30, Step: 420, Loss: 0.10040180385112762, Lr:0.0001\n",
      "Epoch 30, Step: 421, Loss: 0.09986463934183121, Lr:0.0001\n",
      "Epoch 30, Step: 422, Loss: 0.03603459894657135, Lr:0.0001\n",
      "Epoch 30, Step: 423, Loss: 0.006544420495629311, Lr:0.0001\n",
      "Epoch 30, Step: 424, Loss: 0.013020040467381477, Lr:0.0001\n",
      "Epoch 30, Step: 425, Loss: 0.010496890172362328, Lr:0.0001\n",
      "Epoch 30, Step: 426, Loss: 0.023597516119480133, Lr:0.0001\n",
      "Epoch 30, Step: 427, Loss: 0.0060583739541471004, Lr:0.0001\n",
      "Epoch 30, Step: 428, Loss: 0.2332587093114853, Lr:0.0001\n",
      "Epoch 30, Step: 429, Loss: 0.18287353217601776, Lr:0.0001\n",
      "Epoch 30, Step: 430, Loss: 0.014904879964888096, Lr:0.0001\n",
      "Epoch 30, Step: 431, Loss: 0.0025254760403186083, Lr:0.0001\n",
      "Epoch 30, Step: 432, Loss: 0.044285424053668976, Lr:0.0001\n",
      "Epoch 30, Step: 433, Loss: 0.0005686028744094074, Lr:0.0001\n",
      "Epoch 30, Step: 434, Loss: 0.020402295514941216, Lr:0.0001\n",
      "Epoch 30, Step: 435, Loss: 0.010934954509139061, Lr:0.0001\n",
      "Epoch 30, Step: 436, Loss: 0.025454213842749596, Lr:0.0001\n",
      "Epoch 30, Step: 437, Loss: 0.04187818989157677, Lr:0.0001\n",
      "Epoch 30, Step: 438, Loss: 0.0014707735972478986, Lr:0.0001\n",
      "Epoch 30, Step: 439, Loss: 0.03955250233411789, Lr:0.0001\n",
      "Epoch 30, Step: 440, Loss: 0.04904177784919739, Lr:0.0001\n",
      "Epoch 30, Step: 441, Loss: 0.08207802474498749, Lr:0.0001\n",
      "Epoch 30, Step: 442, Loss: 0.021935895085334778, Lr:0.0001\n",
      "Epoch 30, Step: 443, Loss: 0.009967515245079994, Lr:0.0001\n",
      "Epoch 30, Step: 444, Loss: 0.0011216920102015138, Lr:0.0001\n",
      "Epoch 30, Step: 445, Loss: 0.0029450373258441687, Lr:0.0001\n",
      "Epoch 30, Step: 446, Loss: 0.20601773262023926, Lr:0.0001\n",
      "Epoch 30, Step: 447, Loss: 0.1422802060842514, Lr:0.0001\n",
      "Epoch 30, Step: 448, Loss: 0.17465966939926147, Lr:0.0001\n",
      "Epoch 30, Step: 449, Loss: 0.022100776433944702, Lr:0.0001\n",
      "Epoch 30, Step: 450, Loss: 0.042596250772476196, Lr:0.0001\n",
      "Epoch 30, Step: 451, Loss: 0.03465597704052925, Lr:0.0001\n",
      "Epoch 30, Step: 452, Loss: 0.24511797726154327, Lr:0.0001\n",
      "Epoch 30, Step: 453, Loss: 0.2605597674846649, Lr:0.0001\n",
      "Epoch 30, Step: 454, Loss: 0.002536903601139784, Lr:0.0001\n",
      "Epoch 30, Step: 455, Loss: 0.08512736856937408, Lr:0.0001\n",
      "Epoch 30, Step: 456, Loss: 0.006069877650588751, Lr:0.0001\n",
      "Epoch 30, Step: 457, Loss: 0.4541190564632416, Lr:0.0001\n",
      "Epoch 30, Step: 458, Loss: 0.0005744289956055582, Lr:0.0001\n",
      "Epoch 30, Step: 459, Loss: 0.10041641443967819, Lr:0.0001\n",
      "Epoch 30, Step: 460, Loss: 0.1195460706949234, Lr:0.0001\n",
      "Epoch 30, Step: 461, Loss: 0.0063582519069314, Lr:0.0001\n",
      "Epoch 30, Step: 462, Loss: 0.04209507629275322, Lr:0.0001\n",
      "Epoch 30, Step: 463, Loss: 0.015551669523119926, Lr:0.0001\n",
      "Epoch 30, Step: 464, Loss: 0.001773087540641427, Lr:0.0001\n",
      "Epoch 30, Step: 465, Loss: 0.027501318603754044, Lr:0.0001\n",
      "Epoch 30, Step: 466, Loss: 0.011654923669993877, Lr:0.0001\n",
      "Epoch 30, Step: 467, Loss: 0.2789314389228821, Lr:0.0001\n",
      "Epoch 30, Step: 468, Loss: 0.05224841833114624, Lr:0.0001\n",
      "Epoch 30, Step: 469, Loss: 0.0036353985778987408, Lr:0.0001\n",
      "Epoch 30, Step: 470, Loss: 0.004838238470256329, Lr:0.0001\n",
      "Epoch 30, Step: 471, Loss: 0.01334126852452755, Lr:0.0001\n",
      "Epoch 30, Step: 472, Loss: 0.015496842563152313, Lr:0.0001\n",
      "Epoch 30, Step: 473, Loss: 0.03147798776626587, Lr:0.0001\n",
      "Epoch 30, Step: 474, Loss: 0.0451371930539608, Lr:0.0001\n",
      "Epoch 30, Step: 475, Loss: 0.009211944416165352, Lr:0.0001\n",
      "Epoch 30, Step: 476, Loss: 0.03200807049870491, Lr:0.0001\n",
      "Epoch 30, Step: 477, Loss: 0.051689889281988144, Lr:0.0001\n",
      "Epoch 30, Step: 478, Loss: 0.004101868253201246, Lr:0.0001\n",
      "Epoch 30, Step: 479, Loss: 0.1978384256362915, Lr:0.0001\n",
      "Epoch 30, Step: 480, Loss: 0.0024716188199818134, Lr:0.0001\n",
      "Epoch 30, Step: 481, Loss: 0.004398517310619354, Lr:0.0001\n",
      "Epoch 30, Step: 482, Loss: 0.05698871612548828, Lr:0.0001\n",
      "Epoch 30, Step: 483, Loss: 0.33256280422210693, Lr:0.0001\n",
      "Epoch 30, Step: 484, Loss: 0.006929285824298859, Lr:0.0001\n",
      "Epoch 30, Step: 485, Loss: 0.01421415526419878, Lr:0.0001\n",
      "Epoch 30, Step: 486, Loss: 0.11632493883371353, Lr:0.0001\n",
      "Epoch 30, Step: 487, Loss: 0.16312673687934875, Lr:0.0001\n",
      "Epoch 30, Step: 488, Loss: 0.005986450240015984, Lr:0.0001\n",
      "Epoch 30, Step: 489, Loss: 0.001950639532878995, Lr:0.0001\n",
      "Epoch 30, Step: 490, Loss: 0.15255579352378845, Lr:0.0001\n",
      "Epoch 30, Step: 491, Loss: 0.02268126606941223, Lr:0.0001\n",
      "Epoch 30, Step: 492, Loss: 0.0033378901425749063, Lr:0.0001\n",
      "Epoch 30, Step: 493, Loss: 0.037019211798906326, Lr:0.0001\n",
      "Epoch 30, Step: 494, Loss: 0.2644355595111847, Lr:0.0001\n",
      "Epoch 30, Step: 495, Loss: 0.009921936318278313, Lr:0.0001\n",
      "Epoch 30, Step: 496, Loss: 0.06532542407512665, Lr:0.0001\n",
      "Epoch 30, Step: 497, Loss: 0.14024242758750916, Lr:0.0001\n",
      "Epoch 30, Step: 498, Loss: 0.014436565339565277, Lr:0.0001\n",
      "Epoch 30, Step: 499, Loss: 0.014290323480963707, Lr:0.0001\n",
      "Epoch 30, Step: 500, Loss: 0.2316286414861679, Lr:0.0001\n",
      "Epoch 30, Step: 501, Loss: 0.005439612083137035, Lr:0.0001\n",
      "Epoch 30, Step: 502, Loss: 0.009402778930962086, Lr:0.0001\n",
      "Epoch 30, Step: 503, Loss: 0.036263011395931244, Lr:0.0001\n",
      "Epoch 30, Step: 504, Loss: 0.25902482867240906, Lr:0.0001\n",
      "Epoch 30, Step: 505, Loss: 0.0004147615982219577, Lr:0.0001\n",
      "Epoch 30, Step: 506, Loss: 0.0051043774001300335, Lr:0.0001\n",
      "Epoch 30, Step: 507, Loss: 0.032985687255859375, Lr:0.0001\n",
      "Epoch 30, Step: 508, Loss: 0.00895630195736885, Lr:0.0001\n",
      "Epoch 30, Step: 509, Loss: 0.011905252002179623, Lr:0.0001\n",
      "Epoch 30, Step: 510, Loss: 0.015565349720418453, Lr:0.0001\n",
      "Epoch 30, Step: 511, Loss: 0.01106113102287054, Lr:0.0001\n",
      "Epoch 30, Step: 512, Loss: 0.04227864742279053, Lr:0.0001\n",
      "Epoch 30, Step: 513, Loss: 0.08681866526603699, Lr:0.0001\n",
      "Epoch 30, Step: 514, Loss: 0.0915316492319107, Lr:0.0001\n",
      "Epoch 30, Step: 515, Loss: 0.011216659098863602, Lr:0.0001\n",
      "Epoch 30, Step: 516, Loss: 0.11462503671646118, Lr:0.0001\n",
      "Epoch 30, Step: 517, Loss: 0.5273178815841675, Lr:0.0001\n",
      "Epoch 30, Step: 518, Loss: 0.0006316247163340449, Lr:0.0001\n",
      "Epoch 30, Step: 519, Loss: 0.0071352762170135975, Lr:0.0001\n",
      "Epoch 30, Step: 520, Loss: 0.0013024426298215985, Lr:0.0001\n",
      "Epoch 30, Step: 521, Loss: 0.054836586117744446, Lr:0.0001\n",
      "Epoch 30, Step: 522, Loss: 0.024911046028137207, Lr:0.0001\n",
      "Epoch 30, Step: 523, Loss: 0.12450817227363586, Lr:0.0001\n",
      "Epoch 30, Step: 524, Loss: 0.03675809130072594, Lr:0.0001\n",
      "Epoch 30, Step: 525, Loss: 0.044895898550748825, Lr:0.0001\n",
      "Epoch 30, Step: 526, Loss: 0.2309570461511612, Lr:0.0001\n",
      "Epoch 30, Step: 527, Loss: 0.055121034383773804, Lr:0.0001\n",
      "Epoch 30, Step: 528, Loss: 0.01552617084234953, Lr:0.0001\n",
      "Epoch 30, Step: 529, Loss: 0.0014396257465705276, Lr:0.0001\n",
      "Epoch 30, Step: 530, Loss: 0.22893351316452026, Lr:0.0001\n",
      "Epoch 30, Step: 531, Loss: 0.08607222139835358, Lr:0.0001\n",
      "Epoch 30, Step: 532, Loss: 0.02058527246117592, Lr:0.0001\n",
      "Epoch 30, Step: 533, Loss: 0.002562287962064147, Lr:0.0001\n",
      "Epoch 30, Step: 534, Loss: 0.04888072609901428, Lr:0.0001\n",
      "Epoch 30, Step: 535, Loss: 0.07436076551675797, Lr:0.0001\n",
      "Epoch 30, Step: 536, Loss: 0.07368185371160507, Lr:0.0001\n",
      "Epoch 30, Step: 537, Loss: 0.061891715973615646, Lr:0.0001\n",
      "Epoch 30, Step: 538, Loss: 0.16710016131401062, Lr:0.0001\n",
      "Epoch 30, Step: 539, Loss: 0.0146407475695014, Lr:0.0001\n",
      "Epoch 30, Step: 540, Loss: 0.19001363217830658, Lr:0.0001\n",
      "Epoch 30, Step: 541, Loss: 0.01076474692672491, Lr:0.0001\n",
      "Epoch 30, Step: 542, Loss: 0.0009132688865065575, Lr:0.0001\n",
      "Epoch 30, Step: 543, Loss: 0.09614360332489014, Lr:0.0001\n",
      "Epoch 30, Step: 544, Loss: 0.0016245153965428472, Lr:0.0001\n",
      "Epoch 30, Step: 545, Loss: 0.004411838483065367, Lr:0.0001\n",
      "Epoch 30, Step: 546, Loss: 0.03456675261259079, Lr:0.0001\n",
      "Epoch 30, Step: 547, Loss: 0.11486663669347763, Lr:0.0001\n",
      "Epoch 30, Step: 548, Loss: 0.003949016332626343, Lr:0.0001\n",
      "Epoch 30, Step: 549, Loss: 0.049042679369449615, Lr:0.0001\n",
      "Epoch 30, Step: 550, Loss: 0.02220803126692772, Lr:0.0001\n",
      "Epoch 30, Step: 551, Loss: 0.030313830822706223, Lr:0.0001\n",
      "Epoch 30, Step: 552, Loss: 0.24034401774406433, Lr:0.0001\n",
      "Epoch 30, Step: 553, Loss: 0.013591217808425426, Lr:0.0001\n",
      "Epoch 30, Step: 554, Loss: 0.06849303096532822, Lr:0.0001\n",
      "Epoch 30, Step: 555, Loss: 0.09570033848285675, Lr:0.0001\n",
      "Epoch 30, Step: 556, Loss: 0.11826802790164948, Lr:0.0001\n",
      "Epoch 30, Step: 557, Loss: 0.0035998825915157795, Lr:0.0001\n",
      "Epoch 30, Step: 558, Loss: 0.0029866101685911417, Lr:0.0001\n",
      "Epoch 30, Step: 559, Loss: 0.07197164744138718, Lr:0.0001\n",
      "Epoch 30, Step: 560, Loss: 0.043630387634038925, Lr:0.0001\n",
      "Epoch 30, Step: 561, Loss: 0.00366998091340065, Lr:0.0001\n",
      "Epoch 30, Step: 562, Loss: 0.007858376018702984, Lr:0.0001\n",
      "Epoch 30, Step: 563, Loss: 0.0035449531860649586, Lr:0.0001\n",
      "Epoch 30, Step: 564, Loss: 0.04319015145301819, Lr:0.0001\n",
      "Epoch 30, Step: 565, Loss: 0.013271907344460487, Lr:0.0001\n",
      "Epoch 30, Step: 566, Loss: 0.05160056799650192, Lr:0.0001\n",
      "Epoch 30, Step: 567, Loss: 0.06355631351470947, Lr:0.0001\n",
      "Epoch 30, Step: 568, Loss: 0.023418137803673744, Lr:0.0001\n",
      "Epoch 30, Step: 569, Loss: 0.007207067217677832, Lr:0.0001\n",
      "Epoch 30, Step: 570, Loss: 0.05713288486003876, Lr:0.0001\n",
      "Epoch 30, Step: 571, Loss: 0.0025613345205783844, Lr:0.0001\n",
      "Epoch 30, Step: 572, Loss: 0.0018746572313830256, Lr:0.0001\n",
      "Epoch 30, Step: 573, Loss: 0.08778908103704453, Lr:0.0001\n",
      "Epoch 30, Step: 574, Loss: 0.3160058856010437, Lr:0.0001\n",
      "Epoch 30, Step: 575, Loss: 0.03842127323150635, Lr:0.0001\n",
      "Epoch 30, Step: 576, Loss: 0.02156255953013897, Lr:0.0001\n",
      "Epoch 30, Step: 577, Loss: 0.0006683562532998621, Lr:0.0001\n",
      "Epoch 30, Step: 578, Loss: 0.026866015046834946, Lr:0.0001\n",
      "Epoch 30, Step: 579, Loss: 0.008509100414812565, Lr:0.0001\n",
      "Epoch 30, Step: 580, Loss: 0.0002779506321530789, Lr:0.0001\n",
      "Epoch 30, Step: 581, Loss: 0.10243899375200272, Lr:0.0001\n",
      "Epoch 30, Step: 582, Loss: 0.0015323153929784894, Lr:0.0001\n",
      "Epoch 30, Step: 583, Loss: 0.002741757780313492, Lr:0.0001\n",
      "Epoch 30, Step: 584, Loss: 0.011562762781977654, Lr:0.0001\n",
      "Epoch 30, Step: 585, Loss: 0.010473735630512238, Lr:0.0001\n",
      "Epoch 30, Step: 586, Loss: 0.017652146518230438, Lr:0.0001\n",
      "Epoch 30, Step: 587, Loss: 0.007174414582550526, Lr:0.0001\n",
      "Epoch 30, Step: 588, Loss: 0.019874179735779762, Lr:0.0001\n",
      "Epoch 30, Step: 589, Loss: 0.004041094798594713, Lr:0.0001\n",
      "Epoch 30, Step: 590, Loss: 0.0010477364994585514, Lr:0.0001\n",
      "Epoch 30, Step: 591, Loss: 0.018595468252897263, Lr:0.0001\n",
      "Epoch 30, Step: 592, Loss: 0.09748026728630066, Lr:0.0001\n",
      "Epoch 30, Step: 593, Loss: 0.08729181438684464, Lr:0.0001\n",
      "Epoch 30, Step: 594, Loss: 0.10514432936906815, Lr:0.0001\n",
      "Epoch 30, Step: 595, Loss: 0.028348499909043312, Lr:0.0001\n",
      "Epoch 30, Step: 596, Loss: 0.0006014054524712265, Lr:0.0001\n",
      "Epoch 30, Step: 597, Loss: 0.010240030474960804, Lr:0.0001\n",
      "Epoch 30, Step: 598, Loss: 0.10229218006134033, Lr:0.0001\n",
      "Epoch 30, Step: 599, Loss: 0.01261570118367672, Lr:0.0001\n",
      "Epoch 30, Step: 600, Loss: 0.006576609797775745, Lr:0.0001\n",
      "Epoch 30, Step: 601, Loss: 0.16191288828849792, Lr:0.0001\n",
      "Epoch 30, Step: 602, Loss: 0.08993516117334366, Lr:0.0001\n",
      "Epoch 30, Step: 603, Loss: 0.002117625204846263, Lr:0.0001\n",
      "Epoch 30, Step: 604, Loss: 0.0037115546874701977, Lr:0.0001\n",
      "Epoch 30, Step: 605, Loss: 0.07426226884126663, Lr:0.0001\n",
      "Epoch 30, Step: 606, Loss: 0.013143457472324371, Lr:0.0001\n",
      "Epoch 30, Step: 607, Loss: 0.01764131523668766, Lr:0.0001\n",
      "Epoch 30, Step: 608, Loss: 0.00032361195189878345, Lr:0.0001\n",
      "Epoch 30, Step: 609, Loss: 0.05400369316339493, Lr:0.0001\n",
      "Epoch 30, Step: 610, Loss: 0.026637623086571693, Lr:0.0001\n",
      "Epoch 30, Step: 611, Loss: 0.0006650122813880444, Lr:0.0001\n",
      "Epoch 30, Step: 612, Loss: 0.0017866105772554874, Lr:0.0001\n",
      "Epoch 30, Step: 613, Loss: 0.052889905869960785, Lr:0.0001\n",
      "Epoch 30, Step: 614, Loss: 0.012601077556610107, Lr:0.0001\n",
      "Epoch 30, Step: 615, Loss: 0.0013291904469951987, Lr:0.0001\n",
      "Epoch 30, Step: 616, Loss: 0.03696957975625992, Lr:0.0001\n",
      "Epoch 30, Step: 617, Loss: 0.07152364403009415, Lr:0.0001\n",
      "Epoch 30, Step: 618, Loss: 0.009851519949734211, Lr:0.0001\n",
      "Epoch 30, Step: 619, Loss: 0.004923562053591013, Lr:0.0001\n",
      "Epoch 30, Step: 620, Loss: 0.0011442836839705706, Lr:0.0001\n",
      "Epoch 30, Step: 621, Loss: 0.007084842771291733, Lr:0.0001\n",
      "Epoch 30, Step: 622, Loss: 0.016808027401566505, Lr:0.0001\n",
      "Epoch 30, Step: 623, Loss: 0.05033080279827118, Lr:0.0001\n",
      "Epoch 30, Step: 624, Loss: 0.1857527792453766, Lr:0.0001\n",
      "Epoch 30, Step: 625, Loss: 0.024277735501527786, Lr:0.0001\n",
      "Epoch 30, Step: 626, Loss: 0.003499129554256797, Lr:0.0001\n",
      "Epoch 30, Step: 627, Loss: 0.010594043880701065, Lr:0.0001\n",
      "Epoch 30, Step: 628, Loss: 0.15970174968242645, Lr:0.0001\n",
      "Epoch 30, Step: 629, Loss: 0.13050462305545807, Lr:0.0001\n",
      "Epoch 30, Step: 630, Loss: 0.1120598316192627, Lr:0.0001\n",
      "Epoch 30, Step: 631, Loss: 0.024682871997356415, Lr:0.0001\n",
      "Epoch 30, Step: 632, Loss: 0.02170746773481369, Lr:0.0001\n",
      "Epoch 30, Step: 633, Loss: 0.007256672717630863, Lr:0.0001\n",
      "Epoch 30, Step: 634, Loss: 0.0011389589635655284, Lr:0.0001\n",
      "Epoch 30, Step: 635, Loss: 0.047269921749830246, Lr:0.0001\n",
      "Epoch 30, Step: 636, Loss: 0.16094501316547394, Lr:0.0001\n",
      "Epoch 30, Step: 637, Loss: 0.025139573961496353, Lr:0.0001\n",
      "Epoch 30, Step: 638, Loss: 0.001320132170803845, Lr:0.0001\n",
      "Epoch 30, Step: 639, Loss: 0.006516885012388229, Lr:0.0001\n",
      "Epoch 30, Step: 640, Loss: 0.0018870497588068247, Lr:0.0001\n",
      "Epoch 30, Step: 641, Loss: 0.008845599368214607, Lr:0.0001\n",
      "Epoch 30, Step: 642, Loss: 0.3564131259918213, Lr:0.0001\n",
      "Epoch 30, Step: 643, Loss: 0.00602720258757472, Lr:0.0001\n",
      "Epoch 30, Step: 644, Loss: 0.023589514195919037, Lr:0.0001\n",
      "Epoch 30, Step: 645, Loss: 0.29884928464889526, Lr:0.0001\n",
      "Epoch 30, Step: 646, Loss: 0.04322481155395508, Lr:0.0001\n",
      "Epoch 30, Step: 647, Loss: 0.0020849681459367275, Lr:0.0001\n",
      "Epoch 30, Step: 648, Loss: 0.015149676240980625, Lr:0.0001\n",
      "Epoch 30, Step: 649, Loss: 0.0046505555510520935, Lr:0.0001\n",
      "Epoch 30, Step: 650, Loss: 0.05885857343673706, Lr:0.0001\n",
      "Epoch 30, Step: 651, Loss: 0.12888187170028687, Lr:0.0001\n",
      "Epoch 30, Step: 652, Loss: 0.014493921771645546, Lr:0.0001\n",
      "Epoch 30, Step: 653, Loss: 0.009673917666077614, Lr:0.0001\n",
      "Epoch 30, Step: 654, Loss: 0.10899175703525543, Lr:0.0001\n",
      "Epoch 30, Step: 655, Loss: 0.001814412185922265, Lr:0.0001\n",
      "Epoch 30, Step: 656, Loss: 0.04815048724412918, Lr:0.0001\n",
      "Epoch 30, Step: 657, Loss: 0.0027318440843373537, Lr:0.0001\n",
      "Epoch 30, Step: 658, Loss: 0.03713308274745941, Lr:0.0001\n",
      "Epoch 30, Step: 659, Loss: 0.02417655475437641, Lr:0.0001\n",
      "Epoch 30, Step: 660, Loss: 0.039608441293239594, Lr:0.0001\n",
      "Epoch 30, Step: 661, Loss: 0.0686231330037117, Lr:0.0001\n",
      "Epoch 30, Step: 662, Loss: 0.05404143035411835, Lr:0.0001\n",
      "Epoch 30, Step: 663, Loss: 0.1702461689710617, Lr:0.0001\n",
      "Epoch 30, Step: 664, Loss: 0.018427079543471336, Lr:0.0001\n",
      "Epoch 30, Step: 665, Loss: 0.07907826453447342, Lr:0.0001\n",
      "Epoch 30, Step: 666, Loss: 0.0200111772865057, Lr:0.0001\n",
      "Epoch 30, Step: 667, Loss: 0.015363350510597229, Lr:0.0001\n",
      "Epoch 30, Step: 668, Loss: 0.002506452379748225, Lr:0.0001\n",
      "Epoch 30, Step: 669, Loss: 0.005301648285239935, Lr:0.0001\n",
      "Epoch 30, Step: 670, Loss: 0.024834144860506058, Lr:0.0001\n",
      "Epoch 30, Step: 671, Loss: 0.0027723233215510845, Lr:0.0001\n",
      "Epoch 30, Step: 672, Loss: 0.10464362800121307, Lr:0.0001\n",
      "Epoch 30, Step: 673, Loss: 0.0246906541287899, Lr:0.0001\n",
      "Epoch 30, Step: 674, Loss: 0.05407830700278282, Lr:0.0001\n",
      "Epoch 30, Step: 675, Loss: 0.03376176953315735, Lr:0.0001\n",
      "Epoch 30, Step: 676, Loss: 0.023241303861141205, Lr:0.0001\n",
      "Epoch 30, Step: 677, Loss: 0.036745283752679825, Lr:0.0001\n",
      "Epoch 30, Step: 678, Loss: 0.018147042021155357, Lr:0.0001\n",
      "Epoch 30, Step: 679, Loss: 0.012193020433187485, Lr:0.0001\n",
      "Epoch 30, Step: 680, Loss: 0.0061819180846214294, Lr:0.0001\n",
      "Epoch 30, Step: 681, Loss: 0.003608913626521826, Lr:0.0001\n",
      "Epoch 30, Step: 682, Loss: 0.014009667560458183, Lr:0.0001\n",
      "Epoch 30, Step: 683, Loss: 0.0007795493584126234, Lr:0.0001\n",
      "Epoch 30, Step: 684, Loss: 0.0028680015821009874, Lr:0.0001\n",
      "Epoch 30, Step: 685, Loss: 0.0005343038938008249, Lr:0.0001\n",
      "Epoch 30, Step: 686, Loss: 0.1220383569598198, Lr:0.0001\n",
      "Epoch 30, Step: 687, Loss: 0.10767973959445953, Lr:0.0001\n",
      "Epoch 30, Step: 688, Loss: 0.01491348072886467, Lr:0.0001\n",
      "Epoch 30, Step: 689, Loss: 0.010942447930574417, Lr:0.0001\n",
      "Epoch 30, Step: 690, Loss: 0.0027377111837267876, Lr:0.0001\n",
      "Epoch 30, Step: 691, Loss: 0.025316402316093445, Lr:0.0001\n",
      "Epoch 30, Step: 692, Loss: 0.004018999636173248, Lr:0.0001\n",
      "Epoch 30, Step: 693, Loss: 0.04898354411125183, Lr:0.0001\n",
      "Epoch 30, Step: 694, Loss: 0.0759362280368805, Lr:0.0001\n",
      "Epoch 30, Step: 695, Loss: 0.1454501450061798, Lr:0.0001\n",
      "Epoch 30, Step: 696, Loss: 0.0015588898677378893, Lr:0.0001\n",
      "Epoch 30, Step: 697, Loss: 0.06474480032920837, Lr:0.0001\n",
      "Epoch 30, Step: 698, Loss: 0.0014809264102950692, Lr:0.0001\n",
      "Epoch 30, Step: 699, Loss: 0.012177911587059498, Lr:0.0001\n",
      "Epoch 30, Step: 700, Loss: 0.0019348874920979142, Lr:0.0001\n",
      "Epoch 30, Step: 701, Loss: 0.003455181373283267, Lr:0.0001\n",
      "Epoch 30, Step: 702, Loss: 0.06370116025209427, Lr:0.0001\n",
      "Epoch 30, Step: 703, Loss: 0.07062775641679764, Lr:0.0001\n",
      "Epoch 30, Step: 704, Loss: 0.009826872497797012, Lr:0.0001\n",
      "Epoch 30, Step: 705, Loss: 0.0006390936323441565, Lr:0.0001\n",
      "Epoch 30, Step: 706, Loss: 0.03462708741426468, Lr:0.0001\n",
      "Epoch 30, Step: 707, Loss: 0.12106603384017944, Lr:0.0001\n",
      "Epoch 30, Step: 708, Loss: 0.12454205751419067, Lr:0.0001\n",
      "Epoch 30, Step: 709, Loss: 0.18639498949050903, Lr:0.0001\n",
      "Epoch 30, Step: 710, Loss: 0.002539640525355935, Lr:0.0001\n",
      "Epoch 30, Step: 711, Loss: 0.08881310373544693, Lr:0.0001\n",
      "Epoch 30, Step: 712, Loss: 0.23089607059955597, Lr:0.0001\n",
      "Epoch 30, Step: 713, Loss: 0.060772985219955444, Lr:0.0001\n",
      "Epoch 30, Step: 714, Loss: 0.0028487953823059797, Lr:0.0001\n",
      "Epoch 30, Step: 715, Loss: 0.002041278872638941, Lr:0.0001\n",
      "Epoch 30, Step: 716, Loss: 0.04113205149769783, Lr:0.0001\n",
      "Epoch 30, Step: 717, Loss: 0.09859541803598404, Lr:0.0001\n",
      "Epoch 30, Step: 718, Loss: 0.036883395165205, Lr:0.0001\n",
      "Epoch 30, Step: 719, Loss: 0.12913016974925995, Lr:0.0001\n",
      "Epoch 30, Step: 720, Loss: 0.007389329373836517, Lr:0.0001\n",
      "Epoch 30, Step: 721, Loss: 0.03421245142817497, Lr:0.0001\n",
      "Epoch 30, Step: 722, Loss: 0.01282012090086937, Lr:0.0001\n",
      "Epoch 30, Step: 723, Loss: 0.2878871560096741, Lr:0.0001\n",
      "Epoch 30, Step: 724, Loss: 0.009041966870427132, Lr:0.0001\n",
      "Epoch 30, Step: 725, Loss: 0.020246531814336777, Lr:0.0001\n",
      "Epoch 30, Step: 726, Loss: 0.10046945512294769, Lr:0.0001\n",
      "Epoch 30, Step: 727, Loss: 0.2168421745300293, Lr:0.0001\n",
      "Epoch 30, Step: 728, Loss: 0.010359151288866997, Lr:0.0001\n",
      "Epoch 30, Step: 729, Loss: 0.10470884293317795, Lr:0.0001\n",
      "Epoch 30, Step: 730, Loss: 0.01732170581817627, Lr:0.0001\n",
      "Epoch 30, Step: 731, Loss: 0.012085840106010437, Lr:0.0001\n",
      "Epoch 30, Step: 732, Loss: 0.36866259574890137, Lr:0.0001\n",
      "Epoch 30, Step: 733, Loss: 0.004651016555726528, Lr:0.0001\n",
      "Epoch 30, Step: 734, Loss: 0.01296441163867712, Lr:0.0001\n",
      "Epoch 30, Step: 735, Loss: 0.031963691115379333, Lr:0.0001\n",
      "Epoch 30, Step: 736, Loss: 0.0034738958347588778, Lr:0.0001\n",
      "Epoch 30, Step: 737, Loss: 0.0009043319732882082, Lr:0.0001\n",
      "Epoch 30, Step: 738, Loss: 0.16363778710365295, Lr:0.0001\n",
      "Epoch 30, Step: 739, Loss: 0.006434280425310135, Lr:0.0001\n",
      "Epoch 30, Step: 740, Loss: 0.0011783576337620616, Lr:0.0001\n",
      "Epoch 30, Step: 741, Loss: 0.03276786208152771, Lr:0.0001\n",
      "Epoch 30, Step: 742, Loss: 0.013365338556468487, Lr:0.0001\n",
      "Epoch 30, Step: 743, Loss: 0.16089124977588654, Lr:0.0001\n",
      "Epoch 30, Step: 744, Loss: 0.03315800055861473, Lr:0.0001\n",
      "Epoch 30, Step: 745, Loss: 0.0891697034239769, Lr:0.0001\n",
      "Epoch 30, Step: 746, Loss: 0.036052245646715164, Lr:0.0001\n",
      "Epoch 30, Step: 747, Loss: 0.34430113434791565, Lr:0.0001\n",
      "Epoch 30, Step: 748, Loss: 0.009753020480275154, Lr:0.0001\n",
      "Epoch 30, Step: 749, Loss: 0.03729116544127464, Lr:0.0001\n",
      "Epoch 30, Step: 750, Loss: 0.23890896141529083, Lr:0.0001\n",
      "Epoch 30, Step: 751, Loss: 0.05309265851974487, Lr:0.0001\n",
      "Epoch 30, Step: 752, Loss: 0.020430129021406174, Lr:0.0001\n",
      "Epoch 30, Step: 753, Loss: 0.08109176158905029, Lr:0.0001\n",
      "Epoch 30, Step: 754, Loss: 0.0034662901889532804, Lr:0.0001\n",
      "Epoch 30, Step: 755, Loss: 0.134321391582489, Lr:0.0001\n",
      "Epoch 30, Step: 756, Loss: 0.007364058401435614, Lr:0.0001\n",
      "Epoch 30, Step: 757, Loss: 0.018171945586800575, Lr:0.0001\n",
      "Epoch 30, Step: 758, Loss: 0.010074295103549957, Lr:0.0001\n",
      "Epoch 30, Step: 759, Loss: 0.054615817964076996, Lr:0.0001\n",
      "Epoch 30, Step: 760, Loss: 0.03297973424196243, Lr:0.0001\n",
      "Epoch 30, Step: 761, Loss: 0.00435491232201457, Lr:0.0001\n",
      "Epoch 30, Step: 762, Loss: 0.20739564299583435, Lr:0.0001\n",
      "Epoch 30, Step: 763, Loss: 0.2136235386133194, Lr:0.0001\n",
      "Epoch 30, Step: 764, Loss: 0.09765098989009857, Lr:0.0001\n",
      "Epoch 30, Step: 765, Loss: 0.039346687495708466, Lr:0.0001\n",
      "Epoch 30, Step: 766, Loss: 0.0667848140001297, Lr:0.0001\n",
      "Epoch 30, Step: 767, Loss: 0.10937781631946564, Lr:0.0001\n",
      "Epoch 30, Step: 768, Loss: 0.2963052988052368, Lr:0.0001\n",
      "Epoch 30, Step: 769, Loss: 0.02431621216237545, Lr:0.0001\n",
      "Epoch 30, Step: 770, Loss: 0.2571592628955841, Lr:0.0001\n",
      "Epoch 30, Step: 771, Loss: 0.007465022150427103, Lr:0.0001\n",
      "Epoch 30, Step: 772, Loss: 0.14603975415229797, Lr:0.0001\n",
      "Epoch 30, Step: 773, Loss: 0.04616424813866615, Lr:0.0001\n",
      "Epoch 30, Step: 774, Loss: 0.36853933334350586, Lr:0.0001\n",
      "Epoch 30, Step: 775, Loss: 0.0010391018586233258, Lr:0.0001\n",
      "Epoch 30, Step: 776, Loss: 0.05739276856184006, Lr:0.0001\n",
      "Epoch 30, Step: 777, Loss: 0.006358553189784288, Lr:0.0001\n",
      "Epoch 30, Step: 778, Loss: 0.06407003104686737, Lr:0.0001\n",
      "Epoch 30, Step: 779, Loss: 0.024960964918136597, Lr:0.0001\n",
      "Epoch 30, Step: 780, Loss: 0.038749389350414276, Lr:0.0001\n",
      "Epoch 30, Step: 781, Loss: 0.07641465961933136, Lr:0.0001\n",
      "Epoch 30, Step: 782, Loss: 0.020788142457604408, Lr:0.0001\n",
      "Epoch 30, Step: 783, Loss: 0.02043088711798191, Lr:0.0001\n",
      "Epoch 30, Step: 784, Loss: 0.07895588874816895, Lr:0.0001\n",
      "Epoch 30, Step: 785, Loss: 0.026582079008221626, Lr:0.0001\n",
      "Epoch 30, Step: 786, Loss: 0.019898422062397003, Lr:0.0001\n",
      "Epoch 30, Step: 787, Loss: 0.003497257363051176, Lr:0.0001\n",
      "Epoch 30, Step: 788, Loss: 0.0309199970215559, Lr:0.0001\n",
      "Epoch 30, Step: 789, Loss: 0.007781147491186857, Lr:0.0001\n",
      "Epoch 30, Step: 790, Loss: 0.010179073549807072, Lr:0.0001\n",
      "Epoch 30, Step: 791, Loss: 0.012144342064857483, Lr:0.0001\n",
      "Epoch 30, Step: 792, Loss: 0.045676156878471375, Lr:0.0001\n",
      "Epoch 30, Step: 793, Loss: 0.020135559141635895, Lr:0.0001\n",
      "Epoch 30, Step: 794, Loss: 0.0024101813323795795, Lr:0.0001\n",
      "Epoch 30, Step: 795, Loss: 0.06879236549139023, Lr:0.0001\n",
      "Epoch 30, Step: 796, Loss: 0.01966550387442112, Lr:0.0001\n",
      "Epoch 30, Step: 797, Loss: 0.03478148952126503, Lr:0.0001\n",
      "Epoch 30, Step: 798, Loss: 0.0829664021730423, Lr:0.0001\n",
      "Epoch 30, Step: 799, Loss: 0.0956750139594078, Lr:0.0001\n",
      "Epoch 30, Step: 800, Loss: 0.025068260729312897, Lr:0.0001\n",
      "Epoch 30, Step: 801, Loss: 0.023941118270158768, Lr:0.0001\n",
      "Epoch 30, Step: 802, Loss: 0.0965653508901596, Lr:0.0001\n",
      "Epoch 30, Step: 803, Loss: 0.02778189815580845, Lr:0.0001\n",
      "Epoch 30, Step: 804, Loss: 0.002888750284910202, Lr:0.0001\n",
      "Epoch 30, Step: 805, Loss: 0.007982248440384865, Lr:0.0001\n",
      "Epoch 30, Step: 806, Loss: 0.010578902438282967, Lr:0.0001\n",
      "Epoch 30, Step: 807, Loss: 0.20114228129386902, Lr:0.0001\n",
      "Epoch 30, Step: 808, Loss: 0.03762298449873924, Lr:0.0001\n",
      "Epoch 30, Step: 809, Loss: 0.01796158403158188, Lr:0.0001\n",
      "Epoch 30, Step: 810, Loss: 0.009368627332150936, Lr:0.0001\n",
      "Epoch 30, Step: 811, Loss: 0.01140266191214323, Lr:0.0001\n",
      "Epoch 30, Step: 812, Loss: 0.002440287498757243, Lr:0.0001\n",
      "Epoch 30, Step: 813, Loss: 0.0018383337883278728, Lr:0.0001\n",
      "Epoch 30, Step: 814, Loss: 0.11358123272657394, Lr:0.0001\n",
      "Epoch 30, Step: 815, Loss: 0.10014265030622482, Lr:0.0001\n",
      "Epoch 30, Step: 816, Loss: 0.007727024145424366, Lr:0.0001\n",
      "Epoch 30, Step: 817, Loss: 0.015231495723128319, Lr:0.0001\n",
      "Epoch 30, Step: 818, Loss: 0.00052380480337888, Lr:0.0001\n",
      "Epoch 30, Step: 819, Loss: 0.025596775114536285, Lr:0.0001\n",
      "Epoch 30, Step: 820, Loss: 0.00047964457189664245, Lr:0.0001\n",
      "Epoch 30, Step: 821, Loss: 0.07427674531936646, Lr:0.0001\n",
      "Epoch 30, Step: 822, Loss: 0.18408682942390442, Lr:0.0001\n",
      "Epoch 30, Step: 823, Loss: 0.08762925118207932, Lr:0.0001\n",
      "Epoch 30, Step: 824, Loss: 0.2838098704814911, Lr:0.0001\n",
      "Epoch 30, Step: 825, Loss: 0.038438357412815094, Lr:0.0001\n",
      "Epoch 30, Step: 826, Loss: 0.001715879188850522, Lr:0.0001\n",
      "Epoch 30, Step: 827, Loss: 0.030906841158866882, Lr:0.0001\n",
      "Epoch 30, Step: 828, Loss: 0.32651814818382263, Lr:0.0001\n",
      "Epoch 30, Step: 829, Loss: 0.01679639331996441, Lr:0.0001\n",
      "Epoch 30, Step: 830, Loss: 0.006161270197480917, Lr:0.0001\n",
      "Epoch 30, Step: 831, Loss: 0.04457790404558182, Lr:0.0001\n",
      "Epoch 30, Step: 832, Loss: 0.04852540045976639, Lr:0.0001\n",
      "Epoch 30, Step: 833, Loss: 0.009429046884179115, Lr:0.0001\n",
      "Epoch 30, Step: 834, Loss: 0.018055882304906845, Lr:0.0001\n",
      "Epoch 30, Step: 835, Loss: 0.03114737942814827, Lr:0.0001\n",
      "Epoch 30, Step: 836, Loss: 0.0036647592205554247, Lr:0.0001\n",
      "Epoch 30, Step: 837, Loss: 0.012772105634212494, Lr:0.0001\n",
      "Epoch 30, Step: 838, Loss: 0.34042036533355713, Lr:0.0001\n",
      "Epoch 30, Step: 839, Loss: 0.009123957715928555, Lr:0.0001\n",
      "Epoch 30, Step: 840, Loss: 0.005149334203451872, Lr:0.0001\n",
      "Epoch 30, Step: 841, Loss: 0.006650340743362904, Lr:0.0001\n",
      "Epoch 30, Step: 842, Loss: 0.09704455733299255, Lr:0.0001\n",
      "Epoch 30, Step: 843, Loss: 0.0012309863232076168, Lr:0.0001\n",
      "Epoch 30, Step: 844, Loss: 0.08936852961778641, Lr:0.0001\n",
      "Epoch 30, Step: 845, Loss: 0.0014966436428949237, Lr:0.0001\n",
      "Epoch 30, Step: 846, Loss: 0.3303888440132141, Lr:0.0001\n",
      "Epoch 30, Step: 847, Loss: 0.0022777915000915527, Lr:0.0001\n",
      "Epoch 30, Step: 848, Loss: 0.02205059304833412, Lr:0.0001\n",
      "Epoch 30, Step: 849, Loss: 0.23596814274787903, Lr:0.0001\n",
      "Epoch 30, Step: 850, Loss: 0.04970698058605194, Lr:0.0001\n",
      "Epoch 30, Step: 851, Loss: 0.21762388944625854, Lr:0.0001\n",
      "Epoch 30, Step: 852, Loss: 0.07514587044715881, Lr:0.0001\n",
      "Epoch 30, Step: 853, Loss: 0.0397825725376606, Lr:0.0001\n",
      "Epoch 30, Step: 854, Loss: 0.06594841182231903, Lr:0.0001\n",
      "Epoch 30, Step: 855, Loss: 0.10783790051937103, Lr:0.0001\n",
      "Epoch 30, Step: 856, Loss: 0.020466148853302002, Lr:0.0001\n",
      "Epoch 30, Step: 857, Loss: 0.11190097779035568, Lr:0.0001\n",
      "Epoch 30, Step: 858, Loss: 0.004425750579684973, Lr:0.0001\n",
      "Epoch 30, Step: 859, Loss: 0.03832598775625229, Lr:0.0001\n",
      "Epoch 30, Step: 860, Loss: 0.02392026223242283, Lr:0.0001\n",
      "Epoch 30, Step: 861, Loss: 0.06807496398687363, Lr:0.0001\n",
      "Epoch 30, Step: 862, Loss: 0.15343569219112396, Lr:0.0001\n",
      "Epoch 30, Step: 863, Loss: 0.029921328648924828, Lr:0.0001\n",
      "Epoch 30, Step: 864, Loss: 0.010845365934073925, Lr:0.0001\n",
      "Epoch 30, Step: 865, Loss: 0.02315455675125122, Lr:0.0001\n",
      "Epoch 30, Step: 866, Loss: 0.23528465628623962, Lr:0.0001\n",
      "Epoch 30, Step: 867, Loss: 0.01412985846400261, Lr:0.0001\n",
      "Epoch 30, Step: 868, Loss: 0.0037075565196573734, Lr:0.0001\n",
      "Epoch 30, Step: 869, Loss: 0.1589643657207489, Lr:0.0001\n",
      "Epoch 30, Step: 870, Loss: 0.008211608976125717, Lr:0.0001\n",
      "Epoch 30, Step: 871, Loss: 0.2766084671020508, Lr:0.0001\n",
      "Epoch 30, Step: 872, Loss: 0.02416856214404106, Lr:0.0001\n",
      "Epoch 30, Step: 873, Loss: 0.0011026444844901562, Lr:0.0001\n",
      "Epoch 30, Step: 874, Loss: 0.023420268669724464, Lr:0.0001\n",
      "Epoch 30, Step: 875, Loss: 0.0641913041472435, Lr:0.0001\n",
      "Epoch 30, Step: 876, Loss: 0.0842684730887413, Lr:0.0001\n",
      "Epoch 30, Step: 877, Loss: 0.11326432228088379, Lr:0.0001\n",
      "Epoch 30, Step: 878, Loss: 0.012640725821256638, Lr:0.0001\n",
      "Epoch 30, Step: 879, Loss: 0.036884382367134094, Lr:0.0001\n",
      "Epoch 30, Step: 880, Loss: 0.00316749420017004, Lr:0.0001\n",
      "Epoch 30, Step: 881, Loss: 0.0030106916092336178, Lr:0.0001\n",
      "Epoch 30, Step: 882, Loss: 0.22495536506175995, Lr:0.0001\n",
      "Epoch 30, Step: 883, Loss: 0.03033965267241001, Lr:0.0001\n",
      "Epoch 30, Step: 884, Loss: 0.025185104459524155, Lr:0.0001\n",
      "Epoch 30, Step: 885, Loss: 0.019118603318929672, Lr:0.0001\n",
      "Epoch 30, Step: 886, Loss: 0.046350639313459396, Lr:0.0001\n",
      "Epoch 30, Step: 887, Loss: 0.19324959814548492, Lr:0.0001\n",
      "Epoch 30, Step: 888, Loss: 0.02067025564610958, Lr:0.0001\n",
      "Epoch 30, Step: 889, Loss: 0.007866001687943935, Lr:0.0001\n",
      "Epoch 30, Step: 890, Loss: 0.13572686910629272, Lr:0.0001\n",
      "Epoch 30, Step: 891, Loss: 0.08018074929714203, Lr:0.0001\n",
      "Epoch 30, Step: 892, Loss: 0.08702777326107025, Lr:0.0001\n",
      "Epoch 30, Step: 893, Loss: 0.11513539403676987, Lr:0.0001\n",
      "Epoch 30, Step: 894, Loss: 0.018124110996723175, Lr:0.0001\n",
      "Epoch 30, Step: 895, Loss: 0.010075180791318417, Lr:0.0001\n",
      "Epoch 30, Step: 896, Loss: 0.0016914138104766607, Lr:0.0001\n",
      "Epoch 30, Step: 897, Loss: 0.004314502235502005, Lr:0.0001\n",
      "Epoch 30, Step: 898, Loss: 0.025053633376955986, Lr:0.0001\n",
      "Epoch 30, Step: 899, Loss: 0.01741090603172779, Lr:0.0001\n",
      "Epoch 30, Step: 900, Loss: 0.06646610051393509, Lr:0.0001\n",
      "Epoch 30, Step: 901, Loss: 0.07950431853532791, Lr:0.0001\n",
      "Epoch 30, Step: 902, Loss: 0.015632981434464455, Lr:0.0001\n",
      "Epoch 30, Step: 903, Loss: 0.4305115342140198, Lr:0.0001\n",
      "Epoch 30, Step: 904, Loss: 0.013393715023994446, Lr:0.0001\n",
      "Epoch 30, Step: 905, Loss: 0.06996870040893555, Lr:0.0001\n",
      "Epoch 30, Step: 906, Loss: 0.04776112735271454, Lr:0.0001\n",
      "Epoch 30, Step: 907, Loss: 0.17337971925735474, Lr:0.0001\n",
      "Epoch 30, Step: 908, Loss: 0.13068394362926483, Lr:0.0001\n",
      "Epoch 30, Step: 909, Loss: 0.1720573604106903, Lr:0.0001\n",
      "Epoch 30, Step: 910, Loss: 0.13401389122009277, Lr:0.0001\n",
      "Epoch 30, Step: 911, Loss: 0.0031599507201462984, Lr:0.0001\n",
      "Epoch 30, Step: 912, Loss: 0.05952991917729378, Lr:0.0001\n",
      "Epoch 30, Step: 913, Loss: 0.0355704165995121, Lr:0.0001\n",
      "Epoch 30, Step: 914, Loss: 0.003214753232896328, Lr:0.0001\n",
      "Epoch 30, Step: 915, Loss: 0.08709962666034698, Lr:0.0001\n",
      "Epoch 30, Step: 916, Loss: 0.12640513479709625, Lr:0.0001\n",
      "Epoch 30, Step: 917, Loss: 0.00025354139506816864, Lr:0.0001\n",
      "Epoch 30, Step: 918, Loss: 0.016561230644583702, Lr:0.0001\n",
      "Epoch 30, Step: 919, Loss: 0.009237159974873066, Lr:0.0001\n",
      "Epoch 30, Step: 920, Loss: 0.028767546638846397, Lr:0.0001\n",
      "Epoch 30, Step: 921, Loss: 0.24315662682056427, Lr:0.0001\n",
      "Epoch 30, Step: 922, Loss: 0.02991056814789772, Lr:0.0001\n",
      "Epoch 30, Step: 923, Loss: 0.20635031163692474, Lr:0.0001\n",
      "Epoch 30, Step: 924, Loss: 0.030384337529540062, Lr:0.0001\n",
      "Epoch 30, Step: 925, Loss: 0.12081726640462875, Lr:0.0001\n",
      "Epoch 30, Step: 926, Loss: 0.019346287474036217, Lr:0.0001\n",
      "Epoch 30, Step: 927, Loss: 0.005807079840451479, Lr:0.0001\n",
      "Epoch 30, Step: 928, Loss: 0.04999367520213127, Lr:0.0001\n",
      "Epoch 30, Step: 929, Loss: 0.01790706068277359, Lr:0.0001\n",
      "Epoch 30, Step: 930, Loss: 0.0010282156290486455, Lr:0.0001\n",
      "Epoch 30, Step: 931, Loss: 0.005432442761957645, Lr:0.0001\n",
      "Epoch 30, Step: 932, Loss: 0.00010115235636476427, Lr:0.0001\n",
      "Epoch 30, Step: 933, Loss: 0.013941241428256035, Lr:0.0001\n",
      "Epoch 30, Step: 934, Loss: 0.06034153699874878, Lr:0.0001\n",
      "Epoch 30, Step: 935, Loss: 0.0887313112616539, Lr:0.0001\n",
      "Epoch 30, Step: 936, Loss: 0.05946992710232735, Lr:0.0001\n",
      "Epoch 30, Step: 937, Loss: 0.020035406574606895, Lr:0.0001\n",
      "Epoch 30, Step: 938, Loss: 0.007682241965085268, Lr:0.0001\n",
      "Epoch 30, Step: 939, Loss: 0.0031619102228432894, Lr:0.0001\n",
      "Epoch 30, Step: 940, Loss: 0.018704306334257126, Lr:0.0001\n",
      "Epoch 30, Step: 941, Loss: 0.16943280398845673, Lr:0.0001\n",
      "Epoch 30, Step: 942, Loss: 0.041864123195409775, Lr:0.0001\n",
      "Epoch 30, Step: 943, Loss: 0.003409727942198515, Lr:0.0001\n",
      "Epoch 30, Step: 944, Loss: 0.04732292890548706, Lr:0.0001\n",
      "Epoch 30, Step: 945, Loss: 0.007046207319945097, Lr:0.0001\n",
      "Epoch 30, Step: 946, Loss: 0.013825366273522377, Lr:0.0001\n",
      "Epoch 30, Step: 947, Loss: 0.01756720058619976, Lr:0.0001\n",
      "Epoch 30, Step: 948, Loss: 0.08479314297437668, Lr:0.0001\n",
      "Epoch 30, Step: 949, Loss: 0.015240448527038097, Lr:0.0001\n",
      "Epoch 30, Step: 950, Loss: 0.1003064438700676, Lr:0.0001\n",
      "Epoch 30, Step: 951, Loss: 0.00968869961798191, Lr:0.0001\n",
      "Epoch 30, Step: 952, Loss: 0.09257352352142334, Lr:0.0001\n",
      "Epoch 30, Step: 953, Loss: 0.021141577512025833, Lr:0.0001\n",
      "Epoch 30, Step: 954, Loss: 0.13002069294452667, Lr:0.0001\n",
      "Epoch 30, Step: 955, Loss: 0.06845608353614807, Lr:0.0001\n",
      "Epoch 30, Step: 956, Loss: 0.06634718924760818, Lr:0.0001\n",
      "Epoch 30, Step: 957, Loss: 0.019905466586351395, Lr:0.0001\n",
      "Epoch 30, Step: 958, Loss: 0.005495692137628794, Lr:0.0001\n",
      "Epoch 30, Step: 959, Loss: 0.16698460280895233, Lr:0.0001\n",
      "Epoch 30, Step: 960, Loss: 0.008835287764668465, Lr:0.0001\n",
      "Epoch 30, Step: 961, Loss: 0.07499542832374573, Lr:0.0001\n",
      "Epoch 30, Step: 962, Loss: 0.061885811388492584, Lr:0.0001\n",
      "Epoch 30, Step: 963, Loss: 0.0016276980750262737, Lr:0.0001\n",
      "Epoch 30, Step: 964, Loss: 0.01986009255051613, Lr:0.0001\n",
      "Epoch 30, Step: 965, Loss: 0.03052840568125248, Lr:0.0001\n",
      "Epoch 30, Step: 966, Loss: 0.00028740428388118744, Lr:0.0001\n",
      "Epoch 30, Step: 967, Loss: 0.005422242451459169, Lr:0.0001\n",
      "Epoch 30, Step: 968, Loss: 0.02336990088224411, Lr:0.0001\n",
      "Epoch 30, Step: 969, Loss: 0.007928197272121906, Lr:0.0001\n",
      "Epoch 30, Step: 970, Loss: 0.005623926874250174, Lr:0.0001\n",
      "Epoch 30, Step: 971, Loss: 0.06939215213060379, Lr:0.0001\n",
      "Epoch 30, Step: 972, Loss: 0.08368181437253952, Lr:0.0001\n",
      "Epoch 30, Step: 973, Loss: 0.06374628841876984, Lr:0.0001\n",
      "Epoch 30, Step: 974, Loss: 0.07680807262659073, Lr:0.0001\n",
      "Epoch 30, Step: 975, Loss: 0.004408671986311674, Lr:0.0001\n",
      "Epoch 30, Step: 976, Loss: 0.008297274820506573, Lr:0.0001\n",
      "Epoch 30, Step: 977, Loss: 0.015062215737998486, Lr:0.0001\n",
      "Epoch 30, Step: 978, Loss: 0.00676097022369504, Lr:0.0001\n",
      "Epoch 30, Step: 979, Loss: 0.0008791500004008412, Lr:0.0001\n",
      "Epoch 30, Step: 980, Loss: 0.018152663484215736, Lr:0.0001\n",
      "Epoch 30, Step: 981, Loss: 0.0016400653403252363, Lr:0.0001\n",
      "Epoch 30, Step: 982, Loss: 0.00662636011838913, Lr:0.0001\n",
      "Epoch 30, Step: 983, Loss: 0.019594518467783928, Lr:0.0001\n",
      "Epoch 30, Step: 984, Loss: 0.15162219107151031, Lr:0.0001\n",
      "Epoch 30, Step: 985, Loss: 0.002404035534709692, Lr:0.0001\n",
      "Epoch 30, Step: 986, Loss: 0.013317289762198925, Lr:0.0001\n",
      "Epoch 30, Step: 987, Loss: 0.11764849722385406, Lr:0.0001\n",
      "Epoch 30, Step: 988, Loss: 0.004030373878777027, Lr:0.0001\n",
      "Epoch 30, Step: 989, Loss: 0.05471978709101677, Lr:0.0001\n",
      "Epoch 30, Step: 990, Loss: 0.05628631263971329, Lr:0.0001\n",
      "Epoch 30, Step: 991, Loss: 0.0049530197866261005, Lr:0.0001\n",
      "Epoch 30, Step: 992, Loss: 0.03710126131772995, Lr:0.0001\n",
      "Epoch 30, Step: 993, Loss: 0.035730231553316116, Lr:0.0001\n",
      "Epoch 30, Step: 994, Loss: 0.0013924399390816689, Lr:0.0001\n",
      "Epoch 30, Step: 995, Loss: 0.08330778777599335, Lr:0.0001\n",
      "Epoch 30, Step: 996, Loss: 0.030817976221442223, Lr:0.0001\n",
      "Epoch 30, Step: 997, Loss: 0.11410155892372131, Lr:0.0001\n",
      "Epoch 30, Step: 998, Loss: 0.04570746049284935, Lr:0.0001\n",
      "Epoch 30, Step: 999, Loss: 0.06265531480312347, Lr:0.0001\n",
      "Epoch 30, Step: 1000, Loss: 0.14405915141105652, Lr:0.0001\n",
      "Epoch 30, Step: 1001, Loss: 0.07561670243740082, Lr:0.0001\n",
      "Epoch 30, Step: 1002, Loss: 0.006671917624771595, Lr:0.0001\n",
      "Epoch 30, Step: 1003, Loss: 0.0116159338504076, Lr:0.0001\n",
      "Epoch 30, Step: 1004, Loss: 0.4659340977668762, Lr:0.0001\n",
      "Epoch 30, Step: 1005, Loss: 0.2617872357368469, Lr:0.0001\n",
      "Epoch 30, Step: 1006, Loss: 0.08319463580846786, Lr:0.0001\n",
      "Epoch 30, Step: 1007, Loss: 0.015594221651554108, Lr:0.0001\n",
      "Epoch 30, Step: 1008, Loss: 0.12621882557868958, Lr:0.0001\n",
      "Epoch 30, Step: 1009, Loss: 0.006629252806305885, Lr:0.0001\n",
      "Epoch 30, Step: 1010, Loss: 0.021498555317521095, Lr:0.0001\n",
      "Epoch 30, Step: 1011, Loss: 0.022373681887984276, Lr:0.0001\n",
      "Epoch 30, Step: 1012, Loss: 0.0041654990054667, Lr:0.0001\n",
      "Epoch 30, Step: 1013, Loss: 0.5254781246185303, Lr:0.0001\n",
      "Epoch 30, Step: 1014, Loss: 0.002127555198967457, Lr:0.0001\n",
      "Epoch 30, Step: 1015, Loss: 0.00043814763193950057, Lr:0.0001\n",
      "Epoch 30, Step: 1016, Loss: 0.2894773483276367, Lr:0.0001\n",
      "Epoch 30, Step: 1017, Loss: 0.0328328013420105, Lr:0.0001\n",
      "Epoch 30, Step: 1018, Loss: 0.10595853626728058, Lr:0.0001\n",
      "Epoch 30, Step: 1019, Loss: 0.09551404416561127, Lr:0.0001\n",
      "Epoch 30, Step: 1020, Loss: 0.19865666329860687, Lr:0.0001\n",
      "Epoch 30, Step: 1021, Loss: 0.04178899526596069, Lr:0.0001\n",
      "Epoch 30, Step: 1022, Loss: 0.019564075395464897, Lr:0.0001\n",
      "Epoch 30, Step: 1023, Loss: 0.08486367762088776, Lr:0.0001\n",
      "Epoch 30, Step: 1024, Loss: 0.0076875993981957436, Lr:0.0001\n",
      "Epoch 30, Step: 1025, Loss: 0.021084660664200783, Lr:0.0001\n",
      "Epoch 30, Step: 1026, Loss: 0.02398376539349556, Lr:0.0001\n",
      "Epoch 30, Step: 1027, Loss: 0.04584714025259018, Lr:0.0001\n",
      "Epoch 30, Step: 1028, Loss: 0.03496164083480835, Lr:0.0001\n",
      "Epoch 30, Step: 1029, Loss: 0.1508311778306961, Lr:0.0001\n",
      "Epoch 30, Step: 1030, Loss: 0.09036789834499359, Lr:0.0001\n",
      "Epoch 30, Step: 1031, Loss: 0.04980805888772011, Lr:0.0001\n",
      "Epoch 30, Step: 1032, Loss: 0.1460355520248413, Lr:0.0001\n",
      "Epoch 30, Step: 1033, Loss: 0.014384303241968155, Lr:0.0001\n",
      "Epoch 30, Step: 1034, Loss: 0.047563180327415466, Lr:0.0001\n",
      "Epoch 30, Step: 1035, Loss: 0.2538388967514038, Lr:0.0001\n",
      "Epoch 30, Step: 1036, Loss: 0.25620943307876587, Lr:0.0001\n",
      "Epoch 30, Step: 1037, Loss: 0.13196806609630585, Lr:0.0001\n",
      "Epoch 30, Step: 1038, Loss: 0.029982570558786392, Lr:0.0001\n",
      "Epoch 30, Step: 1039, Loss: 0.05812545493245125, Lr:0.0001\n",
      "Epoch 30, Step: 1040, Loss: 0.1585007607936859, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 30\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:15 loss: 0.4082 (0.4082) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.2855 data: 0.1180 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.0818 (0.1397) acc1: 93.7500 (93.1818) acc5: 100.0000 (100.0000) time: 0.2934 data: 0.1157 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0501 (0.1911) acc1: 93.7500 (94.0476) acc5: 100.0000 (100.0000) time: 0.2923 data: 0.1160 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.0657 (0.2045) acc1: 93.7500 (93.7500) acc5: 100.0000 (100.0000) time: 0.2913 data: 0.1176 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.0944 (0.1848) acc1: 93.7500 (94.3598) acc5: 100.0000 (100.0000) time: 0.2975 data: 0.1212 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0185 (0.1605) acc1: 100.0000 (94.9755) acc5: 100.0000 (100.0000) time: 0.2993 data: 0.1228 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0185 (0.1626) acc1: 100.0000 (94.6652) acc5: 100.0000 (100.0000) time: 0.2831 data: 0.1166 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.2896 s / it)\n",
      "* Acc@1 94.665 Acc@5 100.000 loss 0.163\n",
      "Accuracy of the network on the 881 test image: 94.7%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 31, Step: 0, Loss: 0.17954598367214203, Lr:0.0001\n",
      "Epoch 31, Step: 1, Loss: 0.0839373841881752, Lr:0.0001\n",
      "Epoch 31, Step: 2, Loss: 0.039683472365140915, Lr:0.0001\n",
      "Epoch 31, Step: 3, Loss: 0.004477645270526409, Lr:0.0001\n",
      "Epoch 31, Step: 4, Loss: 0.048848990350961685, Lr:0.0001\n",
      "Epoch 31, Step: 5, Loss: 0.004048753995448351, Lr:0.0001\n",
      "Epoch 31, Step: 6, Loss: 0.08662482351064682, Lr:0.0001\n",
      "Epoch 31, Step: 7, Loss: 0.11660325527191162, Lr:0.0001\n",
      "Epoch 31, Step: 8, Loss: 0.0392427071928978, Lr:0.0001\n",
      "Epoch 31, Step: 9, Loss: 0.0030633602291345596, Lr:0.0001\n",
      "Epoch 31, Step: 10, Loss: 0.05614325776696205, Lr:0.0001\n",
      "Epoch 31, Step: 11, Loss: 0.07689770311117172, Lr:0.0001\n",
      "Epoch 31, Step: 12, Loss: 0.0823284313082695, Lr:0.0001\n",
      "Epoch 31, Step: 13, Loss: 0.26684337854385376, Lr:0.0001\n",
      "Epoch 31, Step: 14, Loss: 0.029152940958738327, Lr:0.0001\n",
      "Epoch 31, Step: 15, Loss: 0.06205478310585022, Lr:0.0001\n",
      "Epoch 31, Step: 16, Loss: 0.055050477385520935, Lr:0.0001\n",
      "Epoch 31, Step: 17, Loss: 0.002000823151320219, Lr:0.0001\n",
      "Epoch 31, Step: 18, Loss: 0.23572540283203125, Lr:0.0001\n",
      "Epoch 31, Step: 19, Loss: 0.1914013773202896, Lr:0.0001\n",
      "Epoch 31, Step: 20, Loss: 0.2903493046760559, Lr:0.0001\n",
      "Epoch 31, Step: 21, Loss: 0.05833970010280609, Lr:0.0001\n",
      "Epoch 31, Step: 22, Loss: 0.0013912887079641223, Lr:0.0001\n",
      "Epoch 31, Step: 23, Loss: 0.1284390687942505, Lr:0.0001\n",
      "Epoch 31, Step: 24, Loss: 0.19949033856391907, Lr:0.0001\n",
      "Epoch 31, Step: 25, Loss: 0.12812089920043945, Lr:0.0001\n",
      "Epoch 31, Step: 26, Loss: 0.011667958460748196, Lr:0.0001\n",
      "Epoch 31, Step: 27, Loss: 0.02784835360944271, Lr:0.0001\n",
      "Epoch 31, Step: 28, Loss: 0.20653437077999115, Lr:0.0001\n",
      "Epoch 31, Step: 29, Loss: 0.03998209163546562, Lr:0.0001\n",
      "Epoch 31, Step: 30, Loss: 0.04312162101268768, Lr:0.0001\n",
      "Epoch 31, Step: 31, Loss: 0.0022711765486747026, Lr:0.0001\n",
      "Epoch 31, Step: 32, Loss: 0.10534710437059402, Lr:0.0001\n",
      "Epoch 31, Step: 33, Loss: 0.054096803069114685, Lr:0.0001\n",
      "Epoch 31, Step: 34, Loss: 0.07198373973369598, Lr:0.0001\n",
      "Epoch 31, Step: 35, Loss: 0.10983109474182129, Lr:0.0001\n",
      "Epoch 31, Step: 36, Loss: 0.029908332973718643, Lr:0.0001\n",
      "Epoch 31, Step: 37, Loss: 0.17303811013698578, Lr:0.0001\n",
      "Epoch 31, Step: 38, Loss: 0.005881038494408131, Lr:0.0001\n",
      "Epoch 31, Step: 39, Loss: 0.0114071574062109, Lr:0.0001\n",
      "Epoch 31, Step: 40, Loss: 0.09389711171388626, Lr:0.0001\n",
      "Epoch 31, Step: 41, Loss: 0.008877025917172432, Lr:0.0001\n",
      "Epoch 31, Step: 42, Loss: 0.03382890671491623, Lr:0.0001\n",
      "Epoch 31, Step: 43, Loss: 0.002129955682903528, Lr:0.0001\n",
      "Epoch 31, Step: 44, Loss: 0.02714458480477333, Lr:0.0001\n",
      "Epoch 31, Step: 45, Loss: 0.36729124188423157, Lr:0.0001\n",
      "Epoch 31, Step: 46, Loss: 0.3037952184677124, Lr:0.0001\n",
      "Epoch 31, Step: 47, Loss: 0.09018946439027786, Lr:0.0001\n",
      "Epoch 31, Step: 48, Loss: 0.2832440733909607, Lr:0.0001\n",
      "Epoch 31, Step: 49, Loss: 0.017208157107234, Lr:0.0001\n",
      "Epoch 31, Step: 50, Loss: 0.09419061988592148, Lr:0.0001\n",
      "Epoch 31, Step: 51, Loss: 0.3758295178413391, Lr:0.0001\n",
      "Epoch 31, Step: 52, Loss: 0.26725706458091736, Lr:0.0001\n",
      "Epoch 31, Step: 53, Loss: 0.06973207741975784, Lr:0.0001\n",
      "Epoch 31, Step: 54, Loss: 0.032042913138866425, Lr:0.0001\n",
      "Epoch 31, Step: 55, Loss: 0.04445705562829971, Lr:0.0001\n",
      "Epoch 31, Step: 56, Loss: 0.01820770651102066, Lr:0.0001\n",
      "Epoch 31, Step: 57, Loss: 0.0048179891891777515, Lr:0.0001\n",
      "Epoch 31, Step: 58, Loss: 0.02692953683435917, Lr:0.0001\n",
      "Epoch 31, Step: 59, Loss: 0.013785947114229202, Lr:0.0001\n",
      "Epoch 31, Step: 60, Loss: 0.01708802953362465, Lr:0.0001\n",
      "Epoch 31, Step: 61, Loss: 0.06480225920677185, Lr:0.0001\n",
      "Epoch 31, Step: 62, Loss: 0.03255681321024895, Lr:0.0001\n",
      "Epoch 31, Step: 63, Loss: 0.0521901398897171, Lr:0.0001\n",
      "Epoch 31, Step: 64, Loss: 0.06208278238773346, Lr:0.0001\n",
      "Epoch 31, Step: 65, Loss: 0.010217329487204552, Lr:0.0001\n",
      "Epoch 31, Step: 66, Loss: 0.051968272775411606, Lr:0.0001\n",
      "Epoch 31, Step: 67, Loss: 0.052968136966228485, Lr:0.0001\n",
      "Epoch 31, Step: 68, Loss: 0.011716538108885288, Lr:0.0001\n",
      "Epoch 31, Step: 69, Loss: 0.03279806300997734, Lr:0.0001\n",
      "Epoch 31, Step: 70, Loss: 0.04539594054222107, Lr:0.0001\n",
      "Epoch 31, Step: 71, Loss: 0.022987671196460724, Lr:0.0001\n",
      "Epoch 31, Step: 72, Loss: 0.026891091838479042, Lr:0.0001\n",
      "Epoch 31, Step: 73, Loss: 0.04593902453780174, Lr:0.0001\n",
      "Epoch 31, Step: 74, Loss: 0.017228297889232635, Lr:0.0001\n",
      "Epoch 31, Step: 75, Loss: 0.01685171015560627, Lr:0.0001\n",
      "Epoch 31, Step: 76, Loss: 0.08151112496852875, Lr:0.0001\n",
      "Epoch 31, Step: 77, Loss: 0.04456816241145134, Lr:0.0001\n",
      "Epoch 31, Step: 78, Loss: 0.0539897195994854, Lr:0.0001\n",
      "Epoch 31, Step: 79, Loss: 0.01069586630910635, Lr:0.0001\n",
      "Epoch 31, Step: 80, Loss: 0.0013211267068982124, Lr:0.0001\n",
      "Epoch 31, Step: 81, Loss: 0.056153226643800735, Lr:0.0001\n",
      "Epoch 31, Step: 82, Loss: 0.046619102358818054, Lr:0.0001\n",
      "Epoch 31, Step: 83, Loss: 0.02892407216131687, Lr:0.0001\n",
      "Epoch 31, Step: 84, Loss: 0.002566360868513584, Lr:0.0001\n",
      "Epoch 31, Step: 85, Loss: 0.21275652945041656, Lr:0.0001\n",
      "Epoch 31, Step: 86, Loss: 0.01941562630236149, Lr:0.0001\n",
      "Epoch 31, Step: 87, Loss: 0.013754457235336304, Lr:0.0001\n",
      "Epoch 31, Step: 88, Loss: 0.14510178565979004, Lr:0.0001\n",
      "Epoch 31, Step: 89, Loss: 0.04119269922375679, Lr:0.0001\n",
      "Epoch 31, Step: 90, Loss: 0.022172756493091583, Lr:0.0001\n",
      "Epoch 31, Step: 91, Loss: 0.020594606176018715, Lr:0.0001\n",
      "Epoch 31, Step: 92, Loss: 0.03265233710408211, Lr:0.0001\n",
      "Epoch 31, Step: 93, Loss: 0.15939779579639435, Lr:0.0001\n",
      "Epoch 31, Step: 94, Loss: 0.09532942622900009, Lr:0.0001\n",
      "Epoch 31, Step: 95, Loss: 0.004775156266987324, Lr:0.0001\n",
      "Epoch 31, Step: 96, Loss: 0.0010902268113568425, Lr:0.0001\n",
      "Epoch 31, Step: 97, Loss: 0.0289224274456501, Lr:0.0001\n",
      "Epoch 31, Step: 98, Loss: 0.010366964153945446, Lr:0.0001\n",
      "Epoch 31, Step: 99, Loss: 0.08881863206624985, Lr:0.0001\n",
      "Epoch 31, Step: 100, Loss: 0.10058663785457611, Lr:0.0001\n",
      "Epoch 31, Step: 101, Loss: 0.041866689920425415, Lr:0.0001\n",
      "Epoch 31, Step: 102, Loss: 0.04911953955888748, Lr:0.0001\n",
      "Epoch 31, Step: 103, Loss: 0.03599416837096214, Lr:0.0001\n",
      "Epoch 31, Step: 104, Loss: 0.08881921321153641, Lr:0.0001\n",
      "Epoch 31, Step: 105, Loss: 0.03751624748110771, Lr:0.0001\n",
      "Epoch 31, Step: 106, Loss: 0.07211191207170486, Lr:0.0001\n",
      "Epoch 31, Step: 107, Loss: 0.017918143421411514, Lr:0.0001\n",
      "Epoch 31, Step: 108, Loss: 0.008220220915973186, Lr:0.0001\n",
      "Epoch 31, Step: 109, Loss: 0.0030519762076437473, Lr:0.0001\n",
      "Epoch 31, Step: 110, Loss: 0.0022183344699442387, Lr:0.0001\n",
      "Epoch 31, Step: 111, Loss: 0.0025583659298717976, Lr:0.0001\n",
      "Epoch 31, Step: 112, Loss: 0.0015164157375693321, Lr:0.0001\n",
      "Epoch 31, Step: 113, Loss: 0.18827979266643524, Lr:0.0001\n",
      "Epoch 31, Step: 114, Loss: 0.006205475423485041, Lr:0.0001\n",
      "Epoch 31, Step: 115, Loss: 0.054485976696014404, Lr:0.0001\n",
      "Epoch 31, Step: 116, Loss: 0.003703380934894085, Lr:0.0001\n",
      "Epoch 31, Step: 117, Loss: 0.029363475739955902, Lr:0.0001\n",
      "Epoch 31, Step: 118, Loss: 0.2950657904148102, Lr:0.0001\n",
      "Epoch 31, Step: 119, Loss: 0.025326285511255264, Lr:0.0001\n",
      "Epoch 31, Step: 120, Loss: 0.2462221384048462, Lr:0.0001\n",
      "Epoch 31, Step: 121, Loss: 0.07505422830581665, Lr:0.0001\n",
      "Epoch 31, Step: 122, Loss: 0.11958727985620499, Lr:0.0001\n",
      "Epoch 31, Step: 123, Loss: 0.0014592049410566688, Lr:0.0001\n",
      "Epoch 31, Step: 124, Loss: 0.05444807931780815, Lr:0.0001\n",
      "Epoch 31, Step: 125, Loss: 0.005762698128819466, Lr:0.0001\n",
      "Epoch 31, Step: 126, Loss: 0.13657113909721375, Lr:0.0001\n",
      "Epoch 31, Step: 127, Loss: 0.019475974142551422, Lr:0.0001\n",
      "Epoch 31, Step: 128, Loss: 0.042648132890462875, Lr:0.0001\n",
      "Epoch 31, Step: 129, Loss: 0.09239106625318527, Lr:0.0001\n",
      "Epoch 31, Step: 130, Loss: 0.004124683327972889, Lr:0.0001\n",
      "Epoch 31, Step: 131, Loss: 0.0764618068933487, Lr:0.0001\n",
      "Epoch 31, Step: 132, Loss: 0.01674455776810646, Lr:0.0001\n",
      "Epoch 31, Step: 133, Loss: 0.1768765151500702, Lr:0.0001\n",
      "Epoch 31, Step: 134, Loss: 0.04529062658548355, Lr:0.0001\n",
      "Epoch 31, Step: 135, Loss: 0.04378816857933998, Lr:0.0001\n",
      "Epoch 31, Step: 136, Loss: 0.036179784685373306, Lr:0.0001\n",
      "Epoch 31, Step: 137, Loss: 0.013858138583600521, Lr:0.0001\n",
      "Epoch 31, Step: 138, Loss: 0.010819580405950546, Lr:0.0001\n",
      "Epoch 31, Step: 139, Loss: 0.09211200475692749, Lr:0.0001\n",
      "Epoch 31, Step: 140, Loss: 0.0448538139462471, Lr:0.0001\n",
      "Epoch 31, Step: 141, Loss: 0.11724875867366791, Lr:0.0001\n",
      "Epoch 31, Step: 142, Loss: 0.01601017639040947, Lr:0.0001\n",
      "Epoch 31, Step: 143, Loss: 0.0480349138379097, Lr:0.0001\n",
      "Epoch 31, Step: 144, Loss: 0.03286243975162506, Lr:0.0001\n",
      "Epoch 31, Step: 145, Loss: 0.01630287989974022, Lr:0.0001\n",
      "Epoch 31, Step: 146, Loss: 0.010816961526870728, Lr:0.0001\n",
      "Epoch 31, Step: 147, Loss: 0.017348652705550194, Lr:0.0001\n",
      "Epoch 31, Step: 148, Loss: 0.09066237509250641, Lr:0.0001\n",
      "Epoch 31, Step: 149, Loss: 0.03180927410721779, Lr:0.0001\n",
      "Epoch 31, Step: 150, Loss: 0.005703126545995474, Lr:0.0001\n",
      "Epoch 31, Step: 151, Loss: 0.0007917952025309205, Lr:0.0001\n",
      "Epoch 31, Step: 152, Loss: 0.00727075757458806, Lr:0.0001\n",
      "Epoch 31, Step: 153, Loss: 0.1348610371351242, Lr:0.0001\n",
      "Epoch 31, Step: 154, Loss: 0.19526493549346924, Lr:0.0001\n",
      "Epoch 31, Step: 155, Loss: 0.08378877490758896, Lr:0.0001\n",
      "Epoch 31, Step: 156, Loss: 0.04201045632362366, Lr:0.0001\n",
      "Epoch 31, Step: 157, Loss: 0.07345150411128998, Lr:0.0001\n",
      "Epoch 31, Step: 158, Loss: 0.28076547384262085, Lr:0.0001\n",
      "Epoch 31, Step: 159, Loss: 0.009769299067556858, Lr:0.0001\n",
      "Epoch 31, Step: 160, Loss: 0.0006548177916556597, Lr:0.0001\n",
      "Epoch 31, Step: 161, Loss: 0.005298773758113384, Lr:0.0001\n",
      "Epoch 31, Step: 162, Loss: 0.009811466559767723, Lr:0.0001\n",
      "Epoch 31, Step: 163, Loss: 0.15096406638622284, Lr:0.0001\n",
      "Epoch 31, Step: 164, Loss: 0.03214377909898758, Lr:0.0001\n",
      "Epoch 31, Step: 165, Loss: 0.019757483154535294, Lr:0.0001\n",
      "Epoch 31, Step: 166, Loss: 0.011122220195829868, Lr:0.0001\n",
      "Epoch 31, Step: 167, Loss: 0.009753287769854069, Lr:0.0001\n",
      "Epoch 31, Step: 168, Loss: 0.00836402177810669, Lr:0.0001\n",
      "Epoch 31, Step: 169, Loss: 0.1093684658408165, Lr:0.0001\n",
      "Epoch 31, Step: 170, Loss: 0.004870961420238018, Lr:0.0001\n",
      "Epoch 31, Step: 171, Loss: 0.028216224163770676, Lr:0.0001\n",
      "Epoch 31, Step: 172, Loss: 0.0011056530056521297, Lr:0.0001\n",
      "Epoch 31, Step: 173, Loss: 0.0336410254240036, Lr:0.0001\n",
      "Epoch 31, Step: 174, Loss: 0.05381903052330017, Lr:0.0001\n",
      "Epoch 31, Step: 175, Loss: 0.03431747108697891, Lr:0.0001\n",
      "Epoch 31, Step: 176, Loss: 0.029978955164551735, Lr:0.0001\n",
      "Epoch 31, Step: 177, Loss: 0.22481344640254974, Lr:0.0001\n",
      "Epoch 31, Step: 178, Loss: 0.013255955651402473, Lr:0.0001\n",
      "Epoch 31, Step: 179, Loss: 0.01988488994538784, Lr:0.0001\n",
      "Epoch 31, Step: 180, Loss: 0.04290434345602989, Lr:0.0001\n",
      "Epoch 31, Step: 181, Loss: 0.00036174189881421626, Lr:0.0001\n",
      "Epoch 31, Step: 182, Loss: 0.017764482647180557, Lr:0.0001\n",
      "Epoch 31, Step: 183, Loss: 0.0975099727511406, Lr:0.0001\n",
      "Epoch 31, Step: 184, Loss: 0.00858523603528738, Lr:0.0001\n",
      "Epoch 31, Step: 185, Loss: 0.01802883669734001, Lr:0.0001\n",
      "Epoch 31, Step: 186, Loss: 0.11387867480516434, Lr:0.0001\n",
      "Epoch 31, Step: 187, Loss: 0.05872805044054985, Lr:0.0001\n",
      "Epoch 31, Step: 188, Loss: 0.04938410222530365, Lr:0.0001\n",
      "Epoch 31, Step: 189, Loss: 0.032366782426834106, Lr:0.0001\n",
      "Epoch 31, Step: 190, Loss: 0.0012748364824801683, Lr:0.0001\n",
      "Epoch 31, Step: 191, Loss: 0.021047908812761307, Lr:0.0001\n",
      "Epoch 31, Step: 192, Loss: 0.07043582201004028, Lr:0.0001\n",
      "Epoch 31, Step: 193, Loss: 0.10170185565948486, Lr:0.0001\n",
      "Epoch 31, Step: 194, Loss: 0.006293943151831627, Lr:0.0001\n",
      "Epoch 31, Step: 195, Loss: 0.3769610524177551, Lr:0.0001\n",
      "Epoch 31, Step: 196, Loss: 0.012778837233781815, Lr:0.0001\n",
      "Epoch 31, Step: 197, Loss: 0.24274174869060516, Lr:0.0001\n",
      "Epoch 31, Step: 198, Loss: 0.29451483488082886, Lr:0.0001\n",
      "Epoch 31, Step: 199, Loss: 0.0073941657319664955, Lr:0.0001\n",
      "Epoch 31, Step: 200, Loss: 0.010055500082671642, Lr:0.0001\n",
      "Epoch 31, Step: 201, Loss: 0.022822344675660133, Lr:0.0001\n",
      "Epoch 31, Step: 202, Loss: 0.17706340551376343, Lr:0.0001\n",
      "Epoch 31, Step: 203, Loss: 0.01594352535903454, Lr:0.0001\n",
      "Epoch 31, Step: 204, Loss: 0.053621385246515274, Lr:0.0001\n",
      "Epoch 31, Step: 205, Loss: 0.00869170855730772, Lr:0.0001\n",
      "Epoch 31, Step: 206, Loss: 0.0054277596063911915, Lr:0.0001\n",
      "Epoch 31, Step: 207, Loss: 0.0031393151730298996, Lr:0.0001\n",
      "Epoch 31, Step: 208, Loss: 0.003135540522634983, Lr:0.0001\n",
      "Epoch 31, Step: 209, Loss: 0.1338774859905243, Lr:0.0001\n",
      "Epoch 31, Step: 210, Loss: 0.011617862619459629, Lr:0.0001\n",
      "Epoch 31, Step: 211, Loss: 0.03834229335188866, Lr:0.0001\n",
      "Epoch 31, Step: 212, Loss: 0.10500326007604599, Lr:0.0001\n",
      "Epoch 31, Step: 213, Loss: 0.0343499630689621, Lr:0.0001\n",
      "Epoch 31, Step: 214, Loss: 0.000910852337256074, Lr:0.0001\n",
      "Epoch 31, Step: 215, Loss: 0.07105141878128052, Lr:0.0001\n",
      "Epoch 31, Step: 216, Loss: 0.1043788269162178, Lr:0.0001\n",
      "Epoch 31, Step: 217, Loss: 0.007327169179916382, Lr:0.0001\n",
      "Epoch 31, Step: 218, Loss: 0.03050048276782036, Lr:0.0001\n",
      "Epoch 31, Step: 219, Loss: 0.023246198892593384, Lr:0.0001\n",
      "Epoch 31, Step: 220, Loss: 0.023589884862303734, Lr:0.0001\n",
      "Epoch 31, Step: 221, Loss: 0.09570067375898361, Lr:0.0001\n",
      "Epoch 31, Step: 222, Loss: 0.03637104853987694, Lr:0.0001\n",
      "Epoch 31, Step: 223, Loss: 0.2120615690946579, Lr:0.0001\n",
      "Epoch 31, Step: 224, Loss: 0.08151315152645111, Lr:0.0001\n",
      "Epoch 31, Step: 225, Loss: 0.005248884204775095, Lr:0.0001\n",
      "Epoch 31, Step: 226, Loss: 0.0051502869464457035, Lr:0.0001\n",
      "Epoch 31, Step: 227, Loss: 0.0006349488976411521, Lr:0.0001\n",
      "Epoch 31, Step: 228, Loss: 0.1677531898021698, Lr:0.0001\n",
      "Epoch 31, Step: 229, Loss: 0.19793760776519775, Lr:0.0001\n",
      "Epoch 31, Step: 230, Loss: 0.05327644199132919, Lr:0.0001\n",
      "Epoch 31, Step: 231, Loss: 0.04199684038758278, Lr:0.0001\n",
      "Epoch 31, Step: 232, Loss: 0.04007552191615105, Lr:0.0001\n",
      "Epoch 31, Step: 233, Loss: 0.07894293963909149, Lr:0.0001\n",
      "Epoch 31, Step: 234, Loss: 0.02787569724023342, Lr:0.0001\n",
      "Epoch 31, Step: 235, Loss: 0.07780540734529495, Lr:0.0001\n",
      "Epoch 31, Step: 236, Loss: 0.04422273486852646, Lr:0.0001\n",
      "Epoch 31, Step: 237, Loss: 0.0015918908175081015, Lr:0.0001\n",
      "Epoch 31, Step: 238, Loss: 0.04820381850004196, Lr:0.0001\n",
      "Epoch 31, Step: 239, Loss: 0.018271876499056816, Lr:0.0001\n",
      "Epoch 31, Step: 240, Loss: 0.10177163779735565, Lr:0.0001\n",
      "Epoch 31, Step: 241, Loss: 0.0015259769279509783, Lr:0.0001\n",
      "Epoch 31, Step: 242, Loss: 0.04335782304406166, Lr:0.0001\n",
      "Epoch 31, Step: 243, Loss: 0.038716841489076614, Lr:0.0001\n",
      "Epoch 31, Step: 244, Loss: 0.3383519649505615, Lr:0.0001\n",
      "Epoch 31, Step: 245, Loss: 0.18674740195274353, Lr:0.0001\n",
      "Epoch 31, Step: 246, Loss: 0.07517421245574951, Lr:0.0001\n",
      "Epoch 31, Step: 247, Loss: 0.01222280878573656, Lr:0.0001\n",
      "Epoch 31, Step: 248, Loss: 0.001568065257743001, Lr:0.0001\n",
      "Epoch 31, Step: 249, Loss: 0.03826037794351578, Lr:0.0001\n",
      "Epoch 31, Step: 250, Loss: 0.00455815764144063, Lr:0.0001\n",
      "Epoch 31, Step: 251, Loss: 0.001668549724854529, Lr:0.0001\n",
      "Epoch 31, Step: 252, Loss: 0.12186775356531143, Lr:0.0001\n",
      "Epoch 31, Step: 253, Loss: 0.005421030800789595, Lr:0.0001\n",
      "Epoch 31, Step: 254, Loss: 0.046266958117485046, Lr:0.0001\n",
      "Epoch 31, Step: 255, Loss: 0.00480731250718236, Lr:0.0001\n",
      "Epoch 31, Step: 256, Loss: 0.08640016615390778, Lr:0.0001\n",
      "Epoch 31, Step: 257, Loss: 0.02636687643826008, Lr:0.0001\n",
      "Epoch 31, Step: 258, Loss: 0.020907877013087273, Lr:0.0001\n",
      "Epoch 31, Step: 259, Loss: 0.07835691422224045, Lr:0.0001\n",
      "Epoch 31, Step: 260, Loss: 0.024877144023776054, Lr:0.0001\n",
      "Epoch 31, Step: 261, Loss: 0.060631006956100464, Lr:0.0001\n",
      "Epoch 31, Step: 262, Loss: 0.030198002234101295, Lr:0.0001\n",
      "Epoch 31, Step: 263, Loss: 0.1582530438899994, Lr:0.0001\n",
      "Epoch 31, Step: 264, Loss: 0.026063917204737663, Lr:0.0001\n",
      "Epoch 31, Step: 265, Loss: 0.0023629923816770315, Lr:0.0001\n",
      "Epoch 31, Step: 266, Loss: 0.028094511479139328, Lr:0.0001\n",
      "Epoch 31, Step: 267, Loss: 0.038099516183137894, Lr:0.0001\n",
      "Epoch 31, Step: 268, Loss: 0.005660384893417358, Lr:0.0001\n",
      "Epoch 31, Step: 269, Loss: 0.5895113348960876, Lr:0.0001\n",
      "Epoch 31, Step: 270, Loss: 0.013849246315658092, Lr:0.0001\n",
      "Epoch 31, Step: 271, Loss: 0.14549396932125092, Lr:0.0001\n",
      "Epoch 31, Step: 272, Loss: 0.001462225685827434, Lr:0.0001\n",
      "Epoch 31, Step: 273, Loss: 0.08435018360614777, Lr:0.0001\n",
      "Epoch 31, Step: 274, Loss: 0.5311252474784851, Lr:0.0001\n",
      "Epoch 31, Step: 275, Loss: 0.18385492265224457, Lr:0.0001\n",
      "Epoch 31, Step: 276, Loss: 0.029964504763484, Lr:0.0001\n",
      "Epoch 31, Step: 277, Loss: 0.01521550677716732, Lr:0.0001\n",
      "Epoch 31, Step: 278, Loss: 0.06257963925600052, Lr:0.0001\n",
      "Epoch 31, Step: 279, Loss: 0.18240207433700562, Lr:0.0001\n",
      "Epoch 31, Step: 280, Loss: 0.023742659017443657, Lr:0.0001\n",
      "Epoch 31, Step: 281, Loss: 0.023455243557691574, Lr:0.0001\n",
      "Epoch 31, Step: 282, Loss: 0.16384293138980865, Lr:0.0001\n",
      "Epoch 31, Step: 283, Loss: 0.037718139588832855, Lr:0.0001\n",
      "Epoch 31, Step: 284, Loss: 0.0030099644791334867, Lr:0.0001\n",
      "Epoch 31, Step: 285, Loss: 0.0891260951757431, Lr:0.0001\n",
      "Epoch 31, Step: 286, Loss: 0.05394580215215683, Lr:0.0001\n",
      "Epoch 31, Step: 287, Loss: 0.04460715502500534, Lr:0.0001\n",
      "Epoch 31, Step: 288, Loss: 0.036954592913389206, Lr:0.0001\n",
      "Epoch 31, Step: 289, Loss: 0.0088338702917099, Lr:0.0001\n",
      "Epoch 31, Step: 290, Loss: 0.009658144786953926, Lr:0.0001\n",
      "Epoch 31, Step: 291, Loss: 0.04865642637014389, Lr:0.0001\n",
      "Epoch 31, Step: 292, Loss: 0.00830751284956932, Lr:0.0001\n",
      "Epoch 31, Step: 293, Loss: 0.003108095610514283, Lr:0.0001\n",
      "Epoch 31, Step: 294, Loss: 0.014241551980376244, Lr:0.0001\n",
      "Epoch 31, Step: 295, Loss: 0.004167764913290739, Lr:0.0001\n",
      "Epoch 31, Step: 296, Loss: 0.050235308706760406, Lr:0.0001\n",
      "Epoch 31, Step: 297, Loss: 0.06087026745080948, Lr:0.0001\n",
      "Epoch 31, Step: 298, Loss: 0.01382788922637701, Lr:0.0001\n",
      "Epoch 31, Step: 299, Loss: 0.14697135984897614, Lr:0.0001\n",
      "Epoch 31, Step: 300, Loss: 0.007717964705079794, Lr:0.0001\n",
      "Epoch 31, Step: 301, Loss: 0.09193631261587143, Lr:0.0001\n",
      "Epoch 31, Step: 302, Loss: 0.03939443454146385, Lr:0.0001\n",
      "Epoch 31, Step: 303, Loss: 0.04750661551952362, Lr:0.0001\n",
      "Epoch 31, Step: 304, Loss: 0.011578335426747799, Lr:0.0001\n",
      "Epoch 31, Step: 305, Loss: 0.03423241525888443, Lr:0.0001\n",
      "Epoch 31, Step: 306, Loss: 0.09533647447824478, Lr:0.0001\n",
      "Epoch 31, Step: 307, Loss: 0.012589134275913239, Lr:0.0001\n",
      "Epoch 31, Step: 308, Loss: 0.0062132650054991245, Lr:0.0001\n",
      "Epoch 31, Step: 309, Loss: 0.12516741454601288, Lr:0.0001\n",
      "Epoch 31, Step: 310, Loss: 0.05280235409736633, Lr:0.0001\n",
      "Epoch 31, Step: 311, Loss: 0.008828681893646717, Lr:0.0001\n",
      "Epoch 31, Step: 312, Loss: 0.003270781831815839, Lr:0.0001\n",
      "Epoch 31, Step: 313, Loss: 0.023247014731168747, Lr:0.0001\n",
      "Epoch 31, Step: 314, Loss: 0.0052039106376469135, Lr:0.0001\n",
      "Epoch 31, Step: 315, Loss: 0.00301041966304183, Lr:0.0001\n",
      "Epoch 31, Step: 316, Loss: 0.0015383628197014332, Lr:0.0001\n",
      "Epoch 31, Step: 317, Loss: 0.08521610498428345, Lr:0.0001\n",
      "Epoch 31, Step: 318, Loss: 0.024874825030565262, Lr:0.0001\n",
      "Epoch 31, Step: 319, Loss: 0.002535443054512143, Lr:0.0001\n",
      "Epoch 31, Step: 320, Loss: 0.041006337851285934, Lr:0.0001\n",
      "Epoch 31, Step: 321, Loss: 0.2562977373600006, Lr:0.0001\n",
      "Epoch 31, Step: 322, Loss: 0.046493079513311386, Lr:0.0001\n",
      "Epoch 31, Step: 323, Loss: 0.021486369892954826, Lr:0.0001\n",
      "Epoch 31, Step: 324, Loss: 0.08074403554201126, Lr:0.0001\n",
      "Epoch 31, Step: 325, Loss: 0.1740107238292694, Lr:0.0001\n",
      "Epoch 31, Step: 326, Loss: 0.030029231682419777, Lr:0.0001\n",
      "Epoch 31, Step: 327, Loss: 0.12214713543653488, Lr:0.0001\n",
      "Epoch 31, Step: 328, Loss: 0.06548409163951874, Lr:0.0001\n",
      "Epoch 31, Step: 329, Loss: 0.0019875760190188885, Lr:0.0001\n",
      "Epoch 31, Step: 330, Loss: 0.14355608820915222, Lr:0.0001\n",
      "Epoch 31, Step: 331, Loss: 0.10472486913204193, Lr:0.0001\n",
      "Epoch 31, Step: 332, Loss: 0.058873940259218216, Lr:0.0001\n",
      "Epoch 31, Step: 333, Loss: 0.01929287426173687, Lr:0.0001\n",
      "Epoch 31, Step: 334, Loss: 0.006704198662191629, Lr:0.0001\n",
      "Epoch 31, Step: 335, Loss: 0.08467858284711838, Lr:0.0001\n",
      "Epoch 31, Step: 336, Loss: 0.02464444562792778, Lr:0.0001\n",
      "Epoch 31, Step: 337, Loss: 0.0034590940922498703, Lr:0.0001\n",
      "Epoch 31, Step: 338, Loss: 0.351565957069397, Lr:0.0001\n",
      "Epoch 31, Step: 339, Loss: 0.02104608714580536, Lr:0.0001\n",
      "Epoch 31, Step: 340, Loss: 0.009489831514656544, Lr:0.0001\n",
      "Epoch 31, Step: 341, Loss: 0.020040001720190048, Lr:0.0001\n",
      "Epoch 31, Step: 342, Loss: 0.1502387970685959, Lr:0.0001\n",
      "Epoch 31, Step: 343, Loss: 0.020405685529112816, Lr:0.0001\n",
      "Epoch 31, Step: 344, Loss: 0.017198404297232628, Lr:0.0001\n",
      "Epoch 31, Step: 345, Loss: 0.009458490647375584, Lr:0.0001\n",
      "Epoch 31, Step: 346, Loss: 0.3237704932689667, Lr:0.0001\n",
      "Epoch 31, Step: 347, Loss: 0.0013380255550146103, Lr:0.0001\n",
      "Epoch 31, Step: 348, Loss: 0.020576659590005875, Lr:0.0001\n",
      "Epoch 31, Step: 349, Loss: 0.015560939908027649, Lr:0.0001\n",
      "Epoch 31, Step: 350, Loss: 0.02993427962064743, Lr:0.0001\n",
      "Epoch 31, Step: 351, Loss: 0.05001289024949074, Lr:0.0001\n",
      "Epoch 31, Step: 352, Loss: 0.1138499304652214, Lr:0.0001\n",
      "Epoch 31, Step: 353, Loss: 0.0004997969372197986, Lr:0.0001\n",
      "Epoch 31, Step: 354, Loss: 0.047433022409677505, Lr:0.0001\n",
      "Epoch 31, Step: 355, Loss: 0.0028066064696758986, Lr:0.0001\n",
      "Epoch 31, Step: 356, Loss: 0.0065672751516103745, Lr:0.0001\n",
      "Epoch 31, Step: 357, Loss: 0.12116335332393646, Lr:0.0001\n",
      "Epoch 31, Step: 358, Loss: 0.001173041993752122, Lr:0.0001\n",
      "Epoch 31, Step: 359, Loss: 0.1285601258277893, Lr:0.0001\n",
      "Epoch 31, Step: 360, Loss: 0.006735170725733042, Lr:0.0001\n",
      "Epoch 31, Step: 361, Loss: 0.055040206760168076, Lr:0.0001\n",
      "Epoch 31, Step: 362, Loss: 0.05991840362548828, Lr:0.0001\n",
      "Epoch 31, Step: 363, Loss: 0.13915356993675232, Lr:0.0001\n",
      "Epoch 31, Step: 364, Loss: 0.008461595512926579, Lr:0.0001\n",
      "Epoch 31, Step: 365, Loss: 0.021378731355071068, Lr:0.0001\n",
      "Epoch 31, Step: 366, Loss: 0.034280627965927124, Lr:0.0001\n",
      "Epoch 31, Step: 367, Loss: 0.05857837572693825, Lr:0.0001\n",
      "Epoch 31, Step: 368, Loss: 0.1637435108423233, Lr:0.0001\n",
      "Epoch 31, Step: 369, Loss: 0.015774963423609734, Lr:0.0001\n",
      "Epoch 31, Step: 370, Loss: 0.013250556774437428, Lr:0.0001\n",
      "Epoch 31, Step: 371, Loss: 0.013049756176769733, Lr:0.0001\n",
      "Epoch 31, Step: 372, Loss: 0.19749200344085693, Lr:0.0001\n",
      "Epoch 31, Step: 373, Loss: 0.007323089055716991, Lr:0.0001\n",
      "Epoch 31, Step: 374, Loss: 0.01733887940645218, Lr:0.0001\n",
      "Epoch 31, Step: 375, Loss: 0.009693633764982224, Lr:0.0001\n",
      "Epoch 31, Step: 376, Loss: 0.004954962059855461, Lr:0.0001\n",
      "Epoch 31, Step: 377, Loss: 0.16563057899475098, Lr:0.0001\n",
      "Epoch 31, Step: 378, Loss: 0.024103304371237755, Lr:0.0001\n",
      "Epoch 31, Step: 379, Loss: 0.05694160237908363, Lr:0.0001\n",
      "Epoch 31, Step: 380, Loss: 0.15632230043411255, Lr:0.0001\n",
      "Epoch 31, Step: 381, Loss: 0.010045886039733887, Lr:0.0001\n",
      "Epoch 31, Step: 382, Loss: 0.1303703486919403, Lr:0.0001\n",
      "Epoch 31, Step: 383, Loss: 0.019762177020311356, Lr:0.0001\n",
      "Epoch 31, Step: 384, Loss: 0.021248051896691322, Lr:0.0001\n",
      "Epoch 31, Step: 385, Loss: 0.010125279426574707, Lr:0.0001\n",
      "Epoch 31, Step: 386, Loss: 0.05548567324876785, Lr:0.0001\n",
      "Epoch 31, Step: 387, Loss: 0.04731573909521103, Lr:0.0001\n",
      "Epoch 31, Step: 388, Loss: 0.006609130650758743, Lr:0.0001\n",
      "Epoch 31, Step: 389, Loss: 0.0017810157733038068, Lr:0.0001\n",
      "Epoch 31, Step: 390, Loss: 0.005769140552729368, Lr:0.0001\n",
      "Epoch 31, Step: 391, Loss: 0.05721121281385422, Lr:0.0001\n",
      "Epoch 31, Step: 392, Loss: 0.04562462493777275, Lr:0.0001\n",
      "Epoch 31, Step: 393, Loss: 0.00463462620973587, Lr:0.0001\n",
      "Epoch 31, Step: 394, Loss: 0.009479000233113766, Lr:0.0001\n",
      "Epoch 31, Step: 395, Loss: 0.03201228752732277, Lr:0.0001\n",
      "Epoch 31, Step: 396, Loss: 0.029147962108254433, Lr:0.0001\n",
      "Epoch 31, Step: 397, Loss: 0.04004440829157829, Lr:0.0001\n",
      "Epoch 31, Step: 398, Loss: 0.05121521279215813, Lr:0.0001\n",
      "Epoch 31, Step: 399, Loss: 0.015507858246564865, Lr:0.0001\n",
      "Epoch 31, Step: 400, Loss: 0.011466547846794128, Lr:0.0001\n",
      "Epoch 31, Step: 401, Loss: 0.0007280632853507996, Lr:0.0001\n",
      "Epoch 31, Step: 402, Loss: 0.03236860781908035, Lr:0.0001\n",
      "Epoch 31, Step: 403, Loss: 0.008119501173496246, Lr:0.0001\n",
      "Epoch 31, Step: 404, Loss: 0.02997119538486004, Lr:0.0001\n",
      "Epoch 31, Step: 405, Loss: 0.07940724492073059, Lr:0.0001\n",
      "Epoch 31, Step: 406, Loss: 0.23136594891548157, Lr:0.0001\n",
      "Epoch 31, Step: 407, Loss: 0.009426621720194817, Lr:0.0001\n",
      "Epoch 31, Step: 408, Loss: 0.043979741632938385, Lr:0.0001\n",
      "Epoch 31, Step: 409, Loss: 0.044588346034288406, Lr:0.0001\n",
      "Epoch 31, Step: 410, Loss: 0.054339099675416946, Lr:0.0001\n",
      "Epoch 31, Step: 411, Loss: 0.0756494551897049, Lr:0.0001\n",
      "Epoch 31, Step: 412, Loss: 0.06781988590955734, Lr:0.0001\n",
      "Epoch 31, Step: 413, Loss: 0.037439338862895966, Lr:0.0001\n",
      "Epoch 31, Step: 414, Loss: 0.0038050650618970394, Lr:0.0001\n",
      "Epoch 31, Step: 415, Loss: 0.23851284384727478, Lr:0.0001\n",
      "Epoch 31, Step: 416, Loss: 0.23316453397274017, Lr:0.0001\n",
      "Epoch 31, Step: 417, Loss: 0.0011102407006546855, Lr:0.0001\n",
      "Epoch 31, Step: 418, Loss: 0.007535796612501144, Lr:0.0001\n",
      "Epoch 31, Step: 419, Loss: 0.009769321419298649, Lr:0.0001\n",
      "Epoch 31, Step: 420, Loss: 0.010359121486544609, Lr:0.0001\n",
      "Epoch 31, Step: 421, Loss: 0.0052186669781804085, Lr:0.0001\n",
      "Epoch 31, Step: 422, Loss: 0.009807838127017021, Lr:0.0001\n",
      "Epoch 31, Step: 423, Loss: 0.0015546452486887574, Lr:0.0001\n",
      "Epoch 31, Step: 424, Loss: 0.013352843001484871, Lr:0.0001\n",
      "Epoch 31, Step: 425, Loss: 0.15511523187160492, Lr:0.0001\n",
      "Epoch 31, Step: 426, Loss: 0.09848683327436447, Lr:0.0001\n",
      "Epoch 31, Step: 427, Loss: 0.12793688476085663, Lr:0.0001\n",
      "Epoch 31, Step: 428, Loss: 0.006147636100649834, Lr:0.0001\n",
      "Epoch 31, Step: 429, Loss: 0.012706284411251545, Lr:0.0001\n",
      "Epoch 31, Step: 430, Loss: 0.04790712893009186, Lr:0.0001\n",
      "Epoch 31, Step: 431, Loss: 0.014389123767614365, Lr:0.0001\n",
      "Epoch 31, Step: 432, Loss: 0.021992448717355728, Lr:0.0001\n",
      "Epoch 31, Step: 433, Loss: 0.011115405708551407, Lr:0.0001\n",
      "Epoch 31, Step: 434, Loss: 0.007189001888036728, Lr:0.0001\n",
      "Epoch 31, Step: 435, Loss: 0.019520699977874756, Lr:0.0001\n",
      "Epoch 31, Step: 436, Loss: 0.01328385528177023, Lr:0.0001\n",
      "Epoch 31, Step: 437, Loss: 0.010395452380180359, Lr:0.0001\n",
      "Epoch 31, Step: 438, Loss: 0.002909822156652808, Lr:0.0001\n",
      "Epoch 31, Step: 439, Loss: 0.2635820209980011, Lr:0.0001\n",
      "Epoch 31, Step: 440, Loss: 0.011375868692994118, Lr:0.0001\n",
      "Epoch 31, Step: 441, Loss: 0.07336313277482986, Lr:0.0001\n",
      "Epoch 31, Step: 442, Loss: 0.008301806636154652, Lr:0.0001\n",
      "Epoch 31, Step: 443, Loss: 0.02049725130200386, Lr:0.0001\n",
      "Epoch 31, Step: 444, Loss: 0.001296411850489676, Lr:0.0001\n",
      "Epoch 31, Step: 445, Loss: 0.00012886362674180418, Lr:0.0001\n",
      "Epoch 31, Step: 446, Loss: 0.0399538055062294, Lr:0.0001\n",
      "Epoch 31, Step: 447, Loss: 0.00815898273140192, Lr:0.0001\n",
      "Epoch 31, Step: 448, Loss: 0.004995871800929308, Lr:0.0001\n",
      "Epoch 31, Step: 449, Loss: 0.0015213818987831473, Lr:0.0001\n",
      "Epoch 31, Step: 450, Loss: 0.05186893790960312, Lr:0.0001\n",
      "Epoch 31, Step: 451, Loss: 0.01698143407702446, Lr:0.0001\n",
      "Epoch 31, Step: 452, Loss: 0.14733560383319855, Lr:0.0001\n",
      "Epoch 31, Step: 453, Loss: 0.13546955585479736, Lr:0.0001\n",
      "Epoch 31, Step: 454, Loss: 0.023018278181552887, Lr:0.0001\n",
      "Epoch 31, Step: 455, Loss: 0.029218370094895363, Lr:0.0001\n",
      "Epoch 31, Step: 456, Loss: 0.009506386704742908, Lr:0.0001\n",
      "Epoch 31, Step: 457, Loss: 0.012061936780810356, Lr:0.0001\n",
      "Epoch 31, Step: 458, Loss: 0.14196330308914185, Lr:0.0001\n",
      "Epoch 31, Step: 459, Loss: 0.011708391830325127, Lr:0.0001\n",
      "Epoch 31, Step: 460, Loss: 0.13934239745140076, Lr:0.0001\n",
      "Epoch 31, Step: 461, Loss: 0.008529935032129288, Lr:0.0001\n",
      "Epoch 31, Step: 462, Loss: 0.002074342453852296, Lr:0.0001\n",
      "Epoch 31, Step: 463, Loss: 0.1521064043045044, Lr:0.0001\n",
      "Epoch 31, Step: 464, Loss: 0.010361747816205025, Lr:0.0001\n",
      "Epoch 31, Step: 465, Loss: 0.0741991475224495, Lr:0.0001\n",
      "Epoch 31, Step: 466, Loss: 0.11020901799201965, Lr:0.0001\n",
      "Epoch 31, Step: 467, Loss: 0.03125927224755287, Lr:0.0001\n",
      "Epoch 31, Step: 468, Loss: 0.3549465239048004, Lr:0.0001\n",
      "Epoch 31, Step: 469, Loss: 0.11458674818277359, Lr:0.0001\n",
      "Epoch 31, Step: 470, Loss: 0.0080843735486269, Lr:0.0001\n",
      "Epoch 31, Step: 471, Loss: 0.0007890050765126944, Lr:0.0001\n",
      "Epoch 31, Step: 472, Loss: 0.03869933634996414, Lr:0.0001\n",
      "Epoch 31, Step: 473, Loss: 0.007346209604293108, Lr:0.0001\n",
      "Epoch 31, Step: 474, Loss: 0.19349630177021027, Lr:0.0001\n",
      "Epoch 31, Step: 475, Loss: 0.001329391379840672, Lr:0.0001\n",
      "Epoch 31, Step: 476, Loss: 0.0033929976634681225, Lr:0.0001\n",
      "Epoch 31, Step: 477, Loss: 0.012500879354774952, Lr:0.0001\n",
      "Epoch 31, Step: 478, Loss: 0.00641774432733655, Lr:0.0001\n",
      "Epoch 31, Step: 479, Loss: 0.053614288568496704, Lr:0.0001\n",
      "Epoch 31, Step: 480, Loss: 0.015471120364964008, Lr:0.0001\n",
      "Epoch 31, Step: 481, Loss: 0.009950419887900352, Lr:0.0001\n",
      "Epoch 31, Step: 482, Loss: 0.06860195100307465, Lr:0.0001\n",
      "Epoch 31, Step: 483, Loss: 0.005144668277353048, Lr:0.0001\n",
      "Epoch 31, Step: 484, Loss: 0.03957848995923996, Lr:0.0001\n",
      "Epoch 31, Step: 485, Loss: 0.010557190515100956, Lr:0.0001\n",
      "Epoch 31, Step: 486, Loss: 0.002472410211339593, Lr:0.0001\n",
      "Epoch 31, Step: 487, Loss: 0.006982467137277126, Lr:0.0001\n",
      "Epoch 31, Step: 488, Loss: 0.009861708618700504, Lr:0.0001\n",
      "Epoch 31, Step: 489, Loss: 0.0052825952880084515, Lr:0.0001\n",
      "Epoch 31, Step: 490, Loss: 0.00991537980735302, Lr:0.0001\n",
      "Epoch 31, Step: 491, Loss: 0.03808791562914848, Lr:0.0001\n",
      "Epoch 31, Step: 492, Loss: 0.01957702450454235, Lr:0.0001\n",
      "Epoch 31, Step: 493, Loss: 0.202232226729393, Lr:0.0001\n",
      "Epoch 31, Step: 494, Loss: 0.014473739080131054, Lr:0.0001\n",
      "Epoch 31, Step: 495, Loss: 0.12069939076900482, Lr:0.0001\n",
      "Epoch 31, Step: 496, Loss: 0.004056814592331648, Lr:0.0001\n",
      "Epoch 31, Step: 497, Loss: 0.03520306944847107, Lr:0.0001\n",
      "Epoch 31, Step: 498, Loss: 0.18453393876552582, Lr:0.0001\n",
      "Epoch 31, Step: 499, Loss: 0.011218440718948841, Lr:0.0001\n",
      "Epoch 31, Step: 500, Loss: 0.02144540287554264, Lr:0.0001\n",
      "Epoch 31, Step: 501, Loss: 0.02030150033533573, Lr:0.0001\n",
      "Epoch 31, Step: 502, Loss: 0.002050342969596386, Lr:0.0001\n",
      "Epoch 31, Step: 503, Loss: 0.07893089205026627, Lr:0.0001\n",
      "Epoch 31, Step: 504, Loss: 0.06607044488191605, Lr:0.0001\n",
      "Epoch 31, Step: 505, Loss: 0.005180553998798132, Lr:0.0001\n",
      "Epoch 31, Step: 506, Loss: 0.020470477640628815, Lr:0.0001\n",
      "Epoch 31, Step: 507, Loss: 0.03216411545872688, Lr:0.0001\n",
      "Epoch 31, Step: 508, Loss: 0.11305895447731018, Lr:0.0001\n",
      "Epoch 31, Step: 509, Loss: 0.007654671091586351, Lr:0.0001\n",
      "Epoch 31, Step: 510, Loss: 0.00428619422018528, Lr:0.0001\n",
      "Epoch 31, Step: 511, Loss: 0.004663586150854826, Lr:0.0001\n",
      "Epoch 31, Step: 512, Loss: 0.14038167893886566, Lr:0.0001\n",
      "Epoch 31, Step: 513, Loss: 0.017110900953412056, Lr:0.0001\n",
      "Epoch 31, Step: 514, Loss: 0.0031556077301502228, Lr:0.0001\n",
      "Epoch 31, Step: 515, Loss: 0.07841720432043076, Lr:0.0001\n",
      "Epoch 31, Step: 516, Loss: 0.00261818990111351, Lr:0.0001\n",
      "Epoch 31, Step: 517, Loss: 0.024059604853391647, Lr:0.0001\n",
      "Epoch 31, Step: 518, Loss: 0.21340340375900269, Lr:0.0001\n",
      "Epoch 31, Step: 519, Loss: 0.04568836838006973, Lr:0.0001\n",
      "Epoch 31, Step: 520, Loss: 0.0025838783476501703, Lr:0.0001\n",
      "Epoch 31, Step: 521, Loss: 0.09239283949136734, Lr:0.0001\n",
      "Epoch 31, Step: 522, Loss: 0.0011180371511727571, Lr:0.0001\n",
      "Epoch 31, Step: 523, Loss: 0.0013789356453344226, Lr:0.0001\n",
      "Epoch 31, Step: 524, Loss: 0.07985526323318481, Lr:0.0001\n",
      "Epoch 31, Step: 525, Loss: 0.002228187397122383, Lr:0.0001\n",
      "Epoch 31, Step: 526, Loss: 0.01264231652021408, Lr:0.0001\n",
      "Epoch 31, Step: 527, Loss: 0.03368318825960159, Lr:0.0001\n",
      "Epoch 31, Step: 528, Loss: 0.010928034782409668, Lr:0.0001\n",
      "Epoch 31, Step: 529, Loss: 0.00948403775691986, Lr:0.0001\n",
      "Epoch 31, Step: 530, Loss: 0.006860522553324699, Lr:0.0001\n",
      "Epoch 31, Step: 531, Loss: 0.024213530123233795, Lr:0.0001\n",
      "Epoch 31, Step: 532, Loss: 0.0149793466553092, Lr:0.0001\n",
      "Epoch 31, Step: 533, Loss: 0.013044447638094425, Lr:0.0001\n",
      "Epoch 31, Step: 534, Loss: 0.008094160817563534, Lr:0.0001\n",
      "Epoch 31, Step: 535, Loss: 0.0029931743629276752, Lr:0.0001\n",
      "Epoch 31, Step: 536, Loss: 0.00036049701157025993, Lr:0.0001\n",
      "Epoch 31, Step: 537, Loss: 0.023459527641534805, Lr:0.0001\n",
      "Epoch 31, Step: 538, Loss: 0.0035894708707928658, Lr:0.0001\n",
      "Epoch 31, Step: 539, Loss: 0.21775437891483307, Lr:0.0001\n",
      "Epoch 31, Step: 540, Loss: 0.19415992498397827, Lr:0.0001\n",
      "Epoch 31, Step: 541, Loss: 0.0014708932721987367, Lr:0.0001\n",
      "Epoch 31, Step: 542, Loss: 0.05081837624311447, Lr:0.0001\n",
      "Epoch 31, Step: 543, Loss: 0.011499798856675625, Lr:0.0001\n",
      "Epoch 31, Step: 544, Loss: 0.03684062510728836, Lr:0.0001\n",
      "Epoch 31, Step: 545, Loss: 0.11071457713842392, Lr:0.0001\n",
      "Epoch 31, Step: 546, Loss: 0.003073473460972309, Lr:0.0001\n",
      "Epoch 31, Step: 547, Loss: 0.002829003846272826, Lr:0.0001\n",
      "Epoch 31, Step: 548, Loss: 0.08296343684196472, Lr:0.0001\n",
      "Epoch 31, Step: 549, Loss: 0.13332490622997284, Lr:0.0001\n",
      "Epoch 31, Step: 550, Loss: 0.08065998554229736, Lr:0.0001\n",
      "Epoch 31, Step: 551, Loss: 0.10480125993490219, Lr:0.0001\n",
      "Epoch 31, Step: 552, Loss: 0.066794753074646, Lr:0.0001\n",
      "Epoch 31, Step: 553, Loss: 0.005090879742056131, Lr:0.0001\n",
      "Epoch 31, Step: 554, Loss: 0.07685504853725433, Lr:0.0001\n",
      "Epoch 31, Step: 555, Loss: 0.015032682567834854, Lr:0.0001\n",
      "Epoch 31, Step: 556, Loss: 0.03708753362298012, Lr:0.0001\n",
      "Epoch 31, Step: 557, Loss: 0.04427105188369751, Lr:0.0001\n",
      "Epoch 31, Step: 558, Loss: 0.003498007310554385, Lr:0.0001\n",
      "Epoch 31, Step: 559, Loss: 0.14091111719608307, Lr:0.0001\n",
      "Epoch 31, Step: 560, Loss: 0.3836592733860016, Lr:0.0001\n",
      "Epoch 31, Step: 561, Loss: 0.002693983493372798, Lr:0.0001\n",
      "Epoch 31, Step: 562, Loss: 0.005969746503978968, Lr:0.0001\n",
      "Epoch 31, Step: 563, Loss: 0.1000765711069107, Lr:0.0001\n",
      "Epoch 31, Step: 564, Loss: 0.22750841081142426, Lr:0.0001\n",
      "Epoch 31, Step: 565, Loss: 0.0010212250053882599, Lr:0.0001\n",
      "Epoch 31, Step: 566, Loss: 0.09430321305990219, Lr:0.0001\n",
      "Epoch 31, Step: 567, Loss: 0.017682814970612526, Lr:0.0001\n",
      "Epoch 31, Step: 568, Loss: 0.009572920389473438, Lr:0.0001\n",
      "Epoch 31, Step: 569, Loss: 0.011337864212691784, Lr:0.0001\n",
      "Epoch 31, Step: 570, Loss: 0.004922088235616684, Lr:0.0001\n",
      "Epoch 31, Step: 571, Loss: 0.012446965090930462, Lr:0.0001\n",
      "Epoch 31, Step: 572, Loss: 0.011206896975636482, Lr:0.0001\n",
      "Epoch 31, Step: 573, Loss: 0.3515464663505554, Lr:0.0001\n",
      "Epoch 31, Step: 574, Loss: 0.024009892717003822, Lr:0.0001\n",
      "Epoch 31, Step: 575, Loss: 0.011712172999978065, Lr:0.0001\n",
      "Epoch 31, Step: 576, Loss: 0.0055310772731900215, Lr:0.0001\n",
      "Epoch 31, Step: 577, Loss: 0.015000049956142902, Lr:0.0001\n",
      "Epoch 31, Step: 578, Loss: 0.20842501521110535, Lr:0.0001\n",
      "Epoch 31, Step: 579, Loss: 0.004861074965447187, Lr:0.0001\n",
      "Epoch 31, Step: 580, Loss: 0.01098914910107851, Lr:0.0001\n",
      "Epoch 31, Step: 581, Loss: 0.05715984106063843, Lr:0.0001\n",
      "Epoch 31, Step: 582, Loss: 0.3291011154651642, Lr:0.0001\n",
      "Epoch 31, Step: 583, Loss: 0.027380920946598053, Lr:0.0001\n",
      "Epoch 31, Step: 584, Loss: 0.08358106762170792, Lr:0.0001\n",
      "Epoch 31, Step: 585, Loss: 0.28590089082717896, Lr:0.0001\n",
      "Epoch 31, Step: 586, Loss: 0.009470992721617222, Lr:0.0001\n",
      "Epoch 31, Step: 587, Loss: 0.004198723006993532, Lr:0.0001\n",
      "Epoch 31, Step: 588, Loss: 0.06612996011972427, Lr:0.0001\n",
      "Epoch 31, Step: 589, Loss: 0.008705772459506989, Lr:0.0001\n",
      "Epoch 31, Step: 590, Loss: 0.3560805022716522, Lr:0.0001\n",
      "Epoch 31, Step: 591, Loss: 0.11183854192495346, Lr:0.0001\n",
      "Epoch 31, Step: 592, Loss: 0.11987683176994324, Lr:0.0001\n",
      "Epoch 31, Step: 593, Loss: 0.16454346477985382, Lr:0.0001\n",
      "Epoch 31, Step: 594, Loss: 0.1077464297413826, Lr:0.0001\n",
      "Epoch 31, Step: 595, Loss: 0.02532842382788658, Lr:0.0001\n",
      "Epoch 31, Step: 596, Loss: 0.04354498162865639, Lr:0.0001\n",
      "Epoch 31, Step: 597, Loss: 0.009068510495126247, Lr:0.0001\n",
      "Epoch 31, Step: 598, Loss: 0.0019251632038503885, Lr:0.0001\n",
      "Epoch 31, Step: 599, Loss: 0.05670813471078873, Lr:0.0001\n",
      "Epoch 31, Step: 600, Loss: 0.2763407528400421, Lr:0.0001\n",
      "Epoch 31, Step: 601, Loss: 0.016273081302642822, Lr:0.0001\n",
      "Epoch 31, Step: 602, Loss: 0.18700139224529266, Lr:0.0001\n",
      "Epoch 31, Step: 603, Loss: 0.0211151372641325, Lr:0.0001\n",
      "Epoch 31, Step: 604, Loss: 0.0027931821532547474, Lr:0.0001\n",
      "Epoch 31, Step: 605, Loss: 0.06211976706981659, Lr:0.0001\n",
      "Epoch 31, Step: 606, Loss: 0.0019663372077047825, Lr:0.0001\n",
      "Epoch 31, Step: 607, Loss: 0.004776119254529476, Lr:0.0001\n",
      "Epoch 31, Step: 608, Loss: 0.010920182801783085, Lr:0.0001\n",
      "Epoch 31, Step: 609, Loss: 0.36780792474746704, Lr:0.0001\n",
      "Epoch 31, Step: 610, Loss: 0.10989802330732346, Lr:0.0001\n",
      "Epoch 31, Step: 611, Loss: 0.008766401559114456, Lr:0.0001\n",
      "Epoch 31, Step: 612, Loss: 0.0364314429461956, Lr:0.0001\n",
      "Epoch 31, Step: 613, Loss: 0.0029408568516373634, Lr:0.0001\n",
      "Epoch 31, Step: 614, Loss: 0.04340647906064987, Lr:0.0001\n",
      "Epoch 31, Step: 615, Loss: 0.012427296489477158, Lr:0.0001\n",
      "Epoch 31, Step: 616, Loss: 0.0504455529153347, Lr:0.0001\n",
      "Epoch 31, Step: 617, Loss: 0.051445670425891876, Lr:0.0001\n",
      "Epoch 31, Step: 618, Loss: 0.0013993395259603858, Lr:0.0001\n",
      "Epoch 31, Step: 619, Loss: 0.1032990887761116, Lr:0.0001\n",
      "Epoch 31, Step: 620, Loss: 0.042983442544937134, Lr:0.0001\n",
      "Epoch 31, Step: 621, Loss: 0.07198494672775269, Lr:0.0001\n",
      "Epoch 31, Step: 622, Loss: 0.005424070172011852, Lr:0.0001\n",
      "Epoch 31, Step: 623, Loss: 0.2086716741323471, Lr:0.0001\n",
      "Epoch 31, Step: 624, Loss: 0.019898807629942894, Lr:0.0001\n",
      "Epoch 31, Step: 625, Loss: 0.0482868067920208, Lr:0.0001\n",
      "Epoch 31, Step: 626, Loss: 0.060226183384656906, Lr:0.0001\n",
      "Epoch 31, Step: 627, Loss: 0.25661665201187134, Lr:0.0001\n",
      "Epoch 31, Step: 628, Loss: 0.012343683280050755, Lr:0.0001\n",
      "Epoch 31, Step: 629, Loss: 0.1850252002477646, Lr:0.0001\n",
      "Epoch 31, Step: 630, Loss: 0.10700882226228714, Lr:0.0001\n",
      "Epoch 31, Step: 631, Loss: 0.049967505037784576, Lr:0.0001\n",
      "Epoch 31, Step: 632, Loss: 0.0060080294497311115, Lr:0.0001\n",
      "Epoch 31, Step: 633, Loss: 0.036144088953733444, Lr:0.0001\n",
      "Epoch 31, Step: 634, Loss: 0.05608055740594864, Lr:0.0001\n",
      "Epoch 31, Step: 635, Loss: 0.4014884829521179, Lr:0.0001\n",
      "Epoch 31, Step: 636, Loss: 0.17705316841602325, Lr:0.0001\n",
      "Epoch 31, Step: 637, Loss: 0.19377438724040985, Lr:0.0001\n",
      "Epoch 31, Step: 638, Loss: 0.01690533384680748, Lr:0.0001\n",
      "Epoch 31, Step: 639, Loss: 0.016336577013134956, Lr:0.0001\n",
      "Epoch 31, Step: 640, Loss: 0.008873608894646168, Lr:0.0001\n",
      "Epoch 31, Step: 641, Loss: 0.002575283171609044, Lr:0.0001\n",
      "Epoch 31, Step: 642, Loss: 0.0019512157887220383, Lr:0.0001\n",
      "Epoch 31, Step: 643, Loss: 0.04345156252384186, Lr:0.0001\n",
      "Epoch 31, Step: 644, Loss: 0.08328015357255936, Lr:0.0001\n",
      "Epoch 31, Step: 645, Loss: 0.02711530402302742, Lr:0.0001\n",
      "Epoch 31, Step: 646, Loss: 0.10424329340457916, Lr:0.0001\n",
      "Epoch 31, Step: 647, Loss: 0.03609655052423477, Lr:0.0001\n",
      "Epoch 31, Step: 648, Loss: 0.010266968049108982, Lr:0.0001\n",
      "Epoch 31, Step: 649, Loss: 0.0343593992292881, Lr:0.0001\n",
      "Epoch 31, Step: 650, Loss: 0.05939595401287079, Lr:0.0001\n",
      "Epoch 31, Step: 651, Loss: 0.012432119809091091, Lr:0.0001\n",
      "Epoch 31, Step: 652, Loss: 0.008342944085597992, Lr:0.0001\n",
      "Epoch 31, Step: 653, Loss: 0.00473799416795373, Lr:0.0001\n",
      "Epoch 31, Step: 654, Loss: 0.034333109855651855, Lr:0.0001\n",
      "Epoch 31, Step: 655, Loss: 0.02114453725516796, Lr:0.0001\n",
      "Epoch 31, Step: 656, Loss: 0.01344942208379507, Lr:0.0001\n",
      "Epoch 31, Step: 657, Loss: 0.0021185758523643017, Lr:0.0001\n",
      "Epoch 31, Step: 658, Loss: 0.015303621999919415, Lr:0.0001\n",
      "Epoch 31, Step: 659, Loss: 0.013861080631613731, Lr:0.0001\n",
      "Epoch 31, Step: 660, Loss: 0.044868145138025284, Lr:0.0001\n",
      "Epoch 31, Step: 661, Loss: 0.08591724187135696, Lr:0.0001\n",
      "Epoch 31, Step: 662, Loss: 0.014668971300125122, Lr:0.0001\n",
      "Epoch 31, Step: 663, Loss: 0.14620985090732574, Lr:0.0001\n",
      "Epoch 31, Step: 664, Loss: 0.003119493369013071, Lr:0.0001\n",
      "Epoch 31, Step: 665, Loss: 0.11570969223976135, Lr:0.0001\n",
      "Epoch 31, Step: 666, Loss: 0.3997802138328552, Lr:0.0001\n",
      "Epoch 31, Step: 667, Loss: 0.026497386395931244, Lr:0.0001\n",
      "Epoch 31, Step: 668, Loss: 0.06612388789653778, Lr:0.0001\n",
      "Epoch 31, Step: 669, Loss: 0.09788893908262253, Lr:0.0001\n",
      "Epoch 31, Step: 670, Loss: 0.032567352056503296, Lr:0.0001\n",
      "Epoch 31, Step: 671, Loss: 0.1668674498796463, Lr:0.0001\n",
      "Epoch 31, Step: 672, Loss: 0.01527106761932373, Lr:0.0001\n",
      "Epoch 31, Step: 673, Loss: 0.008936546742916107, Lr:0.0001\n",
      "Epoch 31, Step: 674, Loss: 0.006502895150333643, Lr:0.0001\n",
      "Epoch 31, Step: 675, Loss: 0.024980949237942696, Lr:0.0001\n",
      "Epoch 31, Step: 676, Loss: 0.04121960327029228, Lr:0.0001\n",
      "Epoch 31, Step: 677, Loss: 0.0010996888158842921, Lr:0.0001\n",
      "Epoch 31, Step: 678, Loss: 0.05676731839776039, Lr:0.0001\n",
      "Epoch 31, Step: 679, Loss: 0.020389724522829056, Lr:0.0001\n",
      "Epoch 31, Step: 680, Loss: 0.034750524908304214, Lr:0.0001\n",
      "Epoch 31, Step: 681, Loss: 0.010763606056571007, Lr:0.0001\n",
      "Epoch 31, Step: 682, Loss: 0.2821350693702698, Lr:0.0001\n",
      "Epoch 31, Step: 683, Loss: 0.007007970940321684, Lr:0.0001\n",
      "Epoch 31, Step: 684, Loss: 0.04675380885601044, Lr:0.0001\n",
      "Epoch 31, Step: 685, Loss: 0.05993986129760742, Lr:0.0001\n",
      "Epoch 31, Step: 686, Loss: 0.016240030527114868, Lr:0.0001\n",
      "Epoch 31, Step: 687, Loss: 0.08949011564254761, Lr:0.0001\n",
      "Epoch 31, Step: 688, Loss: 0.15729102492332458, Lr:0.0001\n",
      "Epoch 31, Step: 689, Loss: 0.07965117692947388, Lr:0.0001\n",
      "Epoch 31, Step: 690, Loss: 0.03483806550502777, Lr:0.0001\n",
      "Epoch 31, Step: 691, Loss: 0.06723744422197342, Lr:0.0001\n",
      "Epoch 31, Step: 692, Loss: 0.040270864963531494, Lr:0.0001\n",
      "Epoch 31, Step: 693, Loss: 0.06900002807378769, Lr:0.0001\n",
      "Epoch 31, Step: 694, Loss: 0.029681788757443428, Lr:0.0001\n",
      "Epoch 31, Step: 695, Loss: 0.014481359161436558, Lr:0.0001\n",
      "Epoch 31, Step: 696, Loss: 0.1557600349187851, Lr:0.0001\n",
      "Epoch 31, Step: 697, Loss: 0.020319536328315735, Lr:0.0001\n",
      "Epoch 31, Step: 698, Loss: 0.011308672837913036, Lr:0.0001\n",
      "Epoch 31, Step: 699, Loss: 0.23952575027942657, Lr:0.0001\n",
      "Epoch 31, Step: 700, Loss: 0.004737241193652153, Lr:0.0001\n",
      "Epoch 31, Step: 701, Loss: 0.03445058315992355, Lr:0.0001\n",
      "Epoch 31, Step: 702, Loss: 0.010204669088125229, Lr:0.0001\n",
      "Epoch 31, Step: 703, Loss: 0.06042606011033058, Lr:0.0001\n",
      "Epoch 31, Step: 704, Loss: 0.047113869339227676, Lr:0.0001\n",
      "Epoch 31, Step: 705, Loss: 0.1459020972251892, Lr:0.0001\n",
      "Epoch 31, Step: 706, Loss: 0.08167716860771179, Lr:0.0001\n",
      "Epoch 31, Step: 707, Loss: 0.004697817377746105, Lr:0.0001\n",
      "Epoch 31, Step: 708, Loss: 0.01867150142788887, Lr:0.0001\n",
      "Epoch 31, Step: 709, Loss: 0.10803938657045364, Lr:0.0001\n",
      "Epoch 31, Step: 710, Loss: 0.05789130926132202, Lr:0.0001\n",
      "Epoch 31, Step: 711, Loss: 0.006363176740705967, Lr:0.0001\n",
      "Epoch 31, Step: 712, Loss: 0.019127914682030678, Lr:0.0001\n",
      "Epoch 31, Step: 713, Loss: 0.05881738290190697, Lr:0.0001\n",
      "Epoch 31, Step: 714, Loss: 0.01729263737797737, Lr:0.0001\n",
      "Epoch 31, Step: 715, Loss: 0.011843297630548477, Lr:0.0001\n",
      "Epoch 31, Step: 716, Loss: 0.027594633400440216, Lr:0.0001\n",
      "Epoch 31, Step: 717, Loss: 0.04208435118198395, Lr:0.0001\n",
      "Epoch 31, Step: 718, Loss: 0.08393866568803787, Lr:0.0001\n",
      "Epoch 31, Step: 719, Loss: 0.33305463194847107, Lr:0.0001\n",
      "Epoch 31, Step: 720, Loss: 0.0025897512678056955, Lr:0.0001\n",
      "Epoch 31, Step: 721, Loss: 0.016701094806194305, Lr:0.0001\n",
      "Epoch 31, Step: 722, Loss: 0.017274988815188408, Lr:0.0001\n",
      "Epoch 31, Step: 723, Loss: 0.03243657574057579, Lr:0.0001\n",
      "Epoch 31, Step: 724, Loss: 0.030354544520378113, Lr:0.0001\n",
      "Epoch 31, Step: 725, Loss: 0.04125690087676048, Lr:0.0001\n",
      "Epoch 31, Step: 726, Loss: 0.033379215747117996, Lr:0.0001\n",
      "Epoch 31, Step: 727, Loss: 0.002132260240614414, Lr:0.0001\n",
      "Epoch 31, Step: 728, Loss: 0.0019864009227603674, Lr:0.0001\n",
      "Epoch 31, Step: 729, Loss: 0.19827957451343536, Lr:0.0001\n",
      "Epoch 31, Step: 730, Loss: 0.01297580823302269, Lr:0.0001\n",
      "Epoch 31, Step: 731, Loss: 0.005209533032029867, Lr:0.0001\n",
      "Epoch 31, Step: 732, Loss: 0.07173360139131546, Lr:0.0001\n",
      "Epoch 31, Step: 733, Loss: 0.03379746526479721, Lr:0.0001\n",
      "Epoch 31, Step: 734, Loss: 0.0341070294380188, Lr:0.0001\n",
      "Epoch 31, Step: 735, Loss: 0.1363120675086975, Lr:0.0001\n",
      "Epoch 31, Step: 736, Loss: 0.06948500871658325, Lr:0.0001\n",
      "Epoch 31, Step: 737, Loss: 0.08695670962333679, Lr:0.0001\n",
      "Epoch 31, Step: 738, Loss: 0.01814846135675907, Lr:0.0001\n",
      "Epoch 31, Step: 739, Loss: 0.18079060316085815, Lr:0.0001\n",
      "Epoch 31, Step: 740, Loss: 0.042603008449077606, Lr:0.0001\n",
      "Epoch 31, Step: 741, Loss: 0.007533110212534666, Lr:0.0001\n",
      "Epoch 31, Step: 742, Loss: 0.009201177395880222, Lr:0.0001\n",
      "Epoch 31, Step: 743, Loss: 0.2016286849975586, Lr:0.0001\n",
      "Epoch 31, Step: 744, Loss: 0.04460326209664345, Lr:0.0001\n",
      "Epoch 31, Step: 745, Loss: 0.1620682328939438, Lr:0.0001\n",
      "Epoch 31, Step: 746, Loss: 0.028203323483467102, Lr:0.0001\n",
      "Epoch 31, Step: 747, Loss: 0.052668508142232895, Lr:0.0001\n",
      "Epoch 31, Step: 748, Loss: 0.0062093110755085945, Lr:0.0001\n",
      "Epoch 31, Step: 749, Loss: 0.10894560068845749, Lr:0.0001\n",
      "Epoch 31, Step: 750, Loss: 0.027341118082404137, Lr:0.0001\n",
      "Epoch 31, Step: 751, Loss: 0.3320704996585846, Lr:0.0001\n",
      "Epoch 31, Step: 752, Loss: 0.04375089704990387, Lr:0.0001\n",
      "Epoch 31, Step: 753, Loss: 0.03911258652806282, Lr:0.0001\n",
      "Epoch 31, Step: 754, Loss: 0.005953394342213869, Lr:0.0001\n",
      "Epoch 31, Step: 755, Loss: 0.0013083097292110324, Lr:0.0001\n",
      "Epoch 31, Step: 756, Loss: 0.010921312496066093, Lr:0.0001\n",
      "Epoch 31, Step: 757, Loss: 0.011687732301652431, Lr:0.0001\n",
      "Epoch 31, Step: 758, Loss: 0.02386454865336418, Lr:0.0001\n",
      "Epoch 31, Step: 759, Loss: 0.0002713721478357911, Lr:0.0001\n",
      "Epoch 31, Step: 760, Loss: 0.2442759871482849, Lr:0.0001\n",
      "Epoch 31, Step: 761, Loss: 0.009277715347707272, Lr:0.0001\n",
      "Epoch 31, Step: 762, Loss: 0.013415445573627949, Lr:0.0001\n",
      "Epoch 31, Step: 763, Loss: 0.005429464392364025, Lr:0.0001\n",
      "Epoch 31, Step: 764, Loss: 0.03767240792512894, Lr:0.0001\n",
      "Epoch 31, Step: 765, Loss: 0.05366669222712517, Lr:0.0001\n",
      "Epoch 31, Step: 766, Loss: 0.08524342626333237, Lr:0.0001\n",
      "Epoch 31, Step: 767, Loss: 0.01739232800900936, Lr:0.0001\n",
      "Epoch 31, Step: 768, Loss: 0.2752001881599426, Lr:0.0001\n",
      "Epoch 31, Step: 769, Loss: 0.056431274861097336, Lr:0.0001\n",
      "Epoch 31, Step: 770, Loss: 0.12697391211986542, Lr:0.0001\n",
      "Epoch 31, Step: 771, Loss: 0.0375216007232666, Lr:0.0001\n",
      "Epoch 31, Step: 772, Loss: 0.02355981431901455, Lr:0.0001\n",
      "Epoch 31, Step: 773, Loss: 0.01051659882068634, Lr:0.0001\n",
      "Epoch 31, Step: 774, Loss: 0.01871870458126068, Lr:0.0001\n",
      "Epoch 31, Step: 775, Loss: 0.008491541258990765, Lr:0.0001\n",
      "Epoch 31, Step: 776, Loss: 0.008606190793216228, Lr:0.0001\n",
      "Epoch 31, Step: 777, Loss: 0.06444691866636276, Lr:0.0001\n",
      "Epoch 31, Step: 778, Loss: 0.023891177028417587, Lr:0.0001\n",
      "Epoch 31, Step: 779, Loss: 0.024782076478004456, Lr:0.0001\n",
      "Epoch 31, Step: 780, Loss: 0.01790948212146759, Lr:0.0001\n",
      "Epoch 31, Step: 781, Loss: 0.000382755883038044, Lr:0.0001\n",
      "Epoch 31, Step: 782, Loss: 0.008133366703987122, Lr:0.0001\n",
      "Epoch 31, Step: 783, Loss: 0.006716184318065643, Lr:0.0001\n",
      "Epoch 31, Step: 784, Loss: 0.147652268409729, Lr:0.0001\n",
      "Epoch 31, Step: 785, Loss: 0.04908004403114319, Lr:0.0001\n",
      "Epoch 31, Step: 786, Loss: 0.013014375232160091, Lr:0.0001\n",
      "Epoch 31, Step: 787, Loss: 0.0483870729804039, Lr:0.0001\n",
      "Epoch 31, Step: 788, Loss: 0.004512751940637827, Lr:0.0001\n",
      "Epoch 31, Step: 789, Loss: 0.050714969635009766, Lr:0.0001\n",
      "Epoch 31, Step: 790, Loss: 0.02266603149473667, Lr:0.0001\n",
      "Epoch 31, Step: 791, Loss: 0.033002812415361404, Lr:0.0001\n",
      "Epoch 31, Step: 792, Loss: 0.016987917944788933, Lr:0.0001\n",
      "Epoch 31, Step: 793, Loss: 0.017353150993585587, Lr:0.0001\n",
      "Epoch 31, Step: 794, Loss: 0.01944449543952942, Lr:0.0001\n",
      "Epoch 31, Step: 795, Loss: 0.06531556695699692, Lr:0.0001\n",
      "Epoch 31, Step: 796, Loss: 0.011120758019387722, Lr:0.0001\n",
      "Epoch 31, Step: 797, Loss: 0.01274821162223816, Lr:0.0001\n",
      "Epoch 31, Step: 798, Loss: 0.014879001304507256, Lr:0.0001\n",
      "Epoch 31, Step: 799, Loss: 0.05606739968061447, Lr:0.0001\n",
      "Epoch 31, Step: 800, Loss: 0.09344017505645752, Lr:0.0001\n",
      "Epoch 31, Step: 801, Loss: 0.0025599440559744835, Lr:0.0001\n",
      "Epoch 31, Step: 802, Loss: 0.00045544153545051813, Lr:0.0001\n",
      "Epoch 31, Step: 803, Loss: 0.0629836767911911, Lr:0.0001\n",
      "Epoch 31, Step: 804, Loss: 0.0020966946613043547, Lr:0.0001\n",
      "Epoch 31, Step: 805, Loss: 0.03580131009221077, Lr:0.0001\n",
      "Epoch 31, Step: 806, Loss: 0.08866120874881744, Lr:0.0001\n",
      "Epoch 31, Step: 807, Loss: 0.05015866085886955, Lr:0.0001\n",
      "Epoch 31, Step: 808, Loss: 0.05639590322971344, Lr:0.0001\n",
      "Epoch 31, Step: 809, Loss: 0.0015039565041661263, Lr:0.0001\n",
      "Epoch 31, Step: 810, Loss: 0.011102298274636269, Lr:0.0001\n",
      "Epoch 31, Step: 811, Loss: 0.055152859538793564, Lr:0.0001\n",
      "Epoch 31, Step: 812, Loss: 0.026203973218798637, Lr:0.0001\n",
      "Epoch 31, Step: 813, Loss: 0.3619229197502136, Lr:0.0001\n",
      "Epoch 31, Step: 814, Loss: 0.004170205909758806, Lr:0.0001\n",
      "Epoch 31, Step: 815, Loss: 0.016823912039399147, Lr:0.0001\n",
      "Epoch 31, Step: 816, Loss: 0.1579752266407013, Lr:0.0001\n",
      "Epoch 31, Step: 817, Loss: 0.08927465230226517, Lr:0.0001\n",
      "Epoch 31, Step: 818, Loss: 0.010521821677684784, Lr:0.0001\n",
      "Epoch 31, Step: 819, Loss: 0.0019489413825795054, Lr:0.0001\n",
      "Epoch 31, Step: 820, Loss: 0.053891684859991074, Lr:0.0001\n",
      "Epoch 31, Step: 821, Loss: 0.019087249413132668, Lr:0.0001\n",
      "Epoch 31, Step: 822, Loss: 0.38134703040122986, Lr:0.0001\n",
      "Epoch 31, Step: 823, Loss: 0.02522268146276474, Lr:0.0001\n",
      "Epoch 31, Step: 824, Loss: 0.00601612962782383, Lr:0.0001\n",
      "Epoch 31, Step: 825, Loss: 0.0015007047913968563, Lr:0.0001\n",
      "Epoch 31, Step: 826, Loss: 0.0044954558834433556, Lr:0.0001\n",
      "Epoch 31, Step: 827, Loss: 0.15087832510471344, Lr:0.0001\n",
      "Epoch 31, Step: 828, Loss: 0.09016392379999161, Lr:0.0001\n",
      "Epoch 31, Step: 829, Loss: 0.21538814902305603, Lr:0.0001\n",
      "Epoch 31, Step: 830, Loss: 0.18828807771205902, Lr:0.0001\n",
      "Epoch 31, Step: 831, Loss: 0.10797654837369919, Lr:0.0001\n",
      "Epoch 31, Step: 832, Loss: 0.011803075671195984, Lr:0.0001\n",
      "Epoch 31, Step: 833, Loss: 0.043755944818258286, Lr:0.0001\n",
      "Epoch 31, Step: 834, Loss: 0.02243550308048725, Lr:0.0001\n",
      "Epoch 31, Step: 835, Loss: 0.0005113049410283566, Lr:0.0001\n",
      "Epoch 31, Step: 836, Loss: 0.06431490182876587, Lr:0.0001\n",
      "Epoch 31, Step: 837, Loss: 0.05458664894104004, Lr:0.0001\n",
      "Epoch 31, Step: 838, Loss: 0.040215980261564255, Lr:0.0001\n",
      "Epoch 31, Step: 839, Loss: 0.0040855552069842815, Lr:0.0001\n",
      "Epoch 31, Step: 840, Loss: 0.021466869860887527, Lr:0.0001\n",
      "Epoch 31, Step: 841, Loss: 0.020027421414852142, Lr:0.0001\n",
      "Epoch 31, Step: 842, Loss: 0.028737271204590797, Lr:0.0001\n",
      "Epoch 31, Step: 843, Loss: 0.2738277018070221, Lr:0.0001\n",
      "Epoch 31, Step: 844, Loss: 0.1456054300069809, Lr:0.0001\n",
      "Epoch 31, Step: 845, Loss: 0.0026424864772707224, Lr:0.0001\n",
      "Epoch 31, Step: 846, Loss: 0.027975477278232574, Lr:0.0001\n",
      "Epoch 31, Step: 847, Loss: 0.0013307466870173812, Lr:0.0001\n",
      "Epoch 31, Step: 848, Loss: 0.06901358813047409, Lr:0.0001\n",
      "Epoch 31, Step: 849, Loss: 0.20349201560020447, Lr:0.0001\n",
      "Epoch 31, Step: 850, Loss: 0.11201626062393188, Lr:0.0001\n",
      "Epoch 31, Step: 851, Loss: 0.010517549701035023, Lr:0.0001\n",
      "Epoch 31, Step: 852, Loss: 0.0005425851559266448, Lr:0.0001\n",
      "Epoch 31, Step: 853, Loss: 0.010216964408755302, Lr:0.0001\n",
      "Epoch 31, Step: 854, Loss: 0.059649139642715454, Lr:0.0001\n",
      "Epoch 31, Step: 855, Loss: 0.010662048123776913, Lr:0.0001\n",
      "Epoch 31, Step: 856, Loss: 0.005101592279970646, Lr:0.0001\n",
      "Epoch 31, Step: 857, Loss: 0.0026401951909065247, Lr:0.0001\n",
      "Epoch 31, Step: 858, Loss: 0.031362757086753845, Lr:0.0001\n",
      "Epoch 31, Step: 859, Loss: 0.008205300197005272, Lr:0.0001\n",
      "Epoch 31, Step: 860, Loss: 0.030712958425283432, Lr:0.0001\n",
      "Epoch 31, Step: 861, Loss: 0.021100332960486412, Lr:0.0001\n",
      "Epoch 31, Step: 862, Loss: 0.04818767309188843, Lr:0.0001\n",
      "Epoch 31, Step: 863, Loss: 0.015114596113562584, Lr:0.0001\n",
      "Epoch 31, Step: 864, Loss: 0.10807126015424728, Lr:0.0001\n",
      "Epoch 31, Step: 865, Loss: 0.0009518209844827652, Lr:0.0001\n",
      "Epoch 31, Step: 866, Loss: 0.06007827818393707, Lr:0.0001\n",
      "Epoch 31, Step: 867, Loss: 0.039578862488269806, Lr:0.0001\n",
      "Epoch 31, Step: 868, Loss: 0.029503844678401947, Lr:0.0001\n",
      "Epoch 31, Step: 869, Loss: 0.12409840524196625, Lr:0.0001\n",
      "Epoch 31, Step: 870, Loss: 0.007314343471080065, Lr:0.0001\n",
      "Epoch 31, Step: 871, Loss: 0.04516749829053879, Lr:0.0001\n",
      "Epoch 31, Step: 872, Loss: 0.048281893134117126, Lr:0.0001\n",
      "Epoch 31, Step: 873, Loss: 0.00010144211410079151, Lr:0.0001\n",
      "Epoch 31, Step: 874, Loss: 0.026340879499912262, Lr:0.0001\n",
      "Epoch 31, Step: 875, Loss: 0.0065870569087564945, Lr:0.0001\n",
      "Epoch 31, Step: 876, Loss: 0.005005548242479563, Lr:0.0001\n",
      "Epoch 31, Step: 877, Loss: 0.0025336802937090397, Lr:0.0001\n",
      "Epoch 31, Step: 878, Loss: 0.016275998204946518, Lr:0.0001\n",
      "Epoch 31, Step: 879, Loss: 0.1703326404094696, Lr:0.0001\n",
      "Epoch 31, Step: 880, Loss: 0.023364337161183357, Lr:0.0001\n",
      "Epoch 31, Step: 881, Loss: 0.0014093673089519143, Lr:0.0001\n",
      "Epoch 31, Step: 882, Loss: 0.0174137894064188, Lr:0.0001\n",
      "Epoch 31, Step: 883, Loss: 0.05310191959142685, Lr:0.0001\n",
      "Epoch 31, Step: 884, Loss: 0.013425328768789768, Lr:0.0001\n",
      "Epoch 31, Step: 885, Loss: 0.1073741540312767, Lr:0.0001\n",
      "Epoch 31, Step: 886, Loss: 0.013315139338374138, Lr:0.0001\n",
      "Epoch 31, Step: 887, Loss: 0.007029093336313963, Lr:0.0001\n",
      "Epoch 31, Step: 888, Loss: 0.03711347281932831, Lr:0.0001\n",
      "Epoch 31, Step: 889, Loss: 0.029766639694571495, Lr:0.0001\n",
      "Epoch 31, Step: 890, Loss: 0.07576649636030197, Lr:0.0001\n",
      "Epoch 31, Step: 891, Loss: 0.09720564633607864, Lr:0.0001\n",
      "Epoch 31, Step: 892, Loss: 0.020173653960227966, Lr:0.0001\n",
      "Epoch 31, Step: 893, Loss: 0.010494336485862732, Lr:0.0001\n",
      "Epoch 31, Step: 894, Loss: 0.006832186598330736, Lr:0.0001\n",
      "Epoch 31, Step: 895, Loss: 0.12015973031520844, Lr:0.0001\n",
      "Epoch 31, Step: 896, Loss: 0.004919011611491442, Lr:0.0001\n",
      "Epoch 31, Step: 897, Loss: 0.008868424221873283, Lr:0.0001\n",
      "Epoch 31, Step: 898, Loss: 0.33763787150382996, Lr:0.0001\n",
      "Epoch 31, Step: 899, Loss: 0.02149166353046894, Lr:0.0001\n",
      "Epoch 31, Step: 900, Loss: 0.001862483681179583, Lr:0.0001\n",
      "Epoch 31, Step: 901, Loss: 0.019799454137682915, Lr:0.0001\n",
      "Epoch 31, Step: 902, Loss: 0.04884671792387962, Lr:0.0001\n",
      "Epoch 31, Step: 903, Loss: 0.007002415135502815, Lr:0.0001\n",
      "Epoch 31, Step: 904, Loss: 0.011495975777506828, Lr:0.0001\n",
      "Epoch 31, Step: 905, Loss: 0.003942202311009169, Lr:0.0001\n",
      "Epoch 31, Step: 906, Loss: 0.2619197368621826, Lr:0.0001\n",
      "Epoch 31, Step: 907, Loss: 0.014141585677862167, Lr:0.0001\n",
      "Epoch 31, Step: 908, Loss: 0.03816547244787216, Lr:0.0001\n",
      "Epoch 31, Step: 909, Loss: 0.0016125583788380027, Lr:0.0001\n",
      "Epoch 31, Step: 910, Loss: 0.011159123852849007, Lr:0.0001\n",
      "Epoch 31, Step: 911, Loss: 0.012419043108820915, Lr:0.0001\n",
      "Epoch 31, Step: 912, Loss: 0.0045782155357301235, Lr:0.0001\n",
      "Epoch 31, Step: 913, Loss: 0.0004077887861058116, Lr:0.0001\n",
      "Epoch 31, Step: 914, Loss: 0.0022924994118511677, Lr:0.0001\n",
      "Epoch 31, Step: 915, Loss: 0.187159463763237, Lr:0.0001\n",
      "Epoch 31, Step: 916, Loss: 0.10559256374835968, Lr:0.0001\n",
      "Epoch 31, Step: 917, Loss: 0.0032120528630912304, Lr:0.0001\n",
      "Epoch 31, Step: 918, Loss: 0.006502171047031879, Lr:0.0001\n",
      "Epoch 31, Step: 919, Loss: 0.0020925088319927454, Lr:0.0001\n",
      "Epoch 31, Step: 920, Loss: 0.16218301653862, Lr:0.0001\n",
      "Epoch 31, Step: 921, Loss: 0.133159339427948, Lr:0.0001\n",
      "Epoch 31, Step: 922, Loss: 0.09721744805574417, Lr:0.0001\n",
      "Epoch 31, Step: 923, Loss: 0.02243783138692379, Lr:0.0001\n",
      "Epoch 31, Step: 924, Loss: 0.005495178978890181, Lr:0.0001\n",
      "Epoch 31, Step: 925, Loss: 0.09370776265859604, Lr:0.0001\n",
      "Epoch 31, Step: 926, Loss: 0.0019936677999794483, Lr:0.0001\n",
      "Epoch 31, Step: 927, Loss: 0.3062668442726135, Lr:0.0001\n",
      "Epoch 31, Step: 928, Loss: 0.022606024518609047, Lr:0.0001\n",
      "Epoch 31, Step: 929, Loss: 0.008555455133318901, Lr:0.0001\n",
      "Epoch 31, Step: 930, Loss: 0.027376560494303703, Lr:0.0001\n",
      "Epoch 31, Step: 931, Loss: 0.10557252168655396, Lr:0.0001\n",
      "Epoch 31, Step: 932, Loss: 0.06787703186273575, Lr:0.0001\n",
      "Epoch 31, Step: 933, Loss: 0.012912556529045105, Lr:0.0001\n",
      "Epoch 31, Step: 934, Loss: 0.002658821176737547, Lr:0.0001\n",
      "Epoch 31, Step: 935, Loss: 0.015434560365974903, Lr:0.0001\n",
      "Epoch 31, Step: 936, Loss: 0.16335050761699677, Lr:0.0001\n",
      "Epoch 31, Step: 937, Loss: 0.003374375170096755, Lr:0.0001\n",
      "Epoch 31, Step: 938, Loss: 0.009949197061359882, Lr:0.0001\n",
      "Epoch 31, Step: 939, Loss: 0.02496200054883957, Lr:0.0001\n",
      "Epoch 31, Step: 940, Loss: 0.00017894740449264646, Lr:0.0001\n",
      "Epoch 31, Step: 941, Loss: 0.07560744136571884, Lr:0.0001\n",
      "Epoch 31, Step: 942, Loss: 0.4946094751358032, Lr:0.0001\n",
      "Epoch 31, Step: 943, Loss: 0.06447587162256241, Lr:0.0001\n",
      "Epoch 31, Step: 944, Loss: 0.02046767994761467, Lr:0.0001\n",
      "Epoch 31, Step: 945, Loss: 0.32412609457969666, Lr:0.0001\n",
      "Epoch 31, Step: 946, Loss: 0.011531547643244267, Lr:0.0001\n",
      "Epoch 31, Step: 947, Loss: 0.042714133858680725, Lr:0.0001\n",
      "Epoch 31, Step: 948, Loss: 0.004789382219314575, Lr:0.0001\n",
      "Epoch 31, Step: 949, Loss: 0.015871623530983925, Lr:0.0001\n",
      "Epoch 31, Step: 950, Loss: 0.19477684795856476, Lr:0.0001\n",
      "Epoch 31, Step: 951, Loss: 0.03866860270500183, Lr:0.0001\n",
      "Epoch 31, Step: 952, Loss: 0.06550036370754242, Lr:0.0001\n",
      "Epoch 31, Step: 953, Loss: 0.012642759829759598, Lr:0.0001\n",
      "Epoch 31, Step: 954, Loss: 0.0014095907099545002, Lr:0.0001\n",
      "Epoch 31, Step: 955, Loss: 0.03665982931852341, Lr:0.0001\n",
      "Epoch 31, Step: 956, Loss: 0.014356160536408424, Lr:0.0001\n",
      "Epoch 31, Step: 957, Loss: 0.034665629267692566, Lr:0.0001\n",
      "Epoch 31, Step: 958, Loss: 0.02826724201440811, Lr:0.0001\n",
      "Epoch 31, Step: 959, Loss: 0.04190094396471977, Lr:0.0001\n",
      "Epoch 31, Step: 960, Loss: 0.25251519680023193, Lr:0.0001\n",
      "Epoch 31, Step: 961, Loss: 0.008200068026781082, Lr:0.0001\n",
      "Epoch 31, Step: 962, Loss: 0.2522699236869812, Lr:0.0001\n",
      "Epoch 31, Step: 963, Loss: 0.04218216985464096, Lr:0.0001\n",
      "Epoch 31, Step: 964, Loss: 0.014000591821968555, Lr:0.0001\n",
      "Epoch 31, Step: 965, Loss: 0.00922349002212286, Lr:0.0001\n",
      "Epoch 31, Step: 966, Loss: 0.004130636807531118, Lr:0.0001\n",
      "Epoch 31, Step: 967, Loss: 0.10633061826229095, Lr:0.0001\n",
      "Epoch 31, Step: 968, Loss: 0.09941527247428894, Lr:0.0001\n",
      "Epoch 31, Step: 969, Loss: 0.1212281584739685, Lr:0.0001\n",
      "Epoch 31, Step: 970, Loss: 0.006941708270460367, Lr:0.0001\n",
      "Epoch 31, Step: 971, Loss: 0.001019313232973218, Lr:0.0001\n",
      "Epoch 31, Step: 972, Loss: 0.006087643094360828, Lr:0.0001\n",
      "Epoch 31, Step: 973, Loss: 0.051303792744874954, Lr:0.0001\n",
      "Epoch 31, Step: 974, Loss: 0.04254019632935524, Lr:0.0001\n",
      "Epoch 31, Step: 975, Loss: 0.0010618444066494703, Lr:0.0001\n",
      "Epoch 31, Step: 976, Loss: 0.0013655424118041992, Lr:0.0001\n",
      "Epoch 31, Step: 977, Loss: 0.037620849907398224, Lr:0.0001\n",
      "Epoch 31, Step: 978, Loss: 0.013228187337517738, Lr:0.0001\n",
      "Epoch 31, Step: 979, Loss: 0.15178582072257996, Lr:0.0001\n",
      "Epoch 31, Step: 980, Loss: 0.022443145513534546, Lr:0.0001\n",
      "Epoch 31, Step: 981, Loss: 0.04511774331331253, Lr:0.0001\n",
      "Epoch 31, Step: 982, Loss: 0.03465035930275917, Lr:0.0001\n",
      "Epoch 31, Step: 983, Loss: 0.0404076874256134, Lr:0.0001\n",
      "Epoch 31, Step: 984, Loss: 0.011124683544039726, Lr:0.0001\n",
      "Epoch 31, Step: 985, Loss: 0.012296494096517563, Lr:0.0001\n",
      "Epoch 31, Step: 986, Loss: 0.00246876897290349, Lr:0.0001\n",
      "Epoch 31, Step: 987, Loss: 0.05952996015548706, Lr:0.0001\n",
      "Epoch 31, Step: 988, Loss: 0.04099592566490173, Lr:0.0001\n",
      "Epoch 31, Step: 989, Loss: 0.16655834019184113, Lr:0.0001\n",
      "Epoch 31, Step: 990, Loss: 0.004383374471217394, Lr:0.0001\n",
      "Epoch 31, Step: 991, Loss: 0.05042436346411705, Lr:0.0001\n",
      "Epoch 31, Step: 992, Loss: 0.023821299895644188, Lr:0.0001\n",
      "Epoch 31, Step: 993, Loss: 0.001276490744203329, Lr:0.0001\n",
      "Epoch 31, Step: 994, Loss: 0.03799864277243614, Lr:0.0001\n",
      "Epoch 31, Step: 995, Loss: 0.032228756695985794, Lr:0.0001\n",
      "Epoch 31, Step: 996, Loss: 0.001587376114912331, Lr:0.0001\n",
      "Epoch 31, Step: 997, Loss: 0.02900526113808155, Lr:0.0001\n",
      "Epoch 31, Step: 998, Loss: 0.08725535869598389, Lr:0.0001\n",
      "Epoch 31, Step: 999, Loss: 0.11604885756969452, Lr:0.0001\n",
      "Epoch 31, Step: 1000, Loss: 0.06678994745016098, Lr:0.0001\n",
      "Epoch 31, Step: 1001, Loss: 0.006642576772719622, Lr:0.0001\n",
      "Epoch 31, Step: 1002, Loss: 0.06396198272705078, Lr:0.0001\n",
      "Epoch 31, Step: 1003, Loss: 0.014299996197223663, Lr:0.0001\n",
      "Epoch 31, Step: 1004, Loss: 0.007488079834729433, Lr:0.0001\n",
      "Epoch 31, Step: 1005, Loss: 0.007345312740653753, Lr:0.0001\n",
      "Epoch 31, Step: 1006, Loss: 0.13124361634254456, Lr:0.0001\n",
      "Epoch 31, Step: 1007, Loss: 0.021080736070871353, Lr:0.0001\n",
      "Epoch 31, Step: 1008, Loss: 0.012861767783761024, Lr:0.0001\n",
      "Epoch 31, Step: 1009, Loss: 0.18023043870925903, Lr:0.0001\n",
      "Epoch 31, Step: 1010, Loss: 0.06702356785535812, Lr:0.0001\n",
      "Epoch 31, Step: 1011, Loss: 0.012886116281151772, Lr:0.0001\n",
      "Epoch 31, Step: 1012, Loss: 0.0013381822500377893, Lr:0.0001\n",
      "Epoch 31, Step: 1013, Loss: 0.0631401389837265, Lr:0.0001\n",
      "Epoch 31, Step: 1014, Loss: 0.07044056057929993, Lr:0.0001\n",
      "Epoch 31, Step: 1015, Loss: 0.018367981538176537, Lr:0.0001\n",
      "Epoch 31, Step: 1016, Loss: 0.03564874082803726, Lr:0.0001\n",
      "Epoch 31, Step: 1017, Loss: 0.05060772970318794, Lr:0.0001\n",
      "Epoch 31, Step: 1018, Loss: 0.04617304727435112, Lr:0.0001\n",
      "Epoch 31, Step: 1019, Loss: 0.10270337015390396, Lr:0.0001\n",
      "Epoch 31, Step: 1020, Loss: 0.0522264800965786, Lr:0.0001\n",
      "Epoch 31, Step: 1021, Loss: 0.17250873148441315, Lr:0.0001\n",
      "Epoch 31, Step: 1022, Loss: 0.005070381332188845, Lr:0.0001\n",
      "Epoch 31, Step: 1023, Loss: 0.1623636931180954, Lr:0.0001\n",
      "Epoch 31, Step: 1024, Loss: 0.0012960942694917321, Lr:0.0001\n",
      "Epoch 31, Step: 1025, Loss: 0.09219585359096527, Lr:0.0001\n",
      "Epoch 31, Step: 1026, Loss: 0.0002532287617214024, Lr:0.0001\n",
      "Epoch 31, Step: 1027, Loss: 0.015202263370156288, Lr:0.0001\n",
      "Epoch 31, Step: 1028, Loss: 0.03547732159495354, Lr:0.0001\n",
      "Epoch 31, Step: 1029, Loss: 0.008540505543351173, Lr:0.0001\n",
      "Epoch 31, Step: 1030, Loss: 0.0042168693616986275, Lr:0.0001\n",
      "Epoch 31, Step: 1031, Loss: 0.022068720310926437, Lr:0.0001\n",
      "Epoch 31, Step: 1032, Loss: 0.022010430693626404, Lr:0.0001\n",
      "Epoch 31, Step: 1033, Loss: 0.006289955694228411, Lr:0.0001\n",
      "Epoch 31, Step: 1034, Loss: 0.02426210418343544, Lr:0.0001\n",
      "Epoch 31, Step: 1035, Loss: 0.016151120886206627, Lr:0.0001\n",
      "Epoch 31, Step: 1036, Loss: 0.036001794040203094, Lr:0.0001\n",
      "Epoch 31, Step: 1037, Loss: 0.059774525463581085, Lr:0.0001\n",
      "Epoch 31, Step: 1038, Loss: 0.002481810748577118, Lr:0.0001\n",
      "Epoch 31, Step: 1039, Loss: 0.02969951182603836, Lr:0.0001\n",
      "Epoch 31, Step: 1040, Loss: 0.019511258229613304, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 31\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:16 loss: 0.3010 (0.3010) acc1: 93.7500 (93.7500) acc5: 100.0000 (100.0000) time: 0.2887 data: 0.1210 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.0069 (0.0547) acc1: 100.0000 (98.8636) acc5: 100.0000 (100.0000) time: 0.2939 data: 0.1155 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:11 loss: 0.0050 (0.0577) acc1: 100.0000 (97.9167) acc5: 100.0000 (100.0000) time: 0.3080 data: 0.1160 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.0133 (0.1446) acc1: 100.0000 (95.9677) acc5: 100.0000 (100.0000) time: 0.3105 data: 0.1165 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.0513 (0.2361) acc1: 93.7500 (94.6646) acc5: 100.0000 (100.0000) time: 0.2984 data: 0.1166 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0285 (0.2358) acc1: 93.7500 (94.4853) acc5: 100.0000 (100.0000) time: 0.3014 data: 0.1177 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0186 (0.2398) acc1: 100.0000 (94.3246) acc5: 100.0000 (100.0000) time: 0.2938 data: 0.1122 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.2995 s / it)\n",
      "* Acc@1 94.325 Acc@5 100.000 loss 0.240\n",
      "Accuracy of the network on the 881 test image: 94.3%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 32, Step: 0, Loss: 0.04433354735374451, Lr:0.0001\n",
      "Epoch 32, Step: 1, Loss: 0.037358105182647705, Lr:0.0001\n",
      "Epoch 32, Step: 2, Loss: 0.04142738878726959, Lr:0.0001\n",
      "Epoch 32, Step: 3, Loss: 0.0012620248598977923, Lr:0.0001\n",
      "Epoch 32, Step: 4, Loss: 0.02384134940803051, Lr:0.0001\n",
      "Epoch 32, Step: 5, Loss: 0.012114981189370155, Lr:0.0001\n",
      "Epoch 32, Step: 6, Loss: 0.07689861953258514, Lr:0.0001\n",
      "Epoch 32, Step: 7, Loss: 0.012731810100376606, Lr:0.0001\n",
      "Epoch 32, Step: 8, Loss: 0.0004825056530535221, Lr:0.0001\n",
      "Epoch 32, Step: 9, Loss: 0.003717275569215417, Lr:0.0001\n",
      "Epoch 32, Step: 10, Loss: 0.001722813700325787, Lr:0.0001\n",
      "Epoch 32, Step: 11, Loss: 0.08340742439031601, Lr:0.0001\n",
      "Epoch 32, Step: 12, Loss: 0.5445063710212708, Lr:0.0001\n",
      "Epoch 32, Step: 13, Loss: 0.0032774906139820814, Lr:0.0001\n",
      "Epoch 32, Step: 14, Loss: 0.19480778276920319, Lr:0.0001\n",
      "Epoch 32, Step: 15, Loss: 0.013479329645633698, Lr:0.0001\n",
      "Epoch 32, Step: 16, Loss: 0.02085721306502819, Lr:0.0001\n",
      "Epoch 32, Step: 17, Loss: 0.011843443848192692, Lr:0.0001\n",
      "Epoch 32, Step: 18, Loss: 0.04131655395030975, Lr:0.0001\n",
      "Epoch 32, Step: 19, Loss: 0.04886418581008911, Lr:0.0001\n",
      "Epoch 32, Step: 20, Loss: 0.16536495089530945, Lr:0.0001\n",
      "Epoch 32, Step: 21, Loss: 0.001565122976899147, Lr:0.0001\n",
      "Epoch 32, Step: 22, Loss: 0.5595853924751282, Lr:0.0001\n",
      "Epoch 32, Step: 23, Loss: 0.032505396753549576, Lr:0.0001\n",
      "Epoch 32, Step: 24, Loss: 0.11810917407274246, Lr:0.0001\n",
      "Epoch 32, Step: 25, Loss: 0.01518444437533617, Lr:0.0001\n",
      "Epoch 32, Step: 26, Loss: 0.01747802644968033, Lr:0.0001\n",
      "Epoch 32, Step: 27, Loss: 0.0079650292173028, Lr:0.0001\n",
      "Epoch 32, Step: 28, Loss: 0.04385371506214142, Lr:0.0001\n",
      "Epoch 32, Step: 29, Loss: 0.016585752367973328, Lr:0.0001\n",
      "Epoch 32, Step: 30, Loss: 0.049863651394844055, Lr:0.0001\n",
      "Epoch 32, Step: 31, Loss: 0.0015642247162759304, Lr:0.0001\n",
      "Epoch 32, Step: 32, Loss: 0.0017271427204832435, Lr:0.0001\n",
      "Epoch 32, Step: 33, Loss: 0.08854802697896957, Lr:0.0001\n",
      "Epoch 32, Step: 34, Loss: 0.04327869042754173, Lr:0.0001\n",
      "Epoch 32, Step: 35, Loss: 0.0318099670112133, Lr:0.0001\n",
      "Epoch 32, Step: 36, Loss: 0.008304408751428127, Lr:0.0001\n",
      "Epoch 32, Step: 37, Loss: 0.2257755547761917, Lr:0.0001\n",
      "Epoch 32, Step: 38, Loss: 0.027361705899238586, Lr:0.0001\n",
      "Epoch 32, Step: 39, Loss: 0.016373027116060257, Lr:0.0001\n",
      "Epoch 32, Step: 40, Loss: 0.05001715198159218, Lr:0.0001\n",
      "Epoch 32, Step: 41, Loss: 0.008263889700174332, Lr:0.0001\n",
      "Epoch 32, Step: 42, Loss: 0.005538781173527241, Lr:0.0001\n",
      "Epoch 32, Step: 43, Loss: 0.19115233421325684, Lr:0.0001\n",
      "Epoch 32, Step: 44, Loss: 0.022197086364030838, Lr:0.0001\n",
      "Epoch 32, Step: 45, Loss: 0.011768578551709652, Lr:0.0001\n",
      "Epoch 32, Step: 46, Loss: 0.10912567377090454, Lr:0.0001\n",
      "Epoch 32, Step: 47, Loss: 0.404135525226593, Lr:0.0001\n",
      "Epoch 32, Step: 48, Loss: 0.017634764313697815, Lr:0.0001\n",
      "Epoch 32, Step: 49, Loss: 0.014415361918509007, Lr:0.0001\n",
      "Epoch 32, Step: 50, Loss: 0.0009375559748150408, Lr:0.0001\n",
      "Epoch 32, Step: 51, Loss: 0.004209416918456554, Lr:0.0001\n",
      "Epoch 32, Step: 52, Loss: 0.0047926404513418674, Lr:0.0001\n",
      "Epoch 32, Step: 53, Loss: 0.06094386428594589, Lr:0.0001\n",
      "Epoch 32, Step: 54, Loss: 0.11115464568138123, Lr:0.0001\n",
      "Epoch 32, Step: 55, Loss: 0.08467184007167816, Lr:0.0001\n",
      "Epoch 32, Step: 56, Loss: 0.027039533481001854, Lr:0.0001\n",
      "Epoch 32, Step: 57, Loss: 0.13155241310596466, Lr:0.0001\n",
      "Epoch 32, Step: 58, Loss: 0.04355190694332123, Lr:0.0001\n",
      "Epoch 32, Step: 59, Loss: 0.18645773828029633, Lr:0.0001\n",
      "Epoch 32, Step: 60, Loss: 0.0006466952618211508, Lr:0.0001\n",
      "Epoch 32, Step: 61, Loss: 0.05228578299283981, Lr:0.0001\n",
      "Epoch 32, Step: 62, Loss: 0.0025645303539931774, Lr:0.0001\n",
      "Epoch 32, Step: 63, Loss: 0.12918950617313385, Lr:0.0001\n",
      "Epoch 32, Step: 64, Loss: 0.06848876178264618, Lr:0.0001\n",
      "Epoch 32, Step: 65, Loss: 0.004418434575200081, Lr:0.0001\n",
      "Epoch 32, Step: 66, Loss: 0.003367326222360134, Lr:0.0001\n",
      "Epoch 32, Step: 67, Loss: 0.10979020595550537, Lr:0.0001\n",
      "Epoch 32, Step: 68, Loss: 0.08853614330291748, Lr:0.0001\n",
      "Epoch 32, Step: 69, Loss: 0.03149310126900673, Lr:0.0001\n",
      "Epoch 32, Step: 70, Loss: 0.2579314410686493, Lr:0.0001\n",
      "Epoch 32, Step: 71, Loss: 0.007482211105525494, Lr:0.0001\n",
      "Epoch 32, Step: 72, Loss: 0.007369659375399351, Lr:0.0001\n",
      "Epoch 32, Step: 73, Loss: 0.002699545817449689, Lr:0.0001\n",
      "Epoch 32, Step: 74, Loss: 0.06339045614004135, Lr:0.0001\n",
      "Epoch 32, Step: 75, Loss: 0.00512912031263113, Lr:0.0001\n",
      "Epoch 32, Step: 76, Loss: 0.020579246804118156, Lr:0.0001\n",
      "Epoch 32, Step: 77, Loss: 0.006088610272854567, Lr:0.0001\n",
      "Epoch 32, Step: 78, Loss: 0.4143587648868561, Lr:0.0001\n",
      "Epoch 32, Step: 79, Loss: 0.034216754138469696, Lr:0.0001\n",
      "Epoch 32, Step: 80, Loss: 0.024972843006253242, Lr:0.0001\n",
      "Epoch 32, Step: 81, Loss: 0.028715746477246284, Lr:0.0001\n",
      "Epoch 32, Step: 82, Loss: 0.01777617260813713, Lr:0.0001\n",
      "Epoch 32, Step: 83, Loss: 0.14665339887142181, Lr:0.0001\n",
      "Epoch 32, Step: 84, Loss: 0.015040035359561443, Lr:0.0001\n",
      "Epoch 32, Step: 85, Loss: 0.17394667863845825, Lr:0.0001\n",
      "Epoch 32, Step: 86, Loss: 0.1293494999408722, Lr:0.0001\n",
      "Epoch 32, Step: 87, Loss: 0.4870296120643616, Lr:0.0001\n",
      "Epoch 32, Step: 88, Loss: 0.026522476226091385, Lr:0.0001\n",
      "Epoch 32, Step: 89, Loss: 0.05825509503483772, Lr:0.0001\n",
      "Epoch 32, Step: 90, Loss: 0.31767168641090393, Lr:0.0001\n",
      "Epoch 32, Step: 91, Loss: 0.26012900471687317, Lr:0.0001\n",
      "Epoch 32, Step: 92, Loss: 0.0014913175255060196, Lr:0.0001\n",
      "Epoch 32, Step: 93, Loss: 0.024594048038125038, Lr:0.0001\n",
      "Epoch 32, Step: 94, Loss: 0.020598098635673523, Lr:0.0001\n",
      "Epoch 32, Step: 95, Loss: 0.0011502016568556428, Lr:0.0001\n",
      "Epoch 32, Step: 96, Loss: 0.01414583157747984, Lr:0.0001\n",
      "Epoch 32, Step: 97, Loss: 0.004037828184664249, Lr:0.0001\n",
      "Epoch 32, Step: 98, Loss: 0.02156180888414383, Lr:0.0001\n",
      "Epoch 32, Step: 99, Loss: 0.008374063298106194, Lr:0.0001\n",
      "Epoch 32, Step: 100, Loss: 0.0013433069689199328, Lr:0.0001\n",
      "Epoch 32, Step: 101, Loss: 0.143123596906662, Lr:0.0001\n",
      "Epoch 32, Step: 102, Loss: 0.005907129961997271, Lr:0.0001\n",
      "Epoch 32, Step: 103, Loss: 0.028772611171007156, Lr:0.0001\n",
      "Epoch 32, Step: 104, Loss: 0.02467253990471363, Lr:0.0001\n",
      "Epoch 32, Step: 105, Loss: 0.052680570632219315, Lr:0.0001\n",
      "Epoch 32, Step: 106, Loss: 0.009677969850599766, Lr:0.0001\n",
      "Epoch 32, Step: 107, Loss: 0.14173191785812378, Lr:0.0001\n",
      "Epoch 32, Step: 108, Loss: 0.06829731911420822, Lr:0.0001\n",
      "Epoch 32, Step: 109, Loss: 0.011625482700765133, Lr:0.0001\n",
      "Epoch 32, Step: 110, Loss: 0.0016930181300267577, Lr:0.0001\n",
      "Epoch 32, Step: 111, Loss: 0.010076617822051048, Lr:0.0001\n",
      "Epoch 32, Step: 112, Loss: 0.22777187824249268, Lr:0.0001\n",
      "Epoch 32, Step: 113, Loss: 0.1001867800951004, Lr:0.0001\n",
      "Epoch 32, Step: 114, Loss: 0.0565345399081707, Lr:0.0001\n",
      "Epoch 32, Step: 115, Loss: 0.01785384863615036, Lr:0.0001\n",
      "Epoch 32, Step: 116, Loss: 0.19633185863494873, Lr:0.0001\n",
      "Epoch 32, Step: 117, Loss: 0.2883111834526062, Lr:0.0001\n",
      "Epoch 32, Step: 118, Loss: 0.004243503790348768, Lr:0.0001\n",
      "Epoch 32, Step: 119, Loss: 0.01331365667283535, Lr:0.0001\n",
      "Epoch 32, Step: 120, Loss: 0.05697247385978699, Lr:0.0001\n",
      "Epoch 32, Step: 121, Loss: 0.020756008103489876, Lr:0.0001\n",
      "Epoch 32, Step: 122, Loss: 0.013332439586520195, Lr:0.0001\n",
      "Epoch 32, Step: 123, Loss: 0.003453107550740242, Lr:0.0001\n",
      "Epoch 32, Step: 124, Loss: 0.026750313118100166, Lr:0.0001\n",
      "Epoch 32, Step: 125, Loss: 0.017471307888627052, Lr:0.0001\n",
      "Epoch 32, Step: 126, Loss: 0.018392764031887054, Lr:0.0001\n",
      "Epoch 32, Step: 127, Loss: 0.1043303906917572, Lr:0.0001\n",
      "Epoch 32, Step: 128, Loss: 0.1919885277748108, Lr:0.0001\n",
      "Epoch 32, Step: 129, Loss: 0.18181611597537994, Lr:0.0001\n",
      "Epoch 32, Step: 130, Loss: 0.06722072511911392, Lr:0.0001\n",
      "Epoch 32, Step: 131, Loss: 0.02331140637397766, Lr:0.0001\n",
      "Epoch 32, Step: 132, Loss: 0.0045888242311775684, Lr:0.0001\n",
      "Epoch 32, Step: 133, Loss: 0.012362023815512657, Lr:0.0001\n",
      "Epoch 32, Step: 134, Loss: 0.03390911594033241, Lr:0.0001\n",
      "Epoch 32, Step: 135, Loss: 0.007031232584267855, Lr:0.0001\n",
      "Epoch 32, Step: 136, Loss: 0.03344303369522095, Lr:0.0001\n",
      "Epoch 32, Step: 137, Loss: 0.0214677806943655, Lr:0.0001\n",
      "Epoch 32, Step: 138, Loss: 0.002255217870697379, Lr:0.0001\n",
      "Epoch 32, Step: 139, Loss: 0.004561182577162981, Lr:0.0001\n",
      "Epoch 32, Step: 140, Loss: 0.0370313934981823, Lr:0.0001\n",
      "Epoch 32, Step: 141, Loss: 0.0010157212382182479, Lr:0.0001\n",
      "Epoch 32, Step: 142, Loss: 0.0199112631380558, Lr:0.0001\n",
      "Epoch 32, Step: 143, Loss: 0.012355512008070946, Lr:0.0001\n",
      "Epoch 32, Step: 144, Loss: 0.014502400532364845, Lr:0.0001\n",
      "Epoch 32, Step: 145, Loss: 0.05918576195836067, Lr:0.0001\n",
      "Epoch 32, Step: 146, Loss: 0.006097367964684963, Lr:0.0001\n",
      "Epoch 32, Step: 147, Loss: 0.06828871369361877, Lr:0.0001\n",
      "Epoch 32, Step: 148, Loss: 0.024040240794420242, Lr:0.0001\n",
      "Epoch 32, Step: 149, Loss: 0.006680505815893412, Lr:0.0001\n",
      "Epoch 32, Step: 150, Loss: 0.01215252373367548, Lr:0.0001\n",
      "Epoch 32, Step: 151, Loss: 0.03194962814450264, Lr:0.0001\n",
      "Epoch 32, Step: 152, Loss: 0.0005606276099570096, Lr:0.0001\n",
      "Epoch 32, Step: 153, Loss: 0.06085405498743057, Lr:0.0001\n",
      "Epoch 32, Step: 154, Loss: 0.043754830956459045, Lr:0.0001\n",
      "Epoch 32, Step: 155, Loss: 0.07780979573726654, Lr:0.0001\n",
      "Epoch 32, Step: 156, Loss: 0.0049574607983231544, Lr:0.0001\n",
      "Epoch 32, Step: 157, Loss: 0.01977173238992691, Lr:0.0001\n",
      "Epoch 32, Step: 158, Loss: 0.040508732199668884, Lr:0.0001\n",
      "Epoch 32, Step: 159, Loss: 0.008059248328208923, Lr:0.0001\n",
      "Epoch 32, Step: 160, Loss: 0.07416024059057236, Lr:0.0001\n",
      "Epoch 32, Step: 161, Loss: 0.006596017628908157, Lr:0.0001\n",
      "Epoch 32, Step: 162, Loss: 0.0010408788220956922, Lr:0.0001\n",
      "Epoch 32, Step: 163, Loss: 0.14008161425590515, Lr:0.0001\n",
      "Epoch 32, Step: 164, Loss: 0.0020183403976261616, Lr:0.0001\n",
      "Epoch 32, Step: 165, Loss: 0.16472385823726654, Lr:0.0001\n",
      "Epoch 32, Step: 166, Loss: 0.004909121431410313, Lr:0.0001\n",
      "Epoch 32, Step: 167, Loss: 0.01703226938843727, Lr:0.0001\n",
      "Epoch 32, Step: 168, Loss: 0.028426416218280792, Lr:0.0001\n",
      "Epoch 32, Step: 169, Loss: 0.001835421659052372, Lr:0.0001\n",
      "Epoch 32, Step: 170, Loss: 0.15639176964759827, Lr:0.0001\n",
      "Epoch 32, Step: 171, Loss: 0.08399408310651779, Lr:0.0001\n",
      "Epoch 32, Step: 172, Loss: 0.12902387976646423, Lr:0.0001\n",
      "Epoch 32, Step: 173, Loss: 0.010911298915743828, Lr:0.0001\n",
      "Epoch 32, Step: 174, Loss: 0.10384680330753326, Lr:0.0001\n",
      "Epoch 32, Step: 175, Loss: 0.007039948366582394, Lr:0.0001\n",
      "Epoch 32, Step: 176, Loss: 0.09333242475986481, Lr:0.0001\n",
      "Epoch 32, Step: 177, Loss: 0.07271579653024673, Lr:0.0001\n",
      "Epoch 32, Step: 178, Loss: 0.028931092470884323, Lr:0.0001\n",
      "Epoch 32, Step: 179, Loss: 0.035552121698856354, Lr:0.0001\n",
      "Epoch 32, Step: 180, Loss: 0.008491454645991325, Lr:0.0001\n",
      "Epoch 32, Step: 181, Loss: 0.009580101817846298, Lr:0.0001\n",
      "Epoch 32, Step: 182, Loss: 0.003471207804977894, Lr:0.0001\n",
      "Epoch 32, Step: 183, Loss: 0.13047660887241364, Lr:0.0001\n",
      "Epoch 32, Step: 184, Loss: 0.005974441766738892, Lr:0.0001\n",
      "Epoch 32, Step: 185, Loss: 0.009764404036104679, Lr:0.0001\n",
      "Epoch 32, Step: 186, Loss: 0.0449925921857357, Lr:0.0001\n",
      "Epoch 32, Step: 187, Loss: 0.08080264925956726, Lr:0.0001\n",
      "Epoch 32, Step: 188, Loss: 0.020979909226298332, Lr:0.0001\n",
      "Epoch 32, Step: 189, Loss: 0.006846856325864792, Lr:0.0001\n",
      "Epoch 32, Step: 190, Loss: 0.1750103384256363, Lr:0.0001\n",
      "Epoch 32, Step: 191, Loss: 0.006538036745041609, Lr:0.0001\n",
      "Epoch 32, Step: 192, Loss: 0.08255672454833984, Lr:0.0001\n",
      "Epoch 32, Step: 193, Loss: 0.005077525973320007, Lr:0.0001\n",
      "Epoch 32, Step: 194, Loss: 0.030037567019462585, Lr:0.0001\n",
      "Epoch 32, Step: 195, Loss: 0.002763274358585477, Lr:0.0001\n",
      "Epoch 32, Step: 196, Loss: 0.08864463120698929, Lr:0.0001\n",
      "Epoch 32, Step: 197, Loss: 0.007888255640864372, Lr:0.0001\n",
      "Epoch 32, Step: 198, Loss: 0.012054990977048874, Lr:0.0001\n",
      "Epoch 32, Step: 199, Loss: 0.08188237994909286, Lr:0.0001\n",
      "Epoch 32, Step: 200, Loss: 0.07175066322088242, Lr:0.0001\n",
      "Epoch 32, Step: 201, Loss: 0.04304427281022072, Lr:0.0001\n",
      "Epoch 32, Step: 202, Loss: 0.10770515352487564, Lr:0.0001\n",
      "Epoch 32, Step: 203, Loss: 0.14068932831287384, Lr:0.0001\n",
      "Epoch 32, Step: 204, Loss: 0.007555770687758923, Lr:0.0001\n",
      "Epoch 32, Step: 205, Loss: 0.004720877856016159, Lr:0.0001\n",
      "Epoch 32, Step: 206, Loss: 0.0003224159008823335, Lr:0.0001\n",
      "Epoch 32, Step: 207, Loss: 0.004654002375900745, Lr:0.0001\n",
      "Epoch 32, Step: 208, Loss: 0.133813738822937, Lr:0.0001\n",
      "Epoch 32, Step: 209, Loss: 0.010071470402181149, Lr:0.0001\n",
      "Epoch 32, Step: 210, Loss: 0.14702896773815155, Lr:0.0001\n",
      "Epoch 32, Step: 211, Loss: 0.0017459031660109758, Lr:0.0001\n",
      "Epoch 32, Step: 212, Loss: 0.007355473469942808, Lr:0.0001\n",
      "Epoch 32, Step: 213, Loss: 0.002263239584863186, Lr:0.0001\n",
      "Epoch 32, Step: 214, Loss: 0.011721024289727211, Lr:0.0001\n",
      "Epoch 32, Step: 215, Loss: 0.021613463759422302, Lr:0.0001\n",
      "Epoch 32, Step: 216, Loss: 0.04628385603427887, Lr:0.0001\n",
      "Epoch 32, Step: 217, Loss: 0.03499475494027138, Lr:0.0001\n",
      "Epoch 32, Step: 218, Loss: 0.4797433614730835, Lr:0.0001\n",
      "Epoch 32, Step: 219, Loss: 0.3586447536945343, Lr:0.0001\n",
      "Epoch 32, Step: 220, Loss: 0.005650909151881933, Lr:0.0001\n",
      "Epoch 32, Step: 221, Loss: 0.002461270662024617, Lr:0.0001\n",
      "Epoch 32, Step: 222, Loss: 0.003899077884852886, Lr:0.0001\n",
      "Epoch 32, Step: 223, Loss: 0.016469160094857216, Lr:0.0001\n",
      "Epoch 32, Step: 224, Loss: 0.0024235474411398172, Lr:0.0001\n",
      "Epoch 32, Step: 225, Loss: 0.005345200188457966, Lr:0.0001\n",
      "Epoch 32, Step: 226, Loss: 0.15376496315002441, Lr:0.0001\n",
      "Epoch 32, Step: 227, Loss: 0.10113927721977234, Lr:0.0001\n",
      "Epoch 32, Step: 228, Loss: 0.02447948046028614, Lr:0.0001\n",
      "Epoch 32, Step: 229, Loss: 0.08424815535545349, Lr:0.0001\n",
      "Epoch 32, Step: 230, Loss: 0.06288988888263702, Lr:0.0001\n",
      "Epoch 32, Step: 231, Loss: 0.05866984277963638, Lr:0.0001\n",
      "Epoch 32, Step: 232, Loss: 0.4631626605987549, Lr:0.0001\n",
      "Epoch 32, Step: 233, Loss: 0.2777937948703766, Lr:0.0001\n",
      "Epoch 32, Step: 234, Loss: 0.01015313621610403, Lr:0.0001\n",
      "Epoch 32, Step: 235, Loss: 0.04652031138539314, Lr:0.0001\n",
      "Epoch 32, Step: 236, Loss: 0.0039037810638546944, Lr:0.0001\n",
      "Epoch 32, Step: 237, Loss: 0.038722340017557144, Lr:0.0001\n",
      "Epoch 32, Step: 238, Loss: 0.04708010330796242, Lr:0.0001\n",
      "Epoch 32, Step: 239, Loss: 0.045348066836595535, Lr:0.0001\n",
      "Epoch 32, Step: 240, Loss: 0.014964090660214424, Lr:0.0001\n",
      "Epoch 32, Step: 241, Loss: 0.03516005352139473, Lr:0.0001\n",
      "Epoch 32, Step: 242, Loss: 0.01809883862733841, Lr:0.0001\n",
      "Epoch 32, Step: 243, Loss: 0.018203530460596085, Lr:0.0001\n",
      "Epoch 32, Step: 244, Loss: 0.0012302473187446594, Lr:0.0001\n",
      "Epoch 32, Step: 245, Loss: 0.005791160278022289, Lr:0.0001\n",
      "Epoch 32, Step: 246, Loss: 0.01194835640490055, Lr:0.0001\n",
      "Epoch 32, Step: 247, Loss: 0.022557580843567848, Lr:0.0001\n",
      "Epoch 32, Step: 248, Loss: 0.11469410359859467, Lr:0.0001\n",
      "Epoch 32, Step: 249, Loss: 0.0063247778452932835, Lr:0.0001\n",
      "Epoch 32, Step: 250, Loss: 0.05056789144873619, Lr:0.0001\n",
      "Epoch 32, Step: 251, Loss: 0.004514030646532774, Lr:0.0001\n",
      "Epoch 32, Step: 252, Loss: 0.011259829625487328, Lr:0.0001\n",
      "Epoch 32, Step: 253, Loss: 0.01604301854968071, Lr:0.0001\n",
      "Epoch 32, Step: 254, Loss: 0.1851045936346054, Lr:0.0001\n",
      "Epoch 32, Step: 255, Loss: 0.005898711737245321, Lr:0.0001\n",
      "Epoch 32, Step: 256, Loss: 0.0353197306394577, Lr:0.0001\n",
      "Epoch 32, Step: 257, Loss: 0.13019168376922607, Lr:0.0001\n",
      "Epoch 32, Step: 258, Loss: 0.0198725163936615, Lr:0.0001\n",
      "Epoch 32, Step: 259, Loss: 0.47713199257850647, Lr:0.0001\n",
      "Epoch 32, Step: 260, Loss: 0.020190227776765823, Lr:0.0001\n",
      "Epoch 32, Step: 261, Loss: 0.007032383698970079, Lr:0.0001\n",
      "Epoch 32, Step: 262, Loss: 0.03674345090985298, Lr:0.0001\n",
      "Epoch 32, Step: 263, Loss: 0.0044729202054440975, Lr:0.0001\n",
      "Epoch 32, Step: 264, Loss: 0.02664302848279476, Lr:0.0001\n",
      "Epoch 32, Step: 265, Loss: 0.005765868350863457, Lr:0.0001\n",
      "Epoch 32, Step: 266, Loss: 0.15052078664302826, Lr:0.0001\n",
      "Epoch 32, Step: 267, Loss: 0.002309744479134679, Lr:0.0001\n",
      "Epoch 32, Step: 268, Loss: 0.007593917194753885, Lr:0.0001\n",
      "Epoch 32, Step: 269, Loss: 0.006435644347220659, Lr:0.0001\n",
      "Epoch 32, Step: 270, Loss: 0.010473620146512985, Lr:0.0001\n",
      "Epoch 32, Step: 271, Loss: 0.11789131164550781, Lr:0.0001\n",
      "Epoch 32, Step: 272, Loss: 0.02827136591076851, Lr:0.0001\n",
      "Epoch 32, Step: 273, Loss: 0.007350470405071974, Lr:0.0001\n",
      "Epoch 32, Step: 274, Loss: 0.047347888350486755, Lr:0.0001\n",
      "Epoch 32, Step: 275, Loss: 0.14179790019989014, Lr:0.0001\n",
      "Epoch 32, Step: 276, Loss: 0.10076430439949036, Lr:0.0001\n",
      "Epoch 32, Step: 277, Loss: 0.1091962680220604, Lr:0.0001\n",
      "Epoch 32, Step: 278, Loss: 0.009967712685465813, Lr:0.0001\n",
      "Epoch 32, Step: 279, Loss: 0.003734326222911477, Lr:0.0001\n",
      "Epoch 32, Step: 280, Loss: 0.11610174924135208, Lr:0.0001\n",
      "Epoch 32, Step: 281, Loss: 0.03581658750772476, Lr:0.0001\n",
      "Epoch 32, Step: 282, Loss: 0.007448183372616768, Lr:0.0001\n",
      "Epoch 32, Step: 283, Loss: 0.0015338566154241562, Lr:0.0001\n",
      "Epoch 32, Step: 284, Loss: 0.008827009238302708, Lr:0.0001\n",
      "Epoch 32, Step: 285, Loss: 0.009617205709218979, Lr:0.0001\n",
      "Epoch 32, Step: 286, Loss: 0.034220434725284576, Lr:0.0001\n",
      "Epoch 32, Step: 287, Loss: 0.0016665912698954344, Lr:0.0001\n",
      "Epoch 32, Step: 288, Loss: 0.0228046253323555, Lr:0.0001\n",
      "Epoch 32, Step: 289, Loss: 0.12898597121238708, Lr:0.0001\n",
      "Epoch 32, Step: 290, Loss: 0.013566709123551846, Lr:0.0001\n",
      "Epoch 32, Step: 291, Loss: 0.005420430097728968, Lr:0.0001\n",
      "Epoch 32, Step: 292, Loss: 0.029785742983222008, Lr:0.0001\n",
      "Epoch 32, Step: 293, Loss: 0.025291644036769867, Lr:0.0001\n",
      "Epoch 32, Step: 294, Loss: 0.010833323933184147, Lr:0.0001\n",
      "Epoch 32, Step: 295, Loss: 0.023562254384160042, Lr:0.0001\n",
      "Epoch 32, Step: 296, Loss: 0.020802948623895645, Lr:0.0001\n",
      "Epoch 32, Step: 297, Loss: 0.022187132388353348, Lr:0.0001\n",
      "Epoch 32, Step: 298, Loss: 0.005506777670234442, Lr:0.0001\n",
      "Epoch 32, Step: 299, Loss: 0.0070046111941337585, Lr:0.0001\n",
      "Epoch 32, Step: 300, Loss: 0.0344843752682209, Lr:0.0001\n",
      "Epoch 32, Step: 301, Loss: 0.03570760786533356, Lr:0.0001\n",
      "Epoch 32, Step: 302, Loss: 0.1781228631734848, Lr:0.0001\n",
      "Epoch 32, Step: 303, Loss: 0.07821360975503922, Lr:0.0001\n",
      "Epoch 32, Step: 304, Loss: 0.16362112760543823, Lr:0.0001\n",
      "Epoch 32, Step: 305, Loss: 0.06465370208024979, Lr:0.0001\n",
      "Epoch 32, Step: 306, Loss: 0.012700887396931648, Lr:0.0001\n",
      "Epoch 32, Step: 307, Loss: 0.07949526607990265, Lr:0.0001\n",
      "Epoch 32, Step: 308, Loss: 0.10060494393110275, Lr:0.0001\n",
      "Epoch 32, Step: 309, Loss: 0.027764461934566498, Lr:0.0001\n",
      "Epoch 32, Step: 310, Loss: 0.06253831833600998, Lr:0.0001\n",
      "Epoch 32, Step: 311, Loss: 0.03824121877551079, Lr:0.0001\n",
      "Epoch 32, Step: 312, Loss: 0.07555237412452698, Lr:0.0001\n",
      "Epoch 32, Step: 313, Loss: 0.08227459341287613, Lr:0.0001\n",
      "Epoch 32, Step: 314, Loss: 0.07590951770544052, Lr:0.0001\n",
      "Epoch 32, Step: 315, Loss: 0.02835373766720295, Lr:0.0001\n",
      "Epoch 32, Step: 316, Loss: 0.020375046879053116, Lr:0.0001\n",
      "Epoch 32, Step: 317, Loss: 0.004183534998446703, Lr:0.0001\n",
      "Epoch 32, Step: 318, Loss: 0.002570871729403734, Lr:0.0001\n",
      "Epoch 32, Step: 319, Loss: 0.01642787829041481, Lr:0.0001\n",
      "Epoch 32, Step: 320, Loss: 0.018577266484498978, Lr:0.0001\n",
      "Epoch 32, Step: 321, Loss: 0.018231762573122978, Lr:0.0001\n",
      "Epoch 32, Step: 322, Loss: 0.1712697446346283, Lr:0.0001\n",
      "Epoch 32, Step: 323, Loss: 0.11043991893529892, Lr:0.0001\n",
      "Epoch 32, Step: 324, Loss: 0.16989435255527496, Lr:0.0001\n",
      "Epoch 32, Step: 325, Loss: 0.04159030690789223, Lr:0.0001\n",
      "Epoch 32, Step: 326, Loss: 0.019163671880960464, Lr:0.0001\n",
      "Epoch 32, Step: 327, Loss: 0.005745932925492525, Lr:0.0001\n",
      "Epoch 32, Step: 328, Loss: 0.0020045917481184006, Lr:0.0001\n",
      "Epoch 32, Step: 329, Loss: 0.04969324171543121, Lr:0.0001\n",
      "Epoch 32, Step: 330, Loss: 0.52359539270401, Lr:0.0001\n",
      "Epoch 32, Step: 331, Loss: 0.04037775099277496, Lr:0.0001\n",
      "Epoch 32, Step: 332, Loss: 0.025414325296878815, Lr:0.0001\n",
      "Epoch 32, Step: 333, Loss: 0.043665170669555664, Lr:0.0001\n",
      "Epoch 32, Step: 334, Loss: 0.005270811729133129, Lr:0.0001\n",
      "Epoch 32, Step: 335, Loss: 0.05769417807459831, Lr:0.0001\n",
      "Epoch 32, Step: 336, Loss: 0.03997363895177841, Lr:0.0001\n",
      "Epoch 32, Step: 337, Loss: 0.4446105659008026, Lr:0.0001\n",
      "Epoch 32, Step: 338, Loss: 0.42504867911338806, Lr:0.0001\n",
      "Epoch 32, Step: 339, Loss: 0.026549238711595535, Lr:0.0001\n",
      "Epoch 32, Step: 340, Loss: 0.0036713224835693836, Lr:0.0001\n",
      "Epoch 32, Step: 341, Loss: 0.003891318803653121, Lr:0.0001\n",
      "Epoch 32, Step: 342, Loss: 0.0028163373935967684, Lr:0.0001\n",
      "Epoch 32, Step: 343, Loss: 0.01018454134464264, Lr:0.0001\n",
      "Epoch 32, Step: 344, Loss: 0.012393790297210217, Lr:0.0001\n",
      "Epoch 32, Step: 345, Loss: 0.04044685140252113, Lr:0.0001\n",
      "Epoch 32, Step: 346, Loss: 0.11504877358675003, Lr:0.0001\n",
      "Epoch 32, Step: 347, Loss: 0.00014572327199857682, Lr:0.0001\n",
      "Epoch 32, Step: 348, Loss: 0.04439813643693924, Lr:0.0001\n",
      "Epoch 32, Step: 349, Loss: 0.20551803708076477, Lr:0.0001\n",
      "Epoch 32, Step: 350, Loss: 0.018529260531067848, Lr:0.0001\n",
      "Epoch 32, Step: 351, Loss: 0.014887973666191101, Lr:0.0001\n",
      "Epoch 32, Step: 352, Loss: 0.1230742558836937, Lr:0.0001\n",
      "Epoch 32, Step: 353, Loss: 0.024752670899033546, Lr:0.0001\n",
      "Epoch 32, Step: 354, Loss: 0.022841166704893112, Lr:0.0001\n",
      "Epoch 32, Step: 355, Loss: 0.004887414630502462, Lr:0.0001\n",
      "Epoch 32, Step: 356, Loss: 0.07577532529830933, Lr:0.0001\n",
      "Epoch 32, Step: 357, Loss: 0.1222311407327652, Lr:0.0001\n",
      "Epoch 32, Step: 358, Loss: 0.016082430258393288, Lr:0.0001\n",
      "Epoch 32, Step: 359, Loss: 0.016106093302369118, Lr:0.0001\n",
      "Epoch 32, Step: 360, Loss: 0.04907682538032532, Lr:0.0001\n",
      "Epoch 32, Step: 361, Loss: 0.0067954231053590775, Lr:0.0001\n",
      "Epoch 32, Step: 362, Loss: 0.01949119195342064, Lr:0.0001\n",
      "Epoch 32, Step: 363, Loss: 0.1547119915485382, Lr:0.0001\n",
      "Epoch 32, Step: 364, Loss: 0.001510787638835609, Lr:0.0001\n",
      "Epoch 32, Step: 365, Loss: 0.012015427462756634, Lr:0.0001\n",
      "Epoch 32, Step: 366, Loss: 0.032758891582489014, Lr:0.0001\n",
      "Epoch 32, Step: 367, Loss: 0.089911550283432, Lr:0.0001\n",
      "Epoch 32, Step: 368, Loss: 0.06382979452610016, Lr:0.0001\n",
      "Epoch 32, Step: 369, Loss: 0.07549605518579483, Lr:0.0001\n",
      "Epoch 32, Step: 370, Loss: 0.019282395020127296, Lr:0.0001\n",
      "Epoch 32, Step: 371, Loss: 0.19654405117034912, Lr:0.0001\n",
      "Epoch 32, Step: 372, Loss: 0.19544346630573273, Lr:0.0001\n",
      "Epoch 32, Step: 373, Loss: 0.0024060208816081285, Lr:0.0001\n",
      "Epoch 32, Step: 374, Loss: 0.119459368288517, Lr:0.0001\n",
      "Epoch 32, Step: 375, Loss: 0.13018418848514557, Lr:0.0001\n",
      "Epoch 32, Step: 376, Loss: 0.004779504146426916, Lr:0.0001\n",
      "Epoch 32, Step: 377, Loss: 0.016310660168528557, Lr:0.0001\n",
      "Epoch 32, Step: 378, Loss: 0.049487512558698654, Lr:0.0001\n",
      "Epoch 32, Step: 379, Loss: 0.13964401185512543, Lr:0.0001\n",
      "Epoch 32, Step: 380, Loss: 0.01384730078279972, Lr:0.0001\n",
      "Epoch 32, Step: 381, Loss: 0.001597164897248149, Lr:0.0001\n",
      "Epoch 32, Step: 382, Loss: 0.002716213930398226, Lr:0.0001\n",
      "Epoch 32, Step: 383, Loss: 0.10978575050830841, Lr:0.0001\n",
      "Epoch 32, Step: 384, Loss: 0.09931956976652145, Lr:0.0001\n",
      "Epoch 32, Step: 385, Loss: 0.05257304012775421, Lr:0.0001\n",
      "Epoch 32, Step: 386, Loss: 0.003010894637554884, Lr:0.0001\n",
      "Epoch 32, Step: 387, Loss: 0.0025992232840508223, Lr:0.0001\n",
      "Epoch 32, Step: 388, Loss: 0.09488161653280258, Lr:0.0001\n",
      "Epoch 32, Step: 389, Loss: 0.13056248426437378, Lr:0.0001\n",
      "Epoch 32, Step: 390, Loss: 0.022916143760085106, Lr:0.0001\n",
      "Epoch 32, Step: 391, Loss: 0.025990109890699387, Lr:0.0001\n",
      "Epoch 32, Step: 392, Loss: 0.001030593877658248, Lr:0.0001\n",
      "Epoch 32, Step: 393, Loss: 0.03738150745630264, Lr:0.0001\n",
      "Epoch 32, Step: 394, Loss: 0.06262391060590744, Lr:0.0001\n",
      "Epoch 32, Step: 395, Loss: 0.26062148809432983, Lr:0.0001\n",
      "Epoch 32, Step: 396, Loss: 0.009077203460037708, Lr:0.0001\n",
      "Epoch 32, Step: 397, Loss: 0.08938029408454895, Lr:0.0001\n",
      "Epoch 32, Step: 398, Loss: 0.009623556397855282, Lr:0.0001\n",
      "Epoch 32, Step: 399, Loss: 0.015344900079071522, Lr:0.0001\n",
      "Epoch 32, Step: 400, Loss: 0.0038824218790978193, Lr:0.0001\n",
      "Epoch 32, Step: 401, Loss: 0.11057591438293457, Lr:0.0001\n",
      "Epoch 32, Step: 402, Loss: 0.001838896656408906, Lr:0.0001\n",
      "Epoch 32, Step: 403, Loss: 0.019074393436312675, Lr:0.0001\n",
      "Epoch 32, Step: 404, Loss: 0.052927613258361816, Lr:0.0001\n",
      "Epoch 32, Step: 405, Loss: 0.077767014503479, Lr:0.0001\n",
      "Epoch 32, Step: 406, Loss: 0.03380705416202545, Lr:0.0001\n",
      "Epoch 32, Step: 407, Loss: 0.06577099859714508, Lr:0.0001\n",
      "Epoch 32, Step: 408, Loss: 0.1062726303935051, Lr:0.0001\n",
      "Epoch 32, Step: 409, Loss: 0.01170552708208561, Lr:0.0001\n",
      "Epoch 32, Step: 410, Loss: 0.07270234078168869, Lr:0.0001\n",
      "Epoch 32, Step: 411, Loss: 0.006106499116867781, Lr:0.0001\n",
      "Epoch 32, Step: 412, Loss: 0.07127469033002853, Lr:0.0001\n",
      "Epoch 32, Step: 413, Loss: 0.01106647215783596, Lr:0.0001\n",
      "Epoch 32, Step: 414, Loss: 0.009708075784146786, Lr:0.0001\n",
      "Epoch 32, Step: 415, Loss: 0.002280403394252062, Lr:0.0001\n",
      "Epoch 32, Step: 416, Loss: 0.0031412732787430286, Lr:0.0001\n",
      "Epoch 32, Step: 417, Loss: 0.0006343797431327403, Lr:0.0001\n",
      "Epoch 32, Step: 418, Loss: 0.03223713859915733, Lr:0.0001\n",
      "Epoch 32, Step: 419, Loss: 0.007741250097751617, Lr:0.0001\n",
      "Epoch 32, Step: 420, Loss: 0.0044683488085865974, Lr:0.0001\n",
      "Epoch 32, Step: 421, Loss: 0.07663850486278534, Lr:0.0001\n",
      "Epoch 32, Step: 422, Loss: 0.1283247321844101, Lr:0.0001\n",
      "Epoch 32, Step: 423, Loss: 0.04619264602661133, Lr:0.0001\n",
      "Epoch 32, Step: 424, Loss: 0.0030158888548612595, Lr:0.0001\n",
      "Epoch 32, Step: 425, Loss: 0.01375402882695198, Lr:0.0001\n",
      "Epoch 32, Step: 426, Loss: 0.007863910868763924, Lr:0.0001\n",
      "Epoch 32, Step: 427, Loss: 0.03790837526321411, Lr:0.0001\n",
      "Epoch 32, Step: 428, Loss: 0.015713421627879143, Lr:0.0001\n",
      "Epoch 32, Step: 429, Loss: 0.004048886243253946, Lr:0.0001\n",
      "Epoch 32, Step: 430, Loss: 0.14239250123500824, Lr:0.0001\n",
      "Epoch 32, Step: 431, Loss: 0.004586631432175636, Lr:0.0001\n",
      "Epoch 32, Step: 432, Loss: 0.003358193440362811, Lr:0.0001\n",
      "Epoch 32, Step: 433, Loss: 0.001552495756186545, Lr:0.0001\n",
      "Epoch 32, Step: 434, Loss: 0.14558261632919312, Lr:0.0001\n",
      "Epoch 32, Step: 435, Loss: 0.009905553422868252, Lr:0.0001\n",
      "Epoch 32, Step: 436, Loss: 0.0014918443048372865, Lr:0.0001\n",
      "Epoch 32, Step: 437, Loss: 0.05125071480870247, Lr:0.0001\n",
      "Epoch 32, Step: 438, Loss: 0.02374330535531044, Lr:0.0001\n",
      "Epoch 32, Step: 439, Loss: 0.05654124170541763, Lr:0.0001\n",
      "Epoch 32, Step: 440, Loss: 0.04575736075639725, Lr:0.0001\n",
      "Epoch 32, Step: 441, Loss: 0.048767827451229095, Lr:0.0001\n",
      "Epoch 32, Step: 442, Loss: 0.5056209564208984, Lr:0.0001\n",
      "Epoch 32, Step: 443, Loss: 0.000999079318717122, Lr:0.0001\n",
      "Epoch 32, Step: 444, Loss: 0.007443966809660196, Lr:0.0001\n",
      "Epoch 32, Step: 445, Loss: 0.23240803182125092, Lr:0.0001\n",
      "Epoch 32, Step: 446, Loss: 0.03441615030169487, Lr:0.0001\n",
      "Epoch 32, Step: 447, Loss: 0.0066749779507517815, Lr:0.0001\n",
      "Epoch 32, Step: 448, Loss: 0.26797065138816833, Lr:0.0001\n",
      "Epoch 32, Step: 449, Loss: 0.005531060043722391, Lr:0.0001\n",
      "Epoch 32, Step: 450, Loss: 0.001554632792249322, Lr:0.0001\n",
      "Epoch 32, Step: 451, Loss: 0.2688421905040741, Lr:0.0001\n",
      "Epoch 32, Step: 452, Loss: 0.022452974691987038, Lr:0.0001\n",
      "Epoch 32, Step: 453, Loss: 0.775183916091919, Lr:0.0001\n",
      "Epoch 32, Step: 454, Loss: 0.024641305208206177, Lr:0.0001\n",
      "Epoch 32, Step: 455, Loss: 0.0766361802816391, Lr:0.0001\n",
      "Epoch 32, Step: 456, Loss: 0.0007981321541592479, Lr:0.0001\n",
      "Epoch 32, Step: 457, Loss: 0.004608923103660345, Lr:0.0001\n",
      "Epoch 32, Step: 458, Loss: 0.019083255901932716, Lr:0.0001\n",
      "Epoch 32, Step: 459, Loss: 0.01487813238054514, Lr:0.0001\n",
      "Epoch 32, Step: 460, Loss: 0.008548569865524769, Lr:0.0001\n",
      "Epoch 32, Step: 461, Loss: 0.10332749038934708, Lr:0.0001\n",
      "Epoch 32, Step: 462, Loss: 0.020179234445095062, Lr:0.0001\n",
      "Epoch 32, Step: 463, Loss: 0.01985424943268299, Lr:0.0001\n",
      "Epoch 32, Step: 464, Loss: 0.04860243573784828, Lr:0.0001\n",
      "Epoch 32, Step: 465, Loss: 0.034954894334077835, Lr:0.0001\n",
      "Epoch 32, Step: 466, Loss: 0.00853282306343317, Lr:0.0001\n",
      "Epoch 32, Step: 467, Loss: 0.0035557381343096495, Lr:0.0001\n",
      "Epoch 32, Step: 468, Loss: 0.28606903553009033, Lr:0.0001\n",
      "Epoch 32, Step: 469, Loss: 0.299365371465683, Lr:0.0001\n",
      "Epoch 32, Step: 470, Loss: 0.013366433791816235, Lr:0.0001\n",
      "Epoch 32, Step: 471, Loss: 0.07020240277051926, Lr:0.0001\n",
      "Epoch 32, Step: 472, Loss: 0.019654106348752975, Lr:0.0001\n",
      "Epoch 32, Step: 473, Loss: 0.0257597416639328, Lr:0.0001\n",
      "Epoch 32, Step: 474, Loss: 0.01435920875519514, Lr:0.0001\n",
      "Epoch 32, Step: 475, Loss: 0.2772880792617798, Lr:0.0001\n",
      "Epoch 32, Step: 476, Loss: 0.01055135764181614, Lr:0.0001\n",
      "Epoch 32, Step: 477, Loss: 0.22214455902576447, Lr:0.0001\n",
      "Epoch 32, Step: 478, Loss: 0.054149698466062546, Lr:0.0001\n",
      "Epoch 32, Step: 479, Loss: 0.035272568464279175, Lr:0.0001\n",
      "Epoch 32, Step: 480, Loss: 0.009685175493359566, Lr:0.0001\n",
      "Epoch 32, Step: 481, Loss: 0.010082213208079338, Lr:0.0001\n",
      "Epoch 32, Step: 482, Loss: 0.10285616666078568, Lr:0.0001\n",
      "Epoch 32, Step: 483, Loss: 0.09976911544799805, Lr:0.0001\n",
      "Epoch 32, Step: 484, Loss: 0.0046749175526201725, Lr:0.0001\n",
      "Epoch 32, Step: 485, Loss: 0.23835985362529755, Lr:0.0001\n",
      "Epoch 32, Step: 486, Loss: 0.0058176773600280285, Lr:0.0001\n",
      "Epoch 32, Step: 487, Loss: 0.012093758210539818, Lr:0.0001\n",
      "Epoch 32, Step: 488, Loss: 0.21148812770843506, Lr:0.0001\n",
      "Epoch 32, Step: 489, Loss: 0.007432824466377497, Lr:0.0001\n",
      "Epoch 32, Step: 490, Loss: 0.028121354058384895, Lr:0.0001\n",
      "Epoch 32, Step: 491, Loss: 0.004842878319323063, Lr:0.0001\n",
      "Epoch 32, Step: 492, Loss: 0.037363201379776, Lr:0.0001\n",
      "Epoch 32, Step: 493, Loss: 0.11615345627069473, Lr:0.0001\n",
      "Epoch 32, Step: 494, Loss: 0.0009828968904912472, Lr:0.0001\n",
      "Epoch 32, Step: 495, Loss: 0.10024386644363403, Lr:0.0001\n",
      "Epoch 32, Step: 496, Loss: 0.04705650731921196, Lr:0.0001\n",
      "Epoch 32, Step: 497, Loss: 0.004313756711781025, Lr:0.0001\n",
      "Epoch 32, Step: 498, Loss: 0.001743303844705224, Lr:0.0001\n",
      "Epoch 32, Step: 499, Loss: 0.3430408537387848, Lr:0.0001\n",
      "Epoch 32, Step: 500, Loss: 0.021158866584300995, Lr:0.0001\n",
      "Epoch 32, Step: 501, Loss: 0.12483564764261246, Lr:0.0001\n",
      "Epoch 32, Step: 502, Loss: 0.01179125439375639, Lr:0.0001\n",
      "Epoch 32, Step: 503, Loss: 0.00592092564329505, Lr:0.0001\n",
      "Epoch 32, Step: 504, Loss: 0.0921495333313942, Lr:0.0001\n",
      "Epoch 32, Step: 505, Loss: 0.06086628884077072, Lr:0.0001\n",
      "Epoch 32, Step: 506, Loss: 0.05593704804778099, Lr:0.0001\n",
      "Epoch 32, Step: 507, Loss: 0.053558725863695145, Lr:0.0001\n",
      "Epoch 32, Step: 508, Loss: 0.04882398992776871, Lr:0.0001\n",
      "Epoch 32, Step: 509, Loss: 0.02697967179119587, Lr:0.0001\n",
      "Epoch 32, Step: 510, Loss: 0.004729828331619501, Lr:0.0001\n",
      "Epoch 32, Step: 511, Loss: 0.05514813959598541, Lr:0.0001\n",
      "Epoch 32, Step: 512, Loss: 0.002594469813629985, Lr:0.0001\n",
      "Epoch 32, Step: 513, Loss: 0.07040394097566605, Lr:0.0001\n",
      "Epoch 32, Step: 514, Loss: 0.028454206883907318, Lr:0.0001\n",
      "Epoch 32, Step: 515, Loss: 0.015659300610423088, Lr:0.0001\n",
      "Epoch 32, Step: 516, Loss: 0.02452598512172699, Lr:0.0001\n",
      "Epoch 32, Step: 517, Loss: 0.13270938396453857, Lr:0.0001\n",
      "Epoch 32, Step: 518, Loss: 0.0064559211023151875, Lr:0.0001\n",
      "Epoch 32, Step: 519, Loss: 0.03278898075222969, Lr:0.0001\n",
      "Epoch 32, Step: 520, Loss: 0.004573826678097248, Lr:0.0001\n",
      "Epoch 32, Step: 521, Loss: 0.03832818940281868, Lr:0.0001\n",
      "Epoch 32, Step: 522, Loss: 0.0752471536397934, Lr:0.0001\n",
      "Epoch 32, Step: 523, Loss: 0.12048956006765366, Lr:0.0001\n",
      "Epoch 32, Step: 524, Loss: 0.04699812829494476, Lr:0.0001\n",
      "Epoch 32, Step: 525, Loss: 0.039842117577791214, Lr:0.0001\n",
      "Epoch 32, Step: 526, Loss: 0.014922799542546272, Lr:0.0001\n",
      "Epoch 32, Step: 527, Loss: 0.17921438813209534, Lr:0.0001\n",
      "Epoch 32, Step: 528, Loss: 0.06761633604764938, Lr:0.0001\n",
      "Epoch 32, Step: 529, Loss: 0.14158141613006592, Lr:0.0001\n",
      "Epoch 32, Step: 530, Loss: 0.0028629512526094913, Lr:0.0001\n",
      "Epoch 32, Step: 531, Loss: 0.017726736143231392, Lr:0.0001\n",
      "Epoch 32, Step: 532, Loss: 0.09537573903799057, Lr:0.0001\n",
      "Epoch 32, Step: 533, Loss: 0.1592469960451126, Lr:0.0001\n",
      "Epoch 32, Step: 534, Loss: 0.08757245540618896, Lr:0.0001\n",
      "Epoch 32, Step: 535, Loss: 0.009622551500797272, Lr:0.0001\n",
      "Epoch 32, Step: 536, Loss: 0.005183869507163763, Lr:0.0001\n",
      "Epoch 32, Step: 537, Loss: 0.042236004024744034, Lr:0.0001\n",
      "Epoch 32, Step: 538, Loss: 0.008017608895897865, Lr:0.0001\n",
      "Epoch 32, Step: 539, Loss: 0.02161049284040928, Lr:0.0001\n",
      "Epoch 32, Step: 540, Loss: 0.12306451797485352, Lr:0.0001\n",
      "Epoch 32, Step: 541, Loss: 0.04029206559062004, Lr:0.0001\n",
      "Epoch 32, Step: 542, Loss: 0.03297583386301994, Lr:0.0001\n",
      "Epoch 32, Step: 543, Loss: 0.00435241824015975, Lr:0.0001\n",
      "Epoch 32, Step: 544, Loss: 0.000737047172151506, Lr:0.0001\n",
      "Epoch 32, Step: 545, Loss: 0.01166932750493288, Lr:0.0001\n",
      "Epoch 32, Step: 546, Loss: 0.06784150004386902, Lr:0.0001\n",
      "Epoch 32, Step: 547, Loss: 0.017596621066331863, Lr:0.0001\n",
      "Epoch 32, Step: 548, Loss: 0.0335250124335289, Lr:0.0001\n",
      "Epoch 32, Step: 549, Loss: 0.038028765469789505, Lr:0.0001\n",
      "Epoch 32, Step: 550, Loss: 0.22357888519763947, Lr:0.0001\n",
      "Epoch 32, Step: 551, Loss: 0.0014563367003574967, Lr:0.0001\n",
      "Epoch 32, Step: 552, Loss: 0.002270536730065942, Lr:0.0001\n",
      "Epoch 32, Step: 553, Loss: 0.010600426234304905, Lr:0.0001\n",
      "Epoch 32, Step: 554, Loss: 0.06389405578374863, Lr:0.0001\n",
      "Epoch 32, Step: 555, Loss: 0.040734805166721344, Lr:0.0001\n",
      "Epoch 32, Step: 556, Loss: 0.014214702881872654, Lr:0.0001\n",
      "Epoch 32, Step: 557, Loss: 0.12286174297332764, Lr:0.0001\n",
      "Epoch 32, Step: 558, Loss: 0.07312481850385666, Lr:0.0001\n",
      "Epoch 32, Step: 559, Loss: 0.02516726590692997, Lr:0.0001\n",
      "Epoch 32, Step: 560, Loss: 0.16379445791244507, Lr:0.0001\n",
      "Epoch 32, Step: 561, Loss: 0.05786736309528351, Lr:0.0001\n",
      "Epoch 32, Step: 562, Loss: 0.02158237434923649, Lr:0.0001\n",
      "Epoch 32, Step: 563, Loss: 0.0057718208990991116, Lr:0.0001\n",
      "Epoch 32, Step: 564, Loss: 0.0740131214261055, Lr:0.0001\n",
      "Epoch 32, Step: 565, Loss: 0.04367357864975929, Lr:0.0001\n",
      "Epoch 32, Step: 566, Loss: 0.009552105329930782, Lr:0.0001\n",
      "Epoch 32, Step: 567, Loss: 0.03605446591973305, Lr:0.0001\n",
      "Epoch 32, Step: 568, Loss: 0.004582802299410105, Lr:0.0001\n",
      "Epoch 32, Step: 569, Loss: 0.2850814461708069, Lr:0.0001\n",
      "Epoch 32, Step: 570, Loss: 0.052076712250709534, Lr:0.0001\n",
      "Epoch 32, Step: 571, Loss: 0.01502316165715456, Lr:0.0001\n",
      "Epoch 32, Step: 572, Loss: 0.013505581766366959, Lr:0.0001\n",
      "Epoch 32, Step: 573, Loss: 0.0007185390568338335, Lr:0.0001\n",
      "Epoch 32, Step: 574, Loss: 0.13490603864192963, Lr:0.0001\n",
      "Epoch 32, Step: 575, Loss: 0.0031336923129856586, Lr:0.0001\n",
      "Epoch 32, Step: 576, Loss: 0.08782204240560532, Lr:0.0001\n",
      "Epoch 32, Step: 577, Loss: 0.0059805698692798615, Lr:0.0001\n",
      "Epoch 32, Step: 578, Loss: 0.15366797149181366, Lr:0.0001\n",
      "Epoch 32, Step: 579, Loss: 0.035547226667404175, Lr:0.0001\n",
      "Epoch 32, Step: 580, Loss: 0.02436310611665249, Lr:0.0001\n",
      "Epoch 32, Step: 581, Loss: 0.12768176198005676, Lr:0.0001\n",
      "Epoch 32, Step: 582, Loss: 0.007773252669721842, Lr:0.0001\n",
      "Epoch 32, Step: 583, Loss: 0.03929426521062851, Lr:0.0001\n",
      "Epoch 32, Step: 584, Loss: 0.031442973762750626, Lr:0.0001\n",
      "Epoch 32, Step: 585, Loss: 0.02086295560002327, Lr:0.0001\n",
      "Epoch 32, Step: 586, Loss: 0.0036976553965359926, Lr:0.0001\n",
      "Epoch 32, Step: 587, Loss: 0.045563384890556335, Lr:0.0001\n",
      "Epoch 32, Step: 588, Loss: 0.05652923882007599, Lr:0.0001\n",
      "Epoch 32, Step: 589, Loss: 0.00545607740059495, Lr:0.0001\n",
      "Epoch 32, Step: 590, Loss: 0.142464280128479, Lr:0.0001\n",
      "Epoch 32, Step: 591, Loss: 0.0001518956123618409, Lr:0.0001\n",
      "Epoch 32, Step: 592, Loss: 0.07785461843013763, Lr:0.0001\n",
      "Epoch 32, Step: 593, Loss: 0.0019199191592633724, Lr:0.0001\n",
      "Epoch 32, Step: 594, Loss: 0.18977849185466766, Lr:0.0001\n",
      "Epoch 32, Step: 595, Loss: 0.032661162316799164, Lr:0.0001\n",
      "Epoch 32, Step: 596, Loss: 0.0015925116604194045, Lr:0.0001\n",
      "Epoch 32, Step: 597, Loss: 0.011817611753940582, Lr:0.0001\n",
      "Epoch 32, Step: 598, Loss: 0.00621584989130497, Lr:0.0001\n",
      "Epoch 32, Step: 599, Loss: 0.023100610822439194, Lr:0.0001\n",
      "Epoch 32, Step: 600, Loss: 0.007298929151147604, Lr:0.0001\n",
      "Epoch 32, Step: 601, Loss: 0.0733608826994896, Lr:0.0001\n",
      "Epoch 32, Step: 602, Loss: 0.23367883265018463, Lr:0.0001\n",
      "Epoch 32, Step: 603, Loss: 0.06089586764574051, Lr:0.0001\n",
      "Epoch 32, Step: 604, Loss: 0.006526298355311155, Lr:0.0001\n",
      "Epoch 32, Step: 605, Loss: 0.00379952066577971, Lr:0.0001\n",
      "Epoch 32, Step: 606, Loss: 0.2167300134897232, Lr:0.0001\n",
      "Epoch 32, Step: 607, Loss: 0.0007363868644461036, Lr:0.0001\n",
      "Epoch 32, Step: 608, Loss: 0.08810416609048843, Lr:0.0001\n",
      "Epoch 32, Step: 609, Loss: 0.014554308727383614, Lr:0.0001\n",
      "Epoch 32, Step: 610, Loss: 0.020957861095666885, Lr:0.0001\n",
      "Epoch 32, Step: 611, Loss: 0.00935465469956398, Lr:0.0001\n",
      "Epoch 32, Step: 612, Loss: 0.02778755873441696, Lr:0.0001\n",
      "Epoch 32, Step: 613, Loss: 0.04787969961762428, Lr:0.0001\n",
      "Epoch 32, Step: 614, Loss: 0.005533753894269466, Lr:0.0001\n",
      "Epoch 32, Step: 615, Loss: 0.00318625895306468, Lr:0.0001\n",
      "Epoch 32, Step: 616, Loss: 0.09788239747285843, Lr:0.0001\n",
      "Epoch 32, Step: 617, Loss: 0.04520072042942047, Lr:0.0001\n",
      "Epoch 32, Step: 618, Loss: 0.011592261493206024, Lr:0.0001\n",
      "Epoch 32, Step: 619, Loss: 0.06287625432014465, Lr:0.0001\n",
      "Epoch 32, Step: 620, Loss: 0.05800577998161316, Lr:0.0001\n",
      "Epoch 32, Step: 621, Loss: 0.01903826929628849, Lr:0.0001\n",
      "Epoch 32, Step: 622, Loss: 0.027193566784262657, Lr:0.0001\n",
      "Epoch 32, Step: 623, Loss: 0.006060331594198942, Lr:0.0001\n",
      "Epoch 32, Step: 624, Loss: 0.022490747272968292, Lr:0.0001\n",
      "Epoch 32, Step: 625, Loss: 0.02077077329158783, Lr:0.0001\n",
      "Epoch 32, Step: 626, Loss: 0.004165695980191231, Lr:0.0001\n",
      "Epoch 32, Step: 627, Loss: 0.06926171481609344, Lr:0.0001\n",
      "Epoch 32, Step: 628, Loss: 0.07758971303701401, Lr:0.0001\n",
      "Epoch 32, Step: 629, Loss: 0.2366388589143753, Lr:0.0001\n",
      "Epoch 32, Step: 630, Loss: 0.058357976377010345, Lr:0.0001\n",
      "Epoch 32, Step: 631, Loss: 0.09115241467952728, Lr:0.0001\n",
      "Epoch 32, Step: 632, Loss: 0.0037997011095285416, Lr:0.0001\n",
      "Epoch 32, Step: 633, Loss: 0.023640893399715424, Lr:0.0001\n",
      "Epoch 32, Step: 634, Loss: 0.011279482394456863, Lr:0.0001\n",
      "Epoch 32, Step: 635, Loss: 0.13336966931819916, Lr:0.0001\n",
      "Epoch 32, Step: 636, Loss: 0.0050527420826256275, Lr:0.0001\n",
      "Epoch 32, Step: 637, Loss: 0.03047439642250538, Lr:0.0001\n",
      "Epoch 32, Step: 638, Loss: 0.21525827050209045, Lr:0.0001\n",
      "Epoch 32, Step: 639, Loss: 0.003573024645447731, Lr:0.0001\n",
      "Epoch 32, Step: 640, Loss: 0.039215076714754105, Lr:0.0001\n",
      "Epoch 32, Step: 641, Loss: 0.07020185887813568, Lr:0.0001\n",
      "Epoch 32, Step: 642, Loss: 0.026127224788069725, Lr:0.0001\n",
      "Epoch 32, Step: 643, Loss: 0.12135880440473557, Lr:0.0001\n",
      "Epoch 32, Step: 644, Loss: 0.004937042947858572, Lr:0.0001\n",
      "Epoch 32, Step: 645, Loss: 0.08022938668727875, Lr:0.0001\n",
      "Epoch 32, Step: 646, Loss: 0.018415749073028564, Lr:0.0001\n",
      "Epoch 32, Step: 647, Loss: 0.008567370474338531, Lr:0.0001\n",
      "Epoch 32, Step: 648, Loss: 0.09458409249782562, Lr:0.0001\n",
      "Epoch 32, Step: 649, Loss: 0.020969802513718605, Lr:0.0001\n",
      "Epoch 32, Step: 650, Loss: 0.1000651940703392, Lr:0.0001\n",
      "Epoch 32, Step: 651, Loss: 0.034477684646844864, Lr:0.0001\n",
      "Epoch 32, Step: 652, Loss: 0.036583367735147476, Lr:0.0001\n",
      "Epoch 32, Step: 653, Loss: 0.08009958267211914, Lr:0.0001\n",
      "Epoch 32, Step: 654, Loss: 0.10488452762365341, Lr:0.0001\n",
      "Epoch 32, Step: 655, Loss: 0.07221033424139023, Lr:0.0001\n",
      "Epoch 32, Step: 656, Loss: 0.03796592727303505, Lr:0.0001\n",
      "Epoch 32, Step: 657, Loss: 0.02602924033999443, Lr:0.0001\n",
      "Epoch 32, Step: 658, Loss: 0.008920726366341114, Lr:0.0001\n",
      "Epoch 32, Step: 659, Loss: 0.023069042712450027, Lr:0.0001\n",
      "Epoch 32, Step: 660, Loss: 0.0635983794927597, Lr:0.0001\n",
      "Epoch 32, Step: 661, Loss: 0.23828327655792236, Lr:0.0001\n",
      "Epoch 32, Step: 662, Loss: 0.0019255083752796054, Lr:0.0001\n",
      "Epoch 32, Step: 663, Loss: 0.01346156932413578, Lr:0.0001\n",
      "Epoch 32, Step: 664, Loss: 0.00024008350737858564, Lr:0.0001\n",
      "Epoch 32, Step: 665, Loss: 0.00967050064355135, Lr:0.0001\n",
      "Epoch 32, Step: 666, Loss: 0.041221342980861664, Lr:0.0001\n",
      "Epoch 32, Step: 667, Loss: 0.171424001455307, Lr:0.0001\n",
      "Epoch 32, Step: 668, Loss: 0.16308221220970154, Lr:0.0001\n",
      "Epoch 32, Step: 669, Loss: 0.013606016524136066, Lr:0.0001\n",
      "Epoch 32, Step: 670, Loss: 0.10159578919410706, Lr:0.0001\n",
      "Epoch 32, Step: 671, Loss: 0.011143680661916733, Lr:0.0001\n",
      "Epoch 32, Step: 672, Loss: 0.05382109433412552, Lr:0.0001\n",
      "Epoch 32, Step: 673, Loss: 0.05457935482263565, Lr:0.0001\n",
      "Epoch 32, Step: 674, Loss: 0.10361050814390182, Lr:0.0001\n",
      "Epoch 32, Step: 675, Loss: 0.046975888311862946, Lr:0.0001\n",
      "Epoch 32, Step: 676, Loss: 0.08868810534477234, Lr:0.0001\n",
      "Epoch 32, Step: 677, Loss: 0.014408482238650322, Lr:0.0001\n",
      "Epoch 32, Step: 678, Loss: 0.04455547407269478, Lr:0.0001\n",
      "Epoch 32, Step: 679, Loss: 0.003258960787206888, Lr:0.0001\n",
      "Epoch 32, Step: 680, Loss: 0.03608180955052376, Lr:0.0001\n",
      "Epoch 32, Step: 681, Loss: 0.021954143419861794, Lr:0.0001\n",
      "Epoch 32, Step: 682, Loss: 0.058792851865291595, Lr:0.0001\n",
      "Epoch 32, Step: 683, Loss: 0.03452261537313461, Lr:0.0001\n",
      "Epoch 32, Step: 684, Loss: 0.009698773734271526, Lr:0.0001\n",
      "Epoch 32, Step: 685, Loss: 0.030635446310043335, Lr:0.0001\n",
      "Epoch 32, Step: 686, Loss: 0.004614571575075388, Lr:0.0001\n",
      "Epoch 32, Step: 687, Loss: 0.10656563192605972, Lr:0.0001\n",
      "Epoch 32, Step: 688, Loss: 0.0032802619971334934, Lr:0.0001\n",
      "Epoch 32, Step: 689, Loss: 0.004098863806575537, Lr:0.0001\n",
      "Epoch 32, Step: 690, Loss: 0.17360275983810425, Lr:0.0001\n",
      "Epoch 32, Step: 691, Loss: 0.013666331768035889, Lr:0.0001\n",
      "Epoch 32, Step: 692, Loss: 0.05145158991217613, Lr:0.0001\n",
      "Epoch 32, Step: 693, Loss: 0.03047032840549946, Lr:0.0001\n",
      "Epoch 32, Step: 694, Loss: 0.1205781027674675, Lr:0.0001\n",
      "Epoch 32, Step: 695, Loss: 0.06636275351047516, Lr:0.0001\n",
      "Epoch 32, Step: 696, Loss: 0.09886571764945984, Lr:0.0001\n",
      "Epoch 32, Step: 697, Loss: 0.17415764927864075, Lr:0.0001\n",
      "Epoch 32, Step: 698, Loss: 0.07268793135881424, Lr:0.0001\n",
      "Epoch 32, Step: 699, Loss: 0.03594445437192917, Lr:0.0001\n",
      "Epoch 32, Step: 700, Loss: 0.048350006341934204, Lr:0.0001\n",
      "Epoch 32, Step: 701, Loss: 0.1393456757068634, Lr:0.0001\n",
      "Epoch 32, Step: 702, Loss: 0.060534700751304626, Lr:0.0001\n",
      "Epoch 32, Step: 703, Loss: 0.0009668620768934488, Lr:0.0001\n",
      "Epoch 32, Step: 704, Loss: 0.10776913911104202, Lr:0.0001\n",
      "Epoch 32, Step: 705, Loss: 0.030898643657565117, Lr:0.0001\n",
      "Epoch 32, Step: 706, Loss: 0.04620431736111641, Lr:0.0001\n",
      "Epoch 32, Step: 707, Loss: 0.025768635794520378, Lr:0.0001\n",
      "Epoch 32, Step: 708, Loss: 0.34820225834846497, Lr:0.0001\n",
      "Epoch 32, Step: 709, Loss: 0.3775229752063751, Lr:0.0001\n",
      "Epoch 32, Step: 710, Loss: 0.12141832709312439, Lr:0.0001\n",
      "Epoch 32, Step: 711, Loss: 0.010432264767587185, Lr:0.0001\n",
      "Epoch 32, Step: 712, Loss: 0.0988992303609848, Lr:0.0001\n",
      "Epoch 32, Step: 713, Loss: 0.1364065557718277, Lr:0.0001\n",
      "Epoch 32, Step: 714, Loss: 0.001014603883959353, Lr:0.0001\n",
      "Epoch 32, Step: 715, Loss: 0.004152469336986542, Lr:0.0001\n",
      "Epoch 32, Step: 716, Loss: 0.19573161005973816, Lr:0.0001\n",
      "Epoch 32, Step: 717, Loss: 0.010341855697333813, Lr:0.0001\n",
      "Epoch 32, Step: 718, Loss: 0.12752361595630646, Lr:0.0001\n",
      "Epoch 32, Step: 719, Loss: 0.0370665118098259, Lr:0.0001\n",
      "Epoch 32, Step: 720, Loss: 0.285471111536026, Lr:0.0001\n",
      "Epoch 32, Step: 721, Loss: 0.09486549347639084, Lr:0.0001\n",
      "Epoch 32, Step: 722, Loss: 0.00830540619790554, Lr:0.0001\n",
      "Epoch 32, Step: 723, Loss: 0.020773734897375107, Lr:0.0001\n",
      "Epoch 32, Step: 724, Loss: 0.0021022700238972902, Lr:0.0001\n",
      "Epoch 32, Step: 725, Loss: 0.0025468231178820133, Lr:0.0001\n",
      "Epoch 32, Step: 726, Loss: 0.11512415111064911, Lr:0.0001\n",
      "Epoch 32, Step: 727, Loss: 0.001256850897334516, Lr:0.0001\n",
      "Epoch 32, Step: 728, Loss: 0.10643346607685089, Lr:0.0001\n",
      "Epoch 32, Step: 729, Loss: 0.0015388766769319773, Lr:0.0001\n",
      "Epoch 32, Step: 730, Loss: 0.1516655832529068, Lr:0.0001\n",
      "Epoch 32, Step: 731, Loss: 0.11978846043348312, Lr:0.0001\n",
      "Epoch 32, Step: 732, Loss: 0.010578395798802376, Lr:0.0001\n",
      "Epoch 32, Step: 733, Loss: 0.045816533267498016, Lr:0.0001\n",
      "Epoch 32, Step: 734, Loss: 0.12940120697021484, Lr:0.0001\n",
      "Epoch 32, Step: 735, Loss: 0.01765535958111286, Lr:0.0001\n",
      "Epoch 32, Step: 736, Loss: 0.029291760176420212, Lr:0.0001\n",
      "Epoch 32, Step: 737, Loss: 0.00894209835678339, Lr:0.0001\n",
      "Epoch 32, Step: 738, Loss: 0.452551931142807, Lr:0.0001\n",
      "Epoch 32, Step: 739, Loss: 0.009874330833554268, Lr:0.0001\n",
      "Epoch 32, Step: 740, Loss: 0.004743335768580437, Lr:0.0001\n",
      "Epoch 32, Step: 741, Loss: 0.017628902569413185, Lr:0.0001\n",
      "Epoch 32, Step: 742, Loss: 0.01374146994203329, Lr:0.0001\n",
      "Epoch 32, Step: 743, Loss: 0.06219281256198883, Lr:0.0001\n",
      "Epoch 32, Step: 744, Loss: 0.024031879380345345, Lr:0.0001\n",
      "Epoch 32, Step: 745, Loss: 0.06059112027287483, Lr:0.0001\n",
      "Epoch 32, Step: 746, Loss: 0.00839413981884718, Lr:0.0001\n",
      "Epoch 32, Step: 747, Loss: 0.29453328251838684, Lr:0.0001\n",
      "Epoch 32, Step: 748, Loss: 0.00815313495695591, Lr:0.0001\n",
      "Epoch 32, Step: 749, Loss: 0.013290341012179852, Lr:0.0001\n",
      "Epoch 32, Step: 750, Loss: 0.0014557833783328533, Lr:0.0001\n",
      "Epoch 32, Step: 751, Loss: 0.06472960114479065, Lr:0.0001\n",
      "Epoch 32, Step: 752, Loss: 0.02599954605102539, Lr:0.0001\n",
      "Epoch 32, Step: 753, Loss: 0.013164937496185303, Lr:0.0001\n",
      "Epoch 32, Step: 754, Loss: 0.019507545977830887, Lr:0.0001\n",
      "Epoch 32, Step: 755, Loss: 0.09822613000869751, Lr:0.0001\n",
      "Epoch 32, Step: 756, Loss: 0.010342164896428585, Lr:0.0001\n",
      "Epoch 32, Step: 757, Loss: 0.07401739060878754, Lr:0.0001\n",
      "Epoch 32, Step: 758, Loss: 0.05887993052601814, Lr:0.0001\n",
      "Epoch 32, Step: 759, Loss: 0.028554966673254967, Lr:0.0001\n",
      "Epoch 32, Step: 760, Loss: 0.038143426179885864, Lr:0.0001\n",
      "Epoch 32, Step: 761, Loss: 0.022646063938736916, Lr:0.0001\n",
      "Epoch 32, Step: 762, Loss: 0.11815094202756882, Lr:0.0001\n",
      "Epoch 32, Step: 763, Loss: 0.10403798520565033, Lr:0.0001\n",
      "Epoch 32, Step: 764, Loss: 0.06537353992462158, Lr:0.0001\n",
      "Epoch 32, Step: 765, Loss: 0.02100086212158203, Lr:0.0001\n",
      "Epoch 32, Step: 766, Loss: 0.09631425142288208, Lr:0.0001\n",
      "Epoch 32, Step: 767, Loss: 0.12427397072315216, Lr:0.0001\n",
      "Epoch 32, Step: 768, Loss: 0.0024073952808976173, Lr:0.0001\n",
      "Epoch 32, Step: 769, Loss: 0.09126908332109451, Lr:0.0001\n",
      "Epoch 32, Step: 770, Loss: 0.0039020548574626446, Lr:0.0001\n",
      "Epoch 32, Step: 771, Loss: 0.009719756431877613, Lr:0.0001\n",
      "Epoch 32, Step: 772, Loss: 0.0053162528201937675, Lr:0.0001\n",
      "Epoch 32, Step: 773, Loss: 0.001789344591088593, Lr:0.0001\n",
      "Epoch 32, Step: 774, Loss: 0.0831277146935463, Lr:0.0001\n",
      "Epoch 32, Step: 775, Loss: 0.17314402759075165, Lr:0.0001\n",
      "Epoch 32, Step: 776, Loss: 0.32486188411712646, Lr:0.0001\n",
      "Epoch 32, Step: 777, Loss: 0.10520545393228531, Lr:0.0001\n",
      "Epoch 32, Step: 778, Loss: 0.02156130224466324, Lr:0.0001\n",
      "Epoch 32, Step: 779, Loss: 0.1321810632944107, Lr:0.0001\n",
      "Epoch 32, Step: 780, Loss: 0.0027611127588897943, Lr:0.0001\n",
      "Epoch 32, Step: 781, Loss: 0.10278403013944626, Lr:0.0001\n",
      "Epoch 32, Step: 782, Loss: 0.010139044374227524, Lr:0.0001\n",
      "Epoch 32, Step: 783, Loss: 0.15696097910404205, Lr:0.0001\n",
      "Epoch 32, Step: 784, Loss: 0.009668069891631603, Lr:0.0001\n",
      "Epoch 32, Step: 785, Loss: 0.003544076345860958, Lr:0.0001\n",
      "Epoch 32, Step: 786, Loss: 0.019434118643403053, Lr:0.0001\n",
      "Epoch 32, Step: 787, Loss: 0.128173366189003, Lr:0.0001\n",
      "Epoch 32, Step: 788, Loss: 0.05118458718061447, Lr:0.0001\n",
      "Epoch 32, Step: 789, Loss: 0.020722975954413414, Lr:0.0001\n",
      "Epoch 32, Step: 790, Loss: 0.07175639271736145, Lr:0.0001\n",
      "Epoch 32, Step: 791, Loss: 0.03978889808058739, Lr:0.0001\n",
      "Epoch 32, Step: 792, Loss: 0.1683933436870575, Lr:0.0001\n",
      "Epoch 32, Step: 793, Loss: 0.001261477475054562, Lr:0.0001\n",
      "Epoch 32, Step: 794, Loss: 0.0018128056544810534, Lr:0.0001\n",
      "Epoch 32, Step: 795, Loss: 0.04972567409276962, Lr:0.0001\n",
      "Epoch 32, Step: 796, Loss: 0.056650713086128235, Lr:0.0001\n",
      "Epoch 32, Step: 797, Loss: 0.058826714754104614, Lr:0.0001\n",
      "Epoch 32, Step: 798, Loss: 0.009705410338938236, Lr:0.0001\n",
      "Epoch 32, Step: 799, Loss: 0.044072896242141724, Lr:0.0001\n",
      "Epoch 32, Step: 800, Loss: 0.0065951296128332615, Lr:0.0001\n",
      "Epoch 32, Step: 801, Loss: 0.009833217598497868, Lr:0.0001\n",
      "Epoch 32, Step: 802, Loss: 0.04658966511487961, Lr:0.0001\n",
      "Epoch 32, Step: 803, Loss: 0.020279787480831146, Lr:0.0001\n",
      "Epoch 32, Step: 804, Loss: 0.02903788350522518, Lr:0.0001\n",
      "Epoch 32, Step: 805, Loss: 0.043397560715675354, Lr:0.0001\n",
      "Epoch 32, Step: 806, Loss: 0.09573455154895782, Lr:0.0001\n",
      "Epoch 32, Step: 807, Loss: 0.08095033466815948, Lr:0.0001\n",
      "Epoch 32, Step: 808, Loss: 0.005446763709187508, Lr:0.0001\n",
      "Epoch 32, Step: 809, Loss: 0.16171741485595703, Lr:0.0001\n",
      "Epoch 32, Step: 810, Loss: 0.047353629022836685, Lr:0.0001\n",
      "Epoch 32, Step: 811, Loss: 0.01399533823132515, Lr:0.0001\n",
      "Epoch 32, Step: 812, Loss: 0.10838612914085388, Lr:0.0001\n",
      "Epoch 32, Step: 813, Loss: 0.15328456461429596, Lr:0.0001\n",
      "Epoch 32, Step: 814, Loss: 0.0022300563286989927, Lr:0.0001\n",
      "Epoch 32, Step: 815, Loss: 0.0006816720706410706, Lr:0.0001\n",
      "Epoch 32, Step: 816, Loss: 0.06521902978420258, Lr:0.0001\n",
      "Epoch 32, Step: 817, Loss: 0.006217810325324535, Lr:0.0001\n",
      "Epoch 32, Step: 818, Loss: 0.19746027886867523, Lr:0.0001\n",
      "Epoch 32, Step: 819, Loss: 0.033880945295095444, Lr:0.0001\n",
      "Epoch 32, Step: 820, Loss: 0.005884313490241766, Lr:0.0001\n",
      "Epoch 32, Step: 821, Loss: 0.03419750556349754, Lr:0.0001\n",
      "Epoch 32, Step: 822, Loss: 0.02140543796122074, Lr:0.0001\n",
      "Epoch 32, Step: 823, Loss: 0.0005660102469846606, Lr:0.0001\n",
      "Epoch 32, Step: 824, Loss: 0.01115779485553503, Lr:0.0001\n",
      "Epoch 32, Step: 825, Loss: 0.1472136527299881, Lr:0.0001\n",
      "Epoch 32, Step: 826, Loss: 0.0038377055898308754, Lr:0.0001\n",
      "Epoch 32, Step: 827, Loss: 0.008145330473780632, Lr:0.0001\n",
      "Epoch 32, Step: 828, Loss: 0.04183737188577652, Lr:0.0001\n",
      "Epoch 32, Step: 829, Loss: 0.035466838628053665, Lr:0.0001\n",
      "Epoch 32, Step: 830, Loss: 0.14866013824939728, Lr:0.0001\n",
      "Epoch 32, Step: 831, Loss: 0.027613556012511253, Lr:0.0001\n",
      "Epoch 32, Step: 832, Loss: 0.03290395811200142, Lr:0.0001\n",
      "Epoch 32, Step: 833, Loss: 0.09332429617643356, Lr:0.0001\n",
      "Epoch 32, Step: 834, Loss: 0.019436676055192947, Lr:0.0001\n",
      "Epoch 32, Step: 835, Loss: 0.06182039529085159, Lr:0.0001\n",
      "Epoch 32, Step: 836, Loss: 0.020136326551437378, Lr:0.0001\n",
      "Epoch 32, Step: 837, Loss: 0.011937546543776989, Lr:0.0001\n",
      "Epoch 32, Step: 838, Loss: 0.0014821091899648309, Lr:0.0001\n",
      "Epoch 32, Step: 839, Loss: 0.0057563744485378265, Lr:0.0001\n",
      "Epoch 32, Step: 840, Loss: 0.24592171609401703, Lr:0.0001\n",
      "Epoch 32, Step: 841, Loss: 0.07687816768884659, Lr:0.0001\n",
      "Epoch 32, Step: 842, Loss: 0.004495267756283283, Lr:0.0001\n",
      "Epoch 32, Step: 843, Loss: 0.0065607428550720215, Lr:0.0001\n",
      "Epoch 32, Step: 844, Loss: 0.2986043095588684, Lr:0.0001\n",
      "Epoch 32, Step: 845, Loss: 0.016072720289230347, Lr:0.0001\n",
      "Epoch 32, Step: 846, Loss: 0.022764643654227257, Lr:0.0001\n",
      "Epoch 32, Step: 847, Loss: 0.006172441877424717, Lr:0.0001\n",
      "Epoch 32, Step: 848, Loss: 0.014722535386681557, Lr:0.0001\n",
      "Epoch 32, Step: 849, Loss: 0.009176058694720268, Lr:0.0001\n",
      "Epoch 32, Step: 850, Loss: 0.01487688161432743, Lr:0.0001\n",
      "Epoch 32, Step: 851, Loss: 0.2599668502807617, Lr:0.0001\n",
      "Epoch 32, Step: 852, Loss: 0.0036273791920393705, Lr:0.0001\n",
      "Epoch 32, Step: 853, Loss: 0.003004983766004443, Lr:0.0001\n",
      "Epoch 32, Step: 854, Loss: 0.06813859939575195, Lr:0.0001\n",
      "Epoch 32, Step: 855, Loss: 0.025011595338582993, Lr:0.0001\n",
      "Epoch 32, Step: 856, Loss: 0.10086964815855026, Lr:0.0001\n",
      "Epoch 32, Step: 857, Loss: 0.11532152444124222, Lr:0.0001\n",
      "Epoch 32, Step: 858, Loss: 0.06366508454084396, Lr:0.0001\n",
      "Epoch 32, Step: 859, Loss: 0.008229863829910755, Lr:0.0001\n",
      "Epoch 32, Step: 860, Loss: 0.0012138164602220058, Lr:0.0001\n",
      "Epoch 32, Step: 861, Loss: 0.013631198555231094, Lr:0.0001\n",
      "Epoch 32, Step: 862, Loss: 0.06464772671461105, Lr:0.0001\n",
      "Epoch 32, Step: 863, Loss: 0.03783164545893669, Lr:0.0001\n",
      "Epoch 32, Step: 864, Loss: 0.010865231975913048, Lr:0.0001\n",
      "Epoch 32, Step: 865, Loss: 0.0051842061802744865, Lr:0.0001\n",
      "Epoch 32, Step: 866, Loss: 0.09238184988498688, Lr:0.0001\n",
      "Epoch 32, Step: 867, Loss: 0.074580617249012, Lr:0.0001\n",
      "Epoch 32, Step: 868, Loss: 0.020261846482753754, Lr:0.0001\n",
      "Epoch 32, Step: 869, Loss: 0.07513407617807388, Lr:0.0001\n",
      "Epoch 32, Step: 870, Loss: 0.10763072967529297, Lr:0.0001\n",
      "Epoch 32, Step: 871, Loss: 0.017743248492479324, Lr:0.0001\n",
      "Epoch 32, Step: 872, Loss: 0.06537473201751709, Lr:0.0001\n",
      "Epoch 32, Step: 873, Loss: 0.01235046423971653, Lr:0.0001\n",
      "Epoch 32, Step: 874, Loss: 0.0879761204123497, Lr:0.0001\n",
      "Epoch 32, Step: 875, Loss: 0.15655726194381714, Lr:0.0001\n",
      "Epoch 32, Step: 876, Loss: 0.00166256760712713, Lr:0.0001\n",
      "Epoch 32, Step: 877, Loss: 0.02980620041489601, Lr:0.0001\n",
      "Epoch 32, Step: 878, Loss: 0.0120927132666111, Lr:0.0001\n",
      "Epoch 32, Step: 879, Loss: 0.05828485265374184, Lr:0.0001\n",
      "Epoch 32, Step: 880, Loss: 0.0060849664732813835, Lr:0.0001\n",
      "Epoch 32, Step: 881, Loss: 0.02200927957892418, Lr:0.0001\n",
      "Epoch 32, Step: 882, Loss: 0.15669329464435577, Lr:0.0001\n",
      "Epoch 32, Step: 883, Loss: 0.08205060660839081, Lr:0.0001\n",
      "Epoch 32, Step: 884, Loss: 0.010976025834679604, Lr:0.0001\n",
      "Epoch 32, Step: 885, Loss: 0.06795896589756012, Lr:0.0001\n",
      "Epoch 32, Step: 886, Loss: 0.06414567679166794, Lr:0.0001\n",
      "Epoch 32, Step: 887, Loss: 0.007147524040192366, Lr:0.0001\n",
      "Epoch 32, Step: 888, Loss: 0.0032060181256383657, Lr:0.0001\n",
      "Epoch 32, Step: 889, Loss: 0.013657752424478531, Lr:0.0001\n",
      "Epoch 32, Step: 890, Loss: 0.0779004693031311, Lr:0.0001\n",
      "Epoch 32, Step: 891, Loss: 0.09701460599899292, Lr:0.0001\n",
      "Epoch 32, Step: 892, Loss: 0.036705341190099716, Lr:0.0001\n",
      "Epoch 32, Step: 893, Loss: 0.006516200490295887, Lr:0.0001\n",
      "Epoch 32, Step: 894, Loss: 0.05667983740568161, Lr:0.0001\n",
      "Epoch 32, Step: 895, Loss: 0.01740245893597603, Lr:0.0001\n",
      "Epoch 32, Step: 896, Loss: 0.003426040057092905, Lr:0.0001\n",
      "Epoch 32, Step: 897, Loss: 0.005390007980167866, Lr:0.0001\n",
      "Epoch 32, Step: 898, Loss: 0.005911225453019142, Lr:0.0001\n",
      "Epoch 32, Step: 899, Loss: 0.01242358610033989, Lr:0.0001\n",
      "Epoch 32, Step: 900, Loss: 0.06170717626810074, Lr:0.0001\n",
      "Epoch 32, Step: 901, Loss: 0.002973726484924555, Lr:0.0001\n",
      "Epoch 32, Step: 902, Loss: 0.024558141827583313, Lr:0.0001\n",
      "Epoch 32, Step: 903, Loss: 0.04451989009976387, Lr:0.0001\n",
      "Epoch 32, Step: 904, Loss: 0.009518938139081001, Lr:0.0001\n",
      "Epoch 32, Step: 905, Loss: 0.0018245179671794176, Lr:0.0001\n",
      "Epoch 32, Step: 906, Loss: 0.036495812237262726, Lr:0.0001\n",
      "Epoch 32, Step: 907, Loss: 0.004291872028261423, Lr:0.0001\n",
      "Epoch 32, Step: 908, Loss: 0.06993670016527176, Lr:0.0001\n",
      "Epoch 32, Step: 909, Loss: 0.0650838240981102, Lr:0.0001\n",
      "Epoch 32, Step: 910, Loss: 0.21910393238067627, Lr:0.0001\n",
      "Epoch 32, Step: 911, Loss: 0.014680171385407448, Lr:0.0001\n",
      "Epoch 32, Step: 912, Loss: 0.005535932257771492, Lr:0.0001\n",
      "Epoch 32, Step: 913, Loss: 0.023374782875180244, Lr:0.0001\n",
      "Epoch 32, Step: 914, Loss: 0.0071353004314005375, Lr:0.0001\n",
      "Epoch 32, Step: 915, Loss: 0.016577046364545822, Lr:0.0001\n",
      "Epoch 32, Step: 916, Loss: 0.05158473551273346, Lr:0.0001\n",
      "Epoch 32, Step: 917, Loss: 0.3505341410636902, Lr:0.0001\n",
      "Epoch 32, Step: 918, Loss: 0.005367573816329241, Lr:0.0001\n",
      "Epoch 32, Step: 919, Loss: 0.024587275460362434, Lr:0.0001\n",
      "Epoch 32, Step: 920, Loss: 0.0030639171600341797, Lr:0.0001\n",
      "Epoch 32, Step: 921, Loss: 0.001995079917833209, Lr:0.0001\n",
      "Epoch 32, Step: 922, Loss: 0.010461033321917057, Lr:0.0001\n",
      "Epoch 32, Step: 923, Loss: 0.00353294238448143, Lr:0.0001\n",
      "Epoch 32, Step: 924, Loss: 0.010715056210756302, Lr:0.0001\n",
      "Epoch 32, Step: 925, Loss: 0.01097506657242775, Lr:0.0001\n",
      "Epoch 32, Step: 926, Loss: 0.006878904066979885, Lr:0.0001\n",
      "Epoch 32, Step: 927, Loss: 0.044346895068883896, Lr:0.0001\n",
      "Epoch 32, Step: 928, Loss: 0.031892336905002594, Lr:0.0001\n",
      "Epoch 32, Step: 929, Loss: 0.2308001071214676, Lr:0.0001\n",
      "Epoch 32, Step: 930, Loss: 0.0003203914384357631, Lr:0.0001\n",
      "Epoch 32, Step: 931, Loss: 0.028446365147829056, Lr:0.0001\n",
      "Epoch 32, Step: 932, Loss: 0.03445066139101982, Lr:0.0001\n",
      "Epoch 32, Step: 933, Loss: 0.024633072316646576, Lr:0.0001\n",
      "Epoch 32, Step: 934, Loss: 0.009467021562159061, Lr:0.0001\n",
      "Epoch 32, Step: 935, Loss: 0.010847672820091248, Lr:0.0001\n",
      "Epoch 32, Step: 936, Loss: 0.00911870039999485, Lr:0.0001\n",
      "Epoch 32, Step: 937, Loss: 0.04303127899765968, Lr:0.0001\n",
      "Epoch 32, Step: 938, Loss: 0.017273956909775734, Lr:0.0001\n",
      "Epoch 32, Step: 939, Loss: 0.00839282013475895, Lr:0.0001\n",
      "Epoch 32, Step: 940, Loss: 0.001970181940123439, Lr:0.0001\n",
      "Epoch 32, Step: 941, Loss: 0.004601621069014072, Lr:0.0001\n",
      "Epoch 32, Step: 942, Loss: 0.17531102895736694, Lr:0.0001\n",
      "Epoch 32, Step: 943, Loss: 0.059570781886577606, Lr:0.0001\n",
      "Epoch 32, Step: 944, Loss: 0.022604377940297127, Lr:0.0001\n",
      "Epoch 32, Step: 945, Loss: 0.005852325353771448, Lr:0.0001\n",
      "Epoch 32, Step: 946, Loss: 0.0007349383668042719, Lr:0.0001\n",
      "Epoch 32, Step: 947, Loss: 0.00368110416457057, Lr:0.0001\n",
      "Epoch 32, Step: 948, Loss: 0.030669596046209335, Lr:0.0001\n",
      "Epoch 32, Step: 949, Loss: 0.026710061356425285, Lr:0.0001\n",
      "Epoch 32, Step: 950, Loss: 0.00703542260453105, Lr:0.0001\n",
      "Epoch 32, Step: 951, Loss: 0.3856532871723175, Lr:0.0001\n",
      "Epoch 32, Step: 952, Loss: 0.21780312061309814, Lr:0.0001\n",
      "Epoch 32, Step: 953, Loss: 0.0018835596274584532, Lr:0.0001\n",
      "Epoch 32, Step: 954, Loss: 0.06077255681157112, Lr:0.0001\n",
      "Epoch 32, Step: 955, Loss: 0.09901849925518036, Lr:0.0001\n",
      "Epoch 32, Step: 956, Loss: 0.016509264707565308, Lr:0.0001\n",
      "Epoch 32, Step: 957, Loss: 0.0014919769018888474, Lr:0.0001\n",
      "Epoch 32, Step: 958, Loss: 0.007903852500021458, Lr:0.0001\n",
      "Epoch 32, Step: 959, Loss: 0.04392658919095993, Lr:0.0001\n",
      "Epoch 32, Step: 960, Loss: 0.02954021655023098, Lr:0.0001\n",
      "Epoch 32, Step: 961, Loss: 0.0852213203907013, Lr:0.0001\n",
      "Epoch 32, Step: 962, Loss: 0.07846043258905411, Lr:0.0001\n",
      "Epoch 32, Step: 963, Loss: 0.011495589278638363, Lr:0.0001\n",
      "Epoch 32, Step: 964, Loss: 0.0037745682056993246, Lr:0.0001\n",
      "Epoch 32, Step: 965, Loss: 0.2109450101852417, Lr:0.0001\n",
      "Epoch 32, Step: 966, Loss: 0.02994568832218647, Lr:0.0001\n",
      "Epoch 32, Step: 967, Loss: 0.03458765521645546, Lr:0.0001\n",
      "Epoch 32, Step: 968, Loss: 0.0557892844080925, Lr:0.0001\n",
      "Epoch 32, Step: 969, Loss: 0.03045233152806759, Lr:0.0001\n",
      "Epoch 32, Step: 970, Loss: 0.0248318612575531, Lr:0.0001\n",
      "Epoch 32, Step: 971, Loss: 0.3173665702342987, Lr:0.0001\n",
      "Epoch 32, Step: 972, Loss: 0.04622914642095566, Lr:0.0001\n",
      "Epoch 32, Step: 973, Loss: 0.022973306477069855, Lr:0.0001\n",
      "Epoch 32, Step: 974, Loss: 0.1458868384361267, Lr:0.0001\n",
      "Epoch 32, Step: 975, Loss: 0.1324024647474289, Lr:0.0001\n",
      "Epoch 32, Step: 976, Loss: 0.028512435033917427, Lr:0.0001\n",
      "Epoch 32, Step: 977, Loss: 0.08896272629499435, Lr:0.0001\n",
      "Epoch 32, Step: 978, Loss: 0.08932123333215714, Lr:0.0001\n",
      "Epoch 32, Step: 979, Loss: 0.0006190043059177697, Lr:0.0001\n",
      "Epoch 32, Step: 980, Loss: 0.23767660558223724, Lr:0.0001\n",
      "Epoch 32, Step: 981, Loss: 0.019811661913990974, Lr:0.0001\n",
      "Epoch 32, Step: 982, Loss: 0.20361526310443878, Lr:0.0001\n",
      "Epoch 32, Step: 983, Loss: 0.17502892017364502, Lr:0.0001\n",
      "Epoch 32, Step: 984, Loss: 0.06982765346765518, Lr:0.0001\n",
      "Epoch 32, Step: 985, Loss: 0.10378345102071762, Lr:0.0001\n",
      "Epoch 32, Step: 986, Loss: 0.004695907235145569, Lr:0.0001\n",
      "Epoch 32, Step: 987, Loss: 0.039515379816293716, Lr:0.0001\n",
      "Epoch 32, Step: 988, Loss: 0.0036766119301319122, Lr:0.0001\n",
      "Epoch 32, Step: 989, Loss: 0.015377892181277275, Lr:0.0001\n",
      "Epoch 32, Step: 990, Loss: 0.003993812948465347, Lr:0.0001\n",
      "Epoch 32, Step: 991, Loss: 0.15116088092327118, Lr:0.0001\n",
      "Epoch 32, Step: 992, Loss: 0.013572966679930687, Lr:0.0001\n",
      "Epoch 32, Step: 993, Loss: 0.059603773057460785, Lr:0.0001\n",
      "Epoch 32, Step: 994, Loss: 0.03423183038830757, Lr:0.0001\n",
      "Epoch 32, Step: 995, Loss: 0.013281655497848988, Lr:0.0001\n",
      "Epoch 32, Step: 996, Loss: 0.007814201526343822, Lr:0.0001\n",
      "Epoch 32, Step: 997, Loss: 0.05758950859308243, Lr:0.0001\n",
      "Epoch 32, Step: 998, Loss: 0.18767060339450836, Lr:0.0001\n",
      "Epoch 32, Step: 999, Loss: 0.019520733505487442, Lr:0.0001\n",
      "Epoch 32, Step: 1000, Loss: 0.32290413975715637, Lr:0.0001\n",
      "Epoch 32, Step: 1001, Loss: 0.024592196568846703, Lr:0.0001\n",
      "Epoch 32, Step: 1002, Loss: 0.08202175050973892, Lr:0.0001\n",
      "Epoch 32, Step: 1003, Loss: 0.006236894056200981, Lr:0.0001\n",
      "Epoch 32, Step: 1004, Loss: 0.03809643164277077, Lr:0.0001\n",
      "Epoch 32, Step: 1005, Loss: 0.07359002530574799, Lr:0.0001\n",
      "Epoch 32, Step: 1006, Loss: 0.005499631632119417, Lr:0.0001\n",
      "Epoch 32, Step: 1007, Loss: 0.05584542453289032, Lr:0.0001\n",
      "Epoch 32, Step: 1008, Loss: 0.015320325270295143, Lr:0.0001\n",
      "Epoch 32, Step: 1009, Loss: 0.005003148689866066, Lr:0.0001\n",
      "Epoch 32, Step: 1010, Loss: 0.033618733286857605, Lr:0.0001\n",
      "Epoch 32, Step: 1011, Loss: 0.012576817534863949, Lr:0.0001\n",
      "Epoch 32, Step: 1012, Loss: 0.008670925162732601, Lr:0.0001\n",
      "Epoch 32, Step: 1013, Loss: 0.10286865383386612, Lr:0.0001\n",
      "Epoch 32, Step: 1014, Loss: 0.008541242219507694, Lr:0.0001\n",
      "Epoch 32, Step: 1015, Loss: 0.0030037774704396725, Lr:0.0001\n",
      "Epoch 32, Step: 1016, Loss: 0.004277896601706743, Lr:0.0001\n",
      "Epoch 32, Step: 1017, Loss: 0.001618859707377851, Lr:0.0001\n",
      "Epoch 32, Step: 1018, Loss: 0.23921039700508118, Lr:0.0001\n",
      "Epoch 32, Step: 1019, Loss: 0.20687371492385864, Lr:0.0001\n",
      "Epoch 32, Step: 1020, Loss: 0.20823480188846588, Lr:0.0001\n",
      "Epoch 32, Step: 1021, Loss: 0.4435485601425171, Lr:0.0001\n",
      "Epoch 32, Step: 1022, Loss: 0.01004007738083601, Lr:0.0001\n",
      "Epoch 32, Step: 1023, Loss: 0.01646329276263714, Lr:0.0001\n",
      "Epoch 32, Step: 1024, Loss: 0.003579735290259123, Lr:0.0001\n",
      "Epoch 32, Step: 1025, Loss: 0.050582461059093475, Lr:0.0001\n",
      "Epoch 32, Step: 1026, Loss: 0.16782404482364655, Lr:0.0001\n",
      "Epoch 32, Step: 1027, Loss: 0.03530400991439819, Lr:0.0001\n",
      "Epoch 32, Step: 1028, Loss: 0.010158003307878971, Lr:0.0001\n",
      "Epoch 32, Step: 1029, Loss: 0.12188500165939331, Lr:0.0001\n",
      "Epoch 32, Step: 1030, Loss: 0.012165351770818233, Lr:0.0001\n",
      "Epoch 32, Step: 1031, Loss: 0.12084939330816269, Lr:0.0001\n",
      "Epoch 32, Step: 1032, Loss: 0.0061644003726542, Lr:0.0001\n",
      "Epoch 32, Step: 1033, Loss: 0.0025145469699054956, Lr:0.0001\n",
      "Epoch 32, Step: 1034, Loss: 0.014923927374184132, Lr:0.0001\n",
      "Epoch 32, Step: 1035, Loss: 0.014979541301727295, Lr:0.0001\n",
      "Epoch 32, Step: 1036, Loss: 0.06524970382452011, Lr:0.0001\n",
      "Epoch 32, Step: 1037, Loss: 0.05348420888185501, Lr:0.0001\n",
      "Epoch 32, Step: 1038, Loss: 0.044390253722667694, Lr:0.0001\n",
      "Epoch 32, Step: 1039, Loss: 0.017766324803233147, Lr:0.0001\n",
      "Epoch 32, Step: 1040, Loss: 0.06695032119750977, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 32\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:16 loss: 0.0011 (0.0011) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.2876 data: 0.1156 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.0001 (0.0021) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.2913 data: 0.1191 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0000 (0.0171) acc1: 100.0000 (99.4048) acc5: 100.0000 (100.0000) time: 0.2931 data: 0.1201 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.0022 (0.0698) acc1: 100.0000 (97.9839) acc5: 100.0000 (100.0000) time: 0.2975 data: 0.1223 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.0907 (0.0994) acc1: 93.7500 (96.4939) acc5: 100.0000 (100.0000) time: 0.2985 data: 0.1225 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0574 (0.1373) acc1: 93.7500 (95.9559) acc5: 100.0000 (100.0000) time: 0.2933 data: 0.1183 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0524 (0.1567) acc1: 100.0000 (95.8002) acc5: 100.0000 (100.0000) time: 0.2775 data: 0.1111 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.2894 s / it)\n",
      "* Acc@1 95.800 Acc@5 100.000 loss 0.157\n",
      "Accuracy of the network on the 881 test image: 95.8%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 33, Step: 0, Loss: 0.06667106598615646, Lr:0.0001\n",
      "Epoch 33, Step: 1, Loss: 0.011569924652576447, Lr:0.0001\n",
      "Epoch 33, Step: 2, Loss: 0.005370621103793383, Lr:0.0001\n",
      "Epoch 33, Step: 3, Loss: 0.012370126321911812, Lr:0.0001\n",
      "Epoch 33, Step: 4, Loss: 0.05156205967068672, Lr:0.0001\n",
      "Epoch 33, Step: 5, Loss: 0.12915199995040894, Lr:0.0001\n",
      "Epoch 33, Step: 6, Loss: 0.02397831715643406, Lr:0.0001\n",
      "Epoch 33, Step: 7, Loss: 0.024110868573188782, Lr:0.0001\n",
      "Epoch 33, Step: 8, Loss: 0.0044496022164821625, Lr:0.0001\n",
      "Epoch 33, Step: 9, Loss: 0.0179424025118351, Lr:0.0001\n",
      "Epoch 33, Step: 10, Loss: 0.04600689560174942, Lr:0.0001\n",
      "Epoch 33, Step: 11, Loss: 0.077081598341465, Lr:0.0001\n",
      "Epoch 33, Step: 12, Loss: 0.08125942945480347, Lr:0.0001\n",
      "Epoch 33, Step: 13, Loss: 0.016447555273771286, Lr:0.0001\n",
      "Epoch 33, Step: 14, Loss: 0.014024262316524982, Lr:0.0001\n",
      "Epoch 33, Step: 15, Loss: 0.002310739131644368, Lr:0.0001\n",
      "Epoch 33, Step: 16, Loss: 0.04401456564664841, Lr:0.0001\n",
      "Epoch 33, Step: 17, Loss: 0.0032190720085054636, Lr:0.0001\n",
      "Epoch 33, Step: 18, Loss: 0.022407038137316704, Lr:0.0001\n",
      "Epoch 33, Step: 19, Loss: 0.05080287158489227, Lr:0.0001\n",
      "Epoch 33, Step: 20, Loss: 0.12924447655677795, Lr:0.0001\n",
      "Epoch 33, Step: 21, Loss: 0.0163381639868021, Lr:0.0001\n",
      "Epoch 33, Step: 22, Loss: 0.018334979191422462, Lr:0.0001\n",
      "Epoch 33, Step: 23, Loss: 0.09743190556764603, Lr:0.0001\n",
      "Epoch 33, Step: 24, Loss: 0.28661876916885376, Lr:0.0001\n",
      "Epoch 33, Step: 25, Loss: 0.07219313830137253, Lr:0.0001\n",
      "Epoch 33, Step: 26, Loss: 0.03744831308722496, Lr:0.0001\n",
      "Epoch 33, Step: 27, Loss: 0.010289140976965427, Lr:0.0001\n",
      "Epoch 33, Step: 28, Loss: 0.09058919548988342, Lr:0.0001\n",
      "Epoch 33, Step: 29, Loss: 0.032823916524648666, Lr:0.0001\n",
      "Epoch 33, Step: 30, Loss: 0.024385491386055946, Lr:0.0001\n",
      "Epoch 33, Step: 31, Loss: 0.000363428785931319, Lr:0.0001\n",
      "Epoch 33, Step: 32, Loss: 0.030460774898529053, Lr:0.0001\n",
      "Epoch 33, Step: 33, Loss: 0.008573882281780243, Lr:0.0001\n",
      "Epoch 33, Step: 34, Loss: 5.7801895309239626e-05, Lr:0.0001\n",
      "Epoch 33, Step: 35, Loss: 0.059300508350133896, Lr:0.0001\n",
      "Epoch 33, Step: 36, Loss: 0.1423206776380539, Lr:0.0001\n",
      "Epoch 33, Step: 37, Loss: 0.016856666654348373, Lr:0.0001\n",
      "Epoch 33, Step: 38, Loss: 0.005357045214623213, Lr:0.0001\n",
      "Epoch 33, Step: 39, Loss: 0.0020248345099389553, Lr:0.0001\n",
      "Epoch 33, Step: 40, Loss: 0.017184844240546227, Lr:0.0001\n",
      "Epoch 33, Step: 41, Loss: 0.004909035749733448, Lr:0.0001\n",
      "Epoch 33, Step: 42, Loss: 0.00032709463266655803, Lr:0.0001\n",
      "Epoch 33, Step: 43, Loss: 0.0027683705557137728, Lr:0.0001\n",
      "Epoch 33, Step: 44, Loss: 0.07560387998819351, Lr:0.0001\n",
      "Epoch 33, Step: 45, Loss: 0.024440979585051537, Lr:0.0001\n",
      "Epoch 33, Step: 46, Loss: 0.015707362443208694, Lr:0.0001\n",
      "Epoch 33, Step: 47, Loss: 0.018765287473797798, Lr:0.0001\n",
      "Epoch 33, Step: 48, Loss: 0.1347275823354721, Lr:0.0001\n",
      "Epoch 33, Step: 49, Loss: 0.021737003698945045, Lr:0.0001\n",
      "Epoch 33, Step: 50, Loss: 0.028529874980449677, Lr:0.0001\n",
      "Epoch 33, Step: 51, Loss: 0.019557878375053406, Lr:0.0001\n",
      "Epoch 33, Step: 52, Loss: 0.002264300361275673, Lr:0.0001\n",
      "Epoch 33, Step: 53, Loss: 0.07230377942323685, Lr:0.0001\n",
      "Epoch 33, Step: 54, Loss: 0.01593913696706295, Lr:0.0001\n",
      "Epoch 33, Step: 55, Loss: 0.004662740509957075, Lr:0.0001\n",
      "Epoch 33, Step: 56, Loss: 0.001869443105533719, Lr:0.0001\n",
      "Epoch 33, Step: 57, Loss: 0.05261605978012085, Lr:0.0001\n",
      "Epoch 33, Step: 58, Loss: 0.11712600290775299, Lr:0.0001\n",
      "Epoch 33, Step: 59, Loss: 0.021695807576179504, Lr:0.0001\n",
      "Epoch 33, Step: 60, Loss: 0.046220943331718445, Lr:0.0001\n",
      "Epoch 33, Step: 61, Loss: 0.03562534973025322, Lr:0.0001\n",
      "Epoch 33, Step: 62, Loss: 0.16449998319149017, Lr:0.0001\n",
      "Epoch 33, Step: 63, Loss: 0.025351420044898987, Lr:0.0001\n",
      "Epoch 33, Step: 64, Loss: 0.0025908593088388443, Lr:0.0001\n",
      "Epoch 33, Step: 65, Loss: 0.07230185717344284, Lr:0.0001\n",
      "Epoch 33, Step: 66, Loss: 0.1191655695438385, Lr:0.0001\n",
      "Epoch 33, Step: 67, Loss: 0.0023038319777697325, Lr:0.0001\n",
      "Epoch 33, Step: 68, Loss: 0.010272456333041191, Lr:0.0001\n",
      "Epoch 33, Step: 69, Loss: 0.10693024098873138, Lr:0.0001\n",
      "Epoch 33, Step: 70, Loss: 0.03845418989658356, Lr:0.0001\n",
      "Epoch 33, Step: 71, Loss: 0.017727073282003403, Lr:0.0001\n",
      "Epoch 33, Step: 72, Loss: 0.00915117934346199, Lr:0.0001\n",
      "Epoch 33, Step: 73, Loss: 0.09564591199159622, Lr:0.0001\n",
      "Epoch 33, Step: 74, Loss: 0.011988955549895763, Lr:0.0001\n",
      "Epoch 33, Step: 75, Loss: 0.049686748534440994, Lr:0.0001\n",
      "Epoch 33, Step: 76, Loss: 0.004474296234548092, Lr:0.0001\n",
      "Epoch 33, Step: 77, Loss: 0.008537228219211102, Lr:0.0001\n",
      "Epoch 33, Step: 78, Loss: 0.004059250000864267, Lr:0.0001\n",
      "Epoch 33, Step: 79, Loss: 0.04526424780488014, Lr:0.0001\n",
      "Epoch 33, Step: 80, Loss: 0.04708430543541908, Lr:0.0001\n",
      "Epoch 33, Step: 81, Loss: 0.06372331827878952, Lr:0.0001\n",
      "Epoch 33, Step: 82, Loss: 0.02832472138106823, Lr:0.0001\n",
      "Epoch 33, Step: 83, Loss: 0.039017096161842346, Lr:0.0001\n",
      "Epoch 33, Step: 84, Loss: 0.11965782940387726, Lr:0.0001\n",
      "Epoch 33, Step: 85, Loss: 0.04397111013531685, Lr:0.0001\n",
      "Epoch 33, Step: 86, Loss: 0.024096647277474403, Lr:0.0001\n",
      "Epoch 33, Step: 87, Loss: 0.21421411633491516, Lr:0.0001\n",
      "Epoch 33, Step: 88, Loss: 0.003770353738218546, Lr:0.0001\n",
      "Epoch 33, Step: 89, Loss: 0.12095636129379272, Lr:0.0001\n",
      "Epoch 33, Step: 90, Loss: 0.0005925186560489237, Lr:0.0001\n",
      "Epoch 33, Step: 91, Loss: 0.4093818962574005, Lr:0.0001\n",
      "Epoch 33, Step: 92, Loss: 0.011426141485571861, Lr:0.0001\n",
      "Epoch 33, Step: 93, Loss: 0.0022942274808883667, Lr:0.0001\n",
      "Epoch 33, Step: 94, Loss: 0.16847661137580872, Lr:0.0001\n",
      "Epoch 33, Step: 95, Loss: 0.019566699862480164, Lr:0.0001\n",
      "Epoch 33, Step: 96, Loss: 0.013368474319577217, Lr:0.0001\n",
      "Epoch 33, Step: 97, Loss: 0.19730105996131897, Lr:0.0001\n",
      "Epoch 33, Step: 98, Loss: 0.005373060237616301, Lr:0.0001\n",
      "Epoch 33, Step: 99, Loss: 0.029697155579924583, Lr:0.0001\n",
      "Epoch 33, Step: 100, Loss: 0.03658571094274521, Lr:0.0001\n",
      "Epoch 33, Step: 101, Loss: 0.01647106744349003, Lr:0.0001\n",
      "Epoch 33, Step: 102, Loss: 0.05222778394818306, Lr:0.0001\n",
      "Epoch 33, Step: 103, Loss: 0.02785433456301689, Lr:0.0001\n",
      "Epoch 33, Step: 104, Loss: 0.031967680901288986, Lr:0.0001\n",
      "Epoch 33, Step: 105, Loss: 0.0054113310761749744, Lr:0.0001\n",
      "Epoch 33, Step: 106, Loss: 0.09314548969268799, Lr:0.0001\n",
      "Epoch 33, Step: 107, Loss: 0.024204794317483902, Lr:0.0001\n",
      "Epoch 33, Step: 108, Loss: 0.315325528383255, Lr:0.0001\n",
      "Epoch 33, Step: 109, Loss: 0.043172117322683334, Lr:0.0001\n",
      "Epoch 33, Step: 110, Loss: 0.06210539489984512, Lr:0.0001\n",
      "Epoch 33, Step: 111, Loss: 0.0864788144826889, Lr:0.0001\n",
      "Epoch 33, Step: 112, Loss: 0.037701316177845, Lr:0.0001\n",
      "Epoch 33, Step: 113, Loss: 0.046780072152614594, Lr:0.0001\n",
      "Epoch 33, Step: 114, Loss: 0.0508754625916481, Lr:0.0001\n",
      "Epoch 33, Step: 115, Loss: 0.052993256598711014, Lr:0.0001\n",
      "Epoch 33, Step: 116, Loss: 0.27189144492149353, Lr:0.0001\n",
      "Epoch 33, Step: 117, Loss: 0.009134196676313877, Lr:0.0001\n",
      "Epoch 33, Step: 118, Loss: 0.02548954263329506, Lr:0.0001\n",
      "Epoch 33, Step: 119, Loss: 0.01183582004159689, Lr:0.0001\n",
      "Epoch 33, Step: 120, Loss: 0.022229740396142006, Lr:0.0001\n",
      "Epoch 33, Step: 121, Loss: 0.000746440258808434, Lr:0.0001\n",
      "Epoch 33, Step: 122, Loss: 0.011518738232553005, Lr:0.0001\n",
      "Epoch 33, Step: 123, Loss: 0.010166110470890999, Lr:0.0001\n",
      "Epoch 33, Step: 124, Loss: 0.07295431941747665, Lr:0.0001\n",
      "Epoch 33, Step: 125, Loss: 0.0008261341135948896, Lr:0.0001\n",
      "Epoch 33, Step: 126, Loss: 0.0009588493267074227, Lr:0.0001\n",
      "Epoch 33, Step: 127, Loss: 0.014609253033995628, Lr:0.0001\n",
      "Epoch 33, Step: 128, Loss: 0.005288128741085529, Lr:0.0001\n",
      "Epoch 33, Step: 129, Loss: 0.01930716075003147, Lr:0.0001\n",
      "Epoch 33, Step: 130, Loss: 0.021086419001221657, Lr:0.0001\n",
      "Epoch 33, Step: 131, Loss: 0.10064475238323212, Lr:0.0001\n",
      "Epoch 33, Step: 132, Loss: 0.0032077706418931484, Lr:0.0001\n",
      "Epoch 33, Step: 133, Loss: 0.17708130180835724, Lr:0.0001\n",
      "Epoch 33, Step: 134, Loss: 0.01155991293489933, Lr:0.0001\n",
      "Epoch 33, Step: 135, Loss: 0.056907881051301956, Lr:0.0001\n",
      "Epoch 33, Step: 136, Loss: 0.00037527878885157406, Lr:0.0001\n",
      "Epoch 33, Step: 137, Loss: 0.057157404720783234, Lr:0.0001\n",
      "Epoch 33, Step: 138, Loss: 0.020339300855994225, Lr:0.0001\n",
      "Epoch 33, Step: 139, Loss: 0.06412634998559952, Lr:0.0001\n",
      "Epoch 33, Step: 140, Loss: 0.15626032650470734, Lr:0.0001\n",
      "Epoch 33, Step: 141, Loss: 0.005641467869281769, Lr:0.0001\n",
      "Epoch 33, Step: 142, Loss: 0.03655743971467018, Lr:0.0001\n",
      "Epoch 33, Step: 143, Loss: 0.10487178713083267, Lr:0.0001\n",
      "Epoch 33, Step: 144, Loss: 0.012606315314769745, Lr:0.0001\n",
      "Epoch 33, Step: 145, Loss: 0.04392222687602043, Lr:0.0001\n",
      "Epoch 33, Step: 146, Loss: 0.01373424381017685, Lr:0.0001\n",
      "Epoch 33, Step: 147, Loss: 0.00274017290212214, Lr:0.0001\n",
      "Epoch 33, Step: 148, Loss: 0.005548340734094381, Lr:0.0001\n",
      "Epoch 33, Step: 149, Loss: 0.03607499971985817, Lr:0.0001\n",
      "Epoch 33, Step: 150, Loss: 0.08535193651914597, Lr:0.0001\n",
      "Epoch 33, Step: 151, Loss: 0.1197064220905304, Lr:0.0001\n",
      "Epoch 33, Step: 152, Loss: 0.0005895677022635937, Lr:0.0001\n",
      "Epoch 33, Step: 153, Loss: 0.009802736341953278, Lr:0.0001\n",
      "Epoch 33, Step: 154, Loss: 0.05184725299477577, Lr:0.0001\n",
      "Epoch 33, Step: 155, Loss: 0.004095304291695356, Lr:0.0001\n",
      "Epoch 33, Step: 156, Loss: 0.011940949596464634, Lr:0.0001\n",
      "Epoch 33, Step: 157, Loss: 0.30876144766807556, Lr:0.0001\n",
      "Epoch 33, Step: 158, Loss: 0.0074769314378499985, Lr:0.0001\n",
      "Epoch 33, Step: 159, Loss: 0.009813942946493626, Lr:0.0001\n",
      "Epoch 33, Step: 160, Loss: 0.01950964331626892, Lr:0.0001\n",
      "Epoch 33, Step: 161, Loss: 0.0014810068532824516, Lr:0.0001\n",
      "Epoch 33, Step: 162, Loss: 0.0039718057960271835, Lr:0.0001\n",
      "Epoch 33, Step: 163, Loss: 0.03449190780520439, Lr:0.0001\n",
      "Epoch 33, Step: 164, Loss: 0.02099134400486946, Lr:0.0001\n",
      "Epoch 33, Step: 165, Loss: 0.0016955231549218297, Lr:0.0001\n",
      "Epoch 33, Step: 166, Loss: 0.003981504589319229, Lr:0.0001\n",
      "Epoch 33, Step: 167, Loss: 0.17985641956329346, Lr:0.0001\n",
      "Epoch 33, Step: 168, Loss: 0.12902510166168213, Lr:0.0001\n",
      "Epoch 33, Step: 169, Loss: 0.00216292729601264, Lr:0.0001\n",
      "Epoch 33, Step: 170, Loss: 0.0586758628487587, Lr:0.0001\n",
      "Epoch 33, Step: 171, Loss: 0.007011426147073507, Lr:0.0001\n",
      "Epoch 33, Step: 172, Loss: 0.00031782296719029546, Lr:0.0001\n",
      "Epoch 33, Step: 173, Loss: 0.0011714434949681163, Lr:0.0001\n",
      "Epoch 33, Step: 174, Loss: 0.0022619301453232765, Lr:0.0001\n",
      "Epoch 33, Step: 175, Loss: 0.007195715326815844, Lr:0.0001\n",
      "Epoch 33, Step: 176, Loss: 0.016428470611572266, Lr:0.0001\n",
      "Epoch 33, Step: 177, Loss: 0.0033034428488463163, Lr:0.0001\n",
      "Epoch 33, Step: 178, Loss: 0.005733800586313009, Lr:0.0001\n",
      "Epoch 33, Step: 179, Loss: 0.00725024938583374, Lr:0.0001\n",
      "Epoch 33, Step: 180, Loss: 0.018524138256907463, Lr:0.0001\n",
      "Epoch 33, Step: 181, Loss: 0.044282056391239166, Lr:0.0001\n",
      "Epoch 33, Step: 182, Loss: 0.08449161052703857, Lr:0.0001\n",
      "Epoch 33, Step: 183, Loss: 0.0004484873788896948, Lr:0.0001\n",
      "Epoch 33, Step: 184, Loss: 0.1773644983768463, Lr:0.0001\n",
      "Epoch 33, Step: 185, Loss: 0.0024604438804090023, Lr:0.0001\n",
      "Epoch 33, Step: 186, Loss: 0.0308854803442955, Lr:0.0001\n",
      "Epoch 33, Step: 187, Loss: 0.0019020027248188853, Lr:0.0001\n",
      "Epoch 33, Step: 188, Loss: 0.12269669026136398, Lr:0.0001\n",
      "Epoch 33, Step: 189, Loss: 0.03311209753155708, Lr:0.0001\n",
      "Epoch 33, Step: 190, Loss: 0.00964463222771883, Lr:0.0001\n",
      "Epoch 33, Step: 191, Loss: 0.05763117969036102, Lr:0.0001\n",
      "Epoch 33, Step: 192, Loss: 0.00036125353653915226, Lr:0.0001\n",
      "Epoch 33, Step: 193, Loss: 0.2122786045074463, Lr:0.0001\n",
      "Epoch 33, Step: 194, Loss: 0.0018392171477898955, Lr:0.0001\n",
      "Epoch 33, Step: 195, Loss: 0.19582509994506836, Lr:0.0001\n",
      "Epoch 33, Step: 196, Loss: 0.004583675414323807, Lr:0.0001\n",
      "Epoch 33, Step: 197, Loss: 0.002068188041448593, Lr:0.0001\n",
      "Epoch 33, Step: 198, Loss: 0.044752541929483414, Lr:0.0001\n",
      "Epoch 33, Step: 199, Loss: 0.0109862070530653, Lr:0.0001\n",
      "Epoch 33, Step: 200, Loss: 0.03198422119021416, Lr:0.0001\n",
      "Epoch 33, Step: 201, Loss: 0.0012553571723401546, Lr:0.0001\n",
      "Epoch 33, Step: 202, Loss: 0.008435488678514957, Lr:0.0001\n",
      "Epoch 33, Step: 203, Loss: 0.01420906838029623, Lr:0.0001\n",
      "Epoch 33, Step: 204, Loss: 0.13925595581531525, Lr:0.0001\n",
      "Epoch 33, Step: 205, Loss: 0.014563480392098427, Lr:0.0001\n",
      "Epoch 33, Step: 206, Loss: 0.08306105434894562, Lr:0.0001\n",
      "Epoch 33, Step: 207, Loss: 0.008494642563164234, Lr:0.0001\n",
      "Epoch 33, Step: 208, Loss: 0.011369106359779835, Lr:0.0001\n",
      "Epoch 33, Step: 209, Loss: 0.03457086533308029, Lr:0.0001\n",
      "Epoch 33, Step: 210, Loss: 0.026704153046011925, Lr:0.0001\n",
      "Epoch 33, Step: 211, Loss: 0.018072687089443207, Lr:0.0001\n",
      "Epoch 33, Step: 212, Loss: 0.025416389107704163, Lr:0.0001\n",
      "Epoch 33, Step: 213, Loss: 0.029926635324954987, Lr:0.0001\n",
      "Epoch 33, Step: 214, Loss: 0.028998738154768944, Lr:0.0001\n",
      "Epoch 33, Step: 215, Loss: 0.03396123647689819, Lr:0.0001\n",
      "Epoch 33, Step: 216, Loss: 0.016990233212709427, Lr:0.0001\n",
      "Epoch 33, Step: 217, Loss: 0.0027279939968138933, Lr:0.0001\n",
      "Epoch 33, Step: 218, Loss: 0.020160021260380745, Lr:0.0001\n",
      "Epoch 33, Step: 219, Loss: 0.012670589610934258, Lr:0.0001\n",
      "Epoch 33, Step: 220, Loss: 0.019872404634952545, Lr:0.0001\n",
      "Epoch 33, Step: 221, Loss: 0.023207593709230423, Lr:0.0001\n",
      "Epoch 33, Step: 222, Loss: 0.004914581310003996, Lr:0.0001\n",
      "Epoch 33, Step: 223, Loss: 0.004551979247480631, Lr:0.0001\n",
      "Epoch 33, Step: 224, Loss: 0.040443748235702515, Lr:0.0001\n",
      "Epoch 33, Step: 225, Loss: 0.22419513761997223, Lr:0.0001\n",
      "Epoch 33, Step: 226, Loss: 0.017033621668815613, Lr:0.0001\n",
      "Epoch 33, Step: 227, Loss: 0.0015249293064698577, Lr:0.0001\n",
      "Epoch 33, Step: 228, Loss: 0.008702462539076805, Lr:0.0001\n",
      "Epoch 33, Step: 229, Loss: 0.1114673912525177, Lr:0.0001\n",
      "Epoch 33, Step: 230, Loss: 0.010718969628214836, Lr:0.0001\n",
      "Epoch 33, Step: 231, Loss: 0.01492617093026638, Lr:0.0001\n",
      "Epoch 33, Step: 232, Loss: 0.017512043938040733, Lr:0.0001\n",
      "Epoch 33, Step: 233, Loss: 0.0031232142355293036, Lr:0.0001\n",
      "Epoch 33, Step: 234, Loss: 0.05335863307118416, Lr:0.0001\n",
      "Epoch 33, Step: 235, Loss: 0.004692478105425835, Lr:0.0001\n",
      "Epoch 33, Step: 236, Loss: 0.04568822681903839, Lr:0.0001\n",
      "Epoch 33, Step: 237, Loss: 0.004271683283150196, Lr:0.0001\n",
      "Epoch 33, Step: 238, Loss: 0.10067250579595566, Lr:0.0001\n",
      "Epoch 33, Step: 239, Loss: 0.03815440833568573, Lr:0.0001\n",
      "Epoch 33, Step: 240, Loss: 0.05305752530694008, Lr:0.0001\n",
      "Epoch 33, Step: 241, Loss: 0.034085728228092194, Lr:0.0001\n",
      "Epoch 33, Step: 242, Loss: 0.003687709104269743, Lr:0.0001\n",
      "Epoch 33, Step: 243, Loss: 0.015568484552204609, Lr:0.0001\n",
      "Epoch 33, Step: 244, Loss: 0.05009723827242851, Lr:0.0001\n",
      "Epoch 33, Step: 245, Loss: 0.032117486000061035, Lr:0.0001\n",
      "Epoch 33, Step: 246, Loss: 0.008750815875828266, Lr:0.0001\n",
      "Epoch 33, Step: 247, Loss: 0.029787201434373856, Lr:0.0001\n",
      "Epoch 33, Step: 248, Loss: 0.0013116123154759407, Lr:0.0001\n",
      "Epoch 33, Step: 249, Loss: 0.0013544040266424417, Lr:0.0001\n",
      "Epoch 33, Step: 250, Loss: 0.0024189865216612816, Lr:0.0001\n",
      "Epoch 33, Step: 251, Loss: 0.0027567583601921797, Lr:0.0001\n",
      "Epoch 33, Step: 252, Loss: 0.009417630732059479, Lr:0.0001\n",
      "Epoch 33, Step: 253, Loss: 0.2612503468990326, Lr:0.0001\n",
      "Epoch 33, Step: 254, Loss: 0.00161429971922189, Lr:0.0001\n",
      "Epoch 33, Step: 255, Loss: 0.002992878668010235, Lr:0.0001\n",
      "Epoch 33, Step: 256, Loss: 0.023048004135489464, Lr:0.0001\n",
      "Epoch 33, Step: 257, Loss: 0.0009427319164387882, Lr:0.0001\n",
      "Epoch 33, Step: 258, Loss: 0.023849649354815483, Lr:0.0001\n",
      "Epoch 33, Step: 259, Loss: 0.013839592225849628, Lr:0.0001\n",
      "Epoch 33, Step: 260, Loss: 0.32762768864631653, Lr:0.0001\n",
      "Epoch 33, Step: 261, Loss: 0.016866672784090042, Lr:0.0001\n",
      "Epoch 33, Step: 262, Loss: 0.11393231898546219, Lr:0.0001\n",
      "Epoch 33, Step: 263, Loss: 0.00542360870167613, Lr:0.0001\n",
      "Epoch 33, Step: 264, Loss: 0.04866286367177963, Lr:0.0001\n",
      "Epoch 33, Step: 265, Loss: 0.0027030683122575283, Lr:0.0001\n",
      "Epoch 33, Step: 266, Loss: 0.0011631717206910253, Lr:0.0001\n",
      "Epoch 33, Step: 267, Loss: 0.00860683061182499, Lr:0.0001\n",
      "Epoch 33, Step: 268, Loss: 0.004468883853405714, Lr:0.0001\n",
      "Epoch 33, Step: 269, Loss: 0.0009004392195492983, Lr:0.0001\n",
      "Epoch 33, Step: 270, Loss: 0.014944751746952534, Lr:0.0001\n",
      "Epoch 33, Step: 271, Loss: 0.044095639139413834, Lr:0.0001\n",
      "Epoch 33, Step: 272, Loss: 0.19502797722816467, Lr:0.0001\n",
      "Epoch 33, Step: 273, Loss: 0.004543009679764509, Lr:0.0001\n",
      "Epoch 33, Step: 274, Loss: 0.0008634842233732343, Lr:0.0001\n",
      "Epoch 33, Step: 275, Loss: 0.0283664520829916, Lr:0.0001\n",
      "Epoch 33, Step: 276, Loss: 0.006610393524169922, Lr:0.0001\n",
      "Epoch 33, Step: 277, Loss: 0.00737230246886611, Lr:0.0001\n",
      "Epoch 33, Step: 278, Loss: 0.07063856720924377, Lr:0.0001\n",
      "Epoch 33, Step: 279, Loss: 0.01677231676876545, Lr:0.0001\n",
      "Epoch 33, Step: 280, Loss: 0.000444729725131765, Lr:0.0001\n",
      "Epoch 33, Step: 281, Loss: 0.019714748486876488, Lr:0.0001\n",
      "Epoch 33, Step: 282, Loss: 0.0010603051632642746, Lr:0.0001\n",
      "Epoch 33, Step: 283, Loss: 0.013147634454071522, Lr:0.0001\n",
      "Epoch 33, Step: 284, Loss: 0.19779616594314575, Lr:0.0001\n",
      "Epoch 33, Step: 285, Loss: 0.11887554824352264, Lr:0.0001\n",
      "Epoch 33, Step: 286, Loss: 0.022563092410564423, Lr:0.0001\n",
      "Epoch 33, Step: 287, Loss: 0.022122764959931374, Lr:0.0001\n",
      "Epoch 33, Step: 288, Loss: 0.08465098589658737, Lr:0.0001\n",
      "Epoch 33, Step: 289, Loss: 0.07551412284374237, Lr:0.0001\n",
      "Epoch 33, Step: 290, Loss: 0.004125644452869892, Lr:0.0001\n",
      "Epoch 33, Step: 291, Loss: 0.023942895233631134, Lr:0.0001\n",
      "Epoch 33, Step: 292, Loss: 0.0011321984929963946, Lr:0.0001\n",
      "Epoch 33, Step: 293, Loss: 0.01256774552166462, Lr:0.0001\n",
      "Epoch 33, Step: 294, Loss: 0.03282814100384712, Lr:0.0001\n",
      "Epoch 33, Step: 295, Loss: 0.008830766193568707, Lr:0.0001\n",
      "Epoch 33, Step: 296, Loss: 0.016398074105381966, Lr:0.0001\n",
      "Epoch 33, Step: 297, Loss: 0.004866326693445444, Lr:0.0001\n",
      "Epoch 33, Step: 298, Loss: 0.001796538708731532, Lr:0.0001\n",
      "Epoch 33, Step: 299, Loss: 0.001306412392295897, Lr:0.0001\n",
      "Epoch 33, Step: 300, Loss: 0.05781581252813339, Lr:0.0001\n",
      "Epoch 33, Step: 301, Loss: 0.0034248640295118093, Lr:0.0001\n",
      "Epoch 33, Step: 302, Loss: 0.003047050442546606, Lr:0.0001\n",
      "Epoch 33, Step: 303, Loss: 0.02831992320716381, Lr:0.0001\n",
      "Epoch 33, Step: 304, Loss: 0.0008045998401939869, Lr:0.0001\n",
      "Epoch 33, Step: 305, Loss: 0.01488855667412281, Lr:0.0001\n",
      "Epoch 33, Step: 306, Loss: 0.1646263599395752, Lr:0.0001\n",
      "Epoch 33, Step: 307, Loss: 0.022027159109711647, Lr:0.0001\n",
      "Epoch 33, Step: 308, Loss: 0.008831650018692017, Lr:0.0001\n",
      "Epoch 33, Step: 309, Loss: 0.015725774690508842, Lr:0.0001\n",
      "Epoch 33, Step: 310, Loss: 0.00023014203179627657, Lr:0.0001\n",
      "Epoch 33, Step: 311, Loss: 0.2633439898490906, Lr:0.0001\n",
      "Epoch 33, Step: 312, Loss: 0.055191125720739365, Lr:0.0001\n",
      "Epoch 33, Step: 313, Loss: 0.002216664142906666, Lr:0.0001\n",
      "Epoch 33, Step: 314, Loss: 0.018820740282535553, Lr:0.0001\n",
      "Epoch 33, Step: 315, Loss: 0.18208758533000946, Lr:0.0001\n",
      "Epoch 33, Step: 316, Loss: 0.0008604956092312932, Lr:0.0001\n",
      "Epoch 33, Step: 317, Loss: 0.0008618187857791781, Lr:0.0001\n",
      "Epoch 33, Step: 318, Loss: 0.093518927693367, Lr:0.0001\n",
      "Epoch 33, Step: 319, Loss: 0.09412053972482681, Lr:0.0001\n",
      "Epoch 33, Step: 320, Loss: 0.07258237153291702, Lr:0.0001\n",
      "Epoch 33, Step: 321, Loss: 0.0008384779212065041, Lr:0.0001\n",
      "Epoch 33, Step: 322, Loss: 0.06919175386428833, Lr:0.0001\n",
      "Epoch 33, Step: 323, Loss: 0.002290887525305152, Lr:0.0001\n",
      "Epoch 33, Step: 324, Loss: 0.01860222965478897, Lr:0.0001\n",
      "Epoch 33, Step: 325, Loss: 0.0035016473848372698, Lr:0.0001\n",
      "Epoch 33, Step: 326, Loss: 0.0027603565249592066, Lr:0.0001\n",
      "Epoch 33, Step: 327, Loss: 0.03508751094341278, Lr:0.0001\n",
      "Epoch 33, Step: 328, Loss: 0.10587232559919357, Lr:0.0001\n",
      "Epoch 33, Step: 329, Loss: 0.13366420567035675, Lr:0.0001\n",
      "Epoch 33, Step: 330, Loss: 0.14706438779830933, Lr:0.0001\n",
      "Epoch 33, Step: 331, Loss: 0.0016731503419578075, Lr:0.0001\n",
      "Epoch 33, Step: 332, Loss: 0.054121896624565125, Lr:0.0001\n",
      "Epoch 33, Step: 333, Loss: 0.021836161613464355, Lr:0.0001\n",
      "Epoch 33, Step: 334, Loss: 0.04509595409035683, Lr:0.0001\n",
      "Epoch 33, Step: 335, Loss: 0.03667408227920532, Lr:0.0001\n",
      "Epoch 33, Step: 336, Loss: 0.00041595561197027564, Lr:0.0001\n",
      "Epoch 33, Step: 337, Loss: 0.040705855935811996, Lr:0.0001\n",
      "Epoch 33, Step: 338, Loss: 0.00048284162767231464, Lr:0.0001\n",
      "Epoch 33, Step: 339, Loss: 0.09797673672437668, Lr:0.0001\n",
      "Epoch 33, Step: 340, Loss: 0.07130473852157593, Lr:0.0001\n",
      "Epoch 33, Step: 341, Loss: 0.0012998898746445775, Lr:0.0001\n",
      "Epoch 33, Step: 342, Loss: 0.0059470683336257935, Lr:0.0001\n",
      "Epoch 33, Step: 343, Loss: 0.002125445054844022, Lr:0.0001\n",
      "Epoch 33, Step: 344, Loss: 0.006307299714535475, Lr:0.0001\n",
      "Epoch 33, Step: 345, Loss: 0.0010550846345722675, Lr:0.0001\n",
      "Epoch 33, Step: 346, Loss: 0.0018980527529492974, Lr:0.0001\n",
      "Epoch 33, Step: 347, Loss: 0.008207987993955612, Lr:0.0001\n",
      "Epoch 33, Step: 348, Loss: 0.046593401581048965, Lr:0.0001\n",
      "Epoch 33, Step: 349, Loss: 0.038724519312381744, Lr:0.0001\n",
      "Epoch 33, Step: 350, Loss: 0.021260330453515053, Lr:0.0001\n",
      "Epoch 33, Step: 351, Loss: 0.010278090834617615, Lr:0.0001\n",
      "Epoch 33, Step: 352, Loss: 0.014553539454936981, Lr:0.0001\n",
      "Epoch 33, Step: 353, Loss: 0.10279179364442825, Lr:0.0001\n",
      "Epoch 33, Step: 354, Loss: 0.021785294637084007, Lr:0.0001\n",
      "Epoch 33, Step: 355, Loss: 0.0013276897370815277, Lr:0.0001\n",
      "Epoch 33, Step: 356, Loss: 0.07774875313043594, Lr:0.0001\n",
      "Epoch 33, Step: 357, Loss: 0.03728348761796951, Lr:0.0001\n",
      "Epoch 33, Step: 358, Loss: 0.02947525680065155, Lr:0.0001\n",
      "Epoch 33, Step: 359, Loss: 0.050434984266757965, Lr:0.0001\n",
      "Epoch 33, Step: 360, Loss: 0.08673340082168579, Lr:0.0001\n",
      "Epoch 33, Step: 361, Loss: 0.0020515895448625088, Lr:0.0001\n",
      "Epoch 33, Step: 362, Loss: 0.007452052086591721, Lr:0.0001\n",
      "Epoch 33, Step: 363, Loss: 0.007212015800178051, Lr:0.0001\n",
      "Epoch 33, Step: 364, Loss: 0.10859553515911102, Lr:0.0001\n",
      "Epoch 33, Step: 365, Loss: 0.02790030464529991, Lr:0.0001\n",
      "Epoch 33, Step: 366, Loss: 0.004525181837379932, Lr:0.0001\n",
      "Epoch 33, Step: 367, Loss: 0.07962928712368011, Lr:0.0001\n",
      "Epoch 33, Step: 368, Loss: 0.005864151753485203, Lr:0.0001\n",
      "Epoch 33, Step: 369, Loss: 0.01434975117444992, Lr:0.0001\n",
      "Epoch 33, Step: 370, Loss: 0.0015186942182481289, Lr:0.0001\n",
      "Epoch 33, Step: 371, Loss: 0.009242643602192402, Lr:0.0001\n",
      "Epoch 33, Step: 372, Loss: 0.02395666018128395, Lr:0.0001\n",
      "Epoch 33, Step: 373, Loss: 0.0012199480552226305, Lr:0.0001\n",
      "Epoch 33, Step: 374, Loss: 0.019547972828149796, Lr:0.0001\n",
      "Epoch 33, Step: 375, Loss: 0.09445803612470627, Lr:0.0001\n",
      "Epoch 33, Step: 376, Loss: 0.0017110769404098392, Lr:0.0001\n",
      "Epoch 33, Step: 377, Loss: 0.0066291699185967445, Lr:0.0001\n",
      "Epoch 33, Step: 378, Loss: 0.0007476148311980069, Lr:0.0001\n",
      "Epoch 33, Step: 379, Loss: 0.23624594509601593, Lr:0.0001\n",
      "Epoch 33, Step: 380, Loss: 0.07584289461374283, Lr:0.0001\n",
      "Epoch 33, Step: 381, Loss: 0.17264984548091888, Lr:0.0001\n",
      "Epoch 33, Step: 382, Loss: 0.1464667022228241, Lr:0.0001\n",
      "Epoch 33, Step: 383, Loss: 0.20687028765678406, Lr:0.0001\n",
      "Epoch 33, Step: 384, Loss: 0.01361851766705513, Lr:0.0001\n",
      "Epoch 33, Step: 385, Loss: 0.011995533481240273, Lr:0.0001\n",
      "Epoch 33, Step: 386, Loss: 0.0834718868136406, Lr:0.0001\n",
      "Epoch 33, Step: 387, Loss: 0.24813240766525269, Lr:0.0001\n",
      "Epoch 33, Step: 388, Loss: 0.004817930981516838, Lr:0.0001\n",
      "Epoch 33, Step: 389, Loss: 0.0019806574564427137, Lr:0.0001\n",
      "Epoch 33, Step: 390, Loss: 0.004382385406643152, Lr:0.0001\n",
      "Epoch 33, Step: 391, Loss: 0.0273740217089653, Lr:0.0001\n",
      "Epoch 33, Step: 392, Loss: 0.007255101576447487, Lr:0.0001\n",
      "Epoch 33, Step: 393, Loss: 0.02137400023639202, Lr:0.0001\n",
      "Epoch 33, Step: 394, Loss: 0.07253579050302505, Lr:0.0001\n",
      "Epoch 33, Step: 395, Loss: 0.058932699263095856, Lr:0.0001\n",
      "Epoch 33, Step: 396, Loss: 0.03278028964996338, Lr:0.0001\n",
      "Epoch 33, Step: 397, Loss: 0.002048674738034606, Lr:0.0001\n",
      "Epoch 33, Step: 398, Loss: 0.015632903203368187, Lr:0.0001\n",
      "Epoch 33, Step: 399, Loss: 0.1672791987657547, Lr:0.0001\n",
      "Epoch 33, Step: 400, Loss: 0.39894744753837585, Lr:0.0001\n",
      "Epoch 33, Step: 401, Loss: 0.010105137713253498, Lr:0.0001\n",
      "Epoch 33, Step: 402, Loss: 0.03543425351381302, Lr:0.0001\n",
      "Epoch 33, Step: 403, Loss: 0.045137036591768265, Lr:0.0001\n",
      "Epoch 33, Step: 404, Loss: 0.06988964229822159, Lr:0.0001\n",
      "Epoch 33, Step: 405, Loss: 0.13167239725589752, Lr:0.0001\n",
      "Epoch 33, Step: 406, Loss: 0.011288589797914028, Lr:0.0001\n",
      "Epoch 33, Step: 407, Loss: 0.03399515151977539, Lr:0.0001\n",
      "Epoch 33, Step: 408, Loss: 0.02038995735347271, Lr:0.0001\n",
      "Epoch 33, Step: 409, Loss: 0.03279882296919823, Lr:0.0001\n",
      "Epoch 33, Step: 410, Loss: 0.01086028479039669, Lr:0.0001\n",
      "Epoch 33, Step: 411, Loss: 0.004846733994781971, Lr:0.0001\n",
      "Epoch 33, Step: 412, Loss: 0.2212447077035904, Lr:0.0001\n",
      "Epoch 33, Step: 413, Loss: 0.5213819146156311, Lr:0.0001\n",
      "Epoch 33, Step: 414, Loss: 0.0030966612976044416, Lr:0.0001\n",
      "Epoch 33, Step: 415, Loss: 0.031162763014435768, Lr:0.0001\n",
      "Epoch 33, Step: 416, Loss: 0.009539664722979069, Lr:0.0001\n",
      "Epoch 33, Step: 417, Loss: 0.030903328210115433, Lr:0.0001\n",
      "Epoch 33, Step: 418, Loss: 0.0501323863863945, Lr:0.0001\n",
      "Epoch 33, Step: 419, Loss: 0.0363515205681324, Lr:0.0001\n",
      "Epoch 33, Step: 420, Loss: 0.13751164078712463, Lr:0.0001\n",
      "Epoch 33, Step: 421, Loss: 0.018218647688627243, Lr:0.0001\n",
      "Epoch 33, Step: 422, Loss: 0.03790796548128128, Lr:0.0001\n",
      "Epoch 33, Step: 423, Loss: 0.06756872683763504, Lr:0.0001\n",
      "Epoch 33, Step: 424, Loss: 0.046674810349941254, Lr:0.0001\n",
      "Epoch 33, Step: 425, Loss: 0.013687845319509506, Lr:0.0001\n",
      "Epoch 33, Step: 426, Loss: 0.1003241166472435, Lr:0.0001\n",
      "Epoch 33, Step: 427, Loss: 0.003845566650852561, Lr:0.0001\n",
      "Epoch 33, Step: 428, Loss: 0.03428960219025612, Lr:0.0001\n",
      "Epoch 33, Step: 429, Loss: 0.0297817625105381, Lr:0.0001\n",
      "Epoch 33, Step: 430, Loss: 0.16010071337223053, Lr:0.0001\n",
      "Epoch 33, Step: 431, Loss: 0.009551958180963993, Lr:0.0001\n",
      "Epoch 33, Step: 432, Loss: 0.00798846036195755, Lr:0.0001\n",
      "Epoch 33, Step: 433, Loss: 0.00013049994595348835, Lr:0.0001\n",
      "Epoch 33, Step: 434, Loss: 0.001629723235964775, Lr:0.0001\n",
      "Epoch 33, Step: 435, Loss: 0.015592102892696857, Lr:0.0001\n",
      "Epoch 33, Step: 436, Loss: 0.08256567269563675, Lr:0.0001\n",
      "Epoch 33, Step: 437, Loss: 0.0384536013007164, Lr:0.0001\n",
      "Epoch 33, Step: 438, Loss: 0.03913886472582817, Lr:0.0001\n",
      "Epoch 33, Step: 439, Loss: 0.013656715862452984, Lr:0.0001\n",
      "Epoch 33, Step: 440, Loss: 0.001444815774448216, Lr:0.0001\n",
      "Epoch 33, Step: 441, Loss: 0.004577562678605318, Lr:0.0001\n",
      "Epoch 33, Step: 442, Loss: 0.008931763470172882, Lr:0.0001\n",
      "Epoch 33, Step: 443, Loss: 0.02613302692770958, Lr:0.0001\n",
      "Epoch 33, Step: 444, Loss: 0.0002600731677375734, Lr:0.0001\n",
      "Epoch 33, Step: 445, Loss: 0.060376062989234924, Lr:0.0001\n",
      "Epoch 33, Step: 446, Loss: 0.08878067135810852, Lr:0.0001\n",
      "Epoch 33, Step: 447, Loss: 0.06591013818979263, Lr:0.0001\n",
      "Epoch 33, Step: 448, Loss: 0.020522475242614746, Lr:0.0001\n",
      "Epoch 33, Step: 449, Loss: 0.001515887794084847, Lr:0.0001\n",
      "Epoch 33, Step: 450, Loss: 0.33270421624183655, Lr:0.0001\n",
      "Epoch 33, Step: 451, Loss: 0.014512079767882824, Lr:0.0001\n",
      "Epoch 33, Step: 452, Loss: 0.021565590053796768, Lr:0.0001\n",
      "Epoch 33, Step: 453, Loss: 0.0005218956503085792, Lr:0.0001\n",
      "Epoch 33, Step: 454, Loss: 0.05488889664411545, Lr:0.0001\n",
      "Epoch 33, Step: 455, Loss: 0.030395515263080597, Lr:0.0001\n",
      "Epoch 33, Step: 456, Loss: 0.06042598932981491, Lr:0.0001\n",
      "Epoch 33, Step: 457, Loss: 0.007004487328231335, Lr:0.0001\n",
      "Epoch 33, Step: 458, Loss: 0.013528314419090748, Lr:0.0001\n",
      "Epoch 33, Step: 459, Loss: 0.15963460505008698, Lr:0.0001\n",
      "Epoch 33, Step: 460, Loss: 0.041590847074985504, Lr:0.0001\n",
      "Epoch 33, Step: 461, Loss: 0.003112445818260312, Lr:0.0001\n",
      "Epoch 33, Step: 462, Loss: 0.015475716441869736, Lr:0.0001\n",
      "Epoch 33, Step: 463, Loss: 0.024049894884228706, Lr:0.0001\n",
      "Epoch 33, Step: 464, Loss: 0.02245834469795227, Lr:0.0001\n",
      "Epoch 33, Step: 465, Loss: 0.016119569540023804, Lr:0.0001\n",
      "Epoch 33, Step: 466, Loss: 0.007900872267782688, Lr:0.0001\n",
      "Epoch 33, Step: 467, Loss: 0.18324843049049377, Lr:0.0001\n",
      "Epoch 33, Step: 468, Loss: 0.05000583827495575, Lr:0.0001\n",
      "Epoch 33, Step: 469, Loss: 0.11943225562572479, Lr:0.0001\n",
      "Epoch 33, Step: 470, Loss: 0.004098564386367798, Lr:0.0001\n",
      "Epoch 33, Step: 471, Loss: 0.07139760255813599, Lr:0.0001\n",
      "Epoch 33, Step: 472, Loss: 0.04142209142446518, Lr:0.0001\n",
      "Epoch 33, Step: 473, Loss: 0.004253222607076168, Lr:0.0001\n",
      "Epoch 33, Step: 474, Loss: 0.004492845851927996, Lr:0.0001\n",
      "Epoch 33, Step: 475, Loss: 0.017809037119150162, Lr:0.0001\n",
      "Epoch 33, Step: 476, Loss: 0.003189246403053403, Lr:0.0001\n",
      "Epoch 33, Step: 477, Loss: 0.050690293312072754, Lr:0.0001\n",
      "Epoch 33, Step: 478, Loss: 0.005609237588942051, Lr:0.0001\n",
      "Epoch 33, Step: 479, Loss: 0.003663331735879183, Lr:0.0001\n",
      "Epoch 33, Step: 480, Loss: 0.300578236579895, Lr:0.0001\n",
      "Epoch 33, Step: 481, Loss: 0.03068152815103531, Lr:0.0001\n",
      "Epoch 33, Step: 482, Loss: 0.02644580975174904, Lr:0.0001\n",
      "Epoch 33, Step: 483, Loss: 0.06785649061203003, Lr:0.0001\n",
      "Epoch 33, Step: 484, Loss: 0.334684818983078, Lr:0.0001\n",
      "Epoch 33, Step: 485, Loss: 0.0011760112829506397, Lr:0.0001\n",
      "Epoch 33, Step: 486, Loss: 0.03703926503658295, Lr:0.0001\n",
      "Epoch 33, Step: 487, Loss: 0.023157157003879547, Lr:0.0001\n",
      "Epoch 33, Step: 488, Loss: 0.016881834715604782, Lr:0.0001\n",
      "Epoch 33, Step: 489, Loss: 0.004142222460359335, Lr:0.0001\n",
      "Epoch 33, Step: 490, Loss: 0.05321850627660751, Lr:0.0001\n",
      "Epoch 33, Step: 491, Loss: 0.0025763502344489098, Lr:0.0001\n",
      "Epoch 33, Step: 492, Loss: 0.012710276991128922, Lr:0.0001\n",
      "Epoch 33, Step: 493, Loss: 0.0026673790998756886, Lr:0.0001\n",
      "Epoch 33, Step: 494, Loss: 0.2256980538368225, Lr:0.0001\n",
      "Epoch 33, Step: 495, Loss: 0.02833421342074871, Lr:0.0001\n",
      "Epoch 33, Step: 496, Loss: 0.01629829965531826, Lr:0.0001\n",
      "Epoch 33, Step: 497, Loss: 0.055312372744083405, Lr:0.0001\n",
      "Epoch 33, Step: 498, Loss: 0.04608157277107239, Lr:0.0001\n",
      "Epoch 33, Step: 499, Loss: 0.007950343191623688, Lr:0.0001\n",
      "Epoch 33, Step: 500, Loss: 0.0013877833262085915, Lr:0.0001\n",
      "Epoch 33, Step: 501, Loss: 0.06663261353969574, Lr:0.0001\n",
      "Epoch 33, Step: 502, Loss: 0.007209234870970249, Lr:0.0001\n",
      "Epoch 33, Step: 503, Loss: 0.0016262645367532969, Lr:0.0001\n",
      "Epoch 33, Step: 504, Loss: 0.11048070341348648, Lr:0.0001\n",
      "Epoch 33, Step: 505, Loss: 0.07020389288663864, Lr:0.0001\n",
      "Epoch 33, Step: 506, Loss: 0.22226661443710327, Lr:0.0001\n",
      "Epoch 33, Step: 507, Loss: 0.0022194073535501957, Lr:0.0001\n",
      "Epoch 33, Step: 508, Loss: 0.0025723488070070744, Lr:0.0001\n",
      "Epoch 33, Step: 509, Loss: 0.0018805713625624776, Lr:0.0001\n",
      "Epoch 33, Step: 510, Loss: 0.02252134680747986, Lr:0.0001\n",
      "Epoch 33, Step: 511, Loss: 0.0035046767443418503, Lr:0.0001\n",
      "Epoch 33, Step: 512, Loss: 0.0050969249568879604, Lr:0.0001\n",
      "Epoch 33, Step: 513, Loss: 0.2193080484867096, Lr:0.0001\n",
      "Epoch 33, Step: 514, Loss: 0.1116451621055603, Lr:0.0001\n",
      "Epoch 33, Step: 515, Loss: 0.04828810691833496, Lr:0.0001\n",
      "Epoch 33, Step: 516, Loss: 0.0028510522097349167, Lr:0.0001\n",
      "Epoch 33, Step: 517, Loss: 0.09746331721544266, Lr:0.0001\n",
      "Epoch 33, Step: 518, Loss: 0.0007207053131423891, Lr:0.0001\n",
      "Epoch 33, Step: 519, Loss: 0.013151925057172775, Lr:0.0001\n",
      "Epoch 33, Step: 520, Loss: 0.0039143068715929985, Lr:0.0001\n",
      "Epoch 33, Step: 521, Loss: 0.006069618742913008, Lr:0.0001\n",
      "Epoch 33, Step: 522, Loss: 1.7506585121154785, Lr:0.0001\n",
      "Epoch 33, Step: 523, Loss: 0.022016635164618492, Lr:0.0001\n",
      "Epoch 33, Step: 524, Loss: 0.07441972196102142, Lr:0.0001\n",
      "Epoch 33, Step: 525, Loss: 0.00434091966599226, Lr:0.0001\n",
      "Epoch 33, Step: 526, Loss: 0.01979224570095539, Lr:0.0001\n",
      "Epoch 33, Step: 527, Loss: 0.010211048647761345, Lr:0.0001\n",
      "Epoch 33, Step: 528, Loss: 0.0010649370960891247, Lr:0.0001\n",
      "Epoch 33, Step: 529, Loss: 0.0015181249473243952, Lr:0.0001\n",
      "Epoch 33, Step: 530, Loss: 0.26907095313072205, Lr:0.0001\n",
      "Epoch 33, Step: 531, Loss: 0.11497633904218674, Lr:0.0001\n",
      "Epoch 33, Step: 532, Loss: 0.40090814232826233, Lr:0.0001\n",
      "Epoch 33, Step: 533, Loss: 0.38408344984054565, Lr:0.0001\n",
      "Epoch 33, Step: 534, Loss: 0.013739671558141708, Lr:0.0001\n",
      "Epoch 33, Step: 535, Loss: 0.05193953961133957, Lr:0.0001\n",
      "Epoch 33, Step: 536, Loss: 0.14010263979434967, Lr:0.0001\n",
      "Epoch 33, Step: 537, Loss: 0.017261402681469917, Lr:0.0001\n",
      "Epoch 33, Step: 538, Loss: 0.009701943024992943, Lr:0.0001\n",
      "Epoch 33, Step: 539, Loss: 0.013608535751700401, Lr:0.0001\n",
      "Epoch 33, Step: 540, Loss: 0.05411955341696739, Lr:0.0001\n",
      "Epoch 33, Step: 541, Loss: 0.0633774995803833, Lr:0.0001\n",
      "Epoch 33, Step: 542, Loss: 0.01208991464227438, Lr:0.0001\n",
      "Epoch 33, Step: 543, Loss: 0.051593925803899765, Lr:0.0001\n",
      "Epoch 33, Step: 544, Loss: 0.013360200449824333, Lr:0.0001\n",
      "Epoch 33, Step: 545, Loss: 0.021955249831080437, Lr:0.0001\n",
      "Epoch 33, Step: 546, Loss: 0.2534615695476532, Lr:0.0001\n",
      "Epoch 33, Step: 547, Loss: 0.2751595377922058, Lr:0.0001\n",
      "Epoch 33, Step: 548, Loss: 0.011290508322417736, Lr:0.0001\n",
      "Epoch 33, Step: 549, Loss: 0.06414283812046051, Lr:0.0001\n",
      "Epoch 33, Step: 550, Loss: 0.027798615396022797, Lr:0.0001\n",
      "Epoch 33, Step: 551, Loss: 0.09925646334886551, Lr:0.0001\n",
      "Epoch 33, Step: 552, Loss: 0.02620391547679901, Lr:0.0001\n",
      "Epoch 33, Step: 553, Loss: 0.08431990444660187, Lr:0.0001\n",
      "Epoch 33, Step: 554, Loss: 0.22907328605651855, Lr:0.0001\n",
      "Epoch 33, Step: 555, Loss: 0.09068597853183746, Lr:0.0001\n",
      "Epoch 33, Step: 556, Loss: 0.01373203843832016, Lr:0.0001\n",
      "Epoch 33, Step: 557, Loss: 0.06190277636051178, Lr:0.0001\n",
      "Epoch 33, Step: 558, Loss: 0.0052110073156654835, Lr:0.0001\n",
      "Epoch 33, Step: 559, Loss: 0.00090575753711164, Lr:0.0001\n",
      "Epoch 33, Step: 560, Loss: 0.019533732905983925, Lr:0.0001\n",
      "Epoch 33, Step: 561, Loss: 0.0003870349610224366, Lr:0.0001\n",
      "Epoch 33, Step: 562, Loss: 0.03302282094955444, Lr:0.0001\n",
      "Epoch 33, Step: 563, Loss: 0.004137801937758923, Lr:0.0001\n",
      "Epoch 33, Step: 564, Loss: 0.03800346702337265, Lr:0.0001\n",
      "Epoch 33, Step: 565, Loss: 0.06759190559387207, Lr:0.0001\n",
      "Epoch 33, Step: 566, Loss: 0.028915654867887497, Lr:0.0001\n",
      "Epoch 33, Step: 567, Loss: 0.08434908837080002, Lr:0.0001\n",
      "Epoch 33, Step: 568, Loss: 0.010183584876358509, Lr:0.0001\n",
      "Epoch 33, Step: 569, Loss: 0.11871233582496643, Lr:0.0001\n",
      "Epoch 33, Step: 570, Loss: 0.013731136918067932, Lr:0.0001\n",
      "Epoch 33, Step: 571, Loss: 0.0005518242251127958, Lr:0.0001\n",
      "Epoch 33, Step: 572, Loss: 0.08889047056436539, Lr:0.0001\n",
      "Epoch 33, Step: 573, Loss: 0.0443454384803772, Lr:0.0001\n",
      "Epoch 33, Step: 574, Loss: 0.22695292532444, Lr:0.0001\n",
      "Epoch 33, Step: 575, Loss: 0.003812031587585807, Lr:0.0001\n",
      "Epoch 33, Step: 576, Loss: 0.00480677979066968, Lr:0.0001\n",
      "Epoch 33, Step: 577, Loss: 0.1881367713212967, Lr:0.0001\n",
      "Epoch 33, Step: 578, Loss: 0.01627466082572937, Lr:0.0001\n",
      "Epoch 33, Step: 579, Loss: 0.16010577976703644, Lr:0.0001\n",
      "Epoch 33, Step: 580, Loss: 0.10657032579183578, Lr:0.0001\n",
      "Epoch 33, Step: 581, Loss: 0.0298538226634264, Lr:0.0001\n",
      "Epoch 33, Step: 582, Loss: 0.005198734346777201, Lr:0.0001\n",
      "Epoch 33, Step: 583, Loss: 0.0026225647889077663, Lr:0.0001\n",
      "Epoch 33, Step: 584, Loss: 0.001114285085350275, Lr:0.0001\n",
      "Epoch 33, Step: 585, Loss: 0.02085711807012558, Lr:0.0001\n",
      "Epoch 33, Step: 586, Loss: 0.4957118630409241, Lr:0.0001\n",
      "Epoch 33, Step: 587, Loss: 0.1262964904308319, Lr:0.0001\n",
      "Epoch 33, Step: 588, Loss: 0.16259673237800598, Lr:0.0001\n",
      "Epoch 33, Step: 589, Loss: 0.05380849167704582, Lr:0.0001\n",
      "Epoch 33, Step: 590, Loss: 0.10858560353517532, Lr:0.0001\n",
      "Epoch 33, Step: 591, Loss: 0.024077512323856354, Lr:0.0001\n",
      "Epoch 33, Step: 592, Loss: 0.0581764280796051, Lr:0.0001\n",
      "Epoch 33, Step: 593, Loss: 0.03785812482237816, Lr:0.0001\n",
      "Epoch 33, Step: 594, Loss: 0.007917342707514763, Lr:0.0001\n",
      "Epoch 33, Step: 595, Loss: 0.15907900035381317, Lr:0.0001\n",
      "Epoch 33, Step: 596, Loss: 0.15074464678764343, Lr:0.0001\n",
      "Epoch 33, Step: 597, Loss: 0.12273681908845901, Lr:0.0001\n",
      "Epoch 33, Step: 598, Loss: 0.028657464310526848, Lr:0.0001\n",
      "Epoch 33, Step: 599, Loss: 0.006951130926609039, Lr:0.0001\n",
      "Epoch 33, Step: 600, Loss: 0.13673454523086548, Lr:0.0001\n",
      "Epoch 33, Step: 601, Loss: 0.055444300174713135, Lr:0.0001\n",
      "Epoch 33, Step: 602, Loss: 0.0035882038064301014, Lr:0.0001\n",
      "Epoch 33, Step: 603, Loss: 0.006036676000803709, Lr:0.0001\n",
      "Epoch 33, Step: 604, Loss: 0.004622108768671751, Lr:0.0001\n",
      "Epoch 33, Step: 605, Loss: 0.032228123396635056, Lr:0.0001\n",
      "Epoch 33, Step: 606, Loss: 0.00603443244472146, Lr:0.0001\n",
      "Epoch 33, Step: 607, Loss: 0.020097369328141212, Lr:0.0001\n",
      "Epoch 33, Step: 608, Loss: 0.10720226168632507, Lr:0.0001\n",
      "Epoch 33, Step: 609, Loss: 0.01990419253706932, Lr:0.0001\n",
      "Epoch 33, Step: 610, Loss: 0.0391407310962677, Lr:0.0001\n",
      "Epoch 33, Step: 611, Loss: 0.03953414782881737, Lr:0.0001\n",
      "Epoch 33, Step: 612, Loss: 0.03983607143163681, Lr:0.0001\n",
      "Epoch 33, Step: 613, Loss: 0.017353784292936325, Lr:0.0001\n",
      "Epoch 33, Step: 614, Loss: 0.3807450234889984, Lr:0.0001\n",
      "Epoch 33, Step: 615, Loss: 0.0707855373620987, Lr:0.0001\n",
      "Epoch 33, Step: 616, Loss: 0.039731383323669434, Lr:0.0001\n",
      "Epoch 33, Step: 617, Loss: 0.19320988655090332, Lr:0.0001\n",
      "Epoch 33, Step: 618, Loss: 0.1502968966960907, Lr:0.0001\n",
      "Epoch 33, Step: 619, Loss: 0.04500984400510788, Lr:0.0001\n",
      "Epoch 33, Step: 620, Loss: 0.002525170100852847, Lr:0.0001\n",
      "Epoch 33, Step: 621, Loss: 0.06916279345750809, Lr:0.0001\n",
      "Epoch 33, Step: 622, Loss: 0.0014836183981969953, Lr:0.0001\n",
      "Epoch 33, Step: 623, Loss: 0.013686148449778557, Lr:0.0001\n",
      "Epoch 33, Step: 624, Loss: 0.002637728350237012, Lr:0.0001\n",
      "Epoch 33, Step: 625, Loss: 0.05602777749300003, Lr:0.0001\n",
      "Epoch 33, Step: 626, Loss: 0.18146845698356628, Lr:0.0001\n",
      "Epoch 33, Step: 627, Loss: 0.01087165530771017, Lr:0.0001\n",
      "Epoch 33, Step: 628, Loss: 0.04000948369503021, Lr:0.0001\n",
      "Epoch 33, Step: 629, Loss: 0.2308446168899536, Lr:0.0001\n",
      "Epoch 33, Step: 630, Loss: 0.011296710930764675, Lr:0.0001\n",
      "Epoch 33, Step: 631, Loss: 0.19002743065357208, Lr:0.0001\n",
      "Epoch 33, Step: 632, Loss: 0.026094116270542145, Lr:0.0001\n",
      "Epoch 33, Step: 633, Loss: 0.03089589811861515, Lr:0.0001\n",
      "Epoch 33, Step: 634, Loss: 0.16998271644115448, Lr:0.0001\n",
      "Epoch 33, Step: 635, Loss: 0.13723884522914886, Lr:0.0001\n",
      "Epoch 33, Step: 636, Loss: 0.005500363186001778, Lr:0.0001\n",
      "Epoch 33, Step: 637, Loss: 0.004590291995555162, Lr:0.0001\n",
      "Epoch 33, Step: 638, Loss: 0.010044468566775322, Lr:0.0001\n",
      "Epoch 33, Step: 639, Loss: 0.04484148323535919, Lr:0.0001\n",
      "Epoch 33, Step: 640, Loss: 0.0017201787559315562, Lr:0.0001\n",
      "Epoch 33, Step: 641, Loss: 0.0667952373623848, Lr:0.0001\n",
      "Epoch 33, Step: 642, Loss: 0.02444479800760746, Lr:0.0001\n",
      "Epoch 33, Step: 643, Loss: 0.09399659931659698, Lr:0.0001\n",
      "Epoch 33, Step: 644, Loss: 0.14437612891197205, Lr:0.0001\n",
      "Epoch 33, Step: 645, Loss: 0.0010041650384664536, Lr:0.0001\n",
      "Epoch 33, Step: 646, Loss: 0.012443598359823227, Lr:0.0001\n",
      "Epoch 33, Step: 647, Loss: 0.029394367709755898, Lr:0.0001\n",
      "Epoch 33, Step: 648, Loss: 0.008346046321094036, Lr:0.0001\n",
      "Epoch 33, Step: 649, Loss: 0.02084646373987198, Lr:0.0001\n",
      "Epoch 33, Step: 650, Loss: 0.013282908126711845, Lr:0.0001\n",
      "Epoch 33, Step: 651, Loss: 0.13729029893875122, Lr:0.0001\n",
      "Epoch 33, Step: 652, Loss: 0.10368459671735764, Lr:0.0001\n",
      "Epoch 33, Step: 653, Loss: 0.03654984384775162, Lr:0.0001\n",
      "Epoch 33, Step: 654, Loss: 0.023264428600668907, Lr:0.0001\n",
      "Epoch 33, Step: 655, Loss: 0.18906188011169434, Lr:0.0001\n",
      "Epoch 33, Step: 656, Loss: 0.008700256235897541, Lr:0.0001\n",
      "Epoch 33, Step: 657, Loss: 0.007253194227814674, Lr:0.0001\n",
      "Epoch 33, Step: 658, Loss: 0.15542897582054138, Lr:0.0001\n",
      "Epoch 33, Step: 659, Loss: 0.0754140242934227, Lr:0.0001\n",
      "Epoch 33, Step: 660, Loss: 0.2860274016857147, Lr:0.0001\n",
      "Epoch 33, Step: 661, Loss: 0.006601613014936447, Lr:0.0001\n",
      "Epoch 33, Step: 662, Loss: 0.06003094092011452, Lr:0.0001\n",
      "Epoch 33, Step: 663, Loss: 0.018474198877811432, Lr:0.0001\n",
      "Epoch 33, Step: 664, Loss: 0.017958208918571472, Lr:0.0001\n",
      "Epoch 33, Step: 665, Loss: 0.09397551417350769, Lr:0.0001\n",
      "Epoch 33, Step: 666, Loss: 0.07900086045265198, Lr:0.0001\n",
      "Epoch 33, Step: 667, Loss: 0.1483265906572342, Lr:0.0001\n",
      "Epoch 33, Step: 668, Loss: 0.0022498746402561665, Lr:0.0001\n",
      "Epoch 33, Step: 669, Loss: 0.08982481807470322, Lr:0.0001\n",
      "Epoch 33, Step: 670, Loss: 0.4762207567691803, Lr:0.0001\n",
      "Epoch 33, Step: 671, Loss: 0.17927846312522888, Lr:0.0001\n",
      "Epoch 33, Step: 672, Loss: 0.15764722228050232, Lr:0.0001\n",
      "Epoch 33, Step: 673, Loss: 0.005478270817548037, Lr:0.0001\n",
      "Epoch 33, Step: 674, Loss: 0.11832726746797562, Lr:0.0001\n",
      "Epoch 33, Step: 675, Loss: 0.025970270857214928, Lr:0.0001\n",
      "Epoch 33, Step: 676, Loss: 0.0344022773206234, Lr:0.0001\n",
      "Epoch 33, Step: 677, Loss: 0.06872119754552841, Lr:0.0001\n",
      "Epoch 33, Step: 678, Loss: 0.03626122325658798, Lr:0.0001\n",
      "Epoch 33, Step: 679, Loss: 0.014719213359057903, Lr:0.0001\n",
      "Epoch 33, Step: 680, Loss: 0.009071881882846355, Lr:0.0001\n",
      "Epoch 33, Step: 681, Loss: 0.10845425724983215, Lr:0.0001\n",
      "Epoch 33, Step: 682, Loss: 0.12360822409391403, Lr:0.0001\n",
      "Epoch 33, Step: 683, Loss: 0.005968892015516758, Lr:0.0001\n",
      "Epoch 33, Step: 684, Loss: 0.02812405489385128, Lr:0.0001\n",
      "Epoch 33, Step: 685, Loss: 0.019818272441625595, Lr:0.0001\n",
      "Epoch 33, Step: 686, Loss: 0.06316421180963516, Lr:0.0001\n",
      "Epoch 33, Step: 687, Loss: 0.05125030130147934, Lr:0.0001\n",
      "Epoch 33, Step: 688, Loss: 0.026902053505182266, Lr:0.0001\n",
      "Epoch 33, Step: 689, Loss: 0.40016230940818787, Lr:0.0001\n",
      "Epoch 33, Step: 690, Loss: 0.0020160761196166277, Lr:0.0001\n",
      "Epoch 33, Step: 691, Loss: 0.0014557831455022097, Lr:0.0001\n",
      "Epoch 33, Step: 692, Loss: 0.1580858677625656, Lr:0.0001\n",
      "Epoch 33, Step: 693, Loss: 0.0621798112988472, Lr:0.0001\n",
      "Epoch 33, Step: 694, Loss: 0.1590733826160431, Lr:0.0001\n",
      "Epoch 33, Step: 695, Loss: 0.0757802352309227, Lr:0.0001\n",
      "Epoch 33, Step: 696, Loss: 0.002402331680059433, Lr:0.0001\n",
      "Epoch 33, Step: 697, Loss: 0.025564324110746384, Lr:0.0001\n",
      "Epoch 33, Step: 698, Loss: 0.011520834639668465, Lr:0.0001\n",
      "Epoch 33, Step: 699, Loss: 0.08804184943437576, Lr:0.0001\n",
      "Epoch 33, Step: 700, Loss: 0.013214305974543095, Lr:0.0001\n",
      "Epoch 33, Step: 701, Loss: 0.01038091816008091, Lr:0.0001\n",
      "Epoch 33, Step: 702, Loss: 0.0018634347943589091, Lr:0.0001\n",
      "Epoch 33, Step: 703, Loss: 0.013587510213255882, Lr:0.0001\n",
      "Epoch 33, Step: 704, Loss: 0.17254754900932312, Lr:0.0001\n",
      "Epoch 33, Step: 705, Loss: 0.026583543047308922, Lr:0.0001\n",
      "Epoch 33, Step: 706, Loss: 0.007457675412297249, Lr:0.0001\n",
      "Epoch 33, Step: 707, Loss: 0.10270103812217712, Lr:0.0001\n",
      "Epoch 33, Step: 708, Loss: 0.10866085439920425, Lr:0.0001\n",
      "Epoch 33, Step: 709, Loss: 0.29127857089042664, Lr:0.0001\n",
      "Epoch 33, Step: 710, Loss: 0.0013397345319390297, Lr:0.0001\n",
      "Epoch 33, Step: 711, Loss: 0.161560520529747, Lr:0.0001\n",
      "Epoch 33, Step: 712, Loss: 0.11586575210094452, Lr:0.0001\n",
      "Epoch 33, Step: 713, Loss: 0.13689890503883362, Lr:0.0001\n",
      "Epoch 33, Step: 714, Loss: 0.020698605105280876, Lr:0.0001\n",
      "Epoch 33, Step: 715, Loss: 0.041053466498851776, Lr:0.0001\n",
      "Epoch 33, Step: 716, Loss: 0.00432842830196023, Lr:0.0001\n",
      "Epoch 33, Step: 717, Loss: 0.07018682360649109, Lr:0.0001\n",
      "Epoch 33, Step: 718, Loss: 0.24092727899551392, Lr:0.0001\n",
      "Epoch 33, Step: 719, Loss: 0.0017820697976276278, Lr:0.0001\n",
      "Epoch 33, Step: 720, Loss: 0.08757845312356949, Lr:0.0001\n",
      "Epoch 33, Step: 721, Loss: 0.034725259989500046, Lr:0.0001\n",
      "Epoch 33, Step: 722, Loss: 0.007272583898156881, Lr:0.0001\n",
      "Epoch 33, Step: 723, Loss: 0.07459306716918945, Lr:0.0001\n",
      "Epoch 33, Step: 724, Loss: 0.060170236974954605, Lr:0.0001\n",
      "Epoch 33, Step: 725, Loss: 0.054044563323259354, Lr:0.0001\n",
      "Epoch 33, Step: 726, Loss: 0.02766510657966137, Lr:0.0001\n",
      "Epoch 33, Step: 727, Loss: 0.0034863408654928207, Lr:0.0001\n",
      "Epoch 33, Step: 728, Loss: 0.022116702049970627, Lr:0.0001\n",
      "Epoch 33, Step: 729, Loss: 0.21929487586021423, Lr:0.0001\n",
      "Epoch 33, Step: 730, Loss: 0.11012386530637741, Lr:0.0001\n",
      "Epoch 33, Step: 731, Loss: 0.004635103978216648, Lr:0.0001\n",
      "Epoch 33, Step: 732, Loss: 0.09517662972211838, Lr:0.0001\n",
      "Epoch 33, Step: 733, Loss: 0.010069195181131363, Lr:0.0001\n",
      "Epoch 33, Step: 734, Loss: 0.02808680571615696, Lr:0.0001\n",
      "Epoch 33, Step: 735, Loss: 0.00699339946731925, Lr:0.0001\n",
      "Epoch 33, Step: 736, Loss: 0.08621278405189514, Lr:0.0001\n",
      "Epoch 33, Step: 737, Loss: 0.025211036205291748, Lr:0.0001\n",
      "Epoch 33, Step: 738, Loss: 0.015202143229544163, Lr:0.0001\n",
      "Epoch 33, Step: 739, Loss: 0.010602225549519062, Lr:0.0001\n",
      "Epoch 33, Step: 740, Loss: 0.09610167890787125, Lr:0.0001\n",
      "Epoch 33, Step: 741, Loss: 0.030314503237605095, Lr:0.0001\n",
      "Epoch 33, Step: 742, Loss: 0.0006954982527531683, Lr:0.0001\n",
      "Epoch 33, Step: 743, Loss: 0.052079640328884125, Lr:0.0001\n",
      "Epoch 33, Step: 744, Loss: 0.12883971631526947, Lr:0.0001\n",
      "Epoch 33, Step: 745, Loss: 0.07660038769245148, Lr:0.0001\n",
      "Epoch 33, Step: 746, Loss: 0.024957342073321342, Lr:0.0001\n",
      "Epoch 33, Step: 747, Loss: 0.017990540713071823, Lr:0.0001\n",
      "Epoch 33, Step: 748, Loss: 0.35525667667388916, Lr:0.0001\n",
      "Epoch 33, Step: 749, Loss: 0.04080245643854141, Lr:0.0001\n",
      "Epoch 33, Step: 750, Loss: 0.010445503517985344, Lr:0.0001\n",
      "Epoch 33, Step: 751, Loss: 0.04246669262647629, Lr:0.0001\n",
      "Epoch 33, Step: 752, Loss: 0.02828512340784073, Lr:0.0001\n",
      "Epoch 33, Step: 753, Loss: 0.03770846500992775, Lr:0.0001\n",
      "Epoch 33, Step: 754, Loss: 0.07398566603660583, Lr:0.0001\n",
      "Epoch 33, Step: 755, Loss: 0.00518178241327405, Lr:0.0001\n",
      "Epoch 33, Step: 756, Loss: 0.03201664239168167, Lr:0.0001\n",
      "Epoch 33, Step: 757, Loss: 0.0031949393451213837, Lr:0.0001\n",
      "Epoch 33, Step: 758, Loss: 0.01384895108640194, Lr:0.0001\n",
      "Epoch 33, Step: 759, Loss: 0.0030459556728601456, Lr:0.0001\n",
      "Epoch 33, Step: 760, Loss: 0.007083449047058821, Lr:0.0001\n",
      "Epoch 33, Step: 761, Loss: 0.021611982956528664, Lr:0.0001\n",
      "Epoch 33, Step: 762, Loss: 0.009257321245968342, Lr:0.0001\n",
      "Epoch 33, Step: 763, Loss: 0.1635979413986206, Lr:0.0001\n",
      "Epoch 33, Step: 764, Loss: 0.022272294387221336, Lr:0.0001\n",
      "Epoch 33, Step: 765, Loss: 0.1123604029417038, Lr:0.0001\n",
      "Epoch 33, Step: 766, Loss: 0.005086200311779976, Lr:0.0001\n",
      "Epoch 33, Step: 767, Loss: 0.17304940521717072, Lr:0.0001\n",
      "Epoch 33, Step: 768, Loss: 0.03776753693819046, Lr:0.0001\n",
      "Epoch 33, Step: 769, Loss: 0.005659585818648338, Lr:0.0001\n",
      "Epoch 33, Step: 770, Loss: 0.009070444852113724, Lr:0.0001\n",
      "Epoch 33, Step: 771, Loss: 0.10517505556344986, Lr:0.0001\n",
      "Epoch 33, Step: 772, Loss: 0.1721411496400833, Lr:0.0001\n",
      "Epoch 33, Step: 773, Loss: 0.013511309400200844, Lr:0.0001\n",
      "Epoch 33, Step: 774, Loss: 0.08230621367692947, Lr:0.0001\n",
      "Epoch 33, Step: 775, Loss: 0.09592233598232269, Lr:0.0001\n",
      "Epoch 33, Step: 776, Loss: 0.3132924735546112, Lr:0.0001\n",
      "Epoch 33, Step: 777, Loss: 0.028545470908284187, Lr:0.0001\n",
      "Epoch 33, Step: 778, Loss: 0.00952874030917883, Lr:0.0001\n",
      "Epoch 33, Step: 779, Loss: 0.004901500418782234, Lr:0.0001\n",
      "Epoch 33, Step: 780, Loss: 0.00030839405371807516, Lr:0.0001\n",
      "Epoch 33, Step: 781, Loss: 0.012925410643219948, Lr:0.0001\n",
      "Epoch 33, Step: 782, Loss: 0.019740642979741096, Lr:0.0001\n",
      "Epoch 33, Step: 783, Loss: 0.07108086347579956, Lr:0.0001\n",
      "Epoch 33, Step: 784, Loss: 0.022020723670721054, Lr:0.0001\n",
      "Epoch 33, Step: 785, Loss: 0.0792369693517685, Lr:0.0001\n",
      "Epoch 33, Step: 786, Loss: 0.003065770259127021, Lr:0.0001\n",
      "Epoch 33, Step: 787, Loss: 0.21129994094371796, Lr:0.0001\n",
      "Epoch 33, Step: 788, Loss: 0.04530494287610054, Lr:0.0001\n",
      "Epoch 33, Step: 789, Loss: 0.12930673360824585, Lr:0.0001\n",
      "Epoch 33, Step: 790, Loss: 0.17906180024147034, Lr:0.0001\n",
      "Epoch 33, Step: 791, Loss: 0.2137783169746399, Lr:0.0001\n",
      "Epoch 33, Step: 792, Loss: 0.17038458585739136, Lr:0.0001\n",
      "Epoch 33, Step: 793, Loss: 0.0771096795797348, Lr:0.0001\n",
      "Epoch 33, Step: 794, Loss: 0.07715556770563126, Lr:0.0001\n",
      "Epoch 33, Step: 795, Loss: 0.014278257265686989, Lr:0.0001\n",
      "Epoch 33, Step: 796, Loss: 0.020520664751529694, Lr:0.0001\n",
      "Epoch 33, Step: 797, Loss: 0.003473317250609398, Lr:0.0001\n",
      "Epoch 33, Step: 798, Loss: 0.16502408683300018, Lr:0.0001\n",
      "Epoch 33, Step: 799, Loss: 0.005987192969769239, Lr:0.0001\n",
      "Epoch 33, Step: 800, Loss: 0.029193783178925514, Lr:0.0001\n",
      "Epoch 33, Step: 801, Loss: 0.04358914494514465, Lr:0.0001\n",
      "Epoch 33, Step: 802, Loss: 0.08423063158988953, Lr:0.0001\n",
      "Epoch 33, Step: 803, Loss: 0.06424884498119354, Lr:0.0001\n",
      "Epoch 33, Step: 804, Loss: 0.14921149611473083, Lr:0.0001\n",
      "Epoch 33, Step: 805, Loss: 0.024038761854171753, Lr:0.0001\n",
      "Epoch 33, Step: 806, Loss: 0.0015972935361787677, Lr:0.0001\n",
      "Epoch 33, Step: 807, Loss: 0.026431413367390633, Lr:0.0001\n",
      "Epoch 33, Step: 808, Loss: 0.0072316559962928295, Lr:0.0001\n",
      "Epoch 33, Step: 809, Loss: 0.1548924595117569, Lr:0.0001\n",
      "Epoch 33, Step: 810, Loss: 0.015598030760884285, Lr:0.0001\n",
      "Epoch 33, Step: 811, Loss: 0.10542365163564682, Lr:0.0001\n",
      "Epoch 33, Step: 812, Loss: 0.020800398662686348, Lr:0.0001\n",
      "Epoch 33, Step: 813, Loss: 0.04368425905704498, Lr:0.0001\n",
      "Epoch 33, Step: 814, Loss: 0.2368980050086975, Lr:0.0001\n",
      "Epoch 33, Step: 815, Loss: 0.006051397882401943, Lr:0.0001\n",
      "Epoch 33, Step: 816, Loss: 0.014529594220221043, Lr:0.0001\n",
      "Epoch 33, Step: 817, Loss: 0.04753487929701805, Lr:0.0001\n",
      "Epoch 33, Step: 818, Loss: 0.13141454756259918, Lr:0.0001\n",
      "Epoch 33, Step: 819, Loss: 0.02076778933405876, Lr:0.0001\n",
      "Epoch 33, Step: 820, Loss: 0.004378044977784157, Lr:0.0001\n",
      "Epoch 33, Step: 821, Loss: 0.04918256029486656, Lr:0.0001\n",
      "Epoch 33, Step: 822, Loss: 0.008646952919661999, Lr:0.0001\n",
      "Epoch 33, Step: 823, Loss: 0.009576559998095036, Lr:0.0001\n",
      "Epoch 33, Step: 824, Loss: 0.0764508917927742, Lr:0.0001\n",
      "Epoch 33, Step: 825, Loss: 0.020045915618538857, Lr:0.0001\n",
      "Epoch 33, Step: 826, Loss: 0.16567853093147278, Lr:0.0001\n",
      "Epoch 33, Step: 827, Loss: 0.05022146925330162, Lr:0.0001\n",
      "Epoch 33, Step: 828, Loss: 0.09881666302680969, Lr:0.0001\n",
      "Epoch 33, Step: 829, Loss: 0.04787494242191315, Lr:0.0001\n",
      "Epoch 33, Step: 830, Loss: 0.041070010513067245, Lr:0.0001\n",
      "Epoch 33, Step: 831, Loss: 0.31237778067588806, Lr:0.0001\n",
      "Epoch 33, Step: 832, Loss: 0.05291884392499924, Lr:0.0001\n",
      "Epoch 33, Step: 833, Loss: 0.09184746444225311, Lr:0.0001\n",
      "Epoch 33, Step: 834, Loss: 0.01418362371623516, Lr:0.0001\n",
      "Epoch 33, Step: 835, Loss: 0.08122887462377548, Lr:0.0001\n",
      "Epoch 33, Step: 836, Loss: 0.04474690929055214, Lr:0.0001\n",
      "Epoch 33, Step: 837, Loss: 0.04730319604277611, Lr:0.0001\n",
      "Epoch 33, Step: 838, Loss: 0.00038958998629823327, Lr:0.0001\n",
      "Epoch 33, Step: 839, Loss: 0.06592600792646408, Lr:0.0001\n",
      "Epoch 33, Step: 840, Loss: 0.028062520548701286, Lr:0.0001\n",
      "Epoch 33, Step: 841, Loss: 0.08588560670614243, Lr:0.0001\n",
      "Epoch 33, Step: 842, Loss: 0.0023751496337354183, Lr:0.0001\n",
      "Epoch 33, Step: 843, Loss: 0.01968110352754593, Lr:0.0001\n",
      "Epoch 33, Step: 844, Loss: 0.05394158884882927, Lr:0.0001\n",
      "Epoch 33, Step: 845, Loss: 0.015356151387095451, Lr:0.0001\n",
      "Epoch 33, Step: 846, Loss: 0.014462835155427456, Lr:0.0001\n",
      "Epoch 33, Step: 847, Loss: 0.0023069249000400305, Lr:0.0001\n",
      "Epoch 33, Step: 848, Loss: 0.006622144021093845, Lr:0.0001\n",
      "Epoch 33, Step: 849, Loss: 0.07073332369327545, Lr:0.0001\n",
      "Epoch 33, Step: 850, Loss: 0.011454066261649132, Lr:0.0001\n",
      "Epoch 33, Step: 851, Loss: 0.06233201548457146, Lr:0.0001\n",
      "Epoch 33, Step: 852, Loss: 0.006351377349346876, Lr:0.0001\n",
      "Epoch 33, Step: 853, Loss: 0.010427522473037243, Lr:0.0001\n",
      "Epoch 33, Step: 854, Loss: 0.02729368768632412, Lr:0.0001\n",
      "Epoch 33, Step: 855, Loss: 0.016635628417134285, Lr:0.0001\n",
      "Epoch 33, Step: 856, Loss: 0.004805260803550482, Lr:0.0001\n",
      "Epoch 33, Step: 857, Loss: 0.020749663934111595, Lr:0.0001\n",
      "Epoch 33, Step: 858, Loss: 0.02245968021452427, Lr:0.0001\n",
      "Epoch 33, Step: 859, Loss: 0.0003083165502175689, Lr:0.0001\n",
      "Epoch 33, Step: 860, Loss: 0.06405096501111984, Lr:0.0001\n",
      "Epoch 33, Step: 861, Loss: 0.007944697514176369, Lr:0.0001\n",
      "Epoch 33, Step: 862, Loss: 0.01733371801674366, Lr:0.0001\n",
      "Epoch 33, Step: 863, Loss: 0.025968855246901512, Lr:0.0001\n",
      "Epoch 33, Step: 864, Loss: 0.013739160262048244, Lr:0.0001\n",
      "Epoch 33, Step: 865, Loss: 0.06124119833111763, Lr:0.0001\n",
      "Epoch 33, Step: 866, Loss: 0.01601986773312092, Lr:0.0001\n",
      "Epoch 33, Step: 867, Loss: 0.001019441056996584, Lr:0.0001\n",
      "Epoch 33, Step: 868, Loss: 0.027287285774946213, Lr:0.0001\n",
      "Epoch 33, Step: 869, Loss: 0.21030193567276, Lr:0.0001\n",
      "Epoch 33, Step: 870, Loss: 0.042665980756282806, Lr:0.0001\n",
      "Epoch 33, Step: 871, Loss: 0.0029117590747773647, Lr:0.0001\n",
      "Epoch 33, Step: 872, Loss: 0.018181677907705307, Lr:0.0001\n",
      "Epoch 33, Step: 873, Loss: 0.001503226114436984, Lr:0.0001\n",
      "Epoch 33, Step: 874, Loss: 0.07504110783338547, Lr:0.0001\n",
      "Epoch 33, Step: 875, Loss: 0.028051093220710754, Lr:0.0001\n",
      "Epoch 33, Step: 876, Loss: 0.012788636609911919, Lr:0.0001\n",
      "Epoch 33, Step: 877, Loss: 0.07667849212884903, Lr:0.0001\n",
      "Epoch 33, Step: 878, Loss: 0.1631859987974167, Lr:0.0001\n",
      "Epoch 33, Step: 879, Loss: 0.026146313175559044, Lr:0.0001\n",
      "Epoch 33, Step: 880, Loss: 0.0018804066348820925, Lr:0.0001\n",
      "Epoch 33, Step: 881, Loss: 0.04835278540849686, Lr:0.0001\n",
      "Epoch 33, Step: 882, Loss: 0.005747274961322546, Lr:0.0001\n",
      "Epoch 33, Step: 883, Loss: 0.09435591101646423, Lr:0.0001\n",
      "Epoch 33, Step: 884, Loss: 0.037558723241090775, Lr:0.0001\n",
      "Epoch 33, Step: 885, Loss: 0.12946276366710663, Lr:0.0001\n",
      "Epoch 33, Step: 886, Loss: 0.0193803533911705, Lr:0.0001\n",
      "Epoch 33, Step: 887, Loss: 0.11370410025119781, Lr:0.0001\n",
      "Epoch 33, Step: 888, Loss: 0.02427220717072487, Lr:0.0001\n",
      "Epoch 33, Step: 889, Loss: 0.005986443720757961, Lr:0.0001\n",
      "Epoch 33, Step: 890, Loss: 0.22115935385227203, Lr:0.0001\n",
      "Epoch 33, Step: 891, Loss: 0.004727317485958338, Lr:0.0001\n",
      "Epoch 33, Step: 892, Loss: 0.002265815157443285, Lr:0.0001\n",
      "Epoch 33, Step: 893, Loss: 0.0015022912994027138, Lr:0.0001\n",
      "Epoch 33, Step: 894, Loss: 0.008631293661892414, Lr:0.0001\n",
      "Epoch 33, Step: 895, Loss: 0.04340062290430069, Lr:0.0001\n",
      "Epoch 33, Step: 896, Loss: 0.045648057013750076, Lr:0.0001\n",
      "Epoch 33, Step: 897, Loss: 0.009031730704009533, Lr:0.0001\n",
      "Epoch 33, Step: 898, Loss: 0.05526408553123474, Lr:0.0001\n",
      "Epoch 33, Step: 899, Loss: 0.12096207588911057, Lr:0.0001\n",
      "Epoch 33, Step: 900, Loss: 0.09996096789836884, Lr:0.0001\n",
      "Epoch 33, Step: 901, Loss: 0.12598390877246857, Lr:0.0001\n",
      "Epoch 33, Step: 902, Loss: 0.008552650921046734, Lr:0.0001\n",
      "Epoch 33, Step: 903, Loss: 0.008699583820998669, Lr:0.0001\n",
      "Epoch 33, Step: 904, Loss: 0.007830205373466015, Lr:0.0001\n",
      "Epoch 33, Step: 905, Loss: 0.0015781711554154754, Lr:0.0001\n",
      "Epoch 33, Step: 906, Loss: 0.18068131804466248, Lr:0.0001\n",
      "Epoch 33, Step: 907, Loss: 0.014144179411232471, Lr:0.0001\n",
      "Epoch 33, Step: 908, Loss: 0.23288200795650482, Lr:0.0001\n",
      "Epoch 33, Step: 909, Loss: 0.019173653796315193, Lr:0.0001\n",
      "Epoch 33, Step: 910, Loss: 0.004092471674084663, Lr:0.0001\n",
      "Epoch 33, Step: 911, Loss: 0.01073027215898037, Lr:0.0001\n",
      "Epoch 33, Step: 912, Loss: 0.03970639407634735, Lr:0.0001\n",
      "Epoch 33, Step: 913, Loss: 0.00644910940900445, Lr:0.0001\n",
      "Epoch 33, Step: 914, Loss: 0.2564162015914917, Lr:0.0001\n",
      "Epoch 33, Step: 915, Loss: 0.051537349820137024, Lr:0.0001\n",
      "Epoch 33, Step: 916, Loss: 0.014739321544766426, Lr:0.0001\n",
      "Epoch 33, Step: 917, Loss: 0.007638323586434126, Lr:0.0001\n",
      "Epoch 33, Step: 918, Loss: 0.02128753811120987, Lr:0.0001\n",
      "Epoch 33, Step: 919, Loss: 0.12062352150678635, Lr:0.0001\n",
      "Epoch 33, Step: 920, Loss: 0.02344432659447193, Lr:0.0001\n",
      "Epoch 33, Step: 921, Loss: 0.012398804537951946, Lr:0.0001\n",
      "Epoch 33, Step: 922, Loss: 0.049861613661050797, Lr:0.0001\n",
      "Epoch 33, Step: 923, Loss: 0.04993025213479996, Lr:0.0001\n",
      "Epoch 33, Step: 924, Loss: 0.006130702793598175, Lr:0.0001\n",
      "Epoch 33, Step: 925, Loss: 0.03799838945269585, Lr:0.0001\n",
      "Epoch 33, Step: 926, Loss: 0.19756610691547394, Lr:0.0001\n",
      "Epoch 33, Step: 927, Loss: 0.1507168859243393, Lr:0.0001\n",
      "Epoch 33, Step: 928, Loss: 0.0033509312197566032, Lr:0.0001\n",
      "Epoch 33, Step: 929, Loss: 0.008310092613101006, Lr:0.0001\n",
      "Epoch 33, Step: 930, Loss: 0.30011776089668274, Lr:0.0001\n",
      "Epoch 33, Step: 931, Loss: 0.025051850825548172, Lr:0.0001\n",
      "Epoch 33, Step: 932, Loss: 0.10576562583446503, Lr:0.0001\n",
      "Epoch 33, Step: 933, Loss: 0.007418887224048376, Lr:0.0001\n",
      "Epoch 33, Step: 934, Loss: 0.07153116911649704, Lr:0.0001\n",
      "Epoch 33, Step: 935, Loss: 0.017948854714632034, Lr:0.0001\n",
      "Epoch 33, Step: 936, Loss: 0.061067886650562286, Lr:0.0001\n",
      "Epoch 33, Step: 937, Loss: 0.03595329821109772, Lr:0.0001\n",
      "Epoch 33, Step: 938, Loss: 0.06881702691316605, Lr:0.0001\n",
      "Epoch 33, Step: 939, Loss: 0.041891686618328094, Lr:0.0001\n",
      "Epoch 33, Step: 940, Loss: 0.002676701871678233, Lr:0.0001\n",
      "Epoch 33, Step: 941, Loss: 0.05912257730960846, Lr:0.0001\n",
      "Epoch 33, Step: 942, Loss: 0.15249304473400116, Lr:0.0001\n",
      "Epoch 33, Step: 943, Loss: 0.01623605377972126, Lr:0.0001\n",
      "Epoch 33, Step: 944, Loss: 0.09576024115085602, Lr:0.0001\n",
      "Epoch 33, Step: 945, Loss: 0.007524291984736919, Lr:0.0001\n",
      "Epoch 33, Step: 946, Loss: 0.04325319081544876, Lr:0.0001\n",
      "Epoch 33, Step: 947, Loss: 0.04095747694373131, Lr:0.0001\n",
      "Epoch 33, Step: 948, Loss: 0.006342316046357155, Lr:0.0001\n",
      "Epoch 33, Step: 949, Loss: 0.002773456973955035, Lr:0.0001\n",
      "Epoch 33, Step: 950, Loss: 0.0031309006735682487, Lr:0.0001\n",
      "Epoch 33, Step: 951, Loss: 0.07590161263942719, Lr:0.0001\n",
      "Epoch 33, Step: 952, Loss: 0.04614518955349922, Lr:0.0001\n",
      "Epoch 33, Step: 953, Loss: 0.0023282011970877647, Lr:0.0001\n",
      "Epoch 33, Step: 954, Loss: 0.3062329888343811, Lr:0.0001\n",
      "Epoch 33, Step: 955, Loss: 0.015523230656981468, Lr:0.0001\n",
      "Epoch 33, Step: 956, Loss: 0.025528762489557266, Lr:0.0001\n",
      "Epoch 33, Step: 957, Loss: 0.07589295506477356, Lr:0.0001\n",
      "Epoch 33, Step: 958, Loss: 0.03750721737742424, Lr:0.0001\n",
      "Epoch 33, Step: 959, Loss: 0.26945173740386963, Lr:0.0001\n",
      "Epoch 33, Step: 960, Loss: 0.01211720984429121, Lr:0.0001\n",
      "Epoch 33, Step: 961, Loss: 0.053514715284109116, Lr:0.0001\n",
      "Epoch 33, Step: 962, Loss: 0.0011881571263074875, Lr:0.0001\n",
      "Epoch 33, Step: 963, Loss: 0.039697591215372086, Lr:0.0001\n",
      "Epoch 33, Step: 964, Loss: 0.0004324877227190882, Lr:0.0001\n",
      "Epoch 33, Step: 965, Loss: 0.0071570551954209805, Lr:0.0001\n",
      "Epoch 33, Step: 966, Loss: 0.0014810289721935987, Lr:0.0001\n",
      "Epoch 33, Step: 967, Loss: 0.019731838256120682, Lr:0.0001\n",
      "Epoch 33, Step: 968, Loss: 0.017845511436462402, Lr:0.0001\n",
      "Epoch 33, Step: 969, Loss: 0.1231188029050827, Lr:0.0001\n",
      "Epoch 33, Step: 970, Loss: 0.004174535162746906, Lr:0.0001\n",
      "Epoch 33, Step: 971, Loss: 0.012172415852546692, Lr:0.0001\n",
      "Epoch 33, Step: 972, Loss: 0.4195280373096466, Lr:0.0001\n",
      "Epoch 33, Step: 973, Loss: 0.004164653830230236, Lr:0.0001\n",
      "Epoch 33, Step: 974, Loss: 0.05941179767251015, Lr:0.0001\n",
      "Epoch 33, Step: 975, Loss: 0.013803253881633282, Lr:0.0001\n",
      "Epoch 33, Step: 976, Loss: 0.0024197890888899565, Lr:0.0001\n",
      "Epoch 33, Step: 977, Loss: 0.06533126533031464, Lr:0.0001\n",
      "Epoch 33, Step: 978, Loss: 0.04856423661112785, Lr:0.0001\n",
      "Epoch 33, Step: 979, Loss: 0.007012137211859226, Lr:0.0001\n",
      "Epoch 33, Step: 980, Loss: 0.0024332557804882526, Lr:0.0001\n",
      "Epoch 33, Step: 981, Loss: 0.005273811984807253, Lr:0.0001\n",
      "Epoch 33, Step: 982, Loss: 0.0022294705267995596, Lr:0.0001\n",
      "Epoch 33, Step: 983, Loss: 0.005725238472223282, Lr:0.0001\n",
      "Epoch 33, Step: 984, Loss: 0.009983706288039684, Lr:0.0001\n",
      "Epoch 33, Step: 985, Loss: 0.22673192620277405, Lr:0.0001\n",
      "Epoch 33, Step: 986, Loss: 0.006341423839330673, Lr:0.0001\n",
      "Epoch 33, Step: 987, Loss: 0.03738383203744888, Lr:0.0001\n",
      "Epoch 33, Step: 988, Loss: 0.008604533970355988, Lr:0.0001\n",
      "Epoch 33, Step: 989, Loss: 0.13316360116004944, Lr:0.0001\n",
      "Epoch 33, Step: 990, Loss: 0.00391059136018157, Lr:0.0001\n",
      "Epoch 33, Step: 991, Loss: 0.014706120826303959, Lr:0.0001\n",
      "Epoch 33, Step: 992, Loss: 0.0912059023976326, Lr:0.0001\n",
      "Epoch 33, Step: 993, Loss: 0.05676780641078949, Lr:0.0001\n",
      "Epoch 33, Step: 994, Loss: 0.02689027413725853, Lr:0.0001\n",
      "Epoch 33, Step: 995, Loss: 0.011399616487324238, Lr:0.0001\n",
      "Epoch 33, Step: 996, Loss: 0.001329840742982924, Lr:0.0001\n",
      "Epoch 33, Step: 997, Loss: 0.041040461510419846, Lr:0.0001\n",
      "Epoch 33, Step: 998, Loss: 0.006700657773762941, Lr:0.0001\n",
      "Epoch 33, Step: 999, Loss: 0.03263922408223152, Lr:0.0001\n",
      "Epoch 33, Step: 1000, Loss: 0.12688887119293213, Lr:0.0001\n",
      "Epoch 33, Step: 1001, Loss: 0.19571110606193542, Lr:0.0001\n",
      "Epoch 33, Step: 1002, Loss: 0.04637850821018219, Lr:0.0001\n",
      "Epoch 33, Step: 1003, Loss: 0.011034579016268253, Lr:0.0001\n",
      "Epoch 33, Step: 1004, Loss: 0.012125946581363678, Lr:0.0001\n",
      "Epoch 33, Step: 1005, Loss: 0.006827060133218765, Lr:0.0001\n",
      "Epoch 33, Step: 1006, Loss: 0.18665723502635956, Lr:0.0001\n",
      "Epoch 33, Step: 1007, Loss: 0.0016684836009517312, Lr:0.0001\n",
      "Epoch 33, Step: 1008, Loss: 0.0664251372218132, Lr:0.0001\n",
      "Epoch 33, Step: 1009, Loss: 0.30649706721305847, Lr:0.0001\n",
      "Epoch 33, Step: 1010, Loss: 0.04197634011507034, Lr:0.0001\n",
      "Epoch 33, Step: 1011, Loss: 0.002905318746343255, Lr:0.0001\n",
      "Epoch 33, Step: 1012, Loss: 0.034072667360305786, Lr:0.0001\n",
      "Epoch 33, Step: 1013, Loss: 0.0004906764370389283, Lr:0.0001\n",
      "Epoch 33, Step: 1014, Loss: 0.072017602622509, Lr:0.0001\n",
      "Epoch 33, Step: 1015, Loss: 0.005174752324819565, Lr:0.0001\n",
      "Epoch 33, Step: 1016, Loss: 0.12198974937200546, Lr:0.0001\n",
      "Epoch 33, Step: 1017, Loss: 0.0018382109701633453, Lr:0.0001\n",
      "Epoch 33, Step: 1018, Loss: 0.0002622230094857514, Lr:0.0001\n",
      "Epoch 33, Step: 1019, Loss: 0.0987970307469368, Lr:0.0001\n",
      "Epoch 33, Step: 1020, Loss: 0.0022481882479041815, Lr:0.0001\n",
      "Epoch 33, Step: 1021, Loss: 0.005281008780002594, Lr:0.0001\n",
      "Epoch 33, Step: 1022, Loss: 0.09894776344299316, Lr:0.0001\n",
      "Epoch 33, Step: 1023, Loss: 0.00745763024315238, Lr:0.0001\n",
      "Epoch 33, Step: 1024, Loss: 0.006691959220916033, Lr:0.0001\n",
      "Epoch 33, Step: 1025, Loss: 0.017907341942191124, Lr:0.0001\n",
      "Epoch 33, Step: 1026, Loss: 0.01099342666566372, Lr:0.0001\n",
      "Epoch 33, Step: 1027, Loss: 0.0037266681902110577, Lr:0.0001\n",
      "Epoch 33, Step: 1028, Loss: 0.01308994460850954, Lr:0.0001\n",
      "Epoch 33, Step: 1029, Loss: 0.029322996735572815, Lr:0.0001\n",
      "Epoch 33, Step: 1030, Loss: 0.09572290629148483, Lr:0.0001\n",
      "Epoch 33, Step: 1031, Loss: 0.025095874443650246, Lr:0.0001\n",
      "Epoch 33, Step: 1032, Loss: 0.028636420145630836, Lr:0.0001\n",
      "Epoch 33, Step: 1033, Loss: 0.018343957141041756, Lr:0.0001\n",
      "Epoch 33, Step: 1034, Loss: 6.642311927862465e-05, Lr:0.0001\n",
      "Epoch 33, Step: 1035, Loss: 0.0785662978887558, Lr:0.0001\n",
      "Epoch 33, Step: 1036, Loss: 0.15079466998577118, Lr:0.0001\n",
      "Epoch 33, Step: 1037, Loss: 0.08891669660806656, Lr:0.0001\n",
      "Epoch 33, Step: 1038, Loss: 0.001974794315174222, Lr:0.0001\n",
      "Epoch 33, Step: 1039, Loss: 0.008918171748518944, Lr:0.0001\n",
      "Epoch 33, Step: 1040, Loss: 0.1514301896095276, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 33\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:15 loss: 1.1133 (1.1133) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.2810 data: 0.1130 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.1159 (0.2147) acc1: 93.7500 (94.3182) acc5: 100.0000 (100.0000) time: 0.2837 data: 0.1111 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.1178 (0.2450) acc1: 93.7500 (92.8571) acc5: 100.0000 (100.0000) time: 0.2858 data: 0.1112 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.2024 (0.2764) acc1: 93.7500 (91.7339) acc5: 100.0000 (100.0000) time: 0.2892 data: 0.1133 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.0467 (0.2224) acc1: 93.7500 (93.2927) acc5: 100.0000 (100.0000) time: 0.2908 data: 0.1161 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0205 (0.1950) acc1: 100.0000 (93.7500) acc5: 100.0000 (100.0000) time: 0.2953 data: 0.1181 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0059 (0.1882) acc1: 100.0000 (93.8706) acc5: 100.0000 (100.0000) time: 0.2862 data: 0.1145 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.2872 s / it)\n",
      "* Acc@1 93.871 Acc@5 100.000 loss 0.188\n",
      "Accuracy of the network on the 881 test image: 93.9%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 34, Step: 0, Loss: 0.01508252415806055, Lr:0.0001\n",
      "Epoch 34, Step: 1, Loss: 0.02440846525132656, Lr:0.0001\n",
      "Epoch 34, Step: 2, Loss: 0.03785967081785202, Lr:0.0001\n",
      "Epoch 34, Step: 3, Loss: 0.0008894334314391017, Lr:0.0001\n",
      "Epoch 34, Step: 4, Loss: 0.004977993667125702, Lr:0.0001\n",
      "Epoch 34, Step: 5, Loss: 0.08501387387514114, Lr:0.0001\n",
      "Epoch 34, Step: 6, Loss: 0.000522557005751878, Lr:0.0001\n",
      "Epoch 34, Step: 7, Loss: 0.00207342067733407, Lr:0.0001\n",
      "Epoch 34, Step: 8, Loss: 0.004534942097961903, Lr:0.0001\n",
      "Epoch 34, Step: 9, Loss: 0.006908247247338295, Lr:0.0001\n",
      "Epoch 34, Step: 10, Loss: 0.001894699176773429, Lr:0.0001\n",
      "Epoch 34, Step: 11, Loss: 0.0006036696722730994, Lr:0.0001\n",
      "Epoch 34, Step: 12, Loss: 0.0266401469707489, Lr:0.0001\n",
      "Epoch 34, Step: 13, Loss: 0.20549575984477997, Lr:0.0001\n",
      "Epoch 34, Step: 14, Loss: 0.02401529625058174, Lr:0.0001\n",
      "Epoch 34, Step: 15, Loss: 0.03520762175321579, Lr:0.0001\n",
      "Epoch 34, Step: 16, Loss: 0.008336963132023811, Lr:0.0001\n",
      "Epoch 34, Step: 17, Loss: 0.015826471149921417, Lr:0.0001\n",
      "Epoch 34, Step: 18, Loss: 0.041860807687044144, Lr:0.0001\n",
      "Epoch 34, Step: 19, Loss: 0.03324181213974953, Lr:0.0001\n",
      "Epoch 34, Step: 20, Loss: 0.03047673963010311, Lr:0.0001\n",
      "Epoch 34, Step: 21, Loss: 0.027472537010908127, Lr:0.0001\n",
      "Epoch 34, Step: 22, Loss: 0.023431289941072464, Lr:0.0001\n",
      "Epoch 34, Step: 23, Loss: 0.006802992895245552, Lr:0.0001\n",
      "Epoch 34, Step: 24, Loss: 0.011687768623232841, Lr:0.0001\n",
      "Epoch 34, Step: 25, Loss: 0.011367461644113064, Lr:0.0001\n",
      "Epoch 34, Step: 26, Loss: 0.0704977959394455, Lr:0.0001\n",
      "Epoch 34, Step: 27, Loss: 0.00706916768103838, Lr:0.0001\n",
      "Epoch 34, Step: 28, Loss: 0.00638933852314949, Lr:0.0001\n",
      "Epoch 34, Step: 29, Loss: 0.010873890481889248, Lr:0.0001\n",
      "Epoch 34, Step: 30, Loss: 0.05261137709021568, Lr:0.0001\n",
      "Epoch 34, Step: 31, Loss: 0.007001174613833427, Lr:0.0001\n",
      "Epoch 34, Step: 32, Loss: 0.0006204370874911547, Lr:0.0001\n",
      "Epoch 34, Step: 33, Loss: 0.019264988601207733, Lr:0.0001\n",
      "Epoch 34, Step: 34, Loss: 0.009369194507598877, Lr:0.0001\n",
      "Epoch 34, Step: 35, Loss: 0.05662121996283531, Lr:0.0001\n",
      "Epoch 34, Step: 36, Loss: 0.008851097896695137, Lr:0.0001\n",
      "Epoch 34, Step: 37, Loss: 0.002705482766032219, Lr:0.0001\n",
      "Epoch 34, Step: 38, Loss: 0.14637137949466705, Lr:0.0001\n",
      "Epoch 34, Step: 39, Loss: 0.027512291446328163, Lr:0.0001\n",
      "Epoch 34, Step: 40, Loss: 0.0011291905539110303, Lr:0.0001\n",
      "Epoch 34, Step: 41, Loss: 0.07892810553312302, Lr:0.0001\n",
      "Epoch 34, Step: 42, Loss: 0.032841939479112625, Lr:0.0001\n",
      "Epoch 34, Step: 43, Loss: 0.024118473753333092, Lr:0.0001\n",
      "Epoch 34, Step: 44, Loss: 0.036530978977680206, Lr:0.0001\n",
      "Epoch 34, Step: 45, Loss: 0.04549635946750641, Lr:0.0001\n",
      "Epoch 34, Step: 46, Loss: 0.2831067442893982, Lr:0.0001\n",
      "Epoch 34, Step: 47, Loss: 0.008340096101164818, Lr:0.0001\n",
      "Epoch 34, Step: 48, Loss: 0.001513528754003346, Lr:0.0001\n",
      "Epoch 34, Step: 49, Loss: 0.03227449581027031, Lr:0.0001\n",
      "Epoch 34, Step: 50, Loss: 0.008783901110291481, Lr:0.0001\n",
      "Epoch 34, Step: 51, Loss: 0.02559027262032032, Lr:0.0001\n",
      "Epoch 34, Step: 52, Loss: 0.06893714517354965, Lr:0.0001\n",
      "Epoch 34, Step: 53, Loss: 0.006331090349704027, Lr:0.0001\n",
      "Epoch 34, Step: 54, Loss: 0.10524603724479675, Lr:0.0001\n",
      "Epoch 34, Step: 55, Loss: 0.03923169523477554, Lr:0.0001\n",
      "Epoch 34, Step: 56, Loss: 0.04681876674294472, Lr:0.0001\n",
      "Epoch 34, Step: 57, Loss: 0.08126268535852432, Lr:0.0001\n",
      "Epoch 34, Step: 58, Loss: 0.059014540165662766, Lr:0.0001\n",
      "Epoch 34, Step: 59, Loss: 0.0007008381653577089, Lr:0.0001\n",
      "Epoch 34, Step: 60, Loss: 0.13034985959529877, Lr:0.0001\n",
      "Epoch 34, Step: 61, Loss: 0.010426274500787258, Lr:0.0001\n",
      "Epoch 34, Step: 62, Loss: 0.014791161753237247, Lr:0.0001\n",
      "Epoch 34, Step: 63, Loss: 0.05394618585705757, Lr:0.0001\n",
      "Epoch 34, Step: 64, Loss: 0.057966601103544235, Lr:0.0001\n",
      "Epoch 34, Step: 65, Loss: 0.030636945739388466, Lr:0.0001\n",
      "Epoch 34, Step: 66, Loss: 0.03728029504418373, Lr:0.0001\n",
      "Epoch 34, Step: 67, Loss: 0.005659719463437796, Lr:0.0001\n",
      "Epoch 34, Step: 68, Loss: 0.002945008222013712, Lr:0.0001\n",
      "Epoch 34, Step: 69, Loss: 0.1210201159119606, Lr:0.0001\n",
      "Epoch 34, Step: 70, Loss: 0.04770951345562935, Lr:0.0001\n",
      "Epoch 34, Step: 71, Loss: 0.026014694944024086, Lr:0.0001\n",
      "Epoch 34, Step: 72, Loss: 0.03492648899555206, Lr:0.0001\n",
      "Epoch 34, Step: 73, Loss: 0.0476888045668602, Lr:0.0001\n",
      "Epoch 34, Step: 74, Loss: 0.0051873233169317245, Lr:0.0001\n",
      "Epoch 34, Step: 75, Loss: 0.010138006880879402, Lr:0.0001\n",
      "Epoch 34, Step: 76, Loss: 0.004892601165920496, Lr:0.0001\n",
      "Epoch 34, Step: 77, Loss: 0.010104476474225521, Lr:0.0001\n",
      "Epoch 34, Step: 78, Loss: 0.0010299973655492067, Lr:0.0001\n",
      "Epoch 34, Step: 79, Loss: 0.011471212841570377, Lr:0.0001\n",
      "Epoch 34, Step: 80, Loss: 0.06479109823703766, Lr:0.0001\n",
      "Epoch 34, Step: 81, Loss: 0.00484749861061573, Lr:0.0001\n",
      "Epoch 34, Step: 82, Loss: 0.06577898561954498, Lr:0.0001\n",
      "Epoch 34, Step: 83, Loss: 0.03285747393965721, Lr:0.0001\n",
      "Epoch 34, Step: 84, Loss: 0.001885823206976056, Lr:0.0001\n",
      "Epoch 34, Step: 85, Loss: 0.13499392569065094, Lr:0.0001\n",
      "Epoch 34, Step: 86, Loss: 0.007030326407402754, Lr:0.0001\n",
      "Epoch 34, Step: 87, Loss: 0.053355854004621506, Lr:0.0001\n",
      "Epoch 34, Step: 88, Loss: 0.01503733266144991, Lr:0.0001\n",
      "Epoch 34, Step: 89, Loss: 0.010016830638051033, Lr:0.0001\n",
      "Epoch 34, Step: 90, Loss: 0.024499036371707916, Lr:0.0001\n",
      "Epoch 34, Step: 91, Loss: 0.012593485414981842, Lr:0.0001\n",
      "Epoch 34, Step: 92, Loss: 0.05889192223548889, Lr:0.0001\n",
      "Epoch 34, Step: 93, Loss: 0.060696594417095184, Lr:0.0001\n",
      "Epoch 34, Step: 94, Loss: 0.012532650493085384, Lr:0.0001\n",
      "Epoch 34, Step: 95, Loss: 0.11736416071653366, Lr:0.0001\n",
      "Epoch 34, Step: 96, Loss: 0.03388268128037453, Lr:0.0001\n",
      "Epoch 34, Step: 97, Loss: 0.0016520475037395954, Lr:0.0001\n",
      "Epoch 34, Step: 98, Loss: 0.01834283396601677, Lr:0.0001\n",
      "Epoch 34, Step: 99, Loss: 0.16581116616725922, Lr:0.0001\n",
      "Epoch 34, Step: 100, Loss: 0.001464754343032837, Lr:0.0001\n",
      "Epoch 34, Step: 101, Loss: 0.013858377002179623, Lr:0.0001\n",
      "Epoch 34, Step: 102, Loss: 0.1096004918217659, Lr:0.0001\n",
      "Epoch 34, Step: 103, Loss: 0.10066355019807816, Lr:0.0001\n",
      "Epoch 34, Step: 104, Loss: 0.004335602279752493, Lr:0.0001\n",
      "Epoch 34, Step: 105, Loss: 0.017780672758817673, Lr:0.0001\n",
      "Epoch 34, Step: 106, Loss: 0.046332359313964844, Lr:0.0001\n",
      "Epoch 34, Step: 107, Loss: 0.20033983886241913, Lr:0.0001\n",
      "Epoch 34, Step: 108, Loss: 0.026207298040390015, Lr:0.0001\n",
      "Epoch 34, Step: 109, Loss: 0.018186990171670914, Lr:0.0001\n",
      "Epoch 34, Step: 110, Loss: 0.5289570689201355, Lr:0.0001\n",
      "Epoch 34, Step: 111, Loss: 0.01949324458837509, Lr:0.0001\n",
      "Epoch 34, Step: 112, Loss: 0.011201378889381886, Lr:0.0001\n",
      "Epoch 34, Step: 113, Loss: 0.18521328270435333, Lr:0.0001\n",
      "Epoch 34, Step: 114, Loss: 0.035414472222328186, Lr:0.0001\n",
      "Epoch 34, Step: 115, Loss: 0.005148678552359343, Lr:0.0001\n",
      "Epoch 34, Step: 116, Loss: 0.017031492665410042, Lr:0.0001\n",
      "Epoch 34, Step: 117, Loss: 0.039546459913253784, Lr:0.0001\n",
      "Epoch 34, Step: 118, Loss: 0.011397212743759155, Lr:0.0001\n",
      "Epoch 34, Step: 119, Loss: 0.00201765657402575, Lr:0.0001\n",
      "Epoch 34, Step: 120, Loss: 0.008407078683376312, Lr:0.0001\n",
      "Epoch 34, Step: 121, Loss: 0.0018886703765019774, Lr:0.0001\n",
      "Epoch 34, Step: 122, Loss: 0.000963028403930366, Lr:0.0001\n",
      "Epoch 34, Step: 123, Loss: 0.03382930904626846, Lr:0.0001\n",
      "Epoch 34, Step: 124, Loss: 0.09316197037696838, Lr:0.0001\n",
      "Epoch 34, Step: 125, Loss: 0.0021984155755490065, Lr:0.0001\n",
      "Epoch 34, Step: 126, Loss: 0.10766472667455673, Lr:0.0001\n",
      "Epoch 34, Step: 127, Loss: 0.021619945764541626, Lr:0.0001\n",
      "Epoch 34, Step: 128, Loss: 0.0052323490381240845, Lr:0.0001\n",
      "Epoch 34, Step: 129, Loss: 0.03174274042248726, Lr:0.0001\n",
      "Epoch 34, Step: 130, Loss: 0.03333263844251633, Lr:0.0001\n",
      "Epoch 34, Step: 131, Loss: 0.05357597395777702, Lr:0.0001\n",
      "Epoch 34, Step: 132, Loss: 0.01636528968811035, Lr:0.0001\n",
      "Epoch 34, Step: 133, Loss: 0.12212280184030533, Lr:0.0001\n",
      "Epoch 34, Step: 134, Loss: 0.005789830815047026, Lr:0.0001\n",
      "Epoch 34, Step: 135, Loss: 0.11469051241874695, Lr:0.0001\n",
      "Epoch 34, Step: 136, Loss: 0.00305383512750268, Lr:0.0001\n",
      "Epoch 34, Step: 137, Loss: 0.036734987050294876, Lr:0.0001\n",
      "Epoch 34, Step: 138, Loss: 0.12206730246543884, Lr:0.0001\n",
      "Epoch 34, Step: 139, Loss: 0.005259442143142223, Lr:0.0001\n",
      "Epoch 34, Step: 140, Loss: 0.013794345781207085, Lr:0.0001\n",
      "Epoch 34, Step: 141, Loss: 0.011220395565032959, Lr:0.0001\n",
      "Epoch 34, Step: 142, Loss: 0.16832490265369415, Lr:0.0001\n",
      "Epoch 34, Step: 143, Loss: 0.01741456612944603, Lr:0.0001\n",
      "Epoch 34, Step: 144, Loss: 0.001745132147334516, Lr:0.0001\n",
      "Epoch 34, Step: 145, Loss: 0.046813953667879105, Lr:0.0001\n",
      "Epoch 34, Step: 146, Loss: 0.1196310818195343, Lr:0.0001\n",
      "Epoch 34, Step: 147, Loss: 0.00682209013029933, Lr:0.0001\n",
      "Epoch 34, Step: 148, Loss: 0.00181260472163558, Lr:0.0001\n",
      "Epoch 34, Step: 149, Loss: 0.041978105902671814, Lr:0.0001\n",
      "Epoch 34, Step: 150, Loss: 0.14822015166282654, Lr:0.0001\n",
      "Epoch 34, Step: 151, Loss: 0.025128379464149475, Lr:0.0001\n",
      "Epoch 34, Step: 152, Loss: 0.026193667203187943, Lr:0.0001\n",
      "Epoch 34, Step: 153, Loss: 0.006836877204477787, Lr:0.0001\n",
      "Epoch 34, Step: 154, Loss: 0.03750276193022728, Lr:0.0001\n",
      "Epoch 34, Step: 155, Loss: 0.03258354589343071, Lr:0.0001\n",
      "Epoch 34, Step: 156, Loss: 0.005508477799594402, Lr:0.0001\n",
      "Epoch 34, Step: 157, Loss: 0.005778794176876545, Lr:0.0001\n",
      "Epoch 34, Step: 158, Loss: 0.1924532800912857, Lr:0.0001\n",
      "Epoch 34, Step: 159, Loss: 0.08266609907150269, Lr:0.0001\n",
      "Epoch 34, Step: 160, Loss: 0.10302473604679108, Lr:0.0001\n",
      "Epoch 34, Step: 161, Loss: 0.004301405977457762, Lr:0.0001\n",
      "Epoch 34, Step: 162, Loss: 0.01370033249258995, Lr:0.0001\n",
      "Epoch 34, Step: 163, Loss: 0.11333654075860977, Lr:0.0001\n",
      "Epoch 34, Step: 164, Loss: 0.10427580028772354, Lr:0.0001\n",
      "Epoch 34, Step: 165, Loss: 0.004492606036365032, Lr:0.0001\n",
      "Epoch 34, Step: 166, Loss: 0.013170875608921051, Lr:0.0001\n",
      "Epoch 34, Step: 167, Loss: 0.03230937942862511, Lr:0.0001\n",
      "Epoch 34, Step: 168, Loss: 0.008568063378334045, Lr:0.0001\n",
      "Epoch 34, Step: 169, Loss: 0.01031943503767252, Lr:0.0001\n",
      "Epoch 34, Step: 170, Loss: 0.006085467059165239, Lr:0.0001\n",
      "Epoch 34, Step: 171, Loss: 0.010517606511712074, Lr:0.0001\n",
      "Epoch 34, Step: 172, Loss: 0.006610071752220392, Lr:0.0001\n",
      "Epoch 34, Step: 173, Loss: 0.09568851441144943, Lr:0.0001\n",
      "Epoch 34, Step: 174, Loss: 0.04027514159679413, Lr:0.0001\n",
      "Epoch 34, Step: 175, Loss: 0.03408875688910484, Lr:0.0001\n",
      "Epoch 34, Step: 176, Loss: 0.0045810239389538765, Lr:0.0001\n",
      "Epoch 34, Step: 177, Loss: 0.03026765212416649, Lr:0.0001\n",
      "Epoch 34, Step: 178, Loss: 0.0053842440247535706, Lr:0.0001\n",
      "Epoch 34, Step: 179, Loss: 0.00038322032196447253, Lr:0.0001\n",
      "Epoch 34, Step: 180, Loss: 0.019323058426380157, Lr:0.0001\n",
      "Epoch 34, Step: 181, Loss: 0.06990814954042435, Lr:0.0001\n",
      "Epoch 34, Step: 182, Loss: 0.01358678750693798, Lr:0.0001\n",
      "Epoch 34, Step: 183, Loss: 0.002419188851490617, Lr:0.0001\n",
      "Epoch 34, Step: 184, Loss: 0.1322675496339798, Lr:0.0001\n",
      "Epoch 34, Step: 185, Loss: 0.003686946351081133, Lr:0.0001\n",
      "Epoch 34, Step: 186, Loss: 0.0009426408796571195, Lr:0.0001\n",
      "Epoch 34, Step: 187, Loss: 0.08926018327474594, Lr:0.0001\n",
      "Epoch 34, Step: 188, Loss: 0.006390298716723919, Lr:0.0001\n",
      "Epoch 34, Step: 189, Loss: 0.0015903831226751208, Lr:0.0001\n",
      "Epoch 34, Step: 190, Loss: 0.005431461147964001, Lr:0.0001\n",
      "Epoch 34, Step: 191, Loss: 0.09159737825393677, Lr:0.0001\n",
      "Epoch 34, Step: 192, Loss: 0.03407924994826317, Lr:0.0001\n",
      "Epoch 34, Step: 193, Loss: 0.17531299591064453, Lr:0.0001\n",
      "Epoch 34, Step: 194, Loss: 0.027490267530083656, Lr:0.0001\n",
      "Epoch 34, Step: 195, Loss: 0.007044372148811817, Lr:0.0001\n",
      "Epoch 34, Step: 196, Loss: 0.010353418998420238, Lr:0.0001\n",
      "Epoch 34, Step: 197, Loss: 0.38260480761528015, Lr:0.0001\n",
      "Epoch 34, Step: 198, Loss: 0.003885395359247923, Lr:0.0001\n",
      "Epoch 34, Step: 199, Loss: 0.013186094351112843, Lr:0.0001\n",
      "Epoch 34, Step: 200, Loss: 0.006699997931718826, Lr:0.0001\n",
      "Epoch 34, Step: 201, Loss: 0.31656017899513245, Lr:0.0001\n",
      "Epoch 34, Step: 202, Loss: 0.0018008793704211712, Lr:0.0001\n",
      "Epoch 34, Step: 203, Loss: 0.0007095703622326255, Lr:0.0001\n",
      "Epoch 34, Step: 204, Loss: 0.01693500019609928, Lr:0.0001\n",
      "Epoch 34, Step: 205, Loss: 0.045592814683914185, Lr:0.0001\n",
      "Epoch 34, Step: 206, Loss: 0.0019407656509429216, Lr:0.0001\n",
      "Epoch 34, Step: 207, Loss: 0.03353392332792282, Lr:0.0001\n",
      "Epoch 34, Step: 208, Loss: 0.13359437882900238, Lr:0.0001\n",
      "Epoch 34, Step: 209, Loss: 0.11136426776647568, Lr:0.0001\n",
      "Epoch 34, Step: 210, Loss: 0.009407088160514832, Lr:0.0001\n",
      "Epoch 34, Step: 211, Loss: 0.038907185196876526, Lr:0.0001\n",
      "Epoch 34, Step: 212, Loss: 0.021504521369934082, Lr:0.0001\n",
      "Epoch 34, Step: 213, Loss: 0.22548316419124603, Lr:0.0001\n",
      "Epoch 34, Step: 214, Loss: 0.010143923573195934, Lr:0.0001\n",
      "Epoch 34, Step: 215, Loss: 0.09260033816099167, Lr:0.0001\n",
      "Epoch 34, Step: 216, Loss: 0.005524948704987764, Lr:0.0001\n",
      "Epoch 34, Step: 217, Loss: 0.08003240823745728, Lr:0.0001\n",
      "Epoch 34, Step: 218, Loss: 0.08274223655462265, Lr:0.0001\n",
      "Epoch 34, Step: 219, Loss: 0.031638193875551224, Lr:0.0001\n",
      "Epoch 34, Step: 220, Loss: 0.0025298004038631916, Lr:0.0001\n",
      "Epoch 34, Step: 221, Loss: 0.02258548140525818, Lr:0.0001\n",
      "Epoch 34, Step: 222, Loss: 0.004428933374583721, Lr:0.0001\n",
      "Epoch 34, Step: 223, Loss: 0.005442858207970858, Lr:0.0001\n",
      "Epoch 34, Step: 224, Loss: 0.017150776460766792, Lr:0.0001\n",
      "Epoch 34, Step: 225, Loss: 0.013548667542636395, Lr:0.0001\n",
      "Epoch 34, Step: 226, Loss: 0.029971620067954063, Lr:0.0001\n",
      "Epoch 34, Step: 227, Loss: 0.03209865465760231, Lr:0.0001\n",
      "Epoch 34, Step: 228, Loss: 0.004321474581956863, Lr:0.0001\n",
      "Epoch 34, Step: 229, Loss: 0.004267352633178234, Lr:0.0001\n",
      "Epoch 34, Step: 230, Loss: 0.0007019961485639215, Lr:0.0001\n",
      "Epoch 34, Step: 231, Loss: 0.04909577593207359, Lr:0.0001\n",
      "Epoch 34, Step: 232, Loss: 0.010105798952281475, Lr:0.0001\n",
      "Epoch 34, Step: 233, Loss: 0.11956507712602615, Lr:0.0001\n",
      "Epoch 34, Step: 234, Loss: 0.011644337326288223, Lr:0.0001\n",
      "Epoch 34, Step: 235, Loss: 0.0062972139567136765, Lr:0.0001\n",
      "Epoch 34, Step: 236, Loss: 0.0029743125196546316, Lr:0.0001\n",
      "Epoch 34, Step: 237, Loss: 0.13032500445842743, Lr:0.0001\n",
      "Epoch 34, Step: 238, Loss: 0.0019904691725969315, Lr:0.0001\n",
      "Epoch 34, Step: 239, Loss: 0.0029523740522563457, Lr:0.0001\n",
      "Epoch 34, Step: 240, Loss: 0.02323048561811447, Lr:0.0001\n",
      "Epoch 34, Step: 241, Loss: 0.14990808069705963, Lr:0.0001\n",
      "Epoch 34, Step: 242, Loss: 0.005616970360279083, Lr:0.0001\n",
      "Epoch 34, Step: 243, Loss: 0.04076988622546196, Lr:0.0001\n",
      "Epoch 34, Step: 244, Loss: 0.15218693017959595, Lr:0.0001\n",
      "Epoch 34, Step: 245, Loss: 0.0020626361947506666, Lr:0.0001\n",
      "Epoch 34, Step: 246, Loss: 0.020818136632442474, Lr:0.0001\n",
      "Epoch 34, Step: 247, Loss: 0.0748220831155777, Lr:0.0001\n",
      "Epoch 34, Step: 248, Loss: 0.3217862844467163, Lr:0.0001\n",
      "Epoch 34, Step: 249, Loss: 0.007653361186385155, Lr:0.0001\n",
      "Epoch 34, Step: 250, Loss: 0.025310762226581573, Lr:0.0001\n",
      "Epoch 34, Step: 251, Loss: 0.01324506290256977, Lr:0.0001\n",
      "Epoch 34, Step: 252, Loss: 0.011047768406569958, Lr:0.0001\n",
      "Epoch 34, Step: 253, Loss: 0.015783315524458885, Lr:0.0001\n",
      "Epoch 34, Step: 254, Loss: 0.045364659279584885, Lr:0.0001\n",
      "Epoch 34, Step: 255, Loss: 0.006233879365026951, Lr:0.0001\n",
      "Epoch 34, Step: 256, Loss: 0.016237441450357437, Lr:0.0001\n",
      "Epoch 34, Step: 257, Loss: 0.1566573977470398, Lr:0.0001\n",
      "Epoch 34, Step: 258, Loss: 0.02165081724524498, Lr:0.0001\n",
      "Epoch 34, Step: 259, Loss: 0.004534743260592222, Lr:0.0001\n",
      "Epoch 34, Step: 260, Loss: 0.00674275029450655, Lr:0.0001\n",
      "Epoch 34, Step: 261, Loss: 0.13526400923728943, Lr:0.0001\n",
      "Epoch 34, Step: 262, Loss: 0.051823973655700684, Lr:0.0001\n",
      "Epoch 34, Step: 263, Loss: 0.020267216488718987, Lr:0.0001\n",
      "Epoch 34, Step: 264, Loss: 0.042346980422735214, Lr:0.0001\n",
      "Epoch 34, Step: 265, Loss: 0.02997048944234848, Lr:0.0001\n",
      "Epoch 34, Step: 266, Loss: 0.03661712631583214, Lr:0.0001\n",
      "Epoch 34, Step: 267, Loss: 0.0038121137768030167, Lr:0.0001\n",
      "Epoch 34, Step: 268, Loss: 0.04352138563990593, Lr:0.0001\n",
      "Epoch 34, Step: 269, Loss: 0.00031023641349747777, Lr:0.0001\n",
      "Epoch 34, Step: 270, Loss: 0.0013145903358235955, Lr:0.0001\n",
      "Epoch 34, Step: 271, Loss: 0.011798265390098095, Lr:0.0001\n",
      "Epoch 34, Step: 272, Loss: 0.022207705304026604, Lr:0.0001\n",
      "Epoch 34, Step: 273, Loss: 0.2855231761932373, Lr:0.0001\n",
      "Epoch 34, Step: 274, Loss: 0.014899174682796001, Lr:0.0001\n",
      "Epoch 34, Step: 275, Loss: 0.17319104075431824, Lr:0.0001\n",
      "Epoch 34, Step: 276, Loss: 0.02474900893867016, Lr:0.0001\n",
      "Epoch 34, Step: 277, Loss: 0.08513976633548737, Lr:0.0001\n",
      "Epoch 34, Step: 278, Loss: 0.0024010709021240473, Lr:0.0001\n",
      "Epoch 34, Step: 279, Loss: 0.004245621617883444, Lr:0.0001\n",
      "Epoch 34, Step: 280, Loss: 0.024698134511709213, Lr:0.0001\n",
      "Epoch 34, Step: 281, Loss: 0.05886980891227722, Lr:0.0001\n",
      "Epoch 34, Step: 282, Loss: 0.028019554913043976, Lr:0.0001\n",
      "Epoch 34, Step: 283, Loss: 0.012929823249578476, Lr:0.0001\n",
      "Epoch 34, Step: 284, Loss: 0.0007140525267459452, Lr:0.0001\n",
      "Epoch 34, Step: 285, Loss: 0.05848648026585579, Lr:0.0001\n",
      "Epoch 34, Step: 286, Loss: 0.02153463289141655, Lr:0.0001\n",
      "Epoch 34, Step: 287, Loss: 0.056933194398880005, Lr:0.0001\n",
      "Epoch 34, Step: 288, Loss: 0.05900242552161217, Lr:0.0001\n",
      "Epoch 34, Step: 289, Loss: 0.0008459976525045931, Lr:0.0001\n",
      "Epoch 34, Step: 290, Loss: 0.19442421197891235, Lr:0.0001\n",
      "Epoch 34, Step: 291, Loss: 0.0022257775999605656, Lr:0.0001\n",
      "Epoch 34, Step: 292, Loss: 0.05707641690969467, Lr:0.0001\n",
      "Epoch 34, Step: 293, Loss: 0.01792924292385578, Lr:0.0001\n",
      "Epoch 34, Step: 294, Loss: 0.0040618483908474445, Lr:0.0001\n",
      "Epoch 34, Step: 295, Loss: 0.1670253723859787, Lr:0.0001\n",
      "Epoch 34, Step: 296, Loss: 0.002519422909244895, Lr:0.0001\n",
      "Epoch 34, Step: 297, Loss: 0.01896664872765541, Lr:0.0001\n",
      "Epoch 34, Step: 298, Loss: 0.0022144117392599583, Lr:0.0001\n",
      "Epoch 34, Step: 299, Loss: 0.018867434933781624, Lr:0.0001\n",
      "Epoch 34, Step: 300, Loss: 0.04210858792066574, Lr:0.0001\n",
      "Epoch 34, Step: 301, Loss: 0.030809495598077774, Lr:0.0001\n",
      "Epoch 34, Step: 302, Loss: 0.016988635063171387, Lr:0.0001\n",
      "Epoch 34, Step: 303, Loss: 0.0013541376683861017, Lr:0.0001\n",
      "Epoch 34, Step: 304, Loss: 0.01040859054774046, Lr:0.0001\n",
      "Epoch 34, Step: 305, Loss: 0.0906352549791336, Lr:0.0001\n",
      "Epoch 34, Step: 306, Loss: 0.015092462301254272, Lr:0.0001\n",
      "Epoch 34, Step: 307, Loss: 0.0041393376886844635, Lr:0.0001\n",
      "Epoch 34, Step: 308, Loss: 0.14406484365463257, Lr:0.0001\n",
      "Epoch 34, Step: 309, Loss: 0.04571076110005379, Lr:0.0001\n",
      "Epoch 34, Step: 310, Loss: 0.03711685910820961, Lr:0.0001\n",
      "Epoch 34, Step: 311, Loss: 0.0935867577791214, Lr:0.0001\n",
      "Epoch 34, Step: 312, Loss: 0.0014406421687453985, Lr:0.0001\n",
      "Epoch 34, Step: 313, Loss: 0.012863877229392529, Lr:0.0001\n",
      "Epoch 34, Step: 314, Loss: 0.005444847512990236, Lr:0.0001\n",
      "Epoch 34, Step: 315, Loss: 0.043162088841199875, Lr:0.0001\n",
      "Epoch 34, Step: 316, Loss: 0.00328462733887136, Lr:0.0001\n",
      "Epoch 34, Step: 317, Loss: 0.007999859750270844, Lr:0.0001\n",
      "Epoch 34, Step: 318, Loss: 0.2391866147518158, Lr:0.0001\n",
      "Epoch 34, Step: 319, Loss: 0.04387877508997917, Lr:0.0001\n",
      "Epoch 34, Step: 320, Loss: 0.0037452096585184336, Lr:0.0001\n",
      "Epoch 34, Step: 321, Loss: 0.3962976336479187, Lr:0.0001\n",
      "Epoch 34, Step: 322, Loss: 0.011527307331562042, Lr:0.0001\n",
      "Epoch 34, Step: 323, Loss: 0.006522041279822588, Lr:0.0001\n",
      "Epoch 34, Step: 324, Loss: 0.26801401376724243, Lr:0.0001\n",
      "Epoch 34, Step: 325, Loss: 0.001842200173996389, Lr:0.0001\n",
      "Epoch 34, Step: 326, Loss: 0.08400926738977432, Lr:0.0001\n",
      "Epoch 34, Step: 327, Loss: 0.09375704079866409, Lr:0.0001\n",
      "Epoch 34, Step: 328, Loss: 0.01745077408850193, Lr:0.0001\n",
      "Epoch 34, Step: 329, Loss: 0.25433725118637085, Lr:0.0001\n",
      "Epoch 34, Step: 330, Loss: 0.013764435425400734, Lr:0.0001\n",
      "Epoch 34, Step: 331, Loss: 0.09487319737672806, Lr:0.0001\n",
      "Epoch 34, Step: 332, Loss: 0.04972078278660774, Lr:0.0001\n",
      "Epoch 34, Step: 333, Loss: 0.014094035141170025, Lr:0.0001\n",
      "Epoch 34, Step: 334, Loss: 0.014375549741089344, Lr:0.0001\n",
      "Epoch 34, Step: 335, Loss: 0.00486158998683095, Lr:0.0001\n",
      "Epoch 34, Step: 336, Loss: 0.05365155637264252, Lr:0.0001\n",
      "Epoch 34, Step: 337, Loss: 0.0005935954977758229, Lr:0.0001\n",
      "Epoch 34, Step: 338, Loss: 0.08849309384822845, Lr:0.0001\n",
      "Epoch 34, Step: 339, Loss: 0.0352301225066185, Lr:0.0001\n",
      "Epoch 34, Step: 340, Loss: 0.03851279243826866, Lr:0.0001\n",
      "Epoch 34, Step: 341, Loss: 0.006496053654700518, Lr:0.0001\n",
      "Epoch 34, Step: 342, Loss: 0.035638950765132904, Lr:0.0001\n",
      "Epoch 34, Step: 343, Loss: 0.08344888687133789, Lr:0.0001\n",
      "Epoch 34, Step: 344, Loss: 0.01116134226322174, Lr:0.0001\n",
      "Epoch 34, Step: 345, Loss: 0.12202338874340057, Lr:0.0001\n",
      "Epoch 34, Step: 346, Loss: 0.036937251687049866, Lr:0.0001\n",
      "Epoch 34, Step: 347, Loss: 0.0457281619310379, Lr:0.0001\n",
      "Epoch 34, Step: 348, Loss: 0.2017873376607895, Lr:0.0001\n",
      "Epoch 34, Step: 349, Loss: 0.11686626821756363, Lr:0.0001\n",
      "Epoch 34, Step: 350, Loss: 0.01591598615050316, Lr:0.0001\n",
      "Epoch 34, Step: 351, Loss: 0.058466631919145584, Lr:0.0001\n",
      "Epoch 34, Step: 352, Loss: 0.08495090156793594, Lr:0.0001\n",
      "Epoch 34, Step: 353, Loss: 0.014409122988581657, Lr:0.0001\n",
      "Epoch 34, Step: 354, Loss: 0.08820990473031998, Lr:0.0001\n",
      "Epoch 34, Step: 355, Loss: 0.018666984513401985, Lr:0.0001\n",
      "Epoch 34, Step: 356, Loss: 0.004829579498618841, Lr:0.0001\n",
      "Epoch 34, Step: 357, Loss: 0.04242083430290222, Lr:0.0001\n",
      "Epoch 34, Step: 358, Loss: 0.0021052027586847544, Lr:0.0001\n",
      "Epoch 34, Step: 359, Loss: 0.17498980462551117, Lr:0.0001\n",
      "Epoch 34, Step: 360, Loss: 0.002849543234333396, Lr:0.0001\n",
      "Epoch 34, Step: 361, Loss: 0.01580960303544998, Lr:0.0001\n",
      "Epoch 34, Step: 362, Loss: 0.0172978937625885, Lr:0.0001\n",
      "Epoch 34, Step: 363, Loss: 0.07064959406852722, Lr:0.0001\n",
      "Epoch 34, Step: 364, Loss: 0.007755003869533539, Lr:0.0001\n",
      "Epoch 34, Step: 365, Loss: 0.005462187808007002, Lr:0.0001\n",
      "Epoch 34, Step: 366, Loss: 0.1553865373134613, Lr:0.0001\n",
      "Epoch 34, Step: 367, Loss: 0.004726599436253309, Lr:0.0001\n",
      "Epoch 34, Step: 368, Loss: 0.1330559402704239, Lr:0.0001\n",
      "Epoch 34, Step: 369, Loss: 0.06523957848548889, Lr:0.0001\n",
      "Epoch 34, Step: 370, Loss: 0.02579832449555397, Lr:0.0001\n",
      "Epoch 34, Step: 371, Loss: 0.007075135596096516, Lr:0.0001\n",
      "Epoch 34, Step: 372, Loss: 0.015983562916517258, Lr:0.0001\n",
      "Epoch 34, Step: 373, Loss: 0.1666492372751236, Lr:0.0001\n",
      "Epoch 34, Step: 374, Loss: 0.008873688988387585, Lr:0.0001\n",
      "Epoch 34, Step: 375, Loss: 0.0005227155634202063, Lr:0.0001\n",
      "Epoch 34, Step: 376, Loss: 0.045122284442186356, Lr:0.0001\n",
      "Epoch 34, Step: 377, Loss: 0.09711884707212448, Lr:0.0001\n",
      "Epoch 34, Step: 378, Loss: 0.04260320961475372, Lr:0.0001\n",
      "Epoch 34, Step: 379, Loss: 0.004098997917026281, Lr:0.0001\n",
      "Epoch 34, Step: 380, Loss: 0.003819085191935301, Lr:0.0001\n",
      "Epoch 34, Step: 381, Loss: 0.0001923548406921327, Lr:0.0001\n",
      "Epoch 34, Step: 382, Loss: 0.009384417906403542, Lr:0.0001\n",
      "Epoch 34, Step: 383, Loss: 0.0027978550642728806, Lr:0.0001\n",
      "Epoch 34, Step: 384, Loss: 0.03756559267640114, Lr:0.0001\n",
      "Epoch 34, Step: 385, Loss: 0.13315896689891815, Lr:0.0001\n",
      "Epoch 34, Step: 386, Loss: 0.011875515803694725, Lr:0.0001\n",
      "Epoch 34, Step: 387, Loss: 0.00571047468110919, Lr:0.0001\n",
      "Epoch 34, Step: 388, Loss: 0.027343884110450745, Lr:0.0001\n",
      "Epoch 34, Step: 389, Loss: 0.030363034456968307, Lr:0.0001\n",
      "Epoch 34, Step: 390, Loss: 0.008479627780616283, Lr:0.0001\n",
      "Epoch 34, Step: 391, Loss: 0.15289640426635742, Lr:0.0001\n",
      "Epoch 34, Step: 392, Loss: 0.003030344843864441, Lr:0.0001\n",
      "Epoch 34, Step: 393, Loss: 0.00571341160684824, Lr:0.0001\n",
      "Epoch 34, Step: 394, Loss: 0.08874931186437607, Lr:0.0001\n",
      "Epoch 34, Step: 395, Loss: 0.008471940644085407, Lr:0.0001\n",
      "Epoch 34, Step: 396, Loss: 0.0008947813184931874, Lr:0.0001\n",
      "Epoch 34, Step: 397, Loss: 0.03104698471724987, Lr:0.0001\n",
      "Epoch 34, Step: 398, Loss: 0.0008711973787285388, Lr:0.0001\n",
      "Epoch 34, Step: 399, Loss: 0.020895080640912056, Lr:0.0001\n",
      "Epoch 34, Step: 400, Loss: 0.0160830058157444, Lr:0.0001\n",
      "Epoch 34, Step: 401, Loss: 0.003635082859545946, Lr:0.0001\n",
      "Epoch 34, Step: 402, Loss: 0.09194691479206085, Lr:0.0001\n",
      "Epoch 34, Step: 403, Loss: 0.009366213344037533, Lr:0.0001\n",
      "Epoch 34, Step: 404, Loss: 0.0035406877286732197, Lr:0.0001\n",
      "Epoch 34, Step: 405, Loss: 0.007975148968398571, Lr:0.0001\n",
      "Epoch 34, Step: 406, Loss: 0.013491271995007992, Lr:0.0001\n",
      "Epoch 34, Step: 407, Loss: 0.004664502572268248, Lr:0.0001\n",
      "Epoch 34, Step: 408, Loss: 0.021710801869630814, Lr:0.0001\n",
      "Epoch 34, Step: 409, Loss: 0.11038455367088318, Lr:0.0001\n",
      "Epoch 34, Step: 410, Loss: 0.08271050453186035, Lr:0.0001\n",
      "Epoch 34, Step: 411, Loss: 0.030812721699476242, Lr:0.0001\n",
      "Epoch 34, Step: 412, Loss: 0.07451938092708588, Lr:0.0001\n",
      "Epoch 34, Step: 413, Loss: 0.2269616574048996, Lr:0.0001\n",
      "Epoch 34, Step: 414, Loss: 0.0016089126002043486, Lr:0.0001\n",
      "Epoch 34, Step: 415, Loss: 0.033385515213012695, Lr:0.0001\n",
      "Epoch 34, Step: 416, Loss: 0.005064504686743021, Lr:0.0001\n",
      "Epoch 34, Step: 417, Loss: 0.0008387475390918553, Lr:0.0001\n",
      "Epoch 34, Step: 418, Loss: 0.039015017449855804, Lr:0.0001\n",
      "Epoch 34, Step: 419, Loss: 0.07572319358587265, Lr:0.0001\n",
      "Epoch 34, Step: 420, Loss: 0.016968656331300735, Lr:0.0001\n",
      "Epoch 34, Step: 421, Loss: 0.05686326324939728, Lr:0.0001\n",
      "Epoch 34, Step: 422, Loss: 0.02763255685567856, Lr:0.0001\n",
      "Epoch 34, Step: 423, Loss: 0.03780634328722954, Lr:0.0001\n",
      "Epoch 34, Step: 424, Loss: 0.060559485107660294, Lr:0.0001\n",
      "Epoch 34, Step: 425, Loss: 0.038250632584095, Lr:0.0001\n",
      "Epoch 34, Step: 426, Loss: 0.02258194610476494, Lr:0.0001\n",
      "Epoch 34, Step: 427, Loss: 0.08599895983934402, Lr:0.0001\n",
      "Epoch 34, Step: 428, Loss: 0.0018489407375454903, Lr:0.0001\n",
      "Epoch 34, Step: 429, Loss: 0.008349129930138588, Lr:0.0001\n",
      "Epoch 34, Step: 430, Loss: 0.004513981752097607, Lr:0.0001\n",
      "Epoch 34, Step: 431, Loss: 0.01238078624010086, Lr:0.0001\n",
      "Epoch 34, Step: 432, Loss: 0.008395986631512642, Lr:0.0001\n",
      "Epoch 34, Step: 433, Loss: 0.09893890470266342, Lr:0.0001\n",
      "Epoch 34, Step: 434, Loss: 0.012233516201376915, Lr:0.0001\n",
      "Epoch 34, Step: 435, Loss: 0.0014739477774128318, Lr:0.0001\n",
      "Epoch 34, Step: 436, Loss: 0.12185443192720413, Lr:0.0001\n",
      "Epoch 34, Step: 437, Loss: 0.08974026888608932, Lr:0.0001\n",
      "Epoch 34, Step: 438, Loss: 0.06959804892539978, Lr:0.0001\n",
      "Epoch 34, Step: 439, Loss: 0.06678640842437744, Lr:0.0001\n",
      "Epoch 34, Step: 440, Loss: 0.1189708411693573, Lr:0.0001\n",
      "Epoch 34, Step: 441, Loss: 0.0570412240922451, Lr:0.0001\n",
      "Epoch 34, Step: 442, Loss: 0.001057681511156261, Lr:0.0001\n",
      "Epoch 34, Step: 443, Loss: 0.000772525614593178, Lr:0.0001\n",
      "Epoch 34, Step: 444, Loss: 0.016496239230036736, Lr:0.0001\n",
      "Epoch 34, Step: 445, Loss: 0.06897476315498352, Lr:0.0001\n",
      "Epoch 34, Step: 446, Loss: 0.0033412850461900234, Lr:0.0001\n",
      "Epoch 34, Step: 447, Loss: 0.11635679751634598, Lr:0.0001\n",
      "Epoch 34, Step: 448, Loss: 0.0008670166716910899, Lr:0.0001\n",
      "Epoch 34, Step: 449, Loss: 0.037562496960163116, Lr:0.0001\n",
      "Epoch 34, Step: 450, Loss: 0.11114330589771271, Lr:0.0001\n",
      "Epoch 34, Step: 451, Loss: 0.0011549968039616942, Lr:0.0001\n",
      "Epoch 34, Step: 452, Loss: 0.11672328412532806, Lr:0.0001\n",
      "Epoch 34, Step: 453, Loss: 0.0187015850096941, Lr:0.0001\n",
      "Epoch 34, Step: 454, Loss: 0.0002099001285387203, Lr:0.0001\n",
      "Epoch 34, Step: 455, Loss: 0.0006443821475841105, Lr:0.0001\n",
      "Epoch 34, Step: 456, Loss: 0.01066848449409008, Lr:0.0001\n",
      "Epoch 34, Step: 457, Loss: 0.00032571254996582866, Lr:0.0001\n",
      "Epoch 34, Step: 458, Loss: 0.09937621653079987, Lr:0.0001\n",
      "Epoch 34, Step: 459, Loss: 0.0866614282131195, Lr:0.0001\n",
      "Epoch 34, Step: 460, Loss: 0.006977821234613657, Lr:0.0001\n",
      "Epoch 34, Step: 461, Loss: 0.017173487693071365, Lr:0.0001\n",
      "Epoch 34, Step: 462, Loss: 0.10753131657838821, Lr:0.0001\n",
      "Epoch 34, Step: 463, Loss: 0.3187454342842102, Lr:0.0001\n",
      "Epoch 34, Step: 464, Loss: 0.01030043326318264, Lr:0.0001\n",
      "Epoch 34, Step: 465, Loss: 0.039860811084508896, Lr:0.0001\n",
      "Epoch 34, Step: 466, Loss: 0.025839297100901604, Lr:0.0001\n",
      "Epoch 34, Step: 467, Loss: 0.08074603229761124, Lr:0.0001\n",
      "Epoch 34, Step: 468, Loss: 0.08626165986061096, Lr:0.0001\n",
      "Epoch 34, Step: 469, Loss: 0.09934913367033005, Lr:0.0001\n",
      "Epoch 34, Step: 470, Loss: 0.03708047419786453, Lr:0.0001\n",
      "Epoch 34, Step: 471, Loss: 0.0008560153655707836, Lr:0.0001\n",
      "Epoch 34, Step: 472, Loss: 0.0009547934168949723, Lr:0.0001\n",
      "Epoch 34, Step: 473, Loss: 0.004451551008969545, Lr:0.0001\n",
      "Epoch 34, Step: 474, Loss: 0.0019013970158994198, Lr:0.0001\n",
      "Epoch 34, Step: 475, Loss: 0.157274067401886, Lr:0.0001\n",
      "Epoch 34, Step: 476, Loss: 0.1643906980752945, Lr:0.0001\n",
      "Epoch 34, Step: 477, Loss: 0.1714327037334442, Lr:0.0001\n",
      "Epoch 34, Step: 478, Loss: 0.009123976342380047, Lr:0.0001\n",
      "Epoch 34, Step: 479, Loss: 0.03523266687989235, Lr:0.0001\n",
      "Epoch 34, Step: 480, Loss: 0.20993371307849884, Lr:0.0001\n",
      "Epoch 34, Step: 481, Loss: 0.034133922308683395, Lr:0.0001\n",
      "Epoch 34, Step: 482, Loss: 0.09963933378458023, Lr:0.0001\n",
      "Epoch 34, Step: 483, Loss: 0.005836395546793938, Lr:0.0001\n",
      "Epoch 34, Step: 484, Loss: 0.031164739280939102, Lr:0.0001\n",
      "Epoch 34, Step: 485, Loss: 0.017679739743471146, Lr:0.0001\n",
      "Epoch 34, Step: 486, Loss: 0.0034097814932465553, Lr:0.0001\n",
      "Epoch 34, Step: 487, Loss: 0.042009387165308, Lr:0.0001\n",
      "Epoch 34, Step: 488, Loss: 0.0034497310407459736, Lr:0.0001\n",
      "Epoch 34, Step: 489, Loss: 0.05452636629343033, Lr:0.0001\n",
      "Epoch 34, Step: 490, Loss: 0.007192013319581747, Lr:0.0001\n",
      "Epoch 34, Step: 491, Loss: 0.004359803628176451, Lr:0.0001\n",
      "Epoch 34, Step: 492, Loss: 0.0851454809308052, Lr:0.0001\n",
      "Epoch 34, Step: 493, Loss: 0.0009272959432564676, Lr:0.0001\n",
      "Epoch 34, Step: 494, Loss: 0.03530503064393997, Lr:0.0001\n",
      "Epoch 34, Step: 495, Loss: 0.020934972912073135, Lr:0.0001\n",
      "Epoch 34, Step: 496, Loss: 0.09457875043153763, Lr:0.0001\n",
      "Epoch 34, Step: 497, Loss: 0.01016068086028099, Lr:0.0001\n",
      "Epoch 34, Step: 498, Loss: 0.005633153021335602, Lr:0.0001\n",
      "Epoch 34, Step: 499, Loss: 0.006682076957076788, Lr:0.0001\n",
      "Epoch 34, Step: 500, Loss: 0.0037722487468272448, Lr:0.0001\n",
      "Epoch 34, Step: 501, Loss: 0.005383090581744909, Lr:0.0001\n",
      "Epoch 34, Step: 502, Loss: 0.002437861170619726, Lr:0.0001\n",
      "Epoch 34, Step: 503, Loss: 0.0022725602611899376, Lr:0.0001\n",
      "Epoch 34, Step: 504, Loss: 0.0066520837135612965, Lr:0.0001\n",
      "Epoch 34, Step: 505, Loss: 0.04145609587430954, Lr:0.0001\n",
      "Epoch 34, Step: 506, Loss: 0.0012170362751930952, Lr:0.0001\n",
      "Epoch 34, Step: 507, Loss: 0.06359811872243881, Lr:0.0001\n",
      "Epoch 34, Step: 508, Loss: 0.002165435580536723, Lr:0.0001\n",
      "Epoch 34, Step: 509, Loss: 0.020116837695240974, Lr:0.0001\n",
      "Epoch 34, Step: 510, Loss: 0.029576826840639114, Lr:0.0001\n",
      "Epoch 34, Step: 511, Loss: 0.00025396919227205217, Lr:0.0001\n",
      "Epoch 34, Step: 512, Loss: 0.012752659618854523, Lr:0.0001\n",
      "Epoch 34, Step: 513, Loss: 0.002043394837528467, Lr:0.0001\n",
      "Epoch 34, Step: 514, Loss: 0.004529185127466917, Lr:0.0001\n",
      "Epoch 34, Step: 515, Loss: 0.004421933554112911, Lr:0.0001\n",
      "Epoch 34, Step: 516, Loss: 0.020056741312146187, Lr:0.0001\n",
      "Epoch 34, Step: 517, Loss: 0.1015377789735794, Lr:0.0001\n",
      "Epoch 34, Step: 518, Loss: 0.0016941404901444912, Lr:0.0001\n",
      "Epoch 34, Step: 519, Loss: 0.0007721403380855918, Lr:0.0001\n",
      "Epoch 34, Step: 520, Loss: 0.0622665211558342, Lr:0.0001\n",
      "Epoch 34, Step: 521, Loss: 0.0913955494761467, Lr:0.0001\n",
      "Epoch 34, Step: 522, Loss: 0.03397541120648384, Lr:0.0001\n",
      "Epoch 34, Step: 523, Loss: 0.028576640412211418, Lr:0.0001\n",
      "Epoch 34, Step: 524, Loss: 0.00781932007521391, Lr:0.0001\n",
      "Epoch 34, Step: 525, Loss: 0.028612293303012848, Lr:0.0001\n",
      "Epoch 34, Step: 526, Loss: 0.07831831276416779, Lr:0.0001\n",
      "Epoch 34, Step: 527, Loss: 0.02119574509561062, Lr:0.0001\n",
      "Epoch 34, Step: 528, Loss: 0.003342365613207221, Lr:0.0001\n",
      "Epoch 34, Step: 529, Loss: 0.0395960733294487, Lr:0.0001\n",
      "Epoch 34, Step: 530, Loss: 0.04126305133104324, Lr:0.0001\n",
      "Epoch 34, Step: 531, Loss: 0.045825086534023285, Lr:0.0001\n",
      "Epoch 34, Step: 532, Loss: 0.03100913017988205, Lr:0.0001\n",
      "Epoch 34, Step: 533, Loss: 0.008412841707468033, Lr:0.0001\n",
      "Epoch 34, Step: 534, Loss: 0.027197569608688354, Lr:0.0001\n",
      "Epoch 34, Step: 535, Loss: 0.001500327023677528, Lr:0.0001\n",
      "Epoch 34, Step: 536, Loss: 0.08149412274360657, Lr:0.0001\n",
      "Epoch 34, Step: 537, Loss: 0.0014957657549530268, Lr:0.0001\n",
      "Epoch 34, Step: 538, Loss: 0.0027701726648956537, Lr:0.0001\n",
      "Epoch 34, Step: 539, Loss: 0.06937841325998306, Lr:0.0001\n",
      "Epoch 34, Step: 540, Loss: 0.0003777091042138636, Lr:0.0001\n",
      "Epoch 34, Step: 541, Loss: 0.03873293846845627, Lr:0.0001\n",
      "Epoch 34, Step: 542, Loss: 0.01641191355884075, Lr:0.0001\n",
      "Epoch 34, Step: 543, Loss: 0.09475114196538925, Lr:0.0001\n",
      "Epoch 34, Step: 544, Loss: 0.06329493224620819, Lr:0.0001\n",
      "Epoch 34, Step: 545, Loss: 0.09495453536510468, Lr:0.0001\n",
      "Epoch 34, Step: 546, Loss: 0.000799837289378047, Lr:0.0001\n",
      "Epoch 34, Step: 547, Loss: 0.004469862207770348, Lr:0.0001\n",
      "Epoch 34, Step: 548, Loss: 0.2690410614013672, Lr:0.0001\n",
      "Epoch 34, Step: 549, Loss: 0.013255947269499302, Lr:0.0001\n",
      "Epoch 34, Step: 550, Loss: 0.007139286492019892, Lr:0.0001\n",
      "Epoch 34, Step: 551, Loss: 0.041834402829408646, Lr:0.0001\n",
      "Epoch 34, Step: 552, Loss: 0.007120735943317413, Lr:0.0001\n",
      "Epoch 34, Step: 553, Loss: 0.0034376445692032576, Lr:0.0001\n",
      "Epoch 34, Step: 554, Loss: 0.025939373299479485, Lr:0.0001\n",
      "Epoch 34, Step: 555, Loss: 0.012550672516226768, Lr:0.0001\n",
      "Epoch 34, Step: 556, Loss: 0.0021477648988366127, Lr:0.0001\n",
      "Epoch 34, Step: 557, Loss: 0.012311648577451706, Lr:0.0001\n",
      "Epoch 34, Step: 558, Loss: 0.009300949983298779, Lr:0.0001\n",
      "Epoch 34, Step: 559, Loss: 0.0031961644999682903, Lr:0.0001\n",
      "Epoch 34, Step: 560, Loss: 0.008453143760561943, Lr:0.0001\n",
      "Epoch 34, Step: 561, Loss: 0.002724992111325264, Lr:0.0001\n",
      "Epoch 34, Step: 562, Loss: 0.008640497922897339, Lr:0.0001\n",
      "Epoch 34, Step: 563, Loss: 0.13562652468681335, Lr:0.0001\n",
      "Epoch 34, Step: 564, Loss: 0.06925880908966064, Lr:0.0001\n",
      "Epoch 34, Step: 565, Loss: 0.009719761088490486, Lr:0.0001\n",
      "Epoch 34, Step: 566, Loss: 0.1819678097963333, Lr:0.0001\n",
      "Epoch 34, Step: 567, Loss: 0.07245729863643646, Lr:0.0001\n",
      "Epoch 34, Step: 568, Loss: 0.06173724681138992, Lr:0.0001\n",
      "Epoch 34, Step: 569, Loss: 0.01273995079100132, Lr:0.0001\n",
      "Epoch 34, Step: 570, Loss: 0.03281424567103386, Lr:0.0001\n",
      "Epoch 34, Step: 571, Loss: 0.05729912593960762, Lr:0.0001\n",
      "Epoch 34, Step: 572, Loss: 0.002377699129283428, Lr:0.0001\n",
      "Epoch 34, Step: 573, Loss: 0.057086147367954254, Lr:0.0001\n",
      "Epoch 34, Step: 574, Loss: 0.00507743563503027, Lr:0.0001\n",
      "Epoch 34, Step: 575, Loss: 0.031451206654310226, Lr:0.0001\n",
      "Epoch 34, Step: 576, Loss: 0.01404421217739582, Lr:0.0001\n",
      "Epoch 34, Step: 577, Loss: 0.00017232225218322128, Lr:0.0001\n",
      "Epoch 34, Step: 578, Loss: 0.02563585713505745, Lr:0.0001\n",
      "Epoch 34, Step: 579, Loss: 0.008468277752399445, Lr:0.0001\n",
      "Epoch 34, Step: 580, Loss: 0.002322880085557699, Lr:0.0001\n",
      "Epoch 34, Step: 581, Loss: 0.0004900111816823483, Lr:0.0001\n",
      "Epoch 34, Step: 582, Loss: 0.041227493435144424, Lr:0.0001\n",
      "Epoch 34, Step: 583, Loss: 0.34326601028442383, Lr:0.0001\n",
      "Epoch 34, Step: 584, Loss: 0.00018675382307264954, Lr:0.0001\n",
      "Epoch 34, Step: 585, Loss: 0.0005580309662036598, Lr:0.0001\n",
      "Epoch 34, Step: 586, Loss: 0.002330071059986949, Lr:0.0001\n",
      "Epoch 34, Step: 587, Loss: 0.004400245845317841, Lr:0.0001\n",
      "Epoch 34, Step: 588, Loss: 0.08728880435228348, Lr:0.0001\n",
      "Epoch 34, Step: 589, Loss: 0.0022651939652860165, Lr:0.0001\n",
      "Epoch 34, Step: 590, Loss: 0.0008331072749570012, Lr:0.0001\n",
      "Epoch 34, Step: 591, Loss: 0.17319758236408234, Lr:0.0001\n",
      "Epoch 34, Step: 592, Loss: 0.1470809131860733, Lr:0.0001\n",
      "Epoch 34, Step: 593, Loss: 0.0011221887543797493, Lr:0.0001\n",
      "Epoch 34, Step: 594, Loss: 0.09523364901542664, Lr:0.0001\n",
      "Epoch 34, Step: 595, Loss: 0.0024275071918964386, Lr:0.0001\n",
      "Epoch 34, Step: 596, Loss: 0.00030086698825471103, Lr:0.0001\n",
      "Epoch 34, Step: 597, Loss: 0.11215594410896301, Lr:0.0001\n",
      "Epoch 34, Step: 598, Loss: 0.0030273792799562216, Lr:0.0001\n",
      "Epoch 34, Step: 599, Loss: 0.4185844957828522, Lr:0.0001\n",
      "Epoch 34, Step: 600, Loss: 0.04419296234846115, Lr:0.0001\n",
      "Epoch 34, Step: 601, Loss: 0.1274966299533844, Lr:0.0001\n",
      "Epoch 34, Step: 602, Loss: 0.0005675920401699841, Lr:0.0001\n",
      "Epoch 34, Step: 603, Loss: 0.03634791821241379, Lr:0.0001\n",
      "Epoch 34, Step: 604, Loss: 0.12752336263656616, Lr:0.0001\n",
      "Epoch 34, Step: 605, Loss: 0.01976430043578148, Lr:0.0001\n",
      "Epoch 34, Step: 606, Loss: 0.004329949617385864, Lr:0.0001\n",
      "Epoch 34, Step: 607, Loss: 0.18392300605773926, Lr:0.0001\n",
      "Epoch 34, Step: 608, Loss: 0.0007402540650218725, Lr:0.0001\n",
      "Epoch 34, Step: 609, Loss: 0.016434352844953537, Lr:0.0001\n",
      "Epoch 34, Step: 610, Loss: 0.10390960425138474, Lr:0.0001\n",
      "Epoch 34, Step: 611, Loss: 0.0009722962277010083, Lr:0.0001\n",
      "Epoch 34, Step: 612, Loss: 0.023303208872675896, Lr:0.0001\n",
      "Epoch 34, Step: 613, Loss: 0.08432158082723618, Lr:0.0001\n",
      "Epoch 34, Step: 614, Loss: 0.0036997690331190825, Lr:0.0001\n",
      "Epoch 34, Step: 615, Loss: 0.05381440371274948, Lr:0.0001\n",
      "Epoch 34, Step: 616, Loss: 0.007667604833841324, Lr:0.0001\n",
      "Epoch 34, Step: 617, Loss: 0.029792681336402893, Lr:0.0001\n",
      "Epoch 34, Step: 618, Loss: 0.0006955703720450401, Lr:0.0001\n",
      "Epoch 34, Step: 619, Loss: 0.008344904519617558, Lr:0.0001\n",
      "Epoch 34, Step: 620, Loss: 0.04430162534117699, Lr:0.0001\n",
      "Epoch 34, Step: 621, Loss: 0.05782631039619446, Lr:0.0001\n",
      "Epoch 34, Step: 622, Loss: 0.006303843110799789, Lr:0.0001\n",
      "Epoch 34, Step: 623, Loss: 0.010579346679151058, Lr:0.0001\n",
      "Epoch 34, Step: 624, Loss: 0.35144922137260437, Lr:0.0001\n",
      "Epoch 34, Step: 625, Loss: 0.0010132587049156427, Lr:0.0001\n",
      "Epoch 34, Step: 626, Loss: 0.008837735280394554, Lr:0.0001\n",
      "Epoch 34, Step: 627, Loss: 0.023870224133133888, Lr:0.0001\n",
      "Epoch 34, Step: 628, Loss: 0.10693050920963287, Lr:0.0001\n",
      "Epoch 34, Step: 629, Loss: 0.0014992785872891545, Lr:0.0001\n",
      "Epoch 34, Step: 630, Loss: 0.07818572968244553, Lr:0.0001\n",
      "Epoch 34, Step: 631, Loss: 0.04274312034249306, Lr:0.0001\n",
      "Epoch 34, Step: 632, Loss: 0.01810874044895172, Lr:0.0001\n",
      "Epoch 34, Step: 633, Loss: 0.005760020576417446, Lr:0.0001\n",
      "Epoch 34, Step: 634, Loss: 0.026369864121079445, Lr:0.0001\n",
      "Epoch 34, Step: 635, Loss: 0.010877249762415886, Lr:0.0001\n",
      "Epoch 34, Step: 636, Loss: 0.12196388840675354, Lr:0.0001\n",
      "Epoch 34, Step: 637, Loss: 0.02010587975382805, Lr:0.0001\n",
      "Epoch 34, Step: 638, Loss: 0.02668214961886406, Lr:0.0001\n",
      "Epoch 34, Step: 639, Loss: 0.11079908162355423, Lr:0.0001\n",
      "Epoch 34, Step: 640, Loss: 0.011532934382557869, Lr:0.0001\n",
      "Epoch 34, Step: 641, Loss: 0.08372357487678528, Lr:0.0001\n",
      "Epoch 34, Step: 642, Loss: 0.001616419292986393, Lr:0.0001\n",
      "Epoch 34, Step: 643, Loss: 0.04183238372206688, Lr:0.0001\n",
      "Epoch 34, Step: 644, Loss: 0.049062810838222504, Lr:0.0001\n",
      "Epoch 34, Step: 645, Loss: 0.20424209535121918, Lr:0.0001\n",
      "Epoch 34, Step: 646, Loss: 0.0027505604084581137, Lr:0.0001\n",
      "Epoch 34, Step: 647, Loss: 0.10042907297611237, Lr:0.0001\n",
      "Epoch 34, Step: 648, Loss: 0.0016864317003637552, Lr:0.0001\n",
      "Epoch 34, Step: 649, Loss: 0.3513396978378296, Lr:0.0001\n",
      "Epoch 34, Step: 650, Loss: 0.017357198521494865, Lr:0.0001\n",
      "Epoch 34, Step: 651, Loss: 0.011242530308663845, Lr:0.0001\n",
      "Epoch 34, Step: 652, Loss: 0.004186919424682856, Lr:0.0001\n",
      "Epoch 34, Step: 653, Loss: 0.0001799999736249447, Lr:0.0001\n",
      "Epoch 34, Step: 654, Loss: 0.010329718701541424, Lr:0.0001\n",
      "Epoch 34, Step: 655, Loss: 0.017431901767849922, Lr:0.0001\n",
      "Epoch 34, Step: 656, Loss: 0.13430415093898773, Lr:0.0001\n",
      "Epoch 34, Step: 657, Loss: 0.02024688385426998, Lr:0.0001\n",
      "Epoch 34, Step: 658, Loss: 0.029214290902018547, Lr:0.0001\n",
      "Epoch 34, Step: 659, Loss: 0.0037364899180829525, Lr:0.0001\n",
      "Epoch 34, Step: 660, Loss: 0.2877320349216461, Lr:0.0001\n",
      "Epoch 34, Step: 661, Loss: 0.13499948382377625, Lr:0.0001\n",
      "Epoch 34, Step: 662, Loss: 0.015406470745801926, Lr:0.0001\n",
      "Epoch 34, Step: 663, Loss: 0.08250419795513153, Lr:0.0001\n",
      "Epoch 34, Step: 664, Loss: 0.013959393836557865, Lr:0.0001\n",
      "Epoch 34, Step: 665, Loss: 0.1933269202709198, Lr:0.0001\n",
      "Epoch 34, Step: 666, Loss: 0.05151300132274628, Lr:0.0001\n",
      "Epoch 34, Step: 667, Loss: 0.002589426701888442, Lr:0.0001\n",
      "Epoch 34, Step: 668, Loss: 0.019457891583442688, Lr:0.0001\n",
      "Epoch 34, Step: 669, Loss: 0.18591956794261932, Lr:0.0001\n",
      "Epoch 34, Step: 670, Loss: 0.024533776566386223, Lr:0.0001\n",
      "Epoch 34, Step: 671, Loss: 0.005081766285002232, Lr:0.0001\n",
      "Epoch 34, Step: 672, Loss: 0.003896923502907157, Lr:0.0001\n",
      "Epoch 34, Step: 673, Loss: 0.10693728178739548, Lr:0.0001\n",
      "Epoch 34, Step: 674, Loss: 0.01600881852209568, Lr:0.0001\n",
      "Epoch 34, Step: 675, Loss: 0.0056411805562675, Lr:0.0001\n",
      "Epoch 34, Step: 676, Loss: 0.05735998600721359, Lr:0.0001\n",
      "Epoch 34, Step: 677, Loss: 0.00691536720842123, Lr:0.0001\n",
      "Epoch 34, Step: 678, Loss: 0.03336859494447708, Lr:0.0001\n",
      "Epoch 34, Step: 679, Loss: 0.002214648760855198, Lr:0.0001\n",
      "Epoch 34, Step: 680, Loss: 0.3188855051994324, Lr:0.0001\n",
      "Epoch 34, Step: 681, Loss: 0.013067029416561127, Lr:0.0001\n",
      "Epoch 34, Step: 682, Loss: 0.0007465356029570103, Lr:0.0001\n",
      "Epoch 34, Step: 683, Loss: 0.002564370399340987, Lr:0.0001\n",
      "Epoch 34, Step: 684, Loss: 0.02982999011874199, Lr:0.0001\n",
      "Epoch 34, Step: 685, Loss: 0.033314526081085205, Lr:0.0001\n",
      "Epoch 34, Step: 686, Loss: 0.02333611436188221, Lr:0.0001\n",
      "Epoch 34, Step: 687, Loss: 0.0017396677285432816, Lr:0.0001\n",
      "Epoch 34, Step: 688, Loss: 0.04704364389181137, Lr:0.0001\n",
      "Epoch 34, Step: 689, Loss: 0.029301036149263382, Lr:0.0001\n",
      "Epoch 34, Step: 690, Loss: 0.0036465039011090994, Lr:0.0001\n",
      "Epoch 34, Step: 691, Loss: 0.15359920263290405, Lr:0.0001\n",
      "Epoch 34, Step: 692, Loss: 0.07470884174108505, Lr:0.0001\n",
      "Epoch 34, Step: 693, Loss: 0.010161222890019417, Lr:0.0001\n",
      "Epoch 34, Step: 694, Loss: 0.012861591763794422, Lr:0.0001\n",
      "Epoch 34, Step: 695, Loss: 0.09041699767112732, Lr:0.0001\n",
      "Epoch 34, Step: 696, Loss: 0.005740494932979345, Lr:0.0001\n",
      "Epoch 34, Step: 697, Loss: 0.0012419290142133832, Lr:0.0001\n",
      "Epoch 34, Step: 698, Loss: 0.2218756228685379, Lr:0.0001\n",
      "Epoch 34, Step: 699, Loss: 0.07359425723552704, Lr:0.0001\n",
      "Epoch 34, Step: 700, Loss: 0.13492374122142792, Lr:0.0001\n",
      "Epoch 34, Step: 701, Loss: 0.034185051918029785, Lr:0.0001\n",
      "Epoch 34, Step: 702, Loss: 0.056197717785835266, Lr:0.0001\n",
      "Epoch 34, Step: 703, Loss: 0.0016768593341112137, Lr:0.0001\n",
      "Epoch 34, Step: 704, Loss: 0.010021030902862549, Lr:0.0001\n",
      "Epoch 34, Step: 705, Loss: 0.004439725540578365, Lr:0.0001\n",
      "Epoch 34, Step: 706, Loss: 0.00028964533703401685, Lr:0.0001\n",
      "Epoch 34, Step: 707, Loss: 0.1407495141029358, Lr:0.0001\n",
      "Epoch 34, Step: 708, Loss: 0.020161939784884453, Lr:0.0001\n",
      "Epoch 34, Step: 709, Loss: 0.0015705671394243836, Lr:0.0001\n",
      "Epoch 34, Step: 710, Loss: 0.020152786746621132, Lr:0.0001\n",
      "Epoch 34, Step: 711, Loss: 0.02151838317513466, Lr:0.0001\n",
      "Epoch 34, Step: 712, Loss: 0.01654507964849472, Lr:0.0001\n",
      "Epoch 34, Step: 713, Loss: 0.0034640529192984104, Lr:0.0001\n",
      "Epoch 34, Step: 714, Loss: 0.037634510546922684, Lr:0.0001\n",
      "Epoch 34, Step: 715, Loss: 0.17618653178215027, Lr:0.0001\n",
      "Epoch 34, Step: 716, Loss: 0.013837083242833614, Lr:0.0001\n",
      "Epoch 34, Step: 717, Loss: 0.005566195584833622, Lr:0.0001\n",
      "Epoch 34, Step: 718, Loss: 0.025600261986255646, Lr:0.0001\n",
      "Epoch 34, Step: 719, Loss: 0.0359477698802948, Lr:0.0001\n",
      "Epoch 34, Step: 720, Loss: 0.05520674213767052, Lr:0.0001\n",
      "Epoch 34, Step: 721, Loss: 0.3529699444770813, Lr:0.0001\n",
      "Epoch 34, Step: 722, Loss: 0.01343066617846489, Lr:0.0001\n",
      "Epoch 34, Step: 723, Loss: 0.013282444328069687, Lr:0.0001\n",
      "Epoch 34, Step: 724, Loss: 0.05407635122537613, Lr:0.0001\n",
      "Epoch 34, Step: 725, Loss: 0.0027083312161266804, Lr:0.0001\n",
      "Epoch 34, Step: 726, Loss: 0.12014977633953094, Lr:0.0001\n",
      "Epoch 34, Step: 727, Loss: 0.12430635094642639, Lr:0.0001\n",
      "Epoch 34, Step: 728, Loss: 0.051076944917440414, Lr:0.0001\n",
      "Epoch 34, Step: 729, Loss: 0.0017143820878118277, Lr:0.0001\n",
      "Epoch 34, Step: 730, Loss: 0.0034080056939274073, Lr:0.0001\n",
      "Epoch 34, Step: 731, Loss: 0.019596947357058525, Lr:0.0001\n",
      "Epoch 34, Step: 732, Loss: 0.11756226420402527, Lr:0.0001\n",
      "Epoch 34, Step: 733, Loss: 0.05216251313686371, Lr:0.0001\n",
      "Epoch 34, Step: 734, Loss: 0.04819585010409355, Lr:0.0001\n",
      "Epoch 34, Step: 735, Loss: 0.006460546050220728, Lr:0.0001\n",
      "Epoch 34, Step: 736, Loss: 0.04029962047934532, Lr:0.0001\n",
      "Epoch 34, Step: 737, Loss: 0.02966359816491604, Lr:0.0001\n",
      "Epoch 34, Step: 738, Loss: 0.0935898944735527, Lr:0.0001\n",
      "Epoch 34, Step: 739, Loss: 0.011634552851319313, Lr:0.0001\n",
      "Epoch 34, Step: 740, Loss: 0.008767349645495415, Lr:0.0001\n",
      "Epoch 34, Step: 741, Loss: 0.03353649750351906, Lr:0.0001\n",
      "Epoch 34, Step: 742, Loss: 0.009527099318802357, Lr:0.0001\n",
      "Epoch 34, Step: 743, Loss: 0.23792089521884918, Lr:0.0001\n",
      "Epoch 34, Step: 744, Loss: 0.006094363052397966, Lr:0.0001\n",
      "Epoch 34, Step: 745, Loss: 0.22813311219215393, Lr:0.0001\n",
      "Epoch 34, Step: 746, Loss: 0.09751294553279877, Lr:0.0001\n",
      "Epoch 34, Step: 747, Loss: 0.039806902408599854, Lr:0.0001\n",
      "Epoch 34, Step: 748, Loss: 0.03727507218718529, Lr:0.0001\n",
      "Epoch 34, Step: 749, Loss: 0.031156906858086586, Lr:0.0001\n",
      "Epoch 34, Step: 750, Loss: 0.006808303762227297, Lr:0.0001\n",
      "Epoch 34, Step: 751, Loss: 0.055615201592445374, Lr:0.0001\n",
      "Epoch 34, Step: 752, Loss: 0.010923830792307854, Lr:0.0001\n",
      "Epoch 34, Step: 753, Loss: 0.03120671771466732, Lr:0.0001\n",
      "Epoch 34, Step: 754, Loss: 0.02756671980023384, Lr:0.0001\n",
      "Epoch 34, Step: 755, Loss: 0.025454843416810036, Lr:0.0001\n",
      "Epoch 34, Step: 756, Loss: 0.053689632564783096, Lr:0.0001\n",
      "Epoch 34, Step: 757, Loss: 0.013466985896229744, Lr:0.0001\n",
      "Epoch 34, Step: 758, Loss: 0.012659408152103424, Lr:0.0001\n",
      "Epoch 34, Step: 759, Loss: 0.01425785943865776, Lr:0.0001\n",
      "Epoch 34, Step: 760, Loss: 0.0065921940840780735, Lr:0.0001\n",
      "Epoch 34, Step: 761, Loss: 0.25946879386901855, Lr:0.0001\n",
      "Epoch 34, Step: 762, Loss: 0.05841958522796631, Lr:0.0001\n",
      "Epoch 34, Step: 763, Loss: 0.31400012969970703, Lr:0.0001\n",
      "Epoch 34, Step: 764, Loss: 0.06138335540890694, Lr:0.0001\n",
      "Epoch 34, Step: 765, Loss: 0.24558693170547485, Lr:0.0001\n",
      "Epoch 34, Step: 766, Loss: 0.004015768878161907, Lr:0.0001\n",
      "Epoch 34, Step: 767, Loss: 0.009482289664447308, Lr:0.0001\n",
      "Epoch 34, Step: 768, Loss: 0.07259048521518707, Lr:0.0001\n",
      "Epoch 34, Step: 769, Loss: 0.12531976401805878, Lr:0.0001\n",
      "Epoch 34, Step: 770, Loss: 0.004274409264326096, Lr:0.0001\n",
      "Epoch 34, Step: 771, Loss: 0.28373050689697266, Lr:0.0001\n",
      "Epoch 34, Step: 772, Loss: 0.017229098826646805, Lr:0.0001\n",
      "Epoch 34, Step: 773, Loss: 0.3124917447566986, Lr:0.0001\n",
      "Epoch 34, Step: 774, Loss: 0.051508016884326935, Lr:0.0001\n",
      "Epoch 34, Step: 775, Loss: 0.0027668962720781565, Lr:0.0001\n",
      "Epoch 34, Step: 776, Loss: 0.04281378909945488, Lr:0.0001\n",
      "Epoch 34, Step: 777, Loss: 0.029439538717269897, Lr:0.0001\n",
      "Epoch 34, Step: 778, Loss: 0.016086533665657043, Lr:0.0001\n",
      "Epoch 34, Step: 779, Loss: 0.012102109380066395, Lr:0.0001\n",
      "Epoch 34, Step: 780, Loss: 0.08275999873876572, Lr:0.0001\n",
      "Epoch 34, Step: 781, Loss: 0.002660495461896062, Lr:0.0001\n",
      "Epoch 34, Step: 782, Loss: 0.05254114791750908, Lr:0.0001\n",
      "Epoch 34, Step: 783, Loss: 0.0015504859620705247, Lr:0.0001\n",
      "Epoch 34, Step: 784, Loss: 0.024086125195026398, Lr:0.0001\n",
      "Epoch 34, Step: 785, Loss: 0.0029576821252703667, Lr:0.0001\n",
      "Epoch 34, Step: 786, Loss: 0.006756922230124474, Lr:0.0001\n",
      "Epoch 34, Step: 787, Loss: 0.002624641405418515, Lr:0.0001\n",
      "Epoch 34, Step: 788, Loss: 0.16312643885612488, Lr:0.0001\n",
      "Epoch 34, Step: 789, Loss: 0.049511589109897614, Lr:0.0001\n",
      "Epoch 34, Step: 790, Loss: 0.004032141529023647, Lr:0.0001\n",
      "Epoch 34, Step: 791, Loss: 0.017367331311106682, Lr:0.0001\n",
      "Epoch 34, Step: 792, Loss: 0.0014598402194678783, Lr:0.0001\n",
      "Epoch 34, Step: 793, Loss: 0.10197576135396957, Lr:0.0001\n",
      "Epoch 34, Step: 794, Loss: 0.3556211292743683, Lr:0.0001\n",
      "Epoch 34, Step: 795, Loss: 0.012081678956747055, Lr:0.0001\n",
      "Epoch 34, Step: 796, Loss: 0.018222030252218246, Lr:0.0001\n",
      "Epoch 34, Step: 797, Loss: 0.0028292848728597164, Lr:0.0001\n",
      "Epoch 34, Step: 798, Loss: 0.021386010572314262, Lr:0.0001\n",
      "Epoch 34, Step: 799, Loss: 0.04843651130795479, Lr:0.0001\n",
      "Epoch 34, Step: 800, Loss: 0.0038291264791041613, Lr:0.0001\n",
      "Epoch 34, Step: 801, Loss: 0.006608915515244007, Lr:0.0001\n",
      "Epoch 34, Step: 802, Loss: 0.018957216292619705, Lr:0.0001\n",
      "Epoch 34, Step: 803, Loss: 0.00903657078742981, Lr:0.0001\n",
      "Epoch 34, Step: 804, Loss: 0.10314755141735077, Lr:0.0001\n",
      "Epoch 34, Step: 805, Loss: 0.09826593846082687, Lr:0.0001\n",
      "Epoch 34, Step: 806, Loss: 0.13916076719760895, Lr:0.0001\n",
      "Epoch 34, Step: 807, Loss: 0.010574414394795895, Lr:0.0001\n",
      "Epoch 34, Step: 808, Loss: 0.09819170832633972, Lr:0.0001\n",
      "Epoch 34, Step: 809, Loss: 0.03630118817090988, Lr:0.0001\n",
      "Epoch 34, Step: 810, Loss: 0.005267767701297998, Lr:0.0001\n",
      "Epoch 34, Step: 811, Loss: 0.08626764267683029, Lr:0.0001\n",
      "Epoch 34, Step: 812, Loss: 0.2567196190357208, Lr:0.0001\n",
      "Epoch 34, Step: 813, Loss: 0.02039322815835476, Lr:0.0001\n",
      "Epoch 34, Step: 814, Loss: 0.009718501009047031, Lr:0.0001\n",
      "Epoch 34, Step: 815, Loss: 0.006299495697021484, Lr:0.0001\n",
      "Epoch 34, Step: 816, Loss: 0.03106263279914856, Lr:0.0001\n",
      "Epoch 34, Step: 817, Loss: 0.02181280218064785, Lr:0.0001\n",
      "Epoch 34, Step: 818, Loss: 0.04071425646543503, Lr:0.0001\n",
      "Epoch 34, Step: 819, Loss: 0.06334586441516876, Lr:0.0001\n",
      "Epoch 34, Step: 820, Loss: 0.002194285159930587, Lr:0.0001\n",
      "Epoch 34, Step: 821, Loss: 0.012163732200860977, Lr:0.0001\n",
      "Epoch 34, Step: 822, Loss: 0.04325411468744278, Lr:0.0001\n",
      "Epoch 34, Step: 823, Loss: 0.002729000523686409, Lr:0.0001\n",
      "Epoch 34, Step: 824, Loss: 0.0125355189666152, Lr:0.0001\n",
      "Epoch 34, Step: 825, Loss: 0.0073294127359986305, Lr:0.0001\n",
      "Epoch 34, Step: 826, Loss: 0.06737260520458221, Lr:0.0001\n",
      "Epoch 34, Step: 827, Loss: 0.07544880360364914, Lr:0.0001\n",
      "Epoch 34, Step: 828, Loss: 0.15744008123874664, Lr:0.0001\n",
      "Epoch 34, Step: 829, Loss: 0.016823140904307365, Lr:0.0001\n",
      "Epoch 34, Step: 830, Loss: 0.04127272590994835, Lr:0.0001\n",
      "Epoch 34, Step: 831, Loss: 0.008299397304654121, Lr:0.0001\n",
      "Epoch 34, Step: 832, Loss: 0.02103176899254322, Lr:0.0001\n",
      "Epoch 34, Step: 833, Loss: 0.038573022931814194, Lr:0.0001\n",
      "Epoch 34, Step: 834, Loss: 0.007220780476927757, Lr:0.0001\n",
      "Epoch 34, Step: 835, Loss: 0.0037919292226433754, Lr:0.0001\n",
      "Epoch 34, Step: 836, Loss: 0.017086461186408997, Lr:0.0001\n",
      "Epoch 34, Step: 837, Loss: 0.004352939780801535, Lr:0.0001\n",
      "Epoch 34, Step: 838, Loss: 0.04238614812493324, Lr:0.0001\n",
      "Epoch 34, Step: 839, Loss: 0.03478986769914627, Lr:0.0001\n",
      "Epoch 34, Step: 840, Loss: 0.03887006640434265, Lr:0.0001\n",
      "Epoch 34, Step: 841, Loss: 0.03810594603419304, Lr:0.0001\n",
      "Epoch 34, Step: 842, Loss: 0.03572111204266548, Lr:0.0001\n",
      "Epoch 34, Step: 843, Loss: 0.0005211274838075042, Lr:0.0001\n",
      "Epoch 34, Step: 844, Loss: 0.10634927451610565, Lr:0.0001\n",
      "Epoch 34, Step: 845, Loss: 0.009260864928364754, Lr:0.0001\n",
      "Epoch 34, Step: 846, Loss: 0.01989505998790264, Lr:0.0001\n",
      "Epoch 34, Step: 847, Loss: 0.005424393806606531, Lr:0.0001\n",
      "Epoch 34, Step: 848, Loss: 0.003745994297787547, Lr:0.0001\n",
      "Epoch 34, Step: 849, Loss: 0.045821838080883026, Lr:0.0001\n",
      "Epoch 34, Step: 850, Loss: 0.02167067490518093, Lr:0.0001\n",
      "Epoch 34, Step: 851, Loss: 0.1606101542711258, Lr:0.0001\n",
      "Epoch 34, Step: 852, Loss: 0.025275878608226776, Lr:0.0001\n",
      "Epoch 34, Step: 853, Loss: 0.08825133740901947, Lr:0.0001\n",
      "Epoch 34, Step: 854, Loss: 0.02986634150147438, Lr:0.0001\n",
      "Epoch 34, Step: 855, Loss: 0.05174076557159424, Lr:0.0001\n",
      "Epoch 34, Step: 856, Loss: 0.0001333846157649532, Lr:0.0001\n",
      "Epoch 34, Step: 857, Loss: 0.07448498159646988, Lr:0.0001\n",
      "Epoch 34, Step: 858, Loss: 0.029078084975481033, Lr:0.0001\n",
      "Epoch 34, Step: 859, Loss: 0.037272438406944275, Lr:0.0001\n",
      "Epoch 34, Step: 860, Loss: 0.0026050067972391844, Lr:0.0001\n",
      "Epoch 34, Step: 861, Loss: 0.0465114563703537, Lr:0.0001\n",
      "Epoch 34, Step: 862, Loss: 0.008497389033436775, Lr:0.0001\n",
      "Epoch 34, Step: 863, Loss: 0.0052501424215734005, Lr:0.0001\n",
      "Epoch 34, Step: 864, Loss: 0.021919555962085724, Lr:0.0001\n",
      "Epoch 34, Step: 865, Loss: 0.014388876967132092, Lr:0.0001\n",
      "Epoch 34, Step: 866, Loss: 0.0028628858271986246, Lr:0.0001\n",
      "Epoch 34, Step: 867, Loss: 0.13567321002483368, Lr:0.0001\n",
      "Epoch 34, Step: 868, Loss: 0.028553584590554237, Lr:0.0001\n",
      "Epoch 34, Step: 869, Loss: 0.003459965344518423, Lr:0.0001\n",
      "Epoch 34, Step: 870, Loss: 0.0013867754023522139, Lr:0.0001\n",
      "Epoch 34, Step: 871, Loss: 0.00869586132466793, Lr:0.0001\n",
      "Epoch 34, Step: 872, Loss: 0.0039284322410821915, Lr:0.0001\n",
      "Epoch 34, Step: 873, Loss: 0.03343416750431061, Lr:0.0001\n",
      "Epoch 34, Step: 874, Loss: 0.0888262391090393, Lr:0.0001\n",
      "Epoch 34, Step: 875, Loss: 0.0016627172008156776, Lr:0.0001\n",
      "Epoch 34, Step: 876, Loss: 0.0045504518784582615, Lr:0.0001\n",
      "Epoch 34, Step: 877, Loss: 0.01791057363152504, Lr:0.0001\n",
      "Epoch 34, Step: 878, Loss: 0.2482147216796875, Lr:0.0001\n",
      "Epoch 34, Step: 879, Loss: 0.02243862859904766, Lr:0.0001\n",
      "Epoch 34, Step: 880, Loss: 0.06141314283013344, Lr:0.0001\n",
      "Epoch 34, Step: 881, Loss: 0.03809215873479843, Lr:0.0001\n",
      "Epoch 34, Step: 882, Loss: 0.13466213643550873, Lr:0.0001\n",
      "Epoch 34, Step: 883, Loss: 0.0019192479085177183, Lr:0.0001\n",
      "Epoch 34, Step: 884, Loss: 0.1879071146249771, Lr:0.0001\n",
      "Epoch 34, Step: 885, Loss: 0.011706232093274593, Lr:0.0001\n",
      "Epoch 34, Step: 886, Loss: 0.007866542786359787, Lr:0.0001\n",
      "Epoch 34, Step: 887, Loss: 0.0005092205246910453, Lr:0.0001\n",
      "Epoch 34, Step: 888, Loss: 0.007354281842708588, Lr:0.0001\n",
      "Epoch 34, Step: 889, Loss: 0.11801405996084213, Lr:0.0001\n",
      "Epoch 34, Step: 890, Loss: 0.042749278247356415, Lr:0.0001\n",
      "Epoch 34, Step: 891, Loss: 0.07653676718473434, Lr:0.0001\n",
      "Epoch 34, Step: 892, Loss: 0.004662378691136837, Lr:0.0001\n",
      "Epoch 34, Step: 893, Loss: 0.005108894780278206, Lr:0.0001\n",
      "Epoch 34, Step: 894, Loss: 0.15723900496959686, Lr:0.0001\n",
      "Epoch 34, Step: 895, Loss: 0.07208696752786636, Lr:0.0001\n",
      "Epoch 34, Step: 896, Loss: 0.05308009684085846, Lr:0.0001\n",
      "Epoch 34, Step: 897, Loss: 0.004559349734336138, Lr:0.0001\n",
      "Epoch 34, Step: 898, Loss: 0.06527864933013916, Lr:0.0001\n",
      "Epoch 34, Step: 899, Loss: 0.0036131502129137516, Lr:0.0001\n",
      "Epoch 34, Step: 900, Loss: 0.018519733101129532, Lr:0.0001\n",
      "Epoch 34, Step: 901, Loss: 0.0011702757328748703, Lr:0.0001\n",
      "Epoch 34, Step: 902, Loss: 0.00201042671687901, Lr:0.0001\n",
      "Epoch 34, Step: 903, Loss: 0.023535173386335373, Lr:0.0001\n",
      "Epoch 34, Step: 904, Loss: 0.0537576824426651, Lr:0.0001\n",
      "Epoch 34, Step: 905, Loss: 0.04084179922938347, Lr:0.0001\n",
      "Epoch 34, Step: 906, Loss: 0.003936371766030788, Lr:0.0001\n",
      "Epoch 34, Step: 907, Loss: 0.00037649733712896705, Lr:0.0001\n",
      "Epoch 34, Step: 908, Loss: 0.0023082399275153875, Lr:0.0001\n",
      "Epoch 34, Step: 909, Loss: 0.02886049449443817, Lr:0.0001\n",
      "Epoch 34, Step: 910, Loss: 0.06411697715520859, Lr:0.0001\n",
      "Epoch 34, Step: 911, Loss: 0.06410325318574905, Lr:0.0001\n",
      "Epoch 34, Step: 912, Loss: 0.004671146161854267, Lr:0.0001\n",
      "Epoch 34, Step: 913, Loss: 0.04425279051065445, Lr:0.0001\n",
      "Epoch 34, Step: 914, Loss: 0.04051657393574715, Lr:0.0001\n",
      "Epoch 34, Step: 915, Loss: 0.0070261526852846146, Lr:0.0001\n",
      "Epoch 34, Step: 916, Loss: 0.008687156252563, Lr:0.0001\n",
      "Epoch 34, Step: 917, Loss: 0.009235205128788948, Lr:0.0001\n",
      "Epoch 34, Step: 918, Loss: 0.007147676311433315, Lr:0.0001\n",
      "Epoch 34, Step: 919, Loss: 0.13040921092033386, Lr:0.0001\n",
      "Epoch 34, Step: 920, Loss: 0.06200283765792847, Lr:0.0001\n",
      "Epoch 34, Step: 921, Loss: 0.07338173687458038, Lr:0.0001\n",
      "Epoch 34, Step: 922, Loss: 0.015762658789753914, Lr:0.0001\n",
      "Epoch 34, Step: 923, Loss: 0.0025827577337622643, Lr:0.0001\n",
      "Epoch 34, Step: 924, Loss: 0.10882174968719482, Lr:0.0001\n",
      "Epoch 34, Step: 925, Loss: 0.04484065994620323, Lr:0.0001\n",
      "Epoch 34, Step: 926, Loss: 0.0891432836651802, Lr:0.0001\n",
      "Epoch 34, Step: 927, Loss: 0.13266371190547943, Lr:0.0001\n",
      "Epoch 34, Step: 928, Loss: 0.0039952718652784824, Lr:0.0001\n",
      "Epoch 34, Step: 929, Loss: 0.041168514639139175, Lr:0.0001\n",
      "Epoch 34, Step: 930, Loss: 0.015551717951893806, Lr:0.0001\n",
      "Epoch 34, Step: 931, Loss: 0.07366101443767548, Lr:0.0001\n",
      "Epoch 34, Step: 932, Loss: 0.16285033524036407, Lr:0.0001\n",
      "Epoch 34, Step: 933, Loss: 0.000590871786698699, Lr:0.0001\n",
      "Epoch 34, Step: 934, Loss: 0.0141204334795475, Lr:0.0001\n",
      "Epoch 34, Step: 935, Loss: 0.002773111220449209, Lr:0.0001\n",
      "Epoch 34, Step: 936, Loss: 0.0019259556429460645, Lr:0.0001\n",
      "Epoch 34, Step: 937, Loss: 0.005090806633234024, Lr:0.0001\n",
      "Epoch 34, Step: 938, Loss: 0.0510922446846962, Lr:0.0001\n",
      "Epoch 34, Step: 939, Loss: 0.01026719156652689, Lr:0.0001\n",
      "Epoch 34, Step: 940, Loss: 0.03579119220376015, Lr:0.0001\n",
      "Epoch 34, Step: 941, Loss: 0.032303888350725174, Lr:0.0001\n",
      "Epoch 34, Step: 942, Loss: 0.20261073112487793, Lr:0.0001\n",
      "Epoch 34, Step: 943, Loss: 0.062132999300956726, Lr:0.0001\n",
      "Epoch 34, Step: 944, Loss: 0.0451965294778347, Lr:0.0001\n",
      "Epoch 34, Step: 945, Loss: 0.031168747693300247, Lr:0.0001\n",
      "Epoch 34, Step: 946, Loss: 0.30265146493911743, Lr:0.0001\n",
      "Epoch 34, Step: 947, Loss: 0.005656813737004995, Lr:0.0001\n",
      "Epoch 34, Step: 948, Loss: 0.012405579909682274, Lr:0.0001\n",
      "Epoch 34, Step: 949, Loss: 0.0053274366073310375, Lr:0.0001\n",
      "Epoch 34, Step: 950, Loss: 0.03391839563846588, Lr:0.0001\n",
      "Epoch 34, Step: 951, Loss: 0.13625934720039368, Lr:0.0001\n",
      "Epoch 34, Step: 952, Loss: 0.010042575187981129, Lr:0.0001\n",
      "Epoch 34, Step: 953, Loss: 0.001756083918735385, Lr:0.0001\n",
      "Epoch 34, Step: 954, Loss: 0.163272887468338, Lr:0.0001\n",
      "Epoch 34, Step: 955, Loss: 0.12285403162240982, Lr:0.0001\n",
      "Epoch 34, Step: 956, Loss: 0.79457026720047, Lr:0.0001\n",
      "Epoch 34, Step: 957, Loss: 0.05315094068646431, Lr:0.0001\n",
      "Epoch 34, Step: 958, Loss: 0.0005757279577665031, Lr:0.0001\n",
      "Epoch 34, Step: 959, Loss: 0.02100510522723198, Lr:0.0001\n",
      "Epoch 34, Step: 960, Loss: 0.017356567084789276, Lr:0.0001\n",
      "Epoch 34, Step: 961, Loss: 0.17842556536197662, Lr:0.0001\n",
      "Epoch 34, Step: 962, Loss: 0.022280018776655197, Lr:0.0001\n",
      "Epoch 34, Step: 963, Loss: 0.0006591973942704499, Lr:0.0001\n",
      "Epoch 34, Step: 964, Loss: 0.006809727754443884, Lr:0.0001\n",
      "Epoch 34, Step: 965, Loss: 0.26482123136520386, Lr:0.0001\n",
      "Epoch 34, Step: 966, Loss: 0.0033178958110511303, Lr:0.0001\n",
      "Epoch 34, Step: 967, Loss: 0.01584411785006523, Lr:0.0001\n",
      "Epoch 34, Step: 968, Loss: 0.006352514959871769, Lr:0.0001\n",
      "Epoch 34, Step: 969, Loss: 0.010258035734295845, Lr:0.0001\n",
      "Epoch 34, Step: 970, Loss: 0.18991202116012573, Lr:0.0001\n",
      "Epoch 34, Step: 971, Loss: 0.007659530267119408, Lr:0.0001\n",
      "Epoch 34, Step: 972, Loss: 0.21883077919483185, Lr:0.0001\n",
      "Epoch 34, Step: 973, Loss: 0.00957517884671688, Lr:0.0001\n",
      "Epoch 34, Step: 974, Loss: 0.022994140163064003, Lr:0.0001\n",
      "Epoch 34, Step: 975, Loss: 0.08139069378376007, Lr:0.0001\n",
      "Epoch 34, Step: 976, Loss: 0.08361921459436417, Lr:0.0001\n",
      "Epoch 34, Step: 977, Loss: 0.28533080220222473, Lr:0.0001\n",
      "Epoch 34, Step: 978, Loss: 0.35263940691947937, Lr:0.0001\n",
      "Epoch 34, Step: 979, Loss: 0.03528709337115288, Lr:0.0001\n",
      "Epoch 34, Step: 980, Loss: 0.0462285540997982, Lr:0.0001\n",
      "Epoch 34, Step: 981, Loss: 0.03817298263311386, Lr:0.0001\n",
      "Epoch 34, Step: 982, Loss: 0.05916961282491684, Lr:0.0001\n",
      "Epoch 34, Step: 983, Loss: 0.06582498550415039, Lr:0.0001\n",
      "Epoch 34, Step: 984, Loss: 0.03996257856488228, Lr:0.0001\n",
      "Epoch 34, Step: 985, Loss: 0.016973182559013367, Lr:0.0001\n",
      "Epoch 34, Step: 986, Loss: 0.013820579275488853, Lr:0.0001\n",
      "Epoch 34, Step: 987, Loss: 0.06007235124707222, Lr:0.0001\n",
      "Epoch 34, Step: 988, Loss: 0.006336864549666643, Lr:0.0001\n",
      "Epoch 34, Step: 989, Loss: 0.014771039597690105, Lr:0.0001\n",
      "Epoch 34, Step: 990, Loss: 0.064580537378788, Lr:0.0001\n",
      "Epoch 34, Step: 991, Loss: 0.006835853215306997, Lr:0.0001\n",
      "Epoch 34, Step: 992, Loss: 0.14545917510986328, Lr:0.0001\n",
      "Epoch 34, Step: 993, Loss: 0.05975112318992615, Lr:0.0001\n",
      "Epoch 34, Step: 994, Loss: 0.1342637985944748, Lr:0.0001\n",
      "Epoch 34, Step: 995, Loss: 0.06892693787813187, Lr:0.0001\n",
      "Epoch 34, Step: 996, Loss: 0.057216666638851166, Lr:0.0001\n",
      "Epoch 34, Step: 997, Loss: 0.13180631399154663, Lr:0.0001\n",
      "Epoch 34, Step: 998, Loss: 0.033047985285520554, Lr:0.0001\n",
      "Epoch 34, Step: 999, Loss: 0.01120401918888092, Lr:0.0001\n",
      "Epoch 34, Step: 1000, Loss: 0.03463944420218468, Lr:0.0001\n",
      "Epoch 34, Step: 1001, Loss: 0.12326658517122269, Lr:0.0001\n",
      "Epoch 34, Step: 1002, Loss: 0.024572892114520073, Lr:0.0001\n",
      "Epoch 34, Step: 1003, Loss: 0.02120748721063137, Lr:0.0001\n",
      "Epoch 34, Step: 1004, Loss: 0.24331237375736237, Lr:0.0001\n",
      "Epoch 34, Step: 1005, Loss: 0.0034770641941577196, Lr:0.0001\n",
      "Epoch 34, Step: 1006, Loss: 0.1845971792936325, Lr:0.0001\n",
      "Epoch 34, Step: 1007, Loss: 0.00684436084702611, Lr:0.0001\n",
      "Epoch 34, Step: 1008, Loss: 0.006071622483432293, Lr:0.0001\n",
      "Epoch 34, Step: 1009, Loss: 0.016958389431238174, Lr:0.0001\n",
      "Epoch 34, Step: 1010, Loss: 0.009283539839088917, Lr:0.0001\n",
      "Epoch 34, Step: 1011, Loss: 0.0004444436344783753, Lr:0.0001\n",
      "Epoch 34, Step: 1012, Loss: 0.06428740918636322, Lr:0.0001\n",
      "Epoch 34, Step: 1013, Loss: 0.1260218322277069, Lr:0.0001\n",
      "Epoch 34, Step: 1014, Loss: 0.016367128118872643, Lr:0.0001\n",
      "Epoch 34, Step: 1015, Loss: 0.31288662552833557, Lr:0.0001\n",
      "Epoch 34, Step: 1016, Loss: 0.06364434957504272, Lr:0.0001\n",
      "Epoch 34, Step: 1017, Loss: 0.07931992411613464, Lr:0.0001\n",
      "Epoch 34, Step: 1018, Loss: 0.022325143218040466, Lr:0.0001\n",
      "Epoch 34, Step: 1019, Loss: 0.01991264522075653, Lr:0.0001\n",
      "Epoch 34, Step: 1020, Loss: 0.030780326575040817, Lr:0.0001\n",
      "Epoch 34, Step: 1021, Loss: 0.006925348658114672, Lr:0.0001\n",
      "Epoch 34, Step: 1022, Loss: 0.07406066358089447, Lr:0.0001\n",
      "Epoch 34, Step: 1023, Loss: 0.038710128515958786, Lr:0.0001\n",
      "Epoch 34, Step: 1024, Loss: 0.023993341252207756, Lr:0.0001\n",
      "Epoch 34, Step: 1025, Loss: 0.003356876550242305, Lr:0.0001\n",
      "Epoch 34, Step: 1026, Loss: 0.13734237849712372, Lr:0.0001\n",
      "Epoch 34, Step: 1027, Loss: 0.10507795214653015, Lr:0.0001\n",
      "Epoch 34, Step: 1028, Loss: 0.03256365284323692, Lr:0.0001\n",
      "Epoch 34, Step: 1029, Loss: 0.16855931282043457, Lr:0.0001\n",
      "Epoch 34, Step: 1030, Loss: 0.023103909566998482, Lr:0.0001\n",
      "Epoch 34, Step: 1031, Loss: 0.3044954538345337, Lr:0.0001\n",
      "Epoch 34, Step: 1032, Loss: 0.025671476498246193, Lr:0.0001\n",
      "Epoch 34, Step: 1033, Loss: 0.06690823286771774, Lr:0.0001\n",
      "Epoch 34, Step: 1034, Loss: 0.008377675898373127, Lr:0.0001\n",
      "Epoch 34, Step: 1035, Loss: 0.012167098000645638, Lr:0.0001\n",
      "Epoch 34, Step: 1036, Loss: 0.01759464293718338, Lr:0.0001\n",
      "Epoch 34, Step: 1037, Loss: 0.11056999117136002, Lr:0.0001\n",
      "Epoch 34, Step: 1038, Loss: 0.10167468339204788, Lr:0.0001\n",
      "Epoch 34, Step: 1039, Loss: 0.004575987346470356, Lr:0.0001\n",
      "Epoch 34, Step: 1040, Loss: 0.02948508784174919, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 34\n",
      "length of data_loader_train is 1041\n",
      "Evaluating...\n",
      "Test: [ 0/56] eta: 0:00:16 loss: 0.1199 (0.1199) acc1: 93.7500 (93.7500) acc5: 100.0000 (100.0000) time: 0.2938 data: 0.1250 max mem: 15137\n",
      "Test: [10/56] eta: 0:00:13 loss: 0.0715 (0.1064) acc1: 93.7500 (95.4545) acc5: 100.0000 (100.0000) time: 0.2892 data: 0.1202 max mem: 15137\n",
      "Test: [20/56] eta: 0:00:10 loss: 0.0365 (0.1084) acc1: 100.0000 (95.8333) acc5: 100.0000 (100.0000) time: 0.2908 data: 0.1173 max mem: 15137\n",
      "Test: [30/56] eta: 0:00:07 loss: 0.0447 (0.2881) acc1: 93.7500 (92.3387) acc5: 100.0000 (100.0000) time: 0.2935 data: 0.1163 max mem: 15137\n",
      "Test: [40/56] eta: 0:00:04 loss: 0.2727 (0.3740) acc1: 87.5000 (90.3963) acc5: 100.0000 (100.0000) time: 0.2972 data: 0.1194 max mem: 15137\n",
      "Test: [50/56] eta: 0:00:01 loss: 0.0012 (0.3066) acc1: 100.0000 (92.0343) acc5: 100.0000 (100.0000) time: 0.2986 data: 0.1209 max mem: 15137\n",
      "Test: [55/56] eta: 0:00:00 loss: 0.0004 (0.2796) acc1: 100.0000 (92.6220) acc5: 100.0000 (100.0000) time: 0.2857 data: 0.1149 max mem: 15137\n",
      "Test: Total time: 0:00:16 (0.2905 s / it)\n",
      "* Acc@1 92.622 Acc@5 100.000 loss 0.280\n",
      "Accuracy of the network on the 881 test image: 92.6%\n",
      "Training...\n",
      "log_dir: ./densenet_output_dir\n",
      "Epoch 35, Step: 0, Loss: 0.0017494068015366793, Lr:0.0001\n",
      "Epoch 35, Step: 1, Loss: 0.07304029911756516, Lr:0.0001\n",
      "Epoch 35, Step: 2, Loss: 0.010621298104524612, Lr:0.0001\n",
      "Epoch 35, Step: 3, Loss: 0.023614700883626938, Lr:0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mD:\\AI\\3rdSEED\\SEED2022_gastric_cancer_classification\\densenet_baseline\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m         \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[0msour_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./Test_patch'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AI\\3rdSEED\\SEED2022_gastric_cancer_classification\\densenet_baseline\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(args, mode, test_image_path)\u001b[0m\n\u001b[0;32m    275\u001b[0m                 \u001b[0mloss_scaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m                 \u001b[0mlog_writer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog_writer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m                 \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m             )\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AI\\3rdSEED\\SEED2022_gastric_cancer_classification\\densenet_baseline\\train.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, criterion, data_loader, optimizer, device, epoch, loss_scaler, max_norm, log_writer, args)\u001b[0m\n\u001b[0;32m     95\u001b[0m         loss_scaler(loss, optimizer, clip_grad=max_norm,\n\u001b[0;32m     96\u001b[0m                     \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                     update_grad=(data_iter_step + 1) % accum_iter == 0)\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AI\\3rdSEED\\SEED2022_gastric_cancer_classification\\densenet_baseline\\util\\misc.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, loss, optimizer, clip_grad, parameters, create_graph, update_grad)\u001b[0m\n\u001b[0;32m    265\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m                 \u001b[0mnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\swin\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stage\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\swin\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\swin\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run densenet_baseline/train.py --mode train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8c4524-44cf-449a-b572-c41e4f600ca7",
   "metadata": {},
   "source": [
    "# 使用tensorboard查看训练结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f1da00-a479-49be-9ad5-f64485e922f5",
   "metadata": {},
   "source": [
    "http://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bad7033a-cf62-4ebe-9da9-b077e22b43f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=./densenet_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb78030-c344-4d12-a68a-f973b6ba4380",
   "metadata": {},
   "source": [
    "# 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f69061f-5e92-4f85-9639-d9fcee83ce95",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\0.png\n",
      "score is 0.7917905449867249, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\1.png\n",
      "score is 0.9950531125068665, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\10.png\n",
      "score is 0.5375978350639343, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\11.png\n",
      "score is 0.617510974407196, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\12.png\n",
      "score is 0.6693545579910278, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\13.png\n",
      "score is 0.9806642532348633, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\14.png\n",
      "score is 0.8055431842803955, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\15.png\n",
      "score is 0.7903728485107422, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\16.png\n",
      "score is 0.9833245277404785, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\17.png\n",
      "score is 0.761944055557251, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\18.png\n",
      "score is 0.9949554800987244, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\19.png\n",
      "score is 0.9940913319587708, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\2.png\n",
      "score is 0.9328973293304443, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\20.png\n",
      "score is 0.8554210662841797, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\21.png\n",
      "score is 0.5133600234985352, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\22.png\n",
      "score is 0.5440441370010376, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\23.png\n",
      "score is 0.9104475378990173, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\24.png\n",
      "score is 0.916888952255249, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\25.png\n",
      "score is 0.9537370800971985, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\26.png\n",
      "score is 0.9846166372299194, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\27.png\n",
      "score is 0.7014400959014893, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\28.png\n",
      "score is 0.7359082102775574, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\29.png\n",
      "score is 0.9928293824195862, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\3.png\n",
      "score is 0.34535178542137146, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\4.png\n",
      "score is 0.6681237816810608, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\5.png\n",
      "score is 0.6233859658241272, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\6.png\n",
      "score is 0.5616612434387207, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\7.png\n",
      "score is 0.996936559677124, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\8.png\n",
      "score is 0.5305901765823364, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:17, 17.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\1y9UDX\\1y9UDX_0\\9.png\n",
      "score is 0.9701158404350281, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\0.png\n",
      "score is 0.9791758060455322, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\1.png\n",
      "score is 0.6965034604072571, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\10.png\n",
      "score is 0.507357656955719, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\11.png\n",
      "score is 0.999790608882904, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\12.png\n",
      "score is 0.9999935626983643, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\13.png\n",
      "score is 0.8502218127250671, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\14.png\n",
      "score is 0.9907470941543579, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\15.png\n",
      "score is 0.9999992847442627, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\16.png\n",
      "score is 0.9930819869041443, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\17.png\n",
      "score is 0.7753745913505554, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\18.png\n",
      "score is 0.9857375621795654, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\19.png\n",
      "score is 0.637740433216095, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\2.png\n",
      "score is 0.4403141438961029, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\20.png\n",
      "score is 0.9999802112579346, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\21.png\n",
      "score is 0.9999920129776001, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\22.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\23.png\n",
      "score is 0.5464452505111694, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\24.png\n",
      "score is 0.9999994039535522, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\25.png\n",
      "score is 0.8969651460647583, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\26.png\n",
      "score is 0.9957430958747864, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\27.png\n",
      "score is 0.9999997615814209, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\28.png\n",
      "score is 0.5498947501182556, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\29.png\n",
      "score is 0.5563880205154419, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\3.png\n",
      "score is 0.8748868703842163, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\4.png\n",
      "score is 0.9991536140441895, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\5.png\n",
      "score is 0.8614513874053955, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\6.png\n",
      "score is 0.9997739195823669, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\7.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\8.png\n",
      "score is 0.9879428744316101, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_0\\9.png\n",
      "score is 0.840233325958252, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\0.png\n",
      "score is 0.9989540576934814, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\1.png\n",
      "score is 0.9385799169540405, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\10.png\n",
      "score is 0.9932622313499451, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\11.png\n",
      "score is 0.9992687106132507, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\12.png\n",
      "score is 0.9967058300971985, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\13.png\n",
      "score is 0.9996206760406494, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\14.png\n",
      "score is 0.9980511665344238, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\15.png\n",
      "score is 0.9999954700469971, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\16.png\n",
      "score is 0.9978659749031067, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\17.png\n",
      "score is 0.9925124645233154, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\18.png\n",
      "score is 0.9991214871406555, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\19.png\n",
      "score is 0.9121319055557251, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\2.png\n",
      "score is 0.5194097757339478, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\20.png\n",
      "score is 0.6795008778572083, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\21.png\n",
      "score is 0.9999887943267822, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\22.png\n",
      "score is 0.6607840061187744, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\23.png\n",
      "score is 0.9953441023826599, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\24.png\n",
      "score is 0.5822394490242004, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\25.png\n",
      "score is 0.6009453535079956, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\26.png\n",
      "score is 0.9781972765922546, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\27.png\n",
      "score is 0.9041954278945923, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\28.png\n",
      "score is 0.9999982118606567, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\29.png\n",
      "score is 0.9999961853027344, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\3.png\n",
      "score is 0.9435173273086548, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\4.png\n",
      "score is 0.9967305660247803, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\5.png\n",
      "score is 0.9939510822296143, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\6.png\n",
      "score is 0.9255090951919556, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\7.png\n",
      "score is 0.9648686051368713, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\8.png\n",
      "score is 0.9916867613792419, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_1\\9.png\n",
      "score is 0.9986892342567444, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\0.png\n",
      "score is 0.9999949932098389, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\1.png\n",
      "score is 0.8255200386047363, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\10.png\n",
      "score is 0.6701011061668396, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\11.png\n",
      "score is 0.7971413135528564, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\12.png\n",
      "score is 0.9572232961654663, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\13.png\n",
      "score is 0.9123119711875916, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\14.png\n",
      "score is 0.9986442923545837, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\15.png\n",
      "score is 0.9934210181236267, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\16.png\n",
      "score is 0.7536065578460693, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\17.png\n",
      "score is 0.99680495262146, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\18.png\n",
      "score is 0.855562686920166, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\19.png\n",
      "score is 0.8174970746040344, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\2.png\n",
      "score is 0.9999982118606567, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\20.png\n",
      "score is 0.5073532462120056, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\21.png\n",
      "score is 0.6769489645957947, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\22.png\n",
      "score is 0.9998940229415894, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\23.png\n",
      "score is 0.8993555903434753, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\24.png\n",
      "score is 0.6789260506629944, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\25.png\n",
      "score is 0.970180094242096, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\26.png\n",
      "score is 0.9892469048500061, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\27.png\n",
      "score is 0.7599267959594727, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\28.png\n",
      "score is 0.9993928670883179, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\29.png\n",
      "score is 0.6647760272026062, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\3.png\n",
      "score is 0.9960381984710693, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\4.png\n",
      "score is 0.9999760389328003, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\5.png\n",
      "score is 0.9925755262374878, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\6.png\n",
      "score is 0.569333016872406, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\7.png\n",
      "score is 0.9999933242797852, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\8.png\n",
      "score is 0.9979045391082764, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_2\\9.png\n",
      "score is 0.8896040916442871, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\0.png\n",
      "score is 0.9863656759262085, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\1.png\n",
      "score is 0.9781939387321472, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\10.png\n",
      "score is 0.8974059224128723, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\11.png\n",
      "score is 0.5253039598464966, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\12.png\n",
      "score is 0.564828634262085, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\13.png\n",
      "score is 0.9891659617424011, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\14.png\n",
      "score is 0.9999527931213379, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\15.png\n",
      "score is 0.9999474287033081, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\16.png\n",
      "score is 0.984788179397583, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\17.png\n",
      "score is 0.8550862073898315, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\18.png\n",
      "score is 0.9996657371520996, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\19.png\n",
      "score is 0.9999816417694092, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\2.png\n",
      "score is 0.9999059438705444, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\20.png\n",
      "score is 0.5788925290107727, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\21.png\n",
      "score is 0.9812695980072021, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\22.png\n",
      "score is 0.9978297352790833, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\23.png\n",
      "score is 0.9996699094772339, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\24.png\n",
      "score is 0.995528519153595, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\25.png\n",
      "score is 0.9990468621253967, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\26.png\n",
      "score is 0.9999899864196777, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\27.png\n",
      "score is 0.9991318583488464, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\28.png\n",
      "score is 0.999555766582489, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\29.png\n",
      "score is 0.9445744752883911, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\3.png\n",
      "score is 0.9999780654907227, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\4.png\n",
      "score is 0.9999368190765381, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\5.png\n",
      "score is 0.9668739438056946, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\6.png\n",
      "score is 0.9993009567260742, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\7.png\n",
      "score is 0.9961332082748413, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\8.png\n",
      "score is 0.999639630317688, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:22, 45.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\4mF7tL\\4mF7tL_3\\9.png\n",
      "score is 0.9999804496765137, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\0.png\n",
      "score is 0.9998127818107605, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\1.png\n",
      "score is 0.9405838251113892, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\10.png\n",
      "score is 0.9999468326568604, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\11.png\n",
      "score is 0.9999990463256836, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\12.png\n",
      "score is 0.9994422793388367, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\13.png\n",
      "score is 0.9544721841812134, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\14.png\n",
      "score is 0.9992741942405701, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\15.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\16.png\n",
      "score is 0.43392667174339294, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\17.png\n",
      "score is 0.9625864624977112, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\18.png\n",
      "score is 0.9941934943199158, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\19.png\n",
      "score is 0.9996678829193115, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\2.png\n",
      "score is 0.999977707862854, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\20.png\n",
      "score is 0.5632449984550476, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\21.png\n",
      "score is 0.9547874927520752, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\22.png\n",
      "score is 0.9999561309814453, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\23.png\n",
      "score is 0.9684827327728271, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\24.png\n",
      "score is 0.9998883008956909, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\25.png\n",
      "score is 0.9996851682662964, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\26.png\n",
      "score is 0.985673725605011, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\27.png\n",
      "score is 0.6285088062286377, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\28.png\n",
      "score is 0.9524741172790527, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\29.png\n",
      "score is 0.7010922431945801, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\3.png\n",
      "score is 0.957642138004303, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\4.png\n",
      "score is 0.9315993785858154, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\5.png\n",
      "score is 0.7314548492431641, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\6.png\n",
      "score is 0.9927334785461426, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\7.png\n",
      "score is 0.6999180912971497, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\8.png\n",
      "score is 0.872513473033905, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_0\\9.png\n",
      "score is 0.7197045683860779, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\0.png\n",
      "score is 0.9998745918273926, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\1.png\n",
      "score is 0.9740467071533203, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\10.png\n",
      "score is 0.8070845603942871, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\11.png\n",
      "score is 0.9438437819480896, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\12.png\n",
      "score is 0.9885913729667664, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\13.png\n",
      "score is 0.9259309768676758, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\14.png\n",
      "score is 0.9993594288825989, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\15.png\n",
      "score is 0.9097768068313599, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\16.png\n",
      "score is 0.9999785423278809, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\17.png\n",
      "score is 0.9998210072517395, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\18.png\n",
      "score is 0.7198712229728699, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\19.png\n",
      "score is 0.9994381070137024, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\2.png\n",
      "score is 0.9995805621147156, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\20.png\n",
      "score is 0.9557802677154541, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\21.png\n",
      "score is 0.6505457758903503, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\22.png\n",
      "score is 0.9996594190597534, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\23.png\n",
      "score is 0.9919186234474182, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\24.png\n",
      "score is 0.9726133346557617, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\25.png\n",
      "score is 0.742480993270874, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\26.png\n",
      "score is 0.999988317489624, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\27.png\n",
      "score is 0.9940258264541626, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\28.png\n",
      "score is 0.9998745918273926, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\29.png\n",
      "score is 0.9998021721839905, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\3.png\n",
      "score is 0.810081422328949, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\4.png\n",
      "score is 0.9994995594024658, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\5.png\n",
      "score is 0.9965180158615112, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\6.png\n",
      "score is 0.9684982895851135, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\7.png\n",
      "score is 0.6569034457206726, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\8.png\n",
      "score is 0.7802168130874634, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_1\\9.png\n",
      "score is 0.8264366388320923, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\0.png\n",
      "score is 0.9891268610954285, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\1.png\n",
      "score is 0.4901491701602936, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\10.png\n",
      "score is 0.6597148180007935, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\11.png\n",
      "score is 0.9990413784980774, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\12.png\n",
      "score is 0.9732046723365784, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\13.png\n",
      "score is 0.9999979734420776, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\14.png\n",
      "score is 0.4429512023925781, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\15.png\n",
      "score is 0.8123624324798584, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\16.png\n",
      "score is 0.9179282784461975, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\17.png\n",
      "score is 0.9194958806037903, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\18.png\n",
      "score is 0.9567074775695801, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\19.png\n",
      "score is 0.7399555444717407, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\2.png\n",
      "score is 0.922114372253418, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\20.png\n",
      "score is 0.9999419450759888, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\21.png\n",
      "score is 0.9384894371032715, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\22.png\n",
      "score is 0.9999958276748657, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\23.png\n",
      "score is 0.9999563694000244, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\24.png\n",
      "score is 0.9995737671852112, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\25.png\n",
      "score is 0.7982686161994934, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\26.png\n",
      "score is 0.8747174143791199, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\27.png\n",
      "score is 0.9999939203262329, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\28.png\n",
      "score is 0.9901964664459229, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\29.png\n",
      "score is 0.9995404481887817, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\3.png\n",
      "score is 0.9999992847442627, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\4.png\n",
      "score is 0.5184280276298523, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\5.png\n",
      "score is 0.620787501335144, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\6.png\n",
      "score is 0.9385519027709961, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\7.png\n",
      "score is 0.9752826690673828, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\8.png\n",
      "score is 0.9999932050704956, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_2\\9.png\n",
      "score is 0.9429036974906921, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\0.png\n",
      "score is 0.9926751255989075, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\1.png\n",
      "score is 0.9976400136947632, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\10.png\n",
      "score is 0.9985783100128174, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\11.png\n",
      "score is 0.995372474193573, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\12.png\n",
      "score is 0.9839829206466675, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\13.png\n",
      "score is 0.5254060626029968, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\14.png\n",
      "score is 0.9999954700469971, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\15.png\n",
      "score is 0.9992963075637817, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\16.png\n",
      "score is 0.9999995231628418, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\17.png\n",
      "score is 0.9064125418663025, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\18.png\n",
      "score is 0.9999862909317017, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\19.png\n",
      "score is 0.8762010931968689, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\2.png\n",
      "score is 0.9999682903289795, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\20.png\n",
      "score is 0.5170594453811646, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\21.png\n",
      "score is 0.999090313911438, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\22.png\n",
      "score is 0.9999992847442627, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\23.png\n",
      "score is 0.893976628780365, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\24.png\n",
      "score is 0.999581515789032, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\25.png\n",
      "score is 0.7204679250717163, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\26.png\n",
      "score is 0.9752419590950012, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\27.png\n",
      "score is 0.6819618344306946, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\28.png\n",
      "score is 0.9999011754989624, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\29.png\n",
      "score is 0.9999905824661255, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\3.png\n",
      "score is 0.9973251819610596, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\4.png\n",
      "score is 0.9986326098442078, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\5.png\n",
      "score is 0.9999988079071045, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\6.png\n",
      "score is 0.7614315748214722, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\7.png\n",
      "score is 0.9939330220222473, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\8.png\n",
      "score is 0.9999294281005859, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [02:25, 53.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\B5MAwD\\B5MAwD_3\\9.png\n",
      "score is 0.9999444484710693, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\0.png\n",
      "score is 0.9999997615814209, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\1.png\n",
      "score is 0.9999771118164062, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\10.png\n",
      "score is 0.9999692440032959, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\11.png\n",
      "score is 0.5525096654891968, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\12.png\n",
      "score is 0.9995794892311096, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\13.png\n",
      "score is 0.9786983728408813, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\14.png\n",
      "score is 0.7472688555717468, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\15.png\n",
      "score is 0.9939633011817932, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\16.png\n",
      "score is 0.9996383190155029, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\17.png\n",
      "score is 0.4846997857093811, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\18.png\n",
      "score is 0.9980016350746155, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\19.png\n",
      "score is 0.9249601364135742, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\2.png\n",
      "score is 0.9617714285850525, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\20.png\n",
      "score is 1.0, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\21.png\n",
      "score is 0.7964754104614258, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\22.png\n",
      "score is 0.9999783039093018, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\23.png\n",
      "score is 0.966241717338562, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\24.png\n",
      "score is 0.8602849841117859, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\25.png\n",
      "score is 0.8981672525405884, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\26.png\n",
      "score is 0.9869035482406616, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\27.png\n",
      "score is 0.9888371229171753, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\28.png\n",
      "score is 0.9689485430717468, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\29.png\n",
      "score is 0.9810982942581177, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\3.png\n",
      "score is 0.859722912311554, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\4.png\n",
      "score is 0.7050641179084778, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\5.png\n",
      "score is 0.9623008966445923, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\6.png\n",
      "score is 0.9102246165275574, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\7.png\n",
      "score is 0.6317406892776489, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\8.png\n",
      "score is 0.9992234706878662, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_0\\9.png\n",
      "score is 0.9190832376480103, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\0.png\n",
      "score is 0.9272862672805786, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\1.png\n",
      "score is 0.9434807300567627, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\10.png\n",
      "score is 0.7376071214675903, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\11.png\n",
      "score is 0.9381179213523865, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\12.png\n",
      "score is 0.9894652366638184, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\13.png\n",
      "score is 0.976328432559967, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\14.png\n",
      "score is 0.9191930294036865, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\15.png\n",
      "score is 0.9575796127319336, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\16.png\n",
      "score is 0.9900749325752258, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\17.png\n",
      "score is 0.9941868782043457, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\18.png\n",
      "score is 0.9999719858169556, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\19.png\n",
      "score is 0.6224763989448547, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\2.png\n",
      "score is 0.9980547428131104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\20.png\n",
      "score is 0.9997418522834778, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\21.png\n",
      "score is 0.471832275390625, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\22.png\n",
      "score is 0.9999299049377441, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\23.png\n",
      "score is 0.9997397065162659, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\24.png\n",
      "score is 0.9974420070648193, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\25.png\n",
      "score is 0.9999520778656006, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\26.png\n",
      "score is 0.5673069357872009, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\27.png\n",
      "score is 0.8677694201469421, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\28.png\n",
      "score is 0.9630568027496338, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\29.png\n",
      "score is 0.9076312780380249, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\3.png\n",
      "score is 0.9999006986618042, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\4.png\n",
      "score is 0.8315081596374512, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\5.png\n",
      "score is 1.0, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\6.png\n",
      "score is 1.0, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\7.png\n",
      "score is 0.9317710399627686, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\8.png\n",
      "score is 0.5237551331520081, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_1\\9.png\n",
      "score is 0.976223349571228, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\0.png\n",
      "score is 0.9973170161247253, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\1.png\n",
      "score is 0.8109060525894165, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\10.png\n",
      "score is 0.7473886013031006, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\11.png\n",
      "score is 0.9866495728492737, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\12.png\n",
      "score is 0.9331708550453186, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\13.png\n",
      "score is 0.6081267595291138, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\14.png\n",
      "score is 0.560749351978302, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\15.png\n",
      "score is 0.7793810963630676, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\16.png\n",
      "score is 0.9245789647102356, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\17.png\n",
      "score is 0.8678200244903564, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\18.png\n",
      "score is 0.8382702469825745, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\19.png\n",
      "score is 0.9312586188316345, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\2.png\n",
      "score is 0.6970670819282532, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\20.png\n",
      "score is 0.5370710492134094, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\21.png\n",
      "score is 0.538880467414856, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\22.png\n",
      "score is 0.8885968923568726, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\23.png\n",
      "score is 0.9982233643531799, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\24.png\n",
      "score is 0.9948810338973999, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\25.png\n",
      "score is 0.7441047430038452, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\26.png\n",
      "score is 0.5545106530189514, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\27.png\n",
      "score is 0.5049245357513428, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\28.png\n",
      "score is 0.8737836480140686, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\29.png\n",
      "score is 0.5852944254875183, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\3.png\n",
      "score is 0.695526123046875, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\4.png\n",
      "score is 0.9463930130004883, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\5.png\n",
      "score is 0.8053377866744995, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\6.png\n",
      "score is 0.9355919361114502, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\7.png\n",
      "score is 0.6953298449516296, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\8.png\n",
      "score is 0.7499908208847046, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_2\\9.png\n",
      "score is 0.8541460633277893, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\0.png\n",
      "score is 0.9946416616439819, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\1.png\n",
      "score is 0.9994565844535828, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\10.png\n",
      "score is 0.43828055262565613, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\11.png\n",
      "score is 0.962357759475708, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\12.png\n",
      "score is 0.9999279975891113, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\13.png\n",
      "score is 0.9096401929855347, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\14.png\n",
      "score is 0.999976396560669, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\15.png\n",
      "score is 0.5707351565361023, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\16.png\n",
      "score is 0.9972018003463745, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\17.png\n",
      "score is 0.7285234332084656, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\18.png\n",
      "score is 0.9931584000587463, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\19.png\n",
      "score is 0.6307672262191772, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\2.png\n",
      "score is 0.929720938205719, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\20.png\n",
      "score is 0.9964996576309204, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\21.png\n",
      "score is 0.9503306746482849, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\22.png\n",
      "score is 0.9140533804893494, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\23.png\n",
      "score is 0.8180614113807678, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\24.png\n",
      "score is 0.5054556131362915, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\25.png\n",
      "score is 0.5589428544044495, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\26.png\n",
      "score is 0.8224596977233887, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\27.png\n",
      "score is 0.9626154899597168, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\28.png\n",
      "score is 0.8311640620231628, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\29.png\n",
      "score is 0.8595529198646545, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\3.png\n",
      "score is 0.7625869512557983, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\4.png\n",
      "score is 0.7716895937919617, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\5.png\n",
      "score is 0.9756596088409424, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\6.png\n",
      "score is 0.9966744184494019, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\7.png\n",
      "score is 0.9895869493484497, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\8.png\n",
      "score is 0.8052046298980713, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [03:28, 57.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\cRnBLx\\cRnBLx_3\\9.png\n",
      "score is 0.7678518295288086, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\0.png\n",
      "score is 0.996837854385376, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\1.png\n",
      "score is 0.718257486820221, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\10.png\n",
      "score is 0.9999874830245972, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\11.png\n",
      "score is 0.9995846152305603, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\12.png\n",
      "score is 0.6695634126663208, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\13.png\n",
      "score is 0.9855080246925354, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\14.png\n",
      "score is 0.6175596117973328, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\15.png\n",
      "score is 0.991975724697113, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\16.png\n",
      "score is 0.9167678356170654, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\17.png\n",
      "score is 0.8577471971511841, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\18.png\n",
      "score is 0.9987723231315613, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\19.png\n",
      "score is 0.9967034459114075, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\2.png\n",
      "score is 0.9998252987861633, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\20.png\n",
      "score is 0.7910017371177673, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\21.png\n",
      "score is 0.9996323585510254, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\22.png\n",
      "score is 0.7607204914093018, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\23.png\n",
      "score is 0.981200635433197, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\24.png\n",
      "score is 0.9108636379241943, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\25.png\n",
      "score is 0.9982162117958069, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\26.png\n",
      "score is 0.999505877494812, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\27.png\n",
      "score is 0.9945189356803894, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\28.png\n",
      "score is 0.5417813658714294, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\29.png\n",
      "score is 0.5060248374938965, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\3.png\n",
      "score is 0.8184654712677002, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\4.png\n",
      "score is 0.9957886338233948, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\5.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\6.png\n",
      "score is 0.9993877410888672, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\7.png\n",
      "score is 0.7478911876678467, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\8.png\n",
      "score is 0.8971822261810303, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [03:43, 42.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\gfozad\\gfozad_0\\9.png\n",
      "score is 0.9854352474212646, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\0.png\n",
      "score is 0.996338963508606, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\1.png\n",
      "score is 0.9997192025184631, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\10.png\n",
      "score is 0.8712741136550903, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\11.png\n",
      "score is 0.9583104848861694, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\12.png\n",
      "score is 0.6835066080093384, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\13.png\n",
      "score is 0.9976703524589539, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\14.png\n",
      "score is 0.9755464792251587, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\15.png\n",
      "score is 0.992989182472229, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\16.png\n",
      "score is 0.8485118746757507, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\17.png\n",
      "score is 0.9857826232910156, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\18.png\n",
      "score is 0.9600813388824463, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\19.png\n",
      "score is 0.730102002620697, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\2.png\n",
      "score is 0.928257167339325, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\20.png\n",
      "score is 0.6622331738471985, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\21.png\n",
      "score is 0.9148043990135193, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\22.png\n",
      "score is 0.999365508556366, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\23.png\n",
      "score is 0.9906743168830872, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\24.png\n",
      "score is 0.8727802634239197, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\25.png\n",
      "score is 0.9934155941009521, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\26.png\n",
      "score is 0.9923906922340393, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\27.png\n",
      "score is 0.5523898601531982, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\28.png\n",
      "score is 0.9577041268348694, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\29.png\n",
      "score is 0.823859691619873, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\3.png\n",
      "score is 0.887946367263794, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\4.png\n",
      "score is 0.9976130723953247, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\5.png\n",
      "score is 0.9648385047912598, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\6.png\n",
      "score is 0.999956488609314, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\7.png\n",
      "score is 0.9914180040359497, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\8.png\n",
      "score is 0.9908406138420105, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_0\\9.png\n",
      "score is 0.6186083555221558, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\0.png\n",
      "score is 0.9128401875495911, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\1.png\n",
      "score is 0.981261670589447, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\10.png\n",
      "score is 0.990342378616333, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\11.png\n",
      "score is 0.6301804780960083, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\12.png\n",
      "score is 0.9788506627082825, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\13.png\n",
      "score is 0.9917832612991333, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\14.png\n",
      "score is 0.8465420603752136, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\15.png\n",
      "score is 0.9981154203414917, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\16.png\n",
      "score is 0.9471825957298279, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\17.png\n",
      "score is 0.7605047225952148, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\18.png\n",
      "score is 0.9563538432121277, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\19.png\n",
      "score is 0.9864708781242371, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\2.png\n",
      "score is 0.4315502345561981, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\20.png\n",
      "score is 0.9991928935050964, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\21.png\n",
      "score is 0.9997100234031677, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\22.png\n",
      "score is 0.7351011633872986, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\23.png\n",
      "score is 0.8881562948226929, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\24.png\n",
      "score is 0.6812235116958618, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\25.png\n",
      "score is 0.9542126059532166, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\26.png\n",
      "score is 0.7730632424354553, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\27.png\n",
      "score is 0.9777237772941589, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\28.png\n",
      "score is 0.8598158955574036, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\29.png\n",
      "score is 0.9679632782936096, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\3.png\n",
      "score is 0.9977136850357056, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\4.png\n",
      "score is 0.9828124642372131, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\5.png\n",
      "score is 0.896135687828064, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\6.png\n",
      "score is 0.9526813626289368, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\7.png\n",
      "score is 0.6992442607879639, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\8.png\n",
      "score is 0.9973394274711609, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [04:14, 38.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\i0v7lq\\i0v7lq_1\\9.png\n",
      "score is 0.8552036285400391, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\0.png\n",
      "score is 0.9973312616348267, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\1.png\n",
      "score is 0.991786539554596, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\10.png\n",
      "score is 0.4676183760166168, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\11.png\n",
      "score is 0.9993426203727722, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\12.png\n",
      "score is 0.9081445336341858, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\13.png\n",
      "score is 0.9181102514266968, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\14.png\n",
      "score is 0.9981325268745422, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\15.png\n",
      "score is 0.9246271848678589, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\16.png\n",
      "score is 0.8279057741165161, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\17.png\n",
      "score is 0.8408503532409668, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\18.png\n",
      "score is 0.9979642629623413, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\19.png\n",
      "score is 0.9978716373443604, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\2.png\n",
      "score is 0.8953109383583069, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\20.png\n",
      "score is 0.9467211961746216, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\21.png\n",
      "score is 0.9653909206390381, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\22.png\n",
      "score is 0.6411145329475403, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\23.png\n",
      "score is 0.5313669443130493, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\24.png\n",
      "score is 0.9832736253738403, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\25.png\n",
      "score is 0.9807844161987305, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\26.png\n",
      "score is 0.9253442883491516, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\27.png\n",
      "score is 0.7614502906799316, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\28.png\n",
      "score is 0.6603970527648926, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\29.png\n",
      "score is 0.8751412034034729, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\3.png\n",
      "score is 0.8102466464042664, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\4.png\n",
      "score is 0.588877260684967, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\5.png\n",
      "score is 0.74128657579422, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\6.png\n",
      "score is 0.7619173526763916, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\7.png\n",
      "score is 0.7453728318214417, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\8.png\n",
      "score is 0.5378115177154541, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_0\\9.png\n",
      "score is 0.8574312329292297, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\0.png\n",
      "score is 0.7498130202293396, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\1.png\n",
      "score is 0.874295175075531, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\10.png\n",
      "score is 0.6576720476150513, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\11.png\n",
      "score is 0.873764157295227, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\12.png\n",
      "score is 0.9959665536880493, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\13.png\n",
      "score is 0.9119181036949158, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\14.png\n",
      "score is 0.9189760088920593, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\15.png\n",
      "score is 0.6636399030685425, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\16.png\n",
      "score is 0.9987385869026184, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\17.png\n",
      "score is 0.9504604339599609, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\18.png\n",
      "score is 0.6681194305419922, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\19.png\n",
      "score is 0.9929008483886719, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\2.png\n",
      "score is 0.8213050961494446, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\20.png\n",
      "score is 0.924677312374115, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\21.png\n",
      "score is 0.9920931458473206, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\22.png\n",
      "score is 0.9968530535697937, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\23.png\n",
      "score is 0.5284699201583862, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\24.png\n",
      "score is 0.9886852502822876, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\25.png\n",
      "score is 0.9203265309333801, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\26.png\n",
      "score is 0.9097283482551575, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\27.png\n",
      "score is 0.5590397715568542, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\28.png\n",
      "score is 0.6423613429069519, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\29.png\n",
      "score is 0.5195581316947937, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\3.png\n",
      "score is 0.9970532655715942, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\4.png\n",
      "score is 0.9138084650039673, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\5.png\n",
      "score is 0.9992020726203918, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\6.png\n",
      "score is 0.6195086240768433, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\7.png\n",
      "score is 0.9805721044540405, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\8.png\n",
      "score is 0.8480033874511719, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [04:45, 35.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\iQUs4h\\iQUs4h_1\\9.png\n",
      "score is 0.7771251201629639, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\0.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\10.png\n",
      "score is 0.960258960723877, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\11.png\n",
      "score is 0.8950247764587402, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\12.png\n",
      "score is 0.5068766474723816, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\13.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\14.png\n",
      "score is 0.7290904521942139, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\15.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\16.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\17.png\n",
      "score is 0.7297940254211426, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\18.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\19.png\n",
      "score is 0.9145806431770325, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\2.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\20.png\n",
      "score is 0.9646087288856506, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\21.png\n",
      "score is 0.9999980926513672, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\22.png\n",
      "score is 0.99907386302948, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\24.png\n",
      "score is 0.7156442403793335, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\25.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\26.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\27.png\n",
      "score is 0.9999992847442627, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\28.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\29.png\n",
      "score is 0.5189020037651062, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\3.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\4.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\5.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\6.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\7.png\n",
      "score is 0.9473224878311157, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\8.png\n",
      "score is 0.9688760042190552, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_0\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\0.png\n",
      "score is 0.9371246695518494, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\1.png\n",
      "score is 0.5371399521827698, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\10.png\n",
      "score is 0.6182457208633423, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\11.png\n",
      "score is 0.7922641038894653, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\12.png\n",
      "score is 0.7489708662033081, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\13.png\n",
      "score is 0.8362039923667908, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\14.png\n",
      "score is 0.8784685730934143, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\15.png\n",
      "score is 0.875663697719574, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\16.png\n",
      "score is 0.8980896472930908, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\17.png\n",
      "score is 0.5703571438789368, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\18.png\n",
      "score is 0.8954994082450867, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\19.png\n",
      "score is 0.5648075938224792, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\2.png\n",
      "score is 0.8957424163818359, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\20.png\n",
      "score is 0.9781714081764221, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\21.png\n",
      "score is 0.9460290670394897, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\22.png\n",
      "score is 0.923895001411438, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\23.png\n",
      "score is 0.5600630044937134, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\24.png\n",
      "score is 0.9174956679344177, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\25.png\n",
      "score is 0.8546028137207031, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\26.png\n",
      "score is 0.7013828158378601, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\27.png\n",
      "score is 0.9646503329277039, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\28.png\n",
      "score is 0.9514970183372498, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\29.png\n",
      "score is 0.8171878457069397, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\3.png\n",
      "score is 0.917240560054779, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\4.png\n",
      "score is 0.9714644551277161, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\5.png\n",
      "score is 0.8036842346191406, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\6.png\n",
      "score is 0.8230357766151428, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\7.png\n",
      "score is 0.9650097489356995, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\8.png\n",
      "score is 0.9910050630569458, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_1\\9.png\n",
      "score is 0.7185969352722168, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\0.png\n",
      "score is 0.9766784310340881, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\1.png\n",
      "score is 0.7946283221244812, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\10.png\n",
      "score is 0.8408733606338501, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\11.png\n",
      "score is 0.5739438533782959, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\12.png\n",
      "score is 0.5932630896568298, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\13.png\n",
      "score is 0.9394380450248718, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\14.png\n",
      "score is 0.9690779447555542, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\15.png\n",
      "score is 0.8886977434158325, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\16.png\n",
      "score is 0.9403495192527771, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\17.png\n",
      "score is 0.6782081127166748, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\18.png\n",
      "score is 0.5610226392745972, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\19.png\n",
      "score is 0.9749085307121277, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\2.png\n",
      "score is 0.9402319192886353, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\20.png\n",
      "score is 0.821864128112793, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\21.png\n",
      "score is 0.8014886379241943, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\22.png\n",
      "score is 0.942668080329895, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\23.png\n",
      "score is 0.5028231739997864, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\24.png\n",
      "score is 0.9058672785758972, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\25.png\n",
      "score is 0.5697698593139648, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\26.png\n",
      "score is 0.9282587170600891, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\27.png\n",
      "score is 0.6975026726722717, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\28.png\n",
      "score is 0.7004767656326294, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\29.png\n",
      "score is 0.7471311092376709, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\3.png\n",
      "score is 0.5774989724159241, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\4.png\n",
      "score is 0.6345494389533997, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\5.png\n",
      "score is 0.7727689146995544, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\6.png\n",
      "score is 0.8821647763252258, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\7.png\n",
      "score is 0.9870866537094116, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\8.png\n",
      "score is 0.9733152389526367, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [05:31, 39.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Jw1GFk\\Jw1GFk_2\\9.png\n",
      "score is 0.4992353618144989, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\0.png\n",
      "score is 0.9998310804367065, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\1.png\n",
      "score is 0.999900221824646, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\10.png\n",
      "score is 0.9362527132034302, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\11.png\n",
      "score is 0.9994896650314331, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\12.png\n",
      "score is 0.9998598098754883, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\13.png\n",
      "score is 0.9993067979812622, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\14.png\n",
      "score is 0.9992245435714722, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\15.png\n",
      "score is 0.9995236396789551, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\16.png\n",
      "score is 0.9999945163726807, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\17.png\n",
      "score is 0.9997344613075256, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\18.png\n",
      "score is 0.9984825253486633, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\19.png\n",
      "score is 0.8507363200187683, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\2.png\n",
      "score is 0.9994542002677917, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\20.png\n",
      "score is 0.9990717172622681, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\21.png\n",
      "score is 0.9542202949523926, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\22.png\n",
      "score is 0.9999957084655762, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\23.png\n",
      "score is 0.9999765157699585, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\24.png\n",
      "score is 0.9758287072181702, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\25.png\n",
      "score is 0.9999740123748779, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\26.png\n",
      "score is 0.8688377737998962, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\27.png\n",
      "score is 0.9996533393859863, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\28.png\n",
      "score is 0.9993593096733093, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\29.png\n",
      "score is 0.9999635219573975, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\3.png\n",
      "score is 0.9922131896018982, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\4.png\n",
      "score is 0.9993321299552917, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\5.png\n",
      "score is 0.9999988079071045, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\6.png\n",
      "score is 0.7006006240844727, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\7.png\n",
      "score is 0.9999762773513794, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\8.png\n",
      "score is 0.9999889135360718, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_0\\9.png\n",
      "score is 0.9999436140060425, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\0.png\n",
      "score is 0.9999958276748657, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\1.png\n",
      "score is 0.9997665286064148, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\10.png\n",
      "score is 0.9998167157173157, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\11.png\n",
      "score is 0.9999959468841553, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\12.png\n",
      "score is 0.978847324848175, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\13.png\n",
      "score is 0.9812371134757996, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\14.png\n",
      "score is 0.8730754256248474, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\15.png\n",
      "score is 0.6262608766555786, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\16.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\17.png\n",
      "score is 0.9999996423721313, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\18.png\n",
      "score is 0.8684274554252625, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\19.png\n",
      "score is 0.9855798482894897, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\2.png\n",
      "score is 0.9999843835830688, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\20.png\n",
      "score is 0.9999812841415405, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\21.png\n",
      "score is 0.9999961853027344, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\22.png\n",
      "score is 0.9997379183769226, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\23.png\n",
      "score is 0.9995988011360168, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\24.png\n",
      "score is 0.9994171857833862, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\25.png\n",
      "score is 0.9999980926513672, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\26.png\n",
      "score is 0.9999823570251465, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\27.png\n",
      "score is 0.9872803092002869, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\28.png\n",
      "score is 0.988146960735321, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\29.png\n",
      "score is 0.9998738765716553, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\3.png\n",
      "score is 0.9441090226173401, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\4.png\n",
      "score is 0.9999916553497314, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\5.png\n",
      "score is 0.9994344115257263, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\6.png\n",
      "score is 0.9912449717521667, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\7.png\n",
      "score is 0.9998156428337097, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\8.png\n",
      "score is 0.9864251613616943, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\K2f9Nb\\K2f9Nb_1\\9.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [06:03, 36.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score is 0.9996082186698914, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\0.png\n",
      "score is 0.6699284315109253, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\10.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\11.png\n",
      "score is 0.5064440965652466, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\12.png\n",
      "score is 0.9973306655883789, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\13.png\n",
      "score is 0.7238948345184326, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\14.png\n",
      "score is 0.9269919395446777, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\15.png\n",
      "score is 0.7603951692581177, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\16.png\n",
      "score is 0.8669118881225586, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\17.png\n",
      "score is 0.570128321647644, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\18.png\n",
      "score is 0.6056715846061707, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\19.png\n",
      "score is 0.9998831748962402, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\2.png\n",
      "score is 0.9999982118606567, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\20.png\n",
      "score is 0.9407365322113037, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\21.png\n",
      "score is 0.7467864751815796, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\22.png\n",
      "score is 0.9987016916275024, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\23.png\n",
      "score is 0.8130971789360046, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\24.png\n",
      "score is 0.9406247138977051, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\25.png\n",
      "score is 0.707205057144165, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\26.png\n",
      "score is 0.9957718253135681, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\27.png\n",
      "score is 0.7245085835456848, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\28.png\n",
      "score is 0.9787798523902893, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\29.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\3.png\n",
      "score is 0.9038525223731995, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\4.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\5.png\n",
      "score is 0.9999804496765137, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\6.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\7.png\n",
      "score is 0.9408777356147766, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\8.png\n",
      "score is 0.8977070450782776, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_0\\9.png\n",
      "score is 0.9795511960983276, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\0.png\n",
      "score is 0.9787724018096924, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\1.png\n",
      "score is 0.8935400247573853, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\10.png\n",
      "score is 0.9591851234436035, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\11.png\n",
      "score is 0.6211200952529907, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\12.png\n",
      "score is 0.9561494588851929, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\13.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\14.png\n",
      "score is 0.9972372055053711, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\15.png\n",
      "score is 0.9049282670021057, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\16.png\n",
      "score is 0.7503908276557922, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\17.png\n",
      "score is 0.9247379899024963, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\18.png\n",
      "score is 0.614581823348999, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\19.png\n",
      "score is 0.567322850227356, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\2.png\n",
      "score is 0.9999982118606567, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\20.png\n",
      "score is 0.7693591117858887, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\21.png\n",
      "score is 0.7794790863990784, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\22.png\n",
      "score is 0.6863656044006348, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\23.png\n",
      "score is 0.8426124453544617, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\24.png\n",
      "score is 0.7246233820915222, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\25.png\n",
      "score is 0.9342115521430969, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\26.png\n",
      "score is 0.7371551990509033, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\27.png\n",
      "score is 0.6659387350082397, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\28.png\n",
      "score is 0.9155923128128052, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\29.png\n",
      "score is 0.9902717471122742, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\3.png\n",
      "score is 0.6429669857025146, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\4.png\n",
      "score is 0.9674406051635742, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\5.png\n",
      "score is 0.9885178804397583, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\6.png\n",
      "score is 0.8554970622062683, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\7.png\n",
      "score is 0.6511685848236084, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\8.png\n",
      "score is 0.9110077619552612, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_1\\9.png\n",
      "score is 0.8692262768745422, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\0.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\10.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\11.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\12.png\n",
      "score is 0.9914171099662781, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\13.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\15.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\16.png\n",
      "score is 0.9524847865104675, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\17.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\18.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\19.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\2.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\20.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\21.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\22.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\24.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\25.png\n",
      "score is 0.9995325803756714, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\26.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\27.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\28.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\29.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\3.png\n",
      "score is 0.9982328414916992, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\4.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\5.png\n",
      "score is 0.992620050907135, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\6.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\7.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\8.png\n",
      "score is 0.9191832542419434, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_2\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\0.png\n",
      "score is 0.9999983310699463, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\1.png\n",
      "score is 0.9060826897621155, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\10.png\n",
      "score is 0.9999364614486694, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\11.png\n",
      "score is 0.9999768733978271, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\12.png\n",
      "score is 0.8965247273445129, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\13.png\n",
      "score is 0.9998841285705566, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\14.png\n",
      "score is 0.9694476127624512, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\15.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\16.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\17.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\18.png\n",
      "score is 0.991587221622467, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\19.png\n",
      "score is 0.971384584903717, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\2.png\n",
      "score is 0.7236207723617554, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\20.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\21.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\22.png\n",
      "score is 0.9704431891441345, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\24.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\25.png\n",
      "score is 0.9726927280426025, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\26.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\27.png\n",
      "score is 0.8142129182815552, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\28.png\n",
      "score is 0.9822738766670227, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\29.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\3.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\4.png\n",
      "score is 0.9587817788124084, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\5.png\n",
      "score is 0.9380304217338562, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\6.png\n",
      "score is 0.9999982118606567, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\7.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\8.png\n",
      "score is 0.9996187686920166, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [07:04, 44.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kOUcud\\kOUcud_3\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\0.png\n",
      "score is 0.9946056008338928, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\1.png\n",
      "score is 0.9999983310699463, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\10.png\n",
      "score is 0.5949549078941345, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\11.png\n",
      "score is 0.9707342982292175, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\12.png\n",
      "score is 0.5026379227638245, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\13.png\n",
      "score is 0.7013282775878906, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\14.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\15.png\n",
      "score is 0.7862125039100647, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\16.png\n",
      "score is 0.9680852890014648, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\17.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\18.png\n",
      "score is 0.9981548190116882, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\19.png\n",
      "score is 0.6981640458106995, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\2.png\n",
      "score is 0.6137039661407471, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\20.png\n",
      "score is 0.7726868391036987, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\21.png\n",
      "score is 0.9998841285705566, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\22.png\n",
      "score is 0.9999994039535522, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\23.png\n",
      "score is 0.725951075553894, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\24.png\n",
      "score is 0.9510924816131592, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\25.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\26.png\n",
      "score is 0.9677417278289795, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\27.png\n",
      "score is 0.9999995231628418, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\28.png\n",
      "score is 0.9180673360824585, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\29.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\3.png\n",
      "score is 0.74468594789505, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\4.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\5.png\n",
      "score is 0.7254565358161926, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\6.png\n",
      "score is 0.982067883014679, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\7.png\n",
      "score is 0.8741392493247986, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\8.png\n",
      "score is 0.966315507888794, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_0\\9.png\n",
      "score is 0.9989094734191895, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\0.png\n",
      "score is 0.9057734608650208, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\1.png\n",
      "score is 0.9999366998672485, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\10.png\n",
      "score is 0.9948683977127075, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\11.png\n",
      "score is 0.9951797723770142, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\12.png\n",
      "score is 0.9641611576080322, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\13.png\n",
      "score is 0.9934677481651306, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\14.png\n",
      "score is 0.9988579750061035, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\15.png\n",
      "score is 0.975456714630127, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\16.png\n",
      "score is 0.9907141923904419, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\17.png\n",
      "score is 0.9879963994026184, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\18.png\n",
      "score is 0.5044739842414856, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\19.png\n",
      "score is 0.972292959690094, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\2.png\n",
      "score is 0.9945405125617981, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\20.png\n",
      "score is 0.9703369736671448, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\21.png\n",
      "score is 0.6266008019447327, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\22.png\n",
      "score is 0.9679397344589233, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\23.png\n",
      "score is 0.8550465106964111, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\24.png\n",
      "score is 0.9597658514976501, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\25.png\n",
      "score is 0.9984819293022156, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\26.png\n",
      "score is 0.9958242177963257, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\27.png\n",
      "score is 0.8748577833175659, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\28.png\n",
      "score is 0.9999896287918091, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\29.png\n",
      "score is 0.8615749478340149, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\3.png\n",
      "score is 0.5335828065872192, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\4.png\n",
      "score is 0.5993409156799316, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\5.png\n",
      "score is 0.736238956451416, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\6.png\n",
      "score is 0.8523807525634766, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\7.png\n",
      "score is 0.8335375189781189, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\8.png\n",
      "score is 0.993800938129425, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_1\\9.png\n",
      "score is 0.9921809434890747, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\0.png\n",
      "score is 0.81626957654953, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\1.png\n",
      "score is 0.7930313348770142, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\10.png\n",
      "score is 0.6379432082176208, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\11.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\12.png\n",
      "score is 0.9999991655349731, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\13.png\n",
      "score is 0.7033312320709229, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\14.png\n",
      "score is 0.9662542939186096, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\15.png\n",
      "score is 0.9964989423751831, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\16.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\17.png\n",
      "score is 0.8961822986602783, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\18.png\n",
      "score is 0.9124667644500732, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\19.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\2.png\n",
      "score is 0.7821152210235596, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\20.png\n",
      "score is 0.9980940222740173, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\21.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\22.png\n",
      "score is 0.7120974659919739, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\23.png\n",
      "score is 0.5765853524208069, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\24.png\n",
      "score is 0.6754828095436096, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\25.png\n",
      "score is 0.9999020099639893, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\26.png\n",
      "score is 0.9931582808494568, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\27.png\n",
      "score is 0.6481804847717285, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\28.png\n",
      "score is 0.9981198906898499, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\29.png\n",
      "score is 0.8600913882255554, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\3.png\n",
      "score is 0.9984544515609741, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\4.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\5.png\n",
      "score is 0.9959734082221985, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\6.png\n",
      "score is 0.9999995231628418, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\7.png\n",
      "score is 0.8338269591331482, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\8.png\n",
      "score is 0.9812670946121216, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_2\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\0.png\n",
      "score is 0.997093677520752, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\1.png\n",
      "score is 0.5479481220245361, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\10.png\n",
      "score is 0.9943966865539551, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\11.png\n",
      "score is 0.9754094481468201, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\12.png\n",
      "score is 0.7547256350517273, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\13.png\n",
      "score is 0.9591688513755798, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\14.png\n",
      "score is 0.9988844990730286, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\15.png\n",
      "score is 0.6340399384498596, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\16.png\n",
      "score is 0.5120126605033875, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\17.png\n",
      "score is 0.9629651308059692, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\18.png\n",
      "score is 0.8619124889373779, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\19.png\n",
      "score is 0.8655002117156982, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\2.png\n",
      "score is 0.9999295473098755, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\20.png\n",
      "score is 0.9992985725402832, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\21.png\n",
      "score is 0.786912739276886, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\22.png\n",
      "score is 0.9996168613433838, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\23.png\n",
      "score is 0.9835641384124756, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\24.png\n",
      "score is 0.9266108274459839, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\25.png\n",
      "score is 0.6095610857009888, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\26.png\n",
      "score is 0.9992892742156982, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\27.png\n",
      "score is 0.9329162240028381, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\28.png\n",
      "score is 0.997240424156189, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\29.png\n",
      "score is 0.8869436979293823, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\3.png\n",
      "score is 0.6643874645233154, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\4.png\n",
      "score is 0.7200552225112915, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\5.png\n",
      "score is 0.6830613017082214, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\6.png\n",
      "score is 0.9998352527618408, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\7.png\n",
      "score is 0.9849169850349426, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\8.png\n",
      "score is 0.9679295420646667, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [08:06, 49.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\kQPIhs\\kQPIhs_3\\9.png\n",
      "score is 0.6782970428466797, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\0.png\n",
      "score is 0.9986660480499268, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\1.png\n",
      "score is 0.8211320638656616, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\10.png\n",
      "score is 0.9975971579551697, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\11.png\n",
      "score is 0.8688457012176514, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\12.png\n",
      "score is 0.8427842259407043, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\13.png\n",
      "score is 0.8325811624526978, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\14.png\n",
      "score is 0.8677728176116943, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\15.png\n",
      "score is 0.7226347923278809, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\16.png\n",
      "score is 0.9992361068725586, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\17.png\n",
      "score is 0.913633406162262, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\18.png\n",
      "score is 0.9962175488471985, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\19.png\n",
      "score is 0.7140283584594727, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\2.png\n",
      "score is 0.997343122959137, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\20.png\n",
      "score is 0.9999035596847534, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\21.png\n",
      "score is 0.9046050310134888, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\22.png\n",
      "score is 0.8729068636894226, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\23.png\n",
      "score is 0.5158344507217407, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\24.png\n",
      "score is 0.9893134236335754, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\25.png\n",
      "score is 0.9965041875839233, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\26.png\n",
      "score is 0.6994307637214661, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\27.png\n",
      "score is 0.9985491633415222, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\28.png\n",
      "score is 0.955524742603302, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\29.png\n",
      "score is 0.9277241826057434, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\3.png\n",
      "score is 0.5630365014076233, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\4.png\n",
      "score is 0.7019577622413635, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\5.png\n",
      "score is 0.6178930997848511, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\6.png\n",
      "score is 0.6750180721282959, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\7.png\n",
      "score is 0.9427292943000793, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\8.png\n",
      "score is 0.7731170058250427, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_0\\9.png\n",
      "score is 0.850858747959137, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\0.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\10.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\11.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\12.png\n",
      "score is 0.9862169027328491, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\13.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\15.png\n",
      "score is 0.9871460199356079, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\16.png\n",
      "score is 0.9228941798210144, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\17.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\18.png\n",
      "score is 0.9859528541564941, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\19.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\2.png\n",
      "score is 0.7603697180747986, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\20.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\21.png\n",
      "score is 0.9414013624191284, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\22.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\23.png\n",
      "score is 0.9649099707603455, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\24.png\n",
      "score is 0.9999268054962158, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\25.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\26.png\n",
      "score is 0.9999997615814209, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\27.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\28.png\n",
      "score is 0.9806428551673889, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\29.png\n",
      "score is 0.9996645450592041, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\3.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\4.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\5.png\n",
      "score is 0.9901492595672607, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\6.png\n",
      "score is 0.6170909404754639, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\7.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\8.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_1\\9.png\n",
      "score is 0.9754654765129089, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\0.png\n",
      "score is 0.8147875070571899, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\10.png\n",
      "score is 0.9480491280555725, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\11.png\n",
      "score is 0.9032993912696838, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\12.png\n",
      "score is 0.5249674916267395, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\13.png\n",
      "score is 0.920416533946991, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\15.png\n",
      "score is 0.9187281131744385, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\16.png\n",
      "score is 0.984880805015564, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\17.png\n",
      "score is 0.6951583027839661, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\18.png\n",
      "score is 0.9477444887161255, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\19.png\n",
      "score is 0.8737425208091736, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\2.png\n",
      "score is 0.9992986917495728, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\20.png\n",
      "score is 0.9999825954437256, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\21.png\n",
      "score is 0.9304744005203247, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\22.png\n",
      "score is 0.717018187046051, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\23.png\n",
      "score is 0.7024937868118286, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\24.png\n",
      "score is 0.9588992595672607, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\25.png\n",
      "score is 0.8882936239242554, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\26.png\n",
      "score is 0.9028893113136292, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\27.png\n",
      "score is 0.9995809197425842, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\28.png\n",
      "score is 0.8959003686904907, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\29.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\3.png\n",
      "score is 0.8720267415046692, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\4.png\n",
      "score is 0.9999867677688599, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\5.png\n",
      "score is 0.661604642868042, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\6.png\n",
      "score is 0.7756720781326294, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\7.png\n",
      "score is 0.7343528270721436, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\8.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_2\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\0.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\10.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\11.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\12.png\n",
      "score is 0.9999468326568604, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\13.png\n",
      "score is 0.819075882434845, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\14.png\n",
      "score is 0.7162546515464783, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\15.png\n",
      "score is 0.9966700673103333, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\16.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\17.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\18.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\19.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\2.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\20.png\n",
      "score is 0.9999793767929077, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\21.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\22.png\n",
      "score is 0.8402219414710999, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\24.png\n",
      "score is 0.9968481659889221, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\25.png\n",
      "score is 0.519731342792511, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\26.png\n",
      "score is 0.9999542236328125, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\27.png\n",
      "score is 0.9999831914901733, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\28.png\n",
      "score is 0.9723595380783081, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\29.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\3.png\n",
      "score is 0.99967360496521, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\4.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\5.png\n",
      "score is 0.9992859959602356, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\6.png\n",
      "score is 0.9999685287475586, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\7.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\8.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [09:09, 53.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\KRuNrD\\KRuNrD_3\\9.png\n",
      "score is 0.9138814210891724, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\0.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\1.png\n",
      "score is 0.8210806250572205, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\10.png\n",
      "score is 0.9215535521507263, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\11.png\n",
      "score is 0.6047955751419067, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\12.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\13.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\15.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\16.png\n",
      "score is 0.9765720963478088, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\17.png\n",
      "score is 0.8804870843887329, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\18.png\n",
      "score is 0.9999735355377197, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\19.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\2.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\20.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\21.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\22.png\n",
      "score is 0.8842283487319946, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\24.png\n",
      "score is 0.9953765869140625, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\25.png\n",
      "score is 0.9957114458084106, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\26.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\27.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\28.png\n",
      "score is 0.9999641180038452, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\29.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\3.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\4.png\n",
      "score is 0.907055675983429, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\5.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\6.png\n",
      "score is 0.8758369088172913, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\7.png\n",
      "score is 0.8445253968238831, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\8.png\n",
      "score is 0.7667176723480225, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_0\\9.png\n",
      "score is 0.9689738154411316, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\0.png\n",
      "score is 0.8702781200408936, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\1.png\n",
      "score is 0.9622932076454163, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\10.png\n",
      "score is 0.8661568760871887, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\11.png\n",
      "score is 0.7145813703536987, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\12.png\n",
      "score is 0.5432997345924377, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\13.png\n",
      "score is 0.9054728150367737, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\14.png\n",
      "score is 0.8894762396812439, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\15.png\n",
      "score is 0.6536968350410461, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\16.png\n",
      "score is 0.6844519972801208, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\17.png\n",
      "score is 0.6956018805503845, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\18.png\n",
      "score is 0.6090462803840637, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\19.png\n",
      "score is 0.9825341105461121, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\2.png\n",
      "score is 0.7346628308296204, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\20.png\n",
      "score is 0.7520065903663635, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\21.png\n",
      "score is 0.6541804671287537, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\22.png\n",
      "score is 0.9400092959403992, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\23.png\n",
      "score is 0.5728287696838379, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\24.png\n",
      "score is 0.5933837890625, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\25.png\n",
      "score is 0.9591327905654907, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\26.png\n",
      "score is 0.9385194778442383, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\27.png\n",
      "score is 0.9005375504493713, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\28.png\n",
      "score is 0.9996108412742615, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\29.png\n",
      "score is 0.9944785833358765, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\3.png\n",
      "score is 0.9655205011367798, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\4.png\n",
      "score is 0.6523407697677612, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\5.png\n",
      "score is 0.9015977382659912, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\6.png\n",
      "score is 0.5939272046089172, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\7.png\n",
      "score is 0.6907159686088562, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\8.png\n",
      "score is 0.8757584095001221, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [09:39, 46.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lc3OZp\\lc3OZp_1\\9.png\n",
      "score is 0.6682373285293579, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\0.png\n",
      "score is 0.8231122493743896, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\1.png\n",
      "score is 0.932857871055603, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\10.png\n",
      "score is 0.9998629093170166, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\11.png\n",
      "score is 0.9532797336578369, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\12.png\n",
      "score is 0.9162647128105164, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\13.png\n",
      "score is 0.9701398015022278, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\14.png\n",
      "score is 0.9996486902236938, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\15.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\16.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\17.png\n",
      "score is 0.6440741419792175, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\18.png\n",
      "score is 0.8337598443031311, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\19.png\n",
      "score is 0.8528812527656555, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\2.png\n",
      "score is 0.8384655714035034, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\20.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\21.png\n",
      "score is 0.7761226296424866, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\22.png\n",
      "score is 0.8421639204025269, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\24.png\n",
      "score is 0.998365581035614, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\25.png\n",
      "score is 0.7838245034217834, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\26.png\n",
      "score is 0.8210859894752502, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\27.png\n",
      "score is 0.7877457141876221, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\28.png\n",
      "score is 0.8939146995544434, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\29.png\n",
      "score is 0.9989135265350342, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\3.png\n",
      "score is 0.9225031733512878, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\4.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\5.png\n",
      "score is 0.8747898936271667, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\6.png\n",
      "score is 0.9999997615814209, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\7.png\n",
      "score is 0.8606656789779663, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\8.png\n",
      "score is 0.600188672542572, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_0\\9.png\n",
      "score is 0.9999985694885254, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\0.png\n",
      "score is 0.7758469581604004, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\1.png\n",
      "score is 0.8319104909896851, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\10.png\n",
      "score is 0.8576208353042603, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\11.png\n",
      "score is 0.8417737483978271, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\12.png\n",
      "score is 0.5906930565834045, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\13.png\n",
      "score is 0.9779898524284363, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\14.png\n",
      "score is 0.8380221724510193, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\15.png\n",
      "score is 0.8274592161178589, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\16.png\n",
      "score is 0.8160393834114075, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\17.png\n",
      "score is 0.6330193877220154, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\18.png\n",
      "score is 0.7765867114067078, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\19.png\n",
      "score is 0.6795065999031067, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\2.png\n",
      "score is 0.8270899057388306, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\20.png\n",
      "score is 0.9613349437713623, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\21.png\n",
      "score is 0.5490385293960571, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\22.png\n",
      "score is 0.9786884784698486, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\23.png\n",
      "score is 0.7951592206954956, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\24.png\n",
      "score is 0.9790104627609253, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\25.png\n",
      "score is 0.5365203022956848, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\26.png\n",
      "score is 0.7311540842056274, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\27.png\n",
      "score is 0.6712647676467896, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\28.png\n",
      "score is 0.4952484965324402, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\29.png\n",
      "score is 0.8597094416618347, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\3.png\n",
      "score is 0.6790206432342529, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\4.png\n",
      "score is 0.9081774353981018, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\5.png\n",
      "score is 0.8428986072540283, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\6.png\n",
      "score is 0.6802545189857483, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\7.png\n",
      "score is 0.8170111179351807, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\8.png\n",
      "score is 0.533030092716217, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_1\\9.png\n",
      "score is 0.9353944659233093, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\0.png\n",
      "score is 0.92103111743927, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\1.png\n",
      "score is 0.9015302062034607, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\10.png\n",
      "score is 0.9876999855041504, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\11.png\n",
      "score is 0.7364854216575623, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\12.png\n",
      "score is 0.9999735355377197, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\13.png\n",
      "score is 0.9596086144447327, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\14.png\n",
      "score is 0.47557517886161804, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\15.png\n",
      "score is 0.6321061253547668, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\16.png\n",
      "score is 0.9858185648918152, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\17.png\n",
      "score is 0.9998117089271545, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\18.png\n",
      "score is 0.9450681209564209, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\19.png\n",
      "score is 0.9994031190872192, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\2.png\n",
      "score is 0.9996410608291626, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\20.png\n",
      "score is 0.8847728967666626, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\21.png\n",
      "score is 0.8188397288322449, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\22.png\n",
      "score is 0.6164612174034119, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\23.png\n",
      "score is 0.9375342130661011, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\24.png\n",
      "score is 0.9988273978233337, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\25.png\n",
      "score is 0.8994730710983276, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\26.png\n",
      "score is 0.9685429930686951, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\27.png\n",
      "score is 0.9995806813240051, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\28.png\n",
      "score is 0.9994163513183594, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\29.png\n",
      "score is 0.9916969537734985, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\3.png\n",
      "score is 0.6015212535858154, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\4.png\n",
      "score is 0.7644762396812439, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\5.png\n",
      "score is 0.9260603785514832, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\6.png\n",
      "score is 0.9960517287254333, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\7.png\n",
      "score is 0.9882562756538391, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\8.png\n",
      "score is 0.9383507370948792, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_2\\9.png\n",
      "score is 0.9671977758407593, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\0.png\n",
      "score is 0.6781104803085327, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\1.png\n",
      "score is 0.5784153938293457, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\10.png\n",
      "score is 0.8312054872512817, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\11.png\n",
      "score is 0.863573431968689, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\12.png\n",
      "score is 0.6531989574432373, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\13.png\n",
      "score is 0.7950621843338013, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\14.png\n",
      "score is 0.6497931480407715, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\15.png\n",
      "score is 0.8793516159057617, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\16.png\n",
      "score is 0.695827066898346, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\17.png\n",
      "score is 0.5776661038398743, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\18.png\n",
      "score is 0.967571496963501, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\19.png\n",
      "score is 0.543233335018158, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\2.png\n",
      "score is 0.999974250793457, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\20.png\n",
      "score is 0.6875927448272705, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\21.png\n",
      "score is 0.6488969326019287, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\22.png\n",
      "score is 0.6559357643127441, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\23.png\n",
      "score is 0.8441148996353149, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\24.png\n",
      "score is 0.8567155003547668, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\25.png\n",
      "score is 0.9999897480010986, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\26.png\n",
      "score is 0.8331891894340515, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\27.png\n",
      "score is 0.9999475479125977, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\28.png\n",
      "score is 0.8630840182304382, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\29.png\n",
      "score is 0.9652539491653442, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\3.png\n",
      "score is 0.8078646659851074, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\4.png\n",
      "score is 0.5732290744781494, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\5.png\n",
      "score is 0.8836660981178284, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\6.png\n",
      "score is 0.7498025894165039, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\7.png\n",
      "score is 0.9838628172874451, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\8.png\n",
      "score is 0.7843822836875916, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [10:39, 50.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\lg0CwS\\lg0CwS_3\\9.png\n",
      "score is 0.5974874496459961, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\0.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\1.png\n",
      "score is 0.9291336536407471, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\10.png\n",
      "score is 0.980154275894165, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\11.png\n",
      "score is 0.9999973773956299, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\12.png\n",
      "score is 0.8029021620750427, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\13.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\14.png\n",
      "score is 0.9849515557289124, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\15.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\16.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\17.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\18.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\19.png\n",
      "score is 0.8579346537590027, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\2.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\20.png\n",
      "score is 0.9999969005584717, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\21.png\n",
      "score is 0.680018424987793, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\22.png\n",
      "score is 0.941551685333252, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\23.png\n",
      "score is 0.9331547021865845, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\24.png\n",
      "score is 0.8918129205703735, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\25.png\n",
      "score is 0.9852965474128723, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\26.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\27.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\28.png\n",
      "score is 0.9301772117614746, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\29.png\n",
      "score is 0.9842305779457092, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\3.png\n",
      "score is 0.9999947547912598, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\4.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\5.png\n",
      "score is 0.8746911287307739, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\6.png\n",
      "score is 0.9687018394470215, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\7.png\n",
      "score is 0.8973298072814941, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\8.png\n",
      "score is 0.4998575747013092, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_0\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\0.png\n",
      "score is 0.8954504132270813, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\1.png\n",
      "score is 0.5733926296234131, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\10.png\n",
      "score is 0.888999879360199, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\11.png\n",
      "score is 0.8503603339195251, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\12.png\n",
      "score is 0.6516759395599365, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\13.png\n",
      "score is 0.9265937805175781, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\14.png\n",
      "score is 0.795863151550293, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\15.png\n",
      "score is 0.9962671399116516, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\16.png\n",
      "score is 0.5745024085044861, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\17.png\n",
      "score is 0.9893330335617065, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\18.png\n",
      "score is 0.7265220284461975, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\19.png\n",
      "score is 0.9258013963699341, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\2.png\n",
      "score is 0.6578213572502136, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\20.png\n",
      "score is 0.9962132573127747, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\21.png\n",
      "score is 0.4715818464756012, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\22.png\n",
      "score is 0.9985840320587158, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\23.png\n",
      "score is 0.5135998129844666, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\24.png\n",
      "score is 0.7067357301712036, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\25.png\n",
      "score is 0.6743037104606628, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\26.png\n",
      "score is 0.698436975479126, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\27.png\n",
      "score is 0.895541787147522, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\28.png\n",
      "score is 0.9413920640945435, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\29.png\n",
      "score is 0.8066837787628174, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\3.png\n",
      "score is 0.5377078652381897, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\4.png\n",
      "score is 0.9125860929489136, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\5.png\n",
      "score is 0.9976843595504761, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\6.png\n",
      "score is 0.9984661340713501, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\7.png\n",
      "score is 0.7460544109344482, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\8.png\n",
      "score is 0.9865216016769409, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_1\\9.png\n",
      "score is 0.6674476265907288, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\0.png\n",
      "score is 0.6973003149032593, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\1.png\n",
      "score is 0.6013099551200867, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\10.png\n",
      "score is 0.5736454725265503, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\11.png\n",
      "score is 0.8372613191604614, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\12.png\n",
      "score is 0.9352703094482422, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\13.png\n",
      "score is 0.5235846042633057, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\14.png\n",
      "score is 0.8037670254707336, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\15.png\n",
      "score is 0.6300628781318665, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\16.png\n",
      "score is 0.8999199271202087, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\17.png\n",
      "score is 0.6553381681442261, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\18.png\n",
      "score is 0.9155617356300354, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\19.png\n",
      "score is 0.999957799911499, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\2.png\n",
      "score is 0.9514167308807373, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\20.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\21.png\n",
      "score is 0.5506941676139832, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\22.png\n",
      "score is 0.7731534242630005, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\24.png\n",
      "score is 0.7300565838813782, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\25.png\n",
      "score is 0.7088060975074768, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\26.png\n",
      "score is 0.6652582287788391, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\27.png\n",
      "score is 0.9397313594818115, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\28.png\n",
      "score is 0.5440581440925598, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\29.png\n",
      "score is 0.9790940880775452, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\3.png\n",
      "score is 0.7582328915596008, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\4.png\n",
      "score is 0.7326669692993164, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\5.png\n",
      "score is 0.9977600574493408, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\6.png\n",
      "score is 0.5842350721359253, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\7.png\n",
      "score is 0.6777086853981018, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\8.png\n",
      "score is 0.7165898084640503, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\lO9MmB\\lO9MmB_2\\9.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [11:25, 49.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score is 0.7995588183403015, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\0.png\n",
      "score is 0.8215609192848206, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\1.png\n",
      "score is 0.7615063190460205, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\10.png\n",
      "score is 0.5410093069076538, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\11.png\n",
      "score is 0.9066505432128906, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\12.png\n",
      "score is 0.7399755120277405, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\13.png\n",
      "score is 0.9971588850021362, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\14.png\n",
      "score is 0.7280244827270508, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\15.png\n",
      "score is 0.9687120914459229, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\16.png\n",
      "score is 0.6885960102081299, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\17.png\n",
      "score is 0.6839954853057861, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\18.png\n",
      "score is 0.9402165412902832, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\19.png\n",
      "score is 0.9775564074516296, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\2.png\n",
      "score is 0.6738006472587585, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\20.png\n",
      "score is 0.9867129325866699, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\21.png\n",
      "score is 0.791240930557251, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\22.png\n",
      "score is 0.48149335384368896, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\23.png\n",
      "score is 0.9881964325904846, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\24.png\n",
      "score is 0.6277732253074646, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\25.png\n",
      "score is 0.8737756609916687, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\26.png\n",
      "score is 0.8359118700027466, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\27.png\n",
      "score is 0.7511008381843567, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\28.png\n",
      "score is 0.8082348704338074, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\29.png\n",
      "score is 0.9887921214103699, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\3.png\n",
      "score is 0.8793548941612244, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\4.png\n",
      "score is 0.6282618641853333, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\5.png\n",
      "score is 0.9816620945930481, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\6.png\n",
      "score is 0.9573494791984558, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\7.png\n",
      "score is 0.8942588567733765, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\8.png\n",
      "score is 0.9997774958610535, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_0\\9.png\n",
      "score is 0.5275928378105164, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\0.png\n",
      "score is 0.9967435598373413, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\10.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\11.png\n",
      "score is 0.9417890310287476, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\12.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\13.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\14.png\n",
      "score is 0.5819894671440125, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\15.png\n",
      "score is 0.9862247705459595, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\16.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\17.png\n",
      "score is 0.9937898516654968, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\18.png\n",
      "score is 0.8828452825546265, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\19.png\n",
      "score is 0.9220094680786133, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\2.png\n",
      "score is 0.9974226951599121, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\20.png\n",
      "score is 0.9855234622955322, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\21.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\22.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\24.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\25.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\26.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\27.png\n",
      "score is 0.8646209836006165, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\28.png\n",
      "score is 0.9529090523719788, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\29.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\3.png\n",
      "score is 0.6903682947158813, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\4.png\n",
      "score is 0.9999960660934448, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\5.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\6.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\7.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\8.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_1\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\0.png\n",
      "score is 0.9986796975135803, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\1.png\n",
      "score is 0.5586642026901245, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\10.png\n",
      "score is 0.5056962370872498, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\11.png\n",
      "score is 0.989763617515564, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\12.png\n",
      "score is 0.9098359942436218, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\13.png\n",
      "score is 0.9921610951423645, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\14.png\n",
      "score is 0.9987731575965881, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\15.png\n",
      "score is 0.9999985694885254, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\16.png\n",
      "score is 0.6883403062820435, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\17.png\n",
      "score is 0.6205370426177979, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\18.png\n",
      "score is 0.9897693395614624, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\19.png\n",
      "score is 0.9624919295310974, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\2.png\n",
      "score is 0.9381017088890076, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\20.png\n",
      "score is 0.5086168646812439, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\21.png\n",
      "score is 0.9995843768119812, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\22.png\n",
      "score is 0.7015690207481384, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\23.png\n",
      "score is 0.5638102293014526, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\24.png\n",
      "score is 0.9999980926513672, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\25.png\n",
      "score is 0.5059353709220886, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\26.png\n",
      "score is 0.9970080256462097, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\27.png\n",
      "score is 0.9999631643295288, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\28.png\n",
      "score is 0.7414419054985046, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\29.png\n",
      "score is 0.6894881129264832, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\3.png\n",
      "score is 0.9997372031211853, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\4.png\n",
      "score is 0.9999915361404419, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\5.png\n",
      "score is 0.6362990140914917, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\6.png\n",
      "score is 0.9968460202217102, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\7.png\n",
      "score is 0.9982911944389343, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\8.png\n",
      "score is 0.918071985244751, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [12:10, 47.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\LRJwmg\\LRJwmg_2\\9.png\n",
      "score is 0.9774578809738159, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\0.png\n",
      "score is 0.7096574902534485, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\1.png\n",
      "score is 0.7950818538665771, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\10.png\n",
      "score is 0.8801042437553406, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\11.png\n",
      "score is 0.9149194359779358, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\12.png\n",
      "score is 0.8786302208900452, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\13.png\n",
      "score is 0.68576580286026, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\15.png\n",
      "score is 0.8336224555969238, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\16.png\n",
      "score is 0.9877743124961853, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\17.png\n",
      "score is 0.6997166872024536, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\18.png\n",
      "score is 0.7032889127731323, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\19.png\n",
      "score is 0.8470473289489746, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\2.png\n",
      "score is 0.883878231048584, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\20.png\n",
      "score is 0.877525269985199, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\21.png\n",
      "score is 0.7665861248970032, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\22.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\24.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\25.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\26.png\n",
      "score is 0.5149674415588379, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\27.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\28.png\n",
      "score is 0.5767560601234436, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\29.png\n",
      "score is 0.6722161769866943, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\3.png\n",
      "score is 0.7482447028160095, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\4.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\5.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\6.png\n",
      "score is 0.5473456382751465, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\7.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\8.png\n",
      "score is 0.982588529586792, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_0\\9.png\n",
      "score is 0.5248461365699768, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\0.png\n",
      "score is 0.9653734564781189, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\1.png\n",
      "score is 0.9612072110176086, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\10.png\n",
      "score is 0.9864962697029114, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\11.png\n",
      "score is 0.8770878911018372, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\12.png\n",
      "score is 0.962192177772522, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\13.png\n",
      "score is 0.9937507510185242, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\14.png\n",
      "score is 0.7878048419952393, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\15.png\n",
      "score is 0.8595477342605591, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\16.png\n",
      "score is 0.9840444326400757, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\17.png\n",
      "score is 0.8784575462341309, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\18.png\n",
      "score is 0.9883835911750793, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\19.png\n",
      "score is 0.5648476481437683, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\2.png\n",
      "score is 0.5713531374931335, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\20.png\n",
      "score is 0.960068941116333, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\21.png\n",
      "score is 0.8855451345443726, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\22.png\n",
      "score is 0.9871066212654114, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\23.png\n",
      "score is 0.8624901175498962, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\24.png\n",
      "score is 0.9745714068412781, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\25.png\n",
      "score is 0.7039341926574707, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\26.png\n",
      "score is 0.9412007331848145, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\27.png\n",
      "score is 0.8743511438369751, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\28.png\n",
      "score is 0.9638234972953796, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\29.png\n",
      "score is 0.9792782068252563, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\3.png\n",
      "score is 0.9919805526733398, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\4.png\n",
      "score is 0.9598922729492188, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\5.png\n",
      "score is 0.8742082118988037, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\6.png\n",
      "score is 0.6645676493644714, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\7.png\n",
      "score is 0.6922538876533508, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\8.png\n",
      "score is 0.9962610602378845, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_1\\9.png\n",
      "score is 0.9614112377166748, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\0.png\n",
      "score is 0.9016085267066956, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\1.png\n",
      "score is 0.9995858073234558, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\10.png\n",
      "score is 0.9968351721763611, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\11.png\n",
      "score is 0.9400719404220581, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\12.png\n",
      "score is 0.6880478858947754, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\13.png\n",
      "score is 0.8985786437988281, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\14.png\n",
      "score is 0.9994128942489624, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\15.png\n",
      "score is 0.9807581901550293, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\16.png\n",
      "score is 0.9999178647994995, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\17.png\n",
      "score is 0.8333876132965088, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\18.png\n",
      "score is 0.9931160807609558, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\19.png\n",
      "score is 0.863562285900116, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\2.png\n",
      "score is 0.964414656162262, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\20.png\n",
      "score is 0.999452531337738, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\21.png\n",
      "score is 0.9873695969581604, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\22.png\n",
      "score is 0.9691810607910156, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\23.png\n",
      "score is 0.9980150461196899, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\24.png\n",
      "score is 0.9443075656890869, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\25.png\n",
      "score is 0.9859796166419983, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\26.png\n",
      "score is 0.5226523876190186, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\27.png\n",
      "score is 0.7438448667526245, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\28.png\n",
      "score is 0.9975957274436951, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\29.png\n",
      "score is 0.7385844588279724, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\3.png\n",
      "score is 0.999704897403717, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\4.png\n",
      "score is 0.9764040112495422, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\5.png\n",
      "score is 0.6006850600242615, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\6.png\n",
      "score is 0.6137170791625977, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\7.png\n",
      "score is 0.9091659784317017, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\8.png\n",
      "score is 0.9988529682159424, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_2\\9.png\n",
      "score is 0.9794881939888, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\0.png\n",
      "score is 0.97413569688797, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\1.png\n",
      "score is 0.8444921374320984, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\10.png\n",
      "score is 0.6309056878089905, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\11.png\n",
      "score is 0.8966297507286072, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\12.png\n",
      "score is 0.8080927729606628, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\13.png\n",
      "score is 0.8633425831794739, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\14.png\n",
      "score is 0.9642934799194336, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\15.png\n",
      "score is 0.8193758130073547, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\16.png\n",
      "score is 0.5944135785102844, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\17.png\n",
      "score is 0.9478857517242432, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\18.png\n",
      "score is 0.9013594388961792, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\19.png\n",
      "score is 0.9278963804244995, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\2.png\n",
      "score is 0.8448567390441895, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\20.png\n",
      "score is 0.6462064981460571, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\21.png\n",
      "score is 0.965120792388916, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\22.png\n",
      "score is 0.9958450198173523, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\23.png\n",
      "score is 0.9681988954544067, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\24.png\n",
      "score is 0.9999529123306274, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\25.png\n",
      "score is 0.9214112162590027, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\26.png\n",
      "score is 0.8758129477500916, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\27.png\n",
      "score is 0.9879676699638367, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\28.png\n",
      "score is 0.6907469630241394, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\29.png\n",
      "score is 0.9735889434814453, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\3.png\n",
      "score is 0.9831438660621643, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\4.png\n",
      "score is 0.9394503831863403, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\5.png\n",
      "score is 0.6322214603424072, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\6.png\n",
      "score is 0.6506395936012268, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\7.png\n",
      "score is 0.7425400018692017, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\8.png\n",
      "score is 0.8945223689079285, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [13:12, 52.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\LrKXU4\\LrKXU4_3\\9.png\n",
      "score is 0.7981224060058594, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\0.png\n",
      "score is 0.9956955909729004, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\1.png\n",
      "score is 0.9277853965759277, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\10.png\n",
      "score is 0.9985048770904541, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\11.png\n",
      "score is 0.9994885921478271, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\12.png\n",
      "score is 0.9650569558143616, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\13.png\n",
      "score is 0.9998086094856262, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\14.png\n",
      "score is 0.9493022561073303, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\15.png\n",
      "score is 0.9999873638153076, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\16.png\n",
      "score is 0.8104618191719055, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\17.png\n",
      "score is 0.9133864641189575, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\18.png\n",
      "score is 0.8235888481140137, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\19.png\n",
      "score is 0.8175340890884399, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\2.png\n",
      "score is 0.9999324083328247, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\20.png\n",
      "score is 0.9998327493667603, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\21.png\n",
      "score is 0.9891658425331116, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\22.png\n",
      "score is 0.5715562701225281, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\23.png\n",
      "score is 0.9483314156532288, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\24.png\n",
      "score is 0.8180004954338074, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\25.png\n",
      "score is 0.9975312948226929, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\26.png\n",
      "score is 0.9421851634979248, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\27.png\n",
      "score is 0.999907374382019, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\28.png\n",
      "score is 0.9997807145118713, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\29.png\n",
      "score is 0.9421491026878357, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\3.png\n",
      "score is 0.9986321330070496, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\4.png\n",
      "score is 0.9437486529350281, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\5.png\n",
      "score is 0.9908445477485657, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\6.png\n",
      "score is 0.9999141693115234, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\7.png\n",
      "score is 0.949279248714447, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\8.png\n",
      "score is 0.5652977228164673, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [13:28, 41.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\m14lJk\\m14lJk_0\\9.png\n",
      "score is 0.9999716281890869, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\0.png\n",
      "score is 0.7873582243919373, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\1.png\n",
      "score is 0.9528954029083252, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\10.png\n",
      "score is 0.9387537837028503, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\11.png\n",
      "score is 0.9382311105728149, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\12.png\n",
      "score is 0.7272182703018188, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\13.png\n",
      "score is 0.5503713488578796, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\14.png\n",
      "score is 0.9353471994400024, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\15.png\n",
      "score is 0.8681914210319519, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\16.png\n",
      "score is 0.7047961950302124, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\17.png\n",
      "score is 0.9998952150344849, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\18.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\19.png\n",
      "score is 0.5391188263893127, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\2.png\n",
      "score is 0.9518418312072754, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\20.png\n",
      "score is 0.8919337391853333, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\21.png\n",
      "score is 0.9449285864830017, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\22.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\23.png\n",
      "score is 0.8935773968696594, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\24.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\25.png\n",
      "score is 0.511648416519165, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\26.png\n",
      "score is 0.6732115149497986, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\27.png\n",
      "score is 0.8758679032325745, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\28.png\n",
      "score is 0.9999440908432007, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\29.png\n",
      "score is 0.8733159899711609, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\3.png\n",
      "score is 0.8181388974189758, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\4.png\n",
      "score is 0.6681485772132874, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\5.png\n",
      "score is 0.6215468645095825, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\6.png\n",
      "score is 0.9546548128128052, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\7.png\n",
      "score is 0.6682337522506714, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\8.png\n",
      "score is 0.8665090203285217, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_0\\9.png\n",
      "score is 0.8377785682678223, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\0.png\n",
      "score is 0.9997674822807312, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\10.png\n",
      "score is 0.8872445225715637, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\11.png\n",
      "score is 0.9926618337631226, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\12.png\n",
      "score is 0.9999994039535522, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\13.png\n",
      "score is 0.8183653354644775, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\15.png\n",
      "score is 0.6249081492424011, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\16.png\n",
      "score is 0.9878745675086975, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\17.png\n",
      "score is 0.8712573647499084, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\18.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\19.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\2.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\20.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\21.png\n",
      "score is 0.8526346683502197, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\22.png\n",
      "score is 0.9999997615814209, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\23.png\n",
      "score is 0.5468106865882874, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\24.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\25.png\n",
      "score is 0.8680810928344727, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\26.png\n",
      "score is 0.7977762818336487, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\27.png\n",
      "score is 0.6950309872627258, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\28.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\29.png\n",
      "score is 0.9721073508262634, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\3.png\n",
      "score is 0.7211050987243652, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\4.png\n",
      "score is 0.9985186457633972, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\5.png\n",
      "score is 0.6110925078392029, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\6.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\7.png\n",
      "score is 0.9999932050704956, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\8.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [13:57, 37.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\MHNQ4e\\MHNQ4e_1\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\0.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\10.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\11.png\n",
      "score is 0.5327603220939636, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\12.png\n",
      "score is 0.9583480954170227, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\13.png\n",
      "score is 0.602225124835968, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\15.png\n",
      "score is 0.8545405268669128, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\16.png\n",
      "score is 0.6868032217025757, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\17.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\18.png\n",
      "score is 0.8792685270309448, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\19.png\n",
      "score is 0.8025087714195251, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\2.png\n",
      "score is 0.5207462906837463, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\20.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\21.png\n",
      "score is 0.7023534178733826, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\22.png\n",
      "score is 0.950815737247467, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\24.png\n",
      "score is 0.8651981353759766, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\25.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\26.png\n",
      "score is 0.9999990463256836, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\27.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\28.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\29.png\n",
      "score is 0.9216452836990356, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\3.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\4.png\n",
      "score is 0.8151717185974121, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\5.png\n",
      "score is 0.7439764142036438, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\6.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\7.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\8.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_0\\9.png\n",
      "score is 0.9449535608291626, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\0.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\1.png\n",
      "score is 0.9982380867004395, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\10.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\11.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\12.png\n",
      "score is 0.7091445326805115, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\13.png\n",
      "score is 0.9999997615814209, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\14.png\n",
      "score is 0.9585196375846863, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\15.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\16.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\17.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\18.png\n",
      "score is 0.9942382574081421, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\19.png\n",
      "score is 0.9884452819824219, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\2.png\n",
      "score is 0.9650277495384216, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\20.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\21.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\22.png\n",
      "score is 0.9352526068687439, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\23.png\n",
      "score is 0.8878761529922485, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\24.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\25.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\26.png\n",
      "score is 0.9106757640838623, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\27.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\28.png\n",
      "score is 0.6465970873832703, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\29.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\3.png\n",
      "score is 0.9185953140258789, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\4.png\n",
      "score is 0.7950810790061951, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\5.png\n",
      "score is 0.872337281703949, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\6.png\n",
      "score is 0.9867613315582275, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\7.png\n",
      "score is 0.9999912977218628, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\8.png\n",
      "score is 0.8251268863677979, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_1\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\0.png\n",
      "score is 0.8227843642234802, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\1.png\n",
      "score is 0.9855384826660156, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\10.png\n",
      "score is 0.7431439161300659, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\11.png\n",
      "score is 0.994448184967041, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\12.png\n",
      "score is 0.7593716979026794, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\13.png\n",
      "score is 0.9608849287033081, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\14.png\n",
      "score is 0.9023963809013367, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\15.png\n",
      "score is 0.7287653684616089, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\16.png\n",
      "score is 0.7387674450874329, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\17.png\n",
      "score is 0.9689513444900513, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\18.png\n",
      "score is 0.5543698668479919, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\19.png\n",
      "score is 0.5268193483352661, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\2.png\n",
      "score is 0.7643573880195618, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\20.png\n",
      "score is 0.9564395546913147, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\21.png\n",
      "score is 0.9347638487815857, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\22.png\n",
      "score is 0.982115626335144, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\23.png\n",
      "score is 0.63129061460495, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\24.png\n",
      "score is 0.9416483044624329, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\25.png\n",
      "score is 0.5989469289779663, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\26.png\n",
      "score is 0.9612124562263489, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\27.png\n",
      "score is 0.9752927422523499, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\28.png\n",
      "score is 0.85076904296875, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\29.png\n",
      "score is 0.9341138005256653, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\3.png\n",
      "score is 0.8597566485404968, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\4.png\n",
      "score is 0.9351334571838379, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\5.png\n",
      "score is 0.9215003848075867, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\6.png\n",
      "score is 0.8420372009277344, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\7.png\n",
      "score is 0.9919003248214722, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\8.png\n",
      "score is 0.8767495155334473, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [14:42, 39.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\miuArM\\miuArM_2\\9.png\n",
      "score is 0.9002305269241333, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\0.png\n",
      "score is 0.9957569241523743, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\1.png\n",
      "score is 0.9575434327125549, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\10.png\n",
      "score is 0.9092999696731567, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\11.png\n",
      "score is 0.49755722284317017, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\12.png\n",
      "score is 0.7332581877708435, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\13.png\n",
      "score is 0.7632282972335815, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\14.png\n",
      "score is 0.876460075378418, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\15.png\n",
      "score is 0.9784848093986511, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\16.png\n",
      "score is 0.6771036982536316, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\17.png\n",
      "score is 0.9445034265518188, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\18.png\n",
      "score is 0.9792993664741516, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\19.png\n",
      "score is 0.7924610376358032, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\2.png\n",
      "score is 0.9897420406341553, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\20.png\n",
      "score is 0.6246036291122437, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\21.png\n",
      "score is 0.9946627616882324, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\22.png\n",
      "score is 0.9208638072013855, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\23.png\n",
      "score is 0.5754493474960327, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\24.png\n",
      "score is 0.9727248549461365, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\25.png\n",
      "score is 0.9723933339118958, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\26.png\n",
      "score is 0.9742739796638489, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\27.png\n",
      "score is 0.9400454163551331, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\28.png\n",
      "score is 0.9922488927841187, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\29.png\n",
      "score is 0.9799046516418457, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\3.png\n",
      "score is 0.7223847508430481, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\4.png\n",
      "score is 0.9911333918571472, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\5.png\n",
      "score is 0.6989697813987732, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\6.png\n",
      "score is 0.9638239741325378, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\7.png\n",
      "score is 0.8537227511405945, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\8.png\n",
      "score is 0.9686539173126221, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_0\\9.png\n",
      "score is 0.9223136901855469, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\0.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\1.png\n",
      "score is 0.6894374489784241, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\10.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\11.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\12.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\13.png\n",
      "score is 0.9999890327453613, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\15.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\16.png\n",
      "score is 0.6094840168952942, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\17.png\n",
      "score is 0.6122010946273804, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\18.png\n",
      "score is 0.9999994039535522, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\19.png\n",
      "score is 0.5658161640167236, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\2.png\n",
      "score is 0.5832198858261108, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\20.png\n",
      "score is 0.9946861267089844, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\21.png\n",
      "score is 0.5858691930770874, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\22.png\n",
      "score is 0.9999995231628418, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\24.png\n",
      "score is 0.9611400365829468, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\25.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\26.png\n",
      "score is 0.7327832579612732, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\27.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\28.png\n",
      "score is 0.9999990463256836, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\29.png\n",
      "score is 0.9842676520347595, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\3.png\n",
      "score is 0.7353103756904602, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\4.png\n",
      "score is 0.4049791991710663, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\5.png\n",
      "score is 0.6910889148712158, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\6.png\n",
      "score is 0.3387415111064911, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\7.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\8.png\n",
      "score is 0.5272505283355713, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_1\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\0.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\1.png\n",
      "score is 0.7831644415855408, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\10.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\11.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\12.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\13.png\n",
      "score is 0.6342446804046631, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\15.png\n",
      "score is 0.9997445940971375, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\16.png\n",
      "score is 0.757932186126709, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\17.png\n",
      "score is 0.7513070106506348, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\18.png\n",
      "score is 0.9502796530723572, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\19.png\n",
      "score is 0.9074123501777649, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\2.png\n",
      "score is 0.9992559552192688, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\20.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\21.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\22.png\n",
      "score is 0.694501519203186, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\24.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\25.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\26.png\n",
      "score is 0.9529958963394165, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\27.png\n",
      "score is 0.5208565592765808, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\28.png\n",
      "score is 0.5609562397003174, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\29.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\3.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\4.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\5.png\n",
      "score is 0.587226927280426, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\6.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\7.png\n",
      "score is 0.7741525769233704, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\8.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [15:27, 41.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\N4HDTG\\N4HDTG_2\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\0.png\n",
      "score is 0.9970622658729553, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\1.png\n",
      "score is 0.6662521958351135, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\10.png\n",
      "score is 0.849405825138092, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\11.png\n",
      "score is 0.8998697400093079, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\12.png\n",
      "score is 0.9500452876091003, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\13.png\n",
      "score is 0.9006401896476746, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\14.png\n",
      "score is 0.9415481090545654, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\15.png\n",
      "score is 0.8444666266441345, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\16.png\n",
      "score is 0.7628870606422424, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\17.png\n",
      "score is 0.909307599067688, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\18.png\n",
      "score is 0.8599811792373657, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\19.png\n",
      "score is 0.8671087622642517, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\2.png\n",
      "score is 0.8809136748313904, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\20.png\n",
      "score is 0.6201499700546265, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\21.png\n",
      "score is 0.9026826024055481, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\22.png\n",
      "score is 0.830612063407898, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\23.png\n",
      "score is 0.6648520231246948, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\24.png\n",
      "score is 0.6074124574661255, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\25.png\n",
      "score is 0.9367610216140747, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\26.png\n",
      "score is 0.5987984538078308, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\27.png\n",
      "score is 0.7920213937759399, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\28.png\n",
      "score is 0.9853718876838684, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\29.png\n",
      "score is 0.9546591639518738, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\3.png\n",
      "score is 0.8699186444282532, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\4.png\n",
      "score is 0.7659701108932495, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\5.png\n",
      "score is 0.9395458102226257, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\6.png\n",
      "score is 0.6812303066253662, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\7.png\n",
      "score is 0.9836392998695374, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\8.png\n",
      "score is 0.7791398167610168, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_0\\9.png\n",
      "score is 0.782558023929596, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\0.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\1.png\n",
      "score is 0.7116745710372925, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\10.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\11.png\n",
      "score is 0.9997225403785706, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\12.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\13.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\15.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\16.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\17.png\n",
      "score is 0.9962215423583984, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\18.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\19.png\n",
      "score is 0.7913897037506104, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\2.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\20.png\n",
      "score is 0.9998527765274048, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\21.png\n",
      "score is 0.9999991655349731, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\22.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\23.png\n",
      "score is 0.999920129776001, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\24.png\n",
      "score is 0.9999995231628418, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\25.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\26.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\27.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\28.png\n",
      "score is 0.99988853931427, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\29.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\3.png\n",
      "score is 0.997569739818573, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\4.png\n",
      "score is 0.9999892711639404, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\5.png\n",
      "score is 0.9964109063148499, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\6.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\7.png\n",
      "score is 0.9978640675544739, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\8.png\n",
      "score is 0.9903138279914856, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_1\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\0.png\n",
      "score is 0.8538777828216553, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\1.png\n",
      "score is 0.7696131467819214, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\10.png\n",
      "score is 0.9346131086349487, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\11.png\n",
      "score is 0.8482317328453064, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\12.png\n",
      "score is 0.9291577339172363, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\13.png\n",
      "score is 0.9934119582176208, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\14.png\n",
      "score is 0.9872382879257202, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\15.png\n",
      "score is 0.5536175966262817, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\16.png\n",
      "score is 0.5902358889579773, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\17.png\n",
      "score is 0.6178480386734009, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\18.png\n",
      "score is 0.6161330342292786, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\19.png\n",
      "score is 0.8103117942810059, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\2.png\n",
      "score is 0.6233941912651062, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\20.png\n",
      "score is 0.8896411657333374, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\21.png\n",
      "score is 0.5217660665512085, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\22.png\n",
      "score is 0.5431035757064819, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\23.png\n",
      "score is 0.5286300778388977, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\24.png\n",
      "score is 0.9733830094337463, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\25.png\n",
      "score is 0.8406903147697449, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\26.png\n",
      "score is 0.8609585762023926, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\27.png\n",
      "score is 0.6916759014129639, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\28.png\n",
      "score is 0.790449857711792, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\29.png\n",
      "score is 0.6337279677391052, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\3.png\n",
      "score is 0.6097649931907654, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\4.png\n",
      "score is 0.6282452344894409, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\5.png\n",
      "score is 0.687179446220398, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\6.png\n",
      "score is 0.8350747227668762, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\7.png\n",
      "score is 0.9841798543930054, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\8.png\n",
      "score is 0.9109594821929932, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [16:11, 42.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\NGynsT\\NGynsT_2\\9.png\n",
      "score is 0.8391537666320801, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\0.png\n",
      "score is 0.9256578087806702, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\1.png\n",
      "score is 0.9958374500274658, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\10.png\n",
      "score is 0.7641473412513733, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\11.png\n",
      "score is 0.9988877177238464, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\12.png\n",
      "score is 0.8203858733177185, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\13.png\n",
      "score is 0.9938253164291382, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\14.png\n",
      "score is 0.9537099003791809, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\15.png\n",
      "score is 0.6924389004707336, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\16.png\n",
      "score is 0.8161315321922302, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\17.png\n",
      "score is 0.8436504006385803, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\18.png\n",
      "score is 0.9370056986808777, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\19.png\n",
      "score is 0.6201637387275696, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\2.png\n",
      "score is 0.7653532028198242, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\20.png\n",
      "score is 0.9998916387557983, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\21.png\n",
      "score is 0.9991890788078308, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\22.png\n",
      "score is 0.6403363347053528, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\23.png\n",
      "score is 0.8601030111312866, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\24.png\n",
      "score is 0.8551210761070251, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\25.png\n",
      "score is 0.8011001944541931, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\26.png\n",
      "score is 0.9534714818000793, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\27.png\n",
      "score is 0.9894952178001404, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\28.png\n",
      "score is 0.5384933948516846, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\29.png\n",
      "score is 0.9926095604896545, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\3.png\n",
      "score is 0.9793968200683594, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\4.png\n",
      "score is 0.9961498975753784, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\5.png\n",
      "score is 0.8295391798019409, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\6.png\n",
      "score is 0.9952488541603088, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\7.png\n",
      "score is 0.644179105758667, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\8.png\n",
      "score is 0.9851461052894592, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_0\\9.png\n",
      "score is 0.6191334128379822, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\0.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\1.png\n",
      "score is 0.9622844457626343, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\10.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\11.png\n",
      "score is 0.9233956336975098, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\12.png\n",
      "score is 0.9997114539146423, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\13.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\15.png\n",
      "score is 0.999371349811554, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\16.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\17.png\n",
      "score is 0.8311983346939087, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\18.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\19.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\2.png\n",
      "score is 0.8712405562400818, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\20.png\n",
      "score is 0.9269340634346008, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\21.png\n",
      "score is 0.9939519762992859, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\22.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\23.png\n",
      "score is 0.999994158744812, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\24.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\25.png\n",
      "score is 0.9999995231628418, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\26.png\n",
      "score is 0.985039234161377, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\27.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\28.png\n",
      "score is 0.9999798536300659, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\29.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\3.png\n",
      "score is 0.9772449135780334, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\4.png\n",
      "score is 0.7367591261863708, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\5.png\n",
      "score is 0.9900201559066772, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\6.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\7.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\8.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_1\\9.png\n",
      "score is 0.98130863904953, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\0.png\n",
      "score is 0.6027904748916626, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\1.png\n",
      "score is 0.9146192669868469, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\10.png\n",
      "score is 0.8433384299278259, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\11.png\n",
      "score is 0.9997531771659851, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\12.png\n",
      "score is 0.9987518787384033, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\13.png\n",
      "score is 0.850845217704773, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\14.png\n",
      "score is 0.843288004398346, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\15.png\n",
      "score is 0.9999953508377075, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\16.png\n",
      "score is 0.999961256980896, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\17.png\n",
      "score is 0.7583889961242676, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\18.png\n",
      "score is 0.9932259917259216, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\19.png\n",
      "score is 0.9998538494110107, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\2.png\n",
      "score is 0.8670089244842529, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\20.png\n",
      "score is 0.979303240776062, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\21.png\n",
      "score is 0.8406665325164795, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\22.png\n",
      "score is 0.9999704360961914, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\23.png\n",
      "score is 0.9998897314071655, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\24.png\n",
      "score is 0.7083810567855835, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\25.png\n",
      "score is 0.9945231676101685, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\26.png\n",
      "score is 0.9999754428863525, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\27.png\n",
      "score is 0.9946582913398743, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\28.png\n",
      "score is 0.999991774559021, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\29.png\n",
      "score is 0.8253805041313171, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\3.png\n",
      "score is 0.9995827078819275, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\4.png\n",
      "score is 0.9968308806419373, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\5.png\n",
      "score is 0.8719663023948669, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\6.png\n",
      "score is 0.9991356730461121, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\7.png\n",
      "score is 0.9999107122421265, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\8.png\n",
      "score is 0.985471248626709, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_2\\9.png\n",
      "score is 0.999220609664917, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\0.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\10.png\n",
      "score is 0.9997269511222839, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\11.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\12.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\13.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\15.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\16.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\17.png\n",
      "score is 0.9087057113647461, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\18.png\n",
      "score is 0.9767643809318542, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\19.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\2.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\20.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\21.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\22.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\24.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\25.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\26.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\27.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\28.png\n",
      "score is 0.6972461938858032, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\29.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\3.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\4.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\5.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\6.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\7.png\n",
      "score is 0.99347323179245, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\8.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [17:11, 47.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\OyS7Ax\\OyS7Ax_3\\9.png\n",
      "score is 0.9901247024536133, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\0.png\n",
      "score is 0.999975323677063, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\10.png\n",
      "score is 0.8584230542182922, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\11.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\12.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\13.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\15.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\16.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\17.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\18.png\n",
      "score is 0.6908228397369385, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\19.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\2.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\20.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\21.png\n",
      "score is 0.9999983310699463, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\22.png\n",
      "score is 0.588639497756958, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\24.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\25.png\n",
      "score is 0.8737661838531494, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\26.png\n",
      "score is 0.880940854549408, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\27.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\28.png\n",
      "score is 0.9999746084213257, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\29.png\n",
      "score is 0.999998927116394, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\3.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\4.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\5.png\n",
      "score is 0.9627121686935425, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\6.png\n",
      "score is 0.9980966448783875, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\7.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\8.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_0\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\0.png\n",
      "score is 0.9999361038208008, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\10.png\n",
      "score is 0.9999997615814209, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\11.png\n",
      "score is 0.7314375638961792, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\12.png\n",
      "score is 0.9911041259765625, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\13.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\15.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\16.png\n",
      "score is 0.9975453019142151, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\17.png\n",
      "score is 0.633591890335083, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\18.png\n",
      "score is 0.9999983310699463, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\19.png\n",
      "score is 0.9999997615814209, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\2.png\n",
      "score is 0.8126022219657898, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\20.png\n",
      "score is 0.9999986886978149, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\21.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\22.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\24.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\25.png\n",
      "score is 0.9999973773956299, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\26.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\27.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\28.png\n",
      "score is 0.6462351083755493, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\29.png\n",
      "score is 0.8806414008140564, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\3.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\4.png\n",
      "score is 0.975030779838562, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\5.png\n",
      "score is 0.9763553738594055, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\6.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\7.png\n",
      "score is 0.9990590214729309, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\8.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_1\\9.png\n",
      "score is 0.7734931111335754, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\0.png\n",
      "score is 0.9132727980613708, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\10.png\n",
      "score is 0.9999986886978149, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\11.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\12.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\13.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\14.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\15.png\n",
      "score is 0.9986727237701416, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\16.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\17.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\18.png\n",
      "score is 0.9999994039535522, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\19.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\2.png\n",
      "score is 0.685060977935791, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\20.png\n",
      "score is 0.6123380064964294, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\21.png\n",
      "score is 0.9676717519760132, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\22.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\23.png\n",
      "score is 0.9999898672103882, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\24.png\n",
      "score is 0.9999997615814209, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\25.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\26.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\27.png\n",
      "score is 0.9996689558029175, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\28.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\29.png\n",
      "score is 0.9999889135360718, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\3.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\4.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\5.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\6.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\7.png\n",
      "score is 0.9488461017608643, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\8.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_2\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\0.png\n",
      "score is 0.9676658511161804, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\1.png\n",
      "score is 0.9143085479736328, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\10.png\n",
      "score is 0.978236973285675, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\11.png\n",
      "score is 0.9963968396186829, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\12.png\n",
      "score is 0.9807461500167847, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\13.png\n",
      "score is 0.9740380048751831, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\14.png\n",
      "score is 0.9942259192466736, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\15.png\n",
      "score is 0.806519627571106, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\16.png\n",
      "score is 0.9520542621612549, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\17.png\n",
      "score is 0.9934192299842834, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\18.png\n",
      "score is 0.9964693784713745, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\19.png\n",
      "score is 0.8990350365638733, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\2.png\n",
      "score is 0.9688403010368347, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\20.png\n",
      "score is 0.9902689456939697, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\21.png\n",
      "score is 0.9963803887367249, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\22.png\n",
      "score is 0.6823065876960754, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\23.png\n",
      "score is 0.9918803572654724, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\24.png\n",
      "score is 0.7951420545578003, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\25.png\n",
      "score is 0.9802298545837402, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\26.png\n",
      "score is 0.9857770800590515, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\27.png\n",
      "score is 0.9192997813224792, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\28.png\n",
      "score is 0.9599521160125732, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\29.png\n",
      "score is 0.9926400184631348, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\3.png\n",
      "score is 0.989400327205658, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\4.png\n",
      "score is 0.8801897764205933, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\5.png\n",
      "score is 0.9372119307518005, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\6.png\n",
      "score is 0.9743767380714417, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\7.png\n",
      "score is 0.9964549541473389, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\8.png\n",
      "score is 0.9844303727149963, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [18:11, 51.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\Pdaqkr\\Pdaqkr_3\\9.png\n",
      "score is 0.9871035218238831, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\0.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\1.png\n",
      "score is 0.9767457246780396, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\10.png\n",
      "score is 0.9994680285453796, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\11.png\n",
      "score is 0.9993639588356018, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\12.png\n",
      "score is 0.9998838901519775, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\13.png\n",
      "score is 0.5693328976631165, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\14.png\n",
      "score is 0.7056730389595032, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\15.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\16.png\n",
      "score is 0.8366295099258423, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\17.png\n",
      "score is 0.9257800579071045, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\18.png\n",
      "score is 0.9996291399002075, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\19.png\n",
      "score is 0.8070048689842224, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\2.png\n",
      "score is 0.6381533145904541, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\20.png\n",
      "score is 0.9949795603752136, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\21.png\n",
      "score is 0.951592743396759, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\22.png\n",
      "score is 0.7811639308929443, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\23.png\n",
      "score is 0.9862369298934937, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\24.png\n",
      "score is 0.9954720735549927, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\25.png\n",
      "score is 0.999816358089447, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\26.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\27.png\n",
      "score is 0.9790802597999573, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\28.png\n",
      "score is 0.9995222091674805, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\29.png\n",
      "score is 0.9811129570007324, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\3.png\n",
      "score is 0.34766238927841187, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\4.png\n",
      "score is 0.9906713962554932, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\5.png\n",
      "score is 0.9998317956924438, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\6.png\n",
      "score is 0.7208980917930603, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\7.png\n",
      "score is 0.8521213531494141, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\8.png\n",
      "score is 0.6680102348327637, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_0\\9.png\n",
      "score is 0.9844681620597839, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\0.png\n",
      "score is 0.8914446234703064, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\1.png\n",
      "score is 0.9799574017524719, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\10.png\n",
      "score is 0.6522607207298279, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\11.png\n",
      "score is 0.7731630206108093, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\12.png\n",
      "score is 0.977002739906311, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\13.png\n",
      "score is 0.525652289390564, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\15.png\n",
      "score is 0.5034451484680176, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\16.png\n",
      "score is 0.6539612412452698, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\17.png\n",
      "score is 0.7492226958274841, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\18.png\n",
      "score is 0.6857887506484985, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\19.png\n",
      "score is 0.675324022769928, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\2.png\n",
      "score is 0.5038002729415894, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\20.png\n",
      "score is 0.9085826873779297, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\21.png\n",
      "score is 0.9440997838973999, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\22.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\23.png\n",
      "score is 0.7327776551246643, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\24.png\n",
      "score is 0.9999179840087891, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\25.png\n",
      "score is 0.4485982656478882, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\26.png\n",
      "score is 0.6545414924621582, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\27.png\n",
      "score is 0.8579453825950623, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\28.png\n",
      "score is 0.5569667816162109, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\29.png\n",
      "score is 0.533901572227478, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\3.png\n",
      "score is 0.6645934581756592, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\4.png\n",
      "score is 0.8005731701850891, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\5.png\n",
      "score is 0.9996774196624756, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\6.png\n",
      "score is 0.572918713092804, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\7.png\n",
      "score is 0.9306800961494446, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\8.png\n",
      "score is 0.5659156441688538, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [18:41, 44.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PDmefU\\PDmefU_1\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\0.png\n",
      "score is 0.9759121537208557, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\10.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\11.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\12.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\13.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\15.png\n",
      "score is 0.5564628839492798, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\16.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\17.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\18.png\n",
      "score is 0.9999994039535522, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\19.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\2.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\20.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\21.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\22.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\23.png\n",
      "score is 0.9960446357727051, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\24.png\n",
      "score is 0.9952185750007629, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\25.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\26.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\27.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\28.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\29.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\3.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\4.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\5.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\6.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\7.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\8.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_0\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\0.png\n",
      "score is 0.5140158534049988, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\1.png\n",
      "score is 0.9996238946914673, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\10.png\n",
      "score is 0.9882853031158447, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\11.png\n",
      "score is 0.992122232913971, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\12.png\n",
      "score is 0.9845476746559143, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\13.png\n",
      "score is 0.999649167060852, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\14.png\n",
      "score is 0.6944941878318787, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\15.png\n",
      "score is 0.6106384992599487, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\16.png\n",
      "score is 0.9223171472549438, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\17.png\n",
      "score is 0.7768902778625488, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\18.png\n",
      "score is 0.96676105260849, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\19.png\n",
      "score is 0.5401628017425537, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\2.png\n",
      "score is 0.9644343852996826, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\20.png\n",
      "score is 0.9939895868301392, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\21.png\n",
      "score is 0.5634497404098511, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\22.png\n",
      "score is 0.7301990985870361, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\23.png\n",
      "score is 0.5844403505325317, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\24.png\n",
      "score is 0.65936279296875, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\25.png\n",
      "score is 0.8966901302337646, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\26.png\n",
      "score is 0.733440101146698, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\27.png\n",
      "score is 0.9941179752349854, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\28.png\n",
      "score is 0.800194263458252, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\29.png\n",
      "score is 0.9532759189605713, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\3.png\n",
      "score is 0.9729559421539307, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\4.png\n",
      "score is 0.8658638000488281, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\5.png\n",
      "score is 0.6171417236328125, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\6.png\n",
      "score is 0.9988512992858887, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\7.png\n",
      "score is 0.8384140133857727, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\8.png\n",
      "score is 0.9992183446884155, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_1\\9.png\n",
      "score is 0.9992924928665161, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\0.png\n",
      "score is 0.9687328934669495, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\1.png\n",
      "score is 0.5777802467346191, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\10.png\n",
      "score is 0.6299177408218384, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\11.png\n",
      "score is 0.9999947547912598, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\12.png\n",
      "score is 0.9999926090240479, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\13.png\n",
      "score is 0.9945935606956482, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\14.png\n",
      "score is 0.9995468258857727, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\15.png\n",
      "score is 0.5475248694419861, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\16.png\n",
      "score is 0.8480212092399597, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\17.png\n",
      "score is 0.5044105648994446, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\18.png\n",
      "score is 0.8202113509178162, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\19.png\n",
      "score is 0.9388687014579773, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\2.png\n",
      "score is 0.7913874387741089, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\20.png\n",
      "score is 0.9992013573646545, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\21.png\n",
      "score is 0.9084963202476501, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\22.png\n",
      "score is 0.7813796997070312, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\23.png\n",
      "score is 0.9784876704216003, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\24.png\n",
      "score is 0.9985877275466919, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\25.png\n",
      "score is 0.8037488460540771, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\26.png\n",
      "score is 0.8407818078994751, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\27.png\n",
      "score is 0.9955581426620483, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\28.png\n",
      "score is 0.9723753333091736, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\29.png\n",
      "score is 0.8752861022949219, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\3.png\n",
      "score is 0.9995138645172119, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\4.png\n",
      "score is 0.7575883269309998, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\5.png\n",
      "score is 0.9740673899650574, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\6.png\n",
      "score is 0.8075347542762756, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\7.png\n",
      "score is 0.8647686839103699, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\8.png\n",
      "score is 0.6775984764099121, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [19:25, 44.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\PhoFHq\\PhoFHq_2\\9.png\n",
      "score is 0.7555951476097107, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\0.png\n",
      "score is 0.6195645928382874, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\1.png\n",
      "score is 0.4518316984176636, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\10.png\n",
      "score is 0.5564805865287781, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\11.png\n",
      "score is 0.9996578693389893, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\12.png\n",
      "score is 0.5212602019309998, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\13.png\n",
      "score is 0.9999809265136719, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\14.png\n",
      "score is 0.9736958742141724, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\15.png\n",
      "score is 0.938331663608551, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\16.png\n",
      "score is 0.6831957697868347, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\17.png\n",
      "score is 0.9998779296875, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\18.png\n",
      "score is 0.6004948019981384, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\19.png\n",
      "score is 0.9987019300460815, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\2.png\n",
      "score is 0.9998579025268555, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\20.png\n",
      "score is 0.5739091038703918, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\21.png\n",
      "score is 0.995284378528595, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\22.png\n",
      "score is 0.9999971389770508, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\23.png\n",
      "score is 0.6881975531578064, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\24.png\n",
      "score is 0.8747437596321106, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\25.png\n",
      "score is 0.9986246824264526, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\26.png\n",
      "score is 0.8547283411026001, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\27.png\n",
      "score is 0.9985439777374268, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\28.png\n",
      "score is 0.9952933192253113, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\29.png\n",
      "score is 0.9998236298561096, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\3.png\n",
      "score is 0.9997881054878235, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\4.png\n",
      "score is 0.8164657950401306, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\5.png\n",
      "score is 0.9995602965354919, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\6.png\n",
      "score is 0.6942853331565857, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\7.png\n",
      "score is 0.9999964237213135, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\8.png\n",
      "score is 0.9998350143432617, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_0\\9.png\n",
      "score is 0.9727380871772766, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\0.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\10.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\11.png\n",
      "score is 0.937056839466095, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\12.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\13.png\n",
      "score is 0.9999822378158569, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\15.png\n",
      "score is 0.7656884789466858, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\16.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\17.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\18.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\19.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\2.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\20.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\21.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\22.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\23.png\n",
      "score is 0.9999994039535522, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\24.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\25.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\26.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\27.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\28.png\n",
      "score is 0.9162524342536926, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\29.png\n",
      "score is 0.9236993789672852, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\3.png\n",
      "score is 0.7522570490837097, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\4.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\5.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\6.png\n",
      "score is 0.700214684009552, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\7.png\n",
      "score is 0.9998863935470581, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\8.png\n",
      "score is 0.6151309013366699, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_1\\9.png\n",
      "score is 0.9984058737754822, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\0.png\n",
      "score is 0.9179095029830933, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\1.png\n",
      "score is 0.6676929593086243, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\10.png\n",
      "score is 0.9728507399559021, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\11.png\n",
      "score is 0.9900566935539246, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\12.png\n",
      "score is 0.8052623271942139, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\13.png\n",
      "score is 0.6843060255050659, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\14.png\n",
      "score is 0.6420056223869324, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\15.png\n",
      "score is 0.6780715584754944, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\16.png\n",
      "score is 0.7904810905456543, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\17.png\n",
      "score is 0.8074894547462463, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\18.png\n",
      "score is 0.9120376110076904, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\19.png\n",
      "score is 0.8060749173164368, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\2.png\n",
      "score is 0.7795147895812988, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\20.png\n",
      "score is 0.829350471496582, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\21.png\n",
      "score is 0.9998722076416016, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\22.png\n",
      "score is 0.9909512996673584, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\23.png\n",
      "score is 0.9319577813148499, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\24.png\n",
      "score is 0.9904823303222656, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\25.png\n",
      "score is 0.7303515672683716, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\26.png\n",
      "score is 0.7414421439170837, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\27.png\n",
      "score is 0.6030556559562683, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\28.png\n",
      "score is 0.7672284841537476, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\29.png\n",
      "score is 0.9968425035476685, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\3.png\n",
      "score is 0.6457991600036621, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\4.png\n",
      "score is 0.8258729577064514, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\5.png\n",
      "score is 0.8982439041137695, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\6.png\n",
      "score is 0.531626284122467, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\7.png\n",
      "score is 0.9710121750831604, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\8.png\n",
      "score is 0.61881023645401, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_2\\9.png\n",
      "score is 0.9015401005744934, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\0.png\n",
      "score is 0.5517896413803101, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\1.png\n",
      "score is 0.8826819062232971, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\10.png\n",
      "score is 0.7526804804801941, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\11.png\n",
      "score is 0.9539540410041809, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\12.png\n",
      "score is 0.706000804901123, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\13.png\n",
      "score is 0.9178998470306396, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\14.png\n",
      "score is 0.9613573551177979, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\15.png\n",
      "score is 0.7918761968612671, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\16.png\n",
      "score is 0.8092032074928284, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\17.png\n",
      "score is 0.9505961537361145, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\18.png\n",
      "score is 0.8934110403060913, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\19.png\n",
      "score is 0.8353400230407715, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\2.png\n",
      "score is 0.9922295212745667, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\20.png\n",
      "score is 0.8296119570732117, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\21.png\n",
      "score is 0.9936217665672302, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\22.png\n",
      "score is 0.9920280575752258, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\23.png\n",
      "score is 0.5192717909812927, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\24.png\n",
      "score is 0.8655655980110168, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\25.png\n",
      "score is 0.860435426235199, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\26.png\n",
      "score is 0.75913006067276, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\27.png\n",
      "score is 0.623609721660614, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\28.png\n",
      "score is 0.7906871438026428, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\29.png\n",
      "score is 0.7090258598327637, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\3.png\n",
      "score is 0.9945074915885925, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\4.png\n",
      "score is 0.8808159232139587, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\5.png\n",
      "score is 0.5927078723907471, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\6.png\n",
      "score is 0.9492823481559753, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\7.png\n",
      "score is 0.87184077501297, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\8.png\n",
      "score is 0.79268878698349, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [20:25, 49.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\s7iuvj\\s7iuvj_3\\9.png\n",
      "score is 0.7478494644165039, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\0.png\n",
      "score is 0.922707200050354, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\1.png\n",
      "score is 0.8038734197616577, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\10.png\n",
      "score is 0.9685298800468445, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\11.png\n",
      "score is 0.9278000593185425, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\12.png\n",
      "score is 0.9898462891578674, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\13.png\n",
      "score is 0.9937910437583923, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\14.png\n",
      "score is 0.5071561336517334, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\15.png\n",
      "score is 0.8979766964912415, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\16.png\n",
      "score is 0.9424203634262085, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\17.png\n",
      "score is 0.9983738660812378, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\18.png\n",
      "score is 0.9079758524894714, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\19.png\n",
      "score is 0.9996663331985474, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\2.png\n",
      "score is 0.5391979217529297, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\20.png\n",
      "score is 0.8796072602272034, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\21.png\n",
      "score is 0.9727234840393066, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\22.png\n",
      "score is 0.6091198325157166, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\23.png\n",
      "score is 0.9707558155059814, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\24.png\n",
      "score is 0.9563437104225159, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\25.png\n",
      "score is 0.9940517544746399, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\26.png\n",
      "score is 0.890555202960968, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\27.png\n",
      "score is 0.9996616840362549, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\28.png\n",
      "score is 0.6630303263664246, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\29.png\n",
      "score is 0.9551734924316406, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\3.png\n",
      "score is 0.9739243388175964, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\4.png\n",
      "score is 0.9996040463447571, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\5.png\n",
      "score is 0.9320812225341797, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\6.png\n",
      "score is 0.9592385292053223, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\7.png\n",
      "score is 0.8910505175590515, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\8.png\n",
      "score is 0.7588972449302673, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_0\\9.png\n",
      "score is 0.8711491823196411, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\0.png\n",
      "score is 0.8845776319503784, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\1.png\n",
      "score is 0.654533863067627, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\10.png\n",
      "score is 0.8582553863525391, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\11.png\n",
      "score is 0.9230847954750061, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\12.png\n",
      "score is 0.9866575598716736, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\13.png\n",
      "score is 0.7322486042976379, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\14.png\n",
      "score is 0.9224147796630859, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\15.png\n",
      "score is 0.8160800933837891, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\16.png\n",
      "score is 0.6773689985275269, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\17.png\n",
      "score is 0.6700732111930847, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\18.png\n",
      "score is 0.9683309197425842, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\19.png\n",
      "score is 0.982299268245697, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\2.png\n",
      "score is 0.7979205250740051, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\20.png\n",
      "score is 0.8429661393165588, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\21.png\n",
      "score is 0.986335039138794, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\22.png\n",
      "score is 0.9694929122924805, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\23.png\n",
      "score is 0.9845864772796631, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\24.png\n",
      "score is 0.6571441292762756, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\25.png\n",
      "score is 0.9880180358886719, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\26.png\n",
      "score is 0.8641520142555237, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\27.png\n",
      "score is 0.7643580436706543, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\28.png\n",
      "score is 0.6663439273834229, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\29.png\n",
      "score is 0.7573814988136292, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\3.png\n",
      "score is 0.970710039138794, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\4.png\n",
      "score is 0.821003258228302, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\5.png\n",
      "score is 0.8717154264450073, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\6.png\n",
      "score is 0.7430661916732788, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\7.png\n",
      "score is 0.9847817420959473, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\8.png\n",
      "score is 0.995908260345459, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [20:54, 43.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\sPBTxE\\sPBTxE_1\\9.png\n",
      "score is 0.9344416856765747, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\0.png\n",
      "score is 0.5476980805397034, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\1.png\n",
      "score is 0.9605541825294495, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\10.png\n",
      "score is 0.9997960925102234, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\11.png\n",
      "score is 0.6548611521720886, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\12.png\n",
      "score is 0.8241664171218872, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\13.png\n",
      "score is 0.5380406975746155, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\14.png\n",
      "score is 0.8606322407722473, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\15.png\n",
      "score is 0.8186016082763672, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\16.png\n",
      "score is 0.7119070887565613, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\17.png\n",
      "score is 0.9067549705505371, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\18.png\n",
      "score is 0.5893917083740234, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\19.png\n",
      "score is 0.5708835124969482, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\2.png\n",
      "score is 0.999691367149353, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\20.png\n",
      "score is 0.8428930044174194, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\21.png\n",
      "score is 0.9956756234169006, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\22.png\n",
      "score is 0.9999877214431763, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\23.png\n",
      "score is 0.4797380268573761, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\24.png\n",
      "score is 0.9556026458740234, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\25.png\n",
      "score is 0.9916115403175354, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\26.png\n",
      "score is 0.6723753213882446, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\27.png\n",
      "score is 0.9591571092605591, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\28.png\n",
      "score is 0.9868559241294861, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\29.png\n",
      "score is 0.9631609320640564, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\3.png\n",
      "score is 0.9995241165161133, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\4.png\n",
      "score is 0.9845982789993286, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\5.png\n",
      "score is 0.9690088629722595, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\6.png\n",
      "score is 0.9364940524101257, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\7.png\n",
      "score is 0.9436588287353516, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\8.png\n",
      "score is 0.7827445268630981, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [21:09, 34.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\tePz9r\\tePz9r_0\\9.png\n",
      "score is 0.93918776512146, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\0.png\n",
      "score is 0.9755325317382812, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\1.png\n",
      "score is 0.9389588832855225, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\10.png\n",
      "score is 0.9842627048492432, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\11.png\n",
      "score is 0.9661829471588135, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\12.png\n",
      "score is 0.9137341976165771, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\13.png\n",
      "score is 0.9999955892562866, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\15.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\16.png\n",
      "score is 0.7086933851242065, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\17.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\18.png\n",
      "score is 0.8429377675056458, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\19.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\2.png\n",
      "score is 0.5663294196128845, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\20.png\n",
      "score is 0.6212720274925232, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\21.png\n",
      "score is 0.9848600029945374, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\22.png\n",
      "score is 0.9276576638221741, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\23.png\n",
      "score is 0.883109986782074, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\24.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\25.png\n",
      "score is 0.8129369020462036, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\26.png\n",
      "score is 0.6866389513015747, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\27.png\n",
      "score is 0.6561527848243713, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\28.png\n",
      "score is 0.790963351726532, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\29.png\n",
      "score is 0.9204466342926025, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\3.png\n",
      "score is 0.7085260152816772, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\4.png\n",
      "score is 0.5291221141815186, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\5.png\n",
      "score is 0.9999961853027344, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\6.png\n",
      "score is 0.9414287805557251, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\7.png\n",
      "score is 0.9996621608734131, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\8.png\n",
      "score is 0.9963178634643555, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_0\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\0.png\n",
      "score is 0.9606361389160156, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\1.png\n",
      "score is 0.68960040807724, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\10.png\n",
      "score is 0.8995733857154846, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\11.png\n",
      "score is 0.9977766871452332, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\12.png\n",
      "score is 0.5820175409317017, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\13.png\n",
      "score is 0.8500998616218567, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\14.png\n",
      "score is 0.692495584487915, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\15.png\n",
      "score is 0.5130138993263245, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\16.png\n",
      "score is 0.9526526927947998, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\17.png\n",
      "score is 0.8711429834365845, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\18.png\n",
      "score is 0.8019591569900513, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\19.png\n",
      "score is 0.9449947476387024, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\2.png\n",
      "score is 0.5811048150062561, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\20.png\n",
      "score is 0.6436152458190918, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\21.png\n",
      "score is 0.7501112222671509, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\22.png\n",
      "score is 0.8303327560424805, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\23.png\n",
      "score is 0.7365463972091675, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\24.png\n",
      "score is 0.5947770476341248, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\25.png\n",
      "score is 0.5416600108146667, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\26.png\n",
      "score is 0.7709562182426453, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\27.png\n",
      "score is 0.9187732338905334, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\28.png\n",
      "score is 0.9192978739738464, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\29.png\n",
      "score is 0.7845278382301331, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\3.png\n",
      "score is 0.5318001508712769, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\4.png\n",
      "score is 0.8468944430351257, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\5.png\n",
      "score is 0.6829330921173096, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\6.png\n",
      "score is 0.640855610370636, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\7.png\n",
      "score is 0.5194244384765625, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\8.png\n",
      "score is 0.9660060405731201, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_1\\9.png\n",
      "score is 0.951735258102417, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\0.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\10.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\11.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\12.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\13.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\15.png\n",
      "score is 0.9999861717224121, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\16.png\n",
      "score is 0.9219095706939697, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\17.png\n",
      "score is 0.9989429116249084, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\18.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\19.png\n",
      "score is 0.9994694590568542, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\2.png\n",
      "score is 0.9973627924919128, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\20.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\21.png\n",
      "score is 0.869448721408844, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\22.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\24.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\25.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\26.png\n",
      "score is 0.97320955991745, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\27.png\n",
      "score is 0.868625283241272, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\28.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\29.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\3.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\4.png\n",
      "score is 0.9999996423721313, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\5.png\n",
      "score is 0.9999977350234985, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\6.png\n",
      "score is 0.9999947547912598, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\7.png\n",
      "score is 0.9999996423721313, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\8.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [21:53, 37.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\trx9ej\\trx9ej_2\\9.png\n",
      "score is 0.7527804374694824, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\0.png\n",
      "score is 0.6142866015434265, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\1.png\n",
      "score is 0.6562162041664124, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\10.png\n",
      "score is 0.977661669254303, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\11.png\n",
      "score is 0.9999974966049194, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\12.png\n",
      "score is 0.9316797852516174, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\13.png\n",
      "score is 0.9924271702766418, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\14.png\n",
      "score is 0.9105126857757568, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\15.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\16.png\n",
      "score is 0.864779531955719, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\17.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\18.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\19.png\n",
      "score is 0.705493688583374, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\2.png\n",
      "score is 0.6139706969261169, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\20.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\21.png\n",
      "score is 0.9298762679100037, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\22.png\n",
      "score is 0.6900648474693298, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\23.png\n",
      "score is 0.5145407319068909, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\24.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\25.png\n",
      "score is 0.970386266708374, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\26.png\n",
      "score is 0.5355433821678162, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\27.png\n",
      "score is 0.9652161002159119, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\28.png\n",
      "score is 0.9562291502952576, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\29.png\n",
      "score is 0.963216245174408, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\3.png\n",
      "score is 0.6140413284301758, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\4.png\n",
      "score is 0.9218697547912598, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\5.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\6.png\n",
      "score is 0.9588304162025452, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\7.png\n",
      "score is 0.9635354280471802, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\8.png\n",
      "score is 0.6274170875549316, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_0\\9.png\n",
      "score is 0.833270788192749, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\0.png\n",
      "score is 0.7808116674423218, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\1.png\n",
      "score is 0.7604445815086365, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\10.png\n",
      "score is 0.6768506169319153, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\11.png\n",
      "score is 0.952252209186554, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\12.png\n",
      "score is 0.9651339054107666, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\13.png\n",
      "score is 0.8396289944648743, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\14.png\n",
      "score is 0.931484043598175, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\15.png\n",
      "score is 0.7421859502792358, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\16.png\n",
      "score is 0.9995961785316467, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\17.png\n",
      "score is 0.5723426342010498, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\18.png\n",
      "score is 0.904090166091919, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\19.png\n",
      "score is 0.9916937947273254, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\2.png\n",
      "score is 0.8433119058609009, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\20.png\n",
      "score is 0.9260783195495605, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\21.png\n",
      "score is 0.5955403447151184, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\22.png\n",
      "score is 0.8739921450614929, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\23.png\n",
      "score is 0.5851011872291565, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\24.png\n",
      "score is 0.9986068606376648, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\25.png\n",
      "score is 0.9801191091537476, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\26.png\n",
      "score is 0.9433426856994629, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\27.png\n",
      "score is 0.5475384593009949, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\28.png\n",
      "score is 0.8288546800613403, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\29.png\n",
      "score is 0.9532046318054199, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\3.png\n",
      "score is 0.9951693415641785, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\4.png\n",
      "score is 0.972606897354126, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\5.png\n",
      "score is 0.7161234617233276, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\6.png\n",
      "score is 0.9016956686973572, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\7.png\n",
      "score is 0.8124993443489075, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\8.png\n",
      "score is 0.5731375813484192, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_1\\9.png\n",
      "score is 0.9917424917221069, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\0.png\n",
      "score is 0.9978446960449219, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\1.png\n",
      "score is 0.48903053998947144, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\10.png\n",
      "score is 0.7610003352165222, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\11.png\n",
      "score is 0.993502676486969, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\12.png\n",
      "score is 0.8355548977851868, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\13.png\n",
      "score is 0.996966540813446, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\14.png\n",
      "score is 0.6102701425552368, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\15.png\n",
      "score is 0.5280755162239075, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\16.png\n",
      "score is 0.5838384628295898, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\17.png\n",
      "score is 0.7026624083518982, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\18.png\n",
      "score is 0.6143507957458496, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\19.png\n",
      "score is 0.5296643972396851, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\2.png\n",
      "score is 0.8997381925582886, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\20.png\n",
      "score is 0.9557188153266907, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\21.png\n",
      "score is 0.9625827074050903, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\22.png\n",
      "score is 0.911422610282898, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\23.png\n",
      "score is 0.6934084892272949, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\24.png\n",
      "score is 0.9824138879776001, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\25.png\n",
      "score is 0.6440111398696899, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\26.png\n",
      "score is 0.5034149885177612, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\27.png\n",
      "score is 0.5021421909332275, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\28.png\n",
      "score is 0.7580541968345642, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\29.png\n",
      "score is 0.9722793102264404, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\3.png\n",
      "score is 0.8410043716430664, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\4.png\n",
      "score is 0.7825387716293335, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\5.png\n",
      "score is 0.9988440275192261, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\6.png\n",
      "score is 0.6349601149559021, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\7.png\n",
      "score is 0.7921834588050842, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\8.png\n",
      "score is 0.5703363418579102, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [22:39, 39.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\tZl5k7\\tZl5k7_2\\9.png\n",
      "score is 0.6279049515724182, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\0.png\n",
      "score is 0.9247679710388184, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\1.png\n",
      "score is 0.9926968216896057, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\10.png\n",
      "score is 0.9994038343429565, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\11.png\n",
      "score is 0.9965744018554688, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\12.png\n",
      "score is 0.8795674443244934, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\13.png\n",
      "score is 0.9880699515342712, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\14.png\n",
      "score is 0.8300800323486328, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\15.png\n",
      "score is 0.9936521053314209, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\16.png\n",
      "score is 0.6578790545463562, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\17.png\n",
      "score is 0.9673319458961487, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\18.png\n",
      "score is 0.7483378052711487, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\19.png\n",
      "score is 0.9997013211250305, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\2.png\n",
      "score is 0.9914959669113159, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\20.png\n",
      "score is 0.6868125796318054, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\21.png\n",
      "score is 0.7811681628227234, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\22.png\n",
      "score is 0.6677634716033936, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\23.png\n",
      "score is 0.9814792275428772, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\24.png\n",
      "score is 0.9945007562637329, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\25.png\n",
      "score is 0.999428927898407, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\26.png\n",
      "score is 0.9912999272346497, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\27.png\n",
      "score is 0.6336671113967896, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\28.png\n",
      "score is 0.56949782371521, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\29.png\n",
      "score is 0.9210978150367737, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\3.png\n",
      "score is 0.7430018186569214, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\4.png\n",
      "score is 0.9997658133506775, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\5.png\n",
      "score is 0.5228783488273621, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\6.png\n",
      "score is 0.7269647121429443, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\7.png\n",
      "score is 0.6968413591384888, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\8.png\n",
      "score is 0.9200991988182068, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [22:54, 32.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\uBGVp5\\uBGVp5_0\\9.png\n",
      "score is 0.9238237738609314, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\0.png\n",
      "score is 0.9793522953987122, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\1.png\n",
      "score is 0.6188222169876099, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\10.png\n",
      "score is 0.992766261100769, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\11.png\n",
      "score is 0.8140847682952881, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\12.png\n",
      "score is 0.9825038313865662, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\13.png\n",
      "score is 0.9793242812156677, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\14.png\n",
      "score is 0.8751508593559265, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\15.png\n",
      "score is 0.4743257761001587, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\16.png\n",
      "score is 0.39220958948135376, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\17.png\n",
      "score is 0.5204837918281555, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\18.png\n",
      "score is 0.9858200550079346, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\19.png\n",
      "score is 0.941606342792511, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\2.png\n",
      "score is 0.9619720578193665, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\20.png\n",
      "score is 0.8970303535461426, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\21.png\n",
      "score is 0.947733998298645, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\22.png\n",
      "score is 0.9944741129875183, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\23.png\n",
      "score is 0.5420822501182556, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\24.png\n",
      "score is 0.9836412668228149, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\25.png\n",
      "score is 0.9870801568031311, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\26.png\n",
      "score is 0.988134503364563, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\27.png\n",
      "score is 0.9035664796829224, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\28.png\n",
      "score is 0.5022941827774048, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\29.png\n",
      "score is 0.5085958242416382, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\3.png\n",
      "score is 0.9218311309814453, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\4.png\n",
      "score is 0.7524058818817139, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\5.png\n",
      "score is 0.9899876713752747, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\6.png\n",
      "score is 0.9811601042747498, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\7.png\n",
      "score is 0.9165177345275879, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\8.png\n",
      "score is 0.6914217472076416, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_0\\9.png\n",
      "score is 0.622530996799469, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\0.png\n",
      "score is 0.973655641078949, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\1.png\n",
      "score is 0.7421620488166809, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\10.png\n",
      "score is 0.9981080293655396, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\11.png\n",
      "score is 0.9999731779098511, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\12.png\n",
      "score is 0.9662636518478394, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\13.png\n",
      "score is 0.9982543587684631, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\14.png\n",
      "score is 0.4862182140350342, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\15.png\n",
      "score is 0.9999632835388184, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\16.png\n",
      "score is 0.9003105163574219, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\17.png\n",
      "score is 0.9997578263282776, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\18.png\n",
      "score is 0.996861457824707, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\19.png\n",
      "score is 0.9967869520187378, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\2.png\n",
      "score is 0.5575627088546753, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\20.png\n",
      "score is 0.7075625658035278, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\21.png\n",
      "score is 0.9828277826309204, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\22.png\n",
      "score is 0.9978420734405518, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\23.png\n",
      "score is 0.9631535410881042, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\24.png\n",
      "score is 0.9871986508369446, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\25.png\n",
      "score is 0.6313637495040894, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\26.png\n",
      "score is 0.9996668100357056, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\27.png\n",
      "score is 0.9999698400497437, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\28.png\n",
      "score is 0.999972939491272, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\29.png\n",
      "score is 0.9895360469818115, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\3.png\n",
      "score is 0.6805532574653625, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\4.png\n",
      "score is 0.9864274859428406, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\5.png\n",
      "score is 0.9526793956756592, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\6.png\n",
      "score is 0.5680974721908569, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\7.png\n",
      "score is 0.5469359159469604, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\8.png\n",
      "score is 0.968910813331604, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_1\\9.png\n",
      "score is 0.7442016005516052, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\0.png\n",
      "score is 0.5871080756187439, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\1.png\n",
      "score is 0.9999998807907104, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\10.png\n",
      "score is 0.9997918009757996, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\11.png\n",
      "score is 0.9831792116165161, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\12.png\n",
      "score is 0.9926044940948486, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\13.png\n",
      "score is 0.9754365682601929, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\14.png\n",
      "score is 0.9999992847442627, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\15.png\n",
      "score is 0.9990309476852417, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\16.png\n",
      "score is 0.9856768846511841, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\17.png\n",
      "score is 0.7298263311386108, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\18.png\n",
      "score is 0.9993590712547302, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\19.png\n",
      "score is 0.977916419506073, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\2.png\n",
      "score is 0.6956402659416199, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\20.png\n",
      "score is 0.9081075191497803, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\21.png\n",
      "score is 0.9898092746734619, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\22.png\n",
      "score is 0.9999217987060547, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\23.png\n",
      "score is 0.9379734396934509, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\24.png\n",
      "score is 0.999988317489624, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\25.png\n",
      "score is 0.8356392979621887, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\26.png\n",
      "score is 0.893390953540802, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\27.png\n",
      "score is 0.9999964237213135, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\28.png\n",
      "score is 0.9614647626876831, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\29.png\n",
      "score is 0.6000732779502869, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\3.png\n",
      "score is 0.6214296221733093, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\4.png\n",
      "score is 0.9999998807907104, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\5.png\n",
      "score is 0.9999890327453613, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\6.png\n",
      "score is 0.9999068975448608, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\7.png\n",
      "score is 1.0, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\8.png\n",
      "score is 0.9997807145118713, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_2\\9.png\n",
      "score is 0.678416907787323, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\0.png\n",
      "score is 0.6039000749588013, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\1.png\n",
      "score is 0.9979248046875, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\10.png\n",
      "score is 0.996729850769043, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\11.png\n",
      "score is 0.9957730174064636, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\12.png\n",
      "score is 0.8733331561088562, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\13.png\n",
      "score is 0.9529364109039307, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\14.png\n",
      "score is 0.9326061010360718, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\15.png\n",
      "score is 0.9992157220840454, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\16.png\n",
      "score is 0.9954875111579895, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\17.png\n",
      "score is 0.9985920786857605, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\18.png\n",
      "score is 0.9964583516120911, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\19.png\n",
      "score is 0.6074289083480835, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\2.png\n",
      "score is 0.947272002696991, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\20.png\n",
      "score is 0.9998846054077148, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\21.png\n",
      "score is 0.9884536862373352, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\22.png\n",
      "score is 0.5420156121253967, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\23.png\n",
      "score is 0.8810445070266724, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\24.png\n",
      "score is 0.8109073042869568, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\25.png\n",
      "score is 0.9637664556503296, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\26.png\n",
      "score is 0.4173502027988434, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\27.png\n",
      "score is 0.997665286064148, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\28.png\n",
      "score is 0.5479010343551636, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\29.png\n",
      "score is 0.5924562215805054, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\3.png\n",
      "score is 0.8505024909973145, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\4.png\n",
      "score is 0.999137282371521, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\5.png\n",
      "score is 0.9782016277313232, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\6.png\n",
      "score is 0.6748445630073547, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\7.png\n",
      "score is 0.993629515171051, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\8.png\n",
      "score is 0.6976484656333923, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_3\\9.png\n",
      "score is 0.49038511514663696, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\0.png\n",
      "score is 0.9997033476829529, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\1.png\n",
      "score is 0.8440843224525452, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\10.png\n",
      "score is 0.8755980730056763, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\11.png\n",
      "score is 0.8695193529129028, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\12.png\n",
      "score is 0.8169155120849609, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\13.png\n",
      "score is 0.9972139000892639, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\14.png\n",
      "score is 0.8588427901268005, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\15.png\n",
      "score is 0.9996395111083984, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\16.png\n",
      "score is 0.9761270880699158, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\17.png\n",
      "score is 0.9988892674446106, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\18.png\n",
      "score is 0.9994876384735107, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\19.png\n",
      "score is 0.5945351123809814, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\2.png\n",
      "score is 0.9893937110900879, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\20.png\n",
      "score is 0.9918053150177002, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\21.png\n",
      "score is 0.5022137761116028, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\22.png\n",
      "score is 0.9924206137657166, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\23.png\n",
      "score is 0.908287763595581, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\24.png\n",
      "score is 0.9291369318962097, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\25.png\n",
      "score is 0.9100421071052551, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\26.png\n",
      "score is 0.9845561981201172, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\27.png\n",
      "score is 0.9802435636520386, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\28.png\n",
      "score is 0.9585446715354919, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\29.png\n",
      "score is 0.9828727841377258, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\3.png\n",
      "score is 0.6717531681060791, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\4.png\n",
      "score is 0.8612109422683716, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\5.png\n",
      "score is 0.555004358291626, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\6.png\n",
      "score is 0.9706136584281921, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\7.png\n",
      "score is 0.5673021078109741, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\8.png\n",
      "score is 0.9910814762115479, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_4\\9.png\n",
      "score is 0.9993318915367126, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\0.png\n",
      "score is 0.9993157386779785, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\1.png\n",
      "score is 0.9874191880226135, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\10.png\n",
      "score is 0.9704254269599915, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\11.png\n",
      "score is 0.9935463070869446, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\12.png\n",
      "score is 0.9677956700325012, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\13.png\n",
      "score is 0.9706770777702332, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\14.png\n",
      "score is 0.9931218028068542, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\15.png\n",
      "score is 0.958091139793396, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\16.png\n",
      "score is 0.9872922897338867, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\17.png\n",
      "score is 0.9593146443367004, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\18.png\n",
      "score is 0.4492679834365845, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\19.png\n",
      "score is 0.9962789416313171, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\2.png\n",
      "score is 0.9977216124534607, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\20.png\n",
      "score is 0.9287768006324768, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\21.png\n",
      "score is 0.5067542791366577, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\22.png\n",
      "score is 0.9433876872062683, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\23.png\n",
      "score is 0.6357378363609314, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\24.png\n",
      "score is 0.9995855689048767, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\25.png\n",
      "score is 0.5241988301277161, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\26.png\n",
      "score is 0.8724889755249023, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\27.png\n",
      "score is 0.9999748468399048, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\28.png\n",
      "score is 0.999647855758667, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\29.png\n",
      "score is 0.9978850483894348, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\3.png\n",
      "score is 0.9527708292007446, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\4.png\n",
      "score is 0.610619306564331, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\5.png\n",
      "score is 0.9962471127510071, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\6.png\n",
      "score is 0.9999758005142212, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\7.png\n",
      "score is 0.9993197917938232, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\8.png\n",
      "score is 0.41178300976753235, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_5\\9.png\n",
      "score is 0.9993124008178711, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\0.png\n",
      "score is 0.49802449345588684, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\1.png\n",
      "score is 0.8116200566291809, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\10.png\n",
      "score is 0.9999963045120239, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\11.png\n",
      "score is 0.992199718952179, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\12.png\n",
      "score is 0.9993174076080322, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\13.png\n",
      "score is 0.9997667670249939, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\14.png\n",
      "score is 0.9770315289497375, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\15.png\n",
      "score is 0.6697477102279663, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\16.png\n",
      "score is 0.5735722780227661, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\17.png\n",
      "score is 0.5655982494354248, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\18.png\n",
      "score is 0.9946935772895813, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\19.png\n",
      "score is 0.8946382999420166, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\2.png\n",
      "score is 0.8361945748329163, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\20.png\n",
      "score is 0.666058361530304, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\21.png\n",
      "score is 0.9866310954093933, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\22.png\n",
      "score is 0.7455543279647827, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\23.png\n",
      "score is 0.9999010562896729, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\24.png\n",
      "score is 0.780630886554718, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\25.png\n",
      "score is 0.7646734118461609, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\26.png\n",
      "score is 0.5317527651786804, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\27.png\n",
      "score is 0.6506556868553162, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\28.png\n",
      "score is 0.995684027671814, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\29.png\n",
      "score is 0.9984306693077087, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\3.png\n",
      "score is 0.9994606375694275, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\4.png\n",
      "score is 0.9988800883293152, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\5.png\n",
      "score is 0.9969154596328735, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\6.png\n",
      "score is 0.9992777705192566, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\7.png\n",
      "score is 0.999997615814209, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\8.png\n",
      "score is 0.3684084713459015, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_6\\9.png\n",
      "score is 0.9990702271461487, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\0.png\n",
      "score is 0.9964854717254639, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\1.png\n",
      "score is 0.9992979764938354, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\10.png\n",
      "score is 0.9999881982803345, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\11.png\n",
      "score is 0.9952442049980164, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\12.png\n",
      "score is 0.998991072177887, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\13.png\n",
      "score is 0.871902346611023, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\14.png\n",
      "score is 0.9877063632011414, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\15.png\n",
      "score is 0.8738074898719788, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\16.png\n",
      "score is 0.9998383522033691, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\17.png\n",
      "score is 0.978853166103363, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\18.png\n",
      "score is 0.9467702507972717, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\19.png\n",
      "score is 0.9979259967803955, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\2.png\n",
      "score is 0.9985225796699524, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\20.png\n",
      "score is 0.9995860457420349, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\21.png\n",
      "score is 0.9999555349349976, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\22.png\n",
      "score is 0.9941998720169067, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\23.png\n",
      "score is 0.977835476398468, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\24.png\n",
      "score is 0.9426140189170837, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\25.png\n",
      "score is 0.9999998807907104, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\26.png\n",
      "score is 0.9997671246528625, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\27.png\n",
      "score is 0.49539607763290405, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\28.png\n",
      "score is 0.7214222550392151, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\29.png\n",
      "score is 0.8381427526473999, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\3.png\n",
      "score is 0.986615002155304, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\4.png\n",
      "score is 0.9508817195892334, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\5.png\n",
      "score is 0.9999521970748901, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\6.png\n",
      "score is 0.9999808073043823, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\7.png\n",
      "score is 0.9765229821205139, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\8.png\n",
      "score is 0.9999998807907104, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [24:53, 58.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\uj56hr\\uj56hr_7\\9.png\n",
      "score is 0.9997623562812805, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\0.png\n",
      "score is 0.9999613761901855, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\1.png\n",
      "score is 0.9998946189880371, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\10.png\n",
      "score is 0.5610281825065613, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\11.png\n",
      "score is 0.6167231798171997, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\12.png\n",
      "score is 0.9193115830421448, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\13.png\n",
      "score is 0.9999977350234985, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\14.png\n",
      "score is 0.6023406386375427, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\15.png\n",
      "score is 0.9999966621398926, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\16.png\n",
      "score is 0.9039995670318604, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\17.png\n",
      "score is 0.9169942140579224, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\18.png\n",
      "score is 0.9202044606208801, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\19.png\n",
      "score is 0.9998505115509033, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\2.png\n",
      "score is 0.658290445804596, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\20.png\n",
      "score is 0.9994516968727112, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\21.png\n",
      "score is 0.9930065870285034, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\22.png\n",
      "score is 0.6947329640388489, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\23.png\n",
      "score is 0.9285137057304382, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\24.png\n",
      "score is 0.9999988079071045, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\25.png\n",
      "score is 0.9998759031295776, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\26.png\n",
      "score is 0.6328988671302795, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\27.png\n",
      "score is 0.6810441017150879, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\28.png\n",
      "score is 0.941770613193512, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\29.png\n",
      "score is 0.9987820982933044, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\3.png\n",
      "score is 0.9999905824661255, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\4.png\n",
      "score is 0.8167747259140015, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\5.png\n",
      "score is 0.9999476671218872, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\6.png\n",
      "score is 0.9970291256904602, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\7.png\n",
      "score is 0.8652032017707825, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\8.png\n",
      "score is 0.6075819730758667, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_0\\9.png\n",
      "score is 0.9997243285179138, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\0.png\n",
      "score is 0.6448365449905396, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\1.png\n",
      "score is 0.9989843964576721, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\10.png\n",
      "score is 0.9999971389770508, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\11.png\n",
      "score is 0.9761665463447571, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\12.png\n",
      "score is 0.9998714923858643, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\13.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\14.png\n",
      "score is 0.6075088381767273, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\15.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\16.png\n",
      "score is 0.9729156494140625, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\17.png\n",
      "score is 0.9810720086097717, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\18.png\n",
      "score is 0.5275341272354126, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\19.png\n",
      "score is 0.9999983310699463, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\2.png\n",
      "score is 0.9999717473983765, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\20.png\n",
      "score is 0.9825335144996643, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\21.png\n",
      "score is 0.7988637089729309, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\22.png\n",
      "score is 0.8922306299209595, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\24.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\25.png\n",
      "score is 0.9854009747505188, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\26.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\27.png\n",
      "score is 0.9997919201850891, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\28.png\n",
      "score is 0.8924583792686462, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\29.png\n",
      "score is 0.7654889225959778, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\3.png\n",
      "score is 0.7499455809593201, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\4.png\n",
      "score is 0.9676651358604431, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\5.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\6.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\7.png\n",
      "score is 0.5077018737792969, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\8.png\n",
      "score is 0.8852015137672424, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_1\\9.png\n",
      "score is 0.9920141100883484, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\0.png\n",
      "score is 0.9265192747116089, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\1.png\n",
      "score is 0.9061477780342102, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\10.png\n",
      "score is 0.8994351625442505, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\11.png\n",
      "score is 0.87453693151474, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\12.png\n",
      "score is 0.7440590858459473, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\13.png\n",
      "score is 0.7505393624305725, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\14.png\n",
      "score is 0.5027990937232971, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\15.png\n",
      "score is 0.6326127052307129, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\16.png\n",
      "score is 0.9881459474563599, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\17.png\n",
      "score is 0.9914852976799011, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\18.png\n",
      "score is 0.5429243445396423, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\19.png\n",
      "score is 0.6105614304542542, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\2.png\n",
      "score is 0.9969748258590698, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\20.png\n",
      "score is 0.8978651762008667, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\21.png\n",
      "score is 0.5568131804466248, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\22.png\n",
      "score is 0.827802836894989, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\23.png\n",
      "score is 0.9996856451034546, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\24.png\n",
      "score is 0.7295020818710327, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\25.png\n",
      "score is 0.925773024559021, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\26.png\n",
      "score is 0.9684810638427734, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\27.png\n",
      "score is 0.8931167721748352, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\28.png\n",
      "score is 0.7028382420539856, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\29.png\n",
      "score is 0.9902839064598083, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\3.png\n",
      "score is 0.8850609660148621, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\4.png\n",
      "score is 0.73293536901474, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\5.png\n",
      "score is 0.9667980670928955, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\6.png\n",
      "score is 0.7144092321395874, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\7.png\n",
      "score is 0.9471563696861267, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\8.png\n",
      "score is 0.9143940210342407, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [25:37, 54.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\vLZGD6\\vLZGD6_2\\9.png\n",
      "score is 0.8317311406135559, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\0.png\n",
      "score is 0.999998927116394, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\10.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\11.png\n",
      "score is 0.9769195318222046, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\12.png\n",
      "score is 0.9384627342224121, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\13.png\n",
      "score is 0.9999960660934448, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\14.png\n",
      "score is 0.9999980926513672, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\15.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\16.png\n",
      "score is 0.958426296710968, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\17.png\n",
      "score is 0.8626047968864441, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\18.png\n",
      "score is 0.9999903440475464, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\19.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\2.png\n",
      "score is 0.5502879619598389, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\20.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\21.png\n",
      "score is 0.5524754524230957, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\22.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\24.png\n",
      "score is 0.9861143827438354, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\25.png\n",
      "score is 0.9999842643737793, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\26.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\27.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\28.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\29.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\3.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\4.png\n",
      "score is 0.9966309666633606, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\5.png\n",
      "score is 0.9990180730819702, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\6.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\7.png\n",
      "score is 0.973824143409729, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\8.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_0\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\0.png\n",
      "score is 0.7528142333030701, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\1.png\n",
      "score is 0.9929690957069397, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\10.png\n",
      "score is 0.9753565788269043, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\11.png\n",
      "score is 0.9891995191574097, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\12.png\n",
      "score is 0.9947408437728882, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\13.png\n",
      "score is 0.9999386072158813, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\14.png\n",
      "score is 0.8292303681373596, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\15.png\n",
      "score is 0.995108425617218, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\16.png\n",
      "score is 0.8760843873023987, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\17.png\n",
      "score is 0.9999645948410034, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\18.png\n",
      "score is 0.9390749335289001, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\19.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\2.png\n",
      "score is 0.5307028293609619, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\20.png\n",
      "score is 0.9999942779541016, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\21.png\n",
      "score is 0.972461998462677, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\22.png\n",
      "score is 0.5330671072006226, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\23.png\n",
      "score is 0.9999980926513672, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\24.png\n",
      "score is 0.5632482171058655, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\25.png\n",
      "score is 0.5490765571594238, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\26.png\n",
      "score is 0.8171009421348572, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\27.png\n",
      "score is 0.9487947821617126, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\28.png\n",
      "score is 0.9980565905570984, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\29.png\n",
      "score is 0.9663497805595398, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\3.png\n",
      "score is 0.992141604423523, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\4.png\n",
      "score is 0.9489421844482422, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\5.png\n",
      "score is 0.9777454137802124, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\6.png\n",
      "score is 0.7990513443946838, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\7.png\n",
      "score is 0.8314933776855469, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\8.png\n",
      "score is 0.9999935626983643, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_1\\9.png\n",
      "score is 0.9996131062507629, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\0.png\n",
      "score is 0.6089317202568054, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\1.png\n",
      "score is 0.9995291233062744, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\10.png\n",
      "score is 0.8309944272041321, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\11.png\n",
      "score is 0.5820615291595459, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\12.png\n",
      "score is 0.6113414764404297, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\13.png\n",
      "score is 0.6220383048057556, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\14.png\n",
      "score is 0.7474732995033264, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\15.png\n",
      "score is 0.8589633703231812, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\16.png\n",
      "score is 0.8448622226715088, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\17.png\n",
      "score is 0.9988833069801331, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\18.png\n",
      "score is 0.9995311498641968, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\19.png\n",
      "score is 0.999083399772644, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\2.png\n",
      "score is 0.999966025352478, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\20.png\n",
      "score is 0.9952448010444641, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\21.png\n",
      "score is 0.9982752799987793, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\22.png\n",
      "score is 0.9976651668548584, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\23.png\n",
      "score is 0.5690908432006836, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\24.png\n",
      "score is 0.9999958276748657, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\25.png\n",
      "score is 0.9922419786453247, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\26.png\n",
      "score is 0.7042210698127747, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\27.png\n",
      "score is 0.9942383766174316, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\28.png\n",
      "score is 0.5570903420448303, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\29.png\n",
      "score is 0.5132957696914673, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\3.png\n",
      "score is 0.4916354715824127, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\4.png\n",
      "score is 0.6064196825027466, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\5.png\n",
      "score is 0.6313929557800293, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\6.png\n",
      "score is 0.9864637851715088, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\7.png\n",
      "score is 0.5551174879074097, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\8.png\n",
      "score is 0.7652761340141296, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vNxSRB\\vNxSRB_2\\9.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [26:22, 51.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score is 0.9170721769332886, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\0.png\n",
      "score is 0.9261748194694519, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\1.png\n",
      "score is 0.9985814094543457, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\10.png\n",
      "score is 0.8102116584777832, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\11.png\n",
      "score is 0.6579838395118713, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\12.png\n",
      "score is 0.9224676489830017, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\13.png\n",
      "score is 0.9984323382377625, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\14.png\n",
      "score is 0.9110828042030334, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\15.png\n",
      "score is 0.9998478889465332, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\16.png\n",
      "score is 0.6310946345329285, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\17.png\n",
      "score is 0.9998335838317871, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\18.png\n",
      "score is 0.858485758304596, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\19.png\n",
      "score is 0.7909131050109863, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\2.png\n",
      "score is 0.8715701103210449, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\20.png\n",
      "score is 0.9997292160987854, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\21.png\n",
      "score is 0.8003600239753723, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\22.png\n",
      "score is 0.9976523518562317, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\23.png\n",
      "score is 0.7724596858024597, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\24.png\n",
      "score is 0.999594509601593, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\25.png\n",
      "score is 0.5560692548751831, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\26.png\n",
      "score is 0.542748212814331, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\27.png\n",
      "score is 0.4976575970649719, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\28.png\n",
      "score is 0.9992095232009888, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\29.png\n",
      "score is 0.9976106882095337, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\3.png\n",
      "score is 0.7768324613571167, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\4.png\n",
      "score is 0.9996629953384399, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\5.png\n",
      "score is 0.5810084342956543, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\6.png\n",
      "score is 0.9999983310699463, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\7.png\n",
      "score is 0.9816564917564392, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\8.png\n",
      "score is 0.9999336004257202, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_0\\9.png\n",
      "score is 0.709760844707489, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\0.png\n",
      "score is 0.8934075236320496, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\1.png\n",
      "score is 0.8707706928253174, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\10.png\n",
      "score is 0.9794095754623413, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\11.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\12.png\n",
      "score is 0.9999978542327881, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\13.png\n",
      "score is 0.6699473261833191, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\14.png\n",
      "score is 0.7933581471443176, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\15.png\n",
      "score is 0.7040145993232727, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\16.png\n",
      "score is 0.39078396558761597, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\17.png\n",
      "score is 0.7623557448387146, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\18.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\19.png\n",
      "score is 0.9788326025009155, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\2.png\n",
      "score is 0.5497542023658752, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\20.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\21.png\n",
      "score is 0.9274656772613525, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\22.png\n",
      "score is 0.9650922417640686, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\23.png\n",
      "score is 0.97239750623703, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\24.png\n",
      "score is 0.8060760498046875, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\25.png\n",
      "score is 0.9433338046073914, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\26.png\n",
      "score is 0.5882635116577148, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\27.png\n",
      "score is 0.9620761275291443, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\28.png\n",
      "score is 0.9850168228149414, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\29.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\3.png\n",
      "score is 0.5248682498931885, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\4.png\n",
      "score is 0.6969138979911804, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\5.png\n",
      "score is 0.8465518355369568, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\6.png\n",
      "score is 0.9999868869781494, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\7.png\n",
      "score is 0.9999902248382568, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\8.png\n",
      "score is 0.9867227673530579, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_1\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\0.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\1.png\n",
      "score is 0.9273397922515869, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\10.png\n",
      "score is 0.9970465302467346, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\11.png\n",
      "score is 0.7624596953392029, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\12.png\n",
      "score is 0.9834958910942078, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\13.png\n",
      "score is 0.8545846343040466, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\14.png\n",
      "score is 0.91175776720047, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\15.png\n",
      "score is 0.9971106052398682, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\16.png\n",
      "score is 0.9998960494995117, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\17.png\n",
      "score is 0.8379178643226624, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\18.png\n",
      "score is 0.9999959468841553, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\19.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\2.png\n",
      "score is 0.7706313133239746, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\20.png\n",
      "score is 0.5467599630355835, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\21.png\n",
      "score is 0.9981093406677246, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\22.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\23.png\n",
      "score is 0.9999996423721313, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\24.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\25.png\n",
      "score is 0.9445074796676636, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\26.png\n",
      "score is 0.5700398683547974, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\27.png\n",
      "score is 0.9959081411361694, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\28.png\n",
      "score is 0.6155657172203064, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\29.png\n",
      "score is 0.9865415096282959, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\3.png\n",
      "score is 0.5850499868392944, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\4.png\n",
      "score is 0.6301138997077942, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\5.png\n",
      "score is 0.968257486820221, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\6.png\n",
      "score is 0.9999533891677856, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\7.png\n",
      "score is 0.8430030345916748, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\8.png\n",
      "score is 0.999854564666748, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_2\\9.png\n",
      "score is 0.5115942358970642, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\0.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\10.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\11.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\12.png\n",
      "score is 0.9424580335617065, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\13.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\14.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\15.png\n",
      "score is 0.9997610449790955, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\16.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\17.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\18.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\19.png\n",
      "score is 0.7775503396987915, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\2.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\20.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\21.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\22.png\n",
      "score is 0.9965786337852478, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\24.png\n",
      "score is 0.965576171875, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\25.png\n",
      "score is 0.7577919960021973, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\26.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\27.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\28.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\29.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\3.png\n",
      "score is 0.891792356967926, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\4.png\n",
      "score is 0.9999942779541016, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\5.png\n",
      "score is 0.9918003678321838, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\6.png\n",
      "score is 0.8933291435241699, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\7.png\n",
      "score is 0.9322582483291626, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\8.png\n",
      "score is 0.9161462783813477, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [27:22, 53.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\vPE2HD\\vPE2HD_3\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\0.png\n",
      "score is 0.9694721698760986, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\1.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\10.png\n",
      "score is 0.9999969005584717, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\11.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\12.png\n",
      "score is 0.9999940395355225, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\13.png\n",
      "score is 0.9347904920578003, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\14.png\n",
      "score is 0.9999980926513672, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\15.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\16.png\n",
      "score is 0.7458553314208984, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\17.png\n",
      "score is 0.9819105267524719, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\18.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\19.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\2.png\n",
      "score is 0.9813135862350464, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\20.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\21.png\n",
      "score is 0.9404555559158325, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\22.png\n",
      "score is 0.9999868869781494, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\23.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\24.png\n",
      "score is 0.9341859817504883, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\25.png\n",
      "score is 0.9066888093948364, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\26.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\27.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\28.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\29.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\3.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\4.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\5.png\n",
      "score is 0.5694348812103271, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\6.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\7.png\n",
      "score is 0.9513266086578369, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\8.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_0\\9.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\0.png\n",
      "score is 0.5930513143539429, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\1.png\n",
      "score is 0.9990229606628418, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\10.png\n",
      "score is 0.8866757750511169, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\11.png\n",
      "score is 0.5900522470474243, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\12.png\n",
      "score is 0.9467288255691528, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\13.png\n",
      "score is 0.9859700798988342, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\14.png\n",
      "score is 0.8720790147781372, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\15.png\n",
      "score is 0.7001201510429382, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\16.png\n",
      "score is 0.788716197013855, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\17.png\n",
      "score is 0.8927616477012634, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\18.png\n",
      "score is 0.7726022005081177, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\19.png\n",
      "score is 0.7416557669639587, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\2.png\n",
      "score is 0.9564002752304077, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\20.png\n",
      "score is 0.7816120386123657, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\21.png\n",
      "score is 0.933444619178772, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\22.png\n",
      "score is 0.7558727264404297, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\23.png\n",
      "score is 0.9973515272140503, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\24.png\n",
      "score is 0.6777886152267456, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\25.png\n",
      "score is 0.9732775092124939, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\26.png\n",
      "score is 0.9955768585205078, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\27.png\n",
      "score is 0.8990444540977478, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\28.png\n",
      "score is 0.8683393597602844, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\29.png\n",
      "score is 0.6542667746543884, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\3.png\n",
      "score is 0.698931872844696, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\4.png\n",
      "score is 0.7217573523521423, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\5.png\n",
      "score is 0.96982342004776, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\6.png\n",
      "score is 0.9996341466903687, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\7.png\n",
      "score is 0.800708532333374, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\8.png\n",
      "score is 0.6021374464035034, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_1\\9.png\n",
      "score is 0.5646924376487732, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\0.png\n",
      "score is 0.9781402349472046, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\1.png\n",
      "score is 0.9556796550750732, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\10.png\n",
      "score is 0.5668821930885315, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\11.png\n",
      "score is 0.8357746005058289, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\12.png\n",
      "score is 0.7490341663360596, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\13.png\n",
      "score is 0.9229460954666138, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\14.png\n",
      "score is 0.981846034526825, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\15.png\n",
      "score is 0.9727917313575745, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\16.png\n",
      "score is 0.8868792653083801, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\17.png\n",
      "score is 0.7746170163154602, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\18.png\n",
      "score is 0.999620795249939, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\19.png\n",
      "score is 0.9657877087593079, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\2.png\n",
      "score is 0.9998617172241211, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\20.png\n",
      "score is 0.7577682733535767, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\21.png\n",
      "score is 0.9999862909317017, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\22.png\n",
      "score is 0.9749137163162231, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\23.png\n",
      "score is 0.9254494905471802, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\24.png\n",
      "score is 0.504368007183075, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\25.png\n",
      "score is 0.9984011054039001, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\26.png\n",
      "score is 0.6768869161605835, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\27.png\n",
      "score is 0.8836138844490051, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\28.png\n",
      "score is 0.6334955096244812, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\29.png\n",
      "score is 0.6481828689575195, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\3.png\n",
      "score is 0.9356443285942078, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\4.png\n",
      "score is 0.9998832941055298, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\5.png\n",
      "score is 0.8622208833694458, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\6.png\n",
      "score is 0.6233964562416077, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\7.png\n",
      "score is 0.9994196891784668, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\8.png\n",
      "score is 0.9999833106994629, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_2\\9.png\n",
      "score is 0.7293121218681335, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\0.png\n",
      "score is 0.5439726114273071, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\1.png\n",
      "score is 0.5765661001205444, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\10.png\n",
      "score is 0.6009525060653687, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\11.png\n",
      "score is 0.6641038060188293, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\12.png\n",
      "score is 0.6017933487892151, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\13.png\n",
      "score is 0.6641135215759277, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\14.png\n",
      "score is 0.6616965532302856, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\15.png\n",
      "score is 0.5847758054733276, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\16.png\n",
      "score is 0.7934008836746216, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\17.png\n",
      "score is 0.5447453856468201, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\18.png\n",
      "score is 0.8905898332595825, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\19.png\n",
      "score is 0.6468108892440796, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\2.png\n",
      "score is 0.7962988615036011, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\20.png\n",
      "score is 0.5362774729728699, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\21.png\n",
      "score is 0.6851972341537476, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\22.png\n",
      "score is 0.5756402015686035, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\23.png\n",
      "score is 0.7346622943878174, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\24.png\n",
      "score is 0.4982253313064575, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\25.png\n",
      "score is 0.5105509161949158, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\26.png\n",
      "score is 0.5009328722953796, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\27.png\n",
      "score is 0.823936939239502, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\28.png\n",
      "score is 0.6609353423118591, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\29.png\n",
      "score is 0.8657571077346802, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\3.png\n",
      "score is 0.6963374018669128, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\4.png\n",
      "score is 0.7373455166816711, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\5.png\n",
      "score is 0.8266108632087708, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\6.png\n",
      "score is 0.5434523224830627, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\7.png\n",
      "score is 0.8695777654647827, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\8.png\n",
      "score is 0.6752488017082214, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [28:21, 55.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\w2Qbz8\\w2Qbz8_3\\9.png\n",
      "score is 0.7880508899688721, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\0.png\n",
      "score is 0.584712564945221, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\1.png\n",
      "score is 0.962806761264801, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\10.png\n",
      "score is 0.914954662322998, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\11.png\n",
      "score is 0.7119213342666626, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\12.png\n",
      "score is 0.6932637691497803, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\13.png\n",
      "score is 0.8513972163200378, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\14.png\n",
      "score is 0.5442214608192444, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\15.png\n",
      "score is 0.8914156556129456, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\16.png\n",
      "score is 0.7809197306632996, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\17.png\n",
      "score is 0.8764716982841492, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\18.png\n",
      "score is 0.8769998550415039, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\19.png\n",
      "score is 0.9385613799095154, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\2.png\n",
      "score is 0.7186827659606934, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\20.png\n",
      "score is 0.8962407112121582, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\21.png\n",
      "score is 0.6591907143592834, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\22.png\n",
      "score is 0.6006543636322021, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\23.png\n",
      "score is 0.9653021693229675, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\24.png\n",
      "score is 0.8646382689476013, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\25.png\n",
      "score is 0.9404165744781494, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\26.png\n",
      "score is 0.9216181635856628, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\27.png\n",
      "score is 0.589810311794281, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\28.png\n",
      "score is 0.894635021686554, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\29.png\n",
      "score is 0.5079361200332642, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\3.png\n",
      "score is 0.924674391746521, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\4.png\n",
      "score is 0.7409462332725525, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\5.png\n",
      "score is 0.5572627186775208, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\6.png\n",
      "score is 0.9730921387672424, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\7.png\n",
      "score is 1.0, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\8.png\n",
      "score is 0.9634639620780945, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_0\\9.png\n",
      "score is 0.9904192090034485, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\0.png\n",
      "score is 0.9999988079071045, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\1.png\n",
      "score is 0.9993011951446533, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\10.png\n",
      "score is 0.9999998807907104, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\11.png\n",
      "score is 0.9999910593032837, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\12.png\n",
      "score is 0.9788084626197815, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\13.png\n",
      "score is 0.9999849796295166, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\14.png\n",
      "score is 0.9760269522666931, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\15.png\n",
      "score is 0.9999103546142578, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\16.png\n",
      "score is 0.9999988079071045, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\17.png\n",
      "score is 0.9999992847442627, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\18.png\n",
      "score is 0.9996119141578674, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\19.png\n",
      "score is 0.993962824344635, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\2.png\n",
      "score is 0.9999887943267822, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\20.png\n",
      "score is 0.9999957084655762, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\21.png\n",
      "score is 0.9999933242797852, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\22.png\n",
      "score is 0.9999858140945435, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\23.png\n",
      "score is 0.997757613658905, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\24.png\n",
      "score is 0.9999995231628418, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\25.png\n",
      "score is 0.9999957084655762, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\26.png\n",
      "score is 0.9999974966049194, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\27.png\n",
      "score is 0.9944592714309692, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\28.png\n",
      "score is 0.9998297691345215, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\29.png\n",
      "score is 0.9999996423721313, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\3.png\n",
      "score is 0.9999995231628418, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\4.png\n",
      "score is 0.9995456337928772, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\5.png\n",
      "score is 0.8695747256278992, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\6.png\n",
      "score is 0.9999854564666748, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\7.png\n",
      "score is 0.9999539852142334, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\8.png\n",
      "score is 0.9999938011169434, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_1\\9.png\n",
      "score is 0.9921064376831055, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\0.png\n",
      "score is 0.5452626943588257, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\1.png\n",
      "score is 0.9297428131103516, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\10.png\n",
      "score is 0.9998584985733032, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\11.png\n",
      "score is 0.9935704469680786, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\12.png\n",
      "score is 0.992199718952179, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\13.png\n",
      "score is 0.6436102390289307, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\14.png\n",
      "score is 0.9999940395355225, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\15.png\n",
      "score is 0.973605215549469, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\16.png\n",
      "score is 0.699257493019104, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\17.png\n",
      "score is 0.5450358986854553, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\18.png\n",
      "score is 0.9674889445304871, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\19.png\n",
      "score is 0.9831780791282654, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\2.png\n",
      "score is 0.9906280040740967, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\20.png\n",
      "score is 0.8411940932273865, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\21.png\n",
      "score is 0.9992774128913879, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\22.png\n",
      "score is 0.8725419044494629, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\23.png\n",
      "score is 0.5945133566856384, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\24.png\n",
      "score is 0.9672398567199707, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\25.png\n",
      "score is 0.5553222894668579, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\26.png\n",
      "score is 0.9801051020622253, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\27.png\n",
      "score is 0.5864436030387878, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\28.png\n",
      "score is 0.9975754618644714, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\29.png\n",
      "score is 0.6171810030937195, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\3.png\n",
      "score is 0.9672005772590637, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\4.png\n",
      "score is 0.9948908090591431, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\5.png\n",
      "score is 0.8393219113349915, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\6.png\n",
      "score is 0.9843041300773621, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\7.png\n",
      "score is 0.9799537658691406, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\8.png\n",
      "score is 0.8611185550689697, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [29:05, 52.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\Wp3Lv9\\Wp3Lv9_2\\9.png\n",
      "score is 0.9455694556236267, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\0.png\n",
      "score is 0.892458438873291, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\1.png\n",
      "score is 0.9827069044113159, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\10.png\n",
      "score is 0.9949854612350464, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\11.png\n",
      "score is 0.9916039109230042, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\12.png\n",
      "score is 0.7435296773910522, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\13.png\n",
      "score is 0.95072340965271, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\14.png\n",
      "score is 0.9272085428237915, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\15.png\n",
      "score is 0.9976897239685059, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\16.png\n",
      "score is 0.9987585544586182, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\17.png\n",
      "score is 0.99852055311203, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\18.png\n",
      "score is 0.9716103672981262, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\19.png\n",
      "score is 0.9988422989845276, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\2.png\n",
      "score is 0.9963494539260864, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\20.png\n",
      "score is 0.9957789182662964, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\21.png\n",
      "score is 0.9944760203361511, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\22.png\n",
      "score is 0.9467912912368774, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\23.png\n",
      "score is 0.8722795844078064, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\24.png\n",
      "score is 0.7050296664237976, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\25.png\n",
      "score is 0.9940610527992249, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\26.png\n",
      "score is 0.9923585057258606, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\27.png\n",
      "score is 0.9986162185668945, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\28.png\n",
      "score is 0.9999129772186279, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\29.png\n",
      "score is 0.9447764754295349, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\3.png\n",
      "score is 0.9785155057907104, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\4.png\n",
      "score is 0.9995354413986206, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\5.png\n",
      "score is 0.8986891508102417, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\6.png\n",
      "score is 0.8289996981620789, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\7.png\n",
      "score is 0.9216458797454834, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\8.png\n",
      "score is 0.9855526089668274, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_0\\9.png\n",
      "score is 0.9167884588241577, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\0.png\n",
      "score is 0.953877866268158, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\1.png\n",
      "score is 0.9963954091072083, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\10.png\n",
      "score is 0.9978535771369934, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\11.png\n",
      "score is 0.9916233420372009, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\12.png\n",
      "score is 0.9925486445426941, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\13.png\n",
      "score is 0.7213655114173889, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\14.png\n",
      "score is 0.9941027760505676, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\15.png\n",
      "score is 0.994500994682312, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\16.png\n",
      "score is 0.9903178215026855, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\17.png\n",
      "score is 0.9795897603034973, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\18.png\n",
      "score is 0.9695834517478943, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\19.png\n",
      "score is 0.8065016865730286, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\2.png\n",
      "score is 0.9906532764434814, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\20.png\n",
      "score is 0.9996398687362671, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\21.png\n",
      "score is 0.9888639450073242, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\22.png\n",
      "score is 0.9806022644042969, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\23.png\n",
      "score is 0.9577329754829407, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\24.png\n",
      "score is 0.9648895859718323, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\25.png\n",
      "score is 0.9441057443618774, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\26.png\n",
      "score is 0.7081053256988525, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\27.png\n",
      "score is 0.9296050071716309, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\28.png\n",
      "score is 0.9352086186408997, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\29.png\n",
      "score is 0.7221773266792297, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\3.png\n",
      "score is 0.9910553693771362, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\4.png\n",
      "score is 0.9487766623497009, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\5.png\n",
      "score is 0.9971871972084045, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\6.png\n",
      "score is 0.9973794221878052, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\7.png\n",
      "score is 0.9965898990631104, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\8.png\n",
      "score is 0.9979507327079773, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_1\\9.png\n",
      "score is 0.9920945763587952, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\0.png\n",
      "score is 0.5763378739356995, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\1.png\n",
      "score is 0.9474465847015381, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\10.png\n",
      "score is 0.687972366809845, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\11.png\n",
      "score is 0.5694788098335266, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\12.png\n",
      "score is 0.8220383524894714, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\13.png\n",
      "score is 0.45372939109802246, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\14.png\n",
      "score is 0.984929621219635, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\15.png\n",
      "score is 0.8859959840774536, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\16.png\n",
      "score is 0.5057782530784607, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\17.png\n",
      "score is 0.9681633710861206, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\18.png\n",
      "score is 0.8929089307785034, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\19.png\n",
      "score is 0.8407580256462097, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\2.png\n",
      "score is 0.9621329307556152, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\20.png\n",
      "score is 0.9341538548469543, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\21.png\n",
      "score is 0.9874488711357117, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\22.png\n",
      "score is 0.9147881269454956, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\23.png\n",
      "score is 0.7723669409751892, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\24.png\n",
      "score is 0.955466628074646, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\25.png\n",
      "score is 0.9557380080223083, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\26.png\n",
      "score is 0.7478103041648865, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\27.png\n",
      "score is 0.9275627136230469, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\28.png\n",
      "score is 0.8985883593559265, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\29.png\n",
      "score is 0.6124697327613831, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\3.png\n",
      "score is 0.7847781181335449, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\4.png\n",
      "score is 0.695422887802124, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\5.png\n",
      "score is 0.804589033126831, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\6.png\n",
      "score is 0.6213230490684509, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\7.png\n",
      "score is 0.9553476572036743, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\8.png\n",
      "score is 0.9995267391204834, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_2\\9.png\n",
      "score is 0.8895621299743652, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\0.png\n",
      "score is 0.9852826595306396, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\1.png\n",
      "score is 0.7253381013870239, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\10.png\n",
      "score is 0.7255878448486328, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\11.png\n",
      "score is 0.8392183780670166, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\12.png\n",
      "score is 0.9665825963020325, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\13.png\n",
      "score is 0.9355354905128479, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\14.png\n",
      "score is 0.6149009466171265, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\15.png\n",
      "score is 0.8005727529525757, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\16.png\n",
      "score is 0.9816715121269226, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\17.png\n",
      "score is 0.9366487264633179, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\18.png\n",
      "score is 0.8202568292617798, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\19.png\n",
      "score is 0.6918972134590149, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\2.png\n",
      "score is 0.7621117234230042, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\20.png\n",
      "score is 0.9956890940666199, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\21.png\n",
      "score is 0.695675790309906, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\22.png\n",
      "score is 0.9381898641586304, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\23.png\n",
      "score is 0.8483274579048157, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\24.png\n",
      "score is 0.9588351249694824, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\25.png\n",
      "score is 0.796357274055481, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\26.png\n",
      "score is 0.6885756254196167, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\27.png\n",
      "score is 0.7832863330841064, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\28.png\n",
      "score is 0.7453692555427551, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\29.png\n",
      "score is 0.9785084128379822, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\3.png\n",
      "score is 0.9983318448066711, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\4.png\n",
      "score is 0.9743033647537231, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\5.png\n",
      "score is 0.9553297162055969, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\6.png\n",
      "score is 0.9713134765625, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\7.png\n",
      "score is 0.9166790843009949, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\8.png\n",
      "score is 0.9978405237197876, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_3\\9.png\n",
      "score is 0.9719805121421814, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\0.png\n",
      "score is 0.9616761803627014, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\1.png\n",
      "score is 0.9997668862342834, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\10.png\n",
      "score is 0.8278568983078003, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\11.png\n",
      "score is 0.5612549781799316, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\12.png\n",
      "score is 0.9546458721160889, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\13.png\n",
      "score is 0.9874340891838074, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\14.png\n",
      "score is 0.9779052138328552, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\15.png\n",
      "score is 0.9051609635353088, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\16.png\n",
      "score is 0.9925198554992676, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\17.png\n",
      "score is 0.653528094291687, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\18.png\n",
      "score is 0.9974302649497986, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\19.png\n",
      "score is 0.6022183895111084, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\2.png\n",
      "score is 0.9901376962661743, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\20.png\n",
      "score is 0.9975797533988953, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\21.png\n",
      "score is 0.9821120500564575, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\22.png\n",
      "score is 0.7323939800262451, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\23.png\n",
      "score is 0.998778760433197, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\24.png\n",
      "score is 0.9222684502601624, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\25.png\n",
      "score is 0.7796621918678284, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\26.png\n",
      "score is 0.8580420613288879, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\27.png\n",
      "score is 0.8581493496894836, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\28.png\n",
      "score is 0.527071475982666, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\29.png\n",
      "score is 0.8040175437927246, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\3.png\n",
      "score is 0.9994283318519592, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\4.png\n",
      "score is 0.7856592535972595, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\5.png\n",
      "score is 0.9987186193466187, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\6.png\n",
      "score is 0.806087076663971, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\7.png\n",
      "score is 0.98951655626297, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\8.png\n",
      "score is 0.6814790964126587, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_4\\9.png\n",
      "score is 0.9767407178878784, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\0.png\n",
      "score is 0.9122781157493591, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\1.png\n",
      "score is 0.9994961023330688, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\10.png\n",
      "score is 0.9564838409423828, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\11.png\n",
      "score is 0.856171727180481, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\12.png\n",
      "score is 0.9742514491081238, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\13.png\n",
      "score is 0.8140147924423218, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\14.png\n",
      "score is 0.822884738445282, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\15.png\n",
      "score is 0.985918402671814, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\16.png\n",
      "score is 0.8730543255805969, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\17.png\n",
      "score is 0.6111536622047424, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\18.png\n",
      "score is 0.974833071231842, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\19.png\n",
      "score is 0.5229166150093079, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\2.png\n",
      "score is 0.8500543832778931, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\20.png\n",
      "score is 0.9544448256492615, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\21.png\n",
      "score is 0.5052716135978699, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\22.png\n",
      "score is 0.8407231569290161, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\23.png\n",
      "score is 0.8175327777862549, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\24.png\n",
      "score is 0.9799755215644836, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\25.png\n",
      "score is 0.5142237544059753, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\26.png\n",
      "score is 0.9190065264701843, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\27.png\n",
      "score is 0.967765212059021, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\28.png\n",
      "score is 0.7192329168319702, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\29.png\n",
      "score is 0.9360760450363159, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\3.png\n",
      "score is 0.9891617298126221, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\4.png\n",
      "score is 0.705493688583374, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\5.png\n",
      "score is 0.9807912111282349, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\6.png\n",
      "score is 0.9911468625068665, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\7.png\n",
      "score is 0.9955190420150757, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\8.png\n",
      "score is 0.9606626629829407, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_5\\9.png\n",
      "score is 0.7558509111404419, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\0.png\n",
      "score is 0.8668505549430847, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\1.png\n",
      "score is 0.5443606376647949, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\10.png\n",
      "score is 0.9834042191505432, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\11.png\n",
      "score is 0.49375465512275696, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\12.png\n",
      "score is 0.7597246766090393, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\13.png\n",
      "score is 0.9651264548301697, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\14.png\n",
      "score is 0.7524105310440063, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\15.png\n",
      "score is 0.9697130918502808, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\16.png\n",
      "score is 0.9820835590362549, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\17.png\n",
      "score is 0.8456323146820068, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\18.png\n",
      "score is 0.988339900970459, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\19.png\n",
      "score is 0.9940381050109863, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\2.png\n",
      "score is 0.6007331609725952, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\20.png\n",
      "score is 0.963395893573761, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\21.png\n",
      "score is 0.7735580801963806, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\22.png\n",
      "score is 0.9997817873954773, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\23.png\n",
      "score is 0.8427051305770874, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\24.png\n",
      "score is 0.747312068939209, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\25.png\n",
      "score is 0.8799481987953186, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\26.png\n",
      "score is 0.9134277701377869, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\27.png\n",
      "score is 0.5038269758224487, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\28.png\n",
      "score is 0.9919257760047913, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\29.png\n",
      "score is 0.7633421421051025, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\3.png\n",
      "score is 0.8509839773178101, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\4.png\n",
      "score is 0.9587114453315735, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\5.png\n",
      "score is 0.8429169058799744, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\6.png\n",
      "score is 0.7612970471382141, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\7.png\n",
      "score is 0.9613376259803772, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\8.png\n",
      "score is 0.5920264720916748, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [30:50, 67.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\wuCWgz\\wuCWgz_6\\9.png\n",
      "score is 0.5979793667793274, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\0.png\n",
      "score is 0.5530451536178589, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\1.png\n",
      "score is 0.9999990463256836, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\10.png\n",
      "score is 0.999222993850708, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\11.png\n",
      "score is 0.4364315867424011, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\12.png\n",
      "score is 0.9917886853218079, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\13.png\n",
      "score is 1.0, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\14.png\n",
      "score is 0.9998465776443481, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\15.png\n",
      "score is 0.9993175268173218, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\16.png\n",
      "score is 0.9998457431793213, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\17.png\n",
      "score is 0.8783752918243408, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\18.png\n",
      "score is 0.8490108251571655, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\19.png\n",
      "score is 0.4388907849788666, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\2.png\n",
      "score is 0.9341273307800293, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\20.png\n",
      "score is 0.9998314380645752, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\21.png\n",
      "score is 0.6713299751281738, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\22.png\n",
      "score is 0.7832899689674377, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\23.png\n",
      "score is 0.9999673366546631, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\24.png\n",
      "score is 0.9932793974876404, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\25.png\n",
      "score is 0.9877933859825134, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\26.png\n",
      "score is 0.9993048906326294, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\27.png\n",
      "score is 0.9032028913497925, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\28.png\n",
      "score is 0.9214961528778076, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\29.png\n",
      "score is 0.6508558392524719, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\3.png\n",
      "score is 0.9998661279678345, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\4.png\n",
      "score is 0.9987936019897461, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\5.png\n",
      "score is 0.9979598522186279, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\6.png\n",
      "score is 0.7935550808906555, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\7.png\n",
      "score is 0.9999743700027466, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\8.png\n",
      "score is 0.9074703454971313, class id is 0, class name is T0\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\Y1gva6\\Y1gva6_0\\9.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [31:05, 52.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score is 0.9996812343597412, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\0.png\n",
      "score is 0.9999784231185913, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\1.png\n",
      "score is 0.5765048265457153, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\10.png\n",
      "score is 0.968001127243042, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\11.png\n",
      "score is 0.5121801495552063, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\12.png\n",
      "score is 0.6498680114746094, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\13.png\n",
      "score is 0.8834430575370789, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\14.png\n",
      "score is 0.9999769926071167, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\15.png\n",
      "score is 0.7620124816894531, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\16.png\n",
      "score is 0.9999977350234985, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\17.png\n",
      "score is 0.9232009053230286, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\18.png\n",
      "score is 0.8227705955505371, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\19.png\n",
      "score is 0.9464403986930847, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\2.png\n",
      "score is 0.6445716023445129, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\20.png\n",
      "score is 0.7594066858291626, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\21.png\n",
      "score is 0.9994485974311829, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\22.png\n",
      "score is 0.9540195465087891, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\23.png\n",
      "score is 0.9203181862831116, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\24.png\n",
      "score is 0.8982340693473816, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\25.png\n",
      "score is 0.9999066591262817, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\26.png\n",
      "score is 0.827681303024292, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\27.png\n",
      "score is 0.9884682297706604, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\28.png\n",
      "score is 0.9986156225204468, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\29.png\n",
      "score is 0.8875605463981628, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\3.png\n",
      "score is 0.5103487372398376, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\4.png\n",
      "score is 0.900312602519989, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\5.png\n",
      "score is 0.9154934883117676, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\6.png\n",
      "score is 0.684518575668335, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\7.png\n",
      "score is 0.9604278206825256, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\8.png\n",
      "score is 0.9994757771492004, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_0\\9.png\n",
      "score is 0.960076093673706, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\0.png\n",
      "score is 0.6816397905349731, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\1.png\n",
      "score is 0.9999998807907104, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\10.png\n",
      "score is 0.9766523838043213, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\11.png\n",
      "score is 0.9431232810020447, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\12.png\n",
      "score is 0.9877183437347412, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\13.png\n",
      "score is 0.9404249787330627, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\14.png\n",
      "score is 0.9482834935188293, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\15.png\n",
      "score is 0.9999290704727173, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\16.png\n",
      "score is 0.9422196745872498, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\17.png\n",
      "score is 0.5954636931419373, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\18.png\n",
      "score is 0.583171546459198, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\19.png\n",
      "score is 0.8618612885475159, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\2.png\n",
      "score is 0.9916958212852478, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\20.png\n",
      "score is 0.9999967813491821, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\21.png\n",
      "score is 0.997653067111969, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\22.png\n",
      "score is 0.6243829131126404, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\23.png\n",
      "score is 0.9108003377914429, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\24.png\n",
      "score is 0.9480199813842773, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\25.png\n",
      "score is 0.9022121429443359, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\26.png\n",
      "score is 0.669526219367981, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\27.png\n",
      "score is 0.9992979764938354, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\28.png\n",
      "score is 0.8867366909980774, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\29.png\n",
      "score is 0.619683563709259, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\3.png\n",
      "score is 0.9982683658599854, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\4.png\n",
      "score is 0.905468225479126, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\5.png\n",
      "score is 0.9999589920043945, class id is 2, class name is T2\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\6.png\n",
      "score is 0.7609384059906006, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\7.png\n",
      "score is 0.9956867098808289, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\8.png\n",
      "score is 0.9256179332733154, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [31:35, 45.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\yuBHAm\\yuBHAm_1\\9.png\n",
      "score is 0.8520509004592896, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\0.png\n",
      "score is 0.6841388940811157, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\1.png\n",
      "score is 0.7511968612670898, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\10.png\n",
      "score is 0.8658680319786072, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\11.png\n",
      "score is 0.8117403984069824, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\12.png\n",
      "score is 0.8052051067352295, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\13.png\n",
      "score is 0.7147636413574219, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\14.png\n",
      "score is 0.7377988696098328, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\15.png\n",
      "score is 0.880974531173706, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\16.png\n",
      "score is 0.8455941677093506, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\17.png\n",
      "score is 0.5319725275039673, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\18.png\n",
      "score is 0.6721979379653931, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\19.png\n",
      "score is 0.9993471503257751, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\2.png\n",
      "score is 0.5663467645645142, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\20.png\n",
      "score is 0.7853270769119263, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\21.png\n",
      "score is 0.6339091062545776, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\22.png\n",
      "score is 0.7850866913795471, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\23.png\n",
      "score is 0.9969785213470459, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\24.png\n",
      "score is 0.49829110503196716, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\25.png\n",
      "score is 0.7161256074905396, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\26.png\n",
      "score is 0.5403684973716736, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\27.png\n",
      "score is 0.9548158049583435, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\28.png\n",
      "score is 0.6041619181632996, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\29.png\n",
      "score is 0.8957155346870422, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\3.png\n",
      "score is 0.8074874877929688, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\4.png\n",
      "score is 0.6211512684822083, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\5.png\n",
      "score is 0.9817896485328674, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\6.png\n",
      "score is 0.8134959936141968, class id is 3, class name is T3\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\7.png\n",
      "score is 0.8421105742454529, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n",
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\8.png\n",
      "score is 0.5936252474784851, class id is 4, class name is Tis\n",
      "infer mode...\n",
      "number of trainable params (M): 12.49\n",
      "Resume checkpoint ./densenet_output_dir/checkpoint-26.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [31:50, 45.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With optim & sched!\n",
      "image path is ./Test_patch\\zIGPHq\\zIGPHq_0\\9.png\n",
      "score is 0.6482723951339722, class id is 4, class name is Tis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%run densenet_baseline/train.py --mode infer --resume ./densenet_output_dir/checkpoint-26.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d48660-1464-49ba-89c0-65407cac59c3",
   "metadata": {},
   "source": [
    "# 重排 result 顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6b9ae59-7569-480f-8b6c-b76026c5e8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Jw1GFk_Annotation0', '0'], ['Jw1GFk_Annotation1', '0'], ['Jw1GFk_Annotation2', '4'], ['kOUcud_Annotation0', '0'], ['kOUcud_Annotation1', '3'], ['kOUcud_Annotation2', '0'], ['kOUcud_Annotation3', '0'], ['4mF7tL_Annotation0', '0'], ['4mF7tL_Annotation1', '0'], ['4mF7tL_Annotation2', '0'], ['4mF7tL_Annotation3', '0'], ['lc3OZp_Annotation0', '0'], ['lc3OZp_Annotation1', '4'], ['lg0CwS_Annotation0', '0'], ['lg0CwS_Annotation1', '4'], ['lg0CwS_Annotation2', '0'], ['lg0CwS_Annotation3', '4'], ['wuCWgz_Annotation0', '4'], ['wuCWgz_Annotation1', '4'], ['wuCWgz_Annotation2', '4'], ['wuCWgz_Annotation3', '4'], ['wuCWgz_Annotation4', '4'], ['wuCWgz_Annotation5', '4'], ['wuCWgz_Annotation6', '4'], ['kQPIhs_Annotation0', '0'], ['kQPIhs_Annotation1', '0'], ['kQPIhs_Annotation2', '4'], ['kQPIhs_Annotation3', '0'], ['KRuNrD_Annotation0', '0'], ['KRuNrD_Annotation1', '0'], ['KRuNrD_Annotation2', '0'], ['KRuNrD_Annotation3', '0'], ['gfozad_Annotation0', '0'], ['i0v7lq_Annotation0', '3'], ['i0v7lq_Annotation1', '3'], ['K2f9Nb_Annotation0', '3'], ['K2f9Nb_Annotation1', '3'], ['zIGPHq_Annotation0', '3'], ['yuBHAm_Annotation0', '3'], ['yuBHAm_Annotation1', '3'], ['lO9MmB_Annotation0', '0'], ['lO9MmB_Annotation1', '0'], ['lO9MmB_Annotation2', '4'], ['LRJwmg_Annotation0', '4'], ['LRJwmg_Annotation1', '0'], ['LRJwmg_Annotation2', '0'], ['LrKXU4_Annotation0', '0'], ['LrKXU4_Annotation1', '3'], ['LrKXU4_Annotation2', '0'], ['LrKXU4_Annotation3', '4'], ['MHNQ4e_Annotation0', '4'], ['MHNQ4e_Annotation1', '0'], ['miuArM_Annotation0', '0'], ['miuArM_Annotation1', '0'], ['miuArM_Annotation2', '3'], ['N4HDTG_Annotation0', '3'], ['N4HDTG_Annotation1', '0'], ['N4HDTG_Annotation2', '0'], ['NGynsT_Annotation0', '4'], ['NGynsT_Annotation1', '0'], ['NGynsT_Annotation2', '4'], ['Y1gva6_Annotation0', '2'], ['1y9UDX_Annotation0', '4'], ['Wp3Lv9_Annotation0', '4'], ['Wp3Lv9_Annotation1', '0'], ['Wp3Lv9_Annotation2', '4'], ['uj56hr_Annotation0', '3'], ['uj56hr_Annotation1', '2'], ['uj56hr_Annotation2', '2'], ['uj56hr_Annotation3', '3'], ['uj56hr_Annotation4', '2'], ['uj56hr_Annotation5', '4'], ['uj56hr_Annotation6', '2'], ['uj56hr_Annotation7', '2'], ['OyS7Ax_Annotation0', '0'], ['OyS7Ax_Annotation1', '0'], ['OyS7Ax_Annotation2', '0'], ['OyS7Ax_Annotation3', '0'], ['Pdaqkr_Annotation0', '0'], ['Pdaqkr_Annotation1', '0'], ['Pdaqkr_Annotation2', '0'], ['Pdaqkr_Annotation3', '3'], ['B5MAwD_Annotation0', '0'], ['B5MAwD_Annotation1', '0'], ['B5MAwD_Annotation2', '0'], ['B5MAwD_Annotation3', '0'], ['vPE2HD_Annotation0', '0'], ['vPE2HD_Annotation1', '0'], ['vPE2HD_Annotation2', '0'], ['vPE2HD_Annotation3', '0'], ['w2Qbz8_Annotation0', '0'], ['w2Qbz8_Annotation1', '0'], ['w2Qbz8_Annotation2', '0'], ['w2Qbz8_Annotation3', '4'], ['cRnBLx_Annotation0', '2'], ['cRnBLx_Annotation1', '2'], ['cRnBLx_Annotation2', '4'], ['cRnBLx_Annotation3', '2'], ['PDmefU_Annotation0', '0'], ['PDmefU_Annotation1', '4'], ['PhoFHq_Annotation0', '0'], ['PhoFHq_Annotation1', '0'], ['PhoFHq_Annotation2', '0'], ['iQUs4h_Annotation0', '3'], ['iQUs4h_Annotation1', '3'], ['s7iuvj_Annotation0', '0'], ['s7iuvj_Annotation1', '0'], ['s7iuvj_Annotation2', '0'], ['s7iuvj_Annotation3', '4'], ['trx9ej_Annotation0', '0'], ['trx9ej_Annotation1', '4'], ['trx9ej_Annotation2', '0'], ['m14lJk_Annotation0', '0'], ['sPBTxE_Annotation0', '4'], ['sPBTxE_Annotation1', '4'], ['tZl5k7_Annotation0', '4'], ['tZl5k7_Annotation1', '0'], ['tZl5k7_Annotation2', '3'], ['vLZGD6_Annotation0', '0'], ['vLZGD6_Annotation1', '0'], ['vLZGD6_Annotation2', '0'], ['vNxSRB_Annotation0', '0'], ['vNxSRB_Annotation1', '0'], ['vNxSRB_Annotation2', '0'], ['tePz9r_Annotation0', '0'], ['uBGVp5_Annotation0', '4']]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "example_path = 'E:/3rdSEED/test/test/提交示例.csv'\n",
    "result_path = 'D:/AI/3rdSEED/SEED2022_gastric_cancer_classification/result.csv'\n",
    "\n",
    "result = {}\n",
    "with open(result_path, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    for row in reader:\n",
    "        result[row[0]] = row[1]\n",
    "\n",
    "new_result = []\n",
    "with open(example_path, 'r') as f1:\n",
    "    reader = csv.reader(f1)\n",
    "    for row in reader:\n",
    "        line = []\n",
    "        line.append(row[0])\n",
    "        line.append(result[row[0]])\n",
    "        new_result.append(line)\n",
    "\n",
    "print(new_result)\n",
    "\n",
    "f = open('result1.csv','w',newline='')\n",
    "with f:\n",
    "    w = csv.writer(f,dialect=\"excel\") \n",
    "    for line in new_result:\n",
    "        w.writerow(line) #按行写入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe4ddc-942a-4de6-88a1-f5edba3278b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
