{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce53351b-477a-4285-9137-cd65a347c009",
   "metadata": {},
   "source": [
    "# 图像预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c81a94c-a2e9-4770-a28f-90e50d10a712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 5 classes: ['./data\\\\T0', './data\\\\T1', './data\\\\T2', './data\\\\T3', './data\\\\Tis']\n",
      "T0\n",
      "len(files): 200\n",
      "boundary: 10\n",
      "T1\n",
      "len(files): 22\n",
      "boundary: 1\n",
      "T2\n",
      "len(files): 28\n",
      "boundary: 1\n",
      "T3\n",
      "len(files): 94\n",
      "boundary: 4\n",
      "Tis\n",
      "len(files): 32\n",
      "boundary: 1\n",
      "Totally 354 files for training\n",
      "Totally 22 files for val\n"
     ]
    }
   ],
   "source": [
    "!python resnet_baseline/split_dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a50a0a7-99fc-499c-9014-2c57a59f9fa3",
   "metadata": {},
   "source": [
    "# 统计训练集均值和标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3dbb670-a7c3-4346-bd65-e44dae621839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totally 354 files for training\n",
      "(354, 128, 128, 3)\n",
      "[0.64652182 0.58588489 0.64451334]\n",
      "[0.37205338 0.36406497 0.37243282]\n"
     ]
    }
   ],
   "source": [
    "!python resnet_baseline/statistic_mean_std.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7585e39-8d4a-46d6-9cba-e56060bb3edc",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41a25cc2-075b-4d24-917f-48b0216fa74c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mode...\n",
      "train transform\n",
      "finding classes from ./train:\t['T0', 'T1', 'T2', 'T3', 'Tis']\n",
      "mapping classes from ./train to indexes:\t{'T0': 0, 'T1': 1, 'T2': 2, 'T3': 3, 'Tis': 4}\n",
      "eval transform\n",
      "finding classes from ./val:\t['T0', 'T1', 'T2', 'T3', 'Tis']\n",
      "mapping classes from ./val to indexes:\t{'T0': 0, 'T1': 1, 'T2': 2, 'T3': 3, 'Tis': 4}\n",
      "number of params (M): 11.18\n",
      "Epoch 0\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 2.0615 (2.0615) acc1: 0.0000 (0.0000) acc5: 100.0000 (100.0000) time: 0.0260 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 1.5569 (1.8447) acc1: 0.0000 (9.0909) acc5: 100.0000 (100.0000) time: 0.0300 data: 0.0049 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0302 s / it)\n",
      "* Acc@1 9.091 Acc@5 100.000 loss 1.845\n",
      "Accuracy of the network on the 22 test image: 9.1%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 1, Step: 0, Loss: 2.058619737625122, Lr:0.0001\n",
      "Epoch 1, Step: 1, Loss: 2.2303643226623535, Lr:0.0001\n",
      "Epoch 1, Step: 2, Loss: 1.333949089050293, Lr:0.0001\n",
      "Epoch 1, Step: 3, Loss: 1.817962646484375, Lr:0.0001\n",
      "Epoch 1, Step: 4, Loss: 1.9356387853622437, Lr:0.0001\n",
      "Epoch 1, Step: 5, Loss: 1.3013830184936523, Lr:0.0001\n",
      "Epoch 1, Step: 6, Loss: 1.5654313564300537, Lr:0.0001\n",
      "Epoch 1, Step: 7, Loss: 1.7791309356689453, Lr:0.0001\n",
      "Epoch 1, Step: 8, Loss: 1.9818453788757324, Lr:0.0001\n",
      "Epoch 1, Step: 9, Loss: 2.020811080932617, Lr:0.0001\n",
      "Epoch 1, Step: 10, Loss: 2.1197330951690674, Lr:0.0001\n",
      "Epoch 1, Step: 11, Loss: 1.613034963607788, Lr:0.0001\n",
      "Epoch 1, Step: 12, Loss: 2.3830931186676025, Lr:0.0001\n",
      "Epoch 1, Step: 13, Loss: 2.0927789211273193, Lr:0.0001\n",
      "Epoch 1, Step: 14, Loss: 0.8312261700630188, Lr:0.0001\n",
      "Epoch 1, Step: 15, Loss: 1.8950270414352417, Lr:0.0001\n",
      "Epoch 1, Step: 16, Loss: 1.6117030382156372, Lr:0.0001\n",
      "Epoch 1, Step: 17, Loss: 1.5204296112060547, Lr:0.0001\n",
      "Epoch 1, Step: 18, Loss: 1.3548729419708252, Lr:0.0001\n",
      "Epoch 1, Step: 19, Loss: 1.3356738090515137, Lr:0.0001\n",
      "Epoch 1, Step: 20, Loss: 2.0678484439849854, Lr:0.0001\n",
      "Epoch 1, Step: 21, Loss: 0.964470624923706, Lr:0.0001\n",
      "Epoch 1, Step: 22, Loss: 1.0165817737579346, Lr:0.0001\n",
      "Epoch 1, Step: 23, Loss: 1.291466474533081, Lr:0.0001\n",
      "Epoch 1, Step: 24, Loss: 1.5489139556884766, Lr:0.0001\n",
      "Epoch 1, Step: 25, Loss: 0.43700993061065674, Lr:0.0001\n",
      "Epoch 1, Step: 26, Loss: 1.4326099157333374, Lr:0.0001\n",
      "Epoch 1, Step: 27, Loss: 1.3512650728225708, Lr:0.0001\n",
      "Epoch 1, Step: 28, Loss: 0.7017714977264404, Lr:0.0001\n",
      "Epoch 1, Step: 29, Loss: 0.48927998542785645, Lr:0.0001\n",
      "Epoch 1, Step: 30, Loss: 1.0396592617034912, Lr:0.0001\n",
      "Epoch 1, Step: 31, Loss: 1.785233974456787, Lr:0.0001\n",
      "Epoch 1, Step: 32, Loss: 1.0671526193618774, Lr:0.0001\n",
      "Epoch 1, Step: 33, Loss: 1.1783134937286377, Lr:0.0001\n",
      "Epoch 1, Step: 34, Loss: 1.8410682678222656, Lr:0.0001\n",
      "Epoch 1, Step: 35, Loss: 1.0059782266616821, Lr:0.0001\n",
      "Epoch 1, Step: 36, Loss: 0.9163621068000793, Lr:0.0001\n",
      "Epoch 1, Step: 37, Loss: 1.4108518362045288, Lr:0.0001\n",
      "Epoch 1, Step: 38, Loss: 2.2750580310821533, Lr:0.0001\n",
      "Epoch 1, Step: 39, Loss: 1.3153384923934937, Lr:0.0001\n",
      "Epoch 1, Step: 40, Loss: 1.0889430046081543, Lr:0.0001\n",
      "Epoch 1, Step: 41, Loss: 0.7713735103607178, Lr:0.0001\n",
      "Epoch 1, Step: 42, Loss: 1.160557746887207, Lr:0.0001\n",
      "Epoch 1, Step: 43, Loss: 0.5671845078468323, Lr:0.0001\n",
      "Epoch 1, Step: 44, Loss: 1.614121675491333, Lr:0.0001\n",
      "Epoch 1, Step: 45, Loss: 0.8215668201446533, Lr:0.0001\n",
      "Epoch 1, Step: 46, Loss: 0.9180067777633667, Lr:0.0001\n",
      "Epoch 1, Step: 47, Loss: 1.2076630592346191, Lr:0.0001\n",
      "Epoch 1, Step: 48, Loss: 1.4867029190063477, Lr:0.0001\n",
      "Epoch 1, Step: 49, Loss: 1.1844618320465088, Lr:0.0001\n",
      "Epoch 1, Step: 50, Loss: 1.3523868322372437, Lr:0.0001\n",
      "Epoch 1, Step: 51, Loss: 1.2475372552871704, Lr:0.0001\n",
      "Epoch 1, Step: 52, Loss: 1.491356611251831, Lr:0.0001\n",
      "Epoch 1, Step: 53, Loss: 0.31249481439590454, Lr:0.0001\n",
      "Epoch 1, Step: 54, Loss: 0.5216782093048096, Lr:0.0001\n",
      "Epoch 1, Step: 55, Loss: 1.8588330745697021, Lr:0.0001\n",
      "Epoch 1, Step: 56, Loss: 2.0670952796936035, Lr:0.0001\n",
      "Epoch 1, Step: 57, Loss: 1.1327641010284424, Lr:0.0001\n",
      "Epoch 1, Step: 58, Loss: 1.0167019367218018, Lr:0.0001\n",
      "Epoch 1, Step: 59, Loss: 1.9796977043151855, Lr:0.0001\n",
      "Epoch 1, Step: 60, Loss: 0.6597670912742615, Lr:0.0001\n",
      "Epoch 1, Step: 61, Loss: 0.6206124424934387, Lr:0.0001\n",
      "Epoch 1, Step: 62, Loss: 0.7590887546539307, Lr:0.0001\n",
      "Epoch 1, Step: 63, Loss: 1.720667839050293, Lr:0.0001\n",
      "Epoch 1, Step: 64, Loss: 1.0775630474090576, Lr:0.0001\n",
      "Epoch 1, Step: 65, Loss: 0.3534708619117737, Lr:0.0001\n",
      "Epoch 1, Step: 66, Loss: 0.8098770976066589, Lr:0.0001\n",
      "Epoch 1, Step: 67, Loss: 0.9938804507255554, Lr:0.0001\n",
      "Epoch 1, Step: 68, Loss: 1.5453381538391113, Lr:0.0001\n",
      "Epoch 1, Step: 69, Loss: 0.8303765654563904, Lr:0.0001\n",
      "Epoch 1, Step: 70, Loss: 1.2615687847137451, Lr:0.0001\n",
      "Epoch 1, Step: 71, Loss: 0.4653033912181854, Lr:0.0001\n",
      "Epoch 1, Step: 72, Loss: 0.6015860438346863, Lr:0.0001\n",
      "Epoch 1, Step: 73, Loss: 0.9361560344696045, Lr:0.0001\n",
      "Epoch 1, Step: 74, Loss: 1.407217264175415, Lr:0.0001\n",
      "Epoch 1, Step: 75, Loss: 1.2328389883041382, Lr:0.0001\n",
      "Epoch 1, Step: 76, Loss: 1.1076432466506958, Lr:0.0001\n",
      "Epoch 1, Step: 77, Loss: 0.520403265953064, Lr:0.0001\n",
      "Epoch 1, Step: 78, Loss: 0.7053536176681519, Lr:0.0001\n",
      "Epoch 1, Step: 79, Loss: 0.6227915287017822, Lr:0.0001\n",
      "Epoch 1, Step: 80, Loss: 2.6109349727630615, Lr:0.0001\n",
      "Epoch 1, Step: 81, Loss: 1.1142423152923584, Lr:0.0001\n",
      "Epoch 1, Step: 82, Loss: 2.1031334400177, Lr:0.0001\n",
      "Epoch 1, Step: 83, Loss: 0.9295077323913574, Lr:0.0001\n",
      "Epoch 1, Step: 84, Loss: 0.8073133826255798, Lr:0.0001\n",
      "Epoch 1, Step: 85, Loss: 1.0975209474563599, Lr:0.0001\n",
      "Epoch 1, Step: 86, Loss: 0.9091577529907227, Lr:0.0001\n",
      "Epoch 1, Step: 87, Loss: 0.2262960970401764, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 1\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.0867 (0.0867) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0100 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.8885 (1.3639) acc1: 75.0000 (68.1818) acc5: 100.0000 (100.0000) time: 0.0072 data: 0.0038 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0072 s / it)\n",
      "* Acc@1 68.182 Acc@5 100.000 loss 1.364\n",
      "Accuracy of the network on the 22 test image: 68.2%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 2, Step: 0, Loss: 1.1139559745788574, Lr:0.0001\n",
      "Epoch 2, Step: 1, Loss: 0.6411446332931519, Lr:0.0001\n",
      "Epoch 2, Step: 2, Loss: 0.6516153812408447, Lr:0.0001\n",
      "Epoch 2, Step: 3, Loss: 1.4582455158233643, Lr:0.0001\n",
      "Epoch 2, Step: 4, Loss: 1.061221718788147, Lr:0.0001\n",
      "Epoch 2, Step: 5, Loss: 0.5407270193099976, Lr:0.0001\n",
      "Epoch 2, Step: 6, Loss: 0.14368936419487, Lr:0.0001\n",
      "Epoch 2, Step: 7, Loss: 0.5543903708457947, Lr:0.0001\n",
      "Epoch 2, Step: 8, Loss: 0.8537005186080933, Lr:0.0001\n",
      "Epoch 2, Step: 9, Loss: 1.0092527866363525, Lr:0.0001\n",
      "Epoch 2, Step: 10, Loss: 1.0783777236938477, Lr:0.0001\n",
      "Epoch 2, Step: 11, Loss: 1.4310564994812012, Lr:0.0001\n",
      "Epoch 2, Step: 12, Loss: 0.8350361585617065, Lr:0.0001\n",
      "Epoch 2, Step: 13, Loss: 0.8820724487304688, Lr:0.0001\n",
      "Epoch 2, Step: 14, Loss: 0.47081896662712097, Lr:0.0001\n",
      "Epoch 2, Step: 15, Loss: 0.5798478722572327, Lr:0.0001\n",
      "Epoch 2, Step: 16, Loss: 1.0588279962539673, Lr:0.0001\n",
      "Epoch 2, Step: 17, Loss: 1.6100711822509766, Lr:0.0001\n",
      "Epoch 2, Step: 18, Loss: 0.6460465788841248, Lr:0.0001\n",
      "Epoch 2, Step: 19, Loss: 0.2551054358482361, Lr:0.0001\n",
      "Epoch 2, Step: 20, Loss: 1.0179389715194702, Lr:0.0001\n",
      "Epoch 2, Step: 21, Loss: 1.1641191244125366, Lr:0.0001\n",
      "Epoch 2, Step: 22, Loss: 0.40692850947380066, Lr:0.0001\n",
      "Epoch 2, Step: 23, Loss: 0.8297470808029175, Lr:0.0001\n",
      "Epoch 2, Step: 24, Loss: 0.6623061895370483, Lr:0.0001\n",
      "Epoch 2, Step: 25, Loss: 0.42408621311187744, Lr:0.0001\n",
      "Epoch 2, Step: 26, Loss: 3.635277509689331, Lr:0.0001\n",
      "Epoch 2, Step: 27, Loss: 0.8794117569923401, Lr:0.0001\n",
      "Epoch 2, Step: 28, Loss: 2.412018299102783, Lr:0.0001\n",
      "Epoch 2, Step: 29, Loss: 0.7430567741394043, Lr:0.0001\n",
      "Epoch 2, Step: 30, Loss: 1.6122915744781494, Lr:0.0001\n",
      "Epoch 2, Step: 31, Loss: 0.9331665635108948, Lr:0.0001\n",
      "Epoch 2, Step: 32, Loss: 1.0150599479675293, Lr:0.0001\n",
      "Epoch 2, Step: 33, Loss: 0.4534919261932373, Lr:0.0001\n",
      "Epoch 2, Step: 34, Loss: 0.7427173852920532, Lr:0.0001\n",
      "Epoch 2, Step: 35, Loss: 0.2993498742580414, Lr:0.0001\n",
      "Epoch 2, Step: 36, Loss: 0.7608425617218018, Lr:0.0001\n",
      "Epoch 2, Step: 37, Loss: 1.1576358079910278, Lr:0.0001\n",
      "Epoch 2, Step: 38, Loss: 1.0684688091278076, Lr:0.0001\n",
      "Epoch 2, Step: 39, Loss: 1.5994895696640015, Lr:0.0001\n",
      "Epoch 2, Step: 40, Loss: 0.29076921939849854, Lr:0.0001\n",
      "Epoch 2, Step: 41, Loss: 0.36783528327941895, Lr:0.0001\n",
      "Epoch 2, Step: 42, Loss: 0.8063938021659851, Lr:0.0001\n",
      "Epoch 2, Step: 43, Loss: 0.9095276594161987, Lr:0.0001\n",
      "Epoch 2, Step: 44, Loss: 0.19186623394489288, Lr:0.0001\n",
      "Epoch 2, Step: 45, Loss: 0.8807036280632019, Lr:0.0001\n",
      "Epoch 2, Step: 46, Loss: 0.28112009167671204, Lr:0.0001\n",
      "Epoch 2, Step: 47, Loss: 0.19311581552028656, Lr:0.0001\n",
      "Epoch 2, Step: 48, Loss: 0.7277998924255371, Lr:0.0001\n",
      "Epoch 2, Step: 49, Loss: 0.1628805249929428, Lr:0.0001\n",
      "Epoch 2, Step: 50, Loss: 0.9152864217758179, Lr:0.0001\n",
      "Epoch 2, Step: 51, Loss: 0.9121096730232239, Lr:0.0001\n",
      "Epoch 2, Step: 52, Loss: 0.7780206203460693, Lr:0.0001\n",
      "Epoch 2, Step: 53, Loss: 1.4627445936203003, Lr:0.0001\n",
      "Epoch 2, Step: 54, Loss: 0.990699827671051, Lr:0.0001\n",
      "Epoch 2, Step: 55, Loss: 0.3803613483905792, Lr:0.0001\n",
      "Epoch 2, Step: 56, Loss: 1.3936197757720947, Lr:0.0001\n",
      "Epoch 2, Step: 57, Loss: 0.9628908634185791, Lr:0.0001\n",
      "Epoch 2, Step: 58, Loss: 1.3003060817718506, Lr:0.0001\n",
      "Epoch 2, Step: 59, Loss: 1.6288485527038574, Lr:0.0001\n",
      "Epoch 2, Step: 60, Loss: 0.4233357310295105, Lr:0.0001\n",
      "Epoch 2, Step: 61, Loss: 0.6060927510261536, Lr:0.0001\n",
      "Epoch 2, Step: 62, Loss: 0.9995141625404358, Lr:0.0001\n",
      "Epoch 2, Step: 63, Loss: 0.8537998795509338, Lr:0.0001\n",
      "Epoch 2, Step: 64, Loss: 2.8260209560394287, Lr:0.0001\n",
      "Epoch 2, Step: 65, Loss: 0.9920436143875122, Lr:0.0001\n",
      "Epoch 2, Step: 66, Loss: 0.6106657981872559, Lr:0.0001\n",
      "Epoch 2, Step: 67, Loss: 0.4632476270198822, Lr:0.0001\n",
      "Epoch 2, Step: 68, Loss: 0.648564338684082, Lr:0.0001\n",
      "Epoch 2, Step: 69, Loss: 2.0369815826416016, Lr:0.0001\n",
      "Epoch 2, Step: 70, Loss: 0.9749002456665039, Lr:0.0001\n",
      "Epoch 2, Step: 71, Loss: 0.6809486746788025, Lr:0.0001\n",
      "Epoch 2, Step: 72, Loss: 0.569121241569519, Lr:0.0001\n",
      "Epoch 2, Step: 73, Loss: 0.5781145691871643, Lr:0.0001\n",
      "Epoch 2, Step: 74, Loss: 1.4076182842254639, Lr:0.0001\n",
      "Epoch 2, Step: 75, Loss: 1.1805974245071411, Lr:0.0001\n",
      "Epoch 2, Step: 76, Loss: 0.7326894998550415, Lr:0.0001\n",
      "Epoch 2, Step: 77, Loss: 1.5454716682434082, Lr:0.0001\n",
      "Epoch 2, Step: 78, Loss: 1.8160380125045776, Lr:0.0001\n",
      "Epoch 2, Step: 79, Loss: 1.6912944316864014, Lr:0.0001\n",
      "Epoch 2, Step: 80, Loss: 0.23171192407608032, Lr:0.0001\n",
      "Epoch 2, Step: 81, Loss: 0.7646327018737793, Lr:0.0001\n",
      "Epoch 2, Step: 82, Loss: 1.4247667789459229, Lr:0.0001\n",
      "Epoch 2, Step: 83, Loss: 0.586658775806427, Lr:0.0001\n",
      "Epoch 2, Step: 84, Loss: 0.5268695950508118, Lr:0.0001\n",
      "Epoch 2, Step: 85, Loss: 0.496439665555954, Lr:0.0001\n",
      "Epoch 2, Step: 86, Loss: 0.184240460395813, Lr:0.0001\n",
      "Epoch 2, Step: 87, Loss: 0.4754278063774109, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 2\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.0622 (0.0622) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.1286 (1.1125) acc1: 75.0000 (72.7273) acc5: 100.0000 (100.0000) time: 0.0068 data: 0.0035 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0070 s / it)\n",
      "* Acc@1 72.727 Acc@5 100.000 loss 1.113\n",
      "Accuracy of the network on the 22 test image: 72.7%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 3, Step: 0, Loss: 1.142235517501831, Lr:0.0001\n",
      "Epoch 3, Step: 1, Loss: 1.0229699611663818, Lr:0.0001\n",
      "Epoch 3, Step: 2, Loss: 1.317589282989502, Lr:0.0001\n",
      "Epoch 3, Step: 3, Loss: 0.8724417090415955, Lr:0.0001\n",
      "Epoch 3, Step: 4, Loss: 1.0286668539047241, Lr:0.0001\n",
      "Epoch 3, Step: 5, Loss: 0.9055657386779785, Lr:0.0001\n",
      "Epoch 3, Step: 6, Loss: 1.232315182685852, Lr:0.0001\n",
      "Epoch 3, Step: 7, Loss: 0.8263435959815979, Lr:0.0001\n",
      "Epoch 3, Step: 8, Loss: 0.1060745120048523, Lr:0.0001\n",
      "Epoch 3, Step: 9, Loss: 0.6740309000015259, Lr:0.0001\n",
      "Epoch 3, Step: 10, Loss: 0.29637253284454346, Lr:0.0001\n",
      "Epoch 3, Step: 11, Loss: 0.9793272614479065, Lr:0.0001\n",
      "Epoch 3, Step: 12, Loss: 0.5095493197441101, Lr:0.0001\n",
      "Epoch 3, Step: 13, Loss: 1.7279099225997925, Lr:0.0001\n",
      "Epoch 3, Step: 14, Loss: 0.7581363320350647, Lr:0.0001\n",
      "Epoch 3, Step: 15, Loss: 1.8932602405548096, Lr:0.0001\n",
      "Epoch 3, Step: 16, Loss: 1.4909050464630127, Lr:0.0001\n",
      "Epoch 3, Step: 17, Loss: 0.7375549077987671, Lr:0.0001\n",
      "Epoch 3, Step: 18, Loss: 1.5470792055130005, Lr:0.0001\n",
      "Epoch 3, Step: 19, Loss: 0.47033438086509705, Lr:0.0001\n",
      "Epoch 3, Step: 20, Loss: 1.1706258058547974, Lr:0.0001\n",
      "Epoch 3, Step: 21, Loss: 1.0973230600357056, Lr:0.0001\n",
      "Epoch 3, Step: 22, Loss: 1.0074836015701294, Lr:0.0001\n",
      "Epoch 3, Step: 23, Loss: 1.2202069759368896, Lr:0.0001\n",
      "Epoch 3, Step: 24, Loss: 0.7927759885787964, Lr:0.0001\n",
      "Epoch 3, Step: 25, Loss: 0.09556704014539719, Lr:0.0001\n",
      "Epoch 3, Step: 26, Loss: 1.4066691398620605, Lr:0.0001\n",
      "Epoch 3, Step: 27, Loss: 2.0623185634613037, Lr:0.0001\n",
      "Epoch 3, Step: 28, Loss: 1.7845748662948608, Lr:0.0001\n",
      "Epoch 3, Step: 29, Loss: 0.3260795474052429, Lr:0.0001\n",
      "Epoch 3, Step: 30, Loss: 0.20508244633674622, Lr:0.0001\n",
      "Epoch 3, Step: 31, Loss: 1.4882514476776123, Lr:0.0001\n",
      "Epoch 3, Step: 32, Loss: 0.4168912470340729, Lr:0.0001\n",
      "Epoch 3, Step: 33, Loss: 0.4532853066921234, Lr:0.0001\n",
      "Epoch 3, Step: 34, Loss: 1.1377955675125122, Lr:0.0001\n",
      "Epoch 3, Step: 35, Loss: 1.0652992725372314, Lr:0.0001\n",
      "Epoch 3, Step: 36, Loss: 0.7008467316627502, Lr:0.0001\n",
      "Epoch 3, Step: 37, Loss: 0.4919285774230957, Lr:0.0001\n",
      "Epoch 3, Step: 38, Loss: 2.3846189975738525, Lr:0.0001\n",
      "Epoch 3, Step: 39, Loss: 1.5121310949325562, Lr:0.0001\n",
      "Epoch 3, Step: 40, Loss: 1.8239798545837402, Lr:0.0001\n",
      "Epoch 3, Step: 41, Loss: 1.0399030447006226, Lr:0.0001\n",
      "Epoch 3, Step: 42, Loss: 2.462812900543213, Lr:0.0001\n",
      "Epoch 3, Step: 43, Loss: 1.2740731239318848, Lr:0.0001\n",
      "Epoch 3, Step: 44, Loss: 0.9311264753341675, Lr:0.0001\n",
      "Epoch 3, Step: 45, Loss: 1.012886643409729, Lr:0.0001\n",
      "Epoch 3, Step: 46, Loss: 1.3123319149017334, Lr:0.0001\n",
      "Epoch 3, Step: 47, Loss: 1.3822734355926514, Lr:0.0001\n",
      "Epoch 3, Step: 48, Loss: 0.8143919110298157, Lr:0.0001\n",
      "Epoch 3, Step: 49, Loss: 1.0083564519882202, Lr:0.0001\n",
      "Epoch 3, Step: 50, Loss: 1.3794854879379272, Lr:0.0001\n",
      "Epoch 3, Step: 51, Loss: 2.1834919452667236, Lr:0.0001\n",
      "Epoch 3, Step: 52, Loss: 0.3923310935497284, Lr:0.0001\n",
      "Epoch 3, Step: 53, Loss: 0.6605599522590637, Lr:0.0001\n",
      "Epoch 3, Step: 54, Loss: 3.314748525619507, Lr:0.0001\n",
      "Epoch 3, Step: 55, Loss: 0.44830840826034546, Lr:0.0001\n",
      "Epoch 3, Step: 56, Loss: 1.1573203802108765, Lr:0.0001\n",
      "Epoch 3, Step: 57, Loss: 0.7879581451416016, Lr:0.0001\n",
      "Epoch 3, Step: 58, Loss: 1.3524243831634521, Lr:0.0001\n",
      "Epoch 3, Step: 59, Loss: 0.6361566781997681, Lr:0.0001\n",
      "Epoch 3, Step: 60, Loss: 0.778061032295227, Lr:0.0001\n",
      "Epoch 3, Step: 61, Loss: 0.4498598277568817, Lr:0.0001\n",
      "Epoch 3, Step: 62, Loss: 1.6379457712173462, Lr:0.0001\n",
      "Epoch 3, Step: 63, Loss: 1.3891756534576416, Lr:0.0001\n",
      "Epoch 3, Step: 64, Loss: 0.41043078899383545, Lr:0.0001\n",
      "Epoch 3, Step: 65, Loss: 0.407561331987381, Lr:0.0001\n",
      "Epoch 3, Step: 66, Loss: 0.1038995012640953, Lr:0.0001\n",
      "Epoch 3, Step: 67, Loss: 1.8019399642944336, Lr:0.0001\n",
      "Epoch 3, Step: 68, Loss: 0.619505763053894, Lr:0.0001\n",
      "Epoch 3, Step: 69, Loss: 1.1583497524261475, Lr:0.0001\n",
      "Epoch 3, Step: 70, Loss: 2.397411346435547, Lr:0.0001\n",
      "Epoch 3, Step: 71, Loss: 1.7018141746520996, Lr:0.0001\n",
      "Epoch 3, Step: 72, Loss: 0.6641644239425659, Lr:0.0001\n",
      "Epoch 3, Step: 73, Loss: 1.3610918521881104, Lr:0.0001\n",
      "Epoch 3, Step: 74, Loss: 0.3428190052509308, Lr:0.0001\n",
      "Epoch 3, Step: 75, Loss: 1.4311668872833252, Lr:0.0001\n",
      "Epoch 3, Step: 76, Loss: 0.9593714475631714, Lr:0.0001\n",
      "Epoch 3, Step: 77, Loss: 2.2514214515686035, Lr:0.0001\n",
      "Epoch 3, Step: 78, Loss: 0.17301274836063385, Lr:0.0001\n",
      "Epoch 3, Step: 79, Loss: 0.6600150465965271, Lr:0.0001\n",
      "Epoch 3, Step: 80, Loss: 0.9392515420913696, Lr:0.0001\n",
      "Epoch 3, Step: 81, Loss: 0.35001468658447266, Lr:0.0001\n",
      "Epoch 3, Step: 82, Loss: 0.5838608741760254, Lr:0.0001\n",
      "Epoch 3, Step: 83, Loss: 1.9233059883117676, Lr:0.0001\n",
      "Epoch 3, Step: 84, Loss: 1.2034059762954712, Lr:0.0001\n",
      "Epoch 3, Step: 85, Loss: 0.46615535020828247, Lr:0.0001\n",
      "Epoch 3, Step: 86, Loss: 0.5240103602409363, Lr:0.0001\n",
      "Epoch 3, Step: 87, Loss: 1.2372946739196777, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 3\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 1.0996 (1.0996) acc1: 25.0000 (25.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.7132 (1.2125) acc1: 25.0000 (59.0909) acc5: 100.0000 (100.0000) time: 0.0063 data: 0.0035 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0067 s / it)\n",
      "* Acc@1 59.091 Acc@5 100.000 loss 1.212\n",
      "Accuracy of the network on the 22 test image: 59.1%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 4, Step: 0, Loss: 1.1822160482406616, Lr:0.0001\n",
      "Epoch 4, Step: 1, Loss: 0.9604522585868835, Lr:0.0001\n",
      "Epoch 4, Step: 2, Loss: 0.899999737739563, Lr:0.0001\n",
      "Epoch 4, Step: 3, Loss: 0.5154892802238464, Lr:0.0001\n",
      "Epoch 4, Step: 4, Loss: 1.1202497482299805, Lr:0.0001\n",
      "Epoch 4, Step: 5, Loss: 0.5852289199829102, Lr:0.0001\n",
      "Epoch 4, Step: 6, Loss: 1.050387978553772, Lr:0.0001\n",
      "Epoch 4, Step: 7, Loss: 0.8026863932609558, Lr:0.0001\n",
      "Epoch 4, Step: 8, Loss: 0.7978019118309021, Lr:0.0001\n",
      "Epoch 4, Step: 9, Loss: 0.46148279309272766, Lr:0.0001\n",
      "Epoch 4, Step: 10, Loss: 0.5820639133453369, Lr:0.0001\n",
      "Epoch 4, Step: 11, Loss: 2.996443510055542, Lr:0.0001\n",
      "Epoch 4, Step: 12, Loss: 1.1791020631790161, Lr:0.0001\n",
      "Epoch 4, Step: 13, Loss: 0.8232176303863525, Lr:0.0001\n",
      "Epoch 4, Step: 14, Loss: 1.4730408191680908, Lr:0.0001\n",
      "Epoch 4, Step: 15, Loss: 0.9829937815666199, Lr:0.0001\n",
      "Epoch 4, Step: 16, Loss: 1.8896586894989014, Lr:0.0001\n",
      "Epoch 4, Step: 17, Loss: 0.44013845920562744, Lr:0.0001\n",
      "Epoch 4, Step: 18, Loss: 2.3015410900115967, Lr:0.0001\n",
      "Epoch 4, Step: 19, Loss: 1.0669972896575928, Lr:0.0001\n",
      "Epoch 4, Step: 20, Loss: 0.3539758324623108, Lr:0.0001\n",
      "Epoch 4, Step: 21, Loss: 1.0051349401474, Lr:0.0001\n",
      "Epoch 4, Step: 22, Loss: 1.2635267972946167, Lr:0.0001\n",
      "Epoch 4, Step: 23, Loss: 0.2618260681629181, Lr:0.0001\n",
      "Epoch 4, Step: 24, Loss: 0.22244273126125336, Lr:0.0001\n",
      "Epoch 4, Step: 25, Loss: 0.39767879247665405, Lr:0.0001\n",
      "Epoch 4, Step: 26, Loss: 1.5328788757324219, Lr:0.0001\n",
      "Epoch 4, Step: 27, Loss: 0.6717258095741272, Lr:0.0001\n",
      "Epoch 4, Step: 28, Loss: 0.7427474856376648, Lr:0.0001\n",
      "Epoch 4, Step: 29, Loss: 0.5571730732917786, Lr:0.0001\n",
      "Epoch 4, Step: 30, Loss: 1.2597297430038452, Lr:0.0001\n",
      "Epoch 4, Step: 31, Loss: 0.37548771500587463, Lr:0.0001\n",
      "Epoch 4, Step: 32, Loss: 1.2557498216629028, Lr:0.0001\n",
      "Epoch 4, Step: 33, Loss: 0.5451883673667908, Lr:0.0001\n",
      "Epoch 4, Step: 34, Loss: 1.0794726610183716, Lr:0.0001\n",
      "Epoch 4, Step: 35, Loss: 0.7281903028488159, Lr:0.0001\n",
      "Epoch 4, Step: 36, Loss: 1.7032041549682617, Lr:0.0001\n",
      "Epoch 4, Step: 37, Loss: 0.5521589517593384, Lr:0.0001\n",
      "Epoch 4, Step: 38, Loss: 1.1503756046295166, Lr:0.0001\n",
      "Epoch 4, Step: 39, Loss: 1.1033798456192017, Lr:0.0001\n",
      "Epoch 4, Step: 40, Loss: 0.3252719044685364, Lr:0.0001\n",
      "Epoch 4, Step: 41, Loss: 0.6233469247817993, Lr:0.0001\n",
      "Epoch 4, Step: 42, Loss: 0.29343923926353455, Lr:0.0001\n",
      "Epoch 4, Step: 43, Loss: 0.8319283723831177, Lr:0.0001\n",
      "Epoch 4, Step: 44, Loss: 1.2068859338760376, Lr:0.0001\n",
      "Epoch 4, Step: 45, Loss: 1.2519677877426147, Lr:0.0001\n",
      "Epoch 4, Step: 46, Loss: 0.8776400685310364, Lr:0.0001\n",
      "Epoch 4, Step: 47, Loss: 1.164560317993164, Lr:0.0001\n",
      "Epoch 4, Step: 48, Loss: 0.4896286725997925, Lr:0.0001\n",
      "Epoch 4, Step: 49, Loss: 0.5802640914916992, Lr:0.0001\n",
      "Epoch 4, Step: 50, Loss: 0.5327250361442566, Lr:0.0001\n",
      "Epoch 4, Step: 51, Loss: 2.2587809562683105, Lr:0.0001\n",
      "Epoch 4, Step: 52, Loss: 0.8450160026550293, Lr:0.0001\n",
      "Epoch 4, Step: 53, Loss: 0.885861873626709, Lr:0.0001\n",
      "Epoch 4, Step: 54, Loss: 0.8796762824058533, Lr:0.0001\n",
      "Epoch 4, Step: 55, Loss: 1.0481252670288086, Lr:0.0001\n",
      "Epoch 4, Step: 56, Loss: 0.6745806932449341, Lr:0.0001\n",
      "Epoch 4, Step: 57, Loss: 0.3399191200733185, Lr:0.0001\n",
      "Epoch 4, Step: 58, Loss: 0.8972450494766235, Lr:0.0001\n",
      "Epoch 4, Step: 59, Loss: 1.1708520650863647, Lr:0.0001\n",
      "Epoch 4, Step: 60, Loss: 0.6505452990531921, Lr:0.0001\n",
      "Epoch 4, Step: 61, Loss: 0.1923215091228485, Lr:0.0001\n",
      "Epoch 4, Step: 62, Loss: 0.40065741539001465, Lr:0.0001\n",
      "Epoch 4, Step: 63, Loss: 0.5126911401748657, Lr:0.0001\n",
      "Epoch 4, Step: 64, Loss: 0.43876978754997253, Lr:0.0001\n",
      "Epoch 4, Step: 65, Loss: 1.0056195259094238, Lr:0.0001\n",
      "Epoch 4, Step: 66, Loss: 0.6293846368789673, Lr:0.0001\n",
      "Epoch 4, Step: 67, Loss: 0.8723911046981812, Lr:0.0001\n",
      "Epoch 4, Step: 68, Loss: 1.7587604522705078, Lr:0.0001\n",
      "Epoch 4, Step: 69, Loss: 0.7147887945175171, Lr:0.0001\n",
      "Epoch 4, Step: 70, Loss: 0.697249174118042, Lr:0.0001\n",
      "Epoch 4, Step: 71, Loss: 0.498569130897522, Lr:0.0001\n",
      "Epoch 4, Step: 72, Loss: 1.890669584274292, Lr:0.0001\n",
      "Epoch 4, Step: 73, Loss: 0.5724848508834839, Lr:0.0001\n",
      "Epoch 4, Step: 74, Loss: 1.2334266901016235, Lr:0.0001\n",
      "Epoch 4, Step: 75, Loss: 0.550705075263977, Lr:0.0001\n",
      "Epoch 4, Step: 76, Loss: 1.4294039011001587, Lr:0.0001\n",
      "Epoch 4, Step: 77, Loss: 0.34532007575035095, Lr:0.0001\n",
      "Epoch 4, Step: 78, Loss: 0.4438289999961853, Lr:0.0001\n",
      "Epoch 4, Step: 79, Loss: 0.13038170337677002, Lr:0.0001\n",
      "Epoch 4, Step: 80, Loss: 1.3693777322769165, Lr:0.0001\n",
      "Epoch 4, Step: 81, Loss: 0.6840261220932007, Lr:0.0001\n",
      "Epoch 4, Step: 82, Loss: 1.6022365093231201, Lr:0.0001\n",
      "Epoch 4, Step: 83, Loss: 1.3002524375915527, Lr:0.0001\n",
      "Epoch 4, Step: 84, Loss: 1.2003395557403564, Lr:0.0001\n",
      "Epoch 4, Step: 85, Loss: 0.2961429953575134, Lr:0.0001\n",
      "Epoch 4, Step: 86, Loss: 1.5319441556930542, Lr:0.0001\n",
      "Epoch 4, Step: 87, Loss: 0.7819318771362305, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 4\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.6350 (0.6350) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.3439 (0.7787) acc1: 75.0000 (72.7273) acc5: 100.0000 (100.0000) time: 0.0071 data: 0.0038 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0071 s / it)\n",
      "* Acc@1 72.727 Acc@5 100.000 loss 0.779\n",
      "Accuracy of the network on the 22 test image: 72.7%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 5, Step: 0, Loss: 1.0680228471755981, Lr:0.0001\n",
      "Epoch 5, Step: 1, Loss: 0.27238917350769043, Lr:0.0001\n",
      "Epoch 5, Step: 2, Loss: 0.6102235913276672, Lr:0.0001\n",
      "Epoch 5, Step: 3, Loss: 0.6531506180763245, Lr:0.0001\n",
      "Epoch 5, Step: 4, Loss: 0.7206339836120605, Lr:0.0001\n",
      "Epoch 5, Step: 5, Loss: 2.7806873321533203, Lr:0.0001\n",
      "Epoch 5, Step: 6, Loss: 0.860094428062439, Lr:0.0001\n",
      "Epoch 5, Step: 7, Loss: 0.974911630153656, Lr:0.0001\n",
      "Epoch 5, Step: 8, Loss: 0.748970627784729, Lr:0.0001\n",
      "Epoch 5, Step: 9, Loss: 0.6160185933113098, Lr:0.0001\n",
      "Epoch 5, Step: 10, Loss: 0.7283754944801331, Lr:0.0001\n",
      "Epoch 5, Step: 11, Loss: 1.6976897716522217, Lr:0.0001\n",
      "Epoch 5, Step: 12, Loss: 0.26813235878944397, Lr:0.0001\n",
      "Epoch 5, Step: 13, Loss: 0.9721857309341431, Lr:0.0001\n",
      "Epoch 5, Step: 14, Loss: 3.092118740081787, Lr:0.0001\n",
      "Epoch 5, Step: 15, Loss: 0.7082475423812866, Lr:0.0001\n",
      "Epoch 5, Step: 16, Loss: 0.8404936790466309, Lr:0.0001\n",
      "Epoch 5, Step: 17, Loss: 1.712817668914795, Lr:0.0001\n",
      "Epoch 5, Step: 18, Loss: 0.451580286026001, Lr:0.0001\n",
      "Epoch 5, Step: 19, Loss: 0.8886206746101379, Lr:0.0001\n",
      "Epoch 5, Step: 20, Loss: 1.208437204360962, Lr:0.0001\n",
      "Epoch 5, Step: 21, Loss: 0.8935192823410034, Lr:0.0001\n",
      "Epoch 5, Step: 22, Loss: 1.8758517503738403, Lr:0.0001\n",
      "Epoch 5, Step: 23, Loss: 0.456222265958786, Lr:0.0001\n",
      "Epoch 5, Step: 24, Loss: 0.32309967279434204, Lr:0.0001\n",
      "Epoch 5, Step: 25, Loss: 1.2182866334915161, Lr:0.0001\n",
      "Epoch 5, Step: 26, Loss: 0.7053807973861694, Lr:0.0001\n",
      "Epoch 5, Step: 27, Loss: 0.48565244674682617, Lr:0.0001\n",
      "Epoch 5, Step: 28, Loss: 2.907130718231201, Lr:0.0001\n",
      "Epoch 5, Step: 29, Loss: 0.8840422034263611, Lr:0.0001\n",
      "Epoch 5, Step: 30, Loss: 1.8195608854293823, Lr:0.0001\n",
      "Epoch 5, Step: 31, Loss: 0.8390251398086548, Lr:0.0001\n",
      "Epoch 5, Step: 32, Loss: 0.515392005443573, Lr:0.0001\n",
      "Epoch 5, Step: 33, Loss: 1.8602845668792725, Lr:0.0001\n",
      "Epoch 5, Step: 34, Loss: 0.6165059804916382, Lr:0.0001\n",
      "Epoch 5, Step: 35, Loss: 0.7164879441261292, Lr:0.0001\n",
      "Epoch 5, Step: 36, Loss: 0.4384022653102875, Lr:0.0001\n",
      "Epoch 5, Step: 37, Loss: 0.8695461750030518, Lr:0.0001\n",
      "Epoch 5, Step: 38, Loss: 0.5284399390220642, Lr:0.0001\n",
      "Epoch 5, Step: 39, Loss: 0.546261727809906, Lr:0.0001\n",
      "Epoch 5, Step: 40, Loss: 0.6409318447113037, Lr:0.0001\n",
      "Epoch 5, Step: 41, Loss: 1.0894265174865723, Lr:0.0001\n",
      "Epoch 5, Step: 42, Loss: 0.8195222020149231, Lr:0.0001\n",
      "Epoch 5, Step: 43, Loss: 0.17177900671958923, Lr:0.0001\n",
      "Epoch 5, Step: 44, Loss: 1.341813087463379, Lr:0.0001\n",
      "Epoch 5, Step: 45, Loss: 0.8780390620231628, Lr:0.0001\n",
      "Epoch 5, Step: 46, Loss: 0.3227658271789551, Lr:0.0001\n",
      "Epoch 5, Step: 47, Loss: 1.086245059967041, Lr:0.0001\n",
      "Epoch 5, Step: 48, Loss: 1.3814895153045654, Lr:0.0001\n",
      "Epoch 5, Step: 49, Loss: 0.719912052154541, Lr:0.0001\n",
      "Epoch 5, Step: 50, Loss: 0.7598408460617065, Lr:0.0001\n",
      "Epoch 5, Step: 51, Loss: 0.73447585105896, Lr:0.0001\n",
      "Epoch 5, Step: 52, Loss: 0.4059668481349945, Lr:0.0001\n",
      "Epoch 5, Step: 53, Loss: 1.0726726055145264, Lr:0.0001\n",
      "Epoch 5, Step: 54, Loss: 0.28666621446609497, Lr:0.0001\n",
      "Epoch 5, Step: 55, Loss: 0.858981728553772, Lr:0.0001\n",
      "Epoch 5, Step: 56, Loss: 1.5462645292282104, Lr:0.0001\n",
      "Epoch 5, Step: 57, Loss: 0.7625268697738647, Lr:0.0001\n",
      "Epoch 5, Step: 58, Loss: 0.46944406628608704, Lr:0.0001\n",
      "Epoch 5, Step: 59, Loss: 0.5512871146202087, Lr:0.0001\n",
      "Epoch 5, Step: 60, Loss: 0.4878949522972107, Lr:0.0001\n",
      "Epoch 5, Step: 61, Loss: 1.8482893705368042, Lr:0.0001\n",
      "Epoch 5, Step: 62, Loss: 0.5947864055633545, Lr:0.0001\n",
      "Epoch 5, Step: 63, Loss: 1.034895658493042, Lr:0.0001\n",
      "Epoch 5, Step: 64, Loss: 0.1663910448551178, Lr:0.0001\n",
      "Epoch 5, Step: 65, Loss: 0.9099782705307007, Lr:0.0001\n",
      "Epoch 5, Step: 66, Loss: 0.5363638997077942, Lr:0.0001\n",
      "Epoch 5, Step: 67, Loss: 0.9543173313140869, Lr:0.0001\n",
      "Epoch 5, Step: 68, Loss: 0.34753143787384033, Lr:0.0001\n",
      "Epoch 5, Step: 69, Loss: 1.541768193244934, Lr:0.0001\n",
      "Epoch 5, Step: 70, Loss: 0.5669970512390137, Lr:0.0001\n",
      "Epoch 5, Step: 71, Loss: 0.844102144241333, Lr:0.0001\n",
      "Epoch 5, Step: 72, Loss: 1.8638848066329956, Lr:0.0001\n",
      "Epoch 5, Step: 73, Loss: 2.185932159423828, Lr:0.0001\n",
      "Epoch 5, Step: 74, Loss: 0.8078886270523071, Lr:0.0001\n",
      "Epoch 5, Step: 75, Loss: 0.4063565135002136, Lr:0.0001\n",
      "Epoch 5, Step: 76, Loss: 2.08681058883667, Lr:0.0001\n",
      "Epoch 5, Step: 77, Loss: 0.4101112186908722, Lr:0.0001\n",
      "Epoch 5, Step: 78, Loss: 0.521577775478363, Lr:0.0001\n",
      "Epoch 5, Step: 79, Loss: 0.4853889048099518, Lr:0.0001\n",
      "Epoch 5, Step: 80, Loss: 0.9023603200912476, Lr:0.0001\n",
      "Epoch 5, Step: 81, Loss: 0.4620881974697113, Lr:0.0001\n",
      "Epoch 5, Step: 82, Loss: 3.233179807662964, Lr:0.0001\n",
      "Epoch 5, Step: 83, Loss: 0.49535834789276123, Lr:0.0001\n",
      "Epoch 5, Step: 84, Loss: 0.77991783618927, Lr:0.0001\n",
      "Epoch 5, Step: 85, Loss: 0.3742939233779907, Lr:0.0001\n",
      "Epoch 5, Step: 86, Loss: 0.4294039011001587, Lr:0.0001\n",
      "Epoch 5, Step: 87, Loss: 1.1139895915985107, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 5\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.2033 (0.2033) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0080 data: 0.0040 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.3006 (0.6493) acc1: 75.0000 (77.2727) acc5: 100.0000 (100.0000) time: 0.0062 data: 0.0032 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0065 s / it)\n",
      "* Acc@1 77.273 Acc@5 100.000 loss 0.649\n",
      "Accuracy of the network on the 22 test image: 77.3%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 6, Step: 0, Loss: 2.1033709049224854, Lr:0.0001\n",
      "Epoch 6, Step: 1, Loss: 0.5187988877296448, Lr:0.0001\n",
      "Epoch 6, Step: 2, Loss: 0.6954531073570251, Lr:0.0001\n",
      "Epoch 6, Step: 3, Loss: 0.6098204851150513, Lr:0.0001\n",
      "Epoch 6, Step: 4, Loss: 0.8018559813499451, Lr:0.0001\n",
      "Epoch 6, Step: 5, Loss: 2.0917270183563232, Lr:0.0001\n",
      "Epoch 6, Step: 6, Loss: 0.33485090732574463, Lr:0.0001\n",
      "Epoch 6, Step: 7, Loss: 0.6103659272193909, Lr:0.0001\n",
      "Epoch 6, Step: 8, Loss: 1.06787109375, Lr:0.0001\n",
      "Epoch 6, Step: 9, Loss: 1.0170879364013672, Lr:0.0001\n",
      "Epoch 6, Step: 10, Loss: 0.29744043946266174, Lr:0.0001\n",
      "Epoch 6, Step: 11, Loss: 0.1916833072900772, Lr:0.0001\n",
      "Epoch 6, Step: 12, Loss: 0.11090271174907684, Lr:0.0001\n",
      "Epoch 6, Step: 13, Loss: 1.202003002166748, Lr:0.0001\n",
      "Epoch 6, Step: 14, Loss: 1.4620298147201538, Lr:0.0001\n",
      "Epoch 6, Step: 15, Loss: 0.543059229850769, Lr:0.0001\n",
      "Epoch 6, Step: 16, Loss: 0.6067500114440918, Lr:0.0001\n",
      "Epoch 6, Step: 17, Loss: 1.0328619480133057, Lr:0.0001\n",
      "Epoch 6, Step: 18, Loss: 0.8022636771202087, Lr:0.0001\n",
      "Epoch 6, Step: 19, Loss: 0.38591471314430237, Lr:0.0001\n",
      "Epoch 6, Step: 20, Loss: 0.7069776058197021, Lr:0.0001\n",
      "Epoch 6, Step: 21, Loss: 1.560777187347412, Lr:0.0001\n",
      "Epoch 6, Step: 22, Loss: 1.8233250379562378, Lr:0.0001\n",
      "Epoch 6, Step: 23, Loss: 1.2335739135742188, Lr:0.0001\n",
      "Epoch 6, Step: 24, Loss: 1.8346326351165771, Lr:0.0001\n",
      "Epoch 6, Step: 25, Loss: 0.6495755314826965, Lr:0.0001\n",
      "Epoch 6, Step: 26, Loss: 0.5070159435272217, Lr:0.0001\n",
      "Epoch 6, Step: 27, Loss: 1.5375056266784668, Lr:0.0001\n",
      "Epoch 6, Step: 28, Loss: 0.09476685523986816, Lr:0.0001\n",
      "Epoch 6, Step: 29, Loss: 0.7303271293640137, Lr:0.0001\n",
      "Epoch 6, Step: 30, Loss: 0.21164299547672272, Lr:0.0001\n",
      "Epoch 6, Step: 31, Loss: 0.6526299118995667, Lr:0.0001\n",
      "Epoch 6, Step: 32, Loss: 0.6860767602920532, Lr:0.0001\n",
      "Epoch 6, Step: 33, Loss: 0.5483229160308838, Lr:0.0001\n",
      "Epoch 6, Step: 34, Loss: 1.153011441230774, Lr:0.0001\n",
      "Epoch 6, Step: 35, Loss: 0.2573908567428589, Lr:0.0001\n",
      "Epoch 6, Step: 36, Loss: 0.2254258394241333, Lr:0.0001\n",
      "Epoch 6, Step: 37, Loss: 0.7805963754653931, Lr:0.0001\n",
      "Epoch 6, Step: 38, Loss: 1.0342917442321777, Lr:0.0001\n",
      "Epoch 6, Step: 39, Loss: 0.1612251251935959, Lr:0.0001\n",
      "Epoch 6, Step: 40, Loss: 0.26296207308769226, Lr:0.0001\n",
      "Epoch 6, Step: 41, Loss: 0.13815732300281525, Lr:0.0001\n",
      "Epoch 6, Step: 42, Loss: 0.5181270241737366, Lr:0.0001\n",
      "Epoch 6, Step: 43, Loss: 1.1177220344543457, Lr:0.0001\n",
      "Epoch 6, Step: 44, Loss: 0.06898800283670425, Lr:0.0001\n",
      "Epoch 6, Step: 45, Loss: 1.8178060054779053, Lr:0.0001\n",
      "Epoch 6, Step: 46, Loss: 1.1324337720870972, Lr:0.0001\n",
      "Epoch 6, Step: 47, Loss: 0.48755037784576416, Lr:0.0001\n",
      "Epoch 6, Step: 48, Loss: 0.02806541696190834, Lr:0.0001\n",
      "Epoch 6, Step: 49, Loss: 0.07063142955303192, Lr:0.0001\n",
      "Epoch 6, Step: 50, Loss: 1.8491020202636719, Lr:0.0001\n",
      "Epoch 6, Step: 51, Loss: 0.7784997224807739, Lr:0.0001\n",
      "Epoch 6, Step: 52, Loss: 0.7937015891075134, Lr:0.0001\n",
      "Epoch 6, Step: 53, Loss: 0.16315720975399017, Lr:0.0001\n",
      "Epoch 6, Step: 54, Loss: 1.0930931568145752, Lr:0.0001\n",
      "Epoch 6, Step: 55, Loss: 0.3060327172279358, Lr:0.0001\n",
      "Epoch 6, Step: 56, Loss: 0.8019176721572876, Lr:0.0001\n",
      "Epoch 6, Step: 57, Loss: 0.5732548236846924, Lr:0.0001\n",
      "Epoch 6, Step: 58, Loss: 0.92134028673172, Lr:0.0001\n",
      "Epoch 6, Step: 59, Loss: 0.6625286340713501, Lr:0.0001\n",
      "Epoch 6, Step: 60, Loss: 0.3755025863647461, Lr:0.0001\n",
      "Epoch 6, Step: 61, Loss: 1.5691227912902832, Lr:0.0001\n",
      "Epoch 6, Step: 62, Loss: 0.6838632822036743, Lr:0.0001\n",
      "Epoch 6, Step: 63, Loss: 0.9515371918678284, Lr:0.0001\n",
      "Epoch 6, Step: 64, Loss: 0.660633385181427, Lr:0.0001\n",
      "Epoch 6, Step: 65, Loss: 0.930885910987854, Lr:0.0001\n",
      "Epoch 6, Step: 66, Loss: 1.3164969682693481, Lr:0.0001\n",
      "Epoch 6, Step: 67, Loss: 0.17056016623973846, Lr:0.0001\n",
      "Epoch 6, Step: 68, Loss: 1.333991527557373, Lr:0.0001\n",
      "Epoch 6, Step: 69, Loss: 1.0716712474822998, Lr:0.0001\n",
      "Epoch 6, Step: 70, Loss: 0.441142737865448, Lr:0.0001\n",
      "Epoch 6, Step: 71, Loss: 0.8787252902984619, Lr:0.0001\n",
      "Epoch 6, Step: 72, Loss: 0.6857832670211792, Lr:0.0001\n",
      "Epoch 6, Step: 73, Loss: 1.9484705924987793, Lr:0.0001\n",
      "Epoch 6, Step: 74, Loss: 0.49553442001342773, Lr:0.0001\n",
      "Epoch 6, Step: 75, Loss: 0.2947500944137573, Lr:0.0001\n",
      "Epoch 6, Step: 76, Loss: 0.8207613229751587, Lr:0.0001\n",
      "Epoch 6, Step: 77, Loss: 0.20543938875198364, Lr:0.0001\n",
      "Epoch 6, Step: 78, Loss: 0.8360080718994141, Lr:0.0001\n",
      "Epoch 6, Step: 79, Loss: 0.8506461977958679, Lr:0.0001\n",
      "Epoch 6, Step: 80, Loss: 0.6227579712867737, Lr:0.0001\n",
      "Epoch 6, Step: 81, Loss: 0.7818944454193115, Lr:0.0001\n",
      "Epoch 6, Step: 82, Loss: 0.37065547704696655, Lr:0.0001\n",
      "Epoch 6, Step: 83, Loss: 0.5851410627365112, Lr:0.0001\n",
      "Epoch 6, Step: 84, Loss: 0.20746831595897675, Lr:0.0001\n",
      "Epoch 6, Step: 85, Loss: 0.8485400676727295, Lr:0.0001\n",
      "Epoch 6, Step: 86, Loss: 0.9928160905838013, Lr:0.0001\n",
      "Epoch 6, Step: 87, Loss: 1.3199586868286133, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 6\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.3405 (0.3405) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.5681 (0.7319) acc1: 50.0000 (68.1818) acc5: 100.0000 (100.0000) time: 0.0079 data: 0.0042 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0081 s / it)\n",
      "* Acc@1 68.182 Acc@5 100.000 loss 0.732\n",
      "Accuracy of the network on the 22 test image: 68.2%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 7, Step: 0, Loss: 2.8366079330444336, Lr:0.0001\n",
      "Epoch 7, Step: 1, Loss: 0.08241423964500427, Lr:0.0001\n",
      "Epoch 7, Step: 2, Loss: 0.17029739916324615, Lr:0.0001\n",
      "Epoch 7, Step: 3, Loss: 0.08818966150283813, Lr:0.0001\n",
      "Epoch 7, Step: 4, Loss: 1.9761536121368408, Lr:0.0001\n",
      "Epoch 7, Step: 5, Loss: 0.4072244167327881, Lr:0.0001\n",
      "Epoch 7, Step: 6, Loss: 0.5436966419219971, Lr:0.0001\n",
      "Epoch 7, Step: 7, Loss: 0.16922613978385925, Lr:0.0001\n",
      "Epoch 7, Step: 8, Loss: 0.7433713674545288, Lr:0.0001\n",
      "Epoch 7, Step: 9, Loss: 2.1977384090423584, Lr:0.0001\n",
      "Epoch 7, Step: 10, Loss: 1.123787522315979, Lr:0.0001\n",
      "Epoch 7, Step: 11, Loss: 0.6732145547866821, Lr:0.0001\n",
      "Epoch 7, Step: 12, Loss: 1.6070168018341064, Lr:0.0001\n",
      "Epoch 7, Step: 13, Loss: 0.5463494658470154, Lr:0.0001\n",
      "Epoch 7, Step: 14, Loss: 1.1434797048568726, Lr:0.0001\n",
      "Epoch 7, Step: 15, Loss: 0.5092692971229553, Lr:0.0001\n",
      "Epoch 7, Step: 16, Loss: 1.5041017532348633, Lr:0.0001\n",
      "Epoch 7, Step: 17, Loss: 0.785078763961792, Lr:0.0001\n",
      "Epoch 7, Step: 18, Loss: 1.5746091604232788, Lr:0.0001\n",
      "Epoch 7, Step: 19, Loss: 0.48172545433044434, Lr:0.0001\n",
      "Epoch 7, Step: 20, Loss: 0.5778403282165527, Lr:0.0001\n",
      "Epoch 7, Step: 21, Loss: 2.7170183658599854, Lr:0.0001\n",
      "Epoch 7, Step: 22, Loss: 0.5422930717468262, Lr:0.0001\n",
      "Epoch 7, Step: 23, Loss: 0.13382931053638458, Lr:0.0001\n",
      "Epoch 7, Step: 24, Loss: 0.3128821849822998, Lr:0.0001\n",
      "Epoch 7, Step: 25, Loss: 0.6573757529258728, Lr:0.0001\n",
      "Epoch 7, Step: 26, Loss: 1.163880467414856, Lr:0.0001\n",
      "Epoch 7, Step: 27, Loss: 0.631043553352356, Lr:0.0001\n",
      "Epoch 7, Step: 28, Loss: 0.8897823095321655, Lr:0.0001\n",
      "Epoch 7, Step: 29, Loss: 1.0626169443130493, Lr:0.0001\n",
      "Epoch 7, Step: 30, Loss: 1.1071398258209229, Lr:0.0001\n",
      "Epoch 7, Step: 31, Loss: 1.1031572818756104, Lr:0.0001\n",
      "Epoch 7, Step: 32, Loss: 0.7740269899368286, Lr:0.0001\n",
      "Epoch 7, Step: 33, Loss: 0.057924240827560425, Lr:0.0001\n",
      "Epoch 7, Step: 34, Loss: 0.2612001895904541, Lr:0.0001\n",
      "Epoch 7, Step: 35, Loss: 0.768559992313385, Lr:0.0001\n",
      "Epoch 7, Step: 36, Loss: 1.1147418022155762, Lr:0.0001\n",
      "Epoch 7, Step: 37, Loss: 0.4901198148727417, Lr:0.0001\n",
      "Epoch 7, Step: 38, Loss: 0.7667612433433533, Lr:0.0001\n",
      "Epoch 7, Step: 39, Loss: 0.4027167856693268, Lr:0.0001\n",
      "Epoch 7, Step: 40, Loss: 0.35575705766677856, Lr:0.0001\n",
      "Epoch 7, Step: 41, Loss: 0.39908722043037415, Lr:0.0001\n",
      "Epoch 7, Step: 42, Loss: 0.03869505226612091, Lr:0.0001\n",
      "Epoch 7, Step: 43, Loss: 0.5775687098503113, Lr:0.0001\n",
      "Epoch 7, Step: 44, Loss: 1.8368642330169678, Lr:0.0001\n",
      "Epoch 7, Step: 45, Loss: 1.252195954322815, Lr:0.0001\n",
      "Epoch 7, Step: 46, Loss: 0.5652600526809692, Lr:0.0001\n",
      "Epoch 7, Step: 47, Loss: 0.19213993847370148, Lr:0.0001\n",
      "Epoch 7, Step: 48, Loss: 1.706667184829712, Lr:0.0001\n",
      "Epoch 7, Step: 49, Loss: 0.47020983695983887, Lr:0.0001\n",
      "Epoch 7, Step: 50, Loss: 0.5068686008453369, Lr:0.0001\n",
      "Epoch 7, Step: 51, Loss: 0.5431490540504456, Lr:0.0001\n",
      "Epoch 7, Step: 52, Loss: 0.4711860716342926, Lr:0.0001\n",
      "Epoch 7, Step: 53, Loss: 0.919611394405365, Lr:0.0001\n",
      "Epoch 7, Step: 54, Loss: 0.577113151550293, Lr:0.0001\n",
      "Epoch 7, Step: 55, Loss: 1.2646361589431763, Lr:0.0001\n",
      "Epoch 7, Step: 56, Loss: 0.887565016746521, Lr:0.0001\n",
      "Epoch 7, Step: 57, Loss: 1.3457790613174438, Lr:0.0001\n",
      "Epoch 7, Step: 58, Loss: 0.5604129433631897, Lr:0.0001\n",
      "Epoch 7, Step: 59, Loss: 0.035943206399679184, Lr:0.0001\n",
      "Epoch 7, Step: 60, Loss: 0.6449860334396362, Lr:0.0001\n",
      "Epoch 7, Step: 61, Loss: 0.9619744420051575, Lr:0.0001\n",
      "Epoch 7, Step: 62, Loss: 0.32369086146354675, Lr:0.0001\n",
      "Epoch 7, Step: 63, Loss: 0.5899078249931335, Lr:0.0001\n",
      "Epoch 7, Step: 64, Loss: 0.7319592833518982, Lr:0.0001\n",
      "Epoch 7, Step: 65, Loss: 0.37674808502197266, Lr:0.0001\n",
      "Epoch 7, Step: 66, Loss: 0.8929678201675415, Lr:0.0001\n",
      "Epoch 7, Step: 67, Loss: 0.09991668164730072, Lr:0.0001\n",
      "Epoch 7, Step: 68, Loss: 0.38264280557632446, Lr:0.0001\n",
      "Epoch 7, Step: 69, Loss: 0.2409835308790207, Lr:0.0001\n",
      "Epoch 7, Step: 70, Loss: 0.9093012809753418, Lr:0.0001\n",
      "Epoch 7, Step: 71, Loss: 1.1225664615631104, Lr:0.0001\n",
      "Epoch 7, Step: 72, Loss: 0.7960352897644043, Lr:0.0001\n",
      "Epoch 7, Step: 73, Loss: 0.46727171540260315, Lr:0.0001\n",
      "Epoch 7, Step: 74, Loss: 1.9273430109024048, Lr:0.0001\n",
      "Epoch 7, Step: 75, Loss: 0.9879088997840881, Lr:0.0001\n",
      "Epoch 7, Step: 76, Loss: 1.346467137336731, Lr:0.0001\n",
      "Epoch 7, Step: 77, Loss: 0.11254692077636719, Lr:0.0001\n",
      "Epoch 7, Step: 78, Loss: 0.24476449191570282, Lr:0.0001\n",
      "Epoch 7, Step: 79, Loss: 0.5055059790611267, Lr:0.0001\n",
      "Epoch 7, Step: 80, Loss: 1.172576665878296, Lr:0.0001\n",
      "Epoch 7, Step: 81, Loss: 0.17547020316123962, Lr:0.0001\n",
      "Epoch 7, Step: 82, Loss: 2.887648105621338, Lr:0.0001\n",
      "Epoch 7, Step: 83, Loss: 1.0901455879211426, Lr:0.0001\n",
      "Epoch 7, Step: 84, Loss: 0.1776636838912964, Lr:0.0001\n",
      "Epoch 7, Step: 85, Loss: 0.44984692335128784, Lr:0.0001\n",
      "Epoch 7, Step: 86, Loss: 0.606467068195343, Lr:0.0001\n",
      "Epoch 7, Step: 87, Loss: 0.12779740989208221, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 7\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.0541 (0.0541) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.0541 (0.4796) acc1: 100.0000 (90.9091) acc5: 100.0000 (100.0000) time: 0.0073 data: 0.0037 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0073 s / it)\n",
      "* Acc@1 90.909 Acc@5 100.000 loss 0.480\n",
      "Accuracy of the network on the 22 test image: 90.9%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 8, Step: 0, Loss: 0.32889801263809204, Lr:0.0001\n",
      "Epoch 8, Step: 1, Loss: 0.5659722089767456, Lr:0.0001\n",
      "Epoch 8, Step: 2, Loss: 0.3418120741844177, Lr:0.0001\n",
      "Epoch 8, Step: 3, Loss: 0.10350200533866882, Lr:0.0001\n",
      "Epoch 8, Step: 4, Loss: 0.08165325969457626, Lr:0.0001\n",
      "Epoch 8, Step: 5, Loss: 1.1116883754730225, Lr:0.0001\n",
      "Epoch 8, Step: 6, Loss: 0.9541214108467102, Lr:0.0001\n",
      "Epoch 8, Step: 7, Loss: 0.18527066707611084, Lr:0.0001\n",
      "Epoch 8, Step: 8, Loss: 0.5344457626342773, Lr:0.0001\n",
      "Epoch 8, Step: 9, Loss: 1.5512818098068237, Lr:0.0001\n",
      "Epoch 8, Step: 10, Loss: 0.8159645199775696, Lr:0.0001\n",
      "Epoch 8, Step: 11, Loss: 0.349011093378067, Lr:0.0001\n",
      "Epoch 8, Step: 12, Loss: 0.2909599542617798, Lr:0.0001\n",
      "Epoch 8, Step: 13, Loss: 0.20935703814029694, Lr:0.0001\n",
      "Epoch 8, Step: 14, Loss: 0.3406318426132202, Lr:0.0001\n",
      "Epoch 8, Step: 15, Loss: 0.08247148245573044, Lr:0.0001\n",
      "Epoch 8, Step: 16, Loss: 0.20399442315101624, Lr:0.0001\n",
      "Epoch 8, Step: 17, Loss: 0.2944675087928772, Lr:0.0001\n",
      "Epoch 8, Step: 18, Loss: 0.054893188178539276, Lr:0.0001\n",
      "Epoch 8, Step: 19, Loss: 0.4469117522239685, Lr:0.0001\n",
      "Epoch 8, Step: 20, Loss: 0.15676036477088928, Lr:0.0001\n",
      "Epoch 8, Step: 21, Loss: 0.39650237560272217, Lr:0.0001\n",
      "Epoch 8, Step: 22, Loss: 0.9906393885612488, Lr:0.0001\n",
      "Epoch 8, Step: 23, Loss: 1.251389980316162, Lr:0.0001\n",
      "Epoch 8, Step: 24, Loss: 0.10813615471124649, Lr:0.0001\n",
      "Epoch 8, Step: 25, Loss: 2.5884816646575928, Lr:0.0001\n",
      "Epoch 8, Step: 26, Loss: 0.7281892895698547, Lr:0.0001\n",
      "Epoch 8, Step: 27, Loss: 0.09709656983613968, Lr:0.0001\n",
      "Epoch 8, Step: 28, Loss: 0.4420655071735382, Lr:0.0001\n",
      "Epoch 8, Step: 29, Loss: 1.0594247579574585, Lr:0.0001\n",
      "Epoch 8, Step: 30, Loss: 1.0550543069839478, Lr:0.0001\n",
      "Epoch 8, Step: 31, Loss: 1.732275128364563, Lr:0.0001\n",
      "Epoch 8, Step: 32, Loss: 1.2068769931793213, Lr:0.0001\n",
      "Epoch 8, Step: 33, Loss: 1.9474070072174072, Lr:0.0001\n",
      "Epoch 8, Step: 34, Loss: 0.34494665265083313, Lr:0.0001\n",
      "Epoch 8, Step: 35, Loss: 0.7312133312225342, Lr:0.0001\n",
      "Epoch 8, Step: 36, Loss: 0.312775194644928, Lr:0.0001\n",
      "Epoch 8, Step: 37, Loss: 0.9898576140403748, Lr:0.0001\n",
      "Epoch 8, Step: 38, Loss: 0.045041412115097046, Lr:0.0001\n",
      "Epoch 8, Step: 39, Loss: 0.5485336184501648, Lr:0.0001\n",
      "Epoch 8, Step: 40, Loss: 0.657135009765625, Lr:0.0001\n",
      "Epoch 8, Step: 41, Loss: 0.35166114568710327, Lr:0.0001\n",
      "Epoch 8, Step: 42, Loss: 1.447913408279419, Lr:0.0001\n",
      "Epoch 8, Step: 43, Loss: 1.302029013633728, Lr:0.0001\n",
      "Epoch 8, Step: 44, Loss: 1.739035964012146, Lr:0.0001\n",
      "Epoch 8, Step: 45, Loss: 0.5145799517631531, Lr:0.0001\n",
      "Epoch 8, Step: 46, Loss: 0.6690827012062073, Lr:0.0001\n",
      "Epoch 8, Step: 47, Loss: 0.8144243955612183, Lr:0.0001\n",
      "Epoch 8, Step: 48, Loss: 1.6931734085083008, Lr:0.0001\n",
      "Epoch 8, Step: 49, Loss: 0.1721424013376236, Lr:0.0001\n",
      "Epoch 8, Step: 50, Loss: 0.4123414158821106, Lr:0.0001\n",
      "Epoch 8, Step: 51, Loss: 1.1950551271438599, Lr:0.0001\n",
      "Epoch 8, Step: 52, Loss: 0.865248441696167, Lr:0.0001\n",
      "Epoch 8, Step: 53, Loss: 1.8000812530517578, Lr:0.0001\n",
      "Epoch 8, Step: 54, Loss: 0.4148993492126465, Lr:0.0001\n",
      "Epoch 8, Step: 55, Loss: 0.6884000897407532, Lr:0.0001\n",
      "Epoch 8, Step: 56, Loss: 0.5063474178314209, Lr:0.0001\n",
      "Epoch 8, Step: 57, Loss: 0.7563338875770569, Lr:0.0001\n",
      "Epoch 8, Step: 58, Loss: 1.2971826791763306, Lr:0.0001\n",
      "Epoch 8, Step: 59, Loss: 0.07326110452413559, Lr:0.0001\n",
      "Epoch 8, Step: 60, Loss: 0.5016846656799316, Lr:0.0001\n",
      "Epoch 8, Step: 61, Loss: 0.5905432105064392, Lr:0.0001\n",
      "Epoch 8, Step: 62, Loss: 0.3466704189777374, Lr:0.0001\n",
      "Epoch 8, Step: 63, Loss: 2.593858242034912, Lr:0.0001\n",
      "Epoch 8, Step: 64, Loss: 1.467858910560608, Lr:0.0001\n",
      "Epoch 8, Step: 65, Loss: 0.9141108393669128, Lr:0.0001\n",
      "Epoch 8, Step: 66, Loss: 0.6518572568893433, Lr:0.0001\n",
      "Epoch 8, Step: 67, Loss: 0.35906970500946045, Lr:0.0001\n",
      "Epoch 8, Step: 68, Loss: 0.4417262673377991, Lr:0.0001\n",
      "Epoch 8, Step: 69, Loss: 0.49694105982780457, Lr:0.0001\n",
      "Epoch 8, Step: 70, Loss: 0.5155530571937561, Lr:0.0001\n",
      "Epoch 8, Step: 71, Loss: 0.7819809913635254, Lr:0.0001\n",
      "Epoch 8, Step: 72, Loss: 0.6829763054847717, Lr:0.0001\n",
      "Epoch 8, Step: 73, Loss: 0.5967944860458374, Lr:0.0001\n",
      "Epoch 8, Step: 74, Loss: 1.2210379838943481, Lr:0.0001\n",
      "Epoch 8, Step: 75, Loss: 0.8805751204490662, Lr:0.0001\n",
      "Epoch 8, Step: 76, Loss: 0.07029414176940918, Lr:0.0001\n",
      "Epoch 8, Step: 77, Loss: 1.2027908563613892, Lr:0.0001\n",
      "Epoch 8, Step: 78, Loss: 0.25415951013565063, Lr:0.0001\n",
      "Epoch 8, Step: 79, Loss: 1.1978192329406738, Lr:0.0001\n",
      "Epoch 8, Step: 80, Loss: 0.8594876527786255, Lr:0.0001\n",
      "Epoch 8, Step: 81, Loss: 1.9593042135238647, Lr:0.0001\n",
      "Epoch 8, Step: 82, Loss: 0.8836997747421265, Lr:0.0001\n",
      "Epoch 8, Step: 83, Loss: 0.8014512062072754, Lr:0.0001\n",
      "Epoch 8, Step: 84, Loss: 0.1178676187992096, Lr:0.0001\n",
      "Epoch 8, Step: 85, Loss: 0.451168030500412, Lr:0.0001\n",
      "Epoch 8, Step: 86, Loss: 0.31578558683395386, Lr:0.0001\n",
      "Epoch 8, Step: 87, Loss: 0.6767362356185913, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 8\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.5139 (0.5139) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.5139 (0.5190) acc1: 100.0000 (90.9091) acc5: 100.0000 (100.0000) time: 0.0067 data: 0.0032 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0068 s / it)\n",
      "* Acc@1 90.909 Acc@5 100.000 loss 0.519\n",
      "Accuracy of the network on the 22 test image: 90.9%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 9, Step: 0, Loss: 2.7027573585510254, Lr:0.0001\n",
      "Epoch 9, Step: 1, Loss: 1.3765751123428345, Lr:0.0001\n",
      "Epoch 9, Step: 2, Loss: 0.8812073469161987, Lr:0.0001\n",
      "Epoch 9, Step: 3, Loss: 0.49088844656944275, Lr:0.0001\n",
      "Epoch 9, Step: 4, Loss: 0.5043368339538574, Lr:0.0001\n",
      "Epoch 9, Step: 5, Loss: 0.3200429677963257, Lr:0.0001\n",
      "Epoch 9, Step: 6, Loss: 0.18151801824569702, Lr:0.0001\n",
      "Epoch 9, Step: 7, Loss: 0.7457835674285889, Lr:0.0001\n",
      "Epoch 9, Step: 8, Loss: 0.6624031662940979, Lr:0.0001\n",
      "Epoch 9, Step: 9, Loss: 0.06458909064531326, Lr:0.0001\n",
      "Epoch 9, Step: 10, Loss: 0.8215711712837219, Lr:0.0001\n",
      "Epoch 9, Step: 11, Loss: 0.8396682739257812, Lr:0.0001\n",
      "Epoch 9, Step: 12, Loss: 0.748524010181427, Lr:0.0001\n",
      "Epoch 9, Step: 13, Loss: 2.3744468688964844, Lr:0.0001\n",
      "Epoch 9, Step: 14, Loss: 1.7016844749450684, Lr:0.0001\n",
      "Epoch 9, Step: 15, Loss: 0.26965758204460144, Lr:0.0001\n",
      "Epoch 9, Step: 16, Loss: 0.2213502824306488, Lr:0.0001\n",
      "Epoch 9, Step: 17, Loss: 1.5651514530181885, Lr:0.0001\n",
      "Epoch 9, Step: 18, Loss: 0.93207186460495, Lr:0.0001\n",
      "Epoch 9, Step: 19, Loss: 0.0849362164735794, Lr:0.0001\n",
      "Epoch 9, Step: 20, Loss: 0.7462455034255981, Lr:0.0001\n",
      "Epoch 9, Step: 21, Loss: 0.12526825070381165, Lr:0.0001\n",
      "Epoch 9, Step: 22, Loss: 1.3570066690444946, Lr:0.0001\n",
      "Epoch 9, Step: 23, Loss: 0.1544240415096283, Lr:0.0001\n",
      "Epoch 9, Step: 24, Loss: 0.7928295731544495, Lr:0.0001\n",
      "Epoch 9, Step: 25, Loss: 0.7751736640930176, Lr:0.0001\n",
      "Epoch 9, Step: 26, Loss: 0.6559168100357056, Lr:0.0001\n",
      "Epoch 9, Step: 27, Loss: 0.8341730833053589, Lr:0.0001\n",
      "Epoch 9, Step: 28, Loss: 1.0830459594726562, Lr:0.0001\n",
      "Epoch 9, Step: 29, Loss: 1.0295077562332153, Lr:0.0001\n",
      "Epoch 9, Step: 30, Loss: 1.272244930267334, Lr:0.0001\n",
      "Epoch 9, Step: 31, Loss: 0.5270785093307495, Lr:0.0001\n",
      "Epoch 9, Step: 32, Loss: 1.2254890203475952, Lr:0.0001\n",
      "Epoch 9, Step: 33, Loss: 2.101308584213257, Lr:0.0001\n",
      "Epoch 9, Step: 34, Loss: 0.09792651981115341, Lr:0.0001\n",
      "Epoch 9, Step: 35, Loss: 1.1895828247070312, Lr:0.0001\n",
      "Epoch 9, Step: 36, Loss: 0.5715165138244629, Lr:0.0001\n",
      "Epoch 9, Step: 37, Loss: 0.42440807819366455, Lr:0.0001\n",
      "Epoch 9, Step: 38, Loss: 0.5642554759979248, Lr:0.0001\n",
      "Epoch 9, Step: 39, Loss: 0.12412399053573608, Lr:0.0001\n",
      "Epoch 9, Step: 40, Loss: 0.489332914352417, Lr:0.0001\n",
      "Epoch 9, Step: 41, Loss: 0.6635936498641968, Lr:0.0001\n",
      "Epoch 9, Step: 42, Loss: 0.48806095123291016, Lr:0.0001\n",
      "Epoch 9, Step: 43, Loss: 0.9556493163108826, Lr:0.0001\n",
      "Epoch 9, Step: 44, Loss: 0.5638299584388733, Lr:0.0001\n",
      "Epoch 9, Step: 45, Loss: 1.3115055561065674, Lr:0.0001\n",
      "Epoch 9, Step: 46, Loss: 1.2617923021316528, Lr:0.0001\n",
      "Epoch 9, Step: 47, Loss: 0.18811126053333282, Lr:0.0001\n",
      "Epoch 9, Step: 48, Loss: 0.7823288440704346, Lr:0.0001\n",
      "Epoch 9, Step: 49, Loss: 0.38130655884742737, Lr:0.0001\n",
      "Epoch 9, Step: 50, Loss: 0.5836352109909058, Lr:0.0001\n",
      "Epoch 9, Step: 51, Loss: 0.4177347421646118, Lr:0.0001\n",
      "Epoch 9, Step: 52, Loss: 0.8496477603912354, Lr:0.0001\n",
      "Epoch 9, Step: 53, Loss: 0.7165879607200623, Lr:0.0001\n",
      "Epoch 9, Step: 54, Loss: 0.22119605541229248, Lr:0.0001\n",
      "Epoch 9, Step: 55, Loss: 0.5504417419433594, Lr:0.0001\n",
      "Epoch 9, Step: 56, Loss: 0.5598405599594116, Lr:0.0001\n",
      "Epoch 9, Step: 57, Loss: 0.7369017601013184, Lr:0.0001\n",
      "Epoch 9, Step: 58, Loss: 0.7339710593223572, Lr:0.0001\n",
      "Epoch 9, Step: 59, Loss: 0.7550960779190063, Lr:0.0001\n",
      "Epoch 9, Step: 60, Loss: 0.3504220247268677, Lr:0.0001\n",
      "Epoch 9, Step: 61, Loss: 1.0530314445495605, Lr:0.0001\n",
      "Epoch 9, Step: 62, Loss: 0.15855193138122559, Lr:0.0001\n",
      "Epoch 9, Step: 63, Loss: 0.5098941326141357, Lr:0.0001\n",
      "Epoch 9, Step: 64, Loss: 0.03126612678170204, Lr:0.0001\n",
      "Epoch 9, Step: 65, Loss: 1.4495184421539307, Lr:0.0001\n",
      "Epoch 9, Step: 66, Loss: 0.024074070155620575, Lr:0.0001\n",
      "Epoch 9, Step: 67, Loss: 0.039034403860569, Lr:0.0001\n",
      "Epoch 9, Step: 68, Loss: 0.6373679637908936, Lr:0.0001\n",
      "Epoch 9, Step: 69, Loss: 0.2938872277736664, Lr:0.0001\n",
      "Epoch 9, Step: 70, Loss: 0.3469608724117279, Lr:0.0001\n",
      "Epoch 9, Step: 71, Loss: 1.7276723384857178, Lr:0.0001\n",
      "Epoch 9, Step: 72, Loss: 0.8666408061981201, Lr:0.0001\n",
      "Epoch 9, Step: 73, Loss: 0.4166014790534973, Lr:0.0001\n",
      "Epoch 9, Step: 74, Loss: 0.9794571995735168, Lr:0.0001\n",
      "Epoch 9, Step: 75, Loss: 0.4787081182003021, Lr:0.0001\n",
      "Epoch 9, Step: 76, Loss: 0.4860296845436096, Lr:0.0001\n",
      "Epoch 9, Step: 77, Loss: 0.4104362726211548, Lr:0.0001\n",
      "Epoch 9, Step: 78, Loss: 0.5463106036186218, Lr:0.0001\n",
      "Epoch 9, Step: 79, Loss: 0.9714431762695312, Lr:0.0001\n",
      "Epoch 9, Step: 80, Loss: 0.6090102195739746, Lr:0.0001\n",
      "Epoch 9, Step: 81, Loss: 0.11351987719535828, Lr:0.0001\n",
      "Epoch 9, Step: 82, Loss: 0.4494348168373108, Lr:0.0001\n",
      "Epoch 9, Step: 83, Loss: 1.1565825939178467, Lr:0.0001\n",
      "Epoch 9, Step: 84, Loss: 0.7567809224128723, Lr:0.0001\n",
      "Epoch 9, Step: 85, Loss: 0.7540373802185059, Lr:0.0001\n",
      "Epoch 9, Step: 86, Loss: 0.2279224395751953, Lr:0.0001\n",
      "Epoch 9, Step: 87, Loss: 0.8242425918579102, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 9\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.0113 (0.0113) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0110 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.1254 (0.4375) acc1: 100.0000 (86.3636) acc5: 100.0000 (100.0000) time: 0.0082 data: 0.0038 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0083 s / it)\n",
      "* Acc@1 86.364 Acc@5 100.000 loss 0.438\n",
      "Accuracy of the network on the 22 test image: 86.4%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 10, Step: 0, Loss: 0.5048828125, Lr:0.0001\n",
      "Epoch 10, Step: 1, Loss: 1.201718807220459, Lr:0.0001\n",
      "Epoch 10, Step: 2, Loss: 0.4913351535797119, Lr:0.0001\n",
      "Epoch 10, Step: 3, Loss: 0.4221435487270355, Lr:0.0001\n",
      "Epoch 10, Step: 4, Loss: 0.41888895630836487, Lr:0.0001\n",
      "Epoch 10, Step: 5, Loss: 0.1924644410610199, Lr:0.0001\n",
      "Epoch 10, Step: 6, Loss: 0.45447155833244324, Lr:0.0001\n",
      "Epoch 10, Step: 7, Loss: 1.0889686346054077, Lr:0.0001\n",
      "Epoch 10, Step: 8, Loss: 1.227099895477295, Lr:0.0001\n",
      "Epoch 10, Step: 9, Loss: 0.9820481538772583, Lr:0.0001\n",
      "Epoch 10, Step: 10, Loss: 0.3824945092201233, Lr:0.0001\n",
      "Epoch 10, Step: 11, Loss: 0.39057523012161255, Lr:0.0001\n",
      "Epoch 10, Step: 12, Loss: 0.17681431770324707, Lr:0.0001\n",
      "Epoch 10, Step: 13, Loss: 0.47499772906303406, Lr:0.0001\n",
      "Epoch 10, Step: 14, Loss: 0.32036876678466797, Lr:0.0001\n",
      "Epoch 10, Step: 15, Loss: 0.5186589956283569, Lr:0.0001\n",
      "Epoch 10, Step: 16, Loss: 0.4863719344139099, Lr:0.0001\n",
      "Epoch 10, Step: 17, Loss: 0.10006874054670334, Lr:0.0001\n",
      "Epoch 10, Step: 18, Loss: 0.414387971162796, Lr:0.0001\n",
      "Epoch 10, Step: 19, Loss: 1.8364707231521606, Lr:0.0001\n",
      "Epoch 10, Step: 20, Loss: 0.8758819699287415, Lr:0.0001\n",
      "Epoch 10, Step: 21, Loss: 0.7779425382614136, Lr:0.0001\n",
      "Epoch 10, Step: 22, Loss: 0.5242356657981873, Lr:0.0001\n",
      "Epoch 10, Step: 23, Loss: 0.3289586007595062, Lr:0.0001\n",
      "Epoch 10, Step: 24, Loss: 1.0113599300384521, Lr:0.0001\n",
      "Epoch 10, Step: 25, Loss: 0.6943840384483337, Lr:0.0001\n",
      "Epoch 10, Step: 26, Loss: 0.14555561542510986, Lr:0.0001\n",
      "Epoch 10, Step: 27, Loss: 0.8595429062843323, Lr:0.0001\n",
      "Epoch 10, Step: 28, Loss: 0.4493127465248108, Lr:0.0001\n",
      "Epoch 10, Step: 29, Loss: 0.9151578545570374, Lr:0.0001\n",
      "Epoch 10, Step: 30, Loss: 0.1787359118461609, Lr:0.0001\n",
      "Epoch 10, Step: 31, Loss: 0.16346688568592072, Lr:0.0001\n",
      "Epoch 10, Step: 32, Loss: 0.14683523774147034, Lr:0.0001\n",
      "Epoch 10, Step: 33, Loss: 0.8895494341850281, Lr:0.0001\n",
      "Epoch 10, Step: 34, Loss: 1.6145312786102295, Lr:0.0001\n",
      "Epoch 10, Step: 35, Loss: 0.4110073149204254, Lr:0.0001\n",
      "Epoch 10, Step: 36, Loss: 0.9888367652893066, Lr:0.0001\n",
      "Epoch 10, Step: 37, Loss: 0.5219646692276001, Lr:0.0001\n",
      "Epoch 10, Step: 38, Loss: 0.7333080768585205, Lr:0.0001\n",
      "Epoch 10, Step: 39, Loss: 0.7003710865974426, Lr:0.0001\n",
      "Epoch 10, Step: 40, Loss: 0.7875981330871582, Lr:0.0001\n",
      "Epoch 10, Step: 41, Loss: 1.2236034870147705, Lr:0.0001\n",
      "Epoch 10, Step: 42, Loss: 0.3101244270801544, Lr:0.0001\n",
      "Epoch 10, Step: 43, Loss: 0.7705286741256714, Lr:0.0001\n",
      "Epoch 10, Step: 44, Loss: 0.784529447555542, Lr:0.0001\n",
      "Epoch 10, Step: 45, Loss: 0.24786436557769775, Lr:0.0001\n",
      "Epoch 10, Step: 46, Loss: 2.322749137878418, Lr:0.0001\n",
      "Epoch 10, Step: 47, Loss: 2.1067049503326416, Lr:0.0001\n",
      "Epoch 10, Step: 48, Loss: 0.36687368154525757, Lr:0.0001\n",
      "Epoch 10, Step: 49, Loss: 0.43156158924102783, Lr:0.0001\n",
      "Epoch 10, Step: 50, Loss: 0.3477325439453125, Lr:0.0001\n",
      "Epoch 10, Step: 51, Loss: 4.649117469787598, Lr:0.0001\n",
      "Epoch 10, Step: 52, Loss: 0.34895551204681396, Lr:0.0001\n",
      "Epoch 10, Step: 53, Loss: 0.5280303359031677, Lr:0.0001\n",
      "Epoch 10, Step: 54, Loss: 0.862027108669281, Lr:0.0001\n",
      "Epoch 10, Step: 55, Loss: 0.41349679231643677, Lr:0.0001\n",
      "Epoch 10, Step: 56, Loss: 0.12605345249176025, Lr:0.0001\n",
      "Epoch 10, Step: 57, Loss: 0.9253976941108704, Lr:0.0001\n",
      "Epoch 10, Step: 58, Loss: 0.5729869604110718, Lr:0.0001\n",
      "Epoch 10, Step: 59, Loss: 2.1802382469177246, Lr:0.0001\n",
      "Epoch 10, Step: 60, Loss: 1.2418763637542725, Lr:0.0001\n",
      "Epoch 10, Step: 61, Loss: 0.8639671802520752, Lr:0.0001\n",
      "Epoch 10, Step: 62, Loss: 1.3929486274719238, Lr:0.0001\n",
      "Epoch 10, Step: 63, Loss: 1.5836706161499023, Lr:0.0001\n",
      "Epoch 10, Step: 64, Loss: 0.8699476718902588, Lr:0.0001\n",
      "Epoch 10, Step: 65, Loss: 0.3595726490020752, Lr:0.0001\n",
      "Epoch 10, Step: 66, Loss: 0.42242011427879333, Lr:0.0001\n",
      "Epoch 10, Step: 67, Loss: 0.34611719846725464, Lr:0.0001\n",
      "Epoch 10, Step: 68, Loss: 0.7181943655014038, Lr:0.0001\n",
      "Epoch 10, Step: 69, Loss: 0.6059792637825012, Lr:0.0001\n",
      "Epoch 10, Step: 70, Loss: 0.46533405780792236, Lr:0.0001\n",
      "Epoch 10, Step: 71, Loss: 0.5215909481048584, Lr:0.0001\n",
      "Epoch 10, Step: 72, Loss: 0.6009056568145752, Lr:0.0001\n",
      "Epoch 10, Step: 73, Loss: 2.146275043487549, Lr:0.0001\n",
      "Epoch 10, Step: 74, Loss: 2.924464464187622, Lr:0.0001\n",
      "Epoch 10, Step: 75, Loss: 0.34095966815948486, Lr:0.0001\n",
      "Epoch 10, Step: 76, Loss: 0.5699962377548218, Lr:0.0001\n",
      "Epoch 10, Step: 77, Loss: 2.350198984146118, Lr:0.0001\n",
      "Epoch 10, Step: 78, Loss: 0.6702944040298462, Lr:0.0001\n",
      "Epoch 10, Step: 79, Loss: 0.41820746660232544, Lr:0.0001\n",
      "Epoch 10, Step: 80, Loss: 0.4296879172325134, Lr:0.0001\n",
      "Epoch 10, Step: 81, Loss: 0.22715452313423157, Lr:0.0001\n",
      "Epoch 10, Step: 82, Loss: 0.4066636860370636, Lr:0.0001\n",
      "Epoch 10, Step: 83, Loss: 0.6922466158866882, Lr:0.0001\n",
      "Epoch 10, Step: 84, Loss: 0.5823554396629333, Lr:0.0001\n",
      "Epoch 10, Step: 85, Loss: 0.5671982169151306, Lr:0.0001\n",
      "Epoch 10, Step: 86, Loss: 0.5671205520629883, Lr:0.0001\n",
      "Epoch 10, Step: 87, Loss: 0.5906160473823547, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 10\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.3209 (0.3209) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0110 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.3209 (0.6916) acc1: 75.0000 (81.8182) acc5: 100.0000 (100.0000) time: 0.0089 data: 0.0037 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0091 s / it)\n",
      "* Acc@1 81.818 Acc@5 100.000 loss 0.692\n",
      "Accuracy of the network on the 22 test image: 81.8%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 11, Step: 0, Loss: 0.15199297666549683, Lr:0.0001\n",
      "Epoch 11, Step: 1, Loss: 0.13522756099700928, Lr:0.0001\n",
      "Epoch 11, Step: 2, Loss: 0.21079832315444946, Lr:0.0001\n",
      "Epoch 11, Step: 3, Loss: 0.5806103348731995, Lr:0.0001\n",
      "Epoch 11, Step: 4, Loss: 0.0757218450307846, Lr:0.0001\n",
      "Epoch 11, Step: 5, Loss: 0.5486958622932434, Lr:0.0001\n",
      "Epoch 11, Step: 6, Loss: 0.3175949454307556, Lr:0.0001\n",
      "Epoch 11, Step: 7, Loss: 1.0013638734817505, Lr:0.0001\n",
      "Epoch 11, Step: 8, Loss: 0.33477848768234253, Lr:0.0001\n",
      "Epoch 11, Step: 9, Loss: 1.6948292255401611, Lr:0.0001\n",
      "Epoch 11, Step: 10, Loss: 1.0674906969070435, Lr:0.0001\n",
      "Epoch 11, Step: 11, Loss: 0.44205978512763977, Lr:0.0001\n",
      "Epoch 11, Step: 12, Loss: 0.5065644383430481, Lr:0.0001\n",
      "Epoch 11, Step: 13, Loss: 0.15811480581760406, Lr:0.0001\n",
      "Epoch 11, Step: 14, Loss: 0.9593032598495483, Lr:0.0001\n",
      "Epoch 11, Step: 15, Loss: 0.415182501077652, Lr:0.0001\n",
      "Epoch 11, Step: 16, Loss: 0.5106586813926697, Lr:0.0001\n",
      "Epoch 11, Step: 17, Loss: 0.36830317974090576, Lr:0.0001\n",
      "Epoch 11, Step: 18, Loss: 1.4671902656555176, Lr:0.0001\n",
      "Epoch 11, Step: 19, Loss: 0.84909987449646, Lr:0.0001\n",
      "Epoch 11, Step: 20, Loss: 0.4447433650493622, Lr:0.0001\n",
      "Epoch 11, Step: 21, Loss: 0.7907370328903198, Lr:0.0001\n",
      "Epoch 11, Step: 22, Loss: 1.2447049617767334, Lr:0.0001\n",
      "Epoch 11, Step: 23, Loss: 0.04976891353726387, Lr:0.0001\n",
      "Epoch 11, Step: 24, Loss: 0.43898579478263855, Lr:0.0001\n",
      "Epoch 11, Step: 25, Loss: 0.09070038795471191, Lr:0.0001\n",
      "Epoch 11, Step: 26, Loss: 0.4091021716594696, Lr:0.0001\n",
      "Epoch 11, Step: 27, Loss: 0.13623514771461487, Lr:0.0001\n",
      "Epoch 11, Step: 28, Loss: 0.5158930420875549, Lr:0.0001\n",
      "Epoch 11, Step: 29, Loss: 0.6649451851844788, Lr:0.0001\n",
      "Epoch 11, Step: 30, Loss: 0.11988791823387146, Lr:0.0001\n",
      "Epoch 11, Step: 31, Loss: 2.7040905952453613, Lr:0.0001\n",
      "Epoch 11, Step: 32, Loss: 0.09559416770935059, Lr:0.0001\n",
      "Epoch 11, Step: 33, Loss: 1.1166900396347046, Lr:0.0001\n",
      "Epoch 11, Step: 34, Loss: 0.7050268054008484, Lr:0.0001\n",
      "Epoch 11, Step: 35, Loss: 2.51788330078125, Lr:0.0001\n",
      "Epoch 11, Step: 36, Loss: 0.6850422024726868, Lr:0.0001\n",
      "Epoch 11, Step: 37, Loss: 1.03616201877594, Lr:0.0001\n",
      "Epoch 11, Step: 38, Loss: 1.2607038021087646, Lr:0.0001\n",
      "Epoch 11, Step: 39, Loss: 0.3824656009674072, Lr:0.0001\n",
      "Epoch 11, Step: 40, Loss: 0.23716513812541962, Lr:0.0001\n",
      "Epoch 11, Step: 41, Loss: 0.6686002016067505, Lr:0.0001\n",
      "Epoch 11, Step: 42, Loss: 0.4350321292877197, Lr:0.0001\n",
      "Epoch 11, Step: 43, Loss: 0.6088155508041382, Lr:0.0001\n",
      "Epoch 11, Step: 44, Loss: 0.2661033570766449, Lr:0.0001\n",
      "Epoch 11, Step: 45, Loss: 1.0381817817687988, Lr:0.0001\n",
      "Epoch 11, Step: 46, Loss: 0.7546094655990601, Lr:0.0001\n",
      "Epoch 11, Step: 47, Loss: 0.8635804057121277, Lr:0.0001\n",
      "Epoch 11, Step: 48, Loss: 0.24894395470619202, Lr:0.0001\n",
      "Epoch 11, Step: 49, Loss: 1.0797441005706787, Lr:0.0001\n",
      "Epoch 11, Step: 50, Loss: 0.954829752445221, Lr:0.0001\n",
      "Epoch 11, Step: 51, Loss: 1.0784350633621216, Lr:0.0001\n",
      "Epoch 11, Step: 52, Loss: 0.8034197092056274, Lr:0.0001\n",
      "Epoch 11, Step: 53, Loss: 0.5960775017738342, Lr:0.0001\n",
      "Epoch 11, Step: 54, Loss: 1.4570338726043701, Lr:0.0001\n",
      "Epoch 11, Step: 55, Loss: 0.6281901597976685, Lr:0.0001\n",
      "Epoch 11, Step: 56, Loss: 0.7074307203292847, Lr:0.0001\n",
      "Epoch 11, Step: 57, Loss: 0.37447622418403625, Lr:0.0001\n",
      "Epoch 11, Step: 58, Loss: 0.3556939959526062, Lr:0.0001\n",
      "Epoch 11, Step: 59, Loss: 0.8037998676300049, Lr:0.0001\n",
      "Epoch 11, Step: 60, Loss: 1.1245461702346802, Lr:0.0001\n",
      "Epoch 11, Step: 61, Loss: 0.26562273502349854, Lr:0.0001\n",
      "Epoch 11, Step: 62, Loss: 0.8990646004676819, Lr:0.0001\n",
      "Epoch 11, Step: 63, Loss: 0.7995710372924805, Lr:0.0001\n",
      "Epoch 11, Step: 64, Loss: 0.4111369252204895, Lr:0.0001\n",
      "Epoch 11, Step: 65, Loss: 0.07511898875236511, Lr:0.0001\n",
      "Epoch 11, Step: 66, Loss: 0.5759137868881226, Lr:0.0001\n",
      "Epoch 11, Step: 67, Loss: 1.1586329936981201, Lr:0.0001\n",
      "Epoch 11, Step: 68, Loss: 0.21922361850738525, Lr:0.0001\n",
      "Epoch 11, Step: 69, Loss: 0.7041804194450378, Lr:0.0001\n",
      "Epoch 11, Step: 70, Loss: 0.8595348596572876, Lr:0.0001\n",
      "Epoch 11, Step: 71, Loss: 0.22398696839809418, Lr:0.0001\n",
      "Epoch 11, Step: 72, Loss: 1.026595950126648, Lr:0.0001\n",
      "Epoch 11, Step: 73, Loss: 0.5869655609130859, Lr:0.0001\n",
      "Epoch 11, Step: 74, Loss: 0.34765106439590454, Lr:0.0001\n",
      "Epoch 11, Step: 75, Loss: 0.2567797303199768, Lr:0.0001\n",
      "Epoch 11, Step: 76, Loss: 0.864437997341156, Lr:0.0001\n",
      "Epoch 11, Step: 77, Loss: 0.3575937747955322, Lr:0.0001\n",
      "Epoch 11, Step: 78, Loss: 0.9336377382278442, Lr:0.0001\n",
      "Epoch 11, Step: 79, Loss: 0.0719192698597908, Lr:0.0001\n",
      "Epoch 11, Step: 80, Loss: 0.3912575840950012, Lr:0.0001\n",
      "Epoch 11, Step: 81, Loss: 0.5494163036346436, Lr:0.0001\n",
      "Epoch 11, Step: 82, Loss: 1.3136957883834839, Lr:0.0001\n",
      "Epoch 11, Step: 83, Loss: 0.5035785436630249, Lr:0.0001\n",
      "Epoch 11, Step: 84, Loss: 1.1475813388824463, Lr:0.0001\n",
      "Epoch 11, Step: 85, Loss: 0.8090779781341553, Lr:0.0001\n",
      "Epoch 11, Step: 86, Loss: 0.63004469871521, Lr:0.0001\n",
      "Epoch 11, Step: 87, Loss: 0.4220069646835327, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 11\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.4664 (0.4664) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.3393 (0.5610) acc1: 75.0000 (77.2727) acc5: 100.0000 (100.0000) time: 0.0065 data: 0.0035 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0067 s / it)\n",
      "* Acc@1 77.273 Acc@5 100.000 loss 0.561\n",
      "Accuracy of the network on the 22 test image: 77.3%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 12, Step: 0, Loss: 0.038977667689323425, Lr:0.0001\n",
      "Epoch 12, Step: 1, Loss: 0.06784072518348694, Lr:0.0001\n",
      "Epoch 12, Step: 2, Loss: 0.1285608559846878, Lr:0.0001\n",
      "Epoch 12, Step: 3, Loss: 2.032397747039795, Lr:0.0001\n",
      "Epoch 12, Step: 4, Loss: 0.40338701009750366, Lr:0.0001\n",
      "Epoch 12, Step: 5, Loss: 1.130088210105896, Lr:0.0001\n",
      "Epoch 12, Step: 6, Loss: 1.0786103010177612, Lr:0.0001\n",
      "Epoch 12, Step: 7, Loss: 0.7244738340377808, Lr:0.0001\n",
      "Epoch 12, Step: 8, Loss: 0.1011802926659584, Lr:0.0001\n",
      "Epoch 12, Step: 9, Loss: 1.1280426979064941, Lr:0.0001\n",
      "Epoch 12, Step: 10, Loss: 0.4365823268890381, Lr:0.0001\n",
      "Epoch 12, Step: 11, Loss: 0.6836156249046326, Lr:0.0001\n",
      "Epoch 12, Step: 12, Loss: 0.5222132205963135, Lr:0.0001\n",
      "Epoch 12, Step: 13, Loss: 0.6801799535751343, Lr:0.0001\n",
      "Epoch 12, Step: 14, Loss: 0.07492129504680634, Lr:0.0001\n",
      "Epoch 12, Step: 15, Loss: 0.09361764043569565, Lr:0.0001\n",
      "Epoch 12, Step: 16, Loss: 0.36609187722206116, Lr:0.0001\n",
      "Epoch 12, Step: 17, Loss: 1.8274699449539185, Lr:0.0001\n",
      "Epoch 12, Step: 18, Loss: 1.8140884637832642, Lr:0.0001\n",
      "Epoch 12, Step: 19, Loss: 0.0804625153541565, Lr:0.0001\n",
      "Epoch 12, Step: 20, Loss: 0.1821034550666809, Lr:0.0001\n",
      "Epoch 12, Step: 21, Loss: 0.30197444558143616, Lr:0.0001\n",
      "Epoch 12, Step: 22, Loss: 0.9302610158920288, Lr:0.0001\n",
      "Epoch 12, Step: 23, Loss: 0.995511531829834, Lr:0.0001\n",
      "Epoch 12, Step: 24, Loss: 0.20289580523967743, Lr:0.0001\n",
      "Epoch 12, Step: 25, Loss: 0.20202133059501648, Lr:0.0001\n",
      "Epoch 12, Step: 26, Loss: 0.8420878648757935, Lr:0.0001\n",
      "Epoch 12, Step: 27, Loss: 0.9757956266403198, Lr:0.0001\n",
      "Epoch 12, Step: 28, Loss: 0.5829392671585083, Lr:0.0001\n",
      "Epoch 12, Step: 29, Loss: 1.7693610191345215, Lr:0.0001\n",
      "Epoch 12, Step: 30, Loss: 0.19778871536254883, Lr:0.0001\n",
      "Epoch 12, Step: 31, Loss: 0.4899280071258545, Lr:0.0001\n",
      "Epoch 12, Step: 32, Loss: 0.936284065246582, Lr:0.0001\n",
      "Epoch 12, Step: 33, Loss: 0.07190004736185074, Lr:0.0001\n",
      "Epoch 12, Step: 34, Loss: 0.46907031536102295, Lr:0.0001\n",
      "Epoch 12, Step: 35, Loss: 0.7870506644248962, Lr:0.0001\n",
      "Epoch 12, Step: 36, Loss: 0.18376967310905457, Lr:0.0001\n",
      "Epoch 12, Step: 37, Loss: 0.6182902455329895, Lr:0.0001\n",
      "Epoch 12, Step: 38, Loss: 0.20565688610076904, Lr:0.0001\n",
      "Epoch 12, Step: 39, Loss: 1.125948429107666, Lr:0.0001\n",
      "Epoch 12, Step: 40, Loss: 0.23554621636867523, Lr:0.0001\n",
      "Epoch 12, Step: 41, Loss: 0.4108714759349823, Lr:0.0001\n",
      "Epoch 12, Step: 42, Loss: 0.24861958622932434, Lr:0.0001\n",
      "Epoch 12, Step: 43, Loss: 0.7767127752304077, Lr:0.0001\n",
      "Epoch 12, Step: 44, Loss: 0.6467493176460266, Lr:0.0001\n",
      "Epoch 12, Step: 45, Loss: 0.1137581616640091, Lr:0.0001\n",
      "Epoch 12, Step: 46, Loss: 1.1775084733963013, Lr:0.0001\n",
      "Epoch 12, Step: 47, Loss: 0.09526925534009933, Lr:0.0001\n",
      "Epoch 12, Step: 48, Loss: 0.4101697504520416, Lr:0.0001\n",
      "Epoch 12, Step: 49, Loss: 0.5902795195579529, Lr:0.0001\n",
      "Epoch 12, Step: 50, Loss: 1.4593369960784912, Lr:0.0001\n",
      "Epoch 12, Step: 51, Loss: 0.6307903528213501, Lr:0.0001\n",
      "Epoch 12, Step: 52, Loss: 0.7839375734329224, Lr:0.0001\n",
      "Epoch 12, Step: 53, Loss: 0.5969512462615967, Lr:0.0001\n",
      "Epoch 12, Step: 54, Loss: 0.4456159174442291, Lr:0.0001\n",
      "Epoch 12, Step: 55, Loss: 0.43996211886405945, Lr:0.0001\n",
      "Epoch 12, Step: 56, Loss: 0.7658957839012146, Lr:0.0001\n",
      "Epoch 12, Step: 57, Loss: 0.4043201208114624, Lr:0.0001\n",
      "Epoch 12, Step: 58, Loss: 0.7281292676925659, Lr:0.0001\n",
      "Epoch 12, Step: 59, Loss: 0.6334059834480286, Lr:0.0001\n",
      "Epoch 12, Step: 60, Loss: 0.2478300929069519, Lr:0.0001\n",
      "Epoch 12, Step: 61, Loss: 0.7993125915527344, Lr:0.0001\n",
      "Epoch 12, Step: 62, Loss: 0.78795325756073, Lr:0.0001\n",
      "Epoch 12, Step: 63, Loss: 1.5773025751113892, Lr:0.0001\n",
      "Epoch 12, Step: 64, Loss: 0.16987338662147522, Lr:0.0001\n",
      "Epoch 12, Step: 65, Loss: 0.6099072694778442, Lr:0.0001\n",
      "Epoch 12, Step: 66, Loss: 0.36567366123199463, Lr:0.0001\n",
      "Epoch 12, Step: 67, Loss: 0.22962065041065216, Lr:0.0001\n",
      "Epoch 12, Step: 68, Loss: 0.6474590301513672, Lr:0.0001\n",
      "Epoch 12, Step: 69, Loss: 0.3422453999519348, Lr:0.0001\n",
      "Epoch 12, Step: 70, Loss: 0.23527568578720093, Lr:0.0001\n",
      "Epoch 12, Step: 71, Loss: 0.569209098815918, Lr:0.0001\n",
      "Epoch 12, Step: 72, Loss: 0.16523367166519165, Lr:0.0001\n",
      "Epoch 12, Step: 73, Loss: 0.859848141670227, Lr:0.0001\n",
      "Epoch 12, Step: 74, Loss: 1.3102970123291016, Lr:0.0001\n",
      "Epoch 12, Step: 75, Loss: 0.6562151312828064, Lr:0.0001\n",
      "Epoch 12, Step: 76, Loss: 0.3918488025665283, Lr:0.0001\n",
      "Epoch 12, Step: 77, Loss: 3.059955358505249, Lr:0.0001\n",
      "Epoch 12, Step: 78, Loss: 0.7849416732788086, Lr:0.0001\n",
      "Epoch 12, Step: 79, Loss: 0.1797913759946823, Lr:0.0001\n",
      "Epoch 12, Step: 80, Loss: 0.5275710225105286, Lr:0.0001\n",
      "Epoch 12, Step: 81, Loss: 2.364755153656006, Lr:0.0001\n",
      "Epoch 12, Step: 82, Loss: 0.8545324206352234, Lr:0.0001\n",
      "Epoch 12, Step: 83, Loss: 0.39353275299072266, Lr:0.0001\n",
      "Epoch 12, Step: 84, Loss: 1.219300389289856, Lr:0.0001\n",
      "Epoch 12, Step: 85, Loss: 0.6932689547538757, Lr:0.0001\n",
      "Epoch 12, Step: 86, Loss: 0.3842828869819641, Lr:0.0001\n",
      "Epoch 12, Step: 87, Loss: 0.2325710952281952, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 12\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.2437 (0.2437) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.2371 (0.5555) acc1: 100.0000 (81.8182) acc5: 100.0000 (100.0000) time: 0.0070 data: 0.0037 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0072 s / it)\n",
      "* Acc@1 81.818 Acc@5 100.000 loss 0.556\n",
      "Accuracy of the network on the 22 test image: 81.8%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 13, Step: 0, Loss: 0.07478571683168411, Lr:0.0001\n",
      "Epoch 13, Step: 1, Loss: 2.608412265777588, Lr:0.0001\n",
      "Epoch 13, Step: 2, Loss: 0.4233410358428955, Lr:0.0001\n",
      "Epoch 13, Step: 3, Loss: 0.43733298778533936, Lr:0.0001\n",
      "Epoch 13, Step: 4, Loss: 0.4846979081630707, Lr:0.0001\n",
      "Epoch 13, Step: 5, Loss: 0.5040260553359985, Lr:0.0001\n",
      "Epoch 13, Step: 6, Loss: 1.2288964986801147, Lr:0.0001\n",
      "Epoch 13, Step: 7, Loss: 0.3861919045448303, Lr:0.0001\n",
      "Epoch 13, Step: 8, Loss: 0.15887859463691711, Lr:0.0001\n",
      "Epoch 13, Step: 9, Loss: 1.4583133459091187, Lr:0.0001\n",
      "Epoch 13, Step: 10, Loss: 0.10818446427583694, Lr:0.0001\n",
      "Epoch 13, Step: 11, Loss: 0.6175925135612488, Lr:0.0001\n",
      "Epoch 13, Step: 12, Loss: 1.1822969913482666, Lr:0.0001\n",
      "Epoch 13, Step: 13, Loss: 0.04762914776802063, Lr:0.0001\n",
      "Epoch 13, Step: 14, Loss: 0.3735746741294861, Lr:0.0001\n",
      "Epoch 13, Step: 15, Loss: 0.07893181592226028, Lr:0.0001\n",
      "Epoch 13, Step: 16, Loss: 0.4115162491798401, Lr:0.0001\n",
      "Epoch 13, Step: 17, Loss: 0.560149610042572, Lr:0.0001\n",
      "Epoch 13, Step: 18, Loss: 0.7164492011070251, Lr:0.0001\n",
      "Epoch 13, Step: 19, Loss: 0.8353253602981567, Lr:0.0001\n",
      "Epoch 13, Step: 20, Loss: 0.5041065812110901, Lr:0.0001\n",
      "Epoch 13, Step: 21, Loss: 0.47626635432243347, Lr:0.0001\n",
      "Epoch 13, Step: 22, Loss: 0.3364590108394623, Lr:0.0001\n",
      "Epoch 13, Step: 23, Loss: 0.5208866000175476, Lr:0.0001\n",
      "Epoch 13, Step: 24, Loss: 0.43098312616348267, Lr:0.0001\n",
      "Epoch 13, Step: 25, Loss: 2.8147945404052734, Lr:0.0001\n",
      "Epoch 13, Step: 26, Loss: 0.4941510856151581, Lr:0.0001\n",
      "Epoch 13, Step: 27, Loss: 0.5425311923027039, Lr:0.0001\n",
      "Epoch 13, Step: 28, Loss: 1.1017694473266602, Lr:0.0001\n",
      "Epoch 13, Step: 29, Loss: 0.1606254130601883, Lr:0.0001\n",
      "Epoch 13, Step: 30, Loss: 2.171858072280884, Lr:0.0001\n",
      "Epoch 13, Step: 31, Loss: 0.24505206942558289, Lr:0.0001\n",
      "Epoch 13, Step: 32, Loss: 0.4746837019920349, Lr:0.0001\n",
      "Epoch 13, Step: 33, Loss: 0.0946672111749649, Lr:0.0001\n",
      "Epoch 13, Step: 34, Loss: 0.42609429359436035, Lr:0.0001\n",
      "Epoch 13, Step: 35, Loss: 0.1411329060792923, Lr:0.0001\n",
      "Epoch 13, Step: 36, Loss: 0.5446248650550842, Lr:0.0001\n",
      "Epoch 13, Step: 37, Loss: 0.7481887340545654, Lr:0.0001\n",
      "Epoch 13, Step: 38, Loss: 0.4512169659137726, Lr:0.0001\n",
      "Epoch 13, Step: 39, Loss: 0.9702078104019165, Lr:0.0001\n",
      "Epoch 13, Step: 40, Loss: 1.8353917598724365, Lr:0.0001\n",
      "Epoch 13, Step: 41, Loss: 0.9536675214767456, Lr:0.0001\n",
      "Epoch 13, Step: 42, Loss: 0.447516530752182, Lr:0.0001\n",
      "Epoch 13, Step: 43, Loss: 0.8028513193130493, Lr:0.0001\n",
      "Epoch 13, Step: 44, Loss: 0.050599366426467896, Lr:0.0001\n",
      "Epoch 13, Step: 45, Loss: 0.3775213658809662, Lr:0.0001\n",
      "Epoch 13, Step: 46, Loss: 0.7252964377403259, Lr:0.0001\n",
      "Epoch 13, Step: 47, Loss: 0.1436000019311905, Lr:0.0001\n",
      "Epoch 13, Step: 48, Loss: 0.41390466690063477, Lr:0.0001\n",
      "Epoch 13, Step: 49, Loss: 0.5204950571060181, Lr:0.0001\n",
      "Epoch 13, Step: 50, Loss: 0.6124768853187561, Lr:0.0001\n",
      "Epoch 13, Step: 51, Loss: 0.6848233938217163, Lr:0.0001\n",
      "Epoch 13, Step: 52, Loss: 0.8815159797668457, Lr:0.0001\n",
      "Epoch 13, Step: 53, Loss: 0.5706976056098938, Lr:0.0001\n",
      "Epoch 13, Step: 54, Loss: 1.9533803462982178, Lr:0.0001\n",
      "Epoch 13, Step: 55, Loss: 0.16256175935268402, Lr:0.0001\n",
      "Epoch 13, Step: 56, Loss: 0.06150896102190018, Lr:0.0001\n",
      "Epoch 13, Step: 57, Loss: 0.48700082302093506, Lr:0.0001\n",
      "Epoch 13, Step: 58, Loss: 0.10833524912595749, Lr:0.0001\n",
      "Epoch 13, Step: 59, Loss: 0.68314528465271, Lr:0.0001\n",
      "Epoch 13, Step: 60, Loss: 0.48332324624061584, Lr:0.0001\n",
      "Epoch 13, Step: 61, Loss: 0.4730986952781677, Lr:0.0001\n",
      "Epoch 13, Step: 62, Loss: 0.5873502492904663, Lr:0.0001\n",
      "Epoch 13, Step: 63, Loss: 0.5770174264907837, Lr:0.0001\n",
      "Epoch 13, Step: 64, Loss: 0.8872761726379395, Lr:0.0001\n",
      "Epoch 13, Step: 65, Loss: 0.054611578583717346, Lr:0.0001\n",
      "Epoch 13, Step: 66, Loss: 0.05121733248233795, Lr:0.0001\n",
      "Epoch 13, Step: 67, Loss: 0.03283260762691498, Lr:0.0001\n",
      "Epoch 13, Step: 68, Loss: 0.8030233979225159, Lr:0.0001\n",
      "Epoch 13, Step: 69, Loss: 0.38300958275794983, Lr:0.0001\n",
      "Epoch 13, Step: 70, Loss: 0.5443657636642456, Lr:0.0001\n",
      "Epoch 13, Step: 71, Loss: 0.9369252920150757, Lr:0.0001\n",
      "Epoch 13, Step: 72, Loss: 0.044526632875204086, Lr:0.0001\n",
      "Epoch 13, Step: 73, Loss: 1.0384958982467651, Lr:0.0001\n",
      "Epoch 13, Step: 74, Loss: 0.7376741766929626, Lr:0.0001\n",
      "Epoch 13, Step: 75, Loss: 0.10485079884529114, Lr:0.0001\n",
      "Epoch 13, Step: 76, Loss: 1.9344627857208252, Lr:0.0001\n",
      "Epoch 13, Step: 77, Loss: 1.1023751497268677, Lr:0.0001\n",
      "Epoch 13, Step: 78, Loss: 1.1262385845184326, Lr:0.0001\n",
      "Epoch 13, Step: 79, Loss: 1.0217989683151245, Lr:0.0001\n",
      "Epoch 13, Step: 80, Loss: 0.4054418206214905, Lr:0.0001\n",
      "Epoch 13, Step: 81, Loss: 0.3539150655269623, Lr:0.0001\n",
      "Epoch 13, Step: 82, Loss: 2.175550937652588, Lr:0.0001\n",
      "Epoch 13, Step: 83, Loss: 1.42763352394104, Lr:0.0001\n",
      "Epoch 13, Step: 84, Loss: 0.5352756977081299, Lr:0.0001\n",
      "Epoch 13, Step: 85, Loss: 0.4955153465270996, Lr:0.0001\n",
      "Epoch 13, Step: 86, Loss: 0.5196318030357361, Lr:0.0001\n",
      "Epoch 13, Step: 87, Loss: 1.091517686843872, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 13\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.2406 (0.2406) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.2406 (0.5004) acc1: 75.0000 (77.2727) acc5: 100.0000 (100.0000) time: 0.0076 data: 0.0038 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0079 s / it)\n",
      "* Acc@1 77.273 Acc@5 100.000 loss 0.500\n",
      "Accuracy of the network on the 22 test image: 77.3%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 14, Step: 0, Loss: 0.44136813282966614, Lr:0.0001\n",
      "Epoch 14, Step: 1, Loss: 0.48859065771102905, Lr:0.0001\n",
      "Epoch 14, Step: 2, Loss: 0.8886549472808838, Lr:0.0001\n",
      "Epoch 14, Step: 3, Loss: 0.4299519658088684, Lr:0.0001\n",
      "Epoch 14, Step: 4, Loss: 0.12762266397476196, Lr:0.0001\n",
      "Epoch 14, Step: 5, Loss: 0.35423246026039124, Lr:0.0001\n",
      "Epoch 14, Step: 6, Loss: 0.5711431503295898, Lr:0.0001\n",
      "Epoch 14, Step: 7, Loss: 1.162156581878662, Lr:0.0001\n",
      "Epoch 14, Step: 8, Loss: 0.5952451229095459, Lr:0.0001\n",
      "Epoch 14, Step: 9, Loss: 0.3885165750980377, Lr:0.0001\n",
      "Epoch 14, Step: 10, Loss: 0.7447738647460938, Lr:0.0001\n",
      "Epoch 14, Step: 11, Loss: 0.2293669581413269, Lr:0.0001\n",
      "Epoch 14, Step: 12, Loss: 0.22669589519500732, Lr:0.0001\n",
      "Epoch 14, Step: 13, Loss: 0.6714416742324829, Lr:0.0001\n",
      "Epoch 14, Step: 14, Loss: 0.16637754440307617, Lr:0.0001\n",
      "Epoch 14, Step: 15, Loss: 1.1177555322647095, Lr:0.0001\n",
      "Epoch 14, Step: 16, Loss: 0.7487375736236572, Lr:0.0001\n",
      "Epoch 14, Step: 17, Loss: 0.1884590983390808, Lr:0.0001\n",
      "Epoch 14, Step: 18, Loss: 0.4478664696216583, Lr:0.0001\n",
      "Epoch 14, Step: 19, Loss: 0.22790253162384033, Lr:0.0001\n",
      "Epoch 14, Step: 20, Loss: 2.7569825649261475, Lr:0.0001\n",
      "Epoch 14, Step: 21, Loss: 0.4947665333747864, Lr:0.0001\n",
      "Epoch 14, Step: 22, Loss: 0.4715625047683716, Lr:0.0001\n",
      "Epoch 14, Step: 23, Loss: 1.4894380569458008, Lr:0.0001\n",
      "Epoch 14, Step: 24, Loss: 0.27752432227134705, Lr:0.0001\n",
      "Epoch 14, Step: 25, Loss: 0.3213357925415039, Lr:0.0001\n",
      "Epoch 14, Step: 26, Loss: 0.4947429299354553, Lr:0.0001\n",
      "Epoch 14, Step: 27, Loss: 0.58250892162323, Lr:0.0001\n",
      "Epoch 14, Step: 28, Loss: 0.4936843514442444, Lr:0.0001\n",
      "Epoch 14, Step: 29, Loss: 0.9005305767059326, Lr:0.0001\n",
      "Epoch 14, Step: 30, Loss: 0.7112962007522583, Lr:0.0001\n",
      "Epoch 14, Step: 31, Loss: 0.38288614153862, Lr:0.0001\n",
      "Epoch 14, Step: 32, Loss: 0.42641326785087585, Lr:0.0001\n",
      "Epoch 14, Step: 33, Loss: 0.8705711960792542, Lr:0.0001\n",
      "Epoch 14, Step: 34, Loss: 0.047739043831825256, Lr:0.0001\n",
      "Epoch 14, Step: 35, Loss: 0.12439389526844025, Lr:0.0001\n",
      "Epoch 14, Step: 36, Loss: 0.12098575383424759, Lr:0.0001\n",
      "Epoch 14, Step: 37, Loss: 0.18832695484161377, Lr:0.0001\n",
      "Epoch 14, Step: 38, Loss: 0.6337810158729553, Lr:0.0001\n",
      "Epoch 14, Step: 39, Loss: 1.4130349159240723, Lr:0.0001\n",
      "Epoch 14, Step: 40, Loss: 0.4953773617744446, Lr:0.0001\n",
      "Epoch 14, Step: 41, Loss: 0.11400949209928513, Lr:0.0001\n",
      "Epoch 14, Step: 42, Loss: 1.2068541049957275, Lr:0.0001\n",
      "Epoch 14, Step: 43, Loss: 0.08222915232181549, Lr:0.0001\n",
      "Epoch 14, Step: 44, Loss: 0.8232669830322266, Lr:0.0001\n",
      "Epoch 14, Step: 45, Loss: 0.08574629575014114, Lr:0.0001\n",
      "Epoch 14, Step: 46, Loss: 0.4269255995750427, Lr:0.0001\n",
      "Epoch 14, Step: 47, Loss: 0.9036809206008911, Lr:0.0001\n",
      "Epoch 14, Step: 48, Loss: 1.5132694244384766, Lr:0.0001\n",
      "Epoch 14, Step: 49, Loss: 0.2614434063434601, Lr:0.0001\n",
      "Epoch 14, Step: 50, Loss: 0.3466309607028961, Lr:0.0001\n",
      "Epoch 14, Step: 51, Loss: 0.42832159996032715, Lr:0.0001\n",
      "Epoch 14, Step: 52, Loss: 0.047178804874420166, Lr:0.0001\n",
      "Epoch 14, Step: 53, Loss: 0.2915148138999939, Lr:0.0001\n",
      "Epoch 14, Step: 54, Loss: 1.6235483884811401, Lr:0.0001\n",
      "Epoch 14, Step: 55, Loss: 0.8437916040420532, Lr:0.0001\n",
      "Epoch 14, Step: 56, Loss: 3.0859603881835938, Lr:0.0001\n",
      "Epoch 14, Step: 57, Loss: 0.5753944516181946, Lr:0.0001\n",
      "Epoch 14, Step: 58, Loss: 1.4359263181686401, Lr:0.0001\n",
      "Epoch 14, Step: 59, Loss: 0.29343655705451965, Lr:0.0001\n",
      "Epoch 14, Step: 60, Loss: 4.2996296882629395, Lr:0.0001\n",
      "Epoch 14, Step: 61, Loss: 0.6633701324462891, Lr:0.0001\n",
      "Epoch 14, Step: 62, Loss: 0.9763619899749756, Lr:0.0001\n",
      "Epoch 14, Step: 63, Loss: 0.8706507682800293, Lr:0.0001\n",
      "Epoch 14, Step: 64, Loss: 0.792228639125824, Lr:0.0001\n",
      "Epoch 14, Step: 65, Loss: 0.08431917428970337, Lr:0.0001\n",
      "Epoch 14, Step: 66, Loss: 0.15916192531585693, Lr:0.0001\n",
      "Epoch 14, Step: 67, Loss: 0.06426659971475601, Lr:0.0001\n",
      "Epoch 14, Step: 68, Loss: 2.0236101150512695, Lr:0.0001\n",
      "Epoch 14, Step: 69, Loss: 0.36453837156295776, Lr:0.0001\n",
      "Epoch 14, Step: 70, Loss: 0.7071816325187683, Lr:0.0001\n",
      "Epoch 14, Step: 71, Loss: 0.2228480726480484, Lr:0.0001\n",
      "Epoch 14, Step: 72, Loss: 0.3652054965496063, Lr:0.0001\n",
      "Epoch 14, Step: 73, Loss: 0.5094558000564575, Lr:0.0001\n",
      "Epoch 14, Step: 74, Loss: 0.2626757025718689, Lr:0.0001\n",
      "Epoch 14, Step: 75, Loss: 0.6183308959007263, Lr:0.0001\n",
      "Epoch 14, Step: 76, Loss: 0.07247405499219894, Lr:0.0001\n",
      "Epoch 14, Step: 77, Loss: 0.320398211479187, Lr:0.0001\n",
      "Epoch 14, Step: 78, Loss: 2.443814277648926, Lr:0.0001\n",
      "Epoch 14, Step: 79, Loss: 0.5854251980781555, Lr:0.0001\n",
      "Epoch 14, Step: 80, Loss: 0.4200935661792755, Lr:0.0001\n",
      "Epoch 14, Step: 81, Loss: 2.128502607345581, Lr:0.0001\n",
      "Epoch 14, Step: 82, Loss: 0.16234339773654938, Lr:0.0001\n",
      "Epoch 14, Step: 83, Loss: 2.389486074447632, Lr:0.0001\n",
      "Epoch 14, Step: 84, Loss: 0.5562862157821655, Lr:0.0001\n",
      "Epoch 14, Step: 85, Loss: 0.4429927170276642, Lr:0.0001\n",
      "Epoch 14, Step: 86, Loss: 1.0636723041534424, Lr:0.0001\n",
      "Epoch 14, Step: 87, Loss: 0.5316962003707886, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 14\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.1923 (0.1923) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.1923 (0.5064) acc1: 100.0000 (86.3636) acc5: 100.0000 (100.0000) time: 0.0067 data: 0.0035 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0068 s / it)\n",
      "* Acc@1 86.364 Acc@5 100.000 loss 0.506\n",
      "Accuracy of the network on the 22 test image: 86.4%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 15, Step: 0, Loss: 1.2042690515518188, Lr:0.0001\n",
      "Epoch 15, Step: 1, Loss: 0.67181795835495, Lr:0.0001\n",
      "Epoch 15, Step: 2, Loss: 0.4260709583759308, Lr:0.0001\n",
      "Epoch 15, Step: 3, Loss: 0.30145177245140076, Lr:0.0001\n",
      "Epoch 15, Step: 4, Loss: 0.21096357703208923, Lr:0.0001\n",
      "Epoch 15, Step: 5, Loss: 0.6960079669952393, Lr:0.0001\n",
      "Epoch 15, Step: 6, Loss: 1.1055090427398682, Lr:0.0001\n",
      "Epoch 15, Step: 7, Loss: 1.437017560005188, Lr:0.0001\n",
      "Epoch 15, Step: 8, Loss: 0.47639375925064087, Lr:0.0001\n",
      "Epoch 15, Step: 9, Loss: 0.5347015261650085, Lr:0.0001\n",
      "Epoch 15, Step: 10, Loss: 0.7574717402458191, Lr:0.0001\n",
      "Epoch 15, Step: 11, Loss: 0.3551758825778961, Lr:0.0001\n",
      "Epoch 15, Step: 12, Loss: 0.8860863447189331, Lr:0.0001\n",
      "Epoch 15, Step: 13, Loss: 0.3873221278190613, Lr:0.0001\n",
      "Epoch 15, Step: 14, Loss: 0.22669827938079834, Lr:0.0001\n",
      "Epoch 15, Step: 15, Loss: 0.7303676009178162, Lr:0.0001\n",
      "Epoch 15, Step: 16, Loss: 0.271750807762146, Lr:0.0001\n",
      "Epoch 15, Step: 17, Loss: 0.6949329376220703, Lr:0.0001\n",
      "Epoch 15, Step: 18, Loss: 0.5368913412094116, Lr:0.0001\n",
      "Epoch 15, Step: 19, Loss: 0.4552224576473236, Lr:0.0001\n",
      "Epoch 15, Step: 20, Loss: 0.4204871356487274, Lr:0.0001\n",
      "Epoch 15, Step: 21, Loss: 0.30386561155319214, Lr:0.0001\n",
      "Epoch 15, Step: 22, Loss: 0.07609746605157852, Lr:0.0001\n",
      "Epoch 15, Step: 23, Loss: 1.2399721145629883, Lr:0.0001\n",
      "Epoch 15, Step: 24, Loss: 0.08939298987388611, Lr:0.0001\n",
      "Epoch 15, Step: 25, Loss: 0.5890038013458252, Lr:0.0001\n",
      "Epoch 15, Step: 26, Loss: 0.3157086968421936, Lr:0.0001\n",
      "Epoch 15, Step: 27, Loss: 0.04802706092596054, Lr:0.0001\n",
      "Epoch 15, Step: 28, Loss: 1.1424849033355713, Lr:0.0001\n",
      "Epoch 15, Step: 29, Loss: 0.28143447637557983, Lr:0.0001\n",
      "Epoch 15, Step: 30, Loss: 0.10738075524568558, Lr:0.0001\n",
      "Epoch 15, Step: 31, Loss: 2.7233526706695557, Lr:0.0001\n",
      "Epoch 15, Step: 32, Loss: 0.15476416051387787, Lr:0.0001\n",
      "Epoch 15, Step: 33, Loss: 0.4395405054092407, Lr:0.0001\n",
      "Epoch 15, Step: 34, Loss: 0.20258162915706635, Lr:0.0001\n",
      "Epoch 15, Step: 35, Loss: 0.19075444340705872, Lr:0.0001\n",
      "Epoch 15, Step: 36, Loss: 0.8405836820602417, Lr:0.0001\n",
      "Epoch 15, Step: 37, Loss: 0.7553228735923767, Lr:0.0001\n",
      "Epoch 15, Step: 38, Loss: 2.258552074432373, Lr:0.0001\n",
      "Epoch 15, Step: 39, Loss: 0.4066472351551056, Lr:0.0001\n",
      "Epoch 15, Step: 40, Loss: 0.2473970353603363, Lr:0.0001\n",
      "Epoch 15, Step: 41, Loss: 0.2163485288619995, Lr:0.0001\n",
      "Epoch 15, Step: 42, Loss: 0.27967846393585205, Lr:0.0001\n",
      "Epoch 15, Step: 43, Loss: 0.460249125957489, Lr:0.0001\n",
      "Epoch 15, Step: 44, Loss: 0.18549060821533203, Lr:0.0001\n",
      "Epoch 15, Step: 45, Loss: 0.969279408454895, Lr:0.0001\n",
      "Epoch 15, Step: 46, Loss: 0.8031591176986694, Lr:0.0001\n",
      "Epoch 15, Step: 47, Loss: 1.2652233839035034, Lr:0.0001\n",
      "Epoch 15, Step: 48, Loss: 0.4447653889656067, Lr:0.0001\n",
      "Epoch 15, Step: 49, Loss: 0.040377095341682434, Lr:0.0001\n",
      "Epoch 15, Step: 50, Loss: 3.1129724979400635, Lr:0.0001\n",
      "Epoch 15, Step: 51, Loss: 0.25365161895751953, Lr:0.0001\n",
      "Epoch 15, Step: 52, Loss: 0.23245292901992798, Lr:0.0001\n",
      "Epoch 15, Step: 53, Loss: 0.5682737827301025, Lr:0.0001\n",
      "Epoch 15, Step: 54, Loss: 0.8356250524520874, Lr:0.0001\n",
      "Epoch 15, Step: 55, Loss: 0.30264443159103394, Lr:0.0001\n",
      "Epoch 15, Step: 56, Loss: 0.26534950733184814, Lr:0.0001\n",
      "Epoch 15, Step: 57, Loss: 0.5442692041397095, Lr:0.0001\n",
      "Epoch 15, Step: 58, Loss: 0.10928533226251602, Lr:0.0001\n",
      "Epoch 15, Step: 59, Loss: 0.08999259024858475, Lr:0.0001\n",
      "Epoch 15, Step: 60, Loss: 1.4160290956497192, Lr:0.0001\n",
      "Epoch 15, Step: 61, Loss: 1.0971646308898926, Lr:0.0001\n",
      "Epoch 15, Step: 62, Loss: 0.4354265630245209, Lr:0.0001\n",
      "Epoch 15, Step: 63, Loss: 0.37752968072891235, Lr:0.0001\n",
      "Epoch 15, Step: 64, Loss: 1.191349744796753, Lr:0.0001\n",
      "Epoch 15, Step: 65, Loss: 0.7961582541465759, Lr:0.0001\n",
      "Epoch 15, Step: 66, Loss: 0.465450257062912, Lr:0.0001\n",
      "Epoch 15, Step: 67, Loss: 0.11083751171827316, Lr:0.0001\n",
      "Epoch 15, Step: 68, Loss: 0.042516760528087616, Lr:0.0001\n",
      "Epoch 15, Step: 69, Loss: 0.10673508048057556, Lr:0.0001\n",
      "Epoch 15, Step: 70, Loss: 0.05501954257488251, Lr:0.0001\n",
      "Epoch 15, Step: 71, Loss: 0.07296524196863174, Lr:0.0001\n",
      "Epoch 15, Step: 72, Loss: 0.4106028974056244, Lr:0.0001\n",
      "Epoch 15, Step: 73, Loss: 0.8258492946624756, Lr:0.0001\n",
      "Epoch 15, Step: 74, Loss: 0.39522355794906616, Lr:0.0001\n",
      "Epoch 15, Step: 75, Loss: 0.8315889239311218, Lr:0.0001\n",
      "Epoch 15, Step: 76, Loss: 0.7037506103515625, Lr:0.0001\n",
      "Epoch 15, Step: 77, Loss: 0.4672546982765198, Lr:0.0001\n",
      "Epoch 15, Step: 78, Loss: 0.38946613669395447, Lr:0.0001\n",
      "Epoch 15, Step: 79, Loss: 0.09571459144353867, Lr:0.0001\n",
      "Epoch 15, Step: 80, Loss: 0.7787846922874451, Lr:0.0001\n",
      "Epoch 15, Step: 81, Loss: 0.7341243624687195, Lr:0.0001\n",
      "Epoch 15, Step: 82, Loss: 0.7593280076980591, Lr:0.0001\n",
      "Epoch 15, Step: 83, Loss: 0.994434118270874, Lr:0.0001\n",
      "Epoch 15, Step: 84, Loss: 0.21305938065052032, Lr:0.0001\n",
      "Epoch 15, Step: 85, Loss: 1.8487430810928345, Lr:0.0001\n",
      "Epoch 15, Step: 86, Loss: 0.7028346061706543, Lr:0.0001\n",
      "Epoch 15, Step: 87, Loss: 0.04753922298550606, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 15\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 1.1921 (1.1921) acc1: 50.0000 (50.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.7337 (1.3061) acc1: 50.0000 (54.5455) acc5: 100.0000 (100.0000) time: 0.0067 data: 0.0037 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0068 s / it)\n",
      "* Acc@1 54.545 Acc@5 100.000 loss 1.306\n",
      "Accuracy of the network on the 22 test image: 54.5%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 16, Step: 0, Loss: 0.3814377188682556, Lr:0.0001\n",
      "Epoch 16, Step: 1, Loss: 0.2322710007429123, Lr:0.0001\n",
      "Epoch 16, Step: 2, Loss: 0.2656914293766022, Lr:0.0001\n",
      "Epoch 16, Step: 3, Loss: 1.0252829790115356, Lr:0.0001\n",
      "Epoch 16, Step: 4, Loss: 0.10405940562486649, Lr:0.0001\n",
      "Epoch 16, Step: 5, Loss: 0.7375562191009521, Lr:0.0001\n",
      "Epoch 16, Step: 6, Loss: 0.3783676028251648, Lr:0.0001\n",
      "Epoch 16, Step: 7, Loss: 0.05233455449342728, Lr:0.0001\n",
      "Epoch 16, Step: 8, Loss: 0.3264085054397583, Lr:0.0001\n",
      "Epoch 16, Step: 9, Loss: 0.9911764860153198, Lr:0.0001\n",
      "Epoch 16, Step: 10, Loss: 0.07850924879312515, Lr:0.0001\n",
      "Epoch 16, Step: 11, Loss: 0.5225751996040344, Lr:0.0001\n",
      "Epoch 16, Step: 12, Loss: 0.40805456042289734, Lr:0.0001\n",
      "Epoch 16, Step: 13, Loss: 0.05824022367596626, Lr:0.0001\n",
      "Epoch 16, Step: 14, Loss: 1.2680633068084717, Lr:0.0001\n",
      "Epoch 16, Step: 15, Loss: 1.4113261699676514, Lr:0.0001\n",
      "Epoch 16, Step: 16, Loss: 0.5196543335914612, Lr:0.0001\n",
      "Epoch 16, Step: 17, Loss: 0.3380447328090668, Lr:0.0001\n",
      "Epoch 16, Step: 18, Loss: 0.05394052714109421, Lr:0.0001\n",
      "Epoch 16, Step: 19, Loss: 0.7560722827911377, Lr:0.0001\n",
      "Epoch 16, Step: 20, Loss: 1.0506008863449097, Lr:0.0001\n",
      "Epoch 16, Step: 21, Loss: 0.05763084813952446, Lr:0.0001\n",
      "Epoch 16, Step: 22, Loss: 0.3493257761001587, Lr:0.0001\n",
      "Epoch 16, Step: 23, Loss: 1.3014073371887207, Lr:0.0001\n",
      "Epoch 16, Step: 24, Loss: 0.057795632630586624, Lr:0.0001\n",
      "Epoch 16, Step: 25, Loss: 1.1795624494552612, Lr:0.0001\n",
      "Epoch 16, Step: 26, Loss: 0.471317857503891, Lr:0.0001\n",
      "Epoch 16, Step: 27, Loss: 0.3164362907409668, Lr:0.0001\n",
      "Epoch 16, Step: 28, Loss: 1.174119234085083, Lr:0.0001\n",
      "Epoch 16, Step: 29, Loss: 0.4773222506046295, Lr:0.0001\n",
      "Epoch 16, Step: 30, Loss: 0.15147104859352112, Lr:0.0001\n",
      "Epoch 16, Step: 31, Loss: 0.8842641115188599, Lr:0.0001\n",
      "Epoch 16, Step: 32, Loss: 0.3318788409233093, Lr:0.0001\n",
      "Epoch 16, Step: 33, Loss: 0.7703443765640259, Lr:0.0001\n",
      "Epoch 16, Step: 34, Loss: 0.41987353563308716, Lr:0.0001\n",
      "Epoch 16, Step: 35, Loss: 0.2004273384809494, Lr:0.0001\n",
      "Epoch 16, Step: 36, Loss: 0.3839908838272095, Lr:0.0001\n",
      "Epoch 16, Step: 37, Loss: 1.8921605348587036, Lr:0.0001\n",
      "Epoch 16, Step: 38, Loss: 1.5375815629959106, Lr:0.0001\n",
      "Epoch 16, Step: 39, Loss: 0.4586239159107208, Lr:0.0001\n",
      "Epoch 16, Step: 40, Loss: 0.09675196558237076, Lr:0.0001\n",
      "Epoch 16, Step: 41, Loss: 1.1287614107131958, Lr:0.0001\n",
      "Epoch 16, Step: 42, Loss: 0.4150450825691223, Lr:0.0001\n",
      "Epoch 16, Step: 43, Loss: 0.38811805844306946, Lr:0.0001\n",
      "Epoch 16, Step: 44, Loss: 1.9606833457946777, Lr:0.0001\n",
      "Epoch 16, Step: 45, Loss: 0.9732298254966736, Lr:0.0001\n",
      "Epoch 16, Step: 46, Loss: 0.4093814194202423, Lr:0.0001\n",
      "Epoch 16, Step: 47, Loss: 0.7832632064819336, Lr:0.0001\n",
      "Epoch 16, Step: 48, Loss: 0.5760807991027832, Lr:0.0001\n",
      "Epoch 16, Step: 49, Loss: 0.6956885457038879, Lr:0.0001\n",
      "Epoch 16, Step: 50, Loss: 0.06460263580083847, Lr:0.0001\n",
      "Epoch 16, Step: 51, Loss: 0.8094589710235596, Lr:0.0001\n",
      "Epoch 16, Step: 52, Loss: 0.09715274721384048, Lr:0.0001\n",
      "Epoch 16, Step: 53, Loss: 0.23861193656921387, Lr:0.0001\n",
      "Epoch 16, Step: 54, Loss: 0.6882996559143066, Lr:0.0001\n",
      "Epoch 16, Step: 55, Loss: 0.5471177101135254, Lr:0.0001\n",
      "Epoch 16, Step: 56, Loss: 0.03595823794603348, Lr:0.0001\n",
      "Epoch 16, Step: 57, Loss: 2.140873670578003, Lr:0.0001\n",
      "Epoch 16, Step: 58, Loss: 0.41549211740493774, Lr:0.0001\n",
      "Epoch 16, Step: 59, Loss: 0.5285006761550903, Lr:0.0001\n",
      "Epoch 16, Step: 60, Loss: 0.8913711905479431, Lr:0.0001\n",
      "Epoch 16, Step: 61, Loss: 0.8206487894058228, Lr:0.0001\n",
      "Epoch 16, Step: 62, Loss: 0.3664209842681885, Lr:0.0001\n",
      "Epoch 16, Step: 63, Loss: 0.6935498118400574, Lr:0.0001\n",
      "Epoch 16, Step: 64, Loss: 1.1979106664657593, Lr:0.0001\n",
      "Epoch 16, Step: 65, Loss: 1.5057940483093262, Lr:0.0001\n",
      "Epoch 16, Step: 66, Loss: 0.32080984115600586, Lr:0.0001\n",
      "Epoch 16, Step: 67, Loss: 0.02493635192513466, Lr:0.0001\n",
      "Epoch 16, Step: 68, Loss: 0.17217318713665009, Lr:0.0001\n",
      "Epoch 16, Step: 69, Loss: 0.2607889473438263, Lr:0.0001\n",
      "Epoch 16, Step: 70, Loss: 0.4610553979873657, Lr:0.0001\n",
      "Epoch 16, Step: 71, Loss: 0.6487277746200562, Lr:0.0001\n",
      "Epoch 16, Step: 72, Loss: 0.6126104593276978, Lr:0.0001\n",
      "Epoch 16, Step: 73, Loss: 0.5764014720916748, Lr:0.0001\n",
      "Epoch 16, Step: 74, Loss: 1.8205841779708862, Lr:0.0001\n",
      "Epoch 16, Step: 75, Loss: 0.4104349911212921, Lr:0.0001\n",
      "Epoch 16, Step: 76, Loss: 0.09474549442529678, Lr:0.0001\n",
      "Epoch 16, Step: 77, Loss: 0.07667955011129379, Lr:0.0001\n",
      "Epoch 16, Step: 78, Loss: 0.5093446969985962, Lr:0.0001\n",
      "Epoch 16, Step: 79, Loss: 0.7569172978401184, Lr:0.0001\n",
      "Epoch 16, Step: 80, Loss: 0.8474400639533997, Lr:0.0001\n",
      "Epoch 16, Step: 81, Loss: 0.6896880269050598, Lr:0.0001\n",
      "Epoch 16, Step: 82, Loss: 1.1643918752670288, Lr:0.0001\n",
      "Epoch 16, Step: 83, Loss: 1.134544014930725, Lr:0.0001\n",
      "Epoch 16, Step: 84, Loss: 0.6393410563468933, Lr:0.0001\n",
      "Epoch 16, Step: 85, Loss: 0.9380835890769958, Lr:0.0001\n",
      "Epoch 16, Step: 86, Loss: 0.203751340508461, Lr:0.0001\n",
      "Epoch 16, Step: 87, Loss: 0.24535903334617615, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 16\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.0097 (0.0097) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0100 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.0265 (0.4291) acc1: 100.0000 (86.3636) acc5: 100.0000 (100.0000) time: 0.0087 data: 0.0037 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0087 s / it)\n",
      "* Acc@1 86.364 Acc@5 100.000 loss 0.429\n",
      "Accuracy of the network on the 22 test image: 86.4%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 17, Step: 0, Loss: 0.13079354166984558, Lr:0.0001\n",
      "Epoch 17, Step: 1, Loss: 0.7024859189987183, Lr:0.0001\n",
      "Epoch 17, Step: 2, Loss: 0.03292200714349747, Lr:0.0001\n",
      "Epoch 17, Step: 3, Loss: 0.4486839771270752, Lr:0.0001\n",
      "Epoch 17, Step: 4, Loss: 0.2890368700027466, Lr:0.0001\n",
      "Epoch 17, Step: 5, Loss: 0.32115161418914795, Lr:0.0001\n",
      "Epoch 17, Step: 6, Loss: 1.3978941440582275, Lr:0.0001\n",
      "Epoch 17, Step: 7, Loss: 0.6238195300102234, Lr:0.0001\n",
      "Epoch 17, Step: 8, Loss: 0.6395195722579956, Lr:0.0001\n",
      "Epoch 17, Step: 9, Loss: 0.19408974051475525, Lr:0.0001\n",
      "Epoch 17, Step: 10, Loss: 0.5253800749778748, Lr:0.0001\n",
      "Epoch 17, Step: 11, Loss: 0.3869418501853943, Lr:0.0001\n",
      "Epoch 17, Step: 12, Loss: 0.5168976783752441, Lr:0.0001\n",
      "Epoch 17, Step: 13, Loss: 1.6184500455856323, Lr:0.0001\n",
      "Epoch 17, Step: 14, Loss: 0.5929758548736572, Lr:0.0001\n",
      "Epoch 17, Step: 15, Loss: 0.07422129809856415, Lr:0.0001\n",
      "Epoch 17, Step: 16, Loss: 0.2391597032546997, Lr:0.0001\n",
      "Epoch 17, Step: 17, Loss: 0.1286509782075882, Lr:0.0001\n",
      "Epoch 17, Step: 18, Loss: 0.2522939145565033, Lr:0.0001\n",
      "Epoch 17, Step: 19, Loss: 0.6348204016685486, Lr:0.0001\n",
      "Epoch 17, Step: 20, Loss: 0.6143275499343872, Lr:0.0001\n",
      "Epoch 17, Step: 21, Loss: 0.23643508553504944, Lr:0.0001\n",
      "Epoch 17, Step: 22, Loss: 0.8411998152732849, Lr:0.0001\n",
      "Epoch 17, Step: 23, Loss: 1.6007461547851562, Lr:0.0001\n",
      "Epoch 17, Step: 24, Loss: 0.18496978282928467, Lr:0.0001\n",
      "Epoch 17, Step: 25, Loss: 0.029436033219099045, Lr:0.0001\n",
      "Epoch 17, Step: 26, Loss: 0.4533805549144745, Lr:0.0001\n",
      "Epoch 17, Step: 27, Loss: 0.5370211005210876, Lr:0.0001\n",
      "Epoch 17, Step: 28, Loss: 0.7639968991279602, Lr:0.0001\n",
      "Epoch 17, Step: 29, Loss: 0.12285897135734558, Lr:0.0001\n",
      "Epoch 17, Step: 30, Loss: 1.4847253561019897, Lr:0.0001\n",
      "Epoch 17, Step: 31, Loss: 0.5940937995910645, Lr:0.0001\n",
      "Epoch 17, Step: 32, Loss: 0.3794550895690918, Lr:0.0001\n",
      "Epoch 17, Step: 33, Loss: 0.6221314072608948, Lr:0.0001\n",
      "Epoch 17, Step: 34, Loss: 0.117183156311512, Lr:0.0001\n",
      "Epoch 17, Step: 35, Loss: 0.11331883072853088, Lr:0.0001\n",
      "Epoch 17, Step: 36, Loss: 0.3638157844543457, Lr:0.0001\n",
      "Epoch 17, Step: 37, Loss: 0.37162670493125916, Lr:0.0001\n",
      "Epoch 17, Step: 38, Loss: 0.35672953724861145, Lr:0.0001\n",
      "Epoch 17, Step: 39, Loss: 0.9283728003501892, Lr:0.0001\n",
      "Epoch 17, Step: 40, Loss: 1.4230448007583618, Lr:0.0001\n",
      "Epoch 17, Step: 41, Loss: 0.456149160861969, Lr:0.0001\n",
      "Epoch 17, Step: 42, Loss: 2.20613169670105, Lr:0.0001\n",
      "Epoch 17, Step: 43, Loss: 0.9968177080154419, Lr:0.0001\n",
      "Epoch 17, Step: 44, Loss: 0.7123643755912781, Lr:0.0001\n",
      "Epoch 17, Step: 45, Loss: 0.4481700658798218, Lr:0.0001\n",
      "Epoch 17, Step: 46, Loss: 0.33378174901008606, Lr:0.0001\n",
      "Epoch 17, Step: 47, Loss: 0.6188521385192871, Lr:0.0001\n",
      "Epoch 17, Step: 48, Loss: 0.49042803049087524, Lr:0.0001\n",
      "Epoch 17, Step: 49, Loss: 0.09735284000635147, Lr:0.0001\n",
      "Epoch 17, Step: 50, Loss: 0.2182176411151886, Lr:0.0001\n",
      "Epoch 17, Step: 51, Loss: 0.6308745741844177, Lr:0.0001\n",
      "Epoch 17, Step: 52, Loss: 0.24458946287631989, Lr:0.0001\n",
      "Epoch 17, Step: 53, Loss: 0.25991007685661316, Lr:0.0001\n",
      "Epoch 17, Step: 54, Loss: 0.34491437673568726, Lr:0.0001\n",
      "Epoch 17, Step: 55, Loss: 0.5834112763404846, Lr:0.0001\n",
      "Epoch 17, Step: 56, Loss: 0.18470153212547302, Lr:0.0001\n",
      "Epoch 17, Step: 57, Loss: 0.5616919994354248, Lr:0.0001\n",
      "Epoch 17, Step: 58, Loss: 1.268671989440918, Lr:0.0001\n",
      "Epoch 17, Step: 59, Loss: 0.07800815254449844, Lr:0.0001\n",
      "Epoch 17, Step: 60, Loss: 0.4938007593154907, Lr:0.0001\n",
      "Epoch 17, Step: 61, Loss: 0.2627051770687103, Lr:0.0001\n",
      "Epoch 17, Step: 62, Loss: 0.026776732876896858, Lr:0.0001\n",
      "Epoch 17, Step: 63, Loss: 0.410239577293396, Lr:0.0001\n",
      "Epoch 17, Step: 64, Loss: 0.644646167755127, Lr:0.0001\n",
      "Epoch 17, Step: 65, Loss: 0.5768995881080627, Lr:0.0001\n",
      "Epoch 17, Step: 66, Loss: 0.2513267993927002, Lr:0.0001\n",
      "Epoch 17, Step: 67, Loss: 1.1622118949890137, Lr:0.0001\n",
      "Epoch 17, Step: 68, Loss: 0.4210728108882904, Lr:0.0001\n",
      "Epoch 17, Step: 69, Loss: 1.1783028841018677, Lr:0.0001\n",
      "Epoch 17, Step: 70, Loss: 0.7289100289344788, Lr:0.0001\n",
      "Epoch 17, Step: 71, Loss: 0.556526780128479, Lr:0.0001\n",
      "Epoch 17, Step: 72, Loss: 0.08180690556764603, Lr:0.0001\n",
      "Epoch 17, Step: 73, Loss: 0.3825279176235199, Lr:0.0001\n",
      "Epoch 17, Step: 74, Loss: 0.41776368021965027, Lr:0.0001\n",
      "Epoch 17, Step: 75, Loss: 0.6905795335769653, Lr:0.0001\n",
      "Epoch 17, Step: 76, Loss: 1.4985203742980957, Lr:0.0001\n",
      "Epoch 17, Step: 77, Loss: 0.15382394194602966, Lr:0.0001\n",
      "Epoch 17, Step: 78, Loss: 0.30576401948928833, Lr:0.0001\n",
      "Epoch 17, Step: 79, Loss: 0.9232310652732849, Lr:0.0001\n",
      "Epoch 17, Step: 80, Loss: 0.09002017229795456, Lr:0.0001\n",
      "Epoch 17, Step: 81, Loss: 0.4359889030456543, Lr:0.0001\n",
      "Epoch 17, Step: 82, Loss: 0.3821411728858948, Lr:0.0001\n",
      "Epoch 17, Step: 83, Loss: 0.24055644869804382, Lr:0.0001\n",
      "Epoch 17, Step: 84, Loss: 0.44944414496421814, Lr:0.0001\n",
      "Epoch 17, Step: 85, Loss: 1.4252071380615234, Lr:0.0001\n",
      "Epoch 17, Step: 86, Loss: 0.1121620312333107, Lr:0.0001\n",
      "Epoch 17, Step: 87, Loss: 0.8132563829421997, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 17\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.3187 (0.3187) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0110 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.3187 (0.7330) acc1: 75.0000 (77.2727) acc5: 100.0000 (100.0000) time: 0.0072 data: 0.0037 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0073 s / it)\n",
      "* Acc@1 77.273 Acc@5 100.000 loss 0.733\n",
      "Accuracy of the network on the 22 test image: 77.3%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 18, Step: 0, Loss: 0.6063708066940308, Lr:0.0001\n",
      "Epoch 18, Step: 1, Loss: 1.0629441738128662, Lr:0.0001\n",
      "Epoch 18, Step: 2, Loss: 0.08702502399682999, Lr:0.0001\n",
      "Epoch 18, Step: 3, Loss: 0.7081279754638672, Lr:0.0001\n",
      "Epoch 18, Step: 4, Loss: 0.8161410093307495, Lr:0.0001\n",
      "Epoch 18, Step: 5, Loss: 0.07042121887207031, Lr:0.0001\n",
      "Epoch 18, Step: 6, Loss: 0.36821794509887695, Lr:0.0001\n",
      "Epoch 18, Step: 7, Loss: 0.040802694857120514, Lr:0.0001\n",
      "Epoch 18, Step: 8, Loss: 0.7069787979125977, Lr:0.0001\n",
      "Epoch 18, Step: 9, Loss: 0.39045020937919617, Lr:0.0001\n",
      "Epoch 18, Step: 10, Loss: 0.14203877747058868, Lr:0.0001\n",
      "Epoch 18, Step: 11, Loss: 0.1453455239534378, Lr:0.0001\n",
      "Epoch 18, Step: 12, Loss: 0.5968922972679138, Lr:0.0001\n",
      "Epoch 18, Step: 13, Loss: 0.04508427530527115, Lr:0.0001\n",
      "Epoch 18, Step: 14, Loss: 0.2341734766960144, Lr:0.0001\n",
      "Epoch 18, Step: 15, Loss: 0.34438595175743103, Lr:0.0001\n",
      "Epoch 18, Step: 16, Loss: 0.3764127194881439, Lr:0.0001\n",
      "Epoch 18, Step: 17, Loss: 0.46617382764816284, Lr:0.0001\n",
      "Epoch 18, Step: 18, Loss: 0.6885992288589478, Lr:0.0001\n",
      "Epoch 18, Step: 19, Loss: 0.7567969560623169, Lr:0.0001\n",
      "Epoch 18, Step: 20, Loss: 0.11132339388132095, Lr:0.0001\n",
      "Epoch 18, Step: 21, Loss: 0.6060970425605774, Lr:0.0001\n",
      "Epoch 18, Step: 22, Loss: 0.17025762796401978, Lr:0.0001\n",
      "Epoch 18, Step: 23, Loss: 3.6666600704193115, Lr:0.0001\n",
      "Epoch 18, Step: 24, Loss: 0.08966247737407684, Lr:0.0001\n",
      "Epoch 18, Step: 25, Loss: 0.2234424352645874, Lr:0.0001\n",
      "Epoch 18, Step: 26, Loss: 1.3239867687225342, Lr:0.0001\n",
      "Epoch 18, Step: 27, Loss: 1.7616655826568604, Lr:0.0001\n",
      "Epoch 18, Step: 28, Loss: 0.4820387065410614, Lr:0.0001\n",
      "Epoch 18, Step: 29, Loss: 1.4810189008712769, Lr:0.0001\n",
      "Epoch 18, Step: 30, Loss: 1.0358271598815918, Lr:0.0001\n",
      "Epoch 18, Step: 31, Loss: 0.07526279985904694, Lr:0.0001\n",
      "Epoch 18, Step: 32, Loss: 0.4959154725074768, Lr:0.0001\n",
      "Epoch 18, Step: 33, Loss: 0.41500231623649597, Lr:0.0001\n",
      "Epoch 18, Step: 34, Loss: 0.4276171922683716, Lr:0.0001\n",
      "Epoch 18, Step: 35, Loss: 0.20035916566848755, Lr:0.0001\n",
      "Epoch 18, Step: 36, Loss: 0.43627429008483887, Lr:0.0001\n",
      "Epoch 18, Step: 37, Loss: 0.5733644962310791, Lr:0.0001\n",
      "Epoch 18, Step: 38, Loss: 1.2220860719680786, Lr:0.0001\n",
      "Epoch 18, Step: 39, Loss: 0.06977897137403488, Lr:0.0001\n",
      "Epoch 18, Step: 40, Loss: 0.3897140920162201, Lr:0.0001\n",
      "Epoch 18, Step: 41, Loss: 2.5629985332489014, Lr:0.0001\n",
      "Epoch 18, Step: 42, Loss: 0.7792558670043945, Lr:0.0001\n",
      "Epoch 18, Step: 43, Loss: 0.09241141378879547, Lr:0.0001\n",
      "Epoch 18, Step: 44, Loss: 0.16113123297691345, Lr:0.0001\n",
      "Epoch 18, Step: 45, Loss: 0.31604182720184326, Lr:0.0001\n",
      "Epoch 18, Step: 46, Loss: 0.046429477632045746, Lr:0.0001\n",
      "Epoch 18, Step: 47, Loss: 2.3320538997650146, Lr:0.0001\n",
      "Epoch 18, Step: 48, Loss: 1.2998634576797485, Lr:0.0001\n",
      "Epoch 18, Step: 49, Loss: 0.7108016014099121, Lr:0.0001\n",
      "Epoch 18, Step: 50, Loss: 0.2845323979854584, Lr:0.0001\n",
      "Epoch 18, Step: 51, Loss: 0.7942115068435669, Lr:0.0001\n",
      "Epoch 18, Step: 52, Loss: 1.8064918518066406, Lr:0.0001\n",
      "Epoch 18, Step: 53, Loss: 0.5006664991378784, Lr:0.0001\n",
      "Epoch 18, Step: 54, Loss: 0.8868488073348999, Lr:0.0001\n",
      "Epoch 18, Step: 55, Loss: 1.0350148677825928, Lr:0.0001\n",
      "Epoch 18, Step: 56, Loss: 0.26281940937042236, Lr:0.0001\n",
      "Epoch 18, Step: 57, Loss: 0.7680454254150391, Lr:0.0001\n",
      "Epoch 18, Step: 58, Loss: 0.07042226195335388, Lr:0.0001\n",
      "Epoch 18, Step: 59, Loss: 1.0767749547958374, Lr:0.0001\n",
      "Epoch 18, Step: 60, Loss: 1.1879138946533203, Lr:0.0001\n",
      "Epoch 18, Step: 61, Loss: 1.0121592283248901, Lr:0.0001\n",
      "Epoch 18, Step: 62, Loss: 0.6376148462295532, Lr:0.0001\n",
      "Epoch 18, Step: 63, Loss: 0.3725835084915161, Lr:0.0001\n",
      "Epoch 18, Step: 64, Loss: 0.4540393352508545, Lr:0.0001\n",
      "Epoch 18, Step: 65, Loss: 0.6862450838088989, Lr:0.0001\n",
      "Epoch 18, Step: 66, Loss: 0.4086177945137024, Lr:0.0001\n",
      "Epoch 18, Step: 67, Loss: 0.4206361472606659, Lr:0.0001\n",
      "Epoch 18, Step: 68, Loss: 1.1479101181030273, Lr:0.0001\n",
      "Epoch 18, Step: 69, Loss: 4.783726692199707, Lr:0.0001\n",
      "Epoch 18, Step: 70, Loss: 0.338817834854126, Lr:0.0001\n",
      "Epoch 18, Step: 71, Loss: 0.5269560217857361, Lr:0.0001\n",
      "Epoch 18, Step: 72, Loss: 0.6280497312545776, Lr:0.0001\n",
      "Epoch 18, Step: 73, Loss: 0.616351306438446, Lr:0.0001\n",
      "Epoch 18, Step: 74, Loss: 1.5567561388015747, Lr:0.0001\n",
      "Epoch 18, Step: 75, Loss: 0.4403635859489441, Lr:0.0001\n",
      "Epoch 18, Step: 76, Loss: 0.19886502623558044, Lr:0.0001\n",
      "Epoch 18, Step: 77, Loss: 0.7317887544631958, Lr:0.0001\n",
      "Epoch 18, Step: 78, Loss: 0.5216989517211914, Lr:0.0001\n",
      "Epoch 18, Step: 79, Loss: 0.7167397141456604, Lr:0.0001\n",
      "Epoch 18, Step: 80, Loss: 3.0066184997558594, Lr:0.0001\n",
      "Epoch 18, Step: 81, Loss: 0.8011722564697266, Lr:0.0001\n",
      "Epoch 18, Step: 82, Loss: 0.4568081200122833, Lr:0.0001\n",
      "Epoch 18, Step: 83, Loss: 0.7635156512260437, Lr:0.0001\n",
      "Epoch 18, Step: 84, Loss: 0.3422616720199585, Lr:0.0001\n",
      "Epoch 18, Step: 85, Loss: 0.5837244391441345, Lr:0.0001\n",
      "Epoch 18, Step: 86, Loss: 0.3700215518474579, Lr:0.0001\n",
      "Epoch 18, Step: 87, Loss: 0.2610301077365875, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 18\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.0059 (0.0059) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0120 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.0747 (0.6994) acc1: 100.0000 (81.8182) acc5: 100.0000 (100.0000) time: 0.0075 data: 0.0038 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0075 s / it)\n",
      "* Acc@1 81.818 Acc@5 100.000 loss 0.699\n",
      "Accuracy of the network on the 22 test image: 81.8%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 19, Step: 0, Loss: 0.5200958251953125, Lr:0.0001\n",
      "Epoch 19, Step: 1, Loss: 0.3285812735557556, Lr:0.0001\n",
      "Epoch 19, Step: 2, Loss: 0.5404537916183472, Lr:0.0001\n",
      "Epoch 19, Step: 3, Loss: 0.5287654399871826, Lr:0.0001\n",
      "Epoch 19, Step: 4, Loss: 0.6853399872779846, Lr:0.0001\n",
      "Epoch 19, Step: 5, Loss: 0.3806789815425873, Lr:0.0001\n",
      "Epoch 19, Step: 6, Loss: 0.44481903314590454, Lr:0.0001\n",
      "Epoch 19, Step: 7, Loss: 0.12342624366283417, Lr:0.0001\n",
      "Epoch 19, Step: 8, Loss: 0.49621495604515076, Lr:0.0001\n",
      "Epoch 19, Step: 9, Loss: 0.48940813541412354, Lr:0.0001\n",
      "Epoch 19, Step: 10, Loss: 0.5522651672363281, Lr:0.0001\n",
      "Epoch 19, Step: 11, Loss: 0.49691906571388245, Lr:0.0001\n",
      "Epoch 19, Step: 12, Loss: 0.7243123054504395, Lr:0.0001\n",
      "Epoch 19, Step: 13, Loss: 0.1955203413963318, Lr:0.0001\n",
      "Epoch 19, Step: 14, Loss: 0.5898027420043945, Lr:0.0001\n",
      "Epoch 19, Step: 15, Loss: 0.48333871364593506, Lr:0.0001\n",
      "Epoch 19, Step: 16, Loss: 1.1150240898132324, Lr:0.0001\n",
      "Epoch 19, Step: 17, Loss: 0.4553164541721344, Lr:0.0001\n",
      "Epoch 19, Step: 18, Loss: 0.14302226901054382, Lr:0.0001\n",
      "Epoch 19, Step: 19, Loss: 0.25407955050468445, Lr:0.0001\n",
      "Epoch 19, Step: 20, Loss: 0.2831825613975525, Lr:0.0001\n",
      "Epoch 19, Step: 21, Loss: 0.52888023853302, Lr:0.0001\n",
      "Epoch 19, Step: 22, Loss: 0.8222653865814209, Lr:0.0001\n",
      "Epoch 19, Step: 23, Loss: 0.06473276019096375, Lr:0.0001\n",
      "Epoch 19, Step: 24, Loss: 0.9047046899795532, Lr:0.0001\n",
      "Epoch 19, Step: 25, Loss: 0.12400422990322113, Lr:0.0001\n",
      "Epoch 19, Step: 26, Loss: 0.26131367683410645, Lr:0.0001\n",
      "Epoch 19, Step: 27, Loss: 0.5137159824371338, Lr:0.0001\n",
      "Epoch 19, Step: 28, Loss: 0.4775294065475464, Lr:0.0001\n",
      "Epoch 19, Step: 29, Loss: 1.3260433673858643, Lr:0.0001\n",
      "Epoch 19, Step: 30, Loss: 0.214471697807312, Lr:0.0001\n",
      "Epoch 19, Step: 31, Loss: 0.24954362213611603, Lr:0.0001\n",
      "Epoch 19, Step: 32, Loss: 0.07483948767185211, Lr:0.0001\n",
      "Epoch 19, Step: 33, Loss: 0.26046743988990784, Lr:0.0001\n",
      "Epoch 19, Step: 34, Loss: 0.1653842329978943, Lr:0.0001\n",
      "Epoch 19, Step: 35, Loss: 0.7909380793571472, Lr:0.0001\n",
      "Epoch 19, Step: 36, Loss: 0.43065011501312256, Lr:0.0001\n",
      "Epoch 19, Step: 37, Loss: 0.36576494574546814, Lr:0.0001\n",
      "Epoch 19, Step: 38, Loss: 3.751530170440674, Lr:0.0001\n",
      "Epoch 19, Step: 39, Loss: 0.9026370048522949, Lr:0.0001\n",
      "Epoch 19, Step: 40, Loss: 0.33393386006355286, Lr:0.0001\n",
      "Epoch 19, Step: 41, Loss: 0.5728679895401001, Lr:0.0001\n",
      "Epoch 19, Step: 42, Loss: 0.8418801426887512, Lr:0.0001\n",
      "Epoch 19, Step: 43, Loss: 0.9265893697738647, Lr:0.0001\n",
      "Epoch 19, Step: 44, Loss: 0.6081151366233826, Lr:0.0001\n",
      "Epoch 19, Step: 45, Loss: 0.9180352091789246, Lr:0.0001\n",
      "Epoch 19, Step: 46, Loss: 0.6791753172874451, Lr:0.0001\n",
      "Epoch 19, Step: 47, Loss: 0.6821781992912292, Lr:0.0001\n",
      "Epoch 19, Step: 48, Loss: 0.045138344168663025, Lr:0.0001\n",
      "Epoch 19, Step: 49, Loss: 0.09517009556293488, Lr:0.0001\n",
      "Epoch 19, Step: 50, Loss: 0.0320790559053421, Lr:0.0001\n",
      "Epoch 19, Step: 51, Loss: 0.6562654972076416, Lr:0.0001\n",
      "Epoch 19, Step: 52, Loss: 0.8421865701675415, Lr:0.0001\n",
      "Epoch 19, Step: 53, Loss: 0.39599815011024475, Lr:0.0001\n",
      "Epoch 19, Step: 54, Loss: 0.05516184866428375, Lr:0.0001\n",
      "Epoch 19, Step: 55, Loss: 0.7872660160064697, Lr:0.0001\n",
      "Epoch 19, Step: 56, Loss: 0.764290988445282, Lr:0.0001\n",
      "Epoch 19, Step: 57, Loss: 0.8506051301956177, Lr:0.0001\n",
      "Epoch 19, Step: 58, Loss: 0.0386490561068058, Lr:0.0001\n",
      "Epoch 19, Step: 59, Loss: 1.1490676403045654, Lr:0.0001\n",
      "Epoch 19, Step: 60, Loss: 0.35043853521347046, Lr:0.0001\n",
      "Epoch 19, Step: 61, Loss: 0.041535068303346634, Lr:0.0001\n",
      "Epoch 19, Step: 62, Loss: 0.9484063386917114, Lr:0.0001\n",
      "Epoch 19, Step: 63, Loss: 0.8184908628463745, Lr:0.0001\n",
      "Epoch 19, Step: 64, Loss: 0.843497633934021, Lr:0.0001\n",
      "Epoch 19, Step: 65, Loss: 0.7780386805534363, Lr:0.0001\n",
      "Epoch 19, Step: 66, Loss: 1.1283750534057617, Lr:0.0001\n",
      "Epoch 19, Step: 67, Loss: 0.045840248465538025, Lr:0.0001\n",
      "Epoch 19, Step: 68, Loss: 0.35780927538871765, Lr:0.0001\n",
      "Epoch 19, Step: 69, Loss: 0.029453083872795105, Lr:0.0001\n",
      "Epoch 19, Step: 70, Loss: 0.1196228489279747, Lr:0.0001\n",
      "Epoch 19, Step: 71, Loss: 0.134576678276062, Lr:0.0001\n",
      "Epoch 19, Step: 72, Loss: 0.4539319574832916, Lr:0.0001\n",
      "Epoch 19, Step: 73, Loss: 1.0440400838851929, Lr:0.0001\n",
      "Epoch 19, Step: 74, Loss: 0.5966378450393677, Lr:0.0001\n",
      "Epoch 19, Step: 75, Loss: 0.37122687697410583, Lr:0.0001\n",
      "Epoch 19, Step: 76, Loss: 0.9362246990203857, Lr:0.0001\n",
      "Epoch 19, Step: 77, Loss: 0.07797576487064362, Lr:0.0001\n",
      "Epoch 19, Step: 78, Loss: 0.400956928730011, Lr:0.0001\n",
      "Epoch 19, Step: 79, Loss: 0.8826199173927307, Lr:0.0001\n",
      "Epoch 19, Step: 80, Loss: 3.195376396179199, Lr:0.0001\n",
      "Epoch 19, Step: 81, Loss: 0.06954425573348999, Lr:0.0001\n",
      "Epoch 19, Step: 82, Loss: 0.15308815240859985, Lr:0.0001\n",
      "Epoch 19, Step: 83, Loss: 0.46191665530204773, Lr:0.0001\n",
      "Epoch 19, Step: 84, Loss: 0.4605921804904938, Lr:0.0001\n",
      "Epoch 19, Step: 85, Loss: 0.194497749209404, Lr:0.0001\n",
      "Epoch 19, Step: 86, Loss: 0.5774988532066345, Lr:0.0001\n",
      "Epoch 19, Step: 87, Loss: 0.3637202978134155, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 19\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.1799 (0.1799) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0120 data: 0.0070 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.1799 (0.4361) acc1: 100.0000 (90.9091) acc5: 100.0000 (100.0000) time: 0.0073 data: 0.0040 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0073 s / it)\n",
      "* Acc@1 90.909 Acc@5 100.000 loss 0.436\n",
      "Accuracy of the network on the 22 test image: 90.9%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 20, Step: 0, Loss: 0.36176007986068726, Lr:0.0001\n",
      "Epoch 20, Step: 1, Loss: 0.43218734860420227, Lr:0.0001\n",
      "Epoch 20, Step: 2, Loss: 0.7636211514472961, Lr:0.0001\n",
      "Epoch 20, Step: 3, Loss: 0.32140421867370605, Lr:0.0001\n",
      "Epoch 20, Step: 4, Loss: 0.12823744118213654, Lr:0.0001\n",
      "Epoch 20, Step: 5, Loss: 0.3489726185798645, Lr:0.0001\n",
      "Epoch 20, Step: 6, Loss: 0.3274989426136017, Lr:0.0001\n",
      "Epoch 20, Step: 7, Loss: 0.41057705879211426, Lr:0.0001\n",
      "Epoch 20, Step: 8, Loss: 0.42389634251594543, Lr:0.0001\n",
      "Epoch 20, Step: 9, Loss: 0.9623569250106812, Lr:0.0001\n",
      "Epoch 20, Step: 10, Loss: 0.7595493197441101, Lr:0.0001\n",
      "Epoch 20, Step: 11, Loss: 0.2762965261936188, Lr:0.0001\n",
      "Epoch 20, Step: 12, Loss: 0.06516241282224655, Lr:0.0001\n",
      "Epoch 20, Step: 13, Loss: 0.7692126035690308, Lr:0.0001\n",
      "Epoch 20, Step: 14, Loss: 0.26871031522750854, Lr:0.0001\n",
      "Epoch 20, Step: 15, Loss: 1.35670006275177, Lr:0.0001\n",
      "Epoch 20, Step: 16, Loss: 2.682091474533081, Lr:0.0001\n",
      "Epoch 20, Step: 17, Loss: 0.058539070188999176, Lr:0.0001\n",
      "Epoch 20, Step: 18, Loss: 0.31476452946662903, Lr:0.0001\n",
      "Epoch 20, Step: 19, Loss: 0.1276738941669464, Lr:0.0001\n",
      "Epoch 20, Step: 20, Loss: 0.4807985723018646, Lr:0.0001\n",
      "Epoch 20, Step: 21, Loss: 0.3841085135936737, Lr:0.0001\n",
      "Epoch 20, Step: 22, Loss: 0.1374482959508896, Lr:0.0001\n",
      "Epoch 20, Step: 23, Loss: 0.5615260004997253, Lr:0.0001\n",
      "Epoch 20, Step: 24, Loss: 0.634878396987915, Lr:0.0001\n",
      "Epoch 20, Step: 25, Loss: 0.8757559061050415, Lr:0.0001\n",
      "Epoch 20, Step: 26, Loss: 0.7910365462303162, Lr:0.0001\n",
      "Epoch 20, Step: 27, Loss: 0.3569974899291992, Lr:0.0001\n",
      "Epoch 20, Step: 28, Loss: 0.4932152330875397, Lr:0.0001\n",
      "Epoch 20, Step: 29, Loss: 0.9081591367721558, Lr:0.0001\n",
      "Epoch 20, Step: 30, Loss: 0.2699491083621979, Lr:0.0001\n",
      "Epoch 20, Step: 31, Loss: 1.3662279844284058, Lr:0.0001\n",
      "Epoch 20, Step: 32, Loss: 0.09528134763240814, Lr:0.0001\n",
      "Epoch 20, Step: 33, Loss: 0.24602152407169342, Lr:0.0001\n",
      "Epoch 20, Step: 34, Loss: 0.4321327209472656, Lr:0.0001\n",
      "Epoch 20, Step: 35, Loss: 0.37549152970314026, Lr:0.0001\n",
      "Epoch 20, Step: 36, Loss: 0.3490874469280243, Lr:0.0001\n",
      "Epoch 20, Step: 37, Loss: 0.5026770830154419, Lr:0.0001\n",
      "Epoch 20, Step: 38, Loss: 0.5871868133544922, Lr:0.0001\n",
      "Epoch 20, Step: 39, Loss: 0.2593119740486145, Lr:0.0001\n",
      "Epoch 20, Step: 40, Loss: 0.07590791583061218, Lr:0.0001\n",
      "Epoch 20, Step: 41, Loss: 0.07091028988361359, Lr:0.0001\n",
      "Epoch 20, Step: 42, Loss: 0.497587114572525, Lr:0.0001\n",
      "Epoch 20, Step: 43, Loss: 1.0124602317810059, Lr:0.0001\n",
      "Epoch 20, Step: 44, Loss: 0.21897004544734955, Lr:0.0001\n",
      "Epoch 20, Step: 45, Loss: 0.04825782775878906, Lr:0.0001\n",
      "Epoch 20, Step: 46, Loss: 0.07866183668375015, Lr:0.0001\n",
      "Epoch 20, Step: 47, Loss: 0.7218424677848816, Lr:0.0001\n",
      "Epoch 20, Step: 48, Loss: 0.44339072704315186, Lr:0.0001\n",
      "Epoch 20, Step: 49, Loss: 0.5080146789550781, Lr:0.0001\n",
      "Epoch 20, Step: 50, Loss: 0.4657337963581085, Lr:0.0001\n",
      "Epoch 20, Step: 51, Loss: 0.43312203884124756, Lr:0.0001\n",
      "Epoch 20, Step: 52, Loss: 0.16324254870414734, Lr:0.0001\n",
      "Epoch 20, Step: 53, Loss: 0.1264222264289856, Lr:0.0001\n",
      "Epoch 20, Step: 54, Loss: 1.4882020950317383, Lr:0.0001\n",
      "Epoch 20, Step: 55, Loss: 1.214660406112671, Lr:0.0001\n",
      "Epoch 20, Step: 56, Loss: 0.3249416649341583, Lr:0.0001\n",
      "Epoch 20, Step: 57, Loss: 1.1507925987243652, Lr:0.0001\n",
      "Epoch 20, Step: 58, Loss: 0.5171181559562683, Lr:0.0001\n",
      "Epoch 20, Step: 59, Loss: 0.9134654998779297, Lr:0.0001\n",
      "Epoch 20, Step: 60, Loss: 0.057382386177778244, Lr:0.0001\n",
      "Epoch 20, Step: 61, Loss: 0.23306427896022797, Lr:0.0001\n",
      "Epoch 20, Step: 62, Loss: 0.7827269434928894, Lr:0.0001\n",
      "Epoch 20, Step: 63, Loss: 0.8495180606842041, Lr:0.0001\n",
      "Epoch 20, Step: 64, Loss: 1.0573458671569824, Lr:0.0001\n",
      "Epoch 20, Step: 65, Loss: 0.47790202498435974, Lr:0.0001\n",
      "Epoch 20, Step: 66, Loss: 0.6901956796646118, Lr:0.0001\n",
      "Epoch 20, Step: 67, Loss: 0.5383785963058472, Lr:0.0001\n",
      "Epoch 20, Step: 68, Loss: 0.30631840229034424, Lr:0.0001\n",
      "Epoch 20, Step: 69, Loss: 0.6753702163696289, Lr:0.0001\n",
      "Epoch 20, Step: 70, Loss: 0.04937468096613884, Lr:0.0001\n",
      "Epoch 20, Step: 71, Loss: 0.5270223617553711, Lr:0.0001\n",
      "Epoch 20, Step: 72, Loss: 0.13337057828903198, Lr:0.0001\n",
      "Epoch 20, Step: 73, Loss: 0.07920557260513306, Lr:0.0001\n",
      "Epoch 20, Step: 74, Loss: 0.1896955966949463, Lr:0.0001\n",
      "Epoch 20, Step: 75, Loss: 0.9716498851776123, Lr:0.0001\n",
      "Epoch 20, Step: 76, Loss: 0.15595728158950806, Lr:0.0001\n",
      "Epoch 20, Step: 77, Loss: 0.5831237435340881, Lr:0.0001\n",
      "Epoch 20, Step: 78, Loss: 0.4840315282344818, Lr:0.0001\n",
      "Epoch 20, Step: 79, Loss: 0.5195308327674866, Lr:0.0001\n",
      "Epoch 20, Step: 80, Loss: 0.6124452948570251, Lr:0.0001\n",
      "Epoch 20, Step: 81, Loss: 2.0598411560058594, Lr:0.0001\n",
      "Epoch 20, Step: 82, Loss: 0.19111742079257965, Lr:0.0001\n",
      "Epoch 20, Step: 83, Loss: 0.2225407063961029, Lr:0.0001\n",
      "Epoch 20, Step: 84, Loss: 0.3272417485713959, Lr:0.0001\n",
      "Epoch 20, Step: 85, Loss: 0.648950457572937, Lr:0.0001\n",
      "Epoch 20, Step: 86, Loss: 0.3573863208293915, Lr:0.0001\n",
      "Epoch 20, Step: 87, Loss: 0.6281598806381226, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 20\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.0313 (0.0313) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.0626 (0.4738) acc1: 100.0000 (81.8182) acc5: 100.0000 (100.0000) time: 0.0073 data: 0.0040 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0075 s / it)\n",
      "* Acc@1 81.818 Acc@5 100.000 loss 0.474\n",
      "Accuracy of the network on the 22 test image: 81.8%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 21, Step: 0, Loss: 0.7892951369285583, Lr:0.0001\n",
      "Epoch 21, Step: 1, Loss: 0.02143992856144905, Lr:0.0001\n",
      "Epoch 21, Step: 2, Loss: 1.3222898244857788, Lr:0.0001\n",
      "Epoch 21, Step: 3, Loss: 0.335970938205719, Lr:0.0001\n",
      "Epoch 21, Step: 4, Loss: 0.8178751468658447, Lr:0.0001\n",
      "Epoch 21, Step: 5, Loss: 0.22051110863685608, Lr:0.0001\n",
      "Epoch 21, Step: 6, Loss: 0.187228262424469, Lr:0.0001\n",
      "Epoch 21, Step: 7, Loss: 0.31630221009254456, Lr:0.0001\n",
      "Epoch 21, Step: 8, Loss: 0.68888258934021, Lr:0.0001\n",
      "Epoch 21, Step: 9, Loss: 0.22219440340995789, Lr:0.0001\n",
      "Epoch 21, Step: 10, Loss: 0.32332557439804077, Lr:0.0001\n",
      "Epoch 21, Step: 11, Loss: 0.07199637591838837, Lr:0.0001\n",
      "Epoch 21, Step: 12, Loss: 0.05692635849118233, Lr:0.0001\n",
      "Epoch 21, Step: 13, Loss: 0.06226162612438202, Lr:0.0001\n",
      "Epoch 21, Step: 14, Loss: 0.5224968791007996, Lr:0.0001\n",
      "Epoch 21, Step: 15, Loss: 0.2880564332008362, Lr:0.0001\n",
      "Epoch 21, Step: 16, Loss: 0.8764962553977966, Lr:0.0001\n",
      "Epoch 21, Step: 17, Loss: 1.0903037786483765, Lr:0.0001\n",
      "Epoch 21, Step: 18, Loss: 0.1234937459230423, Lr:0.0001\n",
      "Epoch 21, Step: 19, Loss: 0.5238745808601379, Lr:0.0001\n",
      "Epoch 21, Step: 20, Loss: 0.1385633945465088, Lr:0.0001\n",
      "Epoch 21, Step: 21, Loss: 0.3940883278846741, Lr:0.0001\n",
      "Epoch 21, Step: 22, Loss: 0.1252962052822113, Lr:0.0001\n",
      "Epoch 21, Step: 23, Loss: 2.477130174636841, Lr:0.0001\n",
      "Epoch 21, Step: 24, Loss: 0.0636398121714592, Lr:0.0001\n",
      "Epoch 21, Step: 25, Loss: 1.7281243801116943, Lr:0.0001\n",
      "Epoch 21, Step: 26, Loss: 0.4995085597038269, Lr:0.0001\n",
      "Epoch 21, Step: 27, Loss: 0.793997585773468, Lr:0.0001\n",
      "Epoch 21, Step: 28, Loss: 0.3526794910430908, Lr:0.0001\n",
      "Epoch 21, Step: 29, Loss: 0.40707167983055115, Lr:0.0001\n",
      "Epoch 21, Step: 30, Loss: 0.43999987840652466, Lr:0.0001\n",
      "Epoch 21, Step: 31, Loss: 0.7631205320358276, Lr:0.0001\n",
      "Epoch 21, Step: 32, Loss: 1.5123848915100098, Lr:0.0001\n",
      "Epoch 21, Step: 33, Loss: 0.4572935700416565, Lr:0.0001\n",
      "Epoch 21, Step: 34, Loss: 0.6493905782699585, Lr:0.0001\n",
      "Epoch 21, Step: 35, Loss: 0.3870205879211426, Lr:0.0001\n",
      "Epoch 21, Step: 36, Loss: 0.7790250778198242, Lr:0.0001\n",
      "Epoch 21, Step: 37, Loss: 0.09727845340967178, Lr:0.0001\n",
      "Epoch 21, Step: 38, Loss: 0.04033757373690605, Lr:0.0001\n",
      "Epoch 21, Step: 39, Loss: 0.31603342294692993, Lr:0.0001\n",
      "Epoch 21, Step: 40, Loss: 0.17595629394054413, Lr:0.0001\n",
      "Epoch 21, Step: 41, Loss: 0.525798499584198, Lr:0.0001\n",
      "Epoch 21, Step: 42, Loss: 1.2214381694793701, Lr:0.0001\n",
      "Epoch 21, Step: 43, Loss: 0.0875127762556076, Lr:0.0001\n",
      "Epoch 21, Step: 44, Loss: 0.9177716970443726, Lr:0.0001\n",
      "Epoch 21, Step: 45, Loss: 0.3467889726161957, Lr:0.0001\n",
      "Epoch 21, Step: 46, Loss: 0.42553049325942993, Lr:0.0001\n",
      "Epoch 21, Step: 47, Loss: 0.6946769952774048, Lr:0.0001\n",
      "Epoch 21, Step: 48, Loss: 0.03868837282061577, Lr:0.0001\n",
      "Epoch 21, Step: 49, Loss: 0.30999845266342163, Lr:0.0001\n",
      "Epoch 21, Step: 50, Loss: 0.4880293607711792, Lr:0.0001\n",
      "Epoch 21, Step: 51, Loss: 0.7949539422988892, Lr:0.0001\n",
      "Epoch 21, Step: 52, Loss: 0.8530998229980469, Lr:0.0001\n",
      "Epoch 21, Step: 53, Loss: 0.3016867935657501, Lr:0.0001\n",
      "Epoch 21, Step: 54, Loss: 0.21803312003612518, Lr:0.0001\n",
      "Epoch 21, Step: 55, Loss: 0.39542850852012634, Lr:0.0001\n",
      "Epoch 21, Step: 56, Loss: 0.5276501774787903, Lr:0.0001\n",
      "Epoch 21, Step: 57, Loss: 0.7160574197769165, Lr:0.0001\n",
      "Epoch 21, Step: 58, Loss: 0.4655191898345947, Lr:0.0001\n",
      "Epoch 21, Step: 59, Loss: 0.03222177177667618, Lr:0.0001\n",
      "Epoch 21, Step: 60, Loss: 0.34963715076446533, Lr:0.0001\n",
      "Epoch 21, Step: 61, Loss: 1.4148465394973755, Lr:0.0001\n",
      "Epoch 21, Step: 62, Loss: 0.46927863359451294, Lr:0.0001\n",
      "Epoch 21, Step: 63, Loss: 0.823737621307373, Lr:0.0001\n",
      "Epoch 21, Step: 64, Loss: 0.532550036907196, Lr:0.0001\n",
      "Epoch 21, Step: 65, Loss: 0.10130101442337036, Lr:0.0001\n",
      "Epoch 21, Step: 66, Loss: 0.6497235298156738, Lr:0.0001\n",
      "Epoch 21, Step: 67, Loss: 1.0264480113983154, Lr:0.0001\n",
      "Epoch 21, Step: 68, Loss: 0.14771100878715515, Lr:0.0001\n",
      "Epoch 21, Step: 69, Loss: 0.44653236865997314, Lr:0.0001\n",
      "Epoch 21, Step: 70, Loss: 0.47776758670806885, Lr:0.0001\n",
      "Epoch 21, Step: 71, Loss: 0.6603410243988037, Lr:0.0001\n",
      "Epoch 21, Step: 72, Loss: 0.5966750979423523, Lr:0.0001\n",
      "Epoch 21, Step: 73, Loss: 0.9595521092414856, Lr:0.0001\n",
      "Epoch 21, Step: 74, Loss: 0.2914735674858093, Lr:0.0001\n",
      "Epoch 21, Step: 75, Loss: 0.17355209589004517, Lr:0.0001\n",
      "Epoch 21, Step: 76, Loss: 0.7951569557189941, Lr:0.0001\n",
      "Epoch 21, Step: 77, Loss: 0.9334373474121094, Lr:0.0001\n",
      "Epoch 21, Step: 78, Loss: 0.7063769698143005, Lr:0.0001\n",
      "Epoch 21, Step: 79, Loss: 0.2587053179740906, Lr:0.0001\n",
      "Epoch 21, Step: 80, Loss: 1.182831883430481, Lr:0.0001\n",
      "Epoch 21, Step: 81, Loss: 0.9547695517539978, Lr:0.0001\n",
      "Epoch 21, Step: 82, Loss: 0.18630273640155792, Lr:0.0001\n",
      "Epoch 21, Step: 83, Loss: 1.257932186126709, Lr:0.0001\n",
      "Epoch 21, Step: 84, Loss: 0.25028836727142334, Lr:0.0001\n",
      "Epoch 21, Step: 85, Loss: 0.29471102356910706, Lr:0.0001\n",
      "Epoch 21, Step: 86, Loss: 0.12916067242622375, Lr:0.0001\n",
      "Epoch 21, Step: 87, Loss: 0.3168545365333557, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 21\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.5243 (0.5243) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.5243 (0.7053) acc1: 75.0000 (77.2727) acc5: 100.0000 (100.0000) time: 0.0071 data: 0.0037 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0071 s / it)\n",
      "* Acc@1 77.273 Acc@5 100.000 loss 0.705\n",
      "Accuracy of the network on the 22 test image: 77.3%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 22, Step: 0, Loss: 0.19722318649291992, Lr:0.0001\n",
      "Epoch 22, Step: 1, Loss: 0.13841700553894043, Lr:0.0001\n",
      "Epoch 22, Step: 2, Loss: 0.423734575510025, Lr:0.0001\n",
      "Epoch 22, Step: 3, Loss: 0.05418091267347336, Lr:0.0001\n",
      "Epoch 22, Step: 4, Loss: 0.47884601354599, Lr:0.0001\n",
      "Epoch 22, Step: 5, Loss: 0.2644372284412384, Lr:0.0001\n",
      "Epoch 22, Step: 6, Loss: 1.164013147354126, Lr:0.0001\n",
      "Epoch 22, Step: 7, Loss: 0.3802608251571655, Lr:0.0001\n",
      "Epoch 22, Step: 8, Loss: 0.5953614115715027, Lr:0.0001\n",
      "Epoch 22, Step: 9, Loss: 0.3810303509235382, Lr:0.0001\n",
      "Epoch 22, Step: 10, Loss: 0.1818096786737442, Lr:0.0001\n",
      "Epoch 22, Step: 11, Loss: 0.5122492909431458, Lr:0.0001\n",
      "Epoch 22, Step: 12, Loss: 1.0219662189483643, Lr:0.0001\n",
      "Epoch 22, Step: 13, Loss: 0.31810230016708374, Lr:0.0001\n",
      "Epoch 22, Step: 14, Loss: 0.6896823644638062, Lr:0.0001\n",
      "Epoch 22, Step: 15, Loss: 0.048485562205314636, Lr:0.0001\n",
      "Epoch 22, Step: 16, Loss: 0.24056819081306458, Lr:0.0001\n",
      "Epoch 22, Step: 17, Loss: 0.5359638333320618, Lr:0.0001\n",
      "Epoch 22, Step: 18, Loss: 0.14816883206367493, Lr:0.0001\n",
      "Epoch 22, Step: 19, Loss: 0.8655972480773926, Lr:0.0001\n",
      "Epoch 22, Step: 20, Loss: 0.4040094316005707, Lr:0.0001\n",
      "Epoch 22, Step: 21, Loss: 0.6499917507171631, Lr:0.0001\n",
      "Epoch 22, Step: 22, Loss: 0.5600735545158386, Lr:0.0001\n",
      "Epoch 22, Step: 23, Loss: 0.3837822675704956, Lr:0.0001\n",
      "Epoch 22, Step: 24, Loss: 0.04878160357475281, Lr:0.0001\n",
      "Epoch 22, Step: 25, Loss: 1.3508983850479126, Lr:0.0001\n",
      "Epoch 22, Step: 26, Loss: 1.5422993898391724, Lr:0.0001\n",
      "Epoch 22, Step: 27, Loss: 1.2776572704315186, Lr:0.0001\n",
      "Epoch 22, Step: 28, Loss: 0.297838032245636, Lr:0.0001\n",
      "Epoch 22, Step: 29, Loss: 1.12026047706604, Lr:0.0001\n",
      "Epoch 22, Step: 30, Loss: 0.08788195997476578, Lr:0.0001\n",
      "Epoch 22, Step: 31, Loss: 0.12338285148143768, Lr:0.0001\n",
      "Epoch 22, Step: 32, Loss: 0.3182576894760132, Lr:0.0001\n",
      "Epoch 22, Step: 33, Loss: 0.10143862664699554, Lr:0.0001\n",
      "Epoch 22, Step: 34, Loss: 0.4942127466201782, Lr:0.0001\n",
      "Epoch 22, Step: 35, Loss: 0.02412387914955616, Lr:0.0001\n",
      "Epoch 22, Step: 36, Loss: 0.335040420293808, Lr:0.0001\n",
      "Epoch 22, Step: 37, Loss: 0.7617864608764648, Lr:0.0001\n",
      "Epoch 22, Step: 38, Loss: 1.3409221172332764, Lr:0.0001\n",
      "Epoch 22, Step: 39, Loss: 0.030256666243076324, Lr:0.0001\n",
      "Epoch 22, Step: 40, Loss: 0.27933451533317566, Lr:0.0001\n",
      "Epoch 22, Step: 41, Loss: 0.15912280976772308, Lr:0.0001\n",
      "Epoch 22, Step: 42, Loss: 1.0109803676605225, Lr:0.0001\n",
      "Epoch 22, Step: 43, Loss: 0.9491670727729797, Lr:0.0001\n",
      "Epoch 22, Step: 44, Loss: 0.5741963982582092, Lr:0.0001\n",
      "Epoch 22, Step: 45, Loss: 0.6124963760375977, Lr:0.0001\n",
      "Epoch 22, Step: 46, Loss: 0.0569586381316185, Lr:0.0001\n",
      "Epoch 22, Step: 47, Loss: 0.17589516937732697, Lr:0.0001\n",
      "Epoch 22, Step: 48, Loss: 0.6715992093086243, Lr:0.0001\n",
      "Epoch 22, Step: 49, Loss: 0.07159148156642914, Lr:0.0001\n",
      "Epoch 22, Step: 50, Loss: 1.8574711084365845, Lr:0.0001\n",
      "Epoch 22, Step: 51, Loss: 0.133188858628273, Lr:0.0001\n",
      "Epoch 22, Step: 52, Loss: 0.4660946726799011, Lr:0.0001\n",
      "Epoch 22, Step: 53, Loss: 0.6179047226905823, Lr:0.0001\n",
      "Epoch 22, Step: 54, Loss: 0.3918197751045227, Lr:0.0001\n",
      "Epoch 22, Step: 55, Loss: 0.09430087357759476, Lr:0.0001\n",
      "Epoch 22, Step: 56, Loss: 0.3193529546260834, Lr:0.0001\n",
      "Epoch 22, Step: 57, Loss: 0.07370726764202118, Lr:0.0001\n",
      "Epoch 22, Step: 58, Loss: 0.19321906566619873, Lr:0.0001\n",
      "Epoch 22, Step: 59, Loss: 0.39483001828193665, Lr:0.0001\n",
      "Epoch 22, Step: 60, Loss: 0.08112293481826782, Lr:0.0001\n",
      "Epoch 22, Step: 61, Loss: 0.4607980251312256, Lr:0.0001\n",
      "Epoch 22, Step: 62, Loss: 0.6998973488807678, Lr:0.0001\n",
      "Epoch 22, Step: 63, Loss: 0.06240092217922211, Lr:0.0001\n",
      "Epoch 22, Step: 64, Loss: 0.45874354243278503, Lr:0.0001\n",
      "Epoch 22, Step: 65, Loss: 3.0962228775024414, Lr:0.0001\n",
      "Epoch 22, Step: 66, Loss: 0.05256303399801254, Lr:0.0001\n",
      "Epoch 22, Step: 67, Loss: 0.324667364358902, Lr:0.0001\n",
      "Epoch 22, Step: 68, Loss: 0.32524216175079346, Lr:0.0001\n",
      "Epoch 22, Step: 69, Loss: 0.04509393498301506, Lr:0.0001\n",
      "Epoch 22, Step: 70, Loss: 0.09718617796897888, Lr:0.0001\n",
      "Epoch 22, Step: 71, Loss: 0.06645337492227554, Lr:0.0001\n",
      "Epoch 22, Step: 72, Loss: 0.44997918605804443, Lr:0.0001\n",
      "Epoch 22, Step: 73, Loss: 0.6153070330619812, Lr:0.0001\n",
      "Epoch 22, Step: 74, Loss: 0.4948270320892334, Lr:0.0001\n",
      "Epoch 22, Step: 75, Loss: 0.18108008801937103, Lr:0.0001\n",
      "Epoch 22, Step: 76, Loss: 0.7471199631690979, Lr:0.0001\n",
      "Epoch 22, Step: 77, Loss: 0.5535672903060913, Lr:0.0001\n",
      "Epoch 22, Step: 78, Loss: 0.1712280660867691, Lr:0.0001\n",
      "Epoch 22, Step: 79, Loss: 0.3172535002231598, Lr:0.0001\n",
      "Epoch 22, Step: 80, Loss: 0.056970469653606415, Lr:0.0001\n",
      "Epoch 22, Step: 81, Loss: 0.9518568515777588, Lr:0.0001\n",
      "Epoch 22, Step: 82, Loss: 0.7792308926582336, Lr:0.0001\n",
      "Epoch 22, Step: 83, Loss: 0.20482973754405975, Lr:0.0001\n",
      "Epoch 22, Step: 84, Loss: 0.9705529808998108, Lr:0.0001\n",
      "Epoch 22, Step: 85, Loss: 0.7602777481079102, Lr:0.0001\n",
      "Epoch 22, Step: 86, Loss: 1.2339146137237549, Lr:0.0001\n",
      "Epoch 22, Step: 87, Loss: 2.4786343574523926, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 22\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.0279 (0.0279) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.0279 (0.4694) acc1: 100.0000 (86.3636) acc5: 100.0000 (100.0000) time: 0.0067 data: 0.0035 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0068 s / it)\n",
      "* Acc@1 86.364 Acc@5 100.000 loss 0.469\n",
      "Accuracy of the network on the 22 test image: 86.4%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 23, Step: 0, Loss: 0.4377925395965576, Lr:0.0001\n",
      "Epoch 23, Step: 1, Loss: 0.10196191817522049, Lr:0.0001\n",
      "Epoch 23, Step: 2, Loss: 1.1624259948730469, Lr:0.0001\n",
      "Epoch 23, Step: 3, Loss: 0.3260118067264557, Lr:0.0001\n",
      "Epoch 23, Step: 4, Loss: 0.24277473986148834, Lr:0.0001\n",
      "Epoch 23, Step: 5, Loss: 0.20058439671993256, Lr:0.0001\n",
      "Epoch 23, Step: 6, Loss: 1.1938934326171875, Lr:0.0001\n",
      "Epoch 23, Step: 7, Loss: 0.5520228147506714, Lr:0.0001\n",
      "Epoch 23, Step: 8, Loss: 0.7363452315330505, Lr:0.0001\n",
      "Epoch 23, Step: 9, Loss: 0.09109799563884735, Lr:0.0001\n",
      "Epoch 23, Step: 10, Loss: 0.3242068886756897, Lr:0.0001\n",
      "Epoch 23, Step: 11, Loss: 0.21630007028579712, Lr:0.0001\n",
      "Epoch 23, Step: 12, Loss: 1.2025837898254395, Lr:0.0001\n",
      "Epoch 23, Step: 13, Loss: 0.3486994504928589, Lr:0.0001\n",
      "Epoch 23, Step: 14, Loss: 1.0559848546981812, Lr:0.0001\n",
      "Epoch 23, Step: 15, Loss: 0.9225762486457825, Lr:0.0001\n",
      "Epoch 23, Step: 16, Loss: 0.3157585859298706, Lr:0.0001\n",
      "Epoch 23, Step: 17, Loss: 0.27656981348991394, Lr:0.0001\n",
      "Epoch 23, Step: 18, Loss: 0.06141865998506546, Lr:0.0001\n",
      "Epoch 23, Step: 19, Loss: 0.6908851265907288, Lr:0.0001\n",
      "Epoch 23, Step: 20, Loss: 0.5544885396957397, Lr:0.0001\n",
      "Epoch 23, Step: 21, Loss: 0.8135440349578857, Lr:0.0001\n",
      "Epoch 23, Step: 22, Loss: 0.8322896957397461, Lr:0.0001\n",
      "Epoch 23, Step: 23, Loss: 0.44209426641464233, Lr:0.0001\n",
      "Epoch 23, Step: 24, Loss: 0.03241746127605438, Lr:0.0001\n",
      "Epoch 23, Step: 25, Loss: 0.37098395824432373, Lr:0.0001\n",
      "Epoch 23, Step: 26, Loss: 0.51388019323349, Lr:0.0001\n",
      "Epoch 23, Step: 27, Loss: 0.11183325946331024, Lr:0.0001\n",
      "Epoch 23, Step: 28, Loss: 0.02910001389682293, Lr:0.0001\n",
      "Epoch 23, Step: 29, Loss: 0.09732969105243683, Lr:0.0001\n",
      "Epoch 23, Step: 30, Loss: 0.4715003967285156, Lr:0.0001\n",
      "Epoch 23, Step: 31, Loss: 0.29320481419563293, Lr:0.0001\n",
      "Epoch 23, Step: 32, Loss: 0.4830927550792694, Lr:0.0001\n",
      "Epoch 23, Step: 33, Loss: 1.2217614650726318, Lr:0.0001\n",
      "Epoch 23, Step: 34, Loss: 0.3011011779308319, Lr:0.0001\n",
      "Epoch 23, Step: 35, Loss: 0.07441848516464233, Lr:0.0001\n",
      "Epoch 23, Step: 36, Loss: 0.04698104038834572, Lr:0.0001\n",
      "Epoch 23, Step: 37, Loss: 0.06526575237512589, Lr:0.0001\n",
      "Epoch 23, Step: 38, Loss: 1.1783778667449951, Lr:0.0001\n",
      "Epoch 23, Step: 39, Loss: 0.6791538596153259, Lr:0.0001\n",
      "Epoch 23, Step: 40, Loss: 0.8053759336471558, Lr:0.0001\n",
      "Epoch 23, Step: 41, Loss: 0.1222684383392334, Lr:0.0001\n",
      "Epoch 23, Step: 42, Loss: 0.47283798456192017, Lr:0.0001\n",
      "Epoch 23, Step: 43, Loss: 0.25049716234207153, Lr:0.0001\n",
      "Epoch 23, Step: 44, Loss: 0.2674245834350586, Lr:0.0001\n",
      "Epoch 23, Step: 45, Loss: 0.8335606455802917, Lr:0.0001\n",
      "Epoch 23, Step: 46, Loss: 0.5761816501617432, Lr:0.0001\n",
      "Epoch 23, Step: 47, Loss: 0.0211492870002985, Lr:0.0001\n",
      "Epoch 23, Step: 48, Loss: 0.33646947145462036, Lr:0.0001\n",
      "Epoch 23, Step: 49, Loss: 0.24527469277381897, Lr:0.0001\n",
      "Epoch 23, Step: 50, Loss: 0.14919304847717285, Lr:0.0001\n",
      "Epoch 23, Step: 51, Loss: 0.35949844121932983, Lr:0.0001\n",
      "Epoch 23, Step: 52, Loss: 0.730213463306427, Lr:0.0001\n",
      "Epoch 23, Step: 53, Loss: 0.3319820761680603, Lr:0.0001\n",
      "Epoch 23, Step: 54, Loss: 0.27719828486442566, Lr:0.0001\n",
      "Epoch 23, Step: 55, Loss: 0.9516531825065613, Lr:0.0001\n",
      "Epoch 23, Step: 56, Loss: 0.016316542401909828, Lr:0.0001\n",
      "Epoch 23, Step: 57, Loss: 0.05725627765059471, Lr:0.0001\n",
      "Epoch 23, Step: 58, Loss: 0.4094115197658539, Lr:0.0001\n",
      "Epoch 23, Step: 59, Loss: 0.12912319600582123, Lr:0.0001\n",
      "Epoch 23, Step: 60, Loss: 0.14592520892620087, Lr:0.0001\n",
      "Epoch 23, Step: 61, Loss: 0.008097241632640362, Lr:0.0001\n",
      "Epoch 23, Step: 62, Loss: 0.3429012894630432, Lr:0.0001\n",
      "Epoch 23, Step: 63, Loss: 0.7692468166351318, Lr:0.0001\n",
      "Epoch 23, Step: 64, Loss: 0.4826696813106537, Lr:0.0001\n",
      "Epoch 23, Step: 65, Loss: 0.3430517017841339, Lr:0.0001\n",
      "Epoch 23, Step: 66, Loss: 0.24579642713069916, Lr:0.0001\n",
      "Epoch 23, Step: 67, Loss: 0.009521150030195713, Lr:0.0001\n",
      "Epoch 23, Step: 68, Loss: 0.6520019173622131, Lr:0.0001\n",
      "Epoch 23, Step: 69, Loss: 0.27737048268318176, Lr:0.0001\n",
      "Epoch 23, Step: 70, Loss: 0.520500659942627, Lr:0.0001\n",
      "Epoch 23, Step: 71, Loss: 1.0916659832000732, Lr:0.0001\n",
      "Epoch 23, Step: 72, Loss: 0.017108125612139702, Lr:0.0001\n",
      "Epoch 23, Step: 73, Loss: 0.015307311899960041, Lr:0.0001\n",
      "Epoch 23, Step: 74, Loss: 3.2384464740753174, Lr:0.0001\n",
      "Epoch 23, Step: 75, Loss: 1.4459476470947266, Lr:0.0001\n",
      "Epoch 23, Step: 76, Loss: 0.36752694845199585, Lr:0.0001\n",
      "Epoch 23, Step: 77, Loss: 0.6917475461959839, Lr:0.0001\n",
      "Epoch 23, Step: 78, Loss: 0.35710999369621277, Lr:0.0001\n",
      "Epoch 23, Step: 79, Loss: 0.03144457936286926, Lr:0.0001\n",
      "Epoch 23, Step: 80, Loss: 0.6024705171585083, Lr:0.0001\n",
      "Epoch 23, Step: 81, Loss: 0.996030330657959, Lr:0.0001\n",
      "Epoch 23, Step: 82, Loss: 0.5564838647842407, Lr:0.0001\n",
      "Epoch 23, Step: 83, Loss: 0.7316886186599731, Lr:0.0001\n",
      "Epoch 23, Step: 84, Loss: 0.5481665730476379, Lr:0.0001\n",
      "Epoch 23, Step: 85, Loss: 0.042172543704509735, Lr:0.0001\n",
      "Epoch 23, Step: 86, Loss: 0.3251245319843292, Lr:0.0001\n",
      "Epoch 23, Step: 87, Loss: 0.4071281850337982, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 23\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.0239 (0.0239) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0080 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.0320 (0.3597) acc1: 100.0000 (86.3636) acc5: 100.0000 (100.0000) time: 0.0067 data: 0.0037 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0068 s / it)\n",
      "* Acc@1 86.364 Acc@5 100.000 loss 0.360\n",
      "Accuracy of the network on the 22 test image: 86.4%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 24, Step: 0, Loss: 0.3373778462409973, Lr:0.0001\n",
      "Epoch 24, Step: 1, Loss: 0.32186636328697205, Lr:0.0001\n",
      "Epoch 24, Step: 2, Loss: 0.5945903062820435, Lr:0.0001\n",
      "Epoch 24, Step: 3, Loss: 0.528282105922699, Lr:0.0001\n",
      "Epoch 24, Step: 4, Loss: 0.6846636533737183, Lr:0.0001\n",
      "Epoch 24, Step: 5, Loss: 0.3905749022960663, Lr:0.0001\n",
      "Epoch 24, Step: 6, Loss: 0.4693950414657593, Lr:0.0001\n",
      "Epoch 24, Step: 7, Loss: 3.9656548500061035, Lr:0.0001\n",
      "Epoch 24, Step: 8, Loss: 0.5196419954299927, Lr:0.0001\n",
      "Epoch 24, Step: 9, Loss: 0.3360764682292938, Lr:0.0001\n",
      "Epoch 24, Step: 10, Loss: 0.29509294033050537, Lr:0.0001\n",
      "Epoch 24, Step: 11, Loss: 0.353930801153183, Lr:0.0001\n",
      "Epoch 24, Step: 12, Loss: 0.05414258688688278, Lr:0.0001\n",
      "Epoch 24, Step: 13, Loss: 0.5901058912277222, Lr:0.0001\n",
      "Epoch 24, Step: 14, Loss: 0.23750117421150208, Lr:0.0001\n",
      "Epoch 24, Step: 15, Loss: 0.4924842119216919, Lr:0.0001\n",
      "Epoch 24, Step: 16, Loss: 0.3324761986732483, Lr:0.0001\n",
      "Epoch 24, Step: 17, Loss: 0.11721376329660416, Lr:0.0001\n",
      "Epoch 24, Step: 18, Loss: 0.7458938360214233, Lr:0.0001\n",
      "Epoch 24, Step: 19, Loss: 0.7971056699752808, Lr:0.0001\n",
      "Epoch 24, Step: 20, Loss: 0.25770166516304016, Lr:0.0001\n",
      "Epoch 24, Step: 21, Loss: 0.6781958937644958, Lr:0.0001\n",
      "Epoch 24, Step: 22, Loss: 0.28623107075691223, Lr:0.0001\n",
      "Epoch 24, Step: 23, Loss: 0.5125530958175659, Lr:0.0001\n",
      "Epoch 24, Step: 24, Loss: 0.03477557748556137, Lr:0.0001\n",
      "Epoch 24, Step: 25, Loss: 0.5694414377212524, Lr:0.0001\n",
      "Epoch 24, Step: 26, Loss: 0.5861533284187317, Lr:0.0001\n",
      "Epoch 24, Step: 27, Loss: 0.7623844146728516, Lr:0.0001\n",
      "Epoch 24, Step: 28, Loss: 0.3126787543296814, Lr:0.0001\n",
      "Epoch 24, Step: 29, Loss: 0.5208622217178345, Lr:0.0001\n",
      "Epoch 24, Step: 30, Loss: 0.11316773295402527, Lr:0.0001\n",
      "Epoch 24, Step: 31, Loss: 0.345466673374176, Lr:0.0001\n",
      "Epoch 24, Step: 32, Loss: 0.5366925597190857, Lr:0.0001\n",
      "Epoch 24, Step: 33, Loss: 0.6185654401779175, Lr:0.0001\n",
      "Epoch 24, Step: 34, Loss: 0.6605249643325806, Lr:0.0001\n",
      "Epoch 24, Step: 35, Loss: 0.14500252902507782, Lr:0.0001\n",
      "Epoch 24, Step: 36, Loss: 0.06705640256404877, Lr:0.0001\n",
      "Epoch 24, Step: 37, Loss: 0.7322987914085388, Lr:0.0001\n",
      "Epoch 24, Step: 38, Loss: 0.058279410004615784, Lr:0.0001\n",
      "Epoch 24, Step: 39, Loss: 0.21269623935222626, Lr:0.0001\n",
      "Epoch 24, Step: 40, Loss: 0.20371289551258087, Lr:0.0001\n",
      "Epoch 24, Step: 41, Loss: 2.4127283096313477, Lr:0.0001\n",
      "Epoch 24, Step: 42, Loss: 0.4943689703941345, Lr:0.0001\n",
      "Epoch 24, Step: 43, Loss: 0.4556782841682434, Lr:0.0001\n",
      "Epoch 24, Step: 44, Loss: 0.026517469435930252, Lr:0.0001\n",
      "Epoch 24, Step: 45, Loss: 1.2830899953842163, Lr:0.0001\n",
      "Epoch 24, Step: 46, Loss: 1.5036922693252563, Lr:0.0001\n",
      "Epoch 24, Step: 47, Loss: 0.6532491445541382, Lr:0.0001\n",
      "Epoch 24, Step: 48, Loss: 0.6885309815406799, Lr:0.0001\n",
      "Epoch 24, Step: 49, Loss: 0.2902182936668396, Lr:0.0001\n",
      "Epoch 24, Step: 50, Loss: 0.36009490489959717, Lr:0.0001\n",
      "Epoch 24, Step: 51, Loss: 0.34522995352745056, Lr:0.0001\n",
      "Epoch 24, Step: 52, Loss: 0.31718993186950684, Lr:0.0001\n",
      "Epoch 24, Step: 53, Loss: 0.22602982819080353, Lr:0.0001\n",
      "Epoch 24, Step: 54, Loss: 0.7322288155555725, Lr:0.0001\n",
      "Epoch 24, Step: 55, Loss: 0.4280761182308197, Lr:0.0001\n",
      "Epoch 24, Step: 56, Loss: 0.45894894003868103, Lr:0.0001\n",
      "Epoch 24, Step: 57, Loss: 0.4274229109287262, Lr:0.0001\n",
      "Epoch 24, Step: 58, Loss: 0.1840866357088089, Lr:0.0001\n",
      "Epoch 24, Step: 59, Loss: 0.4319041669368744, Lr:0.0001\n",
      "Epoch 24, Step: 60, Loss: 0.2568761110305786, Lr:0.0001\n",
      "Epoch 24, Step: 61, Loss: 0.185359388589859, Lr:0.0001\n",
      "Epoch 24, Step: 62, Loss: 1.5668907165527344, Lr:0.0001\n",
      "Epoch 24, Step: 63, Loss: 0.1466694474220276, Lr:0.0001\n",
      "Epoch 24, Step: 64, Loss: 0.4212053120136261, Lr:0.0001\n",
      "Epoch 24, Step: 65, Loss: 0.03742501139640808, Lr:0.0001\n",
      "Epoch 24, Step: 66, Loss: 0.8214248418807983, Lr:0.0001\n",
      "Epoch 24, Step: 67, Loss: 0.6918739676475525, Lr:0.0001\n",
      "Epoch 24, Step: 68, Loss: 0.6055534482002258, Lr:0.0001\n",
      "Epoch 24, Step: 69, Loss: 0.14749163389205933, Lr:0.0001\n",
      "Epoch 24, Step: 70, Loss: 0.21919649839401245, Lr:0.0001\n",
      "Epoch 24, Step: 71, Loss: 0.44605404138565063, Lr:0.0001\n",
      "Epoch 24, Step: 72, Loss: 0.7684757709503174, Lr:0.0001\n",
      "Epoch 24, Step: 73, Loss: 0.5934594869613647, Lr:0.0001\n",
      "Epoch 24, Step: 74, Loss: 0.2545640468597412, Lr:0.0001\n",
      "Epoch 24, Step: 75, Loss: 1.0652660131454468, Lr:0.0001\n",
      "Epoch 24, Step: 76, Loss: 0.08079648017883301, Lr:0.0001\n",
      "Epoch 24, Step: 77, Loss: 0.24421551823616028, Lr:0.0001\n",
      "Epoch 24, Step: 78, Loss: 0.14375941455364227, Lr:0.0001\n",
      "Epoch 24, Step: 79, Loss: 2.8152263164520264, Lr:0.0001\n",
      "Epoch 24, Step: 80, Loss: 0.9526777863502502, Lr:0.0001\n",
      "Epoch 24, Step: 81, Loss: 1.4475268125534058, Lr:0.0001\n",
      "Epoch 24, Step: 82, Loss: 0.4186277687549591, Lr:0.0001\n",
      "Epoch 24, Step: 83, Loss: 0.400452196598053, Lr:0.0001\n",
      "Epoch 24, Step: 84, Loss: 1.1347272396087646, Lr:0.0001\n",
      "Epoch 24, Step: 85, Loss: 0.5997405052185059, Lr:0.0001\n",
      "Epoch 24, Step: 86, Loss: 0.43658509850502014, Lr:0.0001\n",
      "Epoch 24, Step: 87, Loss: 0.2187197059392929, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 24\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.1225 (0.1225) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.1225 (0.7107) acc1: 75.0000 (77.2727) acc5: 100.0000 (100.0000) time: 0.0078 data: 0.0037 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0078 s / it)\n",
      "* Acc@1 77.273 Acc@5 100.000 loss 0.711\n",
      "Accuracy of the network on the 22 test image: 77.3%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 25, Step: 0, Loss: 1.6385225057601929, Lr:0.0001\n",
      "Epoch 25, Step: 1, Loss: 0.48411333560943604, Lr:0.0001\n",
      "Epoch 25, Step: 2, Loss: 0.661780834197998, Lr:0.0001\n",
      "Epoch 25, Step: 3, Loss: 0.8099972009658813, Lr:0.0001\n",
      "Epoch 25, Step: 4, Loss: 0.7466967701911926, Lr:0.0001\n",
      "Epoch 25, Step: 5, Loss: 0.9804917573928833, Lr:0.0001\n",
      "Epoch 25, Step: 6, Loss: 0.043707676231861115, Lr:0.0001\n",
      "Epoch 25, Step: 7, Loss: 0.02754170447587967, Lr:0.0001\n",
      "Epoch 25, Step: 8, Loss: 0.6043897271156311, Lr:0.0001\n",
      "Epoch 25, Step: 9, Loss: 0.09730905294418335, Lr:0.0001\n",
      "Epoch 25, Step: 10, Loss: 0.29451072216033936, Lr:0.0001\n",
      "Epoch 25, Step: 11, Loss: 0.2775312662124634, Lr:0.0001\n",
      "Epoch 25, Step: 12, Loss: 0.321551650762558, Lr:0.0001\n",
      "Epoch 25, Step: 13, Loss: 1.3078887462615967, Lr:0.0001\n",
      "Epoch 25, Step: 14, Loss: 0.21446837484836578, Lr:0.0001\n",
      "Epoch 25, Step: 15, Loss: 0.03770000860095024, Lr:0.0001\n",
      "Epoch 25, Step: 16, Loss: 0.16249483823776245, Lr:0.0001\n",
      "Epoch 25, Step: 17, Loss: 0.06177188456058502, Lr:0.0001\n",
      "Epoch 25, Step: 18, Loss: 0.05079210177063942, Lr:0.0001\n",
      "Epoch 25, Step: 19, Loss: 0.1887030154466629, Lr:0.0001\n",
      "Epoch 25, Step: 20, Loss: 1.1479527950286865, Lr:0.0001\n",
      "Epoch 25, Step: 21, Loss: 0.018169375136494637, Lr:0.0001\n",
      "Epoch 25, Step: 22, Loss: 0.4192909598350525, Lr:0.0001\n",
      "Epoch 25, Step: 23, Loss: 0.7726975083351135, Lr:0.0001\n",
      "Epoch 25, Step: 24, Loss: 0.11731249839067459, Lr:0.0001\n",
      "Epoch 25, Step: 25, Loss: 0.37709057331085205, Lr:0.0001\n",
      "Epoch 25, Step: 26, Loss: 0.2538549304008484, Lr:0.0001\n",
      "Epoch 25, Step: 27, Loss: 0.3913612365722656, Lr:0.0001\n",
      "Epoch 25, Step: 28, Loss: 1.0397515296936035, Lr:0.0001\n",
      "Epoch 25, Step: 29, Loss: 0.8242346048355103, Lr:0.0001\n",
      "Epoch 25, Step: 30, Loss: 0.32730236649513245, Lr:0.0001\n",
      "Epoch 25, Step: 31, Loss: 0.421802282333374, Lr:0.0001\n",
      "Epoch 25, Step: 32, Loss: 0.6039908528327942, Lr:0.0001\n",
      "Epoch 25, Step: 33, Loss: 0.5175032019615173, Lr:0.0001\n",
      "Epoch 25, Step: 34, Loss: 0.0454338937997818, Lr:0.0001\n",
      "Epoch 25, Step: 35, Loss: 0.28246280550956726, Lr:0.0001\n",
      "Epoch 25, Step: 36, Loss: 0.8560894727706909, Lr:0.0001\n",
      "Epoch 25, Step: 37, Loss: 0.934819221496582, Lr:0.0001\n",
      "Epoch 25, Step: 38, Loss: 0.9994249939918518, Lr:0.0001\n",
      "Epoch 25, Step: 39, Loss: 0.36954957246780396, Lr:0.0001\n",
      "Epoch 25, Step: 40, Loss: 0.3803871273994446, Lr:0.0001\n",
      "Epoch 25, Step: 41, Loss: 0.382976233959198, Lr:0.0001\n",
      "Epoch 25, Step: 42, Loss: 1.0936191082000732, Lr:0.0001\n",
      "Epoch 25, Step: 43, Loss: 0.1922476440668106, Lr:0.0001\n",
      "Epoch 25, Step: 44, Loss: 0.8740037083625793, Lr:0.0001\n",
      "Epoch 25, Step: 45, Loss: 0.22188490629196167, Lr:0.0001\n",
      "Epoch 25, Step: 46, Loss: 1.5631895065307617, Lr:0.0001\n",
      "Epoch 25, Step: 47, Loss: 0.3443698585033417, Lr:0.0001\n",
      "Epoch 25, Step: 48, Loss: 0.5333520174026489, Lr:0.0001\n",
      "Epoch 25, Step: 49, Loss: 0.10140176117420197, Lr:0.0001\n",
      "Epoch 25, Step: 50, Loss: 0.196904256939888, Lr:0.0001\n",
      "Epoch 25, Step: 51, Loss: 1.2817144393920898, Lr:0.0001\n",
      "Epoch 25, Step: 52, Loss: 0.03732559084892273, Lr:0.0001\n",
      "Epoch 25, Step: 53, Loss: 0.13489049673080444, Lr:0.0001\n",
      "Epoch 25, Step: 54, Loss: 0.7155800461769104, Lr:0.0001\n",
      "Epoch 25, Step: 55, Loss: 0.48389750719070435, Lr:0.0001\n",
      "Epoch 25, Step: 56, Loss: 0.04382654279470444, Lr:0.0001\n",
      "Epoch 25, Step: 57, Loss: 0.41751620173454285, Lr:0.0001\n",
      "Epoch 25, Step: 58, Loss: 0.7635988593101501, Lr:0.0001\n",
      "Epoch 25, Step: 59, Loss: 0.4102036952972412, Lr:0.0001\n",
      "Epoch 25, Step: 60, Loss: 0.110148124396801, Lr:0.0001\n",
      "Epoch 25, Step: 61, Loss: 0.6302069425582886, Lr:0.0001\n",
      "Epoch 25, Step: 62, Loss: 0.4313722252845764, Lr:0.0001\n",
      "Epoch 25, Step: 63, Loss: 1.240478754043579, Lr:0.0001\n",
      "Epoch 25, Step: 64, Loss: 0.503008246421814, Lr:0.0001\n",
      "Epoch 25, Step: 65, Loss: 0.39586082100868225, Lr:0.0001\n",
      "Epoch 25, Step: 66, Loss: 0.2927798628807068, Lr:0.0001\n",
      "Epoch 25, Step: 67, Loss: 0.05520932003855705, Lr:0.0001\n",
      "Epoch 25, Step: 68, Loss: 0.6623737812042236, Lr:0.0001\n",
      "Epoch 25, Step: 69, Loss: 0.5708179473876953, Lr:0.0001\n",
      "Epoch 25, Step: 70, Loss: 0.4562852382659912, Lr:0.0001\n",
      "Epoch 25, Step: 71, Loss: 0.44040337204933167, Lr:0.0001\n",
      "Epoch 25, Step: 72, Loss: 0.11906716227531433, Lr:0.0001\n",
      "Epoch 25, Step: 73, Loss: 0.5969127416610718, Lr:0.0001\n",
      "Epoch 25, Step: 74, Loss: 0.7075995206832886, Lr:0.0001\n",
      "Epoch 25, Step: 75, Loss: 0.4991447627544403, Lr:0.0001\n",
      "Epoch 25, Step: 76, Loss: 0.15962757170200348, Lr:0.0001\n",
      "Epoch 25, Step: 77, Loss: 0.338529109954834, Lr:0.0001\n",
      "Epoch 25, Step: 78, Loss: 0.8144906759262085, Lr:0.0001\n",
      "Epoch 25, Step: 79, Loss: 0.8190479278564453, Lr:0.0001\n",
      "Epoch 25, Step: 80, Loss: 0.3836202621459961, Lr:0.0001\n",
      "Epoch 25, Step: 81, Loss: 1.108920693397522, Lr:0.0001\n",
      "Epoch 25, Step: 82, Loss: 0.48759278655052185, Lr:0.0001\n",
      "Epoch 25, Step: 83, Loss: 0.029796406626701355, Lr:0.0001\n",
      "Epoch 25, Step: 84, Loss: 0.12187835574150085, Lr:0.0001\n",
      "Epoch 25, Step: 85, Loss: 1.119222640991211, Lr:0.0001\n",
      "Epoch 25, Step: 86, Loss: 0.09735740721225739, Lr:0.0001\n",
      "Epoch 25, Step: 87, Loss: 0.021371278911828995, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 25\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.2414 (0.2414) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0110 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.2910 (0.5010) acc1: 75.0000 (81.8182) acc5: 100.0000 (100.0000) time: 0.0093 data: 0.0042 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0093 s / it)\n",
      "* Acc@1 81.818 Acc@5 100.000 loss 0.501\n",
      "Accuracy of the network on the 22 test image: 81.8%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 26, Step: 0, Loss: 0.6582822799682617, Lr:0.0001\n",
      "Epoch 26, Step: 1, Loss: 0.42243438959121704, Lr:0.0001\n",
      "Epoch 26, Step: 2, Loss: 0.031830787658691406, Lr:0.0001\n",
      "Epoch 26, Step: 3, Loss: 0.03637705370783806, Lr:0.0001\n",
      "Epoch 26, Step: 4, Loss: 0.37519389390945435, Lr:0.0001\n",
      "Epoch 26, Step: 5, Loss: 0.9940242767333984, Lr:0.0001\n",
      "Epoch 26, Step: 6, Loss: 0.3932761549949646, Lr:0.0001\n",
      "Epoch 26, Step: 7, Loss: 0.5893787741661072, Lr:0.0001\n",
      "Epoch 26, Step: 8, Loss: 0.3630730211734772, Lr:0.0001\n",
      "Epoch 26, Step: 9, Loss: 0.6583051681518555, Lr:0.0001\n",
      "Epoch 26, Step: 10, Loss: 0.3301732540130615, Lr:0.0001\n",
      "Epoch 26, Step: 11, Loss: 0.6991976499557495, Lr:0.0001\n",
      "Epoch 26, Step: 12, Loss: 0.04957126826047897, Lr:0.0001\n",
      "Epoch 26, Step: 13, Loss: 0.1934286653995514, Lr:0.0001\n",
      "Epoch 26, Step: 14, Loss: 0.7113893628120422, Lr:0.0001\n",
      "Epoch 26, Step: 15, Loss: 0.18866215646266937, Lr:0.0001\n",
      "Epoch 26, Step: 16, Loss: 0.5469135642051697, Lr:0.0001\n",
      "Epoch 26, Step: 17, Loss: 0.3055090010166168, Lr:0.0001\n",
      "Epoch 26, Step: 18, Loss: 0.3402954041957855, Lr:0.0001\n",
      "Epoch 26, Step: 19, Loss: 0.13758589327335358, Lr:0.0001\n",
      "Epoch 26, Step: 20, Loss: 0.4469091594219208, Lr:0.0001\n",
      "Epoch 26, Step: 21, Loss: 0.5677616596221924, Lr:0.0001\n",
      "Epoch 26, Step: 22, Loss: 0.09419886767864227, Lr:0.0001\n",
      "Epoch 26, Step: 23, Loss: 0.09581561386585236, Lr:0.0001\n",
      "Epoch 26, Step: 24, Loss: 0.4488590359687805, Lr:0.0001\n",
      "Epoch 26, Step: 25, Loss: 0.6885002255439758, Lr:0.0001\n",
      "Epoch 26, Step: 26, Loss: 0.7959715127944946, Lr:0.0001\n",
      "Epoch 26, Step: 27, Loss: 0.30635008215904236, Lr:0.0001\n",
      "Epoch 26, Step: 28, Loss: 0.19873712956905365, Lr:0.0001\n",
      "Epoch 26, Step: 29, Loss: 0.4824395775794983, Lr:0.0001\n",
      "Epoch 26, Step: 30, Loss: 0.11841392517089844, Lr:0.0001\n",
      "Epoch 26, Step: 31, Loss: 0.07807281613349915, Lr:0.0001\n",
      "Epoch 26, Step: 32, Loss: 0.2046373188495636, Lr:0.0001\n",
      "Epoch 26, Step: 33, Loss: 0.9259158372879028, Lr:0.0001\n",
      "Epoch 26, Step: 34, Loss: 0.3274354934692383, Lr:0.0001\n",
      "Epoch 26, Step: 35, Loss: 0.23978489637374878, Lr:0.0001\n",
      "Epoch 26, Step: 36, Loss: 1.5561167001724243, Lr:0.0001\n",
      "Epoch 26, Step: 37, Loss: 0.289048969745636, Lr:0.0001\n",
      "Epoch 26, Step: 38, Loss: 0.3368077278137207, Lr:0.0001\n",
      "Epoch 26, Step: 39, Loss: 0.05480179190635681, Lr:0.0001\n",
      "Epoch 26, Step: 40, Loss: 0.4548943042755127, Lr:0.0001\n",
      "Epoch 26, Step: 41, Loss: 0.7596837282180786, Lr:0.0001\n",
      "Epoch 26, Step: 42, Loss: 0.19925951957702637, Lr:0.0001\n",
      "Epoch 26, Step: 43, Loss: 0.7372029423713684, Lr:0.0001\n",
      "Epoch 26, Step: 44, Loss: 0.31540632247924805, Lr:0.0001\n",
      "Epoch 26, Step: 45, Loss: 0.017313120886683464, Lr:0.0001\n",
      "Epoch 26, Step: 46, Loss: 0.3060271441936493, Lr:0.0001\n",
      "Epoch 26, Step: 47, Loss: 0.20510151982307434, Lr:0.0001\n",
      "Epoch 26, Step: 48, Loss: 0.33571839332580566, Lr:0.0001\n",
      "Epoch 26, Step: 49, Loss: 0.32421424984931946, Lr:0.0001\n",
      "Epoch 26, Step: 50, Loss: 0.7005786895751953, Lr:0.0001\n",
      "Epoch 26, Step: 51, Loss: 0.26344773173332214, Lr:0.0001\n",
      "Epoch 26, Step: 52, Loss: 0.029349273070693016, Lr:0.0001\n",
      "Epoch 26, Step: 53, Loss: 0.30682867765426636, Lr:0.0001\n",
      "Epoch 26, Step: 54, Loss: 0.017434027045965195, Lr:0.0001\n",
      "Epoch 26, Step: 55, Loss: 0.1207624077796936, Lr:0.0001\n",
      "Epoch 26, Step: 56, Loss: 0.8999127745628357, Lr:0.0001\n",
      "Epoch 26, Step: 57, Loss: 0.025851260870695114, Lr:0.0001\n",
      "Epoch 26, Step: 58, Loss: 0.49628549814224243, Lr:0.0001\n",
      "Epoch 26, Step: 59, Loss: 0.26726803183555603, Lr:0.0001\n",
      "Epoch 26, Step: 60, Loss: 0.31495410203933716, Lr:0.0001\n",
      "Epoch 26, Step: 61, Loss: 0.4221353232860565, Lr:0.0001\n",
      "Epoch 26, Step: 62, Loss: 0.4792630076408386, Lr:0.0001\n",
      "Epoch 26, Step: 63, Loss: 0.3237321674823761, Lr:0.0001\n",
      "Epoch 26, Step: 64, Loss: 0.14120550453662872, Lr:0.0001\n",
      "Epoch 26, Step: 65, Loss: 0.09235259890556335, Lr:0.0001\n",
      "Epoch 26, Step: 66, Loss: 0.17792317271232605, Lr:0.0001\n",
      "Epoch 26, Step: 67, Loss: 1.7612383365631104, Lr:0.0001\n",
      "Epoch 26, Step: 68, Loss: 0.7322416305541992, Lr:0.0001\n",
      "Epoch 26, Step: 69, Loss: 0.11874652653932571, Lr:0.0001\n",
      "Epoch 26, Step: 70, Loss: 0.029071543365716934, Lr:0.0001\n",
      "Epoch 26, Step: 71, Loss: 0.7851407527923584, Lr:0.0001\n",
      "Epoch 26, Step: 72, Loss: 0.24355116486549377, Lr:0.0001\n",
      "Epoch 26, Step: 73, Loss: 0.1819610595703125, Lr:0.0001\n",
      "Epoch 26, Step: 74, Loss: 0.05652915686368942, Lr:0.0001\n",
      "Epoch 26, Step: 75, Loss: 0.7678008675575256, Lr:0.0001\n",
      "Epoch 26, Step: 76, Loss: 0.6360985040664673, Lr:0.0001\n",
      "Epoch 26, Step: 77, Loss: 0.2678270637989044, Lr:0.0001\n",
      "Epoch 26, Step: 78, Loss: 1.2538435459136963, Lr:0.0001\n",
      "Epoch 26, Step: 79, Loss: 0.03832203149795532, Lr:0.0001\n",
      "Epoch 26, Step: 80, Loss: 1.1345552206039429, Lr:0.0001\n",
      "Epoch 26, Step: 81, Loss: 0.7375478148460388, Lr:0.0001\n",
      "Epoch 26, Step: 82, Loss: 0.39566344022750854, Lr:0.0001\n",
      "Epoch 26, Step: 83, Loss: 0.9904645085334778, Lr:0.0001\n",
      "Epoch 26, Step: 84, Loss: 0.7564038038253784, Lr:0.0001\n",
      "Epoch 26, Step: 85, Loss: 0.06733640283346176, Lr:0.0001\n",
      "Epoch 26, Step: 86, Loss: 0.5535970330238342, Lr:0.0001\n",
      "Epoch 26, Step: 87, Loss: 0.39522212743759155, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 26\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.2276 (0.2276) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0100 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.2730 (0.7790) acc1: 100.0000 (81.8182) acc5: 100.0000 (100.0000) time: 0.0078 data: 0.0041 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0078 s / it)\n",
      "* Acc@1 81.818 Acc@5 100.000 loss 0.779\n",
      "Accuracy of the network on the 22 test image: 81.8%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 27, Step: 0, Loss: 4.583404541015625, Lr:0.0001\n",
      "Epoch 27, Step: 1, Loss: 1.228822112083435, Lr:0.0001\n",
      "Epoch 27, Step: 2, Loss: 0.5863863825798035, Lr:0.0001\n",
      "Epoch 27, Step: 3, Loss: 0.26045894622802734, Lr:0.0001\n",
      "Epoch 27, Step: 4, Loss: 0.4278485178947449, Lr:0.0001\n",
      "Epoch 27, Step: 5, Loss: 0.06651036441326141, Lr:0.0001\n",
      "Epoch 27, Step: 6, Loss: 1.8590394258499146, Lr:0.0001\n",
      "Epoch 27, Step: 7, Loss: 0.1458406150341034, Lr:0.0001\n",
      "Epoch 27, Step: 8, Loss: 0.20140908658504486, Lr:0.0001\n",
      "Epoch 27, Step: 9, Loss: 1.74272882938385, Lr:0.0001\n",
      "Epoch 27, Step: 10, Loss: 0.1866292655467987, Lr:0.0001\n",
      "Epoch 27, Step: 11, Loss: 0.4398178458213806, Lr:0.0001\n",
      "Epoch 27, Step: 12, Loss: 0.745169997215271, Lr:0.0001\n",
      "Epoch 27, Step: 13, Loss: 0.39106735587120056, Lr:0.0001\n",
      "Epoch 27, Step: 14, Loss: 0.3496435582637787, Lr:0.0001\n",
      "Epoch 27, Step: 15, Loss: 0.28610551357269287, Lr:0.0001\n",
      "Epoch 27, Step: 16, Loss: 0.058808792382478714, Lr:0.0001\n",
      "Epoch 27, Step: 17, Loss: 0.4431164562702179, Lr:0.0001\n",
      "Epoch 27, Step: 18, Loss: 0.9856864809989929, Lr:0.0001\n",
      "Epoch 27, Step: 19, Loss: 0.2562325894832611, Lr:0.0001\n",
      "Epoch 27, Step: 20, Loss: 1.0559419393539429, Lr:0.0001\n",
      "Epoch 27, Step: 21, Loss: 0.7596694231033325, Lr:0.0001\n",
      "Epoch 27, Step: 22, Loss: 0.16772738099098206, Lr:0.0001\n",
      "Epoch 27, Step: 23, Loss: 0.3764875531196594, Lr:0.0001\n",
      "Epoch 27, Step: 24, Loss: 0.1468074470758438, Lr:0.0001\n",
      "Epoch 27, Step: 25, Loss: 1.5095115900039673, Lr:0.0001\n",
      "Epoch 27, Step: 26, Loss: 0.009893544018268585, Lr:0.0001\n",
      "Epoch 27, Step: 27, Loss: 0.38021594285964966, Lr:0.0001\n",
      "Epoch 27, Step: 28, Loss: 0.6659983992576599, Lr:0.0001\n",
      "Epoch 27, Step: 29, Loss: 0.4464331567287445, Lr:0.0001\n",
      "Epoch 27, Step: 30, Loss: 0.42984074354171753, Lr:0.0001\n",
      "Epoch 27, Step: 31, Loss: 0.4291512966156006, Lr:0.0001\n",
      "Epoch 27, Step: 32, Loss: 1.3414721488952637, Lr:0.0001\n",
      "Epoch 27, Step: 33, Loss: 0.018386125564575195, Lr:0.0001\n",
      "Epoch 27, Step: 34, Loss: 0.16510877013206482, Lr:0.0001\n",
      "Epoch 27, Step: 35, Loss: 0.038123905658721924, Lr:0.0001\n",
      "Epoch 27, Step: 36, Loss: 0.37238889932632446, Lr:0.0001\n",
      "Epoch 27, Step: 37, Loss: 0.24331770837306976, Lr:0.0001\n",
      "Epoch 27, Step: 38, Loss: 0.03173534944653511, Lr:0.0001\n",
      "Epoch 27, Step: 39, Loss: 0.5184769034385681, Lr:0.0001\n",
      "Epoch 27, Step: 40, Loss: 1.4054456949234009, Lr:0.0001\n",
      "Epoch 27, Step: 41, Loss: 1.0391669273376465, Lr:0.0001\n",
      "Epoch 27, Step: 42, Loss: 0.8666518926620483, Lr:0.0001\n",
      "Epoch 27, Step: 43, Loss: 0.3700365424156189, Lr:0.0001\n",
      "Epoch 27, Step: 44, Loss: 0.1707874834537506, Lr:0.0001\n",
      "Epoch 27, Step: 45, Loss: 0.8855791091918945, Lr:0.0001\n",
      "Epoch 27, Step: 46, Loss: 0.17707635462284088, Lr:0.0001\n",
      "Epoch 27, Step: 47, Loss: 0.6527196764945984, Lr:0.0001\n",
      "Epoch 27, Step: 48, Loss: 1.1329219341278076, Lr:0.0001\n",
      "Epoch 27, Step: 49, Loss: 0.5588484406471252, Lr:0.0001\n",
      "Epoch 27, Step: 50, Loss: 0.39640527963638306, Lr:0.0001\n",
      "Epoch 27, Step: 51, Loss: 1.1965434551239014, Lr:0.0001\n",
      "Epoch 27, Step: 52, Loss: 0.33579063415527344, Lr:0.0001\n",
      "Epoch 27, Step: 53, Loss: 0.021278219297528267, Lr:0.0001\n",
      "Epoch 27, Step: 54, Loss: 0.38380980491638184, Lr:0.0001\n",
      "Epoch 27, Step: 55, Loss: 0.7927359938621521, Lr:0.0001\n",
      "Epoch 27, Step: 56, Loss: 0.0887395367026329, Lr:0.0001\n",
      "Epoch 27, Step: 57, Loss: 1.074273705482483, Lr:0.0001\n",
      "Epoch 27, Step: 58, Loss: 0.43549278378486633, Lr:0.0001\n",
      "Epoch 27, Step: 59, Loss: 0.5880305767059326, Lr:0.0001\n",
      "Epoch 27, Step: 60, Loss: 0.9668178558349609, Lr:0.0001\n",
      "Epoch 27, Step: 61, Loss: 0.6628564596176147, Lr:0.0001\n",
      "Epoch 27, Step: 62, Loss: 0.5991262197494507, Lr:0.0001\n",
      "Epoch 27, Step: 63, Loss: 0.422230064868927, Lr:0.0001\n",
      "Epoch 27, Step: 64, Loss: 0.0948469266295433, Lr:0.0001\n",
      "Epoch 27, Step: 65, Loss: 0.40029555559158325, Lr:0.0001\n",
      "Epoch 27, Step: 66, Loss: 0.24916118383407593, Lr:0.0001\n",
      "Epoch 27, Step: 67, Loss: 0.3798673450946808, Lr:0.0001\n",
      "Epoch 27, Step: 68, Loss: 0.6981384754180908, Lr:0.0001\n",
      "Epoch 27, Step: 69, Loss: 0.23569533228874207, Lr:0.0001\n",
      "Epoch 27, Step: 70, Loss: 0.707878053188324, Lr:0.0001\n",
      "Epoch 27, Step: 71, Loss: 0.4313950836658478, Lr:0.0001\n",
      "Epoch 27, Step: 72, Loss: 0.08084726333618164, Lr:0.0001\n",
      "Epoch 27, Step: 73, Loss: 0.9498241543769836, Lr:0.0001\n",
      "Epoch 27, Step: 74, Loss: 0.053813815116882324, Lr:0.0001\n",
      "Epoch 27, Step: 75, Loss: 0.3951513171195984, Lr:0.0001\n",
      "Epoch 27, Step: 76, Loss: 0.7881280779838562, Lr:0.0001\n",
      "Epoch 27, Step: 77, Loss: 0.7124394774436951, Lr:0.0001\n",
      "Epoch 27, Step: 78, Loss: 0.13043875992298126, Lr:0.0001\n",
      "Epoch 27, Step: 79, Loss: 0.33265426754951477, Lr:0.0001\n",
      "Epoch 27, Step: 80, Loss: 0.21765337884426117, Lr:0.0001\n",
      "Epoch 27, Step: 81, Loss: 0.7739076018333435, Lr:0.0001\n",
      "Epoch 27, Step: 82, Loss: 0.8833571076393127, Lr:0.0001\n",
      "Epoch 27, Step: 83, Loss: 0.7662291526794434, Lr:0.0001\n",
      "Epoch 27, Step: 84, Loss: 0.47737032175064087, Lr:0.0001\n",
      "Epoch 27, Step: 85, Loss: 0.42082449793815613, Lr:0.0001\n",
      "Epoch 27, Step: 86, Loss: 0.8265172243118286, Lr:0.0001\n",
      "Epoch 27, Step: 87, Loss: 0.6611019372940063, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 27\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.0321 (0.0321) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0110 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.0321 (0.3488) acc1: 100.0000 (90.9091) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0040 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0090 s / it)\n",
      "* Acc@1 90.909 Acc@5 100.000 loss 0.349\n",
      "Accuracy of the network on the 22 test image: 90.9%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 28, Step: 0, Loss: 1.0162811279296875, Lr:0.0001\n",
      "Epoch 28, Step: 1, Loss: 0.49350273609161377, Lr:0.0001\n",
      "Epoch 28, Step: 2, Loss: 0.4059281349182129, Lr:0.0001\n",
      "Epoch 28, Step: 3, Loss: 0.5635564923286438, Lr:0.0001\n",
      "Epoch 28, Step: 4, Loss: 0.5230977535247803, Lr:0.0001\n",
      "Epoch 28, Step: 5, Loss: 1.3384642601013184, Lr:0.0001\n",
      "Epoch 28, Step: 6, Loss: 0.2946121096611023, Lr:0.0001\n",
      "Epoch 28, Step: 7, Loss: 3.9113669395446777, Lr:0.0001\n",
      "Epoch 28, Step: 8, Loss: 0.7196717262268066, Lr:0.0001\n",
      "Epoch 28, Step: 9, Loss: 0.9597484469413757, Lr:0.0001\n",
      "Epoch 28, Step: 10, Loss: 0.25137701630592346, Lr:0.0001\n",
      "Epoch 28, Step: 11, Loss: 0.6621615886688232, Lr:0.0001\n",
      "Epoch 28, Step: 12, Loss: 0.07764912396669388, Lr:0.0001\n",
      "Epoch 28, Step: 13, Loss: 0.20047302544116974, Lr:0.0001\n",
      "Epoch 28, Step: 14, Loss: 0.20340736210346222, Lr:0.0001\n",
      "Epoch 28, Step: 15, Loss: 0.3313196301460266, Lr:0.0001\n",
      "Epoch 28, Step: 16, Loss: 0.11706294119358063, Lr:0.0001\n",
      "Epoch 28, Step: 17, Loss: 0.15819662809371948, Lr:0.0001\n",
      "Epoch 28, Step: 18, Loss: 0.22391648590564728, Lr:0.0001\n",
      "Epoch 28, Step: 19, Loss: 0.4908284842967987, Lr:0.0001\n",
      "Epoch 28, Step: 20, Loss: 0.27404192090034485, Lr:0.0001\n",
      "Epoch 28, Step: 21, Loss: 0.6789423227310181, Lr:0.0001\n",
      "Epoch 28, Step: 22, Loss: 0.353962779045105, Lr:0.0001\n",
      "Epoch 28, Step: 23, Loss: 1.0158729553222656, Lr:0.0001\n",
      "Epoch 28, Step: 24, Loss: 0.08642521500587463, Lr:0.0001\n",
      "Epoch 28, Step: 25, Loss: 0.5462586283683777, Lr:0.0001\n",
      "Epoch 28, Step: 26, Loss: 0.2407170981168747, Lr:0.0001\n",
      "Epoch 28, Step: 27, Loss: 0.6543736457824707, Lr:0.0001\n",
      "Epoch 28, Step: 28, Loss: 0.49066227674484253, Lr:0.0001\n",
      "Epoch 28, Step: 29, Loss: 0.44256266951560974, Lr:0.0001\n",
      "Epoch 28, Step: 30, Loss: 0.26504936814308167, Lr:0.0001\n",
      "Epoch 28, Step: 31, Loss: 0.5840741991996765, Lr:0.0001\n",
      "Epoch 28, Step: 32, Loss: 0.6795769929885864, Lr:0.0001\n",
      "Epoch 28, Step: 33, Loss: 0.1635579615831375, Lr:0.0001\n",
      "Epoch 28, Step: 34, Loss: 0.5630335807800293, Lr:0.0001\n",
      "Epoch 28, Step: 35, Loss: 0.4286678433418274, Lr:0.0001\n",
      "Epoch 28, Step: 36, Loss: 0.7219957709312439, Lr:0.0001\n",
      "Epoch 28, Step: 37, Loss: 0.023090550675988197, Lr:0.0001\n",
      "Epoch 28, Step: 38, Loss: 0.07634038478136063, Lr:0.0001\n",
      "Epoch 28, Step: 39, Loss: 0.313737154006958, Lr:0.0001\n",
      "Epoch 28, Step: 40, Loss: 0.05348929762840271, Lr:0.0001\n",
      "Epoch 28, Step: 41, Loss: 1.067923903465271, Lr:0.0001\n",
      "Epoch 28, Step: 42, Loss: 0.13875916600227356, Lr:0.0001\n",
      "Epoch 28, Step: 43, Loss: 0.4218065142631531, Lr:0.0001\n",
      "Epoch 28, Step: 44, Loss: 0.07660700380802155, Lr:0.0001\n",
      "Epoch 28, Step: 45, Loss: 0.04052203148603439, Lr:0.0001\n",
      "Epoch 28, Step: 46, Loss: 0.590686023235321, Lr:0.0001\n",
      "Epoch 28, Step: 47, Loss: 0.4308866560459137, Lr:0.0001\n",
      "Epoch 28, Step: 48, Loss: 0.060784049332141876, Lr:0.0001\n",
      "Epoch 28, Step: 49, Loss: 1.0550861358642578, Lr:0.0001\n",
      "Epoch 28, Step: 50, Loss: 0.5177193880081177, Lr:0.0001\n",
      "Epoch 28, Step: 51, Loss: 0.03818624094128609, Lr:0.0001\n",
      "Epoch 28, Step: 52, Loss: 1.2933015823364258, Lr:0.0001\n",
      "Epoch 28, Step: 53, Loss: 0.42760828137397766, Lr:0.0001\n",
      "Epoch 28, Step: 54, Loss: 0.18585987389087677, Lr:0.0001\n",
      "Epoch 28, Step: 55, Loss: 0.3400125801563263, Lr:0.0001\n",
      "Epoch 28, Step: 56, Loss: 0.07690421491861343, Lr:0.0001\n",
      "Epoch 28, Step: 57, Loss: 0.9057179689407349, Lr:0.0001\n",
      "Epoch 28, Step: 58, Loss: 0.46586528420448303, Lr:0.0001\n",
      "Epoch 28, Step: 59, Loss: 0.24211838841438293, Lr:0.0001\n",
      "Epoch 28, Step: 60, Loss: 0.7656975388526917, Lr:0.0001\n",
      "Epoch 28, Step: 61, Loss: 0.13083995878696442, Lr:0.0001\n",
      "Epoch 28, Step: 62, Loss: 0.007000031881034374, Lr:0.0001\n",
      "Epoch 28, Step: 63, Loss: 0.535749614238739, Lr:0.0001\n",
      "Epoch 28, Step: 64, Loss: 0.31451743841171265, Lr:0.0001\n",
      "Epoch 28, Step: 65, Loss: 0.27573180198669434, Lr:0.0001\n",
      "Epoch 28, Step: 66, Loss: 0.05624280124902725, Lr:0.0001\n",
      "Epoch 28, Step: 67, Loss: 0.28386956453323364, Lr:0.0001\n",
      "Epoch 28, Step: 68, Loss: 0.477806955575943, Lr:0.0001\n",
      "Epoch 28, Step: 69, Loss: 0.5034484267234802, Lr:0.0001\n",
      "Epoch 28, Step: 70, Loss: 0.04515409842133522, Lr:0.0001\n",
      "Epoch 28, Step: 71, Loss: 0.04138081893324852, Lr:0.0001\n",
      "Epoch 28, Step: 72, Loss: 0.49038779735565186, Lr:0.0001\n",
      "Epoch 28, Step: 73, Loss: 0.3688633441925049, Lr:0.0001\n",
      "Epoch 28, Step: 74, Loss: 0.02979905903339386, Lr:0.0001\n",
      "Epoch 28, Step: 75, Loss: 0.4875529408454895, Lr:0.0001\n",
      "Epoch 28, Step: 76, Loss: 0.27636197209358215, Lr:0.0001\n",
      "Epoch 28, Step: 77, Loss: 0.2630593180656433, Lr:0.0001\n",
      "Epoch 28, Step: 78, Loss: 1.6109257936477661, Lr:0.0001\n",
      "Epoch 28, Step: 79, Loss: 0.021498557180166245, Lr:0.0001\n",
      "Epoch 28, Step: 80, Loss: 1.1084434986114502, Lr:0.0001\n",
      "Epoch 28, Step: 81, Loss: 0.0908857136964798, Lr:0.0001\n",
      "Epoch 28, Step: 82, Loss: 0.05499476194381714, Lr:0.0001\n",
      "Epoch 28, Step: 83, Loss: 1.16486394405365, Lr:0.0001\n",
      "Epoch 28, Step: 84, Loss: 0.6761912107467651, Lr:0.0001\n",
      "Epoch 28, Step: 85, Loss: 0.06981353461742401, Lr:0.0001\n",
      "Epoch 28, Step: 86, Loss: 0.2540590465068817, Lr:0.0001\n",
      "Epoch 28, Step: 87, Loss: 0.7961187958717346, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 28\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.6907 (0.6907) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.5057 (0.6161) acc1: 75.0000 (72.7273) acc5: 100.0000 (100.0000) time: 0.0077 data: 0.0040 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0078 s / it)\n",
      "* Acc@1 72.727 Acc@5 100.000 loss 0.616\n",
      "Accuracy of the network on the 22 test image: 72.7%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 29, Step: 0, Loss: 0.5789356827735901, Lr:0.0001\n",
      "Epoch 29, Step: 1, Loss: 0.4165073037147522, Lr:0.0001\n",
      "Epoch 29, Step: 2, Loss: 0.6531959176063538, Lr:0.0001\n",
      "Epoch 29, Step: 3, Loss: 0.2615455985069275, Lr:0.0001\n",
      "Epoch 29, Step: 4, Loss: 0.24504347145557404, Lr:0.0001\n",
      "Epoch 29, Step: 5, Loss: 0.1295890361070633, Lr:0.0001\n",
      "Epoch 29, Step: 6, Loss: 0.7410748600959778, Lr:0.0001\n",
      "Epoch 29, Step: 7, Loss: 0.41826823353767395, Lr:0.0001\n",
      "Epoch 29, Step: 8, Loss: 0.02435452491044998, Lr:0.0001\n",
      "Epoch 29, Step: 9, Loss: 0.7480073571205139, Lr:0.0001\n",
      "Epoch 29, Step: 10, Loss: 0.5300597548484802, Lr:0.0001\n",
      "Epoch 29, Step: 11, Loss: 0.724027156829834, Lr:0.0001\n",
      "Epoch 29, Step: 12, Loss: 0.6107145547866821, Lr:0.0001\n",
      "Epoch 29, Step: 13, Loss: 0.47632744908332825, Lr:0.0001\n",
      "Epoch 29, Step: 14, Loss: 0.31745588779449463, Lr:0.0001\n",
      "Epoch 29, Step: 15, Loss: 0.08238861709833145, Lr:0.0001\n",
      "Epoch 29, Step: 16, Loss: 0.2766125500202179, Lr:0.0001\n",
      "Epoch 29, Step: 17, Loss: 0.623411238193512, Lr:0.0001\n",
      "Epoch 29, Step: 18, Loss: 0.020565755665302277, Lr:0.0001\n",
      "Epoch 29, Step: 19, Loss: 1.0141249895095825, Lr:0.0001\n",
      "Epoch 29, Step: 20, Loss: 0.25860390067100525, Lr:0.0001\n",
      "Epoch 29, Step: 21, Loss: 0.27741438150405884, Lr:0.0001\n",
      "Epoch 29, Step: 22, Loss: 0.12997975945472717, Lr:0.0001\n",
      "Epoch 29, Step: 23, Loss: 0.1700688600540161, Lr:0.0001\n",
      "Epoch 29, Step: 24, Loss: 0.8348994255065918, Lr:0.0001\n",
      "Epoch 29, Step: 25, Loss: 0.2634648084640503, Lr:0.0001\n",
      "Epoch 29, Step: 26, Loss: 0.33198943734169006, Lr:0.0001\n",
      "Epoch 29, Step: 27, Loss: 0.16417965292930603, Lr:0.0001\n",
      "Epoch 29, Step: 28, Loss: 0.0460343211889267, Lr:0.0001\n",
      "Epoch 29, Step: 29, Loss: 0.42408931255340576, Lr:0.0001\n",
      "Epoch 29, Step: 30, Loss: 0.29565292596817017, Lr:0.0001\n",
      "Epoch 29, Step: 31, Loss: 0.515657365322113, Lr:0.0001\n",
      "Epoch 29, Step: 32, Loss: 0.1715962141752243, Lr:0.0001\n",
      "Epoch 29, Step: 33, Loss: 0.0775279551744461, Lr:0.0001\n",
      "Epoch 29, Step: 34, Loss: 0.10711824893951416, Lr:0.0001\n",
      "Epoch 29, Step: 35, Loss: 0.46510982513427734, Lr:0.0001\n",
      "Epoch 29, Step: 36, Loss: 0.176987424492836, Lr:0.0001\n",
      "Epoch 29, Step: 37, Loss: 0.7881163358688354, Lr:0.0001\n",
      "Epoch 29, Step: 38, Loss: 0.3913308084011078, Lr:0.0001\n",
      "Epoch 29, Step: 39, Loss: 0.564170777797699, Lr:0.0001\n",
      "Epoch 29, Step: 40, Loss: 0.3265310525894165, Lr:0.0001\n",
      "Epoch 29, Step: 41, Loss: 0.14252127707004547, Lr:0.0001\n",
      "Epoch 29, Step: 42, Loss: 0.07573632150888443, Lr:0.0001\n",
      "Epoch 29, Step: 43, Loss: 0.4010425806045532, Lr:0.0001\n",
      "Epoch 29, Step: 44, Loss: 0.518598735332489, Lr:0.0001\n",
      "Epoch 29, Step: 45, Loss: 0.029134441167116165, Lr:0.0001\n",
      "Epoch 29, Step: 46, Loss: 0.7012591361999512, Lr:0.0001\n",
      "Epoch 29, Step: 47, Loss: 0.2978968918323517, Lr:0.0001\n",
      "Epoch 29, Step: 48, Loss: 0.007626737933605909, Lr:0.0001\n",
      "Epoch 29, Step: 49, Loss: 0.3931581676006317, Lr:0.0001\n",
      "Epoch 29, Step: 50, Loss: 0.4253968894481659, Lr:0.0001\n",
      "Epoch 29, Step: 51, Loss: 0.2619740664958954, Lr:0.0001\n",
      "Epoch 29, Step: 52, Loss: 0.0034505766816437244, Lr:0.0001\n",
      "Epoch 29, Step: 53, Loss: 0.16707350313663483, Lr:0.0001\n",
      "Epoch 29, Step: 54, Loss: 0.13147635757923126, Lr:0.0001\n",
      "Epoch 29, Step: 55, Loss: 0.08434262126684189, Lr:0.0001\n",
      "Epoch 29, Step: 56, Loss: 0.4473147392272949, Lr:0.0001\n",
      "Epoch 29, Step: 57, Loss: 0.06454475224018097, Lr:0.0001\n",
      "Epoch 29, Step: 58, Loss: 0.011609774082899094, Lr:0.0001\n",
      "Epoch 29, Step: 59, Loss: 0.4855610132217407, Lr:0.0001\n",
      "Epoch 29, Step: 60, Loss: 0.06593822687864304, Lr:0.0001\n",
      "Epoch 29, Step: 61, Loss: 0.25816845893859863, Lr:0.0001\n",
      "Epoch 29, Step: 62, Loss: 0.14477688074111938, Lr:0.0001\n",
      "Epoch 29, Step: 63, Loss: 0.007213177625089884, Lr:0.0001\n",
      "Epoch 29, Step: 64, Loss: 2.447031021118164, Lr:0.0001\n",
      "Epoch 29, Step: 65, Loss: 2.240299940109253, Lr:0.0001\n",
      "Epoch 29, Step: 66, Loss: 0.7784229516983032, Lr:0.0001\n",
      "Epoch 29, Step: 67, Loss: 0.315029501914978, Lr:0.0001\n",
      "Epoch 29, Step: 68, Loss: 1.687284231185913, Lr:0.0001\n",
      "Epoch 29, Step: 69, Loss: 2.765268325805664, Lr:0.0001\n",
      "Epoch 29, Step: 70, Loss: 0.4267288148403168, Lr:0.0001\n",
      "Epoch 29, Step: 71, Loss: 1.0229250192642212, Lr:0.0001\n",
      "Epoch 29, Step: 72, Loss: 0.43849796056747437, Lr:0.0001\n",
      "Epoch 29, Step: 73, Loss: 1.0461318492889404, Lr:0.0001\n",
      "Epoch 29, Step: 74, Loss: 0.010906156152486801, Lr:0.0001\n",
      "Epoch 29, Step: 75, Loss: 0.2151515781879425, Lr:0.0001\n",
      "Epoch 29, Step: 76, Loss: 0.5236280560493469, Lr:0.0001\n",
      "Epoch 29, Step: 77, Loss: 0.08007914572954178, Lr:0.0001\n",
      "Epoch 29, Step: 78, Loss: 0.983068585395813, Lr:0.0001\n",
      "Epoch 29, Step: 79, Loss: 0.07172802835702896, Lr:0.0001\n",
      "Epoch 29, Step: 80, Loss: 0.3971230387687683, Lr:0.0001\n",
      "Epoch 29, Step: 81, Loss: 0.5836784243583679, Lr:0.0001\n",
      "Epoch 29, Step: 82, Loss: 0.5493642687797546, Lr:0.0001\n",
      "Epoch 29, Step: 83, Loss: 0.19754108786582947, Lr:0.0001\n",
      "Epoch 29, Step: 84, Loss: 0.06344672292470932, Lr:0.0001\n",
      "Epoch 29, Step: 85, Loss: 0.47750166058540344, Lr:0.0001\n",
      "Epoch 29, Step: 86, Loss: 0.3582334518432617, Lr:0.0001\n",
      "Epoch 29, Step: 87, Loss: 0.09269825369119644, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 29\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.5679 (0.5679) acc1: 50.0000 (50.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.3534 (0.8181) acc1: 50.0000 (72.7273) acc5: 100.0000 (100.0000) time: 0.0068 data: 0.0035 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0068 s / it)\n",
      "* Acc@1 72.727 Acc@5 100.000 loss 0.818\n",
      "Accuracy of the network on the 22 test image: 72.7%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 30, Step: 0, Loss: 0.4305163025856018, Lr:0.0001\n",
      "Epoch 30, Step: 1, Loss: 0.1333450973033905, Lr:0.0001\n",
      "Epoch 30, Step: 2, Loss: 0.056413616985082626, Lr:0.0001\n",
      "Epoch 30, Step: 3, Loss: 0.3351118564605713, Lr:0.0001\n",
      "Epoch 30, Step: 4, Loss: 1.43145751953125, Lr:0.0001\n",
      "Epoch 30, Step: 5, Loss: 0.5836771726608276, Lr:0.0001\n",
      "Epoch 30, Step: 6, Loss: 0.059378091245889664, Lr:0.0001\n",
      "Epoch 30, Step: 7, Loss: 0.5616873502731323, Lr:0.0001\n",
      "Epoch 30, Step: 8, Loss: 0.057696543633937836, Lr:0.0001\n",
      "Epoch 30, Step: 9, Loss: 0.5766905546188354, Lr:0.0001\n",
      "Epoch 30, Step: 10, Loss: 0.5813313722610474, Lr:0.0001\n",
      "Epoch 30, Step: 11, Loss: 0.035053543746471405, Lr:0.0001\n",
      "Epoch 30, Step: 12, Loss: 0.1803322434425354, Lr:0.0001\n",
      "Epoch 30, Step: 13, Loss: 0.41530662775039673, Lr:0.0001\n",
      "Epoch 30, Step: 14, Loss: 0.23175214231014252, Lr:0.0001\n",
      "Epoch 30, Step: 15, Loss: 0.6567823886871338, Lr:0.0001\n",
      "Epoch 30, Step: 16, Loss: 0.27606672048568726, Lr:0.0001\n",
      "Epoch 30, Step: 17, Loss: 0.2925812005996704, Lr:0.0001\n",
      "Epoch 30, Step: 18, Loss: 0.370874285697937, Lr:0.0001\n",
      "Epoch 30, Step: 19, Loss: 0.26532214879989624, Lr:0.0001\n",
      "Epoch 30, Step: 20, Loss: 1.1357486248016357, Lr:0.0001\n",
      "Epoch 30, Step: 21, Loss: 0.13275626301765442, Lr:0.0001\n",
      "Epoch 30, Step: 22, Loss: 0.1629200428724289, Lr:0.0001\n",
      "Epoch 30, Step: 23, Loss: 0.04912648722529411, Lr:0.0001\n",
      "Epoch 30, Step: 24, Loss: 0.3015027642250061, Lr:0.0001\n",
      "Epoch 30, Step: 25, Loss: 0.010231183841824532, Lr:0.0001\n",
      "Epoch 30, Step: 26, Loss: 0.41462379693984985, Lr:0.0001\n",
      "Epoch 30, Step: 27, Loss: 0.1806856095790863, Lr:0.0001\n",
      "Epoch 30, Step: 28, Loss: 0.07982104271650314, Lr:0.0001\n",
      "Epoch 30, Step: 29, Loss: 1.151724100112915, Lr:0.0001\n",
      "Epoch 30, Step: 30, Loss: 0.3944442868232727, Lr:0.0001\n",
      "Epoch 30, Step: 31, Loss: 0.06107433885335922, Lr:0.0001\n",
      "Epoch 30, Step: 32, Loss: 0.7532471418380737, Lr:0.0001\n",
      "Epoch 30, Step: 33, Loss: 0.35462361574172974, Lr:0.0001\n",
      "Epoch 30, Step: 34, Loss: 0.41662654280662537, Lr:0.0001\n",
      "Epoch 30, Step: 35, Loss: 0.5906121730804443, Lr:0.0001\n",
      "Epoch 30, Step: 36, Loss: 0.1676517277956009, Lr:0.0001\n",
      "Epoch 30, Step: 37, Loss: 0.28774237632751465, Lr:0.0001\n",
      "Epoch 30, Step: 38, Loss: 0.32233574986457825, Lr:0.0001\n",
      "Epoch 30, Step: 39, Loss: 0.379314661026001, Lr:0.0001\n",
      "Epoch 30, Step: 40, Loss: 0.2569856643676758, Lr:0.0001\n",
      "Epoch 30, Step: 41, Loss: 0.05382043123245239, Lr:0.0001\n",
      "Epoch 30, Step: 42, Loss: 0.19131961464881897, Lr:0.0001\n",
      "Epoch 30, Step: 43, Loss: 0.03162572160363197, Lr:0.0001\n",
      "Epoch 30, Step: 44, Loss: 0.21737636625766754, Lr:0.0001\n",
      "Epoch 30, Step: 45, Loss: 0.05180960148572922, Lr:0.0001\n",
      "Epoch 30, Step: 46, Loss: 0.28417062759399414, Lr:0.0001\n",
      "Epoch 30, Step: 47, Loss: 0.8216844797134399, Lr:0.0001\n",
      "Epoch 30, Step: 48, Loss: 1.4156209230422974, Lr:0.0001\n",
      "Epoch 30, Step: 49, Loss: 0.05054295435547829, Lr:0.0001\n",
      "Epoch 30, Step: 50, Loss: 0.6908359527587891, Lr:0.0001\n",
      "Epoch 30, Step: 51, Loss: 0.42831966280937195, Lr:0.0001\n",
      "Epoch 30, Step: 52, Loss: 0.44601717591285706, Lr:0.0001\n",
      "Epoch 30, Step: 53, Loss: 0.528115451335907, Lr:0.0001\n",
      "Epoch 30, Step: 54, Loss: 0.45604565739631653, Lr:0.0001\n",
      "Epoch 30, Step: 55, Loss: 0.6315124034881592, Lr:0.0001\n",
      "Epoch 30, Step: 56, Loss: 0.4605131447315216, Lr:0.0001\n",
      "Epoch 30, Step: 57, Loss: 0.20297348499298096, Lr:0.0001\n",
      "Epoch 30, Step: 58, Loss: 0.7426568269729614, Lr:0.0001\n",
      "Epoch 30, Step: 59, Loss: 0.06774148344993591, Lr:0.0001\n",
      "Epoch 30, Step: 60, Loss: 0.5533812642097473, Lr:0.0001\n",
      "Epoch 30, Step: 61, Loss: 1.7528271675109863, Lr:0.0001\n",
      "Epoch 30, Step: 62, Loss: 0.3070070743560791, Lr:0.0001\n",
      "Epoch 30, Step: 63, Loss: 0.11092990636825562, Lr:0.0001\n",
      "Epoch 30, Step: 64, Loss: 0.02121080830693245, Lr:0.0001\n",
      "Epoch 30, Step: 65, Loss: 0.2808370590209961, Lr:0.0001\n",
      "Epoch 30, Step: 66, Loss: 0.26470687985420227, Lr:0.0001\n",
      "Epoch 30, Step: 67, Loss: 0.5366888046264648, Lr:0.0001\n",
      "Epoch 30, Step: 68, Loss: 0.0558495819568634, Lr:0.0001\n",
      "Epoch 30, Step: 69, Loss: 0.042278654873371124, Lr:0.0001\n",
      "Epoch 30, Step: 70, Loss: 0.7436426877975464, Lr:0.0001\n",
      "Epoch 30, Step: 71, Loss: 0.7141565084457397, Lr:0.0001\n",
      "Epoch 30, Step: 72, Loss: 1.383044958114624, Lr:0.0001\n",
      "Epoch 30, Step: 73, Loss: 0.38165485858917236, Lr:0.0001\n",
      "Epoch 30, Step: 74, Loss: 0.38177549839019775, Lr:0.0001\n",
      "Epoch 30, Step: 75, Loss: 0.6344509124755859, Lr:0.0001\n",
      "Epoch 30, Step: 76, Loss: 0.6857153177261353, Lr:0.0001\n",
      "Epoch 30, Step: 77, Loss: 0.3988647758960724, Lr:0.0001\n",
      "Epoch 30, Step: 78, Loss: 0.5790014266967773, Lr:0.0001\n",
      "Epoch 30, Step: 79, Loss: 0.2979598343372345, Lr:0.0001\n",
      "Epoch 30, Step: 80, Loss: 0.06707946211099625, Lr:0.0001\n",
      "Epoch 30, Step: 81, Loss: 0.21342571079730988, Lr:0.0001\n",
      "Epoch 30, Step: 82, Loss: 0.34684672951698303, Lr:0.0001\n",
      "Epoch 30, Step: 83, Loss: 0.20339708030223846, Lr:0.0001\n",
      "Epoch 30, Step: 84, Loss: 0.12898704409599304, Lr:0.0001\n",
      "Epoch 30, Step: 85, Loss: 1.6224240064620972, Lr:0.0001\n",
      "Epoch 30, Step: 86, Loss: 0.7440046072006226, Lr:0.0001\n",
      "Epoch 30, Step: 87, Loss: 0.2803230881690979, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 30\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.0137 (0.0137) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0100 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.0137 (0.6180) acc1: 100.0000 (86.3636) acc5: 100.0000 (100.0000) time: 0.0087 data: 0.0040 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0087 s / it)\n",
      "* Acc@1 86.364 Acc@5 100.000 loss 0.618\n",
      "Accuracy of the network on the 22 test image: 86.4%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 31, Step: 0, Loss: 0.7046515941619873, Lr:0.0001\n",
      "Epoch 31, Step: 1, Loss: 0.45889151096343994, Lr:0.0001\n",
      "Epoch 31, Step: 2, Loss: 0.05141841247677803, Lr:0.0001\n",
      "Epoch 31, Step: 3, Loss: 1.0728282928466797, Lr:0.0001\n",
      "Epoch 31, Step: 4, Loss: 0.013381775468587875, Lr:0.0001\n",
      "Epoch 31, Step: 5, Loss: 0.98581463098526, Lr:0.0001\n",
      "Epoch 31, Step: 6, Loss: 0.31873127818107605, Lr:0.0001\n",
      "Epoch 31, Step: 7, Loss: 0.0032791923731565475, Lr:0.0001\n",
      "Epoch 31, Step: 8, Loss: 0.21709661185741425, Lr:0.0001\n",
      "Epoch 31, Step: 9, Loss: 1.900693655014038, Lr:0.0001\n",
      "Epoch 31, Step: 10, Loss: 0.2322101593017578, Lr:0.0001\n",
      "Epoch 31, Step: 11, Loss: 0.04392240568995476, Lr:0.0001\n",
      "Epoch 31, Step: 12, Loss: 0.2793087959289551, Lr:0.0001\n",
      "Epoch 31, Step: 13, Loss: 0.29096129536628723, Lr:0.0001\n",
      "Epoch 31, Step: 14, Loss: 0.14405864477157593, Lr:0.0001\n",
      "Epoch 31, Step: 15, Loss: 0.5157789587974548, Lr:0.0001\n",
      "Epoch 31, Step: 16, Loss: 0.35315993428230286, Lr:0.0001\n",
      "Epoch 31, Step: 17, Loss: 0.022390717640519142, Lr:0.0001\n",
      "Epoch 31, Step: 18, Loss: 0.7801716327667236, Lr:0.0001\n",
      "Epoch 31, Step: 19, Loss: 0.05615120381116867, Lr:0.0001\n",
      "Epoch 31, Step: 20, Loss: 0.5615347623825073, Lr:0.0001\n",
      "Epoch 31, Step: 21, Loss: 0.4378192722797394, Lr:0.0001\n",
      "Epoch 31, Step: 22, Loss: 0.1296849399805069, Lr:0.0001\n",
      "Epoch 31, Step: 23, Loss: 0.0907440111041069, Lr:0.0001\n",
      "Epoch 31, Step: 24, Loss: 1.8706860542297363, Lr:0.0001\n",
      "Epoch 31, Step: 25, Loss: 0.7107391357421875, Lr:0.0001\n",
      "Epoch 31, Step: 26, Loss: 0.6025139093399048, Lr:0.0001\n",
      "Epoch 31, Step: 27, Loss: 0.30340397357940674, Lr:0.0001\n",
      "Epoch 31, Step: 28, Loss: 0.19210144877433777, Lr:0.0001\n",
      "Epoch 31, Step: 29, Loss: 1.07791006565094, Lr:0.0001\n",
      "Epoch 31, Step: 30, Loss: 0.1905529499053955, Lr:0.0001\n",
      "Epoch 31, Step: 31, Loss: 0.012458128854632378, Lr:0.0001\n",
      "Epoch 31, Step: 32, Loss: 0.2466271072626114, Lr:0.0001\n",
      "Epoch 31, Step: 33, Loss: 0.03195438161492348, Lr:0.0001\n",
      "Epoch 31, Step: 34, Loss: 0.7573590874671936, Lr:0.0001\n",
      "Epoch 31, Step: 35, Loss: 0.67750483751297, Lr:0.0001\n",
      "Epoch 31, Step: 36, Loss: 0.014850553125143051, Lr:0.0001\n",
      "Epoch 31, Step: 37, Loss: 0.28587839007377625, Lr:0.0001\n",
      "Epoch 31, Step: 38, Loss: 0.008730476722121239, Lr:0.0001\n",
      "Epoch 31, Step: 39, Loss: 0.5421913862228394, Lr:0.0001\n",
      "Epoch 31, Step: 40, Loss: 0.01817570999264717, Lr:0.0001\n",
      "Epoch 31, Step: 41, Loss: 0.2287895828485489, Lr:0.0001\n",
      "Epoch 31, Step: 42, Loss: 0.19451282918453217, Lr:0.0001\n",
      "Epoch 31, Step: 43, Loss: 0.38778233528137207, Lr:0.0001\n",
      "Epoch 31, Step: 44, Loss: 0.1360548734664917, Lr:0.0001\n",
      "Epoch 31, Step: 45, Loss: 0.4546070992946625, Lr:0.0001\n",
      "Epoch 31, Step: 46, Loss: 0.6581288576126099, Lr:0.0001\n",
      "Epoch 31, Step: 47, Loss: 0.07041012495756149, Lr:0.0001\n",
      "Epoch 31, Step: 48, Loss: 0.9190540909767151, Lr:0.0001\n",
      "Epoch 31, Step: 49, Loss: 3.813843250274658, Lr:0.0001\n",
      "Epoch 31, Step: 50, Loss: 0.1591995805501938, Lr:0.0001\n",
      "Epoch 31, Step: 51, Loss: 0.35924357175827026, Lr:0.0001\n",
      "Epoch 31, Step: 52, Loss: 0.901921272277832, Lr:0.0001\n",
      "Epoch 31, Step: 53, Loss: 0.24735018610954285, Lr:0.0001\n",
      "Epoch 31, Step: 54, Loss: 0.010684359818696976, Lr:0.0001\n",
      "Epoch 31, Step: 55, Loss: 0.010885683819651604, Lr:0.0001\n",
      "Epoch 31, Step: 56, Loss: 0.07874364405870438, Lr:0.0001\n",
      "Epoch 31, Step: 57, Loss: 0.038387808948755264, Lr:0.0001\n",
      "Epoch 31, Step: 58, Loss: 0.20242854952812195, Lr:0.0001\n",
      "Epoch 31, Step: 59, Loss: 2.1607792377471924, Lr:0.0001\n",
      "Epoch 31, Step: 60, Loss: 0.741518497467041, Lr:0.0001\n",
      "Epoch 31, Step: 61, Loss: 0.6191800832748413, Lr:0.0001\n",
      "Epoch 31, Step: 62, Loss: 0.32987770438194275, Lr:0.0001\n",
      "Epoch 31, Step: 63, Loss: 0.4419991970062256, Lr:0.0001\n",
      "Epoch 31, Step: 64, Loss: 0.45755666494369507, Lr:0.0001\n",
      "Epoch 31, Step: 65, Loss: 0.31002119183540344, Lr:0.0001\n",
      "Epoch 31, Step: 66, Loss: 0.1320340931415558, Lr:0.0001\n",
      "Epoch 31, Step: 67, Loss: 4.250190734863281, Lr:0.0001\n",
      "Epoch 31, Step: 68, Loss: 0.16034166514873505, Lr:0.0001\n",
      "Epoch 31, Step: 69, Loss: 0.675822377204895, Lr:0.0001\n",
      "Epoch 31, Step: 70, Loss: 0.45982033014297485, Lr:0.0001\n",
      "Epoch 31, Step: 71, Loss: 1.2720857858657837, Lr:0.0001\n",
      "Epoch 31, Step: 72, Loss: 0.49694502353668213, Lr:0.0001\n",
      "Epoch 31, Step: 73, Loss: 0.538608729839325, Lr:0.0001\n",
      "Epoch 31, Step: 74, Loss: 0.48295965790748596, Lr:0.0001\n",
      "Epoch 31, Step: 75, Loss: 0.6329473257064819, Lr:0.0001\n",
      "Epoch 31, Step: 76, Loss: 0.025544356554746628, Lr:0.0001\n",
      "Epoch 31, Step: 77, Loss: 0.34478601813316345, Lr:0.0001\n",
      "Epoch 31, Step: 78, Loss: 0.2501595616340637, Lr:0.0001\n",
      "Epoch 31, Step: 79, Loss: 0.665672779083252, Lr:0.0001\n",
      "Epoch 31, Step: 80, Loss: 0.46814945340156555, Lr:0.0001\n",
      "Epoch 31, Step: 81, Loss: 0.3098468780517578, Lr:0.0001\n",
      "Epoch 31, Step: 82, Loss: 0.6675900220870972, Lr:0.0001\n",
      "Epoch 31, Step: 83, Loss: 0.4181367754936218, Lr:0.0001\n",
      "Epoch 31, Step: 84, Loss: 0.14700669050216675, Lr:0.0001\n",
      "Epoch 31, Step: 85, Loss: 0.4541727602481842, Lr:0.0001\n",
      "Epoch 31, Step: 86, Loss: 0.03852319344878197, Lr:0.0001\n",
      "Epoch 31, Step: 87, Loss: 1.3034099340438843, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 31\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 1.4421 (1.4421) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.3361 (0.6545) acc1: 75.0000 (77.2727) acc5: 100.0000 (100.0000) time: 0.0070 data: 0.0037 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0070 s / it)\n",
      "* Acc@1 77.273 Acc@5 100.000 loss 0.654\n",
      "Accuracy of the network on the 22 test image: 77.3%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 32, Step: 0, Loss: 0.8878402709960938, Lr:0.0001\n",
      "Epoch 32, Step: 1, Loss: 0.6150844097137451, Lr:0.0001\n",
      "Epoch 32, Step: 2, Loss: 1.0469204187393188, Lr:0.0001\n",
      "Epoch 32, Step: 3, Loss: 0.6731439232826233, Lr:0.0001\n",
      "Epoch 32, Step: 4, Loss: 0.2219287008047104, Lr:0.0001\n",
      "Epoch 32, Step: 5, Loss: 0.10878273844718933, Lr:0.0001\n",
      "Epoch 32, Step: 6, Loss: 0.14015904068946838, Lr:0.0001\n",
      "Epoch 32, Step: 7, Loss: 0.23013460636138916, Lr:0.0001\n",
      "Epoch 32, Step: 8, Loss: 0.3631635904312134, Lr:0.0001\n",
      "Epoch 32, Step: 9, Loss: 1.1815769672393799, Lr:0.0001\n",
      "Epoch 32, Step: 10, Loss: 0.07265686988830566, Lr:0.0001\n",
      "Epoch 32, Step: 11, Loss: 0.2534860372543335, Lr:0.0001\n",
      "Epoch 32, Step: 12, Loss: 0.6432226896286011, Lr:0.0001\n",
      "Epoch 32, Step: 13, Loss: 0.13852792978286743, Lr:0.0001\n",
      "Epoch 32, Step: 14, Loss: 0.15785539150238037, Lr:0.0001\n",
      "Epoch 32, Step: 15, Loss: 0.09225692600011826, Lr:0.0001\n",
      "Epoch 32, Step: 16, Loss: 0.407082736492157, Lr:0.0001\n",
      "Epoch 32, Step: 17, Loss: 0.08117850869894028, Lr:0.0001\n",
      "Epoch 32, Step: 18, Loss: 0.874508798122406, Lr:0.0001\n",
      "Epoch 32, Step: 19, Loss: 0.008229715749621391, Lr:0.0001\n",
      "Epoch 32, Step: 20, Loss: 0.016060257330536842, Lr:0.0001\n",
      "Epoch 32, Step: 21, Loss: 0.20241643488407135, Lr:0.0001\n",
      "Epoch 32, Step: 22, Loss: 0.024078868329524994, Lr:0.0001\n",
      "Epoch 32, Step: 23, Loss: 0.32237860560417175, Lr:0.0001\n",
      "Epoch 32, Step: 24, Loss: 0.6771100759506226, Lr:0.0001\n",
      "Epoch 32, Step: 25, Loss: 0.504552960395813, Lr:0.0001\n",
      "Epoch 32, Step: 26, Loss: 0.9287489056587219, Lr:0.0001\n",
      "Epoch 32, Step: 27, Loss: 1.2640745639801025, Lr:0.0001\n",
      "Epoch 32, Step: 28, Loss: 0.4110618829727173, Lr:0.0001\n",
      "Epoch 32, Step: 29, Loss: 0.5987743139266968, Lr:0.0001\n",
      "Epoch 32, Step: 30, Loss: 0.09515231102705002, Lr:0.0001\n",
      "Epoch 32, Step: 31, Loss: 1.0164985656738281, Lr:0.0001\n",
      "Epoch 32, Step: 32, Loss: 0.31503167748451233, Lr:0.0001\n",
      "Epoch 32, Step: 33, Loss: 0.9020060896873474, Lr:0.0001\n",
      "Epoch 32, Step: 34, Loss: 0.4956674575805664, Lr:0.0001\n",
      "Epoch 32, Step: 35, Loss: 1.029769778251648, Lr:0.0001\n",
      "Epoch 32, Step: 36, Loss: 0.04808153212070465, Lr:0.0001\n",
      "Epoch 32, Step: 37, Loss: 0.716055154800415, Lr:0.0001\n",
      "Epoch 32, Step: 38, Loss: 0.020915893837809563, Lr:0.0001\n",
      "Epoch 32, Step: 39, Loss: 0.033464036881923676, Lr:0.0001\n",
      "Epoch 32, Step: 40, Loss: 0.08088535815477371, Lr:0.0001\n",
      "Epoch 32, Step: 41, Loss: 0.5854108333587646, Lr:0.0001\n",
      "Epoch 32, Step: 42, Loss: 0.8836894035339355, Lr:0.0001\n",
      "Epoch 32, Step: 43, Loss: 0.021744919940829277, Lr:0.0001\n",
      "Epoch 32, Step: 44, Loss: 0.5867335200309753, Lr:0.0001\n",
      "Epoch 32, Step: 45, Loss: 0.44993075728416443, Lr:0.0001\n",
      "Epoch 32, Step: 46, Loss: 0.18910247087478638, Lr:0.0001\n",
      "Epoch 32, Step: 47, Loss: 0.12403459846973419, Lr:0.0001\n",
      "Epoch 32, Step: 48, Loss: 0.7115703821182251, Lr:0.0001\n",
      "Epoch 32, Step: 49, Loss: 0.5197798013687134, Lr:0.0001\n",
      "Epoch 32, Step: 50, Loss: 0.24510492384433746, Lr:0.0001\n",
      "Epoch 32, Step: 51, Loss: 0.47482430934906006, Lr:0.0001\n",
      "Epoch 32, Step: 52, Loss: 0.32047784328460693, Lr:0.0001\n",
      "Epoch 32, Step: 53, Loss: 0.00993746891617775, Lr:0.0001\n",
      "Epoch 32, Step: 54, Loss: 0.7757262587547302, Lr:0.0001\n",
      "Epoch 32, Step: 55, Loss: 0.7259491086006165, Lr:0.0001\n",
      "Epoch 32, Step: 56, Loss: 0.43673229217529297, Lr:0.0001\n",
      "Epoch 32, Step: 57, Loss: 0.5593660473823547, Lr:0.0001\n",
      "Epoch 32, Step: 58, Loss: 0.4940686821937561, Lr:0.0001\n",
      "Epoch 32, Step: 59, Loss: 0.43114855885505676, Lr:0.0001\n",
      "Epoch 32, Step: 60, Loss: 0.37777209281921387, Lr:0.0001\n",
      "Epoch 32, Step: 61, Loss: 0.02138548716902733, Lr:0.0001\n",
      "Epoch 32, Step: 62, Loss: 0.016710806638002396, Lr:0.0001\n",
      "Epoch 32, Step: 63, Loss: 0.674225926399231, Lr:0.0001\n",
      "Epoch 32, Step: 64, Loss: 0.014040636830031872, Lr:0.0001\n",
      "Epoch 32, Step: 65, Loss: 0.36990824341773987, Lr:0.0001\n",
      "Epoch 32, Step: 66, Loss: 0.09224831312894821, Lr:0.0001\n",
      "Epoch 32, Step: 67, Loss: 0.7223571538925171, Lr:0.0001\n",
      "Epoch 32, Step: 68, Loss: 0.6662063002586365, Lr:0.0001\n",
      "Epoch 32, Step: 69, Loss: 0.1058351993560791, Lr:0.0001\n",
      "Epoch 32, Step: 70, Loss: 0.4523550868034363, Lr:0.0001\n",
      "Epoch 32, Step: 71, Loss: 0.4835848808288574, Lr:0.0001\n",
      "Epoch 32, Step: 72, Loss: 0.9224027395248413, Lr:0.0001\n",
      "Epoch 32, Step: 73, Loss: 0.015185108408331871, Lr:0.0001\n",
      "Epoch 32, Step: 74, Loss: 0.38313406705856323, Lr:0.0001\n",
      "Epoch 32, Step: 75, Loss: 0.7202660441398621, Lr:0.0001\n",
      "Epoch 32, Step: 76, Loss: 0.2542669177055359, Lr:0.0001\n",
      "Epoch 32, Step: 77, Loss: 0.616910994052887, Lr:0.0001\n",
      "Epoch 32, Step: 78, Loss: 1.2636646032333374, Lr:0.0001\n",
      "Epoch 32, Step: 79, Loss: 1.3343913555145264, Lr:0.0001\n",
      "Epoch 32, Step: 80, Loss: 0.7611766457557678, Lr:0.0001\n",
      "Epoch 32, Step: 81, Loss: 0.024333171546459198, Lr:0.0001\n",
      "Epoch 32, Step: 82, Loss: 0.37574219703674316, Lr:0.0001\n",
      "Epoch 32, Step: 83, Loss: 0.41158154606819153, Lr:0.0001\n",
      "Epoch 32, Step: 84, Loss: 0.04964834451675415, Lr:0.0001\n",
      "Epoch 32, Step: 85, Loss: 0.298505961894989, Lr:0.0001\n",
      "Epoch 32, Step: 86, Loss: 0.43526479601860046, Lr:0.0001\n",
      "Epoch 32, Step: 87, Loss: 0.35540151596069336, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 32\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.0016 (0.0016) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.0529 (0.3702) acc1: 75.0000 (81.8182) acc5: 100.0000 (100.0000) time: 0.0072 data: 0.0038 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0073 s / it)\n",
      "* Acc@1 81.818 Acc@5 100.000 loss 0.370\n",
      "Accuracy of the network on the 22 test image: 81.8%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 33, Step: 0, Loss: 0.22540295124053955, Lr:0.0001\n",
      "Epoch 33, Step: 1, Loss: 0.2674759328365326, Lr:0.0001\n",
      "Epoch 33, Step: 2, Loss: 0.15389111638069153, Lr:0.0001\n",
      "Epoch 33, Step: 3, Loss: 0.0701674297451973, Lr:0.0001\n",
      "Epoch 33, Step: 4, Loss: 0.07033407688140869, Lr:0.0001\n",
      "Epoch 33, Step: 5, Loss: 0.5082802176475525, Lr:0.0001\n",
      "Epoch 33, Step: 6, Loss: 0.011313622817397118, Lr:0.0001\n",
      "Epoch 33, Step: 7, Loss: 0.08362609148025513, Lr:0.0001\n",
      "Epoch 33, Step: 8, Loss: 0.8182235360145569, Lr:0.0001\n",
      "Epoch 33, Step: 9, Loss: 0.036329638212919235, Lr:0.0001\n",
      "Epoch 33, Step: 10, Loss: 1.3355337381362915, Lr:0.0001\n",
      "Epoch 33, Step: 11, Loss: 0.2794429659843445, Lr:0.0001\n",
      "Epoch 33, Step: 12, Loss: 0.2860402464866638, Lr:0.0001\n",
      "Epoch 33, Step: 13, Loss: 0.15061604976654053, Lr:0.0001\n",
      "Epoch 33, Step: 14, Loss: 0.01856292597949505, Lr:0.0001\n",
      "Epoch 33, Step: 15, Loss: 0.013024380430579185, Lr:0.0001\n",
      "Epoch 33, Step: 16, Loss: 0.31902632117271423, Lr:0.0001\n",
      "Epoch 33, Step: 17, Loss: 0.46563607454299927, Lr:0.0001\n",
      "Epoch 33, Step: 18, Loss: 0.42444655299186707, Lr:0.0001\n",
      "Epoch 33, Step: 19, Loss: 0.3603827953338623, Lr:0.0001\n",
      "Epoch 33, Step: 20, Loss: 0.3981668949127197, Lr:0.0001\n",
      "Epoch 33, Step: 21, Loss: 0.1671900898218155, Lr:0.0001\n",
      "Epoch 33, Step: 22, Loss: 0.23091043531894684, Lr:0.0001\n",
      "Epoch 33, Step: 23, Loss: 0.6392621397972107, Lr:0.0001\n",
      "Epoch 33, Step: 24, Loss: 0.010738745331764221, Lr:0.0001\n",
      "Epoch 33, Step: 25, Loss: 0.35925111174583435, Lr:0.0001\n",
      "Epoch 33, Step: 26, Loss: 0.0396265871822834, Lr:0.0001\n",
      "Epoch 33, Step: 27, Loss: 0.03854948654770851, Lr:0.0001\n",
      "Epoch 33, Step: 28, Loss: 0.0173929575830698, Lr:0.0001\n",
      "Epoch 33, Step: 29, Loss: 0.42273402214050293, Lr:0.0001\n",
      "Epoch 33, Step: 30, Loss: 0.06594245880842209, Lr:0.0001\n",
      "Epoch 33, Step: 31, Loss: 0.384640634059906, Lr:0.0001\n",
      "Epoch 33, Step: 32, Loss: 0.2386394888162613, Lr:0.0001\n",
      "Epoch 33, Step: 33, Loss: 0.7221239805221558, Lr:0.0001\n",
      "Epoch 33, Step: 34, Loss: 0.01220363937318325, Lr:0.0001\n",
      "Epoch 33, Step: 35, Loss: 0.23561905324459076, Lr:0.0001\n",
      "Epoch 33, Step: 36, Loss: 0.013233188539743423, Lr:0.0001\n",
      "Epoch 33, Step: 37, Loss: 0.01333372388035059, Lr:0.0001\n",
      "Epoch 33, Step: 38, Loss: 0.5495599508285522, Lr:0.0001\n",
      "Epoch 33, Step: 39, Loss: 0.5731878280639648, Lr:0.0001\n",
      "Epoch 33, Step: 40, Loss: 0.7688621878623962, Lr:0.0001\n",
      "Epoch 33, Step: 41, Loss: 0.635222852230072, Lr:0.0001\n",
      "Epoch 33, Step: 42, Loss: 1.0243866443634033, Lr:0.0001\n",
      "Epoch 33, Step: 43, Loss: 0.7847904562950134, Lr:0.0001\n",
      "Epoch 33, Step: 44, Loss: 0.6107226610183716, Lr:0.0001\n",
      "Epoch 33, Step: 45, Loss: 0.08798681944608688, Lr:0.0001\n",
      "Epoch 33, Step: 46, Loss: 0.24328488111495972, Lr:0.0001\n",
      "Epoch 33, Step: 47, Loss: 0.24592509865760803, Lr:0.0001\n",
      "Epoch 33, Step: 48, Loss: 0.9096375107765198, Lr:0.0001\n",
      "Epoch 33, Step: 49, Loss: 0.22227120399475098, Lr:0.0001\n",
      "Epoch 33, Step: 50, Loss: 0.5180479884147644, Lr:0.0001\n",
      "Epoch 33, Step: 51, Loss: 0.11657314747571945, Lr:0.0001\n",
      "Epoch 33, Step: 52, Loss: 0.5798638463020325, Lr:0.0001\n",
      "Epoch 33, Step: 53, Loss: 0.30349627137184143, Lr:0.0001\n",
      "Epoch 33, Step: 54, Loss: 0.019455887377262115, Lr:0.0001\n",
      "Epoch 33, Step: 55, Loss: 0.9327096939086914, Lr:0.0001\n",
      "Epoch 33, Step: 56, Loss: 0.4025997519493103, Lr:0.0001\n",
      "Epoch 33, Step: 57, Loss: 0.4876508116722107, Lr:0.0001\n",
      "Epoch 33, Step: 58, Loss: 0.7348973751068115, Lr:0.0001\n",
      "Epoch 33, Step: 59, Loss: 0.3075725734233856, Lr:0.0001\n",
      "Epoch 33, Step: 60, Loss: 0.2993858754634857, Lr:0.0001\n",
      "Epoch 33, Step: 61, Loss: 0.10741009563207626, Lr:0.0001\n",
      "Epoch 33, Step: 62, Loss: 0.7271777391433716, Lr:0.0001\n",
      "Epoch 33, Step: 63, Loss: 0.017246056348085403, Lr:0.0001\n",
      "Epoch 33, Step: 64, Loss: 0.084143728017807, Lr:0.0001\n",
      "Epoch 33, Step: 65, Loss: 0.158225879073143, Lr:0.0001\n",
      "Epoch 33, Step: 66, Loss: 0.10683232545852661, Lr:0.0001\n",
      "Epoch 33, Step: 67, Loss: 0.32841238379478455, Lr:0.0001\n",
      "Epoch 33, Step: 68, Loss: 0.7723209857940674, Lr:0.0001\n",
      "Epoch 33, Step: 69, Loss: 0.03280884400010109, Lr:0.0001\n",
      "Epoch 33, Step: 70, Loss: 0.7705785632133484, Lr:0.0001\n",
      "Epoch 33, Step: 71, Loss: 0.03594068065285683, Lr:0.0001\n",
      "Epoch 33, Step: 72, Loss: 0.3502490520477295, Lr:0.0001\n",
      "Epoch 33, Step: 73, Loss: 0.05967925116419792, Lr:0.0001\n",
      "Epoch 33, Step: 74, Loss: 0.3531499207019806, Lr:0.0001\n",
      "Epoch 33, Step: 75, Loss: 0.41471025347709656, Lr:0.0001\n",
      "Epoch 33, Step: 76, Loss: 0.017962604761123657, Lr:0.0001\n",
      "Epoch 33, Step: 77, Loss: 0.36466163396835327, Lr:0.0001\n",
      "Epoch 33, Step: 78, Loss: 0.41795480251312256, Lr:0.0001\n",
      "Epoch 33, Step: 79, Loss: 1.2988229990005493, Lr:0.0001\n",
      "Epoch 33, Step: 80, Loss: 0.46968212723731995, Lr:0.0001\n",
      "Epoch 33, Step: 81, Loss: 0.4470042884349823, Lr:0.0001\n",
      "Epoch 33, Step: 82, Loss: 0.7083703279495239, Lr:0.0001\n",
      "Epoch 33, Step: 83, Loss: 0.5651432275772095, Lr:0.0001\n",
      "Epoch 33, Step: 84, Loss: 0.6218715310096741, Lr:0.0001\n",
      "Epoch 33, Step: 85, Loss: 0.11918036639690399, Lr:0.0001\n",
      "Epoch 33, Step: 86, Loss: 0.6177976131439209, Lr:0.0001\n",
      "Epoch 33, Step: 87, Loss: 0.8635842800140381, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 33\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.0264 (0.0264) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0080 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.0264 (0.4084) acc1: 100.0000 (86.3636) acc5: 100.0000 (100.0000) time: 0.0070 data: 0.0038 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0072 s / it)\n",
      "* Acc@1 86.364 Acc@5 100.000 loss 0.408\n",
      "Accuracy of the network on the 22 test image: 86.4%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 34, Step: 0, Loss: 0.3674599826335907, Lr:0.0001\n",
      "Epoch 34, Step: 1, Loss: 0.43976864218711853, Lr:0.0001\n",
      "Epoch 34, Step: 2, Loss: 0.32153773307800293, Lr:0.0001\n",
      "Epoch 34, Step: 3, Loss: 1.6887140274047852, Lr:0.0001\n",
      "Epoch 34, Step: 4, Loss: 0.050672199577093124, Lr:0.0001\n",
      "Epoch 34, Step: 5, Loss: 0.1707143634557724, Lr:0.0001\n",
      "Epoch 34, Step: 6, Loss: 0.3884629011154175, Lr:0.0001\n",
      "Epoch 34, Step: 7, Loss: 0.40466949343681335, Lr:0.0001\n",
      "Epoch 34, Step: 8, Loss: 0.06681668758392334, Lr:0.0001\n",
      "Epoch 34, Step: 9, Loss: 0.030466202646493912, Lr:0.0001\n",
      "Epoch 34, Step: 10, Loss: 0.33751019835472107, Lr:0.0001\n",
      "Epoch 34, Step: 11, Loss: 0.005927051417529583, Lr:0.0001\n",
      "Epoch 34, Step: 12, Loss: 0.0228753462433815, Lr:0.0001\n",
      "Epoch 34, Step: 13, Loss: 0.29689958691596985, Lr:0.0001\n",
      "Epoch 34, Step: 14, Loss: 0.5370025634765625, Lr:0.0001\n",
      "Epoch 34, Step: 15, Loss: 0.09324962645769119, Lr:0.0001\n",
      "Epoch 34, Step: 16, Loss: 0.5549826622009277, Lr:0.0001\n",
      "Epoch 34, Step: 17, Loss: 0.287249356508255, Lr:0.0001\n",
      "Epoch 34, Step: 18, Loss: 0.08026933670043945, Lr:0.0001\n",
      "Epoch 34, Step: 19, Loss: 0.4688287377357483, Lr:0.0001\n",
      "Epoch 34, Step: 20, Loss: 0.03451762720942497, Lr:0.0001\n",
      "Epoch 34, Step: 21, Loss: 0.03571734204888344, Lr:0.0001\n",
      "Epoch 34, Step: 22, Loss: 0.11305507272481918, Lr:0.0001\n",
      "Epoch 34, Step: 23, Loss: 0.6574020385742188, Lr:0.0001\n",
      "Epoch 34, Step: 24, Loss: 0.6944358348846436, Lr:0.0001\n",
      "Epoch 34, Step: 25, Loss: 0.03991904854774475, Lr:0.0001\n",
      "Epoch 34, Step: 26, Loss: 0.0444646030664444, Lr:0.0001\n",
      "Epoch 34, Step: 27, Loss: 3.7988529205322266, Lr:0.0001\n",
      "Epoch 34, Step: 28, Loss: 0.06144952028989792, Lr:0.0001\n",
      "Epoch 34, Step: 29, Loss: 0.18918712437152863, Lr:0.0001\n",
      "Epoch 34, Step: 30, Loss: 0.3063395023345947, Lr:0.0001\n",
      "Epoch 34, Step: 31, Loss: 0.08919471502304077, Lr:0.0001\n",
      "Epoch 34, Step: 32, Loss: 0.07159896939992905, Lr:0.0001\n",
      "Epoch 34, Step: 33, Loss: 0.22033344209194183, Lr:0.0001\n",
      "Epoch 34, Step: 34, Loss: 0.07004985213279724, Lr:0.0001\n",
      "Epoch 34, Step: 35, Loss: 0.0892610028386116, Lr:0.0001\n",
      "Epoch 34, Step: 36, Loss: 0.6092289686203003, Lr:0.0001\n",
      "Epoch 34, Step: 37, Loss: 0.05145232751965523, Lr:0.0001\n",
      "Epoch 34, Step: 38, Loss: 0.10640306770801544, Lr:0.0001\n",
      "Epoch 34, Step: 39, Loss: 0.6506340503692627, Lr:0.0001\n",
      "Epoch 34, Step: 40, Loss: 0.31725889444351196, Lr:0.0001\n",
      "Epoch 34, Step: 41, Loss: 0.782619833946228, Lr:0.0001\n",
      "Epoch 34, Step: 42, Loss: 1.1732910871505737, Lr:0.0001\n",
      "Epoch 34, Step: 43, Loss: 0.387482225894928, Lr:0.0001\n",
      "Epoch 34, Step: 44, Loss: 0.08142119646072388, Lr:0.0001\n",
      "Epoch 34, Step: 45, Loss: 0.8736449480056763, Lr:0.0001\n",
      "Epoch 34, Step: 46, Loss: 0.5309879183769226, Lr:0.0001\n",
      "Epoch 34, Step: 47, Loss: 0.4311242401599884, Lr:0.0001\n",
      "Epoch 34, Step: 48, Loss: 0.09099031984806061, Lr:0.0001\n",
      "Epoch 34, Step: 49, Loss: 0.6330320239067078, Lr:0.0001\n",
      "Epoch 34, Step: 50, Loss: 0.16996918618679047, Lr:0.0001\n",
      "Epoch 34, Step: 51, Loss: 0.3488111197948456, Lr:0.0001\n",
      "Epoch 34, Step: 52, Loss: 0.14421997964382172, Lr:0.0001\n",
      "Epoch 34, Step: 53, Loss: 0.18451766669750214, Lr:0.0001\n",
      "Epoch 34, Step: 54, Loss: 0.07413849234580994, Lr:0.0001\n",
      "Epoch 34, Step: 55, Loss: 0.03419937193393707, Lr:0.0001\n",
      "Epoch 34, Step: 56, Loss: 0.38534966111183167, Lr:0.0001\n",
      "Epoch 34, Step: 57, Loss: 0.5311176776885986, Lr:0.0001\n",
      "Epoch 34, Step: 58, Loss: 0.777917742729187, Lr:0.0001\n",
      "Epoch 34, Step: 59, Loss: 0.3578644394874573, Lr:0.0001\n",
      "Epoch 34, Step: 60, Loss: 0.5070204734802246, Lr:0.0001\n",
      "Epoch 34, Step: 61, Loss: 0.1298554539680481, Lr:0.0001\n",
      "Epoch 34, Step: 62, Loss: 0.9169648885726929, Lr:0.0001\n",
      "Epoch 34, Step: 63, Loss: 0.3586713969707489, Lr:0.0001\n",
      "Epoch 34, Step: 64, Loss: 0.7201158404350281, Lr:0.0001\n",
      "Epoch 34, Step: 65, Loss: 0.00924269575625658, Lr:0.0001\n",
      "Epoch 34, Step: 66, Loss: 0.013930384069681168, Lr:0.0001\n",
      "Epoch 34, Step: 67, Loss: 1.7366658449172974, Lr:0.0001\n",
      "Epoch 34, Step: 68, Loss: 0.0436532162129879, Lr:0.0001\n",
      "Epoch 34, Step: 69, Loss: 0.029071304947137833, Lr:0.0001\n",
      "Epoch 34, Step: 70, Loss: 0.3078151047229767, Lr:0.0001\n",
      "Epoch 34, Step: 71, Loss: 0.033091697841882706, Lr:0.0001\n",
      "Epoch 34, Step: 72, Loss: 0.006784568540751934, Lr:0.0001\n",
      "Epoch 34, Step: 73, Loss: 0.9598566293716431, Lr:0.0001\n",
      "Epoch 34, Step: 74, Loss: 0.9093887209892273, Lr:0.0001\n",
      "Epoch 34, Step: 75, Loss: 0.9728745222091675, Lr:0.0001\n",
      "Epoch 34, Step: 76, Loss: 0.37243086099624634, Lr:0.0001\n",
      "Epoch 34, Step: 77, Loss: 0.7323111295700073, Lr:0.0001\n",
      "Epoch 34, Step: 78, Loss: 0.5632342100143433, Lr:0.0001\n",
      "Epoch 34, Step: 79, Loss: 0.010887663811445236, Lr:0.0001\n",
      "Epoch 34, Step: 80, Loss: 0.09730266779661179, Lr:0.0001\n",
      "Epoch 34, Step: 81, Loss: 0.1920238882303238, Lr:0.0001\n",
      "Epoch 34, Step: 82, Loss: 0.4156051278114319, Lr:0.0001\n",
      "Epoch 34, Step: 83, Loss: 0.5342150330543518, Lr:0.0001\n",
      "Epoch 34, Step: 84, Loss: 0.759748637676239, Lr:0.0001\n",
      "Epoch 34, Step: 85, Loss: 0.4420194923877716, Lr:0.0001\n",
      "Epoch 34, Step: 86, Loss: 1.3368151187896729, Lr:0.0001\n",
      "Epoch 34, Step: 87, Loss: 0.4355803430080414, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 34\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.1801 (0.1801) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.1801 (0.7240) acc1: 100.0000 (86.3636) acc5: 100.0000 (100.0000) time: 0.0082 data: 0.0040 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0082 s / it)\n",
      "* Acc@1 86.364 Acc@5 100.000 loss 0.724\n",
      "Accuracy of the network on the 22 test image: 86.4%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 35, Step: 0, Loss: 0.7037709951400757, Lr:0.0001\n",
      "Epoch 35, Step: 1, Loss: 0.7483058571815491, Lr:0.0001\n",
      "Epoch 35, Step: 2, Loss: 0.8952696919441223, Lr:0.0001\n",
      "Epoch 35, Step: 3, Loss: 0.0043588681146502495, Lr:0.0001\n",
      "Epoch 35, Step: 4, Loss: 0.0667700469493866, Lr:0.0001\n",
      "Epoch 35, Step: 5, Loss: 2.5457913875579834, Lr:0.0001\n",
      "Epoch 35, Step: 6, Loss: 0.6898109912872314, Lr:0.0001\n",
      "Epoch 35, Step: 7, Loss: 0.5160799026489258, Lr:0.0001\n",
      "Epoch 35, Step: 8, Loss: 0.27040985226631165, Lr:0.0001\n",
      "Epoch 35, Step: 9, Loss: 0.3558900058269501, Lr:0.0001\n",
      "Epoch 35, Step: 10, Loss: 0.08815590292215347, Lr:0.0001\n",
      "Epoch 35, Step: 11, Loss: 0.4249876141548157, Lr:0.0001\n",
      "Epoch 35, Step: 12, Loss: 0.5695546865463257, Lr:0.0001\n",
      "Epoch 35, Step: 13, Loss: 0.09096615761518478, Lr:0.0001\n",
      "Epoch 35, Step: 14, Loss: 0.06624548137187958, Lr:0.0001\n",
      "Epoch 35, Step: 15, Loss: 0.7613386511802673, Lr:0.0001\n",
      "Epoch 35, Step: 16, Loss: 0.42490047216415405, Lr:0.0001\n",
      "Epoch 35, Step: 17, Loss: 0.5058656930923462, Lr:0.0001\n",
      "Epoch 35, Step: 18, Loss: 0.2783295214176178, Lr:0.0001\n",
      "Epoch 35, Step: 19, Loss: 0.010602661408483982, Lr:0.0001\n",
      "Epoch 35, Step: 20, Loss: 0.2218385487794876, Lr:0.0001\n",
      "Epoch 35, Step: 21, Loss: 0.05082234740257263, Lr:0.0001\n",
      "Epoch 35, Step: 22, Loss: 0.47735852003097534, Lr:0.0001\n",
      "Epoch 35, Step: 23, Loss: 0.00419444777071476, Lr:0.0001\n",
      "Epoch 35, Step: 24, Loss: 0.4368717074394226, Lr:0.0001\n",
      "Epoch 35, Step: 25, Loss: 0.3235281705856323, Lr:0.0001\n",
      "Epoch 35, Step: 26, Loss: 0.48881739377975464, Lr:0.0001\n",
      "Epoch 35, Step: 27, Loss: 0.2883809804916382, Lr:0.0001\n",
      "Epoch 35, Step: 28, Loss: 0.5201013684272766, Lr:0.0001\n",
      "Epoch 35, Step: 29, Loss: 0.8033392429351807, Lr:0.0001\n",
      "Epoch 35, Step: 30, Loss: 0.06865999102592468, Lr:0.0001\n",
      "Epoch 35, Step: 31, Loss: 0.2990824580192566, Lr:0.0001\n",
      "Epoch 35, Step: 32, Loss: 0.558191180229187, Lr:0.0001\n",
      "Epoch 35, Step: 33, Loss: 0.6041929721832275, Lr:0.0001\n",
      "Epoch 35, Step: 34, Loss: 0.0679992064833641, Lr:0.0001\n",
      "Epoch 35, Step: 35, Loss: 0.051994696259498596, Lr:0.0001\n",
      "Epoch 35, Step: 36, Loss: 0.6977925300598145, Lr:0.0001\n",
      "Epoch 35, Step: 37, Loss: 0.0500810332596302, Lr:0.0001\n",
      "Epoch 35, Step: 38, Loss: 0.038786228746175766, Lr:0.0001\n",
      "Epoch 35, Step: 39, Loss: 0.4475764334201813, Lr:0.0001\n",
      "Epoch 35, Step: 40, Loss: 0.7754426598548889, Lr:0.0001\n",
      "Epoch 35, Step: 41, Loss: 0.8265729546546936, Lr:0.0001\n",
      "Epoch 35, Step: 42, Loss: 0.2893486022949219, Lr:0.0001\n",
      "Epoch 35, Step: 43, Loss: 0.4079596996307373, Lr:0.0001\n",
      "Epoch 35, Step: 44, Loss: 0.4209887683391571, Lr:0.0001\n",
      "Epoch 35, Step: 45, Loss: 0.4344801902770996, Lr:0.0001\n",
      "Epoch 35, Step: 46, Loss: 0.38798046112060547, Lr:0.0001\n",
      "Epoch 35, Step: 47, Loss: 0.32230907678604126, Lr:0.0001\n",
      "Epoch 35, Step: 48, Loss: 0.4003823399543762, Lr:0.0001\n",
      "Epoch 35, Step: 49, Loss: 1.7315165996551514, Lr:0.0001\n",
      "Epoch 35, Step: 50, Loss: 0.010694431141018867, Lr:0.0001\n",
      "Epoch 35, Step: 51, Loss: 0.4207097887992859, Lr:0.0001\n",
      "Epoch 35, Step: 52, Loss: 0.42264220118522644, Lr:0.0001\n",
      "Epoch 35, Step: 53, Loss: 0.4974671006202698, Lr:0.0001\n",
      "Epoch 35, Step: 54, Loss: 1.208601474761963, Lr:0.0001\n",
      "Epoch 35, Step: 55, Loss: 0.5906122326850891, Lr:0.0001\n",
      "Epoch 35, Step: 56, Loss: 0.0081953015178442, Lr:0.0001\n",
      "Epoch 35, Step: 57, Loss: 0.6373275518417358, Lr:0.0001\n",
      "Epoch 35, Step: 58, Loss: 0.5324332118034363, Lr:0.0001\n",
      "Epoch 35, Step: 59, Loss: 0.1686733067035675, Lr:0.0001\n",
      "Epoch 35, Step: 60, Loss: 0.053592536598443985, Lr:0.0001\n",
      "Epoch 35, Step: 61, Loss: 0.005818450357764959, Lr:0.0001\n",
      "Epoch 35, Step: 62, Loss: 0.02543623372912407, Lr:0.0001\n",
      "Epoch 35, Step: 63, Loss: 0.3691563904285431, Lr:0.0001\n",
      "Epoch 35, Step: 64, Loss: 0.2788526117801666, Lr:0.0001\n",
      "Epoch 35, Step: 65, Loss: 0.5661261677742004, Lr:0.0001\n",
      "Epoch 35, Step: 66, Loss: 0.2120056003332138, Lr:0.0001\n",
      "Epoch 35, Step: 67, Loss: 0.7089771628379822, Lr:0.0001\n",
      "Epoch 35, Step: 68, Loss: 0.475639671087265, Lr:0.0001\n",
      "Epoch 35, Step: 69, Loss: 0.14564648270606995, Lr:0.0001\n",
      "Epoch 35, Step: 70, Loss: 0.10468468070030212, Lr:0.0001\n",
      "Epoch 35, Step: 71, Loss: 0.05539250001311302, Lr:0.0001\n",
      "Epoch 35, Step: 72, Loss: 0.4006538391113281, Lr:0.0001\n",
      "Epoch 35, Step: 73, Loss: 0.678900957107544, Lr:0.0001\n",
      "Epoch 35, Step: 74, Loss: 0.02706834115087986, Lr:0.0001\n",
      "Epoch 35, Step: 75, Loss: 0.2680916488170624, Lr:0.0001\n",
      "Epoch 35, Step: 76, Loss: 0.009763164445757866, Lr:0.0001\n",
      "Epoch 35, Step: 77, Loss: 0.3876292109489441, Lr:0.0001\n",
      "Epoch 35, Step: 78, Loss: 1.6318203210830688, Lr:0.0001\n",
      "Epoch 35, Step: 79, Loss: 0.49275025725364685, Lr:0.0001\n",
      "Epoch 35, Step: 80, Loss: 0.03833451867103577, Lr:0.0001\n",
      "Epoch 35, Step: 81, Loss: 0.7341675162315369, Lr:0.0001\n",
      "Epoch 35, Step: 82, Loss: 0.2341432273387909, Lr:0.0001\n",
      "Epoch 35, Step: 83, Loss: 0.3962678909301758, Lr:0.0001\n",
      "Epoch 35, Step: 84, Loss: 0.13171768188476562, Lr:0.0001\n",
      "Epoch 35, Step: 85, Loss: 0.536107063293457, Lr:0.0001\n",
      "Epoch 35, Step: 86, Loss: 0.6859802603721619, Lr:0.0001\n",
      "Epoch 35, Step: 87, Loss: 0.0697602778673172, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 35\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 1.3392 (1.3392) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.0100 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.2258 (0.5557) acc1: 100.0000 (90.9091) acc5: 100.0000 (100.0000) time: 0.0085 data: 0.0048 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0085 s / it)\n",
      "* Acc@1 90.909 Acc@5 100.000 loss 0.556\n",
      "Accuracy of the network on the 22 test image: 90.9%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 36, Step: 0, Loss: 0.40195947885513306, Lr:0.0001\n",
      "Epoch 36, Step: 1, Loss: 0.2324814647436142, Lr:0.0001\n",
      "Epoch 36, Step: 2, Loss: 0.8166470527648926, Lr:0.0001\n",
      "Epoch 36, Step: 3, Loss: 0.5353429317474365, Lr:0.0001\n",
      "Epoch 36, Step: 4, Loss: 0.028431104496121407, Lr:0.0001\n",
      "Epoch 36, Step: 5, Loss: 0.15362846851348877, Lr:0.0001\n",
      "Epoch 36, Step: 6, Loss: 0.19079388678073883, Lr:0.0001\n",
      "Epoch 36, Step: 7, Loss: 0.08841215074062347, Lr:0.0001\n",
      "Epoch 36, Step: 8, Loss: 0.880467414855957, Lr:0.0001\n",
      "Epoch 36, Step: 9, Loss: 0.49182745814323425, Lr:0.0001\n",
      "Epoch 36, Step: 10, Loss: 0.32771027088165283, Lr:0.0001\n",
      "Epoch 36, Step: 11, Loss: 0.10466106235980988, Lr:0.0001\n",
      "Epoch 36, Step: 12, Loss: 0.47835180163383484, Lr:0.0001\n",
      "Epoch 36, Step: 13, Loss: 0.37386223673820496, Lr:0.0001\n",
      "Epoch 36, Step: 14, Loss: 0.10472556203603745, Lr:0.0001\n",
      "Epoch 36, Step: 15, Loss: 0.6638922095298767, Lr:0.0001\n",
      "Epoch 36, Step: 16, Loss: 0.41621315479278564, Lr:0.0001\n",
      "Epoch 36, Step: 17, Loss: 0.5877389311790466, Lr:0.0001\n",
      "Epoch 36, Step: 18, Loss: 0.048653703182935715, Lr:0.0001\n",
      "Epoch 36, Step: 19, Loss: 0.3063981533050537, Lr:0.0001\n",
      "Epoch 36, Step: 20, Loss: 0.09991112351417542, Lr:0.0001\n",
      "Epoch 36, Step: 21, Loss: 0.24526561796665192, Lr:0.0001\n",
      "Epoch 36, Step: 22, Loss: 0.007626079488545656, Lr:0.0001\n",
      "Epoch 36, Step: 23, Loss: 0.090362049639225, Lr:0.0001\n",
      "Epoch 36, Step: 24, Loss: 0.871086061000824, Lr:0.0001\n",
      "Epoch 36, Step: 25, Loss: 0.4240932762622833, Lr:0.0001\n",
      "Epoch 36, Step: 26, Loss: 0.229465052485466, Lr:0.0001\n",
      "Epoch 36, Step: 27, Loss: 0.5609984397888184, Lr:0.0001\n",
      "Epoch 36, Step: 28, Loss: 0.07776255905628204, Lr:0.0001\n",
      "Epoch 36, Step: 29, Loss: 1.838904619216919, Lr:0.0001\n",
      "Epoch 36, Step: 30, Loss: 0.6956491470336914, Lr:0.0001\n",
      "Epoch 36, Step: 31, Loss: 0.28369420766830444, Lr:0.0001\n",
      "Epoch 36, Step: 32, Loss: 0.625218391418457, Lr:0.0001\n",
      "Epoch 36, Step: 33, Loss: 0.38143691420555115, Lr:0.0001\n",
      "Epoch 36, Step: 34, Loss: 0.0914425253868103, Lr:0.0001\n",
      "Epoch 36, Step: 35, Loss: 1.5257307291030884, Lr:0.0001\n",
      "Epoch 36, Step: 36, Loss: 0.02869763970375061, Lr:0.0001\n",
      "Epoch 36, Step: 37, Loss: 0.05137528106570244, Lr:0.0001\n",
      "Epoch 36, Step: 38, Loss: 0.0224324818700552, Lr:0.0001\n",
      "Epoch 36, Step: 39, Loss: 0.553432822227478, Lr:0.0001\n",
      "Epoch 36, Step: 40, Loss: 0.2012888789176941, Lr:0.0001\n",
      "Epoch 36, Step: 41, Loss: 0.3357537090778351, Lr:0.0001\n",
      "Epoch 36, Step: 42, Loss: 0.6209906339645386, Lr:0.0001\n",
      "Epoch 36, Step: 43, Loss: 0.32571858167648315, Lr:0.0001\n",
      "Epoch 36, Step: 44, Loss: 0.2433154284954071, Lr:0.0001\n",
      "Epoch 36, Step: 45, Loss: 0.3714752495288849, Lr:0.0001\n",
      "Epoch 36, Step: 46, Loss: 0.4436843991279602, Lr:0.0001\n",
      "Epoch 36, Step: 47, Loss: 1.1014807224273682, Lr:0.0001\n",
      "Epoch 36, Step: 48, Loss: 0.230989009141922, Lr:0.0001\n",
      "Epoch 36, Step: 49, Loss: 0.005771996453404427, Lr:0.0001\n",
      "Epoch 36, Step: 50, Loss: 0.419247567653656, Lr:0.0001\n",
      "Epoch 36, Step: 51, Loss: 0.01932423934340477, Lr:0.0001\n",
      "Epoch 36, Step: 52, Loss: 0.6364220380783081, Lr:0.0001\n",
      "Epoch 36, Step: 53, Loss: 0.12487924844026566, Lr:0.0001\n",
      "Epoch 36, Step: 54, Loss: 0.03787337243556976, Lr:0.0001\n",
      "Epoch 36, Step: 55, Loss: 0.3614580035209656, Lr:0.0001\n",
      "Epoch 36, Step: 56, Loss: 0.04272814840078354, Lr:0.0001\n",
      "Epoch 36, Step: 57, Loss: 1.0108121633529663, Lr:0.0001\n",
      "Epoch 36, Step: 58, Loss: 0.12283845990896225, Lr:0.0001\n",
      "Epoch 36, Step: 59, Loss: 0.28985533118247986, Lr:0.0001\n",
      "Epoch 36, Step: 60, Loss: 0.111198291182518, Lr:0.0001\n",
      "Epoch 36, Step: 61, Loss: 0.8655846118927002, Lr:0.0001\n",
      "Epoch 36, Step: 62, Loss: 0.5905143022537231, Lr:0.0001\n",
      "Epoch 36, Step: 63, Loss: 0.24711278080940247, Lr:0.0001\n",
      "Epoch 36, Step: 64, Loss: 0.15787942707538605, Lr:0.0001\n",
      "Epoch 36, Step: 65, Loss: 1.0198596715927124, Lr:0.0001\n",
      "Epoch 36, Step: 66, Loss: 0.4233671724796295, Lr:0.0001\n",
      "Epoch 36, Step: 67, Loss: 0.4357185959815979, Lr:0.0001\n",
      "Epoch 36, Step: 68, Loss: 0.6897277235984802, Lr:0.0001\n",
      "Epoch 36, Step: 69, Loss: 0.03455895185470581, Lr:0.0001\n",
      "Epoch 36, Step: 70, Loss: 0.023582782596349716, Lr:0.0001\n",
      "Epoch 36, Step: 71, Loss: 0.017046581953763962, Lr:0.0001\n",
      "Epoch 36, Step: 72, Loss: 0.3307308554649353, Lr:0.0001\n",
      "Epoch 36, Step: 73, Loss: 0.7074275016784668, Lr:0.0001\n",
      "Epoch 36, Step: 74, Loss: 0.18089698255062103, Lr:0.0001\n",
      "Epoch 36, Step: 75, Loss: 0.33845847845077515, Lr:0.0001\n",
      "Epoch 36, Step: 76, Loss: 0.3270789682865143, Lr:0.0001\n",
      "Epoch 36, Step: 77, Loss: 0.4060073494911194, Lr:0.0001\n",
      "Epoch 36, Step: 78, Loss: 0.2694646716117859, Lr:0.0001\n",
      "Epoch 36, Step: 79, Loss: 0.3720017671585083, Lr:0.0001\n",
      "Epoch 36, Step: 80, Loss: 0.17845292389392853, Lr:0.0001\n",
      "Epoch 36, Step: 81, Loss: 0.24648067355155945, Lr:0.0001\n",
      "Epoch 36, Step: 82, Loss: 0.26645323634147644, Lr:0.0001\n",
      "Epoch 36, Step: 83, Loss: 0.22351495921611786, Lr:0.0001\n",
      "Epoch 36, Step: 84, Loss: 0.021233510226011276, Lr:0.0001\n",
      "Epoch 36, Step: 85, Loss: 0.6418805718421936, Lr:0.0001\n",
      "Epoch 36, Step: 86, Loss: 0.005034185945987701, Lr:0.0001\n",
      "Epoch 36, Step: 87, Loss: 0.2321600764989853, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 36\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.6279 (0.6279) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.2036 (0.4797) acc1: 100.0000 (86.3636) acc5: 100.0000 (100.0000) time: 0.0085 data: 0.0042 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0087 s / it)\n",
      "* Acc@1 86.364 Acc@5 100.000 loss 0.480\n",
      "Accuracy of the network on the 22 test image: 86.4%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 37, Step: 0, Loss: 0.199024960398674, Lr:0.0001\n",
      "Epoch 37, Step: 1, Loss: 0.08695326745510101, Lr:0.0001\n",
      "Epoch 37, Step: 2, Loss: 0.0033153663389384747, Lr:0.0001\n",
      "Epoch 37, Step: 3, Loss: 0.2448415905237198, Lr:0.0001\n",
      "Epoch 37, Step: 4, Loss: 0.6014218330383301, Lr:0.0001\n",
      "Epoch 37, Step: 5, Loss: 0.4355006217956543, Lr:0.0001\n",
      "Epoch 37, Step: 6, Loss: 0.04163877293467522, Lr:0.0001\n",
      "Epoch 37, Step: 7, Loss: 0.011651693843305111, Lr:0.0001\n",
      "Epoch 37, Step: 8, Loss: 0.7678729891777039, Lr:0.0001\n",
      "Epoch 37, Step: 9, Loss: 0.12479712069034576, Lr:0.0001\n",
      "Epoch 37, Step: 10, Loss: 0.35258474946022034, Lr:0.0001\n",
      "Epoch 37, Step: 11, Loss: 0.029828380793333054, Lr:0.0001\n",
      "Epoch 37, Step: 12, Loss: 0.4275062680244446, Lr:0.0001\n",
      "Epoch 37, Step: 13, Loss: 0.14197689294815063, Lr:0.0001\n",
      "Epoch 37, Step: 14, Loss: 1.553260087966919, Lr:0.0001\n",
      "Epoch 37, Step: 15, Loss: 0.27480408549308777, Lr:0.0001\n",
      "Epoch 37, Step: 16, Loss: 0.02748153731226921, Lr:0.0001\n",
      "Epoch 37, Step: 17, Loss: 0.5702823996543884, Lr:0.0001\n",
      "Epoch 37, Step: 18, Loss: 0.0371856614947319, Lr:0.0001\n",
      "Epoch 37, Step: 19, Loss: 0.2678995728492737, Lr:0.0001\n",
      "Epoch 37, Step: 20, Loss: 0.09469027072191238, Lr:0.0001\n",
      "Epoch 37, Step: 21, Loss: 0.0027933940291404724, Lr:0.0001\n",
      "Epoch 37, Step: 22, Loss: 1.2804174423217773, Lr:0.0001\n",
      "Epoch 37, Step: 23, Loss: 0.061958540230989456, Lr:0.0001\n",
      "Epoch 37, Step: 24, Loss: 0.4547836482524872, Lr:0.0001\n",
      "Epoch 37, Step: 25, Loss: 0.2821143567562103, Lr:0.0001\n",
      "Epoch 37, Step: 26, Loss: 0.005745450034737587, Lr:0.0001\n",
      "Epoch 37, Step: 27, Loss: 0.3140837252140045, Lr:0.0001\n",
      "Epoch 37, Step: 28, Loss: 0.026185566559433937, Lr:0.0001\n",
      "Epoch 37, Step: 29, Loss: 0.05491367727518082, Lr:0.0001\n",
      "Epoch 37, Step: 30, Loss: 0.04767640680074692, Lr:0.0001\n",
      "Epoch 37, Step: 31, Loss: 0.20775876939296722, Lr:0.0001\n",
      "Epoch 37, Step: 32, Loss: 0.2036251723766327, Lr:0.0001\n",
      "Epoch 37, Step: 33, Loss: 1.1284236907958984, Lr:0.0001\n",
      "Epoch 37, Step: 34, Loss: 0.987084150314331, Lr:0.0001\n",
      "Epoch 37, Step: 35, Loss: 1.2285183668136597, Lr:0.0001\n",
      "Epoch 37, Step: 36, Loss: 0.5438998341560364, Lr:0.0001\n",
      "Epoch 37, Step: 37, Loss: 0.19736969470977783, Lr:0.0001\n",
      "Epoch 37, Step: 38, Loss: 0.35196757316589355, Lr:0.0001\n",
      "Epoch 37, Step: 39, Loss: 0.03183465451002121, Lr:0.0001\n",
      "Epoch 37, Step: 40, Loss: 0.7693558931350708, Lr:0.0001\n",
      "Epoch 37, Step: 41, Loss: 0.3524947762489319, Lr:0.0001\n",
      "Epoch 37, Step: 42, Loss: 0.4037289321422577, Lr:0.0001\n",
      "Epoch 37, Step: 43, Loss: 1.2143923044204712, Lr:0.0001\n",
      "Epoch 37, Step: 44, Loss: 0.04194276034832001, Lr:0.0001\n",
      "Epoch 37, Step: 45, Loss: 0.017521090805530548, Lr:0.0001\n",
      "Epoch 37, Step: 46, Loss: 0.3279815912246704, Lr:0.0001\n",
      "Epoch 37, Step: 47, Loss: 0.940054178237915, Lr:0.0001\n",
      "Epoch 37, Step: 48, Loss: 1.0534520149230957, Lr:0.0001\n",
      "Epoch 37, Step: 49, Loss: 0.343485027551651, Lr:0.0001\n",
      "Epoch 37, Step: 50, Loss: 0.08351987600326538, Lr:0.0001\n",
      "Epoch 37, Step: 51, Loss: 0.421941339969635, Lr:0.0001\n",
      "Epoch 37, Step: 52, Loss: 0.11643565446138382, Lr:0.0001\n",
      "Epoch 37, Step: 53, Loss: 0.06254464387893677, Lr:0.0001\n",
      "Epoch 37, Step: 54, Loss: 0.4535691738128662, Lr:0.0001\n",
      "Epoch 37, Step: 55, Loss: 0.3181731700897217, Lr:0.0001\n",
      "Epoch 37, Step: 56, Loss: 0.6487441658973694, Lr:0.0001\n",
      "Epoch 37, Step: 57, Loss: 0.5043675899505615, Lr:0.0001\n",
      "Epoch 37, Step: 58, Loss: 0.02519790641963482, Lr:0.0001\n",
      "Epoch 37, Step: 59, Loss: 0.02064334973692894, Lr:0.0001\n",
      "Epoch 37, Step: 60, Loss: 1.7750589847564697, Lr:0.0001\n",
      "Epoch 37, Step: 61, Loss: 0.32680144906044006, Lr:0.0001\n",
      "Epoch 37, Step: 62, Loss: 1.2713086605072021, Lr:0.0001\n",
      "Epoch 37, Step: 63, Loss: 0.7537492513656616, Lr:0.0001\n",
      "Epoch 37, Step: 64, Loss: 0.5914099216461182, Lr:0.0001\n",
      "Epoch 37, Step: 65, Loss: 0.5505959987640381, Lr:0.0001\n",
      "Epoch 37, Step: 66, Loss: 0.01777688041329384, Lr:0.0001\n",
      "Epoch 37, Step: 67, Loss: 1.0739378929138184, Lr:0.0001\n",
      "Epoch 37, Step: 68, Loss: 0.0645626038312912, Lr:0.0001\n",
      "Epoch 37, Step: 69, Loss: 0.3470793068408966, Lr:0.0001\n",
      "Epoch 37, Step: 70, Loss: 0.27758410573005676, Lr:0.0001\n",
      "Epoch 37, Step: 71, Loss: 0.4152247905731201, Lr:0.0001\n",
      "Epoch 37, Step: 72, Loss: 0.05555873364210129, Lr:0.0001\n",
      "Epoch 37, Step: 73, Loss: 0.07191361486911774, Lr:0.0001\n",
      "Epoch 37, Step: 74, Loss: 0.1370849609375, Lr:0.0001\n",
      "Epoch 37, Step: 75, Loss: 0.011706464923918247, Lr:0.0001\n",
      "Epoch 37, Step: 76, Loss: 0.30777910351753235, Lr:0.0001\n",
      "Epoch 37, Step: 77, Loss: 0.25380757451057434, Lr:0.0001\n",
      "Epoch 37, Step: 78, Loss: 0.15475158393383026, Lr:0.0001\n",
      "Epoch 37, Step: 79, Loss: 0.9459757208824158, Lr:0.0001\n",
      "Epoch 37, Step: 80, Loss: 0.7544052600860596, Lr:0.0001\n",
      "Epoch 37, Step: 81, Loss: 0.4791966676712036, Lr:0.0001\n",
      "Epoch 37, Step: 82, Loss: 0.09557370096445084, Lr:0.0001\n",
      "Epoch 37, Step: 83, Loss: 0.1466292440891266, Lr:0.0001\n",
      "Epoch 37, Step: 84, Loss: 0.24477508664131165, Lr:0.0001\n",
      "Epoch 37, Step: 85, Loss: 0.5745307207107544, Lr:0.0001\n",
      "Epoch 37, Step: 86, Loss: 0.1509941816329956, Lr:0.0001\n",
      "Epoch 37, Step: 87, Loss: 0.8562389016151428, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 37\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.1991 (0.1991) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0110 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.0256 (0.5931) acc1: 100.0000 (81.8182) acc5: 100.0000 (100.0000) time: 0.0080 data: 0.0042 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0083 s / it)\n",
      "* Acc@1 81.818 Acc@5 100.000 loss 0.593\n",
      "Accuracy of the network on the 22 test image: 81.8%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 38, Step: 0, Loss: 0.3334813117980957, Lr:0.0001\n",
      "Epoch 38, Step: 1, Loss: 0.06881000846624374, Lr:0.0001\n",
      "Epoch 38, Step: 2, Loss: 0.8361244201660156, Lr:0.0001\n",
      "Epoch 38, Step: 3, Loss: 0.07351424545049667, Lr:0.0001\n",
      "Epoch 38, Step: 4, Loss: 1.071243166923523, Lr:0.0001\n",
      "Epoch 38, Step: 5, Loss: 0.025577859953045845, Lr:0.0001\n",
      "Epoch 38, Step: 6, Loss: 0.3974311351776123, Lr:0.0001\n",
      "Epoch 38, Step: 7, Loss: 0.3404407203197479, Lr:0.0001\n",
      "Epoch 38, Step: 8, Loss: 0.26584088802337646, Lr:0.0001\n",
      "Epoch 38, Step: 9, Loss: 0.5012636184692383, Lr:0.0001\n",
      "Epoch 38, Step: 10, Loss: 0.17360901832580566, Lr:0.0001\n",
      "Epoch 38, Step: 11, Loss: 0.08097013831138611, Lr:0.0001\n",
      "Epoch 38, Step: 12, Loss: 0.4826623499393463, Lr:0.0001\n",
      "Epoch 38, Step: 13, Loss: 0.35334208607673645, Lr:0.0001\n",
      "Epoch 38, Step: 14, Loss: 0.3517456650733948, Lr:0.0001\n",
      "Epoch 38, Step: 15, Loss: 0.5874509811401367, Lr:0.0001\n",
      "Epoch 38, Step: 16, Loss: 0.06825651228427887, Lr:0.0001\n",
      "Epoch 38, Step: 17, Loss: 0.6214017271995544, Lr:0.0001\n",
      "Epoch 38, Step: 18, Loss: 0.5398683547973633, Lr:0.0001\n",
      "Epoch 38, Step: 19, Loss: 0.23137535154819489, Lr:0.0001\n",
      "Epoch 38, Step: 20, Loss: 0.7542423009872437, Lr:0.0001\n",
      "Epoch 38, Step: 21, Loss: 0.031696416437625885, Lr:0.0001\n",
      "Epoch 38, Step: 22, Loss: 0.031218912452459335, Lr:0.0001\n",
      "Epoch 38, Step: 23, Loss: 0.13320912420749664, Lr:0.0001\n",
      "Epoch 38, Step: 24, Loss: 0.9177002310752869, Lr:0.0001\n",
      "Epoch 38, Step: 25, Loss: 0.08684930205345154, Lr:0.0001\n",
      "Epoch 38, Step: 26, Loss: 0.09270234405994415, Lr:0.0001\n",
      "Epoch 38, Step: 27, Loss: 0.40606600046157837, Lr:0.0001\n",
      "Epoch 38, Step: 28, Loss: 0.03528338298201561, Lr:0.0001\n",
      "Epoch 38, Step: 29, Loss: 0.5484429597854614, Lr:0.0001\n",
      "Epoch 38, Step: 30, Loss: 0.15179723501205444, Lr:0.0001\n",
      "Epoch 38, Step: 31, Loss: 0.49853163957595825, Lr:0.0001\n",
      "Epoch 38, Step: 32, Loss: 0.06422655284404755, Lr:0.0001\n",
      "Epoch 38, Step: 33, Loss: 0.00430078711360693, Lr:0.0001\n",
      "Epoch 38, Step: 34, Loss: 0.3903985321521759, Lr:0.0001\n",
      "Epoch 38, Step: 35, Loss: 0.2569723427295685, Lr:0.0001\n",
      "Epoch 38, Step: 36, Loss: 0.5779998302459717, Lr:0.0001\n",
      "Epoch 38, Step: 37, Loss: 0.07456882297992706, Lr:0.0001\n",
      "Epoch 38, Step: 38, Loss: 0.010802239179611206, Lr:0.0001\n",
      "Epoch 38, Step: 39, Loss: 0.5317678451538086, Lr:0.0001\n",
      "Epoch 38, Step: 40, Loss: 0.6084795594215393, Lr:0.0001\n",
      "Epoch 38, Step: 41, Loss: 0.5082904696464539, Lr:0.0001\n",
      "Epoch 38, Step: 42, Loss: 0.14988413453102112, Lr:0.0001\n",
      "Epoch 38, Step: 43, Loss: 0.5081105828285217, Lr:0.0001\n",
      "Epoch 38, Step: 44, Loss: 0.0033295871689915657, Lr:0.0001\n",
      "Epoch 38, Step: 45, Loss: 0.4476488530635834, Lr:0.0001\n",
      "Epoch 38, Step: 46, Loss: 0.06210721284151077, Lr:0.0001\n",
      "Epoch 38, Step: 47, Loss: 1.2055987119674683, Lr:0.0001\n",
      "Epoch 38, Step: 48, Loss: 0.013561420142650604, Lr:0.0001\n",
      "Epoch 38, Step: 49, Loss: 0.011572071351110935, Lr:0.0001\n",
      "Epoch 38, Step: 50, Loss: 1.115902066230774, Lr:0.0001\n",
      "Epoch 38, Step: 51, Loss: 0.35789838433265686, Lr:0.0001\n",
      "Epoch 38, Step: 52, Loss: 0.9395954608917236, Lr:0.0001\n",
      "Epoch 38, Step: 53, Loss: 0.6149759888648987, Lr:0.0001\n",
      "Epoch 38, Step: 54, Loss: 0.04396217688918114, Lr:0.0001\n",
      "Epoch 38, Step: 55, Loss: 1.5310959815979004, Lr:0.0001\n",
      "Epoch 38, Step: 56, Loss: 0.22683832049369812, Lr:0.0001\n",
      "Epoch 38, Step: 57, Loss: 0.3945164680480957, Lr:0.0001\n",
      "Epoch 38, Step: 58, Loss: 0.0037908314261585474, Lr:0.0001\n",
      "Epoch 38, Step: 59, Loss: 1.0460143089294434, Lr:0.0001\n",
      "Epoch 38, Step: 60, Loss: 0.04183390736579895, Lr:0.0001\n",
      "Epoch 38, Step: 61, Loss: 0.4834349751472473, Lr:0.0001\n",
      "Epoch 38, Step: 62, Loss: 0.08624878525733948, Lr:0.0001\n",
      "Epoch 38, Step: 63, Loss: 0.32897940278053284, Lr:0.0001\n",
      "Epoch 38, Step: 64, Loss: 0.2742331326007843, Lr:0.0001\n",
      "Epoch 38, Step: 65, Loss: 0.2375124990940094, Lr:0.0001\n",
      "Epoch 38, Step: 66, Loss: 0.2678985595703125, Lr:0.0001\n",
      "Epoch 38, Step: 67, Loss: 0.33704206347465515, Lr:0.0001\n",
      "Epoch 38, Step: 68, Loss: 0.6815819144248962, Lr:0.0001\n",
      "Epoch 38, Step: 69, Loss: 0.8099846839904785, Lr:0.0001\n",
      "Epoch 38, Step: 70, Loss: 0.7248731255531311, Lr:0.0001\n",
      "Epoch 38, Step: 71, Loss: 0.02434983104467392, Lr:0.0001\n",
      "Epoch 38, Step: 72, Loss: 0.32871270179748535, Lr:0.0001\n",
      "Epoch 38, Step: 73, Loss: 0.788213849067688, Lr:0.0001\n",
      "Epoch 38, Step: 74, Loss: 0.09598909318447113, Lr:0.0001\n",
      "Epoch 38, Step: 75, Loss: 0.18309690058231354, Lr:0.0001\n",
      "Epoch 38, Step: 76, Loss: 0.5637146234512329, Lr:0.0001\n",
      "Epoch 38, Step: 77, Loss: 0.3798922300338745, Lr:0.0001\n",
      "Epoch 38, Step: 78, Loss: 0.9574759602546692, Lr:0.0001\n",
      "Epoch 38, Step: 79, Loss: 0.7859795093536377, Lr:0.0001\n",
      "Epoch 38, Step: 80, Loss: 1.8103702068328857, Lr:0.0001\n",
      "Epoch 38, Step: 81, Loss: 0.2515963315963745, Lr:0.0001\n",
      "Epoch 38, Step: 82, Loss: 0.2543897032737732, Lr:0.0001\n",
      "Epoch 38, Step: 83, Loss: 0.4214811623096466, Lr:0.0001\n",
      "Epoch 38, Step: 84, Loss: 0.0028369417414069176, Lr:0.0001\n",
      "Epoch 38, Step: 85, Loss: 0.22207807004451752, Lr:0.0001\n",
      "Epoch 38, Step: 86, Loss: 0.07803241163492203, Lr:0.0001\n",
      "Epoch 38, Step: 87, Loss: 0.01197444461286068, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 38\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.5022 (0.5022) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.0130 data: 0.0070 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.5022 (0.5575) acc1: 75.0000 (77.2727) acc5: 100.0000 (100.0000) time: 0.0093 data: 0.0043 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0095 s / it)\n",
      "* Acc@1 77.273 Acc@5 100.000 loss 0.557\n",
      "Accuracy of the network on the 22 test image: 77.3%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 39, Step: 0, Loss: 0.7825908660888672, Lr:0.0001\n",
      "Epoch 39, Step: 1, Loss: 0.24930322170257568, Lr:0.0001\n",
      "Epoch 39, Step: 2, Loss: 0.4210573434829712, Lr:0.0001\n",
      "Epoch 39, Step: 3, Loss: 0.5169007778167725, Lr:0.0001\n",
      "Epoch 39, Step: 4, Loss: 0.1215498149394989, Lr:0.0001\n",
      "Epoch 39, Step: 5, Loss: 0.5244015455245972, Lr:0.0001\n",
      "Epoch 39, Step: 6, Loss: 0.03995216637849808, Lr:0.0001\n",
      "Epoch 39, Step: 7, Loss: 0.2747322916984558, Lr:0.0001\n",
      "Epoch 39, Step: 8, Loss: 0.2954234778881073, Lr:0.0001\n",
      "Epoch 39, Step: 9, Loss: 0.048206791281700134, Lr:0.0001\n",
      "Epoch 39, Step: 10, Loss: 0.2895927131175995, Lr:0.0001\n",
      "Epoch 39, Step: 11, Loss: 0.010376248508691788, Lr:0.0001\n",
      "Epoch 39, Step: 12, Loss: 0.34792810678482056, Lr:0.0001\n",
      "Epoch 39, Step: 13, Loss: 0.00613527512177825, Lr:0.0001\n",
      "Epoch 39, Step: 14, Loss: 0.1501135230064392, Lr:0.0001\n",
      "Epoch 39, Step: 15, Loss: 0.687801718711853, Lr:0.0001\n",
      "Epoch 39, Step: 16, Loss: 0.27305930852890015, Lr:0.0001\n",
      "Epoch 39, Step: 17, Loss: 0.924464225769043, Lr:0.0001\n",
      "Epoch 39, Step: 18, Loss: 0.2001655399799347, Lr:0.0001\n",
      "Epoch 39, Step: 19, Loss: 0.03731755539774895, Lr:0.0001\n",
      "Epoch 39, Step: 20, Loss: 0.6552973389625549, Lr:0.0001\n",
      "Epoch 39, Step: 21, Loss: 0.13019146025180817, Lr:0.0001\n",
      "Epoch 39, Step: 22, Loss: 0.3316958248615265, Lr:0.0001\n",
      "Epoch 39, Step: 23, Loss: 1.0465649366378784, Lr:0.0001\n",
      "Epoch 39, Step: 24, Loss: 0.00861931499093771, Lr:0.0001\n",
      "Epoch 39, Step: 25, Loss: 0.5220422744750977, Lr:0.0001\n",
      "Epoch 39, Step: 26, Loss: 0.005689650774002075, Lr:0.0001\n",
      "Epoch 39, Step: 27, Loss: 0.45359861850738525, Lr:0.0001\n",
      "Epoch 39, Step: 28, Loss: 0.43243464827537537, Lr:0.0001\n",
      "Epoch 39, Step: 29, Loss: 0.941727876663208, Lr:0.0001\n",
      "Epoch 39, Step: 30, Loss: 0.012519512325525284, Lr:0.0001\n",
      "Epoch 39, Step: 31, Loss: 0.03340037912130356, Lr:0.0001\n",
      "Epoch 39, Step: 32, Loss: 0.2532211244106293, Lr:0.0001\n",
      "Epoch 39, Step: 33, Loss: 0.45793846249580383, Lr:0.0001\n",
      "Epoch 39, Step: 34, Loss: 0.8556705117225647, Lr:0.0001\n",
      "Epoch 39, Step: 35, Loss: 0.3930245637893677, Lr:0.0001\n",
      "Epoch 39, Step: 36, Loss: 1.1721292734146118, Lr:0.0001\n",
      "Epoch 39, Step: 37, Loss: 0.25817981362342834, Lr:0.0001\n",
      "Epoch 39, Step: 38, Loss: 0.24654360115528107, Lr:0.0001\n",
      "Epoch 39, Step: 39, Loss: 0.02065488137304783, Lr:0.0001\n",
      "Epoch 39, Step: 40, Loss: 0.23524542152881622, Lr:0.0001\n",
      "Epoch 39, Step: 41, Loss: 1.0387650728225708, Lr:0.0001\n",
      "Epoch 39, Step: 42, Loss: 0.04743339493870735, Lr:0.0001\n",
      "Epoch 39, Step: 43, Loss: 0.1365625113248825, Lr:0.0001\n",
      "Epoch 39, Step: 44, Loss: 0.520513653755188, Lr:0.0001\n",
      "Epoch 39, Step: 45, Loss: 0.402609258890152, Lr:0.0001\n",
      "Epoch 39, Step: 46, Loss: 0.6023308038711548, Lr:0.0001\n",
      "Epoch 39, Step: 47, Loss: 0.06798356026411057, Lr:0.0001\n",
      "Epoch 39, Step: 48, Loss: 0.6880855560302734, Lr:0.0001\n",
      "Epoch 39, Step: 49, Loss: 0.41618871688842773, Lr:0.0001\n",
      "Epoch 39, Step: 50, Loss: 0.27739349007606506, Lr:0.0001\n",
      "Epoch 39, Step: 51, Loss: 0.761570155620575, Lr:0.0001\n",
      "Epoch 39, Step: 52, Loss: 0.4202314019203186, Lr:0.0001\n",
      "Epoch 39, Step: 53, Loss: 0.10599356889724731, Lr:0.0001\n",
      "Epoch 39, Step: 54, Loss: 0.12320873141288757, Lr:0.0001\n",
      "Epoch 39, Step: 55, Loss: 0.012529635801911354, Lr:0.0001\n",
      "Epoch 39, Step: 56, Loss: 0.28991660475730896, Lr:0.0001\n",
      "Epoch 39, Step: 57, Loss: 0.3648506999015808, Lr:0.0001\n",
      "Epoch 39, Step: 58, Loss: 0.7274768948554993, Lr:0.0001\n",
      "Epoch 39, Step: 59, Loss: 1.2164669036865234, Lr:0.0001\n",
      "Epoch 39, Step: 60, Loss: 0.44970405101776123, Lr:0.0001\n",
      "Epoch 39, Step: 61, Loss: 0.17775675654411316, Lr:0.0001\n",
      "Epoch 39, Step: 62, Loss: 0.7284621596336365, Lr:0.0001\n",
      "Epoch 39, Step: 63, Loss: 0.03927508369088173, Lr:0.0001\n",
      "Epoch 39, Step: 64, Loss: 0.041055046021938324, Lr:0.0001\n",
      "Epoch 39, Step: 65, Loss: 0.09598731249570847, Lr:0.0001\n",
      "Epoch 39, Step: 66, Loss: 0.46959275007247925, Lr:0.0001\n",
      "Epoch 39, Step: 67, Loss: 1.1221014261245728, Lr:0.0001\n",
      "Epoch 39, Step: 68, Loss: 0.15469121932983398, Lr:0.0001\n",
      "Epoch 39, Step: 69, Loss: 0.24688249826431274, Lr:0.0001\n",
      "Epoch 39, Step: 70, Loss: 0.8214948177337646, Lr:0.0001\n",
      "Epoch 39, Step: 71, Loss: 0.007955489680171013, Lr:0.0001\n",
      "Epoch 39, Step: 72, Loss: 0.528459370136261, Lr:0.0001\n",
      "Epoch 39, Step: 73, Loss: 0.37932613492012024, Lr:0.0001\n",
      "Epoch 39, Step: 74, Loss: 0.019350344315171242, Lr:0.0001\n",
      "Epoch 39, Step: 75, Loss: 0.5649654269218445, Lr:0.0001\n",
      "Epoch 39, Step: 76, Loss: 0.6584067940711975, Lr:0.0001\n",
      "Epoch 39, Step: 77, Loss: 0.08642245829105377, Lr:0.0001\n",
      "Epoch 39, Step: 78, Loss: 0.8378271460533142, Lr:0.0001\n",
      "Epoch 39, Step: 79, Loss: 0.006686116103082895, Lr:0.0001\n",
      "Epoch 39, Step: 80, Loss: 0.34271329641342163, Lr:0.0001\n",
      "Epoch 39, Step: 81, Loss: 0.829342246055603, Lr:0.0001\n",
      "Epoch 39, Step: 82, Loss: 0.5189356207847595, Lr:0.0001\n",
      "Epoch 39, Step: 83, Loss: 0.28342580795288086, Lr:0.0001\n",
      "Epoch 39, Step: 84, Loss: 0.07155482470989227, Lr:0.0001\n",
      "Epoch 39, Step: 85, Loss: 0.5743750333786011, Lr:0.0001\n",
      "Epoch 39, Step: 86, Loss: 0.018665295094251633, Lr:0.0001\n",
      "Epoch 39, Step: 87, Loss: 0.5885128378868103, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 39\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.0127 (0.0127) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0120 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.0178 (0.2966) acc1: 100.0000 (86.3636) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0040 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0090 s / it)\n",
      "* Acc@1 86.364 Acc@5 100.000 loss 0.297\n",
      "Accuracy of the network on the 22 test image: 86.4%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 40, Step: 0, Loss: 0.3513091206550598, Lr:0.0001\n",
      "Epoch 40, Step: 1, Loss: 0.5866611003875732, Lr:0.0001\n",
      "Epoch 40, Step: 2, Loss: 0.6371597051620483, Lr:0.0001\n",
      "Epoch 40, Step: 3, Loss: 0.08056531101465225, Lr:0.0001\n",
      "Epoch 40, Step: 4, Loss: 0.23405912518501282, Lr:0.0001\n",
      "Epoch 40, Step: 5, Loss: 0.7863324284553528, Lr:0.0001\n",
      "Epoch 40, Step: 6, Loss: 0.5749573707580566, Lr:0.0001\n",
      "Epoch 40, Step: 7, Loss: 0.4322246313095093, Lr:0.0001\n",
      "Epoch 40, Step: 8, Loss: 0.0355166532099247, Lr:0.0001\n",
      "Epoch 40, Step: 9, Loss: 0.35583144426345825, Lr:0.0001\n",
      "Epoch 40, Step: 10, Loss: 0.012159791775047779, Lr:0.0001\n",
      "Epoch 40, Step: 11, Loss: 0.4675588309764862, Lr:0.0001\n",
      "Epoch 40, Step: 12, Loss: 0.013206861913204193, Lr:0.0001\n",
      "Epoch 40, Step: 13, Loss: 0.7714627981185913, Lr:0.0001\n",
      "Epoch 40, Step: 14, Loss: 0.38823235034942627, Lr:0.0001\n",
      "Epoch 40, Step: 15, Loss: 0.40126851201057434, Lr:0.0001\n",
      "Epoch 40, Step: 16, Loss: 2.0331971645355225, Lr:0.0001\n",
      "Epoch 40, Step: 17, Loss: 0.2681463956832886, Lr:0.0001\n",
      "Epoch 40, Step: 18, Loss: 0.07998046278953552, Lr:0.0001\n",
      "Epoch 40, Step: 19, Loss: 0.365774005651474, Lr:0.0001\n",
      "Epoch 40, Step: 20, Loss: 0.5702022314071655, Lr:0.0001\n",
      "Epoch 40, Step: 21, Loss: 0.09166737645864487, Lr:0.0001\n",
      "Epoch 40, Step: 22, Loss: 0.03561955690383911, Lr:0.0001\n",
      "Epoch 40, Step: 23, Loss: 0.5743515491485596, Lr:0.0001\n",
      "Epoch 40, Step: 24, Loss: 0.5869746804237366, Lr:0.0001\n",
      "Epoch 40, Step: 25, Loss: 0.40575093030929565, Lr:0.0001\n",
      "Epoch 40, Step: 26, Loss: 0.2701372504234314, Lr:0.0001\n",
      "Epoch 40, Step: 27, Loss: 0.8451006412506104, Lr:0.0001\n",
      "Epoch 40, Step: 28, Loss: 0.7832950353622437, Lr:0.0001\n",
      "Epoch 40, Step: 29, Loss: 0.21633410453796387, Lr:0.0001\n",
      "Epoch 40, Step: 30, Loss: 0.4306442439556122, Lr:0.0001\n",
      "Epoch 40, Step: 31, Loss: 0.5032278895378113, Lr:0.0001\n",
      "Epoch 40, Step: 32, Loss: 0.11257059127092361, Lr:0.0001\n",
      "Epoch 40, Step: 33, Loss: 0.27042675018310547, Lr:0.0001\n",
      "Epoch 40, Step: 34, Loss: 0.35811129212379456, Lr:0.0001\n",
      "Epoch 40, Step: 35, Loss: 0.4688991904258728, Lr:0.0001\n",
      "Epoch 40, Step: 36, Loss: 0.2655330300331116, Lr:0.0001\n",
      "Epoch 40, Step: 37, Loss: 0.02297145128250122, Lr:0.0001\n",
      "Epoch 40, Step: 38, Loss: 0.13834306597709656, Lr:0.0001\n",
      "Epoch 40, Step: 39, Loss: 0.2481093853712082, Lr:0.0001\n",
      "Epoch 40, Step: 40, Loss: 4.1577677726745605, Lr:0.0001\n",
      "Epoch 40, Step: 41, Loss: 0.20470023155212402, Lr:0.0001\n",
      "Epoch 40, Step: 42, Loss: 0.3024945557117462, Lr:0.0001\n",
      "Epoch 40, Step: 43, Loss: 0.7612038850784302, Lr:0.0001\n",
      "Epoch 40, Step: 44, Loss: 0.28026720881462097, Lr:0.0001\n",
      "Epoch 40, Step: 45, Loss: 0.8616546988487244, Lr:0.0001\n",
      "Epoch 40, Step: 46, Loss: 0.1393962949514389, Lr:0.0001\n",
      "Epoch 40, Step: 47, Loss: 0.4310843050479889, Lr:0.0001\n",
      "Epoch 40, Step: 48, Loss: 0.19628112018108368, Lr:0.0001\n",
      "Epoch 40, Step: 49, Loss: 0.5627285242080688, Lr:0.0001\n",
      "Epoch 40, Step: 50, Loss: 0.28770121932029724, Lr:0.0001\n",
      "Epoch 40, Step: 51, Loss: 0.44069841504096985, Lr:0.0001\n",
      "Epoch 40, Step: 52, Loss: 0.27999043464660645, Lr:0.0001\n",
      "Epoch 40, Step: 53, Loss: 0.009241592139005661, Lr:0.0001\n",
      "Epoch 40, Step: 54, Loss: 0.018289603292942047, Lr:0.0001\n",
      "Epoch 40, Step: 55, Loss: 0.4236135184764862, Lr:0.0001\n",
      "Epoch 40, Step: 56, Loss: 0.06343219429254532, Lr:0.0001\n",
      "Epoch 40, Step: 57, Loss: 0.20933835208415985, Lr:0.0001\n",
      "Epoch 40, Step: 58, Loss: 0.20912806689739227, Lr:0.0001\n",
      "Epoch 40, Step: 59, Loss: 0.4800627529621124, Lr:0.0001\n",
      "Epoch 40, Step: 60, Loss: 0.4076436460018158, Lr:0.0001\n",
      "Epoch 40, Step: 61, Loss: 0.2124977707862854, Lr:0.0001\n",
      "Epoch 40, Step: 62, Loss: 0.42151138186454773, Lr:0.0001\n",
      "Epoch 40, Step: 63, Loss: 0.25883108377456665, Lr:0.0001\n",
      "Epoch 40, Step: 64, Loss: 0.021467583253979683, Lr:0.0001\n",
      "Epoch 40, Step: 65, Loss: 0.04512696713209152, Lr:0.0001\n",
      "Epoch 40, Step: 66, Loss: 0.006769312545657158, Lr:0.0001\n",
      "Epoch 40, Step: 67, Loss: 0.6216106414794922, Lr:0.0001\n",
      "Epoch 40, Step: 68, Loss: 0.6761770844459534, Lr:0.0001\n",
      "Epoch 40, Step: 69, Loss: 0.3317181169986725, Lr:0.0001\n",
      "Epoch 40, Step: 70, Loss: 0.024826306849718094, Lr:0.0001\n",
      "Epoch 40, Step: 71, Loss: 0.7219957113265991, Lr:0.0001\n",
      "Epoch 40, Step: 72, Loss: 0.5243164300918579, Lr:0.0001\n",
      "Epoch 40, Step: 73, Loss: 0.011370941065251827, Lr:0.0001\n",
      "Epoch 40, Step: 74, Loss: 1.2642874717712402, Lr:0.0001\n",
      "Epoch 40, Step: 75, Loss: 0.07043235749006271, Lr:0.0001\n",
      "Epoch 40, Step: 76, Loss: 0.027124712243676186, Lr:0.0001\n",
      "Epoch 40, Step: 77, Loss: 0.6388724446296692, Lr:0.0001\n",
      "Epoch 40, Step: 78, Loss: 0.06560410559177399, Lr:0.0001\n",
      "Epoch 40, Step: 79, Loss: 0.8098233938217163, Lr:0.0001\n",
      "Epoch 40, Step: 80, Loss: 0.7209184765815735, Lr:0.0001\n",
      "Epoch 40, Step: 81, Loss: 0.2548428475856781, Lr:0.0001\n",
      "Epoch 40, Step: 82, Loss: 0.18729902803897858, Lr:0.0001\n",
      "Epoch 40, Step: 83, Loss: 0.7861728668212891, Lr:0.0001\n",
      "Epoch 40, Step: 84, Loss: 0.17739969491958618, Lr:0.0001\n",
      "Epoch 40, Step: 85, Loss: 0.5506712794303894, Lr:0.0001\n",
      "Epoch 40, Step: 86, Loss: 0.7822244167327881, Lr:0.0001\n",
      "Epoch 40, Step: 87, Loss: 0.21353763341903687, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 40\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.9079 (0.9079) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.0100 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.4988 (0.7938) acc1: 75.0000 (77.2727) acc5: 100.0000 (100.0000) time: 0.0083 data: 0.0040 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0085 s / it)\n",
      "* Acc@1 77.273 Acc@5 100.000 loss 0.794\n",
      "Accuracy of the network on the 22 test image: 77.3%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 41, Step: 0, Loss: 0.4016188383102417, Lr:0.0001\n",
      "Epoch 41, Step: 1, Loss: 0.647138774394989, Lr:0.0001\n",
      "Epoch 41, Step: 2, Loss: 0.09116706252098083, Lr:0.0001\n",
      "Epoch 41, Step: 3, Loss: 0.059425923973321915, Lr:0.0001\n",
      "Epoch 41, Step: 4, Loss: 0.5609834790229797, Lr:0.0001\n",
      "Epoch 41, Step: 5, Loss: 1.0593914985656738, Lr:0.0001\n",
      "Epoch 41, Step: 6, Loss: 0.5516307950019836, Lr:0.0001\n",
      "Epoch 41, Step: 7, Loss: 0.7133238315582275, Lr:0.0001\n",
      "Epoch 41, Step: 8, Loss: 0.396022766828537, Lr:0.0001\n",
      "Epoch 41, Step: 9, Loss: 5.084505081176758, Lr:0.0001\n",
      "Epoch 41, Step: 10, Loss: 0.28692296147346497, Lr:0.0001\n",
      "Epoch 41, Step: 11, Loss: 0.4174712300300598, Lr:0.0001\n",
      "Epoch 41, Step: 12, Loss: 1.8837065696716309, Lr:0.0001\n",
      "Epoch 41, Step: 13, Loss: 0.6176446676254272, Lr:0.0001\n",
      "Epoch 41, Step: 14, Loss: 0.1127130314707756, Lr:0.0001\n",
      "Epoch 41, Step: 15, Loss: 0.17223086953163147, Lr:0.0001\n",
      "Epoch 41, Step: 16, Loss: 0.014116091653704643, Lr:0.0001\n",
      "Epoch 41, Step: 17, Loss: 0.5329940319061279, Lr:0.0001\n",
      "Epoch 41, Step: 18, Loss: 0.773418664932251, Lr:0.0001\n",
      "Epoch 41, Step: 19, Loss: 0.20914746820926666, Lr:0.0001\n",
      "Epoch 41, Step: 20, Loss: 0.03737548738718033, Lr:0.0001\n",
      "Epoch 41, Step: 21, Loss: 0.6403433084487915, Lr:0.0001\n",
      "Epoch 41, Step: 22, Loss: 0.7741596102714539, Lr:0.0001\n",
      "Epoch 41, Step: 23, Loss: 0.11573906987905502, Lr:0.0001\n",
      "Epoch 41, Step: 24, Loss: 0.02068500965833664, Lr:0.0001\n",
      "Epoch 41, Step: 25, Loss: 0.12579022347927094, Lr:0.0001\n",
      "Epoch 41, Step: 26, Loss: 0.10944078862667084, Lr:0.0001\n",
      "Epoch 41, Step: 27, Loss: 0.13377739489078522, Lr:0.0001\n",
      "Epoch 41, Step: 28, Loss: 0.3204366862773895, Lr:0.0001\n",
      "Epoch 41, Step: 29, Loss: 0.8372972011566162, Lr:0.0001\n",
      "Epoch 41, Step: 30, Loss: 0.012144271284341812, Lr:0.0001\n",
      "Epoch 41, Step: 31, Loss: 0.15250937640666962, Lr:0.0001\n",
      "Epoch 41, Step: 32, Loss: 0.2955196797847748, Lr:0.0001\n",
      "Epoch 41, Step: 33, Loss: 0.09429185092449188, Lr:0.0001\n",
      "Epoch 41, Step: 34, Loss: 0.01936265267431736, Lr:0.0001\n",
      "Epoch 41, Step: 35, Loss: 0.3746776282787323, Lr:0.0001\n",
      "Epoch 41, Step: 36, Loss: 0.021521996706724167, Lr:0.0001\n",
      "Epoch 41, Step: 37, Loss: 0.2679891288280487, Lr:0.0001\n",
      "Epoch 41, Step: 38, Loss: 0.9218239784240723, Lr:0.0001\n",
      "Epoch 41, Step: 39, Loss: 0.16279847919940948, Lr:0.0001\n",
      "Epoch 41, Step: 40, Loss: 0.02176845073699951, Lr:0.0001\n",
      "Epoch 41, Step: 41, Loss: 0.4087357223033905, Lr:0.0001\n",
      "Epoch 41, Step: 42, Loss: 0.2602511942386627, Lr:0.0001\n",
      "Epoch 41, Step: 43, Loss: 0.2632497549057007, Lr:0.0001\n",
      "Epoch 41, Step: 44, Loss: 0.27858561277389526, Lr:0.0001\n",
      "Epoch 41, Step: 45, Loss: 0.24789327383041382, Lr:0.0001\n",
      "Epoch 41, Step: 46, Loss: 0.9555557370185852, Lr:0.0001\n",
      "Epoch 41, Step: 47, Loss: 0.1510409563779831, Lr:0.0001\n",
      "Epoch 41, Step: 48, Loss: 0.4666922092437744, Lr:0.0001\n",
      "Epoch 41, Step: 49, Loss: 0.4796643853187561, Lr:0.0001\n",
      "Epoch 41, Step: 50, Loss: 0.32299166917800903, Lr:0.0001\n",
      "Epoch 41, Step: 51, Loss: 0.9505442976951599, Lr:0.0001\n",
      "Epoch 41, Step: 52, Loss: 0.01131762471050024, Lr:0.0001\n",
      "Epoch 41, Step: 53, Loss: 0.15791864693164825, Lr:0.0001\n",
      "Epoch 41, Step: 54, Loss: 0.7032471299171448, Lr:0.0001\n",
      "Epoch 41, Step: 55, Loss: 0.35118919610977173, Lr:0.0001\n",
      "Epoch 41, Step: 56, Loss: 0.176555335521698, Lr:0.0001\n",
      "Epoch 41, Step: 57, Loss: 0.32165423035621643, Lr:0.0001\n",
      "Epoch 41, Step: 58, Loss: 0.4131622612476349, Lr:0.0001\n",
      "Epoch 41, Step: 59, Loss: 0.24343475699424744, Lr:0.0001\n",
      "Epoch 41, Step: 60, Loss: 0.6965147256851196, Lr:0.0001\n",
      "Epoch 41, Step: 61, Loss: 0.09316004067659378, Lr:0.0001\n",
      "Epoch 41, Step: 62, Loss: 0.3423783779144287, Lr:0.0001\n",
      "Epoch 41, Step: 63, Loss: 0.11755090951919556, Lr:0.0001\n",
      "Epoch 41, Step: 64, Loss: 0.36879006028175354, Lr:0.0001\n",
      "Epoch 41, Step: 65, Loss: 0.006738197058439255, Lr:0.0001\n",
      "Epoch 41, Step: 66, Loss: 0.21263602375984192, Lr:0.0001\n",
      "Epoch 41, Step: 67, Loss: 0.554509162902832, Lr:0.0001\n",
      "Epoch 41, Step: 68, Loss: 0.5486391186714172, Lr:0.0001\n",
      "Epoch 41, Step: 69, Loss: 0.6921414136886597, Lr:0.0001\n",
      "Epoch 41, Step: 70, Loss: 0.2360464334487915, Lr:0.0001\n",
      "Epoch 41, Step: 71, Loss: 0.31824004650115967, Lr:0.0001\n",
      "Epoch 41, Step: 72, Loss: 0.03181138262152672, Lr:0.0001\n",
      "Epoch 41, Step: 73, Loss: 0.2774101793766022, Lr:0.0001\n",
      "Epoch 41, Step: 74, Loss: 0.002004698384553194, Lr:0.0001\n",
      "Epoch 41, Step: 75, Loss: 0.027413439005613327, Lr:0.0001\n",
      "Epoch 41, Step: 76, Loss: 0.44689539074897766, Lr:0.0001\n",
      "Epoch 41, Step: 77, Loss: 0.8511778116226196, Lr:0.0001\n",
      "Epoch 41, Step: 78, Loss: 0.6992520093917847, Lr:0.0001\n",
      "Epoch 41, Step: 79, Loss: 0.584234893321991, Lr:0.0001\n",
      "Epoch 41, Step: 80, Loss: 0.5029518604278564, Lr:0.0001\n",
      "Epoch 41, Step: 81, Loss: 0.039819084107875824, Lr:0.0001\n",
      "Epoch 41, Step: 82, Loss: 0.015243606641888618, Lr:0.0001\n",
      "Epoch 41, Step: 83, Loss: 0.4763602614402771, Lr:0.0001\n",
      "Epoch 41, Step: 84, Loss: 0.5903041958808899, Lr:0.0001\n",
      "Epoch 41, Step: 85, Loss: 0.21627196669578552, Lr:0.0001\n",
      "Epoch 41, Step: 86, Loss: 0.12383159250020981, Lr:0.0001\n",
      "Epoch 41, Step: 87, Loss: 0.40747103095054626, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 41\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.6786 (0.6786) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.6490 (0.6561) acc1: 75.0000 (77.2727) acc5: 100.0000 (100.0000) time: 0.0068 data: 0.0037 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0070 s / it)\n",
      "* Acc@1 77.273 Acc@5 100.000 loss 0.656\n",
      "Accuracy of the network on the 22 test image: 77.3%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 42, Step: 0, Loss: 0.2739035189151764, Lr:0.0001\n",
      "Epoch 42, Step: 1, Loss: 0.541252613067627, Lr:0.0001\n",
      "Epoch 42, Step: 2, Loss: 0.028477689251303673, Lr:0.0001\n",
      "Epoch 42, Step: 3, Loss: 0.5732960104942322, Lr:0.0001\n",
      "Epoch 42, Step: 4, Loss: 0.4198591709136963, Lr:0.0001\n",
      "Epoch 42, Step: 5, Loss: 0.2034791260957718, Lr:0.0001\n",
      "Epoch 42, Step: 6, Loss: 4.456510066986084, Lr:0.0001\n",
      "Epoch 42, Step: 7, Loss: 0.06568983942270279, Lr:0.0001\n",
      "Epoch 42, Step: 8, Loss: 0.0498599149286747, Lr:0.0001\n",
      "Epoch 42, Step: 9, Loss: 0.20379215478897095, Lr:0.0001\n",
      "Epoch 42, Step: 10, Loss: 0.24348129332065582, Lr:0.0001\n",
      "Epoch 42, Step: 11, Loss: 0.002511175349354744, Lr:0.0001\n",
      "Epoch 42, Step: 12, Loss: 0.09356459230184555, Lr:0.0001\n",
      "Epoch 42, Step: 13, Loss: 0.16347187757492065, Lr:0.0001\n",
      "Epoch 42, Step: 14, Loss: 0.41312339901924133, Lr:0.0001\n",
      "Epoch 42, Step: 15, Loss: 0.41788768768310547, Lr:0.0001\n",
      "Epoch 42, Step: 16, Loss: 0.5046543478965759, Lr:0.0001\n",
      "Epoch 42, Step: 17, Loss: 0.2240263819694519, Lr:0.0001\n",
      "Epoch 42, Step: 18, Loss: 0.44520285725593567, Lr:0.0001\n",
      "Epoch 42, Step: 19, Loss: 0.8195924758911133, Lr:0.0001\n",
      "Epoch 42, Step: 20, Loss: 0.022119197994470596, Lr:0.0001\n",
      "Epoch 42, Step: 21, Loss: 0.15879017114639282, Lr:0.0001\n",
      "Epoch 42, Step: 22, Loss: 2.9049317836761475, Lr:0.0001\n",
      "Epoch 42, Step: 23, Loss: 0.07894783467054367, Lr:0.0001\n",
      "Epoch 42, Step: 24, Loss: 0.3977421820163727, Lr:0.0001\n",
      "Epoch 42, Step: 25, Loss: 0.39021971821784973, Lr:0.0001\n",
      "Epoch 42, Step: 26, Loss: 0.47109276056289673, Lr:0.0001\n",
      "Epoch 42, Step: 27, Loss: 0.010927073657512665, Lr:0.0001\n",
      "Epoch 42, Step: 28, Loss: 0.17344316840171814, Lr:0.0001\n",
      "Epoch 42, Step: 29, Loss: 0.04354732483625412, Lr:0.0001\n",
      "Epoch 42, Step: 30, Loss: 0.10206307470798492, Lr:0.0001\n",
      "Epoch 42, Step: 31, Loss: 0.0050679040141403675, Lr:0.0001\n",
      "Epoch 42, Step: 32, Loss: 2.5211644172668457, Lr:0.0001\n",
      "Epoch 42, Step: 33, Loss: 0.8467114567756653, Lr:0.0001\n",
      "Epoch 42, Step: 34, Loss: 0.30373522639274597, Lr:0.0001\n",
      "Epoch 42, Step: 35, Loss: 0.032415665686130524, Lr:0.0001\n",
      "Epoch 42, Step: 36, Loss: 0.7797415852546692, Lr:0.0001\n",
      "Epoch 42, Step: 37, Loss: 0.026346735656261444, Lr:0.0001\n",
      "Epoch 42, Step: 38, Loss: 0.5161980986595154, Lr:0.0001\n",
      "Epoch 42, Step: 39, Loss: 0.4444580674171448, Lr:0.0001\n",
      "Epoch 42, Step: 40, Loss: 0.6136776208877563, Lr:0.0001\n",
      "Epoch 42, Step: 41, Loss: 0.1238124817609787, Lr:0.0001\n",
      "Epoch 42, Step: 42, Loss: 0.3868051767349243, Lr:0.0001\n",
      "Epoch 42, Step: 43, Loss: 0.3162004053592682, Lr:0.0001\n",
      "Epoch 42, Step: 44, Loss: 0.35292044281959534, Lr:0.0001\n",
      "Epoch 42, Step: 45, Loss: 0.6639754772186279, Lr:0.0001\n",
      "Epoch 42, Step: 46, Loss: 0.62714684009552, Lr:0.0001\n",
      "Epoch 42, Step: 47, Loss: 0.18262729048728943, Lr:0.0001\n",
      "Epoch 42, Step: 48, Loss: 0.21718226373195648, Lr:0.0001\n",
      "Epoch 42, Step: 49, Loss: 0.04832405224442482, Lr:0.0001\n",
      "Epoch 42, Step: 50, Loss: 0.020348060876131058, Lr:0.0001\n",
      "Epoch 42, Step: 51, Loss: 1.2920889854431152, Lr:0.0001\n",
      "Epoch 42, Step: 52, Loss: 0.14975623786449432, Lr:0.0001\n",
      "Epoch 42, Step: 53, Loss: 0.38662585616111755, Lr:0.0001\n",
      "Epoch 42, Step: 54, Loss: 1.90297532081604, Lr:0.0001\n",
      "Epoch 42, Step: 55, Loss: 0.2714245319366455, Lr:0.0001\n",
      "Epoch 42, Step: 56, Loss: 0.5094164609909058, Lr:0.0001\n",
      "Epoch 42, Step: 57, Loss: 0.5841989517211914, Lr:0.0001\n",
      "Epoch 42, Step: 58, Loss: 2.0211098194122314, Lr:0.0001\n",
      "Epoch 42, Step: 59, Loss: 0.4055511951446533, Lr:0.0001\n",
      "Epoch 42, Step: 60, Loss: 0.4792446494102478, Lr:0.0001\n",
      "Epoch 42, Step: 61, Loss: 0.5655993223190308, Lr:0.0001\n",
      "Epoch 42, Step: 62, Loss: 0.3385216295719147, Lr:0.0001\n",
      "Epoch 42, Step: 63, Loss: 0.580933690071106, Lr:0.0001\n",
      "Epoch 42, Step: 64, Loss: 0.26500606536865234, Lr:0.0001\n",
      "Epoch 42, Step: 65, Loss: 0.09840864688158035, Lr:0.0001\n",
      "Epoch 42, Step: 66, Loss: 0.27284374833106995, Lr:0.0001\n",
      "Epoch 42, Step: 67, Loss: 0.7043595910072327, Lr:0.0001\n",
      "Epoch 42, Step: 68, Loss: 0.4177599251270294, Lr:0.0001\n",
      "Epoch 42, Step: 69, Loss: 1.0454659461975098, Lr:0.0001\n",
      "Epoch 42, Step: 70, Loss: 1.1312787532806396, Lr:0.0001\n",
      "Epoch 42, Step: 71, Loss: 0.0785539299249649, Lr:0.0001\n",
      "Epoch 42, Step: 72, Loss: 0.43844297528266907, Lr:0.0001\n",
      "Epoch 42, Step: 73, Loss: 0.3918396532535553, Lr:0.0001\n",
      "Epoch 42, Step: 74, Loss: 0.3111523985862732, Lr:0.0001\n",
      "Epoch 42, Step: 75, Loss: 0.7318395376205444, Lr:0.0001\n",
      "Epoch 42, Step: 76, Loss: 0.2299206554889679, Lr:0.0001\n",
      "Epoch 42, Step: 77, Loss: 0.016597189009189606, Lr:0.0001\n",
      "Epoch 42, Step: 78, Loss: 0.7395510077476501, Lr:0.0001\n",
      "Epoch 42, Step: 79, Loss: 0.1017676517367363, Lr:0.0001\n",
      "Epoch 42, Step: 80, Loss: 0.3955961763858795, Lr:0.0001\n",
      "Epoch 42, Step: 81, Loss: 0.25024333596229553, Lr:0.0001\n",
      "Epoch 42, Step: 82, Loss: 0.510435938835144, Lr:0.0001\n",
      "Epoch 42, Step: 83, Loss: 0.384232759475708, Lr:0.0001\n",
      "Epoch 42, Step: 84, Loss: 0.29167696833610535, Lr:0.0001\n",
      "Epoch 42, Step: 85, Loss: 0.5553956031799316, Lr:0.0001\n",
      "Epoch 42, Step: 86, Loss: 0.07973334193229675, Lr:0.0001\n",
      "Epoch 42, Step: 87, Loss: 0.8565288782119751, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 42\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.0023 (0.0023) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0110 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.0357 (0.4337) acc1: 100.0000 (81.8182) acc5: 100.0000 (100.0000) time: 0.0093 data: 0.0047 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0093 s / it)\n",
      "* Acc@1 81.818 Acc@5 100.000 loss 0.434\n",
      "Accuracy of the network on the 22 test image: 81.8%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 43, Step: 0, Loss: 0.04350966587662697, Lr:0.0001\n",
      "Epoch 43, Step: 1, Loss: 0.5688068866729736, Lr:0.0001\n",
      "Epoch 43, Step: 2, Loss: 0.09321627765893936, Lr:0.0001\n",
      "Epoch 43, Step: 3, Loss: 0.5952135324478149, Lr:0.0001\n",
      "Epoch 43, Step: 4, Loss: 0.4445440471172333, Lr:0.0001\n",
      "Epoch 43, Step: 5, Loss: 0.18859532475471497, Lr:0.0001\n",
      "Epoch 43, Step: 6, Loss: 0.24564425647258759, Lr:0.0001\n",
      "Epoch 43, Step: 7, Loss: 0.10050026327371597, Lr:0.0001\n",
      "Epoch 43, Step: 8, Loss: 0.4159679114818573, Lr:0.0001\n",
      "Epoch 43, Step: 9, Loss: 4.49715518951416, Lr:0.0001\n",
      "Epoch 43, Step: 10, Loss: 0.7256476879119873, Lr:0.0001\n",
      "Epoch 43, Step: 11, Loss: 0.2517986297607422, Lr:0.0001\n",
      "Epoch 43, Step: 12, Loss: 0.3464317321777344, Lr:0.0001\n",
      "Epoch 43, Step: 13, Loss: 0.06194973364472389, Lr:0.0001\n",
      "Epoch 43, Step: 14, Loss: 0.15737181901931763, Lr:0.0001\n",
      "Epoch 43, Step: 15, Loss: 0.2737543284893036, Lr:0.0001\n",
      "Epoch 43, Step: 16, Loss: 1.1405826807022095, Lr:0.0001\n",
      "Epoch 43, Step: 17, Loss: 0.716262936592102, Lr:0.0001\n",
      "Epoch 43, Step: 18, Loss: 0.3939898610115051, Lr:0.0001\n",
      "Epoch 43, Step: 19, Loss: 0.7819860577583313, Lr:0.0001\n",
      "Epoch 43, Step: 20, Loss: 0.16219699382781982, Lr:0.0001\n",
      "Epoch 43, Step: 21, Loss: 0.4588962495326996, Lr:0.0001\n",
      "Epoch 43, Step: 22, Loss: 0.44963058829307556, Lr:0.0001\n",
      "Epoch 43, Step: 23, Loss: 0.14612425863742828, Lr:0.0001\n",
      "Epoch 43, Step: 24, Loss: 0.4852502942085266, Lr:0.0001\n",
      "Epoch 43, Step: 25, Loss: 0.42645910382270813, Lr:0.0001\n",
      "Epoch 43, Step: 26, Loss: 0.4521231949329376, Lr:0.0001\n",
      "Epoch 43, Step: 27, Loss: 0.6532255411148071, Lr:0.0001\n",
      "Epoch 43, Step: 28, Loss: 0.023675275966525078, Lr:0.0001\n",
      "Epoch 43, Step: 29, Loss: 0.9421879053115845, Lr:0.0001\n",
      "Epoch 43, Step: 30, Loss: 0.3813576400279999, Lr:0.0001\n",
      "Epoch 43, Step: 31, Loss: 0.593375563621521, Lr:0.0001\n",
      "Epoch 43, Step: 32, Loss: 0.10873903334140778, Lr:0.0001\n",
      "Epoch 43, Step: 33, Loss: 0.4453607201576233, Lr:0.0001\n",
      "Epoch 43, Step: 34, Loss: 0.029526297003030777, Lr:0.0001\n",
      "Epoch 43, Step: 35, Loss: 0.4038740396499634, Lr:0.0001\n",
      "Epoch 43, Step: 36, Loss: 1.6337668895721436, Lr:0.0001\n",
      "Epoch 43, Step: 37, Loss: 0.10879525542259216, Lr:0.0001\n",
      "Epoch 43, Step: 38, Loss: 0.03522743284702301, Lr:0.0001\n",
      "Epoch 43, Step: 39, Loss: 0.6146953701972961, Lr:0.0001\n",
      "Epoch 43, Step: 40, Loss: 0.2520359754562378, Lr:0.0001\n",
      "Epoch 43, Step: 41, Loss: 0.026136459782719612, Lr:0.0001\n",
      "Epoch 43, Step: 42, Loss: 0.29422640800476074, Lr:0.0001\n",
      "Epoch 43, Step: 43, Loss: 0.030529234558343887, Lr:0.0001\n",
      "Epoch 43, Step: 44, Loss: 0.465562641620636, Lr:0.0001\n",
      "Epoch 43, Step: 45, Loss: 0.4299336373806, Lr:0.0001\n",
      "Epoch 43, Step: 46, Loss: 0.6517202854156494, Lr:0.0001\n",
      "Epoch 43, Step: 47, Loss: 0.26806098222732544, Lr:0.0001\n",
      "Epoch 43, Step: 48, Loss: 0.5849559903144836, Lr:0.0001\n",
      "Epoch 43, Step: 49, Loss: 0.17537406086921692, Lr:0.0001\n",
      "Epoch 43, Step: 50, Loss: 0.05169137194752693, Lr:0.0001\n",
      "Epoch 43, Step: 51, Loss: 0.4521050453186035, Lr:0.0001\n",
      "Epoch 43, Step: 52, Loss: 0.269255667924881, Lr:0.0001\n",
      "Epoch 43, Step: 53, Loss: 0.015290632843971252, Lr:0.0001\n",
      "Epoch 43, Step: 54, Loss: 0.019740009680390358, Lr:0.0001\n",
      "Epoch 43, Step: 55, Loss: 1.3751013278961182, Lr:0.0001\n",
      "Epoch 43, Step: 56, Loss: 0.42883986234664917, Lr:0.0001\n",
      "Epoch 43, Step: 57, Loss: 0.2746017873287201, Lr:0.0001\n",
      "Epoch 43, Step: 58, Loss: 0.5760697722434998, Lr:0.0001\n",
      "Epoch 43, Step: 59, Loss: 0.1560022234916687, Lr:0.0001\n",
      "Epoch 43, Step: 60, Loss: 0.24729159474372864, Lr:0.0001\n",
      "Epoch 43, Step: 61, Loss: 2.0991828441619873, Lr:0.0001\n",
      "Epoch 43, Step: 62, Loss: 0.20298391580581665, Lr:0.0001\n",
      "Epoch 43, Step: 63, Loss: 0.10387691110372543, Lr:0.0001\n",
      "Epoch 43, Step: 64, Loss: 3.9731414318084717, Lr:0.0001\n",
      "Epoch 43, Step: 65, Loss: 0.011634055525064468, Lr:0.0001\n",
      "Epoch 43, Step: 66, Loss: 0.058697380125522614, Lr:0.0001\n",
      "Epoch 43, Step: 67, Loss: 0.3537270426750183, Lr:0.0001\n",
      "Epoch 43, Step: 68, Loss: 1.4551976919174194, Lr:0.0001\n",
      "Epoch 43, Step: 69, Loss: 0.6765186786651611, Lr:0.0001\n",
      "Epoch 43, Step: 70, Loss: 0.01758868247270584, Lr:0.0001\n",
      "Epoch 43, Step: 71, Loss: 0.2490948885679245, Lr:0.0001\n",
      "Epoch 43, Step: 72, Loss: 0.8766114711761475, Lr:0.0001\n",
      "Epoch 43, Step: 73, Loss: 0.3309856951236725, Lr:0.0001\n",
      "Epoch 43, Step: 74, Loss: 0.3075602948665619, Lr:0.0001\n",
      "Epoch 43, Step: 75, Loss: 0.8879595994949341, Lr:0.0001\n",
      "Epoch 43, Step: 76, Loss: 0.04483054578304291, Lr:0.0001\n",
      "Epoch 43, Step: 77, Loss: 0.056160639971494675, Lr:0.0001\n",
      "Epoch 43, Step: 78, Loss: 0.2590942084789276, Lr:0.0001\n",
      "Epoch 43, Step: 79, Loss: 0.07903885841369629, Lr:0.0001\n",
      "Epoch 43, Step: 80, Loss: 0.22848589718341827, Lr:0.0001\n",
      "Epoch 43, Step: 81, Loss: 0.617072582244873, Lr:0.0001\n",
      "Epoch 43, Step: 82, Loss: 0.1262354999780655, Lr:0.0001\n",
      "Epoch 43, Step: 83, Loss: 0.8883137702941895, Lr:0.0001\n",
      "Epoch 43, Step: 84, Loss: 0.18304701149463654, Lr:0.0001\n",
      "Epoch 43, Step: 85, Loss: 0.1354331225156784, Lr:0.0001\n",
      "Epoch 43, Step: 86, Loss: 0.022433370351791382, Lr:0.0001\n",
      "Epoch 43, Step: 87, Loss: 0.3794648051261902, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 43\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 1.8345 (1.8345) acc1: 50.0000 (50.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 1.0950 (1.1054) acc1: 50.0000 (68.1818) acc5: 100.0000 (100.0000) time: 0.0065 data: 0.0037 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0065 s / it)\n",
      "* Acc@1 68.182 Acc@5 100.000 loss 1.105\n",
      "Accuracy of the network on the 22 test image: 68.2%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 44, Step: 0, Loss: 0.45890429615974426, Lr:0.0001\n",
      "Epoch 44, Step: 1, Loss: 0.04126354679465294, Lr:0.0001\n",
      "Epoch 44, Step: 2, Loss: 0.6170593500137329, Lr:0.0001\n",
      "Epoch 44, Step: 3, Loss: 1.0925108194351196, Lr:0.0001\n",
      "Epoch 44, Step: 4, Loss: 0.3778376877307892, Lr:0.0001\n",
      "Epoch 44, Step: 5, Loss: 0.4106923043727875, Lr:0.0001\n",
      "Epoch 44, Step: 6, Loss: 0.27409031987190247, Lr:0.0001\n",
      "Epoch 44, Step: 7, Loss: 0.005009032785892487, Lr:0.0001\n",
      "Epoch 44, Step: 8, Loss: 0.19747941195964813, Lr:0.0001\n",
      "Epoch 44, Step: 9, Loss: 0.6129515767097473, Lr:0.0001\n",
      "Epoch 44, Step: 10, Loss: 0.5981512069702148, Lr:0.0001\n",
      "Epoch 44, Step: 11, Loss: 0.6930672526359558, Lr:0.0001\n",
      "Epoch 44, Step: 12, Loss: 0.5881949663162231, Lr:0.0001\n",
      "Epoch 44, Step: 13, Loss: 0.07520972192287445, Lr:0.0001\n",
      "Epoch 44, Step: 14, Loss: 0.7978622317314148, Lr:0.0001\n",
      "Epoch 44, Step: 15, Loss: 0.21170157194137573, Lr:0.0001\n",
      "Epoch 44, Step: 16, Loss: 0.17508770525455475, Lr:0.0001\n",
      "Epoch 44, Step: 17, Loss: 0.530173122882843, Lr:0.0001\n",
      "Epoch 44, Step: 18, Loss: 0.6650729179382324, Lr:0.0001\n",
      "Epoch 44, Step: 19, Loss: 0.7294316291809082, Lr:0.0001\n",
      "Epoch 44, Step: 20, Loss: 0.019598908722400665, Lr:0.0001\n",
      "Epoch 44, Step: 21, Loss: 0.05074082314968109, Lr:0.0001\n",
      "Epoch 44, Step: 22, Loss: 0.09813448786735535, Lr:0.0001\n",
      "Epoch 44, Step: 23, Loss: 0.08708202838897705, Lr:0.0001\n",
      "Epoch 44, Step: 24, Loss: 0.07454139739274979, Lr:0.0001\n",
      "Epoch 44, Step: 25, Loss: 0.277782142162323, Lr:0.0001\n",
      "Epoch 44, Step: 26, Loss: 1.2397654056549072, Lr:0.0001\n",
      "Epoch 44, Step: 27, Loss: 0.024108370766043663, Lr:0.0001\n",
      "Epoch 44, Step: 28, Loss: 0.4187445640563965, Lr:0.0001\n",
      "Epoch 44, Step: 29, Loss: 0.30285823345184326, Lr:0.0001\n",
      "Epoch 44, Step: 30, Loss: 0.16491787135601044, Lr:0.0001\n",
      "Epoch 44, Step: 31, Loss: 0.16063086688518524, Lr:0.0001\n",
      "Epoch 44, Step: 32, Loss: 0.04956486448645592, Lr:0.0001\n",
      "Epoch 44, Step: 33, Loss: 0.20527216792106628, Lr:0.0001\n",
      "Epoch 44, Step: 34, Loss: 0.3997623324394226, Lr:0.0001\n",
      "Epoch 44, Step: 35, Loss: 0.008437657728791237, Lr:0.0001\n",
      "Epoch 44, Step: 36, Loss: 0.10168415307998657, Lr:0.0001\n",
      "Epoch 44, Step: 37, Loss: 0.41748782992362976, Lr:0.0001\n",
      "Epoch 44, Step: 38, Loss: 1.173909306526184, Lr:0.0001\n",
      "Epoch 44, Step: 39, Loss: 0.007843450643122196, Lr:0.0001\n",
      "Epoch 44, Step: 40, Loss: 0.4360926151275635, Lr:0.0001\n",
      "Epoch 44, Step: 41, Loss: 1.4075140953063965, Lr:0.0001\n",
      "Epoch 44, Step: 42, Loss: 0.4545654356479645, Lr:0.0001\n",
      "Epoch 44, Step: 43, Loss: 0.6775150299072266, Lr:0.0001\n",
      "Epoch 44, Step: 44, Loss: 0.5949569940567017, Lr:0.0001\n",
      "Epoch 44, Step: 45, Loss: 0.3525570034980774, Lr:0.0001\n",
      "Epoch 44, Step: 46, Loss: 0.011536557227373123, Lr:0.0001\n",
      "Epoch 44, Step: 47, Loss: 0.331675261259079, Lr:0.0001\n",
      "Epoch 44, Step: 48, Loss: 0.14017654955387115, Lr:0.0001\n",
      "Epoch 44, Step: 49, Loss: 0.9269701242446899, Lr:0.0001\n",
      "Epoch 44, Step: 50, Loss: 0.20614780485630035, Lr:0.0001\n",
      "Epoch 44, Step: 51, Loss: 0.022647660225629807, Lr:0.0001\n",
      "Epoch 44, Step: 52, Loss: 0.5418097376823425, Lr:0.0001\n",
      "Epoch 44, Step: 53, Loss: 0.6188398599624634, Lr:0.0001\n",
      "Epoch 44, Step: 54, Loss: 0.11347267776727676, Lr:0.0001\n",
      "Epoch 44, Step: 55, Loss: 0.2327965497970581, Lr:0.0001\n",
      "Epoch 44, Step: 56, Loss: 0.3229127824306488, Lr:0.0001\n",
      "Epoch 44, Step: 57, Loss: 0.33470040559768677, Lr:0.0001\n",
      "Epoch 44, Step: 58, Loss: 0.016899216920137405, Lr:0.0001\n",
      "Epoch 44, Step: 59, Loss: 0.028164034709334373, Lr:0.0001\n",
      "Epoch 44, Step: 60, Loss: 0.27175644040107727, Lr:0.0001\n",
      "Epoch 44, Step: 61, Loss: 0.44665461778640747, Lr:0.0001\n",
      "Epoch 44, Step: 62, Loss: 0.25444620847702026, Lr:0.0001\n",
      "Epoch 44, Step: 63, Loss: 0.04878349229693413, Lr:0.0001\n",
      "Epoch 44, Step: 64, Loss: 0.24227949976921082, Lr:0.0001\n",
      "Epoch 44, Step: 65, Loss: 0.7190361022949219, Lr:0.0001\n",
      "Epoch 44, Step: 66, Loss: 0.0024010264314711094, Lr:0.0001\n",
      "Epoch 44, Step: 67, Loss: 0.19043974578380585, Lr:0.0001\n",
      "Epoch 44, Step: 68, Loss: 0.48331284523010254, Lr:0.0001\n",
      "Epoch 44, Step: 69, Loss: 0.49760323762893677, Lr:0.0001\n",
      "Epoch 44, Step: 70, Loss: 0.07222376763820648, Lr:0.0001\n",
      "Epoch 44, Step: 71, Loss: 0.5118695497512817, Lr:0.0001\n",
      "Epoch 44, Step: 72, Loss: 0.10406014323234558, Lr:0.0001\n",
      "Epoch 44, Step: 73, Loss: 0.9949383735656738, Lr:0.0001\n",
      "Epoch 44, Step: 74, Loss: 0.6410641670227051, Lr:0.0001\n",
      "Epoch 44, Step: 75, Loss: 0.2673872709274292, Lr:0.0001\n",
      "Epoch 44, Step: 76, Loss: 1.0243759155273438, Lr:0.0001\n",
      "Epoch 44, Step: 77, Loss: 0.10883155465126038, Lr:0.0001\n",
      "Epoch 44, Step: 78, Loss: 0.2666413187980652, Lr:0.0001\n",
      "Epoch 44, Step: 79, Loss: 0.04702944681048393, Lr:0.0001\n",
      "Epoch 44, Step: 80, Loss: 0.28234443068504333, Lr:0.0001\n",
      "Epoch 44, Step: 81, Loss: 0.004628801718354225, Lr:0.0001\n",
      "Epoch 44, Step: 82, Loss: 0.6001349091529846, Lr:0.0001\n",
      "Epoch 44, Step: 83, Loss: 3.3593621253967285, Lr:0.0001\n",
      "Epoch 44, Step: 84, Loss: 0.4368070960044861, Lr:0.0001\n",
      "Epoch 44, Step: 85, Loss: 0.23067471385002136, Lr:0.0001\n",
      "Epoch 44, Step: 86, Loss: 0.8842509388923645, Lr:0.0001\n",
      "Epoch 44, Step: 87, Loss: 0.2784477472305298, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 44\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 1.1635 (1.1635) acc1: 50.0000 (50.0000) acc5: 100.0000 (100.0000) time: 0.0086 data: 0.0056 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.5425 (0.6766) acc1: 75.0000 (72.7273) acc5: 100.0000 (100.0000) time: 0.0074 data: 0.0039 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0078 s / it)\n",
      "* Acc@1 72.727 Acc@5 100.000 loss 0.677\n",
      "Accuracy of the network on the 22 test image: 72.7%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 45, Step: 0, Loss: 0.9272447824478149, Lr:0.0001\n",
      "Epoch 45, Step: 1, Loss: 0.9161055088043213, Lr:0.0001\n",
      "Epoch 45, Step: 2, Loss: 0.392650306224823, Lr:0.0001\n",
      "Epoch 45, Step: 3, Loss: 0.6055946946144104, Lr:0.0001\n",
      "Epoch 45, Step: 4, Loss: 0.0869947001338005, Lr:0.0001\n",
      "Epoch 45, Step: 5, Loss: 0.07322000712156296, Lr:0.0001\n",
      "Epoch 45, Step: 6, Loss: 0.40303027629852295, Lr:0.0001\n",
      "Epoch 45, Step: 7, Loss: 0.5750589966773987, Lr:0.0001\n",
      "Epoch 45, Step: 8, Loss: 0.3411870300769806, Lr:0.0001\n",
      "Epoch 45, Step: 9, Loss: 1.365084171295166, Lr:0.0001\n",
      "Epoch 45, Step: 10, Loss: 0.5508705973625183, Lr:0.0001\n",
      "Epoch 45, Step: 11, Loss: 0.1386818289756775, Lr:0.0001\n",
      "Epoch 45, Step: 12, Loss: 0.010206080041825771, Lr:0.0001\n",
      "Epoch 45, Step: 13, Loss: 0.4703714847564697, Lr:0.0001\n",
      "Epoch 45, Step: 14, Loss: 0.4867601990699768, Lr:0.0001\n",
      "Epoch 45, Step: 15, Loss: 0.030422920361161232, Lr:0.0001\n",
      "Epoch 45, Step: 16, Loss: 0.0772782415151596, Lr:0.0001\n",
      "Epoch 45, Step: 17, Loss: 0.9693942666053772, Lr:0.0001\n",
      "Epoch 45, Step: 18, Loss: 0.3005431294441223, Lr:0.0001\n",
      "Epoch 45, Step: 19, Loss: 0.035646673291921616, Lr:0.0001\n",
      "Epoch 45, Step: 20, Loss: 0.13688179850578308, Lr:0.0001\n",
      "Epoch 45, Step: 21, Loss: 0.10326878726482391, Lr:0.0001\n",
      "Epoch 45, Step: 22, Loss: 0.39053165912628174, Lr:0.0001\n",
      "Epoch 45, Step: 23, Loss: 0.01735687255859375, Lr:0.0001\n",
      "Epoch 45, Step: 24, Loss: 2.471290111541748, Lr:0.0001\n",
      "Epoch 45, Step: 25, Loss: 0.6200219392776489, Lr:0.0001\n",
      "Epoch 45, Step: 26, Loss: 0.08987417817115784, Lr:0.0001\n",
      "Epoch 45, Step: 27, Loss: 0.4858993887901306, Lr:0.0001\n",
      "Epoch 45, Step: 28, Loss: 0.010992951691150665, Lr:0.0001\n",
      "Epoch 45, Step: 29, Loss: 0.019954565912485123, Lr:0.0001\n",
      "Epoch 45, Step: 30, Loss: 0.32872632145881653, Lr:0.0001\n",
      "Epoch 45, Step: 31, Loss: 0.5048112869262695, Lr:0.0001\n",
      "Epoch 45, Step: 32, Loss: 0.3672434985637665, Lr:0.0001\n",
      "Epoch 45, Step: 33, Loss: 1.0156667232513428, Lr:0.0001\n",
      "Epoch 45, Step: 34, Loss: 0.17935359477996826, Lr:0.0001\n",
      "Epoch 45, Step: 35, Loss: 0.08547133207321167, Lr:0.0001\n",
      "Epoch 45, Step: 36, Loss: 0.5241241455078125, Lr:0.0001\n",
      "Epoch 45, Step: 37, Loss: 0.08384118974208832, Lr:0.0001\n",
      "Epoch 45, Step: 38, Loss: 0.08909545838832855, Lr:0.0001\n",
      "Epoch 45, Step: 39, Loss: 0.20158369839191437, Lr:0.0001\n",
      "Epoch 45, Step: 40, Loss: 0.11333426833152771, Lr:0.0001\n",
      "Epoch 45, Step: 41, Loss: 0.4633409082889557, Lr:0.0001\n",
      "Epoch 45, Step: 42, Loss: 0.4244747459888458, Lr:0.0001\n",
      "Epoch 45, Step: 43, Loss: 0.05281106010079384, Lr:0.0001\n",
      "Epoch 45, Step: 44, Loss: 0.5372645854949951, Lr:0.0001\n",
      "Epoch 45, Step: 45, Loss: 0.04780273512005806, Lr:0.0001\n",
      "Epoch 45, Step: 46, Loss: 0.12461188435554504, Lr:0.0001\n",
      "Epoch 45, Step: 47, Loss: 0.10364140570163727, Lr:0.0001\n",
      "Epoch 45, Step: 48, Loss: 0.14459341764450073, Lr:0.0001\n",
      "Epoch 45, Step: 49, Loss: 0.2501969635486603, Lr:0.0001\n",
      "Epoch 45, Step: 50, Loss: 0.0050156693905591965, Lr:0.0001\n",
      "Epoch 45, Step: 51, Loss: 0.31997150182724, Lr:0.0001\n",
      "Epoch 45, Step: 52, Loss: 0.13710413873195648, Lr:0.0001\n",
      "Epoch 45, Step: 53, Loss: 0.48704931139945984, Lr:0.0001\n",
      "Epoch 45, Step: 54, Loss: 0.5671327114105225, Lr:0.0001\n",
      "Epoch 45, Step: 55, Loss: 0.00797313917428255, Lr:0.0001\n",
      "Epoch 45, Step: 56, Loss: 3.009629726409912, Lr:0.0001\n",
      "Epoch 45, Step: 57, Loss: 0.22776319086551666, Lr:0.0001\n",
      "Epoch 45, Step: 58, Loss: 0.00836630817502737, Lr:0.0001\n",
      "Epoch 45, Step: 59, Loss: 0.010454253293573856, Lr:0.0001\n",
      "Epoch 45, Step: 60, Loss: 0.7114194631576538, Lr:0.0001\n",
      "Epoch 45, Step: 61, Loss: 0.34871676564216614, Lr:0.0001\n",
      "Epoch 45, Step: 62, Loss: 0.6391944289207458, Lr:0.0001\n",
      "Epoch 45, Step: 63, Loss: 1.25387442111969, Lr:0.0001\n",
      "Epoch 45, Step: 64, Loss: 0.5951176881790161, Lr:0.0001\n",
      "Epoch 45, Step: 65, Loss: 0.8594611883163452, Lr:0.0001\n",
      "Epoch 45, Step: 66, Loss: 0.26468566060066223, Lr:0.0001\n",
      "Epoch 45, Step: 67, Loss: 0.6526439785957336, Lr:0.0001\n",
      "Epoch 45, Step: 68, Loss: 0.019611772149801254, Lr:0.0001\n",
      "Epoch 45, Step: 69, Loss: 0.29666876792907715, Lr:0.0001\n",
      "Epoch 45, Step: 70, Loss: 0.3339758813381195, Lr:0.0001\n",
      "Epoch 45, Step: 71, Loss: 0.5478931665420532, Lr:0.0001\n",
      "Epoch 45, Step: 72, Loss: 0.1614082306623459, Lr:0.0001\n",
      "Epoch 45, Step: 73, Loss: 0.12970253825187683, Lr:0.0001\n",
      "Epoch 45, Step: 74, Loss: 0.21988306939601898, Lr:0.0001\n",
      "Epoch 45, Step: 75, Loss: 0.3648913502693176, Lr:0.0001\n",
      "Epoch 45, Step: 76, Loss: 0.25983667373657227, Lr:0.0001\n",
      "Epoch 45, Step: 77, Loss: 0.30510246753692627, Lr:0.0001\n",
      "Epoch 45, Step: 78, Loss: 0.23771707713603973, Lr:0.0001\n",
      "Epoch 45, Step: 79, Loss: 0.388336181640625, Lr:0.0001\n",
      "Epoch 45, Step: 80, Loss: 0.4202934801578522, Lr:0.0001\n",
      "Epoch 45, Step: 81, Loss: 0.04204562306404114, Lr:0.0001\n",
      "Epoch 45, Step: 82, Loss: 0.12671515345573425, Lr:0.0001\n",
      "Epoch 45, Step: 83, Loss: 0.22248761355876923, Lr:0.0001\n",
      "Epoch 45, Step: 84, Loss: 0.028554117307066917, Lr:0.0001\n",
      "Epoch 45, Step: 85, Loss: 0.13122329115867615, Lr:0.0001\n",
      "Epoch 45, Step: 86, Loss: 0.039515092968940735, Lr:0.0001\n",
      "Epoch 45, Step: 87, Loss: 1.0299756526947021, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 45\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 2.1126 (2.1126) acc1: 50.0000 (50.0000) acc5: 100.0000 (100.0000) time: 0.0086 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.5093 (0.7932) acc1: 50.0000 (72.7273) acc5: 100.0000 (100.0000) time: 0.0074 data: 0.0035 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0076 s / it)\n",
      "* Acc@1 72.727 Acc@5 100.000 loss 0.793\n",
      "Accuracy of the network on the 22 test image: 72.7%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 46, Step: 0, Loss: 0.40367376804351807, Lr:0.0001\n",
      "Epoch 46, Step: 1, Loss: 0.039411574602127075, Lr:0.0001\n",
      "Epoch 46, Step: 2, Loss: 0.21129019558429718, Lr:0.0001\n",
      "Epoch 46, Step: 3, Loss: 0.15131543576717377, Lr:0.0001\n",
      "Epoch 46, Step: 4, Loss: 0.06377376616001129, Lr:0.0001\n",
      "Epoch 46, Step: 5, Loss: 0.03527814894914627, Lr:0.0001\n",
      "Epoch 46, Step: 6, Loss: 0.31415271759033203, Lr:0.0001\n",
      "Epoch 46, Step: 7, Loss: 0.029955536127090454, Lr:0.0001\n",
      "Epoch 46, Step: 8, Loss: 1.4676593542099, Lr:0.0001\n",
      "Epoch 46, Step: 9, Loss: 0.1633210927248001, Lr:0.0001\n",
      "Epoch 46, Step: 10, Loss: 0.10788683593273163, Lr:0.0001\n",
      "Epoch 46, Step: 11, Loss: 0.2572436034679413, Lr:0.0001\n",
      "Epoch 46, Step: 12, Loss: 0.8295241594314575, Lr:0.0001\n",
      "Epoch 46, Step: 13, Loss: 0.7529479265213013, Lr:0.0001\n",
      "Epoch 46, Step: 14, Loss: 0.0368032343685627, Lr:0.0001\n",
      "Epoch 46, Step: 15, Loss: 0.7063531279563904, Lr:0.0001\n",
      "Epoch 46, Step: 16, Loss: 0.2706068456172943, Lr:0.0001\n",
      "Epoch 46, Step: 17, Loss: 0.044679462909698486, Lr:0.0001\n",
      "Epoch 46, Step: 18, Loss: 0.595562219619751, Lr:0.0001\n",
      "Epoch 46, Step: 19, Loss: 0.20358039438724518, Lr:0.0001\n",
      "Epoch 46, Step: 20, Loss: 0.7825655937194824, Lr:0.0001\n",
      "Epoch 46, Step: 21, Loss: 0.9809325337409973, Lr:0.0001\n",
      "Epoch 46, Step: 22, Loss: 0.08391647040843964, Lr:0.0001\n",
      "Epoch 46, Step: 23, Loss: 0.15938779711723328, Lr:0.0001\n",
      "Epoch 46, Step: 24, Loss: 0.014950095675885677, Lr:0.0001\n",
      "Epoch 46, Step: 25, Loss: 0.4459424614906311, Lr:0.0001\n",
      "Epoch 46, Step: 26, Loss: 0.20649394392967224, Lr:0.0001\n",
      "Epoch 46, Step: 27, Loss: 0.18666422367095947, Lr:0.0001\n",
      "Epoch 46, Step: 28, Loss: 0.4852779805660248, Lr:0.0001\n",
      "Epoch 46, Step: 29, Loss: 0.48857882618904114, Lr:0.0001\n",
      "Epoch 46, Step: 30, Loss: 0.08830307424068451, Lr:0.0001\n",
      "Epoch 46, Step: 31, Loss: 0.18195891380310059, Lr:0.0001\n",
      "Epoch 46, Step: 32, Loss: 0.06561730057001114, Lr:0.0001\n",
      "Epoch 46, Step: 33, Loss: 0.053621556609869, Lr:0.0001\n",
      "Epoch 46, Step: 34, Loss: 0.08152882009744644, Lr:0.0001\n",
      "Epoch 46, Step: 35, Loss: 0.07166741788387299, Lr:0.0001\n",
      "Epoch 46, Step: 36, Loss: 0.5142508745193481, Lr:0.0001\n",
      "Epoch 46, Step: 37, Loss: 0.033904846757650375, Lr:0.0001\n",
      "Epoch 46, Step: 38, Loss: 0.03639163821935654, Lr:0.0001\n",
      "Epoch 46, Step: 39, Loss: 0.5202728509902954, Lr:0.0001\n",
      "Epoch 46, Step: 40, Loss: 0.22539402544498444, Lr:0.0001\n",
      "Epoch 46, Step: 41, Loss: 0.517048716545105, Lr:0.0001\n",
      "Epoch 46, Step: 42, Loss: 0.24902960658073425, Lr:0.0001\n",
      "Epoch 46, Step: 43, Loss: 0.5150445699691772, Lr:0.0001\n",
      "Epoch 46, Step: 44, Loss: 0.5300163626670837, Lr:0.0001\n",
      "Epoch 46, Step: 45, Loss: 0.2826612889766693, Lr:0.0001\n",
      "Epoch 46, Step: 46, Loss: 1.0966746807098389, Lr:0.0001\n",
      "Epoch 46, Step: 47, Loss: 0.9306082725524902, Lr:0.0001\n",
      "Epoch 46, Step: 48, Loss: 0.20168599486351013, Lr:0.0001\n",
      "Epoch 46, Step: 49, Loss: 0.21319624781608582, Lr:0.0001\n",
      "Epoch 46, Step: 50, Loss: 0.014105301350355148, Lr:0.0001\n",
      "Epoch 46, Step: 51, Loss: 0.16485454142093658, Lr:0.0001\n",
      "Epoch 46, Step: 52, Loss: 3.2479491233825684, Lr:0.0001\n",
      "Epoch 46, Step: 53, Loss: 0.23848071694374084, Lr:0.0001\n",
      "Epoch 46, Step: 54, Loss: 0.9098347425460815, Lr:0.0001\n",
      "Epoch 46, Step: 55, Loss: 0.15342876315116882, Lr:0.0001\n",
      "Epoch 46, Step: 56, Loss: 0.503706693649292, Lr:0.0001\n",
      "Epoch 46, Step: 57, Loss: 0.0034157210029661655, Lr:0.0001\n",
      "Epoch 46, Step: 58, Loss: 0.39572346210479736, Lr:0.0001\n",
      "Epoch 46, Step: 59, Loss: 0.803015947341919, Lr:0.0001\n",
      "Epoch 46, Step: 60, Loss: 0.6625033617019653, Lr:0.0001\n",
      "Epoch 46, Step: 61, Loss: 0.13481149077415466, Lr:0.0001\n",
      "Epoch 46, Step: 62, Loss: 0.27190637588500977, Lr:0.0001\n",
      "Epoch 46, Step: 63, Loss: 0.5335414409637451, Lr:0.0001\n",
      "Epoch 46, Step: 64, Loss: 0.004153343383222818, Lr:0.0001\n",
      "Epoch 46, Step: 65, Loss: 0.9428229331970215, Lr:0.0001\n",
      "Epoch 46, Step: 66, Loss: 0.25799760222435, Lr:0.0001\n",
      "Epoch 46, Step: 67, Loss: 0.2885422110557556, Lr:0.0001\n",
      "Epoch 46, Step: 68, Loss: 0.08736841380596161, Lr:0.0001\n",
      "Epoch 46, Step: 69, Loss: 0.003906510770320892, Lr:0.0001\n",
      "Epoch 46, Step: 70, Loss: 1.4734439849853516, Lr:0.0001\n",
      "Epoch 46, Step: 71, Loss: 0.11058911681175232, Lr:0.0001\n",
      "Epoch 46, Step: 72, Loss: 0.003678541164845228, Lr:0.0001\n",
      "Epoch 46, Step: 73, Loss: 0.4281100928783417, Lr:0.0001\n",
      "Epoch 46, Step: 74, Loss: 0.20968356728553772, Lr:0.0001\n",
      "Epoch 46, Step: 75, Loss: 0.0429796501994133, Lr:0.0001\n",
      "Epoch 46, Step: 76, Loss: 0.977580726146698, Lr:0.0001\n",
      "Epoch 46, Step: 77, Loss: 0.7211818695068359, Lr:0.0001\n",
      "Epoch 46, Step: 78, Loss: 0.5236894488334656, Lr:0.0001\n",
      "Epoch 46, Step: 79, Loss: 0.14246657490730286, Lr:0.0001\n",
      "Epoch 46, Step: 80, Loss: 0.03388111665844917, Lr:0.0001\n",
      "Epoch 46, Step: 81, Loss: 0.2578378915786743, Lr:0.0001\n",
      "Epoch 46, Step: 82, Loss: 0.6581369638442993, Lr:0.0001\n",
      "Epoch 46, Step: 83, Loss: 0.17417505383491516, Lr:0.0001\n",
      "Epoch 46, Step: 84, Loss: 0.009339120239019394, Lr:0.0001\n",
      "Epoch 46, Step: 85, Loss: 0.2384859323501587, Lr:0.0001\n",
      "Epoch 46, Step: 86, Loss: 1.125235915184021, Lr:0.0001\n",
      "Epoch 46, Step: 87, Loss: 0.1656322032213211, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 46\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 1.4606 (1.4606) acc1: 75.0000 (75.0000) acc5: 100.0000 (100.0000) time: 0.0100 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.6955 (0.8685) acc1: 50.0000 (68.1818) acc5: 100.0000 (100.0000) time: 0.0083 data: 0.0042 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0083 s / it)\n",
      "* Acc@1 68.182 Acc@5 100.000 loss 0.868\n",
      "Accuracy of the network on the 22 test image: 68.2%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 47, Step: 0, Loss: 0.23836861550807953, Lr:0.0001\n",
      "Epoch 47, Step: 1, Loss: 0.25061506032943726, Lr:0.0001\n",
      "Epoch 47, Step: 2, Loss: 0.3401103615760803, Lr:0.0001\n",
      "Epoch 47, Step: 3, Loss: 0.12943999469280243, Lr:0.0001\n",
      "Epoch 47, Step: 4, Loss: 0.37519705295562744, Lr:0.0001\n",
      "Epoch 47, Step: 5, Loss: 0.6469609141349792, Lr:0.0001\n",
      "Epoch 47, Step: 6, Loss: 0.9212520122528076, Lr:0.0001\n",
      "Epoch 47, Step: 7, Loss: 0.06397742033004761, Lr:0.0001\n",
      "Epoch 47, Step: 8, Loss: 0.9174752235412598, Lr:0.0001\n",
      "Epoch 47, Step: 9, Loss: 0.2947767376899719, Lr:0.0001\n",
      "Epoch 47, Step: 10, Loss: 0.0078953942283988, Lr:0.0001\n",
      "Epoch 47, Step: 11, Loss: 0.011445095762610435, Lr:0.0001\n",
      "Epoch 47, Step: 12, Loss: 0.010889174416661263, Lr:0.0001\n",
      "Epoch 47, Step: 13, Loss: 0.0069943079724907875, Lr:0.0001\n",
      "Epoch 47, Step: 14, Loss: 0.009085885249078274, Lr:0.0001\n",
      "Epoch 47, Step: 15, Loss: 0.3900212049484253, Lr:0.0001\n",
      "Epoch 47, Step: 16, Loss: 0.44569918513298035, Lr:0.0001\n",
      "Epoch 47, Step: 17, Loss: 0.5324279069900513, Lr:0.0001\n",
      "Epoch 47, Step: 18, Loss: 0.1839427798986435, Lr:0.0001\n",
      "Epoch 47, Step: 19, Loss: 0.01892734505236149, Lr:0.0001\n",
      "Epoch 47, Step: 20, Loss: 0.20534899830818176, Lr:0.0001\n",
      "Epoch 47, Step: 21, Loss: 0.0377868227660656, Lr:0.0001\n",
      "Epoch 47, Step: 22, Loss: 0.0013843983178958297, Lr:0.0001\n",
      "Epoch 47, Step: 23, Loss: 0.2738797068595886, Lr:0.0001\n",
      "Epoch 47, Step: 24, Loss: 0.06351815909147263, Lr:0.0001\n",
      "Epoch 47, Step: 25, Loss: 0.2808885872364044, Lr:0.0001\n",
      "Epoch 47, Step: 26, Loss: 0.29403209686279297, Lr:0.0001\n",
      "Epoch 47, Step: 27, Loss: 0.007970700040459633, Lr:0.0001\n",
      "Epoch 47, Step: 28, Loss: 0.5797693133354187, Lr:0.0001\n",
      "Epoch 47, Step: 29, Loss: 0.003669728757813573, Lr:0.0001\n",
      "Epoch 47, Step: 30, Loss: 0.33440086245536804, Lr:0.0001\n",
      "Epoch 47, Step: 31, Loss: 0.13249868154525757, Lr:0.0001\n",
      "Epoch 47, Step: 32, Loss: 0.40256667137145996, Lr:0.0001\n",
      "Epoch 47, Step: 33, Loss: 0.5705457925796509, Lr:0.0001\n",
      "Epoch 47, Step: 34, Loss: 0.04795210435986519, Lr:0.0001\n",
      "Epoch 47, Step: 35, Loss: 0.3654739558696747, Lr:0.0001\n",
      "Epoch 47, Step: 36, Loss: 0.12749400734901428, Lr:0.0001\n",
      "Epoch 47, Step: 37, Loss: 0.0013339495053514838, Lr:0.0001\n",
      "Epoch 47, Step: 38, Loss: 2.6009581089019775, Lr:0.0001\n",
      "Epoch 47, Step: 39, Loss: 0.3215685784816742, Lr:0.0001\n",
      "Epoch 47, Step: 40, Loss: 0.15738826990127563, Lr:0.0001\n",
      "Epoch 47, Step: 41, Loss: 0.5881651043891907, Lr:0.0001\n",
      "Epoch 47, Step: 42, Loss: 0.23296958208084106, Lr:0.0001\n",
      "Epoch 47, Step: 43, Loss: 0.3606182336807251, Lr:0.0001\n",
      "Epoch 47, Step: 44, Loss: 0.05445152521133423, Lr:0.0001\n",
      "Epoch 47, Step: 45, Loss: 0.588699996471405, Lr:0.0001\n",
      "Epoch 47, Step: 46, Loss: 0.46554601192474365, Lr:0.0001\n",
      "Epoch 47, Step: 47, Loss: 0.08285540342330933, Lr:0.0001\n",
      "Epoch 47, Step: 48, Loss: 0.5144486427307129, Lr:0.0001\n",
      "Epoch 47, Step: 49, Loss: 0.3167352080345154, Lr:0.0001\n",
      "Epoch 47, Step: 50, Loss: 0.27287623286247253, Lr:0.0001\n",
      "Epoch 47, Step: 51, Loss: 0.8825892806053162, Lr:0.0001\n",
      "Epoch 47, Step: 52, Loss: 0.370399534702301, Lr:0.0001\n",
      "Epoch 47, Step: 53, Loss: 0.17767667770385742, Lr:0.0001\n",
      "Epoch 47, Step: 54, Loss: 0.21735504269599915, Lr:0.0001\n",
      "Epoch 47, Step: 55, Loss: 0.31169670820236206, Lr:0.0001\n",
      "Epoch 47, Step: 56, Loss: 0.21913236379623413, Lr:0.0001\n",
      "Epoch 47, Step: 57, Loss: 0.6212448477745056, Lr:0.0001\n",
      "Epoch 47, Step: 58, Loss: 0.6698180437088013, Lr:0.0001\n",
      "Epoch 47, Step: 59, Loss: 0.1349967122077942, Lr:0.0001\n",
      "Epoch 47, Step: 60, Loss: 0.36245009303092957, Lr:0.0001\n",
      "Epoch 47, Step: 61, Loss: 0.1259002387523651, Lr:0.0001\n",
      "Epoch 47, Step: 62, Loss: 0.005454191006720066, Lr:0.0001\n",
      "Epoch 47, Step: 63, Loss: 1.1950641870498657, Lr:0.0001\n",
      "Epoch 47, Step: 64, Loss: 0.15083904564380646, Lr:0.0001\n",
      "Epoch 47, Step: 65, Loss: 0.018874013796448708, Lr:0.0001\n",
      "Epoch 47, Step: 66, Loss: 0.3346148431301117, Lr:0.0001\n",
      "Epoch 47, Step: 67, Loss: 0.4664757549762726, Lr:0.0001\n",
      "Epoch 47, Step: 68, Loss: 0.7028841972351074, Lr:0.0001\n",
      "Epoch 47, Step: 69, Loss: 0.10329890251159668, Lr:0.0001\n",
      "Epoch 47, Step: 70, Loss: 0.12715643644332886, Lr:0.0001\n",
      "Epoch 47, Step: 71, Loss: 0.17888662219047546, Lr:0.0001\n",
      "Epoch 47, Step: 72, Loss: 0.04283547401428223, Lr:0.0001\n",
      "Epoch 47, Step: 73, Loss: 0.28517264127731323, Lr:0.0001\n",
      "Epoch 47, Step: 74, Loss: 0.6422520279884338, Lr:0.0001\n",
      "Epoch 47, Step: 75, Loss: 0.6639246344566345, Lr:0.0001\n",
      "Epoch 47, Step: 76, Loss: 0.4699358344078064, Lr:0.0001\n",
      "Epoch 47, Step: 77, Loss: 0.06697914004325867, Lr:0.0001\n",
      "Epoch 47, Step: 78, Loss: 0.33434444665908813, Lr:0.0001\n",
      "Epoch 47, Step: 79, Loss: 0.010666697286069393, Lr:0.0001\n",
      "Epoch 47, Step: 80, Loss: 0.3057476580142975, Lr:0.0001\n",
      "Epoch 47, Step: 81, Loss: 0.5961333513259888, Lr:0.0001\n",
      "Epoch 47, Step: 82, Loss: 0.07470167428255081, Lr:0.0001\n",
      "Epoch 47, Step: 83, Loss: 0.044521674513816833, Lr:0.0001\n",
      "Epoch 47, Step: 84, Loss: 0.05005615949630737, Lr:0.0001\n",
      "Epoch 47, Step: 85, Loss: 0.029649626463651657, Lr:0.0001\n",
      "Epoch 47, Step: 86, Loss: 0.40438759326934814, Lr:0.0001\n",
      "Epoch 47, Step: 87, Loss: 0.06184889376163483, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 47\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 1.7530 (1.7530) acc1: 50.0000 (50.0000) acc5: 100.0000 (100.0000) time: 0.0090 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.6472 (0.9862) acc1: 50.0000 (68.1818) acc5: 100.0000 (100.0000) time: 0.0073 data: 0.0038 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0075 s / it)\n",
      "* Acc@1 68.182 Acc@5 100.000 loss 0.986\n",
      "Accuracy of the network on the 22 test image: 68.2%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 48, Step: 0, Loss: 0.035305775701999664, Lr:0.0001\n",
      "Epoch 48, Step: 1, Loss: 0.2168913185596466, Lr:0.0001\n",
      "Epoch 48, Step: 2, Loss: 0.32669076323509216, Lr:0.0001\n",
      "Epoch 48, Step: 3, Loss: 0.3131064176559448, Lr:0.0001\n",
      "Epoch 48, Step: 4, Loss: 0.41111981868743896, Lr:0.0001\n",
      "Epoch 48, Step: 5, Loss: 0.24059134721755981, Lr:0.0001\n",
      "Epoch 48, Step: 6, Loss: 0.10038430243730545, Lr:0.0001\n",
      "Epoch 48, Step: 7, Loss: 0.014427158050239086, Lr:0.0001\n",
      "Epoch 48, Step: 8, Loss: 0.6252918839454651, Lr:0.0001\n",
      "Epoch 48, Step: 9, Loss: 0.5051420331001282, Lr:0.0001\n",
      "Epoch 48, Step: 10, Loss: 0.07786357402801514, Lr:0.0001\n",
      "Epoch 48, Step: 11, Loss: 1.1897692680358887, Lr:0.0001\n",
      "Epoch 48, Step: 12, Loss: 0.5170718431472778, Lr:0.0001\n",
      "Epoch 48, Step: 13, Loss: 0.03109666518867016, Lr:0.0001\n",
      "Epoch 48, Step: 14, Loss: 0.2789537012577057, Lr:0.0001\n",
      "Epoch 48, Step: 15, Loss: 0.39647722244262695, Lr:0.0001\n",
      "Epoch 48, Step: 16, Loss: 0.3822230398654938, Lr:0.0001\n",
      "Epoch 48, Step: 17, Loss: 0.33193838596343994, Lr:0.0001\n",
      "Epoch 48, Step: 18, Loss: 0.7092416882514954, Lr:0.0001\n",
      "Epoch 48, Step: 19, Loss: 0.06827668845653534, Lr:0.0001\n",
      "Epoch 48, Step: 20, Loss: 0.15826812386512756, Lr:0.0001\n",
      "Epoch 48, Step: 21, Loss: 0.09825615584850311, Lr:0.0001\n",
      "Epoch 48, Step: 22, Loss: 0.26382097601890564, Lr:0.0001\n",
      "Epoch 48, Step: 23, Loss: 0.08765905350446701, Lr:0.0001\n",
      "Epoch 48, Step: 24, Loss: 1.1438759565353394, Lr:0.0001\n",
      "Epoch 48, Step: 25, Loss: 0.036776017397642136, Lr:0.0001\n",
      "Epoch 48, Step: 26, Loss: 0.4298403859138489, Lr:0.0001\n",
      "Epoch 48, Step: 27, Loss: 0.007853909395635128, Lr:0.0001\n",
      "Epoch 48, Step: 28, Loss: 0.7046594619750977, Lr:0.0001\n",
      "Epoch 48, Step: 29, Loss: 0.4637766480445862, Lr:0.0001\n",
      "Epoch 48, Step: 30, Loss: 0.06133951619267464, Lr:0.0001\n",
      "Epoch 48, Step: 31, Loss: 0.020916273817420006, Lr:0.0001\n",
      "Epoch 48, Step: 32, Loss: 0.5467429161071777, Lr:0.0001\n",
      "Epoch 48, Step: 33, Loss: 0.006061546038836241, Lr:0.0001\n",
      "Epoch 48, Step: 34, Loss: 1.0368802547454834, Lr:0.0001\n",
      "Epoch 48, Step: 35, Loss: 0.005812219809740782, Lr:0.0001\n",
      "Epoch 48, Step: 36, Loss: 0.18722344934940338, Lr:0.0001\n",
      "Epoch 48, Step: 37, Loss: 0.009161640889942646, Lr:0.0001\n",
      "Epoch 48, Step: 38, Loss: 0.4068712294101715, Lr:0.0001\n",
      "Epoch 48, Step: 39, Loss: 0.862043559551239, Lr:0.0001\n",
      "Epoch 48, Step: 40, Loss: 0.20746412873268127, Lr:0.0001\n",
      "Epoch 48, Step: 41, Loss: 0.1017335057258606, Lr:0.0001\n",
      "Epoch 48, Step: 42, Loss: 0.4494114816188812, Lr:0.0001\n",
      "Epoch 48, Step: 43, Loss: 1.0658230781555176, Lr:0.0001\n",
      "Epoch 48, Step: 44, Loss: 0.07036463171243668, Lr:0.0001\n",
      "Epoch 48, Step: 45, Loss: 0.2074311226606369, Lr:0.0001\n",
      "Epoch 48, Step: 46, Loss: 0.04421613737940788, Lr:0.0001\n",
      "Epoch 48, Step: 47, Loss: 0.3429538309574127, Lr:0.0001\n",
      "Epoch 48, Step: 48, Loss: 0.003324769902974367, Lr:0.0001\n",
      "Epoch 48, Step: 49, Loss: 0.41327276825904846, Lr:0.0001\n",
      "Epoch 48, Step: 50, Loss: 0.00456067593768239, Lr:0.0001\n",
      "Epoch 48, Step: 51, Loss: 0.5839437246322632, Lr:0.0001\n",
      "Epoch 48, Step: 52, Loss: 0.4709292948246002, Lr:0.0001\n",
      "Epoch 48, Step: 53, Loss: 0.4106280207633972, Lr:0.0001\n",
      "Epoch 48, Step: 54, Loss: 0.6076304912567139, Lr:0.0001\n",
      "Epoch 48, Step: 55, Loss: 0.16790129244327545, Lr:0.0001\n",
      "Epoch 48, Step: 56, Loss: 0.5120583772659302, Lr:0.0001\n",
      "Epoch 48, Step: 57, Loss: 0.158066064119339, Lr:0.0001\n",
      "Epoch 48, Step: 58, Loss: 0.5411854982376099, Lr:0.0001\n",
      "Epoch 48, Step: 59, Loss: 0.1519680619239807, Lr:0.0001\n",
      "Epoch 48, Step: 60, Loss: 0.182803675532341, Lr:0.0001\n",
      "Epoch 48, Step: 61, Loss: 0.018789876252412796, Lr:0.0001\n",
      "Epoch 48, Step: 62, Loss: 0.48372501134872437, Lr:0.0001\n",
      "Epoch 48, Step: 63, Loss: 0.08388983458280563, Lr:0.0001\n",
      "Epoch 48, Step: 64, Loss: 0.7395980358123779, Lr:0.0001\n",
      "Epoch 48, Step: 65, Loss: 1.3904621601104736, Lr:0.0001\n",
      "Epoch 48, Step: 66, Loss: 0.05602595955133438, Lr:0.0001\n",
      "Epoch 48, Step: 67, Loss: 0.41481590270996094, Lr:0.0001\n",
      "Epoch 48, Step: 68, Loss: 0.19395841658115387, Lr:0.0001\n",
      "Epoch 48, Step: 69, Loss: 0.009958435781300068, Lr:0.0001\n",
      "Epoch 48, Step: 70, Loss: 0.25531595945358276, Lr:0.0001\n",
      "Epoch 48, Step: 71, Loss: 0.3147468566894531, Lr:0.0001\n",
      "Epoch 48, Step: 72, Loss: 0.8974997401237488, Lr:0.0001\n",
      "Epoch 48, Step: 73, Loss: 0.46661368012428284, Lr:0.0001\n",
      "Epoch 48, Step: 74, Loss: 0.44580990076065063, Lr:0.0001\n",
      "Epoch 48, Step: 75, Loss: 0.129609152674675, Lr:0.0001\n",
      "Epoch 48, Step: 76, Loss: 0.3551139533519745, Lr:0.0001\n",
      "Epoch 48, Step: 77, Loss: 0.29681503772735596, Lr:0.0001\n",
      "Epoch 48, Step: 78, Loss: 0.13574723899364471, Lr:0.0001\n",
      "Epoch 48, Step: 79, Loss: 0.05154193937778473, Lr:0.0001\n",
      "Epoch 48, Step: 80, Loss: 0.029305096715688705, Lr:0.0001\n",
      "Epoch 48, Step: 81, Loss: 0.7075204849243164, Lr:0.0001\n",
      "Epoch 48, Step: 82, Loss: 0.6392203569412231, Lr:0.0001\n",
      "Epoch 48, Step: 83, Loss: 1.0256997346878052, Lr:0.0001\n",
      "Epoch 48, Step: 84, Loss: 0.6838176250457764, Lr:0.0001\n",
      "Epoch 48, Step: 85, Loss: 0.1782287359237671, Lr:0.0001\n",
      "Epoch 48, Step: 86, Loss: 0.1390131562948227, Lr:0.0001\n",
      "Epoch 48, Step: 87, Loss: 0.19610102474689484, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 48\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.0117 (0.0117) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0120 data: 0.0060 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.0117 (0.2341) acc1: 100.0000 (86.3636) acc5: 100.0000 (100.0000) time: 0.0093 data: 0.0042 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0093 s / it)\n",
      "* Acc@1 86.364 Acc@5 100.000 loss 0.234\n",
      "Accuracy of the network on the 22 test image: 86.4%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 49, Step: 0, Loss: 0.03355064615607262, Lr:0.0001\n",
      "Epoch 49, Step: 1, Loss: 0.47769007086753845, Lr:0.0001\n",
      "Epoch 49, Step: 2, Loss: 0.41538205742836, Lr:0.0001\n",
      "Epoch 49, Step: 3, Loss: 1.4169654846191406, Lr:0.0001\n",
      "Epoch 49, Step: 4, Loss: 0.03216816484928131, Lr:0.0001\n",
      "Epoch 49, Step: 5, Loss: 3.303478717803955, Lr:0.0001\n",
      "Epoch 49, Step: 6, Loss: 0.34089356660842896, Lr:0.0001\n",
      "Epoch 49, Step: 7, Loss: 0.050254978239536285, Lr:0.0001\n",
      "Epoch 49, Step: 8, Loss: 0.13463537395000458, Lr:0.0001\n",
      "Epoch 49, Step: 9, Loss: 0.4138350784778595, Lr:0.0001\n",
      "Epoch 49, Step: 10, Loss: 0.09005413949489594, Lr:0.0001\n",
      "Epoch 49, Step: 11, Loss: 0.795792818069458, Lr:0.0001\n",
      "Epoch 49, Step: 12, Loss: 0.3866043984889984, Lr:0.0001\n",
      "Epoch 49, Step: 13, Loss: 0.43286335468292236, Lr:0.0001\n",
      "Epoch 49, Step: 14, Loss: 0.053630828857421875, Lr:0.0001\n",
      "Epoch 49, Step: 15, Loss: 0.578589916229248, Lr:0.0001\n",
      "Epoch 49, Step: 16, Loss: 0.508682131767273, Lr:0.0001\n",
      "Epoch 49, Step: 17, Loss: 0.7539827227592468, Lr:0.0001\n",
      "Epoch 49, Step: 18, Loss: 0.44172918796539307, Lr:0.0001\n",
      "Epoch 49, Step: 19, Loss: 0.3154065012931824, Lr:0.0001\n",
      "Epoch 49, Step: 20, Loss: 0.20469269156455994, Lr:0.0001\n",
      "Epoch 49, Step: 21, Loss: 1.0624935626983643, Lr:0.0001\n",
      "Epoch 49, Step: 22, Loss: 0.009546665474772453, Lr:0.0001\n",
      "Epoch 49, Step: 23, Loss: 0.006288063246756792, Lr:0.0001\n",
      "Epoch 49, Step: 24, Loss: 0.4480704665184021, Lr:0.0001\n",
      "Epoch 49, Step: 25, Loss: 0.14821816980838776, Lr:0.0001\n",
      "Epoch 49, Step: 26, Loss: 0.26808011531829834, Lr:0.0001\n",
      "Epoch 49, Step: 27, Loss: 0.04060009866952896, Lr:0.0001\n",
      "Epoch 49, Step: 28, Loss: 0.25302502512931824, Lr:0.0001\n",
      "Epoch 49, Step: 29, Loss: 0.3911743760108948, Lr:0.0001\n",
      "Epoch 49, Step: 30, Loss: 0.05185295268893242, Lr:0.0001\n",
      "Epoch 49, Step: 31, Loss: 0.18864035606384277, Lr:0.0001\n",
      "Epoch 49, Step: 32, Loss: 0.19313621520996094, Lr:0.0001\n",
      "Epoch 49, Step: 33, Loss: 0.027455832809209824, Lr:0.0001\n",
      "Epoch 49, Step: 34, Loss: 0.07099610567092896, Lr:0.0001\n",
      "Epoch 49, Step: 35, Loss: 0.6734113097190857, Lr:0.0001\n",
      "Epoch 49, Step: 36, Loss: 0.4607588052749634, Lr:0.0001\n",
      "Epoch 49, Step: 37, Loss: 1.167051911354065, Lr:0.0001\n",
      "Epoch 49, Step: 38, Loss: 0.041092805564403534, Lr:0.0001\n",
      "Epoch 49, Step: 39, Loss: 0.14589574933052063, Lr:0.0001\n",
      "Epoch 49, Step: 40, Loss: 0.20705026388168335, Lr:0.0001\n",
      "Epoch 49, Step: 41, Loss: 0.1282578706741333, Lr:0.0001\n",
      "Epoch 49, Step: 42, Loss: 0.27451586723327637, Lr:0.0001\n",
      "Epoch 49, Step: 43, Loss: 0.4259355366230011, Lr:0.0001\n",
      "Epoch 49, Step: 44, Loss: 0.4393569231033325, Lr:0.0001\n",
      "Epoch 49, Step: 45, Loss: 0.25703123211860657, Lr:0.0001\n",
      "Epoch 49, Step: 46, Loss: 0.006269851699471474, Lr:0.0001\n",
      "Epoch 49, Step: 47, Loss: 0.0934995487332344, Lr:0.0001\n",
      "Epoch 49, Step: 48, Loss: 0.0024577805306762457, Lr:0.0001\n",
      "Epoch 49, Step: 49, Loss: 0.5014515519142151, Lr:0.0001\n",
      "Epoch 49, Step: 50, Loss: 0.7413010597229004, Lr:0.0001\n",
      "Epoch 49, Step: 51, Loss: 0.009936362504959106, Lr:0.0001\n",
      "Epoch 49, Step: 52, Loss: 0.033240605145692825, Lr:0.0001\n",
      "Epoch 49, Step: 53, Loss: 0.7809260487556458, Lr:0.0001\n",
      "Epoch 49, Step: 54, Loss: 0.22363433241844177, Lr:0.0001\n",
      "Epoch 49, Step: 55, Loss: 0.1064271554350853, Lr:0.0001\n",
      "Epoch 49, Step: 56, Loss: 0.129922553896904, Lr:0.0001\n",
      "Epoch 49, Step: 57, Loss: 3.379061222076416, Lr:0.0001\n",
      "Epoch 49, Step: 58, Loss: 0.1821548342704773, Lr:0.0001\n",
      "Epoch 49, Step: 59, Loss: 0.2973308861255646, Lr:0.0001\n",
      "Epoch 49, Step: 60, Loss: 0.40208062529563904, Lr:0.0001\n",
      "Epoch 49, Step: 61, Loss: 0.20516656339168549, Lr:0.0001\n",
      "Epoch 49, Step: 62, Loss: 0.2065967619419098, Lr:0.0001\n",
      "Epoch 49, Step: 63, Loss: 0.47431135177612305, Lr:0.0001\n",
      "Epoch 49, Step: 64, Loss: 0.10947246849536896, Lr:0.0001\n",
      "Epoch 49, Step: 65, Loss: 0.37653642892837524, Lr:0.0001\n",
      "Epoch 49, Step: 66, Loss: 0.17629435658454895, Lr:0.0001\n",
      "Epoch 49, Step: 67, Loss: 0.06816759705543518, Lr:0.0001\n",
      "Epoch 49, Step: 68, Loss: 0.9351028203964233, Lr:0.0001\n",
      "Epoch 49, Step: 69, Loss: 0.6790684461593628, Lr:0.0001\n",
      "Epoch 49, Step: 70, Loss: 0.2910619378089905, Lr:0.0001\n",
      "Epoch 49, Step: 71, Loss: 0.02167644165456295, Lr:0.0001\n",
      "Epoch 49, Step: 72, Loss: 0.4677489399909973, Lr:0.0001\n",
      "Epoch 49, Step: 73, Loss: 0.6293228268623352, Lr:0.0001\n",
      "Epoch 49, Step: 74, Loss: 0.3849545121192932, Lr:0.0001\n",
      "Epoch 49, Step: 75, Loss: 0.4215044677257538, Lr:0.0001\n",
      "Epoch 49, Step: 76, Loss: 0.31874412298202515, Lr:0.0001\n",
      "Epoch 49, Step: 77, Loss: 0.1787220537662506, Lr:0.0001\n",
      "Epoch 49, Step: 78, Loss: 0.026598922908306122, Lr:0.0001\n",
      "Epoch 49, Step: 79, Loss: 0.2686476707458496, Lr:0.0001\n",
      "Epoch 49, Step: 80, Loss: 0.3293716311454773, Lr:0.0001\n",
      "Epoch 49, Step: 81, Loss: 0.31676262617111206, Lr:0.0001\n",
      "Epoch 49, Step: 82, Loss: 0.20716895163059235, Lr:0.0001\n",
      "Epoch 49, Step: 83, Loss: 1.0411689281463623, Lr:0.0001\n",
      "Epoch 49, Step: 84, Loss: 0.0651615783572197, Lr:0.0001\n",
      "Epoch 49, Step: 85, Loss: 0.41538646817207336, Lr:0.0001\n",
      "Epoch 49, Step: 86, Loss: 0.002604889217764139, Lr:0.0001\n",
      "Epoch 49, Step: 87, Loss: 1.2559653520584106, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "Epoch 49\n",
      "length of data_loader_train is 88\n",
      "Evaluating...\n",
      "Test: [0/6] eta: 0:00:00 loss: 0.0429 (0.0429) acc1: 100.0000 (100.0000) acc5: 100.0000 (100.0000) time: 0.0080 data: 0.0050 max mem: 396\n",
      "Test: [5/6] eta: 0:00:00 loss: 0.0192 (0.3518) acc1: 100.0000 (86.3636) acc5: 100.0000 (100.0000) time: 0.0072 data: 0.0037 max mem: 396\n",
      "Test: Total time: 0:00:00 (0.0073 s / it)\n",
      "* Acc@1 86.364 Acc@5 100.000 loss 0.352\n",
      "Accuracy of the network on the 22 test image: 86.4%\n",
      "Training...\n",
      "log_dir: ./resnet_output_dir\n",
      "Epoch 50, Step: 0, Loss: 0.10585236549377441, Lr:0.0001\n",
      "Epoch 50, Step: 1, Loss: 0.6297699809074402, Lr:0.0001\n",
      "Epoch 50, Step: 2, Loss: 0.42280301451683044, Lr:0.0001\n",
      "Epoch 50, Step: 3, Loss: 0.7875493168830872, Lr:0.0001\n",
      "Epoch 50, Step: 4, Loss: 0.1892530769109726, Lr:0.0001\n",
      "Epoch 50, Step: 5, Loss: 0.12410597503185272, Lr:0.0001\n",
      "Epoch 50, Step: 6, Loss: 0.09786245226860046, Lr:0.0001\n",
      "Epoch 50, Step: 7, Loss: 0.36638370156288147, Lr:0.0001\n",
      "Epoch 50, Step: 8, Loss: 0.26792654395103455, Lr:0.0001\n",
      "Epoch 50, Step: 9, Loss: 0.7299929857254028, Lr:0.0001\n",
      "Epoch 50, Step: 10, Loss: 0.28975504636764526, Lr:0.0001\n",
      "Epoch 50, Step: 11, Loss: 1.5118505954742432, Lr:0.0001\n",
      "Epoch 50, Step: 12, Loss: 0.21045710146427155, Lr:0.0001\n",
      "Epoch 50, Step: 13, Loss: 0.2613217234611511, Lr:0.0001\n",
      "Epoch 50, Step: 14, Loss: 0.024228155612945557, Lr:0.0001\n",
      "Epoch 50, Step: 15, Loss: 0.6651597023010254, Lr:0.0001\n",
      "Epoch 50, Step: 16, Loss: 0.17042411863803864, Lr:0.0001\n",
      "Epoch 50, Step: 17, Loss: 0.01840982586145401, Lr:0.0001\n",
      "Epoch 50, Step: 18, Loss: 0.6527109146118164, Lr:0.0001\n",
      "Epoch 50, Step: 19, Loss: 0.03611879423260689, Lr:0.0001\n",
      "Epoch 50, Step: 20, Loss: 0.020639726892113686, Lr:0.0001\n",
      "Epoch 50, Step: 21, Loss: 0.2252679467201233, Lr:0.0001\n",
      "Epoch 50, Step: 22, Loss: 0.3419386148452759, Lr:0.0001\n",
      "Epoch 50, Step: 23, Loss: 0.029461530968546867, Lr:0.0001\n",
      "Epoch 50, Step: 24, Loss: 0.26893150806427, Lr:0.0001\n",
      "Epoch 50, Step: 25, Loss: 0.49923938512802124, Lr:0.0001\n",
      "Epoch 50, Step: 26, Loss: 0.011914627626538277, Lr:0.0001\n",
      "Epoch 50, Step: 27, Loss: 0.01014447771012783, Lr:0.0001\n",
      "Epoch 50, Step: 28, Loss: 0.6687481999397278, Lr:0.0001\n",
      "Epoch 50, Step: 29, Loss: 0.14458797872066498, Lr:0.0001\n",
      "Epoch 50, Step: 30, Loss: 0.4886350631713867, Lr:0.0001\n",
      "Epoch 50, Step: 31, Loss: 0.003143787384033203, Lr:0.0001\n",
      "Epoch 50, Step: 32, Loss: 0.7909796237945557, Lr:0.0001\n",
      "Epoch 50, Step: 33, Loss: 0.0279669389128685, Lr:0.0001\n",
      "Epoch 50, Step: 34, Loss: 0.09795290231704712, Lr:0.0001\n",
      "Epoch 50, Step: 35, Loss: 0.0028313924558460712, Lr:0.0001\n",
      "Epoch 50, Step: 36, Loss: 0.16870972514152527, Lr:0.0001\n",
      "Epoch 50, Step: 37, Loss: 1.0503718852996826, Lr:0.0001\n",
      "Epoch 50, Step: 38, Loss: 0.036840226501226425, Lr:0.0001\n",
      "Epoch 50, Step: 39, Loss: 1.2511674165725708, Lr:0.0001\n",
      "Epoch 50, Step: 40, Loss: 0.0042624385096132755, Lr:0.0001\n",
      "Epoch 50, Step: 41, Loss: 0.004031733144074678, Lr:0.0001\n",
      "Epoch 50, Step: 42, Loss: 1.1544928550720215, Lr:0.0001\n",
      "Epoch 50, Step: 43, Loss: 0.9019265174865723, Lr:0.0001\n",
      "Epoch 50, Step: 44, Loss: 0.08725975453853607, Lr:0.0001\n",
      "Epoch 50, Step: 45, Loss: 0.05057844892144203, Lr:0.0001\n",
      "Epoch 50, Step: 46, Loss: 0.17917613685131073, Lr:0.0001\n",
      "Epoch 50, Step: 47, Loss: 0.12063078582286835, Lr:0.0001\n",
      "Epoch 50, Step: 48, Loss: 0.14769358932971954, Lr:0.0001\n",
      "Epoch 50, Step: 49, Loss: 0.27841827273368835, Lr:0.0001\n",
      "Epoch 50, Step: 50, Loss: 0.41445276141166687, Lr:0.0001\n",
      "Epoch 50, Step: 51, Loss: 0.06893399357795715, Lr:0.0001\n",
      "Epoch 50, Step: 52, Loss: 0.44416406750679016, Lr:0.0001\n",
      "Epoch 50, Step: 53, Loss: 0.6263694167137146, Lr:0.0001\n",
      "Epoch 50, Step: 54, Loss: 0.043113622814416885, Lr:0.0001\n",
      "Epoch 50, Step: 55, Loss: 0.8939844369888306, Lr:0.0001\n",
      "Epoch 50, Step: 56, Loss: 0.2987978160381317, Lr:0.0001\n",
      "Epoch 50, Step: 57, Loss: 0.14682765305042267, Lr:0.0001\n",
      "Epoch 50, Step: 58, Loss: 0.420363187789917, Lr:0.0001\n",
      "Epoch 50, Step: 59, Loss: 0.16734182834625244, Lr:0.0001\n",
      "Epoch 50, Step: 60, Loss: 0.1753418892621994, Lr:0.0001\n",
      "Epoch 50, Step: 61, Loss: 0.3325992524623871, Lr:0.0001\n",
      "Epoch 50, Step: 62, Loss: 0.0036384405102580786, Lr:0.0001\n",
      "Epoch 50, Step: 63, Loss: 0.4092191755771637, Lr:0.0001\n",
      "Epoch 50, Step: 64, Loss: 0.40235260128974915, Lr:0.0001\n",
      "Epoch 50, Step: 65, Loss: 0.06373129040002823, Lr:0.0001\n",
      "Epoch 50, Step: 66, Loss: 0.0509420782327652, Lr:0.0001\n",
      "Epoch 50, Step: 67, Loss: 0.8744491338729858, Lr:0.0001\n",
      "Epoch 50, Step: 68, Loss: 0.11279244720935822, Lr:0.0001\n",
      "Epoch 50, Step: 69, Loss: 0.6147350668907166, Lr:0.0001\n",
      "Epoch 50, Step: 70, Loss: 0.2969222366809845, Lr:0.0001\n",
      "Epoch 50, Step: 71, Loss: 0.0033378724474459887, Lr:0.0001\n",
      "Epoch 50, Step: 72, Loss: 0.007710301782935858, Lr:0.0001\n",
      "Epoch 50, Step: 73, Loss: 0.5810864567756653, Lr:0.0001\n",
      "Epoch 50, Step: 74, Loss: 0.45566117763519287, Lr:0.0001\n",
      "Epoch 50, Step: 75, Loss: 0.1413985639810562, Lr:0.0001\n",
      "Epoch 50, Step: 76, Loss: 0.15345370769500732, Lr:0.0001\n",
      "Epoch 50, Step: 77, Loss: 0.0009684372344054282, Lr:0.0001\n",
      "Epoch 50, Step: 78, Loss: 0.0013977927155792713, Lr:0.0001\n",
      "Epoch 50, Step: 79, Loss: 0.4464852511882782, Lr:0.0001\n",
      "Epoch 50, Step: 80, Loss: 0.13032865524291992, Lr:0.0001\n",
      "Epoch 50, Step: 81, Loss: 0.4685257375240326, Lr:0.0001\n",
      "Epoch 50, Step: 82, Loss: 0.35815271735191345, Lr:0.0001\n",
      "Epoch 50, Step: 83, Loss: 0.43358248472213745, Lr:0.0001\n",
      "Epoch 50, Step: 84, Loss: 0.028907759115099907, Lr:0.0001\n",
      "Epoch 50, Step: 85, Loss: 0.45271021127700806, Lr:0.0001\n",
      "Epoch 50, Step: 86, Loss: 0.2108171433210373, Lr:0.0001\n",
      "Epoch 50, Step: 87, Loss: 0.03578619286417961, Lr:0.0001\n",
      "Saving checkpoints...\n",
      "best acc is 90.9090909090909 at 35 epoch\n"
     ]
    }
   ],
   "source": [
    "%run resnet_baseline/train.py --mode train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c72039-fdb5-4553-89c3-6f00ab3c7579",
   "metadata": {},
   "source": [
    "# 使用tensorboard查看训练结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8610d80c-c3c7-4fa6-9617-5493bec753d1",
   "metadata": {},
   "source": [
    "http://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cfd9eb6-12b4-4e3d-9554-19b8d412d531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=./resnet_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4493fc4e-7aaf-4db0-9b6f-3d584b87dc17",
   "metadata": {},
   "source": [
    "# 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73606596-cc45-42c2-844e-4f24c62305ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\1y9UDX.jpg\n",
      "score is 0.6367442607879639, class id is 4, class name is Tis\n",
      "1y9UDX\n",
      "4\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\4mF7tL.jpg\n",
      "score is 0.9307817220687866, class id is 3, class name is T3\n",
      "4mF7tL\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\B5MAwD.jpg\n",
      "score is 0.5825316905975342, class id is 4, class name is Tis\n",
      "B5MAwD\n",
      "4\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\cRnBLx.jpg\n",
      "score is 0.7667100429534912, class id is 1, class name is T1\n",
      "cRnBLx\n",
      "1\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\gfozad.jpg\n",
      "score is 0.6584815382957458, class id is 3, class name is T3\n",
      "gfozad\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\i0v7lq.jpg\n",
      "score is 0.48403671383857727, class id is 2, class name is T2\n",
      "i0v7lq\n",
      "2\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\iQUs4h.jpg\n",
      "score is 0.5784178376197815, class id is 4, class name is Tis\n",
      "iQUs4h\n",
      "4\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\Jw1GFk.jpg\n",
      "score is 0.4023076295852661, class id is 0, class name is T0\n",
      "Jw1GFk\n",
      "0\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\K2f9Nb.jpg\n",
      "score is 0.9811665415763855, class id is 3, class name is T3\n",
      "K2f9Nb\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\kOUcud.jpg\n",
      "score is 0.5825175642967224, class id is 0, class name is T0\n",
      "kOUcud\n",
      "0\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\kQPIhs.jpg\n",
      "score is 0.5675061345100403, class id is 3, class name is T3\n",
      "kQPIhs\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\KRuNrD.jpg\n",
      "score is 0.4918133318424225, class id is 0, class name is T0\n",
      "KRuNrD\n",
      "0\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\lc3OZp.jpg\n",
      "score is 0.5095081925392151, class id is 3, class name is T3\n",
      "lc3OZp\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\lg0CwS.jpg\n",
      "score is 0.5100996494293213, class id is 0, class name is T0\n",
      "lg0CwS\n",
      "0\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\lO9MmB.jpg\n",
      "score is 0.5758810639381409, class id is 3, class name is T3\n",
      "lO9MmB\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\LRJwmg.jpg\n",
      "score is 0.5037462711334229, class id is 3, class name is T3\n",
      "LRJwmg\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\LrKXU4.jpg\n",
      "score is 0.4048764705657959, class id is 3, class name is T3\n",
      "LrKXU4\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\m14lJk.jpg\n",
      "score is 0.28117913007736206, class id is 3, class name is T3\n",
      "m14lJk\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\MHNQ4e.jpg\n",
      "score is 0.5811245441436768, class id is 0, class name is T0\n",
      "MHNQ4e\n",
      "0\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\miuArM.jpg\n",
      "score is 0.39940178394317627, class id is 3, class name is T3\n",
      "miuArM\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\N4HDTG.jpg\n",
      "score is 0.47508230805397034, class id is 3, class name is T3\n",
      "N4HDTG\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\NGynsT.jpg\n",
      "score is 0.3655942976474762, class id is 3, class name is T3\n",
      "NGynsT\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\OyS7Ax.jpg\n",
      "score is 0.36638742685317993, class id is 0, class name is T0\n",
      "OyS7Ax\n",
      "0\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\Pdaqkr.jpg\n",
      "score is 0.3871254324913025, class id is 1, class name is T1\n",
      "Pdaqkr\n",
      "1\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\PDmefU.jpg\n",
      "score is 0.34969350695610046, class id is 1, class name is T1\n",
      "PDmefU\n",
      "1\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\PhoFHq.jpg\n",
      "score is 0.5301116704940796, class id is 0, class name is T0\n",
      "PhoFHq\n",
      "0\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\s7iuvj.jpg\n",
      "score is 0.6729452610015869, class id is 3, class name is T3\n",
      "s7iuvj\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\sPBTxE.jpg\n",
      "score is 0.5994735360145569, class id is 4, class name is Tis\n",
      "sPBTxE\n",
      "4\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\tePz9r.jpg\n",
      "score is 0.8159209489822388, class id is 4, class name is Tis\n",
      "tePz9r\n",
      "4\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\trx9ej.jpg\n",
      "score is 0.6368456482887268, class id is 0, class name is T0\n",
      "trx9ej\n",
      "0\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\tZl5k7.jpg\n",
      "score is 0.4222608506679535, class id is 3, class name is T3\n",
      "tZl5k7\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\uBGVp5.jpg\n",
      "score is 0.5385586023330688, class id is 4, class name is Tis\n",
      "uBGVp5\n",
      "4\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\uj56hr.jpg\n",
      "score is 0.4209648668766022, class id is 1, class name is T1\n",
      "uj56hr\n",
      "1\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\vLZGD6.jpg\n",
      "score is 0.5420832633972168, class id is 3, class name is T3\n",
      "vLZGD6\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\vNxSRB.jpg\n",
      "score is 0.7635200619697571, class id is 3, class name is T3\n",
      "vNxSRB\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\vPE2HD.jpg\n",
      "score is 0.4463678002357483, class id is 3, class name is T3\n",
      "vPE2HD\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\w2Qbz8.jpg\n",
      "score is 0.4968809187412262, class id is 3, class name is T3\n",
      "w2Qbz8\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\Wp3Lv9.jpg\n",
      "score is 0.3836444020271301, class id is 3, class name is T3\n",
      "Wp3Lv9\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\wuCWgz.jpg\n",
      "score is 0.7152212858200073, class id is 3, class name is T3\n",
      "wuCWgz\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\Y1gva6.jpg\n",
      "score is 0.5768550634384155, class id is 1, class name is T1\n",
      "Y1gva6\n",
      "1\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\yuBHAm.jpg\n",
      "score is 0.9996565580368042, class id is 3, class name is T3\n",
      "yuBHAm\n",
      "3\n",
      "\n",
      "\n",
      "infer mode...\n",
      "number of trainable params (M): 11.18\n",
      "Resume checkpoint ./resnet_output_dir/checkpoint-35.pth\n",
      "With optim & sched!\n",
      "image path is ./Test\\zIGPHq.jpg\n",
      "score is 0.598345160484314, class id is 2, class name is T2\n",
      "zIGPHq\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "%run resnet_baseline/train.py --mode infer --resume ./resnet_output_dir/checkpoint-35.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb294c8-415a-42de-97f7-556b950a7c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
